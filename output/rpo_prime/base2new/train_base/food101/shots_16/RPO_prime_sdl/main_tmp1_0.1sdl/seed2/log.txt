***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
816 10200 15300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  51
# train_x  816
# val      10,200
# test     15,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
epoch [1/30] batch [20/204] time 0.250 (0.385) data 0.000 (0.057) loss 0.4346 (1.6750) lr 1.0000e-02 eta 0:39:06
epoch [1/30] batch [40/204] time 0.259 (0.320) data 0.000 (0.029) loss 0.9854 (1.7266) lr 1.0000e-02 eta 0:32:26
epoch [1/30] batch [60/204] time 0.249 (0.298) data 0.000 (0.019) loss 0.9834 (1.7181) lr 1.0000e-02 eta 0:30:05
epoch [1/30] batch [80/204] time 0.249 (0.287) data 0.000 (0.014) loss 1.1123 (1.4852) lr 1.0000e-02 eta 0:28:54
epoch [1/30] batch [100/204] time 0.256 (0.282) data 0.000 (0.012) loss 5.1094 (1.4716) lr 1.0000e-02 eta 0:28:15
epoch [1/30] batch [120/204] time 0.257 (0.277) data 0.000 (0.010) loss 1.3867 (1.4113) lr 1.0000e-02 eta 0:27:43
epoch [1/30] batch [140/204] time 0.253 (0.274) data 0.000 (0.008) loss 2.1250 (1.4383) lr 1.0000e-02 eta 0:27:18
epoch [1/30] batch [160/204] time 0.252 (0.272) data 0.000 (0.007) loss 0.0549 (1.4096) lr 1.0000e-02 eta 0:26:58
epoch [1/30] batch [180/204] time 0.242 (0.269) data 0.000 (0.007) loss 5.0859 (1.3897) lr 1.0000e-02 eta 0:26:38
epoch [1/30] batch [200/204] time 0.241 (0.267) data 0.000 (0.006) loss 0.6323 (1.3926) lr 1.0000e-02 eta 0:26:18
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,130
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 89.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
epoch [2/30] batch [20/204] time 0.247 (0.297) data 0.000 (0.037) loss 1.4033 (1.2563) lr 9.9726e-03 eta 0:29:09
epoch [2/30] batch [40/204] time 0.254 (0.275) data 0.000 (0.019) loss 1.0508 (1.1424) lr 9.9726e-03 eta 0:26:58
epoch [2/30] batch [60/204] time 0.256 (0.268) data 0.000 (0.013) loss 2.6289 (1.1121) lr 9.9726e-03 eta 0:26:10
epoch [2/30] batch [80/204] time 0.247 (0.266) data 0.000 (0.010) loss 0.2900 (1.1288) lr 9.9726e-03 eta 0:25:50
epoch [2/30] batch [100/204] time 0.251 (0.263) data 0.000 (0.008) loss 0.7324 (1.1139) lr 9.9726e-03 eta 0:25:30
epoch [2/30] batch [120/204] time 0.252 (0.261) data 0.000 (0.006) loss 0.2585 (1.1589) lr 9.9726e-03 eta 0:25:13
epoch [2/30] batch [140/204] time 0.251 (0.260) data 0.000 (0.006) loss 0.0618 (1.1400) lr 9.9726e-03 eta 0:25:01
epoch [2/30] batch [160/204] time 0.253 (0.259) data 0.000 (0.005) loss 0.0201 (1.1394) lr 9.9726e-03 eta 0:24:50
epoch [2/30] batch [180/204] time 0.246 (0.258) data 0.000 (0.004) loss 0.7344 (1.1706) lr 9.9726e-03 eta 0:24:38
epoch [2/30] batch [200/204] time 0.241 (0.256) data 0.000 (0.004) loss 0.9492 (1.2144) lr 9.9726e-03 eta 0:24:24
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,163
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 89.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
epoch [3/30] batch [20/204] time 0.252 (0.296) data 0.000 (0.039) loss 3.1406 (1.2590) lr 9.8907e-03 eta 0:28:05
epoch [3/30] batch [40/204] time 0.251 (0.276) data 0.000 (0.020) loss 0.3027 (1.2122) lr 9.8907e-03 eta 0:26:02
epoch [3/30] batch [60/204] time 0.255 (0.269) data 0.000 (0.013) loss 0.4314 (1.1270) lr 9.8907e-03 eta 0:25:17
epoch [3/30] batch [80/204] time 0.257 (0.266) data 0.000 (0.010) loss 2.3828 (1.1297) lr 9.8907e-03 eta 0:24:58
epoch [3/30] batch [100/204] time 0.252 (0.264) data 0.000 (0.008) loss 2.2148 (1.0794) lr 9.8907e-03 eta 0:24:39
epoch [3/30] batch [120/204] time 0.249 (0.262) data 0.000 (0.007) loss -0.0496 (1.0909) lr 9.8907e-03 eta 0:24:23
epoch [3/30] batch [140/204] time 0.260 (0.261) data 0.000 (0.006) loss 0.0703 (1.1016) lr 9.8907e-03 eta 0:24:12
epoch [3/30] batch [160/204] time 0.252 (0.260) data 0.000 (0.005) loss 1.7158 (1.1462) lr 9.8907e-03 eta 0:24:02
epoch [3/30] batch [180/204] time 0.241 (0.258) data 0.000 (0.005) loss 0.0151 (1.1521) lr 9.8907e-03 eta 0:23:49
epoch [3/30] batch [200/204] time 0.241 (0.257) data 0.000 (0.004) loss 0.3433 (1.1678) lr 9.8907e-03 eta 0:23:35
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,177
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
epoch [4/30] batch [20/204] time 0.251 (0.302) data 0.000 (0.039) loss 2.5625 (1.2748) lr 9.7553e-03 eta 0:27:37
epoch [4/30] batch [40/204] time 0.254 (0.277) data 0.000 (0.020) loss -0.0342 (1.2926) lr 9.7553e-03 eta 0:25:15
epoch [4/30] batch [60/204] time 0.249 (0.270) data 0.000 (0.013) loss 0.6421 (1.1619) lr 9.7553e-03 eta 0:24:28
epoch [4/30] batch [80/204] time 0.254 (0.266) data 0.000 (0.010) loss -0.0421 (1.1211) lr 9.7553e-03 eta 0:24:04
epoch [4/30] batch [100/204] time 0.256 (0.264) data 0.000 (0.008) loss 3.4141 (1.1612) lr 9.7553e-03 eta 0:23:50
epoch [4/30] batch [120/204] time 0.250 (0.263) data 0.000 (0.007) loss 2.5996 (1.1917) lr 9.7553e-03 eta 0:23:35
epoch [4/30] batch [140/204] time 0.253 (0.262) data 0.000 (0.006) loss 0.0764 (1.1984) lr 9.7553e-03 eta 0:23:24
epoch [4/30] batch [160/204] time 0.251 (0.261) data 0.000 (0.005) loss 0.0480 (1.2014) lr 9.7553e-03 eta 0:23:14
epoch [4/30] batch [180/204] time 0.243 (0.260) data 0.000 (0.005) loss 0.7319 (1.2232) lr 9.7553e-03 eta 0:23:02
epoch [4/30] batch [200/204] time 0.240 (0.258) data 0.000 (0.004) loss 0.1902 (1.2206) lr 9.7553e-03 eta 0:22:48
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,172
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.9%
epoch [5/30] batch [20/204] time 0.256 (0.296) data 0.000 (0.041) loss -0.0020 (1.5121) lr 9.5677e-03 eta 0:26:03
epoch [5/30] batch [40/204] time 0.253 (0.277) data 0.000 (0.021) loss 0.0966 (1.5695) lr 9.5677e-03 eta 0:24:16
epoch [5/30] batch [60/204] time 0.254 (0.269) data 0.000 (0.014) loss 0.0596 (1.3783) lr 9.5677e-03 eta 0:23:28
epoch [5/30] batch [80/204] time 0.258 (0.265) data 0.000 (0.010) loss 2.7402 (1.3421) lr 9.5677e-03 eta 0:23:03
epoch [5/30] batch [100/204] time 0.254 (0.263) data 0.000 (0.008) loss 0.6094 (1.2767) lr 9.5677e-03 eta 0:22:49
epoch [5/30] batch [120/204] time 0.249 (0.261) data 0.000 (0.007) loss 5.7969 (1.2806) lr 9.5677e-03 eta 0:22:34
epoch [5/30] batch [140/204] time 0.261 (0.260) data 0.000 (0.006) loss 0.6016 (1.3002) lr 9.5677e-03 eta 0:22:23
epoch [5/30] batch [160/204] time 0.247 (0.259) data 0.000 (0.005) loss 3.8594 (1.3195) lr 9.5677e-03 eta 0:22:12
epoch [5/30] batch [180/204] time 0.242 (0.258) data 0.000 (0.005) loss 0.6743 (1.3133) lr 9.5677e-03 eta 0:22:01
epoch [5/30] batch [200/204] time 0.240 (0.256) data 0.000 (0.004) loss 4.4297 (1.3038) lr 9.5677e-03 eta 0:21:47
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,172
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.9%
epoch [6/30] batch [20/204] time 0.255 (0.299) data 0.000 (0.037) loss 0.0593 (1.5233) lr 9.3301e-03 eta 0:25:17
epoch [6/30] batch [40/204] time 0.261 (0.280) data 0.000 (0.019) loss 0.8569 (1.2070) lr 9.3301e-03 eta 0:23:34
epoch [6/30] batch [60/204] time 0.252 (0.271) data 0.000 (0.013) loss -0.0328 (1.2441) lr 9.3301e-03 eta 0:22:45
epoch [6/30] batch [80/204] time 0.248 (0.267) data 0.000 (0.010) loss 2.6152 (1.2725) lr 9.3301e-03 eta 0:22:19
epoch [6/30] batch [100/204] time 0.255 (0.265) data 0.000 (0.008) loss 0.2018 (1.2758) lr 9.3301e-03 eta 0:22:04
epoch [6/30] batch [120/204] time 0.251 (0.263) data 0.000 (0.006) loss 0.0954 (1.1848) lr 9.3301e-03 eta 0:21:49
epoch [6/30] batch [140/204] time 0.250 (0.261) data 0.000 (0.006) loss 0.2379 (1.1373) lr 9.3301e-03 eta 0:21:36
epoch [6/30] batch [160/204] time 0.250 (0.260) data 0.000 (0.005) loss 0.8442 (1.1163) lr 9.3301e-03 eta 0:21:25
epoch [6/30] batch [180/204] time 0.242 (0.259) data 0.000 (0.004) loss 0.8232 (1.1194) lr 9.3301e-03 eta 0:21:13
epoch [6/30] batch [200/204] time 0.239 (0.257) data 0.000 (0.004) loss 0.7451 (1.1227) lr 9.3301e-03 eta 0:20:59
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,184
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
epoch [7/30] batch [20/204] time 0.250 (0.296) data 0.000 (0.042) loss 0.0989 (1.0152) lr 9.0451e-03 eta 0:24:03
epoch [7/30] batch [40/204] time 0.254 (0.277) data 0.000 (0.021) loss 4.8750 (1.2897) lr 9.0451e-03 eta 0:22:24
epoch [7/30] batch [60/204] time 0.255 (0.269) data 0.000 (0.014) loss 0.4666 (1.1851) lr 9.0451e-03 eta 0:21:42
epoch [7/30] batch [80/204] time 0.252 (0.265) data 0.000 (0.011) loss 1.6797 (1.1434) lr 9.0451e-03 eta 0:21:15
epoch [7/30] batch [100/204] time 0.255 (0.264) data 0.000 (0.009) loss 2.3633 (1.0422) lr 9.0451e-03 eta 0:21:03
epoch [7/30] batch [120/204] time 0.249 (0.262) data 0.000 (0.007) loss 0.0918 (1.0810) lr 9.0451e-03 eta 0:20:49
epoch [7/30] batch [140/204] time 0.253 (0.260) data 0.000 (0.006) loss 1.3184 (1.0999) lr 9.0451e-03 eta 0:20:38
epoch [7/30] batch [160/204] time 0.251 (0.260) data 0.000 (0.005) loss 0.6875 (1.1365) lr 9.0451e-03 eta 0:20:29
epoch [7/30] batch [180/204] time 0.242 (0.259) data 0.000 (0.005) loss 1.5127 (1.1580) lr 9.0451e-03 eta 0:20:19
epoch [7/30] batch [200/204] time 0.243 (0.257) data 0.000 (0.004) loss 0.8169 (1.1440) lr 9.0451e-03 eta 0:20:06
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,188
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
epoch [8/30] batch [20/204] time 0.253 (0.300) data 0.000 (0.040) loss 1.4180 (1.5163) lr 8.7157e-03 eta 0:23:21
epoch [8/30] batch [40/204] time 0.254 (0.279) data 0.000 (0.020) loss 1.0459 (1.2321) lr 8.7157e-03 eta 0:21:36
epoch [8/30] batch [60/204] time 0.255 (0.270) data 0.000 (0.013) loss 0.5811 (1.0919) lr 8.7157e-03 eta 0:20:50
epoch [8/30] batch [80/204] time 0.257 (0.266) data 0.000 (0.010) loss 0.1910 (1.0588) lr 8.7157e-03 eta 0:20:27
epoch [8/30] batch [100/204] time 0.266 (0.265) data 0.000 (0.008) loss 0.1344 (0.9651) lr 8.7157e-03 eta 0:20:15
epoch [8/30] batch [120/204] time 0.255 (0.263) data 0.000 (0.007) loss 1.3281 (1.0659) lr 8.7157e-03 eta 0:20:02
epoch [8/30] batch [140/204] time 0.260 (0.262) data 0.000 (0.006) loss 1.0410 (1.1154) lr 8.7157e-03 eta 0:19:52
epoch [8/30] batch [160/204] time 0.250 (0.261) data 0.000 (0.005) loss 0.9966 (1.1145) lr 8.7157e-03 eta 0:19:41
epoch [8/30] batch [180/204] time 0.241 (0.259) data 0.000 (0.005) loss 0.0621 (1.1356) lr 8.7157e-03 eta 0:19:29
epoch [8/30] batch [200/204] time 0.242 (0.258) data 0.000 (0.004) loss -0.0223 (1.1451) lr 8.7157e-03 eta 0:19:16
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,201
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
epoch [9/30] batch [20/204] time 0.252 (0.295) data 0.000 (0.040) loss 0.5830 (1.0374) lr 8.3457e-03 eta 0:22:00
epoch [9/30] batch [40/204] time 0.261 (0.277) data 0.000 (0.020) loss 1.2158 (1.0326) lr 8.3457e-03 eta 0:20:32
epoch [9/30] batch [60/204] time 0.255 (0.270) data 0.000 (0.014) loss 0.1941 (1.0755) lr 8.3457e-03 eta 0:19:55
epoch [9/30] batch [80/204] time 0.251 (0.266) data 0.000 (0.010) loss 0.6431 (1.1191) lr 8.3457e-03 eta 0:19:32
epoch [9/30] batch [100/204] time 0.255 (0.264) data 0.000 (0.008) loss 0.1838 (1.0663) lr 8.3457e-03 eta 0:19:20
epoch [9/30] batch [120/204] time 0.249 (0.263) data 0.000 (0.007) loss 1.1914 (1.0446) lr 8.3457e-03 eta 0:19:06
epoch [9/30] batch [140/204] time 0.253 (0.261) data 0.000 (0.006) loss 0.0111 (1.0890) lr 8.3457e-03 eta 0:18:55
epoch [9/30] batch [160/204] time 0.249 (0.260) data 0.000 (0.005) loss 2.7734 (1.1105) lr 8.3457e-03 eta 0:18:46
epoch [9/30] batch [180/204] time 0.240 (0.259) data 0.000 (0.005) loss 0.4805 (1.1066) lr 8.3457e-03 eta 0:18:34
epoch [9/30] batch [200/204] time 0.241 (0.257) data 0.000 (0.004) loss 2.8965 (1.0867) lr 8.3457e-03 eta 0:18:22
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,183
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
epoch [10/30] batch [20/204] time 0.251 (0.300) data 0.000 (0.041) loss 2.9531 (1.1940) lr 7.9389e-03 eta 0:21:19
epoch [10/30] batch [40/204] time 0.253 (0.276) data 0.000 (0.021) loss 0.0554 (0.8945) lr 7.9389e-03 eta 0:19:31
epoch [10/30] batch [60/204] time 0.252 (0.268) data 0.000 (0.014) loss 1.4590 (1.0155) lr 7.9389e-03 eta 0:18:52
epoch [10/30] batch [80/204] time 0.250 (0.264) data 0.000 (0.010) loss 1.6465 (1.0670) lr 7.9389e-03 eta 0:18:31
epoch [10/30] batch [100/204] time 0.251 (0.262) data 0.000 (0.008) loss 1.3770 (0.9824) lr 7.9389e-03 eta 0:18:15
epoch [10/30] batch [120/204] time 0.254 (0.261) data 0.000 (0.007) loss 1.9434 (1.0242) lr 7.9389e-03 eta 0:18:05
epoch [10/30] batch [140/204] time 0.254 (0.260) data 0.000 (0.006) loss 0.1483 (1.0075) lr 7.9389e-03 eta 0:17:58
epoch [10/30] batch [160/204] time 0.254 (0.259) data 0.000 (0.005) loss 2.1797 (1.0133) lr 7.9389e-03 eta 0:17:49
epoch [10/30] batch [180/204] time 0.243 (0.258) data 0.000 (0.005) loss 0.9492 (1.0038) lr 7.9389e-03 eta 0:17:39
epoch [10/30] batch [200/204] time 0.242 (0.257) data 0.000 (0.004) loss 0.4905 (1.0280) lr 7.9389e-03 eta 0:17:28
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,184
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-10
epoch [11/30] batch [20/204] time 0.262 (0.299) data 0.000 (0.040) loss 0.3945 (0.8256) lr 7.5000e-03 eta 0:20:15
epoch [11/30] batch [40/204] time 0.262 (0.276) data 0.000 (0.020) loss 0.8643 (0.9979) lr 7.5000e-03 eta 0:18:34
epoch [11/30] batch [60/204] time 0.254 (0.268) data 0.000 (0.013) loss 0.0548 (1.1167) lr 7.5000e-03 eta 0:17:57
epoch [11/30] batch [80/204] time 0.254 (0.264) data 0.000 (0.010) loss 0.0506 (1.0762) lr 7.5000e-03 eta 0:17:36
epoch [11/30] batch [100/204] time 0.248 (0.262) data 0.000 (0.008) loss 1.8154 (1.1185) lr 7.5000e-03 eta 0:17:23
epoch [11/30] batch [120/204] time 0.258 (0.261) data 0.000 (0.007) loss 4.2109 (1.1614) lr 7.5000e-03 eta 0:17:12
epoch [11/30] batch [140/204] time 0.255 (0.260) data 0.000 (0.006) loss 0.1406 (1.1796) lr 7.5000e-03 eta 0:17:03
epoch [11/30] batch [160/204] time 0.251 (0.259) data 0.000 (0.005) loss 0.1689 (1.1397) lr 7.5000e-03 eta 0:16:56
epoch [11/30] batch [180/204] time 0.241 (0.258) data 0.000 (0.005) loss -0.0268 (1.1330) lr 7.5000e-03 eta 0:16:46
epoch [11/30] batch [200/204] time 0.240 (0.257) data 0.000 (0.004) loss 0.2805 (1.1413) lr 7.5000e-03 eta 0:16:36
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,214
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
epoch [12/30] batch [20/204] time 0.255 (0.296) data 0.000 (0.039) loss 0.0544 (1.1410) lr 7.0337e-03 eta 0:19:02
epoch [12/30] batch [40/204] time 0.255 (0.276) data 0.000 (0.019) loss 1.3467 (1.1281) lr 7.0337e-03 eta 0:17:38
epoch [12/30] batch [60/204] time 0.254 (0.270) data 0.000 (0.013) loss 0.6768 (1.0587) lr 7.0337e-03 eta 0:17:09
epoch [12/30] batch [80/204] time 0.254 (0.267) data 0.000 (0.010) loss 0.5142 (1.0686) lr 7.0337e-03 eta 0:16:54
epoch [12/30] batch [100/204] time 0.258 (0.265) data 0.000 (0.008) loss 0.1715 (1.1789) lr 7.0337e-03 eta 0:16:39
epoch [12/30] batch [120/204] time 0.254 (0.263) data 0.000 (0.007) loss 0.2627 (1.1492) lr 7.0337e-03 eta 0:16:27
epoch [12/30] batch [140/204] time 0.258 (0.262) data 0.000 (0.006) loss 1.4814 (1.1691) lr 7.0337e-03 eta 0:16:17
epoch [12/30] batch [160/204] time 0.256 (0.261) data 0.000 (0.005) loss 0.2595 (1.1973) lr 7.0337e-03 eta 0:16:09
epoch [12/30] batch [180/204] time 0.242 (0.260) data 0.000 (0.004) loss 1.7100 (1.2043) lr 7.0337e-03 eta 0:15:59
epoch [12/30] batch [200/204] time 0.240 (0.258) data 0.000 (0.004) loss 0.4202 (1.2080) lr 7.0337e-03 eta 0:15:47
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,184
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
epoch [13/30] batch [20/204] time 0.251 (0.295) data 0.000 (0.038) loss 0.0313 (0.7230) lr 6.5451e-03 eta 0:17:56
epoch [13/30] batch [40/204] time 0.265 (0.276) data 0.000 (0.019) loss 0.1827 (0.9359) lr 6.5451e-03 eta 0:16:44
epoch [13/30] batch [60/204] time 0.251 (0.269) data 0.000 (0.013) loss 2.0449 (1.0458) lr 6.5451e-03 eta 0:16:10
epoch [13/30] batch [80/204] time 0.252 (0.264) data 0.000 (0.010) loss 0.8003 (0.9509) lr 6.5451e-03 eta 0:15:49
epoch [13/30] batch [100/204] time 0.250 (0.263) data 0.000 (0.008) loss 0.0168 (0.9813) lr 6.5451e-03 eta 0:15:37
epoch [13/30] batch [120/204] time 0.246 (0.261) data 0.000 (0.007) loss 0.0781 (1.0126) lr 6.5451e-03 eta 0:15:26
epoch [13/30] batch [140/204] time 0.254 (0.259) data 0.000 (0.006) loss 1.3184 (1.0178) lr 6.5451e-03 eta 0:15:16
epoch [13/30] batch [160/204] time 0.245 (0.258) data 0.000 (0.005) loss 0.5576 (1.0588) lr 6.5451e-03 eta 0:15:06
epoch [13/30] batch [180/204] time 0.240 (0.257) data 0.000 (0.004) loss 2.0840 (1.0400) lr 6.5451e-03 eta 0:14:57
epoch [13/30] batch [200/204] time 0.241 (0.255) data 0.000 (0.004) loss -0.0337 (1.0547) lr 6.5451e-03 eta 0:14:46
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,193
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%
epoch [14/30] batch [20/204] time 0.256 (0.298) data 0.000 (0.039) loss 0.6035 (0.9051) lr 6.0396e-03 eta 0:17:07
epoch [14/30] batch [40/204] time 0.263 (0.279) data 0.000 (0.019) loss 1.8398 (0.9982) lr 6.0396e-03 eta 0:15:55
epoch [14/30] batch [60/204] time 0.249 (0.270) data 0.000 (0.013) loss 0.5688 (0.9812) lr 6.0396e-03 eta 0:15:20
epoch [14/30] batch [80/204] time 0.252 (0.266) data 0.000 (0.010) loss 0.3269 (1.0257) lr 6.0396e-03 eta 0:15:00
epoch [14/30] batch [100/204] time 0.253 (0.264) data 0.000 (0.008) loss 4.5508 (1.1117) lr 6.0396e-03 eta 0:14:47
epoch [14/30] batch [120/204] time 0.249 (0.262) data 0.000 (0.007) loss 1.9170 (1.2461) lr 6.0396e-03 eta 0:14:37
epoch [14/30] batch [140/204] time 0.249 (0.261) data 0.000 (0.006) loss -0.0350 (1.1981) lr 6.0396e-03 eta 0:14:27
epoch [14/30] batch [160/204] time 0.248 (0.260) data 0.000 (0.005) loss -0.0409 (1.1409) lr 6.0396e-03 eta 0:14:18
epoch [14/30] batch [180/204] time 0.240 (0.258) data 0.000 (0.005) loss 0.8369 (1.1110) lr 6.0396e-03 eta 0:14:09
epoch [14/30] batch [200/204] time 0.240 (0.257) data 0.000 (0.004) loss 0.5029 (1.1239) lr 6.0396e-03 eta 0:13:58
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,218
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 90.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
epoch [15/30] batch [20/204] time 0.251 (0.295) data 0.000 (0.041) loss 0.0226 (0.9231) lr 5.5226e-03 eta 0:15:58
epoch [15/30] batch [40/204] time 0.256 (0.277) data 0.000 (0.021) loss 0.1254 (0.9582) lr 5.5226e-03 eta 0:14:52
epoch [15/30] batch [60/204] time 0.252 (0.269) data 0.000 (0.014) loss 1.5918 (0.9004) lr 5.5226e-03 eta 0:14:23
epoch [15/30] batch [80/204] time 0.257 (0.265) data 0.000 (0.010) loss 1.4287 (0.8690) lr 5.5226e-03 eta 0:14:04
epoch [15/30] batch [100/204] time 0.247 (0.263) data 0.000 (0.008) loss 0.0764 (0.8221) lr 5.5226e-03 eta 0:13:53
epoch [15/30] batch [120/204] time 0.250 (0.262) data 0.000 (0.007) loss 0.2238 (0.8789) lr 5.5226e-03 eta 0:13:44
epoch [15/30] batch [140/204] time 0.257 (0.261) data 0.003 (0.006) loss -0.0149 (0.9430) lr 5.5226e-03 eta 0:13:35
epoch [15/30] batch [160/204] time 0.249 (0.260) data 0.000 (0.005) loss 2.1348 (0.9489) lr 5.5226e-03 eta 0:13:27
epoch [15/30] batch [180/204] time 0.243 (0.259) data 0.000 (0.005) loss 2.7676 (0.9595) lr 5.5226e-03 eta 0:13:18
epoch [15/30] batch [200/204] time 0.244 (0.257) data 0.000 (0.004) loss 3.4277 (0.9807) lr 5.5226e-03 eta 0:13:08
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,210
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
epoch [16/30] batch [20/204] time 0.254 (0.297) data 0.000 (0.040) loss 2.8555 (0.9412) lr 5.0000e-03 eta 0:15:02
epoch [16/30] batch [40/204] time 0.254 (0.276) data 0.000 (0.020) loss 1.3633 (0.9773) lr 5.0000e-03 eta 0:13:54
epoch [16/30] batch [60/204] time 0.258 (0.271) data 0.000 (0.014) loss 3.8672 (1.0121) lr 5.0000e-03 eta 0:13:33
epoch [16/30] batch [80/204] time 0.257 (0.267) data 0.000 (0.010) loss 0.2288 (0.9022) lr 5.0000e-03 eta 0:13:14
epoch [16/30] batch [100/204] time 0.253 (0.264) data 0.000 (0.008) loss 1.0957 (0.8929) lr 5.0000e-03 eta 0:13:01
epoch [16/30] batch [120/204] time 0.255 (0.262) data 0.000 (0.007) loss 0.0272 (0.8742) lr 5.0000e-03 eta 0:12:51
epoch [16/30] batch [140/204] time 0.248 (0.262) data 0.000 (0.006) loss 0.0555 (0.9260) lr 5.0000e-03 eta 0:12:43
epoch [16/30] batch [160/204] time 0.258 (0.261) data 0.000 (0.005) loss 3.0371 (0.8920) lr 5.0000e-03 eta 0:12:36
epoch [16/30] batch [180/204] time 0.242 (0.259) data 0.000 (0.005) loss 1.7969 (0.8629) lr 5.0000e-03 eta 0:12:26
epoch [16/30] batch [200/204] time 0.241 (0.258) data 0.000 (0.004) loss 0.1919 (0.8600) lr 5.0000e-03 eta 0:12:16
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,198
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%
epoch [17/30] batch [20/204] time 0.254 (0.296) data 0.000 (0.040) loss 1.6895 (1.5368) lr 4.4774e-03 eta 0:13:58
epoch [17/30] batch [40/204] time 0.255 (0.275) data 0.000 (0.020) loss 0.5410 (1.0153) lr 4.4774e-03 eta 0:12:54
epoch [17/30] batch [60/204] time 0.254 (0.268) data 0.000 (0.013) loss 0.1422 (0.9353) lr 4.4774e-03 eta 0:12:30
epoch [17/30] batch [80/204] time 0.252 (0.267) data 0.000 (0.010) loss 0.2859 (0.9492) lr 4.4774e-03 eta 0:12:20
epoch [17/30] batch [100/204] time 0.252 (0.264) data 0.000 (0.008) loss 0.1487 (0.8936) lr 4.4774e-03 eta 0:12:07
epoch [17/30] batch [120/204] time 0.250 (0.262) data 0.000 (0.007) loss 3.3203 (0.8725) lr 4.4774e-03 eta 0:11:57
epoch [17/30] batch [140/204] time 0.250 (0.261) data 0.000 (0.006) loss 0.0108 (0.9160) lr 4.4774e-03 eta 0:11:48
epoch [17/30] batch [160/204] time 0.257 (0.260) data 0.000 (0.005) loss 0.2397 (0.9293) lr 4.4774e-03 eta 0:11:41
epoch [17/30] batch [180/204] time 0.241 (0.259) data 0.000 (0.005) loss 0.1821 (0.9424) lr 4.4774e-03 eta 0:11:33
epoch [17/30] batch [200/204] time 0.241 (0.257) data 0.000 (0.004) loss 0.1462 (0.9892) lr 4.4774e-03 eta 0:11:23
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,227
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 90.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
epoch [18/30] batch [20/204] time 0.260 (0.302) data 0.000 (0.039) loss 0.1792 (0.9139) lr 3.9604e-03 eta 0:13:15
epoch [18/30] batch [40/204] time 0.252 (0.277) data 0.000 (0.019) loss 0.3484 (1.1750) lr 3.9604e-03 eta 0:12:04
epoch [18/30] batch [60/204] time 0.254 (0.269) data 0.000 (0.013) loss 0.3105 (1.2058) lr 3.9604e-03 eta 0:11:38
epoch [18/30] batch [80/204] time 0.252 (0.266) data 0.000 (0.010) loss 2.2285 (1.1319) lr 3.9604e-03 eta 0:11:23
epoch [18/30] batch [100/204] time 0.253 (0.264) data 0.000 (0.008) loss 0.2617 (1.1386) lr 3.9604e-03 eta 0:11:13
epoch [18/30] batch [120/204] time 0.255 (0.262) data 0.000 (0.007) loss 0.2563 (1.0593) lr 3.9604e-03 eta 0:11:04
epoch [18/30] batch [140/204] time 0.254 (0.261) data 0.000 (0.006) loss 0.3171 (0.9822) lr 3.9604e-03 eta 0:10:56
epoch [18/30] batch [160/204] time 0.248 (0.261) data 0.000 (0.005) loss 0.1389 (0.9665) lr 3.9604e-03 eta 0:10:49
epoch [18/30] batch [180/204] time 0.238 (0.259) data 0.000 (0.005) loss 1.2676 (0.9681) lr 3.9604e-03 eta 0:10:40
epoch [18/30] batch [200/204] time 0.241 (0.257) data 0.000 (0.004) loss 4.7930 (0.9856) lr 3.9604e-03 eta 0:10:30
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,205
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%
epoch [19/30] batch [20/204] time 0.253 (0.295) data 0.000 (0.040) loss 0.7939 (0.8330) lr 3.4549e-03 eta 0:11:55
epoch [19/30] batch [40/204] time 0.249 (0.274) data 0.000 (0.020) loss 0.8906 (0.7759) lr 3.4549e-03 eta 0:10:59
epoch [19/30] batch [60/204] time 0.258 (0.269) data 0.000 (0.014) loss 2.3555 (0.7820) lr 3.4549e-03 eta 0:10:41
epoch [19/30] batch [80/204] time 0.259 (0.265) data 0.000 (0.010) loss 0.1360 (0.7749) lr 3.4549e-03 eta 0:10:27
epoch [19/30] batch [100/204] time 0.256 (0.263) data 0.000 (0.008) loss 2.8340 (0.8015) lr 3.4549e-03 eta 0:10:17
epoch [19/30] batch [120/204] time 0.251 (0.262) data 0.000 (0.007) loss 0.6460 (0.8557) lr 3.4549e-03 eta 0:10:09
epoch [19/30] batch [140/204] time 0.246 (0.261) data 0.000 (0.006) loss 0.1411 (0.8347) lr 3.4549e-03 eta 0:10:01
epoch [19/30] batch [160/204] time 0.256 (0.260) data 0.000 (0.005) loss 0.4143 (0.8986) lr 3.4549e-03 eta 0:09:55
epoch [19/30] batch [180/204] time 0.242 (0.259) data 0.000 (0.005) loss 0.5508 (0.9106) lr 3.4549e-03 eta 0:09:47
epoch [19/30] batch [200/204] time 0.243 (0.257) data 0.000 (0.004) loss 0.7871 (0.8945) lr 3.4549e-03 eta 0:09:38
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,211
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
epoch [20/30] batch [20/204] time 0.250 (0.298) data 0.000 (0.040) loss 0.4548 (1.0211) lr 2.9663e-03 eta 0:11:03
epoch [20/30] batch [40/204] time 0.259 (0.276) data 0.000 (0.020) loss 1.3262 (0.7306) lr 2.9663e-03 eta 0:10:07
epoch [20/30] batch [60/204] time 0.254 (0.269) data 0.000 (0.013) loss 0.1025 (0.8914) lr 2.9663e-03 eta 0:09:48
epoch [20/30] batch [80/204] time 0.253 (0.265) data 0.000 (0.010) loss 0.3401 (0.9647) lr 2.9663e-03 eta 0:09:34
epoch [20/30] batch [100/204] time 0.257 (0.263) data 0.000 (0.008) loss 0.0758 (0.9635) lr 2.9663e-03 eta 0:09:23
epoch [20/30] batch [120/204] time 0.254 (0.262) data 0.000 (0.007) loss 0.1876 (1.0193) lr 2.9663e-03 eta 0:09:15
epoch [20/30] batch [140/204] time 0.256 (0.261) data 0.000 (0.006) loss 0.2786 (1.0143) lr 2.9663e-03 eta 0:09:08
epoch [20/30] batch [160/204] time 0.252 (0.260) data 0.000 (0.005) loss -0.0336 (1.0261) lr 2.9663e-03 eta 0:09:01
epoch [20/30] batch [180/204] time 0.244 (0.258) data 0.000 (0.005) loss 0.2583 (1.0558) lr 2.9663e-03 eta 0:08:53
epoch [20/30] batch [200/204] time 0.241 (0.257) data 0.000 (0.004) loss 0.7734 (1.0591) lr 2.9663e-03 eta 0:08:44
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,192
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20
epoch [21/30] batch [20/204] time 0.254 (0.301) data 0.000 (0.040) loss 0.5654 (1.3669) lr 2.5000e-03 eta 0:10:08
epoch [21/30] batch [40/204] time 0.249 (0.278) data 0.000 (0.020) loss 0.1045 (1.2884) lr 2.5000e-03 eta 0:09:16
epoch [21/30] batch [60/204] time 0.253 (0.270) data 0.000 (0.014) loss 2.0273 (1.2240) lr 2.5000e-03 eta 0:08:55
epoch [21/30] batch [80/204] time 0.256 (0.267) data 0.000 (0.010) loss 1.1777 (1.2001) lr 2.5000e-03 eta 0:08:42
epoch [21/30] batch [100/204] time 0.257 (0.265) data 0.000 (0.008) loss 1.5693 (1.1175) lr 2.5000e-03 eta 0:08:33
epoch [21/30] batch [120/204] time 0.253 (0.263) data 0.000 (0.007) loss 1.6924 (1.1008) lr 2.5000e-03 eta 0:08:24
epoch [21/30] batch [140/204] time 0.257 (0.261) data 0.000 (0.006) loss 0.0373 (1.0282) lr 2.5000e-03 eta 0:08:15
epoch [21/30] batch [160/204] time 0.319 (0.260) data 0.000 (0.005) loss -0.0335 (0.9565) lr 2.5000e-03 eta 0:08:09
epoch [21/30] batch [180/204] time 0.239 (0.259) data 0.000 (0.005) loss 0.3513 (0.9517) lr 2.5000e-03 eta 0:08:01
epoch [21/30] batch [200/204] time 0.242 (0.257) data 0.000 (0.004) loss 0.3125 (0.9512) lr 2.5000e-03 eta 0:07:53
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,210
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
epoch [22/30] batch [20/204] time 0.248 (0.297) data 0.000 (0.040) loss 1.1436 (0.6810) lr 2.0611e-03 eta 0:08:59
epoch [22/30] batch [40/204] time 0.250 (0.276) data 0.000 (0.020) loss 0.0591 (0.8410) lr 2.0611e-03 eta 0:08:14
epoch [22/30] batch [60/204] time 0.353 (0.271) data 0.000 (0.013) loss 0.0965 (0.8387) lr 2.0611e-03 eta 0:08:01
epoch [22/30] batch [80/204] time 0.257 (0.267) data 0.000 (0.010) loss 0.9980 (0.8935) lr 2.0611e-03 eta 0:07:48
epoch [22/30] batch [100/204] time 0.263 (0.264) data 0.000 (0.008) loss 0.6343 (0.9329) lr 2.0611e-03 eta 0:07:38
epoch [22/30] batch [120/204] time 0.251 (0.262) data 0.000 (0.007) loss 3.6289 (0.9675) lr 2.0611e-03 eta 0:07:30
epoch [22/30] batch [140/204] time 0.250 (0.261) data 0.000 (0.006) loss 0.2338 (0.9561) lr 2.0611e-03 eta 0:07:22
epoch [22/30] batch [160/204] time 0.255 (0.260) data 0.000 (0.005) loss 2.1152 (0.9814) lr 2.0611e-03 eta 0:07:16
epoch [22/30] batch [180/204] time 0.243 (0.259) data 0.000 (0.005) loss 0.8369 (1.0158) lr 2.0611e-03 eta 0:07:08
epoch [22/30] batch [200/204] time 0.240 (0.257) data 0.000 (0.004) loss 0.5752 (1.0367) lr 2.0611e-03 eta 0:07:00
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,228
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 90.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
epoch [23/30] batch [20/204] time 0.253 (0.300) data 0.000 (0.040) loss 0.8643 (0.6895) lr 1.6543e-03 eta 0:08:03
epoch [23/30] batch [40/204] time 0.253 (0.277) data 0.000 (0.020) loss 4.2891 (1.0169) lr 1.6543e-03 eta 0:07:20
epoch [23/30] batch [60/204] time 0.261 (0.269) data 0.000 (0.014) loss -0.0429 (0.9978) lr 1.6543e-03 eta 0:07:03
epoch [23/30] batch [80/204] time 0.257 (0.267) data 0.000 (0.010) loss 0.0609 (0.9408) lr 1.6543e-03 eta 0:06:54
epoch [23/30] batch [100/204] time 0.255 (0.264) data 0.000 (0.008) loss 1.0996 (0.9696) lr 1.6543e-03 eta 0:06:44
epoch [23/30] batch [120/204] time 0.251 (0.263) data 0.000 (0.007) loss 4.7812 (0.9041) lr 1.6543e-03 eta 0:06:37
epoch [23/30] batch [140/204] time 0.254 (0.262) data 0.000 (0.006) loss 2.2285 (0.9721) lr 1.6543e-03 eta 0:06:30
epoch [23/30] batch [160/204] time 0.270 (0.261) data 0.000 (0.005) loss 0.6982 (0.9324) lr 1.6543e-03 eta 0:06:23
epoch [23/30] batch [180/204] time 0.245 (0.260) data 0.000 (0.005) loss 1.6299 (0.9617) lr 1.6543e-03 eta 0:06:17
epoch [23/30] batch [200/204] time 0.245 (0.258) data 0.000 (0.004) loss 0.0525 (0.9419) lr 1.6543e-03 eta 0:06:09
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,211
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
epoch [24/30] batch [20/204] time 0.257 (0.296) data 0.000 (0.039) loss 0.6133 (0.6807) lr 1.2843e-03 eta 0:06:56
epoch [24/30] batch [40/204] time 0.248 (0.278) data 0.000 (0.019) loss 0.4402 (0.8235) lr 1.2843e-03 eta 0:06:25
epoch [24/30] batch [60/204] time 0.252 (0.269) data 0.000 (0.013) loss 0.3091 (0.8716) lr 1.2843e-03 eta 0:06:08
epoch [24/30] batch [80/204] time 0.254 (0.265) data 0.000 (0.010) loss 0.6016 (0.8601) lr 1.2843e-03 eta 0:05:57
epoch [24/30] batch [100/204] time 0.255 (0.264) data 0.000 (0.008) loss 0.4648 (0.8340) lr 1.2843e-03 eta 0:05:50
epoch [24/30] batch [120/204] time 0.256 (0.262) data 0.000 (0.007) loss 0.0798 (0.8596) lr 1.2843e-03 eta 0:05:43
epoch [24/30] batch [140/204] time 0.251 (0.261) data 0.000 (0.006) loss 0.0894 (0.8909) lr 1.2843e-03 eta 0:05:36
epoch [24/30] batch [160/204] time 0.245 (0.260) data 0.000 (0.005) loss 1.5967 (0.9348) lr 1.2843e-03 eta 0:05:29
epoch [24/30] batch [180/204] time 0.241 (0.259) data 0.000 (0.005) loss 0.0152 (0.9515) lr 1.2843e-03 eta 0:05:23
epoch [24/30] batch [200/204] time 0.240 (0.257) data 0.000 (0.004) loss 0.4551 (0.9563) lr 1.2843e-03 eta 0:05:15
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,198
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%
epoch [25/30] batch [20/204] time 0.260 (0.299) data 0.000 (0.040) loss 0.0701 (0.5207) lr 9.5492e-04 eta 0:06:00
epoch [25/30] batch [40/204] time 0.253 (0.279) data 0.000 (0.020) loss 0.0750 (0.8312) lr 9.5492e-04 eta 0:05:30
epoch [25/30] batch [60/204] time 0.252 (0.271) data 0.001 (0.013) loss 0.6138 (0.8769) lr 9.5492e-04 eta 0:05:15
epoch [25/30] batch [80/204] time 0.252 (0.267) data 0.000 (0.010) loss -0.0054 (0.9370) lr 9.5492e-04 eta 0:05:05
epoch [25/30] batch [100/204] time 0.253 (0.265) data 0.000 (0.008) loss 1.5977 (0.9830) lr 9.5492e-04 eta 0:04:57
epoch [25/30] batch [120/204] time 0.255 (0.263) data 0.000 (0.007) loss -0.0036 (0.9486) lr 9.5492e-04 eta 0:04:50
epoch [25/30] batch [140/204] time 0.249 (0.262) data 0.000 (0.006) loss 0.0961 (1.0236) lr 9.5492e-04 eta 0:04:44
epoch [25/30] batch [160/204] time 0.251 (0.261) data 0.000 (0.005) loss 0.0854 (0.9660) lr 9.5492e-04 eta 0:04:37
epoch [25/30] batch [180/204] time 0.240 (0.260) data 0.000 (0.005) loss 1.7910 (0.9558) lr 9.5492e-04 eta 0:04:31
epoch [25/30] batch [200/204] time 0.241 (0.258) data 0.000 (0.004) loss 2.2461 (0.9755) lr 9.5492e-04 eta 0:04:24
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,208
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
epoch [26/30] batch [20/204] time 0.251 (0.294) data 0.000 (0.039) loss 2.9551 (1.0647) lr 6.6987e-04 eta 0:04:54
epoch [26/30] batch [40/204] time 0.250 (0.276) data 0.000 (0.020) loss 0.6562 (0.8728) lr 6.6987e-04 eta 0:04:30
epoch [26/30] batch [60/204] time 0.257 (0.268) data 0.000 (0.013) loss 0.8784 (1.0844) lr 6.6987e-04 eta 0:04:17
epoch [26/30] batch [80/204] time 0.245 (0.264) data 0.000 (0.010) loss 1.0029 (1.0124) lr 6.6987e-04 eta 0:04:08
epoch [26/30] batch [100/204] time 0.262 (0.262) data 0.000 (0.008) loss 0.1576 (1.0522) lr 6.6987e-04 eta 0:04:01
epoch [26/30] batch [120/204] time 0.250 (0.261) data 0.000 (0.007) loss 0.3704 (1.0761) lr 6.6987e-04 eta 0:03:54
epoch [26/30] batch [140/204] time 0.252 (0.260) data 0.000 (0.006) loss 2.7285 (1.0774) lr 6.6987e-04 eta 0:03:48
epoch [26/30] batch [160/204] time 0.256 (0.260) data 0.000 (0.005) loss 4.0586 (1.0723) lr 6.6987e-04 eta 0:03:43
epoch [26/30] batch [180/204] time 0.245 (0.259) data 0.000 (0.005) loss 0.4326 (1.0429) lr 6.6987e-04 eta 0:03:37
epoch [26/30] batch [200/204] time 0.243 (0.257) data 0.000 (0.004) loss 0.2234 (0.9995) lr 6.6987e-04 eta 0:03:30
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,212
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
epoch [27/30] batch [20/204] time 0.269 (0.296) data 0.000 (0.038) loss 0.9478 (1.5275) lr 4.3227e-04 eta 0:03:55
epoch [27/30] batch [40/204] time 0.250 (0.277) data 0.000 (0.019) loss 1.6797 (1.1931) lr 4.3227e-04 eta 0:03:34
epoch [27/30] batch [60/204] time 0.251 (0.269) data 0.000 (0.013) loss 0.7529 (1.1224) lr 4.3227e-04 eta 0:03:23
epoch [27/30] batch [80/204] time 0.253 (0.265) data 0.000 (0.010) loss -0.0269 (1.0313) lr 4.3227e-04 eta 0:03:15
epoch [27/30] batch [100/204] time 0.252 (0.263) data 0.000 (0.008) loss 2.0977 (1.0269) lr 4.3227e-04 eta 0:03:08
epoch [27/30] batch [120/204] time 0.256 (0.261) data 0.000 (0.007) loss 2.4746 (1.0065) lr 4.3227e-04 eta 0:03:01
epoch [27/30] batch [140/204] time 0.252 (0.260) data 0.000 (0.006) loss 0.6963 (1.0417) lr 4.3227e-04 eta 0:02:56
epoch [27/30] batch [160/204] time 0.259 (0.260) data 0.000 (0.005) loss 1.1689 (0.9793) lr 4.3227e-04 eta 0:02:50
epoch [27/30] batch [180/204] time 0.242 (0.258) data 0.000 (0.004) loss 2.4883 (0.9800) lr 4.3227e-04 eta 0:02:44
epoch [27/30] batch [200/204] time 0.242 (0.257) data 0.000 (0.004) loss 1.5771 (0.9963) lr 4.3227e-04 eta 0:02:38
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,209
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
epoch [28/30] batch [20/204] time 0.255 (0.304) data 0.000 (0.038) loss 1.8203 (1.3914) lr 2.4472e-04 eta 0:02:59
epoch [28/30] batch [40/204] time 0.245 (0.279) data 0.000 (0.019) loss 0.3145 (1.0952) lr 2.4472e-04 eta 0:02:39
epoch [28/30] batch [60/204] time 0.259 (0.271) data 0.000 (0.013) loss 0.2942 (1.1167) lr 2.4472e-04 eta 0:02:29
epoch [28/30] batch [80/204] time 0.253 (0.268) data 0.000 (0.010) loss -0.0256 (1.0864) lr 2.4472e-04 eta 0:02:22
epoch [28/30] batch [100/204] time 0.252 (0.265) data 0.000 (0.008) loss 1.4268 (1.0191) lr 2.4472e-04 eta 0:02:15
epoch [28/30] batch [120/204] time 0.255 (0.263) data 0.000 (0.007) loss 0.0833 (0.9834) lr 2.4472e-04 eta 0:02:09
epoch [28/30] batch [140/204] time 0.256 (0.262) data 0.000 (0.006) loss 1.0586 (0.9766) lr 2.4472e-04 eta 0:02:03
epoch [28/30] batch [160/204] time 0.257 (0.261) data 0.000 (0.005) loss 0.5991 (0.9717) lr 2.4472e-04 eta 0:01:58
epoch [28/30] batch [180/204] time 0.240 (0.260) data 0.000 (0.004) loss -0.0233 (0.9637) lr 2.4472e-04 eta 0:01:52
epoch [28/30] batch [200/204] time 0.241 (0.258) data 0.000 (0.004) loss 0.5967 (0.9903) lr 2.4472e-04 eta 0:01:46
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,206
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.2%
epoch [29/30] batch [20/204] time 0.253 (0.296) data 0.000 (0.038) loss 0.0534 (0.9263) lr 1.0926e-04 eta 0:01:55
epoch [29/30] batch [40/204] time 0.251 (0.277) data 0.000 (0.019) loss 0.8369 (0.9806) lr 1.0926e-04 eta 0:01:41
epoch [29/30] batch [60/204] time 0.249 (0.269) data 0.000 (0.013) loss 0.1030 (0.9452) lr 1.0926e-04 eta 0:01:33
epoch [29/30] batch [80/204] time 0.247 (0.265) data 0.000 (0.010) loss 0.7246 (0.8785) lr 1.0926e-04 eta 0:01:26
epoch [29/30] batch [100/204] time 0.247 (0.262) data 0.000 (0.008) loss 0.1533 (0.8662) lr 1.0926e-04 eta 0:01:20
epoch [29/30] batch [120/204] time 0.251 (0.261) data 0.000 (0.007) loss 0.1731 (0.8897) lr 1.0926e-04 eta 0:01:15
epoch [29/30] batch [140/204] time 0.250 (0.260) data 0.000 (0.006) loss 0.0039 (0.8930) lr 1.0926e-04 eta 0:01:09
epoch [29/30] batch [160/204] time 0.254 (0.259) data 0.000 (0.005) loss 0.5249 (0.9116) lr 1.0926e-04 eta 0:01:04
epoch [29/30] batch [180/204] time 0.240 (0.258) data 0.000 (0.004) loss 2.6289 (0.9201) lr 1.0926e-04 eta 0:00:58
epoch [29/30] batch [200/204] time 0.240 (0.256) data 0.000 (0.004) loss 0.1575 (0.8827) lr 1.0926e-04 eta 0:00:53
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,207
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.2%
epoch [30/30] batch [20/204] time 0.258 (0.300) data 0.000 (0.040) loss 0.0883 (0.6626) lr 2.7391e-05 eta 0:00:55
epoch [30/30] batch [40/204] time 0.252 (0.277) data 0.000 (0.020) loss 0.0767 (0.9342) lr 2.7391e-05 eta 0:00:45
epoch [30/30] batch [60/204] time 0.256 (0.268) data 0.000 (0.014) loss 0.7617 (0.8972) lr 2.7391e-05 eta 0:00:38
epoch [30/30] batch [80/204] time 0.250 (0.267) data 0.000 (0.010) loss -0.0216 (0.8837) lr 2.7391e-05 eta 0:00:33
epoch [30/30] batch [100/204] time 0.258 (0.265) data 0.000 (0.008) loss -0.0504 (0.9605) lr 2.7391e-05 eta 0:00:27
epoch [30/30] batch [120/204] time 0.257 (0.263) data 0.000 (0.007) loss 0.1787 (0.9155) lr 2.7391e-05 eta 0:00:22
epoch [30/30] batch [140/204] time 0.251 (0.261) data 0.000 (0.006) loss 0.2168 (0.9130) lr 2.7391e-05 eta 0:00:16
epoch [30/30] batch [160/204] time 0.252 (0.260) data 0.000 (0.005) loss 0.2336 (0.8560) lr 2.7391e-05 eta 0:00:11
epoch [30/30] batch [180/204] time 0.241 (0.259) data 0.000 (0.005) loss 0.3296 (0.8905) lr 2.7391e-05 eta 0:00:06
epoch [30/30] batch [200/204] time 0.242 (0.257) data 0.000 (0.004) loss 0.2166 (0.8976) lr 2.7391e-05 eta 0:00:01
Evaluate on the *val* set
=> result
* total: 10,200
* correct: 9,209
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 22)
Evaluate on the *test* set
=> result
* total: 15,300
* correct: 13,892
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.8%
Elapsed: 0:39:38

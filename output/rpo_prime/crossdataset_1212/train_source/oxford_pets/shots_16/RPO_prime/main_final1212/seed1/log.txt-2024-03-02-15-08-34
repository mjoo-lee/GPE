***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final1212.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/crossdataset_1212/train_source/oxford_pets/shots_16/RPO_prime/main_final1212/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/crossdataset_1212/train_source/oxford_pets/shots_16/RPO_prime/main_final1212/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 24
    K2: 0
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA TITAN RTX
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_1.pkl
592 736 3669
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      736
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/crossdataset_1212/train_source/oxford_pets/shots_16/RPO_prime/main_final1212/seed1/tensorboard)
epoch [1/30] batch [2/148] time 0.311 (1.477) data 0.001 (0.457) loss 5.4727 (5.6660) lr 1.0000e-02 eta 1:49:14
epoch [1/30] batch [4/148] time 0.310 (0.897) data 0.000 (0.229) loss 5.4062 (5.3691) lr 1.0000e-02 eta 1:06:17
epoch [1/30] batch [6/148] time 0.300 (0.700) data 0.000 (0.152) loss 4.3086 (5.0566) lr 1.0000e-02 eta 0:51:41
epoch [1/30] batch [8/148] time 0.309 (0.603) data 0.000 (0.114) loss 7.1914 (5.3042) lr 1.0000e-02 eta 0:44:31
epoch [1/30] batch [10/148] time 0.315 (0.545) data 0.000 (0.092) loss 2.7988 (5.2361) lr 1.0000e-02 eta 0:40:12
epoch [1/30] batch [12/148] time 0.305 (0.505) data 0.000 (0.076) loss 3.5430 (4.9079) lr 1.0000e-02 eta 0:37:17
epoch [1/30] batch [14/148] time 0.314 (0.478) data 0.000 (0.066) loss 5.6484 (4.9568) lr 1.0000e-02 eta 0:35:16
epoch [1/30] batch [16/148] time 0.310 (0.458) data 0.000 (0.057) loss 3.4727 (4.6936) lr 1.0000e-02 eta 0:33:44
epoch [1/30] batch [18/148] time 0.309 (0.441) data 0.000 (0.051) loss 4.9922 (4.5883) lr 1.0000e-02 eta 0:32:31
epoch [1/30] batch [20/148] time 0.311 (0.428) data 0.000 (0.046) loss 4.7969 (4.4594) lr 1.0000e-02 eta 0:31:32
epoch [1/30] batch [22/148] time 0.309 (0.417) data 0.000 (0.042) loss 4.1289 (4.4413) lr 1.0000e-02 eta 0:30:43
epoch [1/30] batch [24/148] time 0.309 (0.408) data 0.000 (0.038) loss 3.0801 (4.3409) lr 1.0000e-02 eta 0:30:03
epoch [1/30] batch [26/148] time 0.307 (0.401) data 0.000 (0.035) loss 6.1523 (4.3687) lr 1.0000e-02 eta 0:29:30
epoch [1/30] batch [28/148] time 0.313 (0.395) data 0.000 (0.033) loss 3.9922 (4.3294) lr 1.0000e-02 eta 0:29:02
epoch [1/30] batch [30/148] time 0.311 (0.390) data 0.000 (0.031) loss 3.1406 (4.2920) lr 1.0000e-02 eta 0:28:40
epoch [1/30] batch [32/148] time 0.311 (0.385) data 0.000 (0.029) loss 3.0391 (4.2254) lr 1.0000e-02 eta 0:28:16
epoch [1/30] batch [34/148] time 0.310 (0.380) data 0.000 (0.027) loss 3.9922 (4.1832) lr 1.0000e-02 eta 0:27:56
epoch [1/30] batch [36/148] time 0.310 (0.377) data 0.000 (0.026) loss 1.4512 (4.0725) lr 1.0000e-02 eta 0:27:38
epoch [1/30] batch [38/148] time 0.316 (0.373) data 0.000 (0.024) loss 3.6484 (4.0517) lr 1.0000e-02 eta 0:27:22
epoch [1/30] batch [40/148] time 0.313 (0.370) data 0.000 (0.023) loss 1.9365 (3.9722) lr 1.0000e-02 eta 0:27:08
epoch [1/30] batch [42/148] time 0.305 (0.367) data 0.000 (0.022) loss 2.0254 (3.8614) lr 1.0000e-02 eta 0:26:54
epoch [1/30] batch [44/148] time 0.309 (0.365) data 0.000 (0.021) loss 2.0645 (3.7640) lr 1.0000e-02 eta 0:26:42
epoch [1/30] batch [46/148] time 0.307 (0.362) data 0.000 (0.020) loss 1.5732 (3.7363) lr 1.0000e-02 eta 0:26:31
epoch [1/30] batch [48/148] time 0.304 (0.360) data 0.000 (0.019) loss 1.5771 (3.6629) lr 1.0000e-02 eta 0:26:21
epoch [1/30] batch [50/148] time 0.309 (0.358) data 0.000 (0.019) loss 0.9780 (3.6021) lr 1.0000e-02 eta 0:26:11
epoch [1/30] batch [52/148] time 0.316 (0.356) data 0.000 (0.018) loss 1.4912 (3.5554) lr 1.0000e-02 eta 0:26:03
epoch [1/30] batch [54/148] time 0.310 (0.355) data 0.000 (0.017) loss 0.4617 (3.4660) lr 1.0000e-02 eta 0:25:55
epoch [1/30] batch [56/148] time 0.304 (0.353) data 0.000 (0.017) loss 1.5029 (3.3831) lr 1.0000e-02 eta 0:25:47
epoch [1/30] batch [58/148] time 0.315 (0.352) data 0.000 (0.016) loss 1.7656 (3.3224) lr 1.0000e-02 eta 0:25:40
epoch [1/30] batch [60/148] time 0.301 (0.350) data 0.000 (0.016) loss 1.8418 (3.2668) lr 1.0000e-02 eta 0:25:32
epoch [1/30] batch [62/148] time 0.313 (0.349) data 0.000 (0.015) loss 2.4219 (3.2304) lr 1.0000e-02 eta 0:25:27
epoch [1/30] batch [64/148] time 0.307 (0.347) data 0.000 (0.015) loss 1.6973 (3.1708) lr 1.0000e-02 eta 0:25:20
epoch [1/30] batch [66/148] time 0.310 (0.346) data 0.000 (0.014) loss 2.8066 (3.1580) lr 1.0000e-02 eta 0:25:14
epoch [1/30] batch [68/148] time 0.308 (0.345) data 0.000 (0.014) loss 4.5742 (3.1419) lr 1.0000e-02 eta 0:25:08
epoch [1/30] batch [70/148] time 0.311 (0.344) data 0.000 (0.013) loss 1.9453 (3.1278) lr 1.0000e-02 eta 0:25:03
epoch [1/30] batch [72/148] time 0.305 (0.343) data 0.000 (0.013) loss 1.1221 (3.0653) lr 1.0000e-02 eta 0:24:58
epoch [1/30] batch [74/148] time 0.312 (0.342) data 0.000 (0.013) loss 1.2861 (3.0104) lr 1.0000e-02 eta 0:24:54
epoch [1/30] batch [76/148] time 0.309 (0.341) data 0.000 (0.012) loss 2.1875 (2.9813) lr 1.0000e-02 eta 0:24:49
epoch [1/30] batch [78/148] time 0.311 (0.341) data 0.000 (0.012) loss 1.1816 (2.9322) lr 1.0000e-02 eta 0:24:46
epoch [1/30] batch [80/148] time 0.302 (0.340) data 0.000 (0.012) loss 2.5020 (2.9339) lr 1.0000e-02 eta 0:24:41
epoch [1/30] batch [82/148] time 0.306 (0.339) data 0.000 (0.011) loss 3.2422 (2.9216) lr 1.0000e-02 eta 0:24:37
epoch [1/30] batch [84/148] time 0.313 (0.338) data 0.000 (0.011) loss 1.5693 (2.8909) lr 1.0000e-02 eta 0:24:33
epoch [1/30] batch [86/148] time 0.312 (0.338) data 0.000 (0.011) loss 1.9219 (2.8905) lr 1.0000e-02 eta 0:24:29
epoch [1/30] batch [88/148] time 0.337 (0.337) data 0.000 (0.011) loss 3.9531 (2.8878) lr 1.0000e-02 eta 0:24:28
epoch [1/30] batch [90/148] time 0.308 (0.337) data 0.000 (0.010) loss 1.4492 (2.8457) lr 1.0000e-02 eta 0:24:24
epoch [1/30] batch [92/148] time 0.314 (0.336) data 0.000 (0.010) loss 1.9814 (2.8233) lr 1.0000e-02 eta 0:24:22
epoch [1/30] batch [94/148] time 0.404 (0.337) data 0.000 (0.010) loss 1.1152 (2.7890) lr 1.0000e-02 eta 0:24:23
epoch [1/30] batch [96/148] time 0.307 (0.336) data 0.000 (0.010) loss 2.2559 (2.7803) lr 1.0000e-02 eta 0:24:19
epoch [1/30] batch [98/148] time 0.313 (0.336) data 0.000 (0.010) loss 2.7891 (2.7688) lr 1.0000e-02 eta 0:24:18
epoch [1/30] batch [100/148] time 0.306 (0.335) data 0.000 (0.009) loss 2.5254 (2.7540) lr 1.0000e-02 eta 0:24:15
epoch [1/30] batch [102/148] time 0.309 (0.335) data 0.000 (0.009) loss 1.5186 (2.7314) lr 1.0000e-02 eta 0:24:12
epoch [1/30] batch [104/148] time 0.306 (0.334) data 0.000 (0.009) loss 1.6055 (2.7116) lr 1.0000e-02 eta 0:24:10
epoch [1/30] batch [106/148] time 0.307 (0.334) data 0.001 (0.009) loss 2.9629 (2.7084) lr 1.0000e-02 eta 0:24:07
epoch [1/30] batch [108/148] time 0.310 (0.333) data 0.000 (0.009) loss 3.5234 (2.6992) lr 1.0000e-02 eta 0:24:04
epoch [1/30] batch [110/148] time 0.311 (0.333) data 0.000 (0.009) loss 1.3564 (2.6702) lr 1.0000e-02 eta 0:24:02
epoch [1/30] batch [112/148] time 0.309 (0.333) data 0.000 (0.008) loss 0.2040 (2.6355) lr 1.0000e-02 eta 0:23:59
epoch [1/30] batch [114/148] time 0.307 (0.332) data 0.000 (0.008) loss 2.8789 (2.6418) lr 1.0000e-02 eta 0:23:57
epoch [1/30] batch [116/148] time 0.307 (0.332) data 0.000 (0.008) loss 1.0400 (2.6112) lr 1.0000e-02 eta 0:23:55
epoch [1/30] batch [118/148] time 0.308 (0.331) data 0.000 (0.008) loss 0.9351 (2.5780) lr 1.0000e-02 eta 0:23:52
epoch [1/30] batch [120/148] time 0.313 (0.331) data 0.000 (0.008) loss 2.5547 (2.5757) lr 1.0000e-02 eta 0:23:50
epoch [1/30] batch [122/148] time 0.311 (0.331) data 0.000 (0.008) loss 2.9648 (2.5863) lr 1.0000e-02 eta 0:23:48
epoch [1/30] batch [124/148] time 0.308 (0.330) data 0.000 (0.008) loss 1.3076 (2.5699) lr 1.0000e-02 eta 0:23:46
epoch [1/30] batch [126/148] time 0.291 (0.330) data 0.000 (0.008) loss 0.3550 (2.5361) lr 1.0000e-02 eta 0:23:42
epoch [1/30] batch [128/148] time 0.292 (0.329) data 0.000 (0.007) loss 1.8799 (2.5216) lr 1.0000e-02 eta 0:23:39
epoch [1/30] batch [130/148] time 0.292 (0.329) data 0.000 (0.007) loss 4.2891 (2.5275) lr 1.0000e-02 eta 0:23:36
epoch [1/30] batch [132/148] time 0.291 (0.328) data 0.000 (0.007) loss 2.2500 (2.5150) lr 1.0000e-02 eta 0:23:33
epoch [1/30] batch [134/148] time 0.295 (0.328) data 0.000 (0.007) loss 3.6543 (2.5147) lr 1.0000e-02 eta 0:23:30
epoch [1/30] batch [136/148] time 0.293 (0.327) data 0.000 (0.007) loss 3.5801 (2.5081) lr 1.0000e-02 eta 0:23:28
epoch [1/30] batch [138/148] time 0.293 (0.327) data 0.000 (0.007) loss 0.2296 (2.4924) lr 1.0000e-02 eta 0:23:25
epoch [1/30] batch [140/148] time 0.296 (0.326) data 0.000 (0.007) loss 1.2715 (2.4771) lr 1.0000e-02 eta 0:23:22
epoch [1/30] batch [142/148] time 0.291 (0.326) data 0.000 (0.007) loss 1.3799 (2.4781) lr 1.0000e-02 eta 0:23:19
epoch [1/30] batch [144/148] time 0.292 (0.325) data 0.000 (0.007) loss 0.8462 (2.4641) lr 1.0000e-02 eta 0:23:17
epoch [1/30] batch [146/148] time 0.290 (0.325) data 0.000 (0.007) loss 2.5312 (2.4598) lr 1.0000e-02 eta 0:23:14
epoch [1/30] batch [148/148] time 0.295 (0.324) data 0.000 (0.006) loss 0.2703 (2.4336) lr 9.9726e-03 eta 0:23:12
epoch [2/30] batch [2/148] time 0.311 (0.603) data 0.000 (0.249) loss 1.3672 (1.4141) lr 9.9726e-03 eta 0:43:06
epoch [2/30] batch [4/148] time 0.308 (0.457) data 0.000 (0.124) loss 0.8291 (1.2278) lr 9.9726e-03 eta 0:32:37
epoch [2/30] batch [6/148] time 0.317 (0.409) data 0.000 (0.083) loss 0.5054 (0.9437) lr 9.9726e-03 eta 0:29:14
epoch [2/30] batch [8/148] time 0.304 (0.383) data 0.000 (0.062) loss 2.2930 (1.1732) lr 9.9726e-03 eta 0:27:22
epoch [2/30] batch [10/148] time 0.314 (0.370) data 0.000 (0.050) loss 2.2793 (1.2508) lr 9.9726e-03 eta 0:26:23
epoch [2/30] batch [12/148] time 0.313 (0.360) data 0.000 (0.042) loss 0.7974 (1.3545) lr 9.9726e-03 eta 0:25:39
epoch [2/30] batch [14/148] time 0.310 (0.353) data 0.000 (0.036) loss 0.8896 (1.3903) lr 9.9726e-03 eta 0:25:08
epoch [2/30] batch [16/148] time 0.306 (0.348) data 0.000 (0.031) loss 0.8701 (1.3402) lr 9.9726e-03 eta 0:24:46
epoch [2/30] batch [18/148] time 0.311 (0.344) data 0.000 (0.028) loss 2.9883 (1.3788) lr 9.9726e-03 eta 0:24:29
epoch [2/30] batch [20/148] time 0.316 (0.341) data 0.000 (0.025) loss 1.7256 (1.4467) lr 9.9726e-03 eta 0:24:16
epoch [2/30] batch [22/148] time 0.310 (0.338) data 0.000 (0.023) loss 0.6108 (1.4141) lr 9.9726e-03 eta 0:24:04
epoch [2/30] batch [24/148] time 0.330 (0.337) data 0.000 (0.021) loss 0.8135 (1.4478) lr 9.9726e-03 eta 0:23:56
epoch [2/30] batch [26/148] time 0.312 (0.335) data 0.000 (0.019) loss 1.9385 (1.5598) lr 9.9726e-03 eta 0:23:47
epoch [2/30] batch [28/148] time 0.319 (0.337) data 0.000 (0.018) loss 1.8447 (1.5671) lr 9.9726e-03 eta 0:23:57
epoch [2/30] batch [30/148] time 0.320 (0.336) data 0.000 (0.017) loss 0.4226 (1.5656) lr 9.9726e-03 eta 0:23:50
epoch [2/30] batch [32/148] time 0.311 (0.334) data 0.000 (0.016) loss 0.1609 (1.4771) lr 9.9726e-03 eta 0:23:42
epoch [2/30] batch [34/148] time 0.313 (0.332) data 0.000 (0.015) loss 3.0918 (1.5527) lr 9.9726e-03 eta 0:23:35
epoch [2/30] batch [36/148] time 0.316 (0.331) data 0.000 (0.014) loss 1.3291 (1.5536) lr 9.9726e-03 eta 0:23:30
epoch [2/30] batch [38/148] time 0.310 (0.330) data 0.000 (0.013) loss 0.1552 (1.5601) lr 9.9726e-03 eta 0:23:24
epoch [2/30] batch [40/148] time 0.309 (0.329) data 0.000 (0.013) loss 2.3945 (1.5925) lr 9.9726e-03 eta 0:23:19
epoch [2/30] batch [42/148] time 0.314 (0.328) data 0.000 (0.012) loss 0.6973 (1.5487) lr 9.9726e-03 eta 0:23:15
epoch [2/30] batch [44/148] time 0.311 (0.328) data 0.000 (0.012) loss 1.1592 (1.5426) lr 9.9726e-03 eta 0:23:11
epoch [2/30] batch [46/148] time 0.321 (0.327) data 0.000 (0.011) loss 0.8506 (1.5628) lr 9.9726e-03 eta 0:23:08
epoch [2/30] batch [48/148] time 0.306 (0.326) data 0.000 (0.011) loss 1.9814 (1.5736) lr 9.9726e-03 eta 0:23:05
epoch [2/30] batch [50/148] time 0.309 (0.326) data 0.000 (0.010) loss 0.3330 (1.5571) lr 9.9726e-03 eta 0:23:01
epoch [2/30] batch [52/148] time 0.309 (0.325) data 0.000 (0.010) loss 0.8394 (1.5479) lr 9.9726e-03 eta 0:22:58
epoch [2/30] batch [54/148] time 0.311 (0.325) data 0.000 (0.009) loss 2.0684 (1.5401) lr 9.9726e-03 eta 0:22:56
epoch [2/30] batch [56/148] time 0.308 (0.324) data 0.000 (0.009) loss 0.6973 (1.5238) lr 9.9726e-03 eta 0:22:53
epoch [2/30] batch [58/148] time 0.311 (0.324) data 0.000 (0.009) loss 1.4395 (1.5297) lr 9.9726e-03 eta 0:22:51
epoch [2/30] batch [60/148] time 0.308 (0.323) data 0.000 (0.009) loss 1.4199 (1.5393) lr 9.9726e-03 eta 0:22:48
epoch [2/30] batch [62/148] time 0.305 (0.323) data 0.000 (0.008) loss 1.5225 (1.5220) lr 9.9726e-03 eta 0:22:45
epoch [2/30] batch [64/148] time 0.305 (0.322) data 0.000 (0.008) loss 4.1328 (1.5523) lr 9.9726e-03 eta 0:22:42
epoch [2/30] batch [66/148] time 0.312 (0.322) data 0.000 (0.008) loss 0.2871 (1.5487) lr 9.9726e-03 eta 0:22:40
epoch [2/30] batch [68/148] time 0.315 (0.322) data 0.000 (0.008) loss 1.9316 (1.5349) lr 9.9726e-03 eta 0:22:38
epoch [2/30] batch [70/148] time 0.356 (0.322) data 0.000 (0.007) loss 0.4453 (1.5094) lr 9.9726e-03 eta 0:22:39
epoch [2/30] batch [72/148] time 0.320 (0.322) data 0.000 (0.007) loss 0.1604 (1.4863) lr 9.9726e-03 eta 0:22:39
epoch [2/30] batch [74/148] time 0.311 (0.322) data 0.000 (0.007) loss 2.1230 (1.4795) lr 9.9726e-03 eta 0:22:37
epoch [2/30] batch [76/148] time 0.309 (0.322) data 0.000 (0.007) loss 2.0234 (1.5115) lr 9.9726e-03 eta 0:22:35
epoch [2/30] batch [78/148] time 0.318 (0.321) data 0.000 (0.007) loss 0.3774 (1.4856) lr 9.9726e-03 eta 0:22:34
epoch [2/30] batch [80/148] time 0.318 (0.321) data 0.000 (0.007) loss 0.2871 (1.4583) lr 9.9726e-03 eta 0:22:32
epoch [2/30] batch [82/148] time 0.322 (0.321) data 0.000 (0.006) loss 2.2402 (1.4834) lr 9.9726e-03 eta 0:22:31
epoch [2/30] batch [84/148] time 0.305 (0.321) data 0.000 (0.006) loss 1.4648 (1.4850) lr 9.9726e-03 eta 0:22:30
epoch [2/30] batch [86/148] time 0.313 (0.321) data 0.000 (0.006) loss 0.9009 (1.4980) lr 9.9726e-03 eta 0:22:28
epoch [2/30] batch [88/148] time 0.316 (0.320) data 0.000 (0.006) loss 4.4844 (1.5460) lr 9.9726e-03 eta 0:22:27
epoch [2/30] batch [90/148] time 0.313 (0.320) data 0.000 (0.006) loss 1.8379 (1.5373) lr 9.9726e-03 eta 0:22:25
epoch [2/30] batch [92/148] time 0.313 (0.320) data 0.000 (0.006) loss 1.3125 (1.5214) lr 9.9726e-03 eta 0:22:24
epoch [2/30] batch [94/148] time 0.304 (0.320) data 0.000 (0.006) loss 3.3789 (1.5589) lr 9.9726e-03 eta 0:22:22
epoch [2/30] batch [96/148] time 0.311 (0.320) data 0.000 (0.005) loss 2.7949 (1.5687) lr 9.9726e-03 eta 0:22:20
epoch [2/30] batch [98/148] time 0.316 (0.319) data 0.000 (0.005) loss 0.3884 (1.5653) lr 9.9726e-03 eta 0:22:19
epoch [2/30] batch [100/148] time 0.307 (0.319) data 0.000 (0.005) loss 0.3186 (1.5453) lr 9.9726e-03 eta 0:22:18
epoch [2/30] batch [102/148] time 0.402 (0.320) data 0.000 (0.005) loss 1.4385 (1.5510) lr 9.9726e-03 eta 0:22:21
epoch [2/30] batch [104/148] time 0.313 (0.320) data 0.000 (0.005) loss 1.0928 (1.5571) lr 9.9726e-03 eta 0:22:20
epoch [2/30] batch [106/148] time 0.322 (0.320) data 0.000 (0.005) loss 0.3628 (1.5361) lr 9.9726e-03 eta 0:22:20
epoch [2/30] batch [108/148] time 0.313 (0.320) data 0.000 (0.005) loss 1.5420 (1.5314) lr 9.9726e-03 eta 0:22:18
epoch [2/30] batch [110/148] time 0.313 (0.320) data 0.000 (0.005) loss 1.0635 (1.5445) lr 9.9726e-03 eta 0:22:17
epoch [2/30] batch [112/148] time 0.309 (0.320) data 0.000 (0.005) loss 0.7446 (1.5431) lr 9.9726e-03 eta 0:22:16
epoch [2/30] batch [114/148] time 0.313 (0.320) data 0.000 (0.005) loss 1.8877 (1.5432) lr 9.9726e-03 eta 0:22:15
epoch [2/30] batch [116/148] time 0.308 (0.320) data 0.000 (0.005) loss 0.1504 (1.5188) lr 9.9726e-03 eta 0:22:14
epoch [2/30] batch [118/148] time 0.306 (0.319) data 0.000 (0.005) loss 5.4141 (1.5474) lr 9.9726e-03 eta 0:22:12
epoch [2/30] batch [120/148] time 0.321 (0.319) data 0.000 (0.004) loss 0.7729 (1.5383) lr 9.9726e-03 eta 0:22:12
epoch [2/30] batch [122/148] time 0.313 (0.319) data 0.000 (0.004) loss 2.9629 (1.5429) lr 9.9726e-03 eta 0:22:11
epoch [2/30] batch [124/148] time 0.311 (0.319) data 0.000 (0.004) loss 2.8320 (1.5590) lr 9.9726e-03 eta 0:22:10
epoch [2/30] batch [126/148] time 0.294 (0.319) data 0.000 (0.004) loss 1.3477 (1.5515) lr 9.9726e-03 eta 0:22:07
epoch [2/30] batch [128/148] time 0.293 (0.318) data 0.000 (0.004) loss 0.6123 (1.5416) lr 9.9726e-03 eta 0:22:05
epoch [2/30] batch [130/148] time 0.294 (0.318) data 0.000 (0.004) loss 2.5762 (1.5730) lr 9.9726e-03 eta 0:22:03
epoch [2/30] batch [132/148] time 0.297 (0.318) data 0.000 (0.004) loss 0.6807 (1.5579) lr 9.9726e-03 eta 0:22:01
epoch [2/30] batch [134/148] time 0.294 (0.317) data 0.000 (0.004) loss 4.2305 (1.5789) lr 9.9726e-03 eta 0:21:59
epoch [2/30] batch [136/148] time 0.293 (0.317) data 0.000 (0.004) loss 1.8291 (1.5959) lr 9.9726e-03 eta 0:21:57
epoch [2/30] batch [138/148] time 0.299 (0.317) data 0.000 (0.004) loss 2.3672 (1.6041) lr 9.9726e-03 eta 0:21:55
epoch [2/30] batch [140/148] time 0.298 (0.316) data 0.000 (0.004) loss 2.8340 (1.6030) lr 9.9726e-03 eta 0:21:53
epoch [2/30] batch [142/148] time 0.296 (0.316) data 0.000 (0.004) loss 1.3682 (1.5988) lr 9.9726e-03 eta 0:21:51
epoch [2/30] batch [144/148] time 0.295 (0.316) data 0.000 (0.004) loss 1.0381 (1.5966) lr 9.9726e-03 eta 0:21:49
epoch [2/30] batch [146/148] time 0.292 (0.315) data 0.000 (0.004) loss 0.2435 (1.5924) lr 9.9726e-03 eta 0:21:48
epoch [2/30] batch [148/148] time 0.296 (0.315) data 0.000 (0.004) loss 0.6611 (1.5860) lr 9.8907e-03 eta 0:21:46
epoch [3/30] batch [2/148] time 0.307 (0.584) data 0.000 (0.246) loss 2.4258 (1.7202) lr 9.8907e-03 eta 0:40:20
epoch [3/30] batch [4/148] time 0.316 (0.448) data 0.000 (0.123) loss 1.6250 (1.5046) lr 9.8907e-03 eta 0:30:55
epoch [3/30] batch [6/148] time 0.309 (0.402) data 0.000 (0.082) loss 2.0273 (1.5726) lr 9.8907e-03 eta 0:27:43
epoch [3/30] batch [8/148] time 0.311 (0.380) data 0.000 (0.062) loss 3.1328 (1.5818) lr 9.8907e-03 eta 0:26:11
epoch [3/30] batch [10/148] time 0.313 (0.366) data 0.000 (0.049) loss 6.3477 (2.0143) lr 9.8907e-03 eta 0:25:14
epoch [3/30] batch [12/148] time 0.310 (0.358) data 0.000 (0.041) loss 0.5337 (1.9290) lr 9.8907e-03 eta 0:24:37
epoch [3/30] batch [14/148] time 0.442 (0.360) data 0.000 (0.035) loss 3.5820 (2.0492) lr 9.8907e-03 eta 0:24:47
epoch [3/30] batch [16/148] time 0.309 (0.354) data 0.000 (0.031) loss 2.7480 (2.0899) lr 9.8907e-03 eta 0:24:20
epoch [3/30] batch [18/148] time 0.307 (0.349) data 0.000 (0.028) loss 1.2168 (2.1183) lr 9.8907e-03 eta 0:23:59
epoch [3/30] batch [20/148] time 0.306 (0.345) data 0.000 (0.025) loss 1.8291 (2.0630) lr 9.8907e-03 eta 0:23:42
epoch [3/30] batch [22/148] time 0.311 (0.342) data 0.000 (0.023) loss 0.1687 (1.9239) lr 9.8907e-03 eta 0:23:29
epoch [3/30] batch [24/148] time 0.309 (0.339) data 0.000 (0.021) loss 0.5825 (1.8327) lr 9.8907e-03 eta 0:23:18
epoch [3/30] batch [26/148] time 0.320 (0.338) data 0.000 (0.019) loss 0.4807 (1.7259) lr 9.8907e-03 eta 0:23:11
epoch [3/30] batch [28/148] time 0.313 (0.336) data 0.000 (0.018) loss 1.1611 (1.7357) lr 9.8907e-03 eta 0:23:04
epoch [3/30] batch [30/148] time 0.306 (0.335) data 0.000 (0.017) loss 0.2050 (1.7117) lr 9.8907e-03 eta 0:22:56
epoch [3/30] batch [32/148] time 0.312 (0.333) data 0.000 (0.016) loss 1.3271 (1.6776) lr 9.8907e-03 eta 0:22:50
epoch [3/30] batch [34/148] time 0.313 (0.332) data 0.000 (0.015) loss 2.8672 (1.6843) lr 9.8907e-03 eta 0:22:44
epoch [3/30] batch [36/148] time 0.315 (0.331) data 0.000 (0.014) loss 1.9707 (1.6742) lr 9.8907e-03 eta 0:22:39
epoch [3/30] batch [38/148] time 0.309 (0.330) data 0.000 (0.013) loss 0.4995 (1.6074) lr 9.8907e-03 eta 0:22:34
epoch [3/30] batch [40/148] time 0.306 (0.329) data 0.000 (0.013) loss 0.3240 (1.5944) lr 9.8907e-03 eta 0:22:29
epoch [3/30] batch [42/148] time 0.318 (0.328) data 0.000 (0.012) loss 0.1458 (1.5323) lr 9.8907e-03 eta 0:22:26
epoch [3/30] batch [44/148] time 0.314 (0.328) data 0.000 (0.011) loss 0.1802 (1.5181) lr 9.8907e-03 eta 0:22:23
epoch [3/30] batch [46/148] time 0.306 (0.327) data 0.000 (0.011) loss 2.4531 (1.5181) lr 9.8907e-03 eta 0:22:18
epoch [3/30] batch [48/148] time 0.317 (0.326) data 0.000 (0.011) loss 2.2949 (1.5161) lr 9.8907e-03 eta 0:22:16
epoch [3/30] batch [50/148] time 0.311 (0.326) data 0.000 (0.010) loss 0.4905 (1.4935) lr 9.8907e-03 eta 0:22:13
epoch [3/30] batch [52/148] time 0.311 (0.325) data 0.000 (0.010) loss 0.2114 (1.4653) lr 9.8907e-03 eta 0:22:09
epoch [3/30] batch [54/148] time 0.307 (0.324) data 0.000 (0.009) loss 0.4517 (1.4479) lr 9.8907e-03 eta 0:22:06
epoch [3/30] batch [56/148] time 0.307 (0.324) data 0.000 (0.009) loss 1.2256 (1.4372) lr 9.8907e-03 eta 0:22:03
epoch [3/30] batch [58/148] time 0.314 (0.323) data 0.000 (0.009) loss 0.6982 (1.4422) lr 9.8907e-03 eta 0:22:01
epoch [3/30] batch [60/148] time 0.307 (0.323) data 0.000 (0.008) loss 3.8633 (1.5230) lr 9.8907e-03 eta 0:21:58
epoch [3/30] batch [62/148] time 0.320 (0.323) data 0.000 (0.008) loss 2.3926 (1.5336) lr 9.8907e-03 eta 0:21:57
epoch [3/30] batch [64/148] time 0.310 (0.322) data 0.000 (0.008) loss 1.8174 (1.5280) lr 9.8907e-03 eta 0:21:55
epoch [3/30] batch [66/148] time 0.328 (0.322) data 0.000 (0.008) loss 1.1006 (1.5477) lr 9.8907e-03 eta 0:21:54
epoch [3/30] batch [68/148] time 0.303 (0.322) data 0.000 (0.008) loss 0.2188 (1.5214) lr 9.8907e-03 eta 0:21:51
epoch [3/30] batch [70/148] time 0.311 (0.321) data 0.000 (0.007) loss 3.3496 (1.5351) lr 9.8907e-03 eta 0:21:49
epoch [3/30] batch [72/148] time 0.392 (0.322) data 0.000 (0.007) loss 2.4453 (1.5465) lr 9.8907e-03 eta 0:21:52
epoch [3/30] batch [74/148] time 0.317 (0.322) data 0.000 (0.007) loss 0.6504 (1.5309) lr 9.8907e-03 eta 0:21:50
epoch [3/30] batch [76/148] time 0.328 (0.322) data 0.000 (0.007) loss 0.9658 (1.5079) lr 9.8907e-03 eta 0:21:49
epoch [3/30] batch [78/148] time 0.311 (0.322) data 0.000 (0.007) loss 0.7910 (1.5074) lr 9.8907e-03 eta 0:21:47
epoch [3/30] batch [80/148] time 0.312 (0.321) data 0.000 (0.006) loss 2.2559 (1.5037) lr 9.8907e-03 eta 0:21:46
epoch [3/30] batch [82/148] time 0.315 (0.321) data 0.000 (0.006) loss 3.1895 (1.5695) lr 9.8907e-03 eta 0:21:44
epoch [3/30] batch [84/148] time 0.305 (0.321) data 0.000 (0.006) loss 0.0992 (1.5424) lr 9.8907e-03 eta 0:21:42
epoch [3/30] batch [86/148] time 0.316 (0.321) data 0.000 (0.006) loss 1.2500 (1.5499) lr 9.8907e-03 eta 0:21:41
epoch [3/30] batch [88/148] time 0.304 (0.320) data 0.000 (0.006) loss 4.2305 (1.5690) lr 9.8907e-03 eta 0:21:39
epoch [3/30] batch [90/148] time 0.310 (0.320) data 0.000 (0.006) loss 1.4404 (1.5648) lr 9.8907e-03 eta 0:21:38
epoch [3/30] batch [92/148] time 0.342 (0.320) data 0.000 (0.006) loss 4.2656 (1.5933) lr 9.8907e-03 eta 0:21:38
epoch [3/30] batch [94/148] time 0.313 (0.320) data 0.000 (0.006) loss 0.6426 (1.5699) lr 9.8907e-03 eta 0:21:37
epoch [3/30] batch [96/148] time 0.308 (0.320) data 0.000 (0.005) loss 2.9961 (1.5804) lr 9.8907e-03 eta 0:21:35
epoch [3/30] batch [98/148] time 0.310 (0.320) data 0.000 (0.005) loss 1.6514 (1.5663) lr 9.8907e-03 eta 0:21:33
epoch [3/30] batch [100/148] time 0.312 (0.320) data 0.000 (0.005) loss 1.7832 (1.5918) lr 9.8907e-03 eta 0:21:32
epoch [3/30] batch [102/148] time 0.305 (0.319) data 0.000 (0.005) loss 0.6211 (1.5687) lr 9.8907e-03 eta 0:21:31
epoch [3/30] batch [104/148] time 0.305 (0.319) data 0.000 (0.005) loss 1.1816 (1.5572) lr 9.8907e-03 eta 0:21:29
epoch [3/30] batch [106/148] time 0.303 (0.319) data 0.000 (0.005) loss 0.2238 (1.5564) lr 9.8907e-03 eta 0:21:27
epoch [3/30] batch [108/148] time 0.309 (0.319) data 0.000 (0.005) loss 1.9688 (1.5712) lr 9.8907e-03 eta 0:21:26
epoch [3/30] batch [110/148] time 0.314 (0.319) data 0.000 (0.005) loss 0.6982 (1.5640) lr 9.8907e-03 eta 0:21:25
epoch [3/30] batch [112/148] time 0.317 (0.319) data 0.000 (0.005) loss 0.2859 (1.5565) lr 9.8907e-03 eta 0:21:24
epoch [3/30] batch [114/148] time 0.320 (0.318) data 0.000 (0.005) loss 0.4417 (1.5350) lr 9.8907e-03 eta 0:21:23
epoch [3/30] batch [116/148] time 0.308 (0.318) data 0.000 (0.005) loss 1.0635 (1.5345) lr 9.8907e-03 eta 0:21:22
epoch [3/30] batch [118/148] time 0.303 (0.318) data 0.000 (0.004) loss 3.5859 (1.5561) lr 9.8907e-03 eta 0:21:20
epoch [3/30] batch [120/148] time 0.308 (0.318) data 0.000 (0.004) loss 0.2018 (1.5428) lr 9.8907e-03 eta 0:21:19
epoch [3/30] batch [122/148] time 0.312 (0.318) data 0.000 (0.004) loss 0.6113 (1.5549) lr 9.8907e-03 eta 0:21:18
epoch [3/30] batch [124/148] time 0.308 (0.318) data 0.000 (0.004) loss 1.3984 (1.5443) lr 9.8907e-03 eta 0:21:17
epoch [3/30] batch [126/148] time 0.293 (0.317) data 0.000 (0.004) loss 2.8809 (1.5649) lr 9.8907e-03 eta 0:21:15
epoch [3/30] batch [128/148] time 0.302 (0.317) data 0.000 (0.004) loss 5.0742 (1.5880) lr 9.8907e-03 eta 0:21:13
epoch [3/30] batch [130/148] time 0.293 (0.317) data 0.000 (0.004) loss 1.1777 (1.5849) lr 9.8907e-03 eta 0:21:11
epoch [3/30] batch [132/148] time 0.298 (0.316) data 0.000 (0.004) loss 3.2148 (1.5924) lr 9.8907e-03 eta 0:21:09
epoch [3/30] batch [134/148] time 0.290 (0.316) data 0.000 (0.004) loss 2.1445 (1.6046) lr 9.8907e-03 eta 0:21:07
epoch [3/30] batch [136/148] time 0.295 (0.316) data 0.000 (0.004) loss 0.7900 (1.5912) lr 9.8907e-03 eta 0:21:05
epoch [3/30] batch [138/148] time 0.293 (0.315) data 0.000 (0.004) loss 1.0146 (1.5803) lr 9.8907e-03 eta 0:21:03
epoch [3/30] batch [140/148] time 0.297 (0.315) data 0.000 (0.004) loss 2.7461 (1.5800) lr 9.8907e-03 eta 0:21:01
epoch [3/30] batch [142/148] time 0.290 (0.315) data 0.000 (0.004) loss 3.0430 (1.5952) lr 9.8907e-03 eta 0:21:00
epoch [3/30] batch [144/148] time 0.292 (0.315) data 0.000 (0.004) loss 0.6660 (1.5935) lr 9.8907e-03 eta 0:20:58
epoch [3/30] batch [146/148] time 0.297 (0.314) data 0.000 (0.004) loss 0.1180 (1.5864) lr 9.8907e-03 eta 0:20:56
epoch [3/30] batch [148/148] time 0.295 (0.314) data 0.000 (0.004) loss 0.7119 (1.5893) lr 9.7553e-03 eta 0:20:54
epoch [4/30] batch [2/148] time 0.316 (0.595) data 0.000 (0.243) loss 4.1055 (2.2059) lr 9.7553e-03 eta 0:39:37
epoch [4/30] batch [4/148] time 0.317 (0.455) data 0.000 (0.122) loss 0.1342 (1.2542) lr 9.7553e-03 eta 0:30:17
epoch [4/30] batch [6/148] time 0.318 (0.410) data 0.000 (0.081) loss 4.1250 (1.8329) lr 9.7553e-03 eta 0:27:16
epoch [4/30] batch [8/148] time 0.309 (0.385) data 0.000 (0.061) loss 1.1162 (1.7498) lr 9.7553e-03 eta 0:25:35
epoch [4/30] batch [10/148] time 0.311 (0.370) data 0.000 (0.049) loss 3.6426 (2.3020) lr 9.7553e-03 eta 0:24:34
epoch [4/30] batch [12/148] time 0.314 (0.360) data 0.000 (0.041) loss 0.6006 (2.0057) lr 9.7553e-03 eta 0:23:54
epoch [4/30] batch [14/148] time 0.304 (0.353) data 0.000 (0.035) loss 0.3230 (1.8263) lr 9.7553e-03 eta 0:23:26
epoch [4/30] batch [16/148] time 0.314 (0.348) data 0.000 (0.031) loss 0.1968 (1.6505) lr 9.7553e-03 eta 0:23:04
epoch [4/30] batch [18/148] time 0.317 (0.344) data 0.000 (0.027) loss 0.5312 (1.7116) lr 9.7553e-03 eta 0:22:47
epoch [4/30] batch [20/148] time 0.309 (0.341) data 0.000 (0.025) loss 3.7969 (1.7726) lr 9.7553e-03 eta 0:22:34
epoch [4/30] batch [22/148] time 0.320 (0.338) data 0.000 (0.022) loss 4.0156 (1.8418) lr 9.7553e-03 eta 0:22:24
epoch [4/30] batch [24/148] time 0.308 (0.336) data 0.000 (0.021) loss 0.2974 (1.7553) lr 9.7553e-03 eta 0:22:16
epoch [4/30] batch [26/148] time 0.300 (0.334) data 0.000 (0.019) loss 0.7642 (1.6674) lr 9.7553e-03 eta 0:22:06
epoch [4/30] batch [28/148] time 0.319 (0.333) data 0.000 (0.018) loss 0.7075 (1.6394) lr 9.7553e-03 eta 0:21:59
epoch [4/30] batch [30/148] time 0.323 (0.331) data 0.000 (0.016) loss 0.7617 (1.5611) lr 9.7553e-03 eta 0:21:54
epoch [4/30] batch [32/148] time 0.415 (0.333) data 0.000 (0.015) loss 2.6836 (1.5871) lr 9.7553e-03 eta 0:22:01
epoch [4/30] batch [34/148] time 0.315 (0.332) data 0.000 (0.015) loss 0.1892 (1.5499) lr 9.7553e-03 eta 0:21:56
epoch [4/30] batch [36/148] time 0.307 (0.331) data 0.000 (0.014) loss 1.2881 (1.5627) lr 9.7553e-03 eta 0:21:49
epoch [4/30] batch [38/148] time 0.305 (0.330) data 0.000 (0.013) loss 0.8105 (1.5313) lr 9.7553e-03 eta 0:21:44
epoch [4/30] batch [40/148] time 0.317 (0.329) data 0.000 (0.012) loss 0.5474 (1.5373) lr 9.7553e-03 eta 0:21:40
epoch [4/30] batch [42/148] time 0.309 (0.328) data 0.000 (0.012) loss 0.1934 (1.5028) lr 9.7553e-03 eta 0:21:36
epoch [4/30] batch [44/148] time 0.307 (0.327) data 0.000 (0.011) loss 2.1719 (1.5202) lr 9.7553e-03 eta 0:21:32
epoch [4/30] batch [46/148] time 0.314 (0.326) data 0.000 (0.011) loss 0.1499 (1.4646) lr 9.7553e-03 eta 0:21:29
epoch [4/30] batch [48/148] time 0.303 (0.326) data 0.000 (0.010) loss 2.1934 (1.5501) lr 9.7553e-03 eta 0:21:25
epoch [4/30] batch [50/148] time 0.308 (0.325) data 0.000 (0.010) loss 0.3628 (1.5566) lr 9.7553e-03 eta 0:21:22
epoch [4/30] batch [52/148] time 0.309 (0.324) data 0.000 (0.010) loss 1.1592 (1.5232) lr 9.7553e-03 eta 0:21:18
epoch [4/30] batch [54/148] time 0.297 (0.324) data 0.000 (0.009) loss 2.1914 (1.5098) lr 9.7553e-03 eta 0:21:15
epoch [4/30] batch [56/148] time 0.309 (0.323) data 0.000 (0.009) loss 1.3086 (1.5051) lr 9.7553e-03 eta 0:21:12
epoch [4/30] batch [58/148] time 0.307 (0.323) data 0.000 (0.009) loss 2.4609 (1.5693) lr 9.7553e-03 eta 0:21:10
epoch [4/30] batch [60/148] time 0.306 (0.322) data 0.000 (0.008) loss 2.0742 (1.5862) lr 9.7553e-03 eta 0:21:07
epoch [4/30] batch [62/148] time 0.309 (0.322) data 0.000 (0.008) loss 2.1270 (1.6100) lr 9.7553e-03 eta 0:21:05
epoch [4/30] batch [64/148] time 0.300 (0.321) data 0.000 (0.008) loss 0.0889 (1.5766) lr 9.7553e-03 eta 0:21:02
epoch [4/30] batch [66/148] time 0.307 (0.321) data 0.000 (0.008) loss 4.7695 (1.6389) lr 9.7553e-03 eta 0:21:00
epoch [4/30] batch [68/148] time 0.302 (0.321) data 0.000 (0.007) loss 0.7939 (1.6535) lr 9.7553e-03 eta 0:20:58
epoch [4/30] batch [70/148] time 0.303 (0.321) data 0.000 (0.007) loss 1.6338 (1.6821) lr 9.7553e-03 eta 0:20:58
epoch [4/30] batch [72/148] time 0.304 (0.320) data 0.000 (0.007) loss 0.3486 (1.6762) lr 9.7553e-03 eta 0:20:55
epoch [4/30] batch [74/148] time 0.311 (0.320) data 0.000 (0.007) loss 1.4766 (1.6553) lr 9.7553e-03 eta 0:20:53
epoch [4/30] batch [76/148] time 0.317 (0.320) data 0.000 (0.007) loss 2.8809 (1.6596) lr 9.7553e-03 eta 0:20:53
epoch [4/30] batch [78/148] time 0.308 (0.320) data 0.000 (0.007) loss 2.7812 (1.6709) lr 9.7553e-03 eta 0:20:52
epoch [4/30] batch [80/148] time 0.309 (0.319) data 0.000 (0.006) loss 0.6621 (1.6448) lr 9.7553e-03 eta 0:20:50
epoch [4/30] batch [82/148] time 0.308 (0.319) data 0.000 (0.006) loss 2.7676 (1.6949) lr 9.7553e-03 eta 0:20:48
epoch [4/30] batch [84/148] time 0.311 (0.319) data 0.000 (0.006) loss 2.7109 (1.7037) lr 9.7553e-03 eta 0:20:47
epoch [4/30] batch [86/148] time 0.307 (0.319) data 0.000 (0.006) loss 0.2844 (1.6692) lr 9.7553e-03 eta 0:20:46
epoch [4/30] batch [88/148] time 0.317 (0.318) data 0.000 (0.006) loss 0.7812 (1.6541) lr 9.7553e-03 eta 0:20:44
epoch [4/30] batch [90/148] time 0.304 (0.318) data 0.000 (0.006) loss 1.1934 (1.6340) lr 9.7553e-03 eta 0:20:42
epoch [4/30] batch [92/148] time 0.308 (0.318) data 0.000 (0.006) loss 1.3379 (1.6188) lr 9.7553e-03 eta 0:20:41
epoch [4/30] batch [94/148] time 0.315 (0.318) data 0.000 (0.005) loss 1.6689 (1.6112) lr 9.7553e-03 eta 0:20:40
epoch [4/30] batch [96/148] time 0.304 (0.318) data 0.000 (0.005) loss 0.4290 (1.5877) lr 9.7553e-03 eta 0:20:38
epoch [4/30] batch [98/148] time 0.309 (0.317) data 0.000 (0.005) loss 0.4963 (1.5648) lr 9.7553e-03 eta 0:20:36
epoch [4/30] batch [100/148] time 0.306 (0.317) data 0.000 (0.005) loss 0.7256 (1.5510) lr 9.7553e-03 eta 0:20:35
epoch [4/30] batch [102/148] time 0.305 (0.317) data 0.000 (0.005) loss 2.9551 (1.5616) lr 9.7553e-03 eta 0:20:33
epoch [4/30] batch [104/148] time 0.306 (0.317) data 0.000 (0.005) loss 0.8442 (1.5519) lr 9.7553e-03 eta 0:20:32
epoch [4/30] batch [106/148] time 0.308 (0.316) data 0.000 (0.005) loss 1.1025 (1.5534) lr 9.7553e-03 eta 0:20:30
epoch [4/30] batch [108/148] time 0.303 (0.316) data 0.000 (0.005) loss 0.6333 (1.5499) lr 9.7553e-03 eta 0:20:29
epoch [4/30] batch [110/148] time 0.306 (0.316) data 0.000 (0.005) loss 0.5962 (1.5529) lr 9.7553e-03 eta 0:20:28
epoch [4/30] batch [112/148] time 0.316 (0.316) data 0.000 (0.005) loss 1.0576 (1.5448) lr 9.7553e-03 eta 0:20:27
epoch [4/30] batch [114/148] time 0.308 (0.316) data 0.000 (0.005) loss 1.0713 (1.5544) lr 9.7553e-03 eta 0:20:26
epoch [4/30] batch [116/148] time 0.310 (0.316) data 0.000 (0.004) loss 1.4619 (1.5552) lr 9.7553e-03 eta 0:20:25
epoch [4/30] batch [118/148] time 0.313 (0.316) data 0.000 (0.004) loss 2.1074 (1.5673) lr 9.7553e-03 eta 0:20:24
epoch [4/30] batch [120/148] time 0.308 (0.316) data 0.000 (0.004) loss 0.6025 (1.5566) lr 9.7553e-03 eta 0:20:23
epoch [4/30] batch [122/148] time 0.305 (0.316) data 0.000 (0.004) loss 1.5938 (1.5493) lr 9.7553e-03 eta 0:20:22
epoch [4/30] batch [124/148] time 0.315 (0.315) data 0.000 (0.004) loss 0.2556 (1.5294) lr 9.7553e-03 eta 0:20:21
epoch [4/30] batch [126/148] time 0.292 (0.315) data 0.000 (0.004) loss 3.4707 (1.5381) lr 9.7553e-03 eta 0:20:19
epoch [4/30] batch [128/148] time 0.289 (0.315) data 0.000 (0.004) loss 4.3711 (1.5611) lr 9.7553e-03 eta 0:20:17
epoch [4/30] batch [130/148] time 0.294 (0.314) data 0.000 (0.004) loss 2.8320 (1.5640) lr 9.7553e-03 eta 0:20:15
epoch [4/30] batch [132/148] time 0.295 (0.314) data 0.000 (0.004) loss 0.3750 (1.5511) lr 9.7553e-03 eta 0:20:13
epoch [4/30] batch [134/148] time 0.292 (0.314) data 0.000 (0.004) loss 0.7861 (1.5396) lr 9.7553e-03 eta 0:20:11
epoch [4/30] batch [136/148] time 0.292 (0.313) data 0.000 (0.004) loss 1.5605 (1.5493) lr 9.7553e-03 eta 0:20:09
epoch [4/30] batch [138/148] time 0.293 (0.313) data 0.000 (0.004) loss 2.0742 (1.5520) lr 9.7553e-03 eta 0:20:07
epoch [4/30] batch [140/148] time 0.293 (0.313) data 0.000 (0.004) loss 0.9678 (1.5423) lr 9.7553e-03 eta 0:20:05
epoch [4/30] batch [142/148] time 0.290 (0.312) data 0.000 (0.004) loss 2.1211 (1.5500) lr 9.7553e-03 eta 0:20:04
epoch [4/30] batch [144/148] time 0.292 (0.312) data 0.000 (0.004) loss 1.3447 (1.5504) lr 9.7553e-03 eta 0:20:02
epoch [4/30] batch [146/148] time 0.292 (0.312) data 0.000 (0.004) loss 1.6641 (1.5602) lr 9.7553e-03 eta 0:20:00
epoch [4/30] batch [148/148] time 0.292 (0.312) data 0.000 (0.004) loss 5.6055 (1.5879) lr 9.5677e-03 eta 0:19:59
epoch [5/30] batch [2/148] time 0.312 (0.586) data 0.000 (0.253) loss 1.8398 (1.4375) lr 9.5677e-03 eta 0:37:33
epoch [5/30] batch [4/148] time 0.307 (0.446) data 0.000 (0.126) loss 0.6113 (1.2817) lr 9.5677e-03 eta 0:28:35
epoch [5/30] batch [6/148] time 0.309 (0.400) data 0.000 (0.084) loss 0.2208 (0.9407) lr 9.5677e-03 eta 0:25:36
epoch [5/30] batch [8/148] time 0.311 (0.378) data 0.000 (0.063) loss 1.4170 (1.1044) lr 9.5677e-03 eta 0:24:10
epoch [5/30] batch [10/148] time 0.313 (0.364) data 0.000 (0.051) loss 1.6963 (1.1505) lr 9.5677e-03 eta 0:23:18
epoch [5/30] batch [12/148] time 0.312 (0.356) data 0.000 (0.042) loss 0.2122 (1.0854) lr 9.5677e-03 eta 0:22:44
epoch [5/30] batch [14/148] time 0.306 (0.350) data 0.000 (0.036) loss 0.5781 (1.0631) lr 9.5677e-03 eta 0:22:20
epoch [5/30] batch [16/148] time 0.303 (0.344) data 0.000 (0.032) loss 0.1553 (0.9478) lr 9.5677e-03 eta 0:21:57
epoch [5/30] batch [18/148] time 0.311 (0.340) data 0.000 (0.028) loss 0.1617 (0.9236) lr 9.5677e-03 eta 0:21:41
epoch [5/30] batch [20/148] time 0.306 (0.337) data 0.000 (0.026) loss 0.6226 (0.8699) lr 9.5677e-03 eta 0:21:29
epoch [5/30] batch [22/148] time 0.413 (0.339) data 0.000 (0.023) loss 1.6631 (0.9340) lr 9.5677e-03 eta 0:21:36
epoch [5/30] batch [24/148] time 0.313 (0.337) data 0.000 (0.021) loss 2.0039 (1.1987) lr 9.5677e-03 eta 0:21:27
epoch [5/30] batch [26/148] time 0.309 (0.334) data 0.000 (0.020) loss 1.5742 (1.1840) lr 9.5677e-03 eta 0:21:18
epoch [5/30] batch [28/148] time 0.308 (0.334) data 0.000 (0.018) loss 1.4990 (1.1741) lr 9.5677e-03 eta 0:21:15
epoch [5/30] batch [30/148] time 0.304 (0.332) data 0.000 (0.017) loss 0.8716 (1.2680) lr 9.5677e-03 eta 0:21:08
epoch [5/30] batch [32/148] time 0.316 (0.331) data 0.000 (0.016) loss 1.3955 (1.2677) lr 9.5677e-03 eta 0:21:03
epoch [5/30] batch [34/148] time 0.306 (0.330) data 0.000 (0.015) loss 0.3225 (1.2148) lr 9.5677e-03 eta 0:20:57
epoch [5/30] batch [36/148] time 0.311 (0.329) data 0.000 (0.014) loss 1.1016 (1.2736) lr 9.5677e-03 eta 0:20:53
epoch [5/30] batch [38/148] time 0.308 (0.328) data 0.000 (0.014) loss 0.7402 (1.2665) lr 9.5677e-03 eta 0:20:49
epoch [5/30] batch [40/148] time 0.312 (0.327) data 0.000 (0.013) loss 1.3584 (1.2761) lr 9.5677e-03 eta 0:20:45
epoch [5/30] batch [42/148] time 0.304 (0.326) data 0.000 (0.012) loss 1.1768 (1.2824) lr 9.5677e-03 eta 0:20:40
epoch [5/30] batch [44/148] time 0.304 (0.325) data 0.000 (0.012) loss 0.5122 (1.2569) lr 9.5677e-03 eta 0:20:36
epoch [5/30] batch [46/148] time 0.319 (0.325) data 0.000 (0.011) loss 0.1514 (1.2116) lr 9.5677e-03 eta 0:20:34
epoch [5/30] batch [48/148] time 0.311 (0.324) data 0.000 (0.011) loss 1.3438 (1.2910) lr 9.5677e-03 eta 0:20:32
epoch [5/30] batch [50/148] time 0.316 (0.324) data 0.000 (0.010) loss 0.9907 (1.2720) lr 9.5677e-03 eta 0:20:29
epoch [5/30] batch [52/148] time 0.315 (0.323) data 0.000 (0.010) loss 2.6699 (1.2758) lr 9.5677e-03 eta 0:20:27
epoch [5/30] batch [54/148] time 0.304 (0.323) data 0.000 (0.010) loss 0.5181 (1.2626) lr 9.5677e-03 eta 0:20:24
epoch [5/30] batch [56/148] time 0.309 (0.322) data 0.000 (0.009) loss 0.7290 (1.2476) lr 9.5677e-03 eta 0:20:21
epoch [5/30] batch [58/148] time 0.304 (0.322) data 0.000 (0.009) loss 1.0908 (1.2248) lr 9.5677e-03 eta 0:20:19
epoch [5/30] batch [60/148] time 0.313 (0.321) data 0.000 (0.009) loss 0.6646 (1.2362) lr 9.5677e-03 eta 0:20:17
epoch [5/30] batch [62/148] time 0.308 (0.321) data 0.000 (0.008) loss 0.8701 (1.2403) lr 9.5677e-03 eta 0:20:15
epoch [5/30] batch [64/148] time 0.310 (0.320) data 0.000 (0.008) loss 0.3384 (1.2670) lr 9.5677e-03 eta 0:20:12
epoch [5/30] batch [66/148] time 0.308 (0.320) data 0.000 (0.008) loss 2.6289 (1.2747) lr 9.5677e-03 eta 0:20:10
epoch [5/30] batch [68/148] time 0.313 (0.320) data 0.000 (0.008) loss 4.3711 (1.3169) lr 9.5677e-03 eta 0:20:08
epoch [5/30] batch [70/148] time 0.315 (0.320) data 0.000 (0.007) loss 1.8164 (1.3182) lr 9.5677e-03 eta 0:20:07
epoch [5/30] batch [72/148] time 0.315 (0.319) data 0.000 (0.007) loss 0.0958 (1.2925) lr 9.5677e-03 eta 0:20:05
epoch [5/30] batch [74/148] time 0.312 (0.319) data 0.000 (0.007) loss 3.7129 (1.3187) lr 9.5677e-03 eta 0:20:04
epoch [5/30] batch [76/148] time 0.311 (0.319) data 0.000 (0.007) loss 0.9487 (1.3010) lr 9.5677e-03 eta 0:20:02
epoch [5/30] batch [78/148] time 0.312 (0.319) data 0.000 (0.007) loss 0.5742 (1.2833) lr 9.5677e-03 eta 0:20:01
epoch [5/30] batch [80/148] time 0.308 (0.318) data 0.000 (0.007) loss 1.9531 (1.2841) lr 9.5677e-03 eta 0:20:00
epoch [5/30] batch [82/148] time 0.306 (0.318) data 0.000 (0.006) loss 1.0742 (1.2742) lr 9.5677e-03 eta 0:19:58
epoch [5/30] batch [84/148] time 0.306 (0.318) data 0.000 (0.006) loss 0.6475 (1.3144) lr 9.5677e-03 eta 0:19:56
epoch [5/30] batch [86/148] time 0.310 (0.318) data 0.000 (0.006) loss 0.8247 (1.2994) lr 9.5677e-03 eta 0:19:55
epoch [5/30] batch [88/148] time 0.308 (0.318) data 0.000 (0.006) loss 2.7793 (1.3295) lr 9.5677e-03 eta 0:19:54
epoch [5/30] batch [90/148] time 0.312 (0.318) data 0.000 (0.006) loss 0.2930 (1.3044) lr 9.5677e-03 eta 0:19:53
epoch [5/30] batch [92/148] time 0.320 (0.318) data 0.000 (0.006) loss 0.6099 (1.2851) lr 9.5677e-03 eta 0:19:52
epoch [5/30] batch [94/148] time 0.312 (0.317) data 0.000 (0.006) loss 1.8438 (1.2991) lr 9.5677e-03 eta 0:19:51
epoch [5/30] batch [96/148] time 0.307 (0.317) data 0.000 (0.006) loss 0.3152 (1.2961) lr 9.5677e-03 eta 0:19:50
epoch [5/30] batch [98/148] time 0.312 (0.317) data 0.000 (0.005) loss 0.6025 (1.2798) lr 9.5677e-03 eta 0:19:48
epoch [5/30] batch [100/148] time 0.310 (0.317) data 0.000 (0.005) loss 0.8267 (1.2702) lr 9.5677e-03 eta 0:19:48
epoch [5/30] batch [102/148] time 0.316 (0.317) data 0.000 (0.005) loss 0.2058 (1.2547) lr 9.5677e-03 eta 0:19:47
epoch [5/30] batch [104/148] time 0.312 (0.317) data 0.000 (0.005) loss 2.8320 (1.2648) lr 9.5677e-03 eta 0:19:46
epoch [5/30] batch [106/148] time 0.310 (0.317) data 0.000 (0.005) loss 0.5474 (1.2807) lr 9.5677e-03 eta 0:19:45
epoch [5/30] batch [108/148] time 0.323 (0.317) data 0.000 (0.005) loss 2.1133 (1.2891) lr 9.5677e-03 eta 0:19:44
epoch [5/30] batch [110/148] time 0.312 (0.317) data 0.000 (0.005) loss 3.5156 (1.3456) lr 9.5677e-03 eta 0:19:43
epoch [5/30] batch [112/148] time 0.308 (0.316) data 0.000 (0.005) loss 0.6572 (1.3322) lr 9.5677e-03 eta 0:19:42
epoch [5/30] batch [114/148] time 0.323 (0.316) data 0.000 (0.005) loss 0.7241 (1.3372) lr 9.5677e-03 eta 0:19:41
epoch [5/30] batch [116/148] time 0.310 (0.316) data 0.000 (0.005) loss 1.9512 (1.3342) lr 9.5677e-03 eta 0:19:40
epoch [5/30] batch [118/148] time 0.308 (0.316) data 0.000 (0.005) loss 1.7910 (1.3489) lr 9.5677e-03 eta 0:19:39
epoch [5/30] batch [120/148] time 0.306 (0.316) data 0.000 (0.004) loss 0.5576 (1.3354) lr 9.5677e-03 eta 0:19:38
epoch [5/30] batch [122/148] time 0.306 (0.316) data 0.000 (0.004) loss 6.2500 (1.3707) lr 9.5677e-03 eta 0:19:37
epoch [5/30] batch [124/148] time 0.314 (0.316) data 0.000 (0.004) loss 0.1034 (1.3542) lr 9.5677e-03 eta 0:19:36
epoch [5/30] batch [126/148] time 0.285 (0.315) data 0.000 (0.004) loss 0.7998 (1.3417) lr 9.5677e-03 eta 0:19:34
epoch [5/30] batch [128/148] time 0.286 (0.315) data 0.000 (0.004) loss 0.2186 (1.3301) lr 9.5677e-03 eta 0:19:31
epoch [5/30] batch [130/148] time 0.284 (0.314) data 0.000 (0.004) loss 1.1611 (1.3347) lr 9.5677e-03 eta 0:19:29
epoch [5/30] batch [132/148] time 0.284 (0.314) data 0.000 (0.004) loss 0.5137 (1.3548) lr 9.5677e-03 eta 0:19:26
epoch [5/30] batch [134/148] time 0.283 (0.314) data 0.000 (0.004) loss 2.1582 (1.3841) lr 9.5677e-03 eta 0:19:24
epoch [5/30] batch [136/148] time 0.285 (0.313) data 0.000 (0.004) loss 1.9160 (1.3794) lr 9.5677e-03 eta 0:19:22
epoch [5/30] batch [138/148] time 0.285 (0.313) data 0.000 (0.004) loss 3.4297 (1.3848) lr 9.5677e-03 eta 0:19:20
epoch [5/30] batch [140/148] time 0.283 (0.312) data 0.000 (0.004) loss 1.3662 (1.3800) lr 9.5677e-03 eta 0:19:17
epoch [5/30] batch [142/148] time 0.283 (0.312) data 0.000 (0.004) loss 0.7500 (1.3735) lr 9.5677e-03 eta 0:19:15
epoch [5/30] batch [144/148] time 0.283 (0.311) data 0.000 (0.004) loss 1.7490 (1.3826) lr 9.5677e-03 eta 0:19:13
epoch [5/30] batch [146/148] time 0.283 (0.311) data 0.000 (0.004) loss 3.8945 (1.4066) lr 9.5677e-03 eta 0:19:11
epoch [5/30] batch [148/148] time 0.283 (0.311) data 0.000 (0.004) loss 0.2275 (1.3992) lr 9.3301e-03 eta 0:19:09

set -e
set -x

eval "$(conda shell.bash hook)"
++ conda shell.bash hook
+ eval 'export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We're not allowing PS1 to be unbound. It must at least be set.
    # However, we're not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi
++ '[' -z x ']'

conda activate base
++ conda activate base
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate base
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate base
+++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate base
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''5'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_4='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''5'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_4='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(base) '
+++ PS1='(base) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
+++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
+++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda'
+++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda
+++ CONDA_PREFIX=/home/s2/mjoolee/anaconda
export CONDA_SHLVL='5'
+++ export CONDA_SHLVL=5
+++ CONDA_SHLVL=5
export CONDA_DEFAULT_ENV='base'
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
export CONDA_PROMPT_MODIFIER='(base) '
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
export CONDA_PREFIX_4='/home/s2/mjoolee/anaconda/envs/dassl'
+++ export CONDA_PREFIX_4=/home/s2/mjoolee/anaconda/envs/dassl
+++ CONDA_PREFIX_4=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
+++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
+++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
+++ export _CE_M=
+++ _CE_M=
export _CE_CONDA=''
+++ export _CE_CONDA=
+++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
+++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
conda activate dassl
+ conda activate dassl
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate dassl
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate dassl
++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate dassl
+ ask_conda='PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''6'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_5='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
+ eval 'PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''6'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_5='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(dassl) '
++ PS1='(dassl) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda/envs/dassl'
++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
++ CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_SHLVL='6'
++ export CONDA_SHLVL=6
++ CONDA_SHLVL=6
export CONDA_DEFAULT_ENV='dassl'
++ export CONDA_DEFAULT_ENV=dassl
++ CONDA_DEFAULT_ENV=dassl
export CONDA_PROMPT_MODIFIER='(dassl) '
++ export 'CONDA_PROMPT_MODIFIER=(dassl) '
++ CONDA_PROMPT_MODIFIER='(dassl) '
export CONDA_PREFIX_5='/home/s2/mjoolee/anaconda'
++ export CONDA_PREFIX_5=/home/s2/mjoolee/anaconda
++ CONDA_PREFIX_5=/home/s2/mjoolee/anaconda
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r

GPU=0
+ GPU=0
SHOT=16
+ SHOT=16

for dataset in eurosat dtd oxford_flowers stanford_cars oxford_pets food101 ucf101 caltech101 sun397  imagenet
#for dataset in caltech101 imagenet
do
    for seed in 1 2 3
    do
    sh scripts/rpo_prime/base2new_train_sdl.sh ${dataset} ${seed} ${GPU} main_tmp1_0.1sdl ${SHOT}
    #sh scripts/rpo_prime/base2new_test.sh ${dataset} ${seed} ${GPU} main_9_9 ${SHOT} base
    sh scripts/rpo_prime/base2new_test_sdl.sh ${dataset} ${seed} ${GPU} main_tmp1_0.1sdl ${SHOT} new
    done
done
+ for dataset in eurosat dtd oxford_flowers stanford_cars oxford_pets food101 ucf101 caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh eurosat 1 0 main_tmp1_0.1sdl 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
80 2800 4200
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  5
# train_x  80
# val      2,800
# test     4,200
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/20] time 0.221 (0.364) data 0.000 (0.056) loss 2.4102 (1.8534) lr 9.9726e-03 eta 0:03:31
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:02<00:54,  2.01s/it]  7%|▋         | 2/28 [00:02<00:26,  1.03s/it] 11%|█         | 3/28 [00:02<00:18,  1.36it/s] 14%|█▍        | 4/28 [00:02<00:12,  1.91it/s] 18%|█▊        | 5/28 [00:03<00:08,  2.64it/s] 21%|██▏       | 6/28 [00:03<00:06,  3.43it/s] 25%|██▌       | 7/28 [00:03<00:04,  4.22it/s] 29%|██▊       | 8/28 [00:03<00:04,  4.98it/s] 32%|███▏      | 9/28 [00:03<00:03,  5.66it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.23it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.69it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.06it/s] 46%|████▋     | 13/28 [00:04<00:02,  7.34it/s] 50%|█████     | 14/28 [00:04<00:01,  7.54it/s] 54%|█████▎    | 15/28 [00:04<00:01,  7.69it/s] 57%|█████▋    | 16/28 [00:04<00:01,  7.79it/s] 61%|██████    | 17/28 [00:04<00:01,  7.88it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  8.00it/s] 75%|███████▌  | 21/28 [00:05<00:00,  8.03it/s] 79%|███████▊  | 22/28 [00:05<00:00,  8.06it/s] 82%|████████▏ | 23/28 [00:05<00:00,  8.07it/s] 86%|████████▌ | 24/28 [00:05<00:00,  8.08it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.08it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.09it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.09it/s]100%|██████████| 28/28 [00:05<00:00,  8.12it/s]100%|██████████| 28/28 [00:06<00:00,  4.60it/s]=> result
* total: 2,800
* correct: 1,836
* accuracy: 65.6%
* error: 34.4%
* macro_f1: 62.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/20] time 0.218 (0.262) data 0.000 (0.044) loss 1.3047 (1.4058) lr 9.8907e-03 eta 0:02:26
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.79s/it]  7%|▋         | 2/28 [00:01<00:21,  1.21it/s] 11%|█         | 3/28 [00:02<00:13,  1.84it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.44it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.27it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.09it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.88it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.58it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.18it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.65it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.03it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.31it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.53it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.89it/s] 61%|██████    | 17/28 [00:03<00:01,  7.95it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.90it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.96it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.04it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.07it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.08it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.10it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.09it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.09it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.10it/s]100%|██████████| 28/28 [00:05<00:00,  8.10it/s]100%|██████████| 28/28 [00:05<00:00,  5.11it/s]=> result
* total: 2,800
* correct: 1,868
* accuracy: 66.7%
* error: 33.3%
* macro_f1: 65.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/20] time 0.217 (0.261) data 0.000 (0.042) loss 0.6235 (1.0426) lr 9.7553e-03 eta 0:02:21
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.78s/it]  7%|▋         | 2/28 [00:02<00:22,  1.15it/s] 11%|█         | 3/28 [00:02<00:14,  1.75it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.41it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.22it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.05it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.84it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.55it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.10it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.59it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.97it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.27it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.50it/s] 50%|█████     | 14/28 [00:03<00:01,  7.66it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:04<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.99it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.02it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.04it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.04it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.06it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.06it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.05it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.07it/s]100%|██████████| 28/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  5.04it/s]=> result
* total: 2,800
* correct: 2,022
* accuracy: 72.2%
* error: 27.8%
* macro_f1: 70.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/20] time 0.217 (0.264) data 0.000 (0.043) loss 1.5410 (1.1411) lr 9.5677e-03 eta 0:02:17
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:02<00:54,  2.02s/it]  7%|▋         | 2/28 [00:02<00:25,  1.01it/s] 11%|█         | 3/28 [00:02<00:14,  1.68it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.44it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.26it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.08it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.86it/s] 29%|██▊       | 8/28 [00:03<00:03,  5.56it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.16it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.65it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.02it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.30it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.51it/s] 50%|█████     | 14/28 [00:03<00:01,  7.66it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.72it/s] 57%|█████▋    | 16/28 [00:04<00:01,  7.80it/s] 61%|██████    | 17/28 [00:04<00:01,  7.86it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.91it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.94it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.00it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.01it/s] 86%|████████▌ | 24/28 [00:05<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  4.91it/s]=> result
* total: 2,800
* correct: 2,165
* accuracy: 77.3%
* error: 22.7%
* macro_f1: 76.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/20] time 0.215 (0.270) data 0.000 (0.044) loss 1.8740 (0.8757) lr 9.3301e-03 eta 0:02:14
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:52,  1.96s/it]  7%|▋         | 2/28 [00:02<00:24,  1.05it/s] 11%|█         | 3/28 [00:02<00:14,  1.73it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.51it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.33it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.16it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.93it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.62it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.21it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.67it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.04it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.31it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.66it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:04<00:01,  7.77it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.83it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.89it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.93it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.96it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.02it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  4.97it/s]=> result
* total: 2,800
* correct: 2,250
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 80.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/20] time 0.218 (0.265) data 0.000 (0.043) loss 0.2388 (0.5612) lr 9.0451e-03 eta 0:02:07
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:50,  1.87s/it]  7%|▋         | 2/28 [00:02<00:23,  1.10it/s] 11%|█         | 3/28 [00:02<00:15,  1.66it/s] 14%|█▍        | 4/28 [00:02<00:10,  2.37it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.18it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.00it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.79it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.50it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.10it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.60it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.98it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.27it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.50it/s] 50%|█████     | 14/28 [00:03<00:01,  7.66it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.77it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:04<00:01,  7.91it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  4.97it/s]=> result
* total: 2,800
* correct: 2,347
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 83.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/20] time 0.217 (0.262) data 0.000 (0.043) loss 2.1016 (0.7281) lr 8.7157e-03 eta 0:02:00
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:02<00:55,  2.06s/it]  7%|▋         | 2/28 [00:02<00:25,  1.03it/s] 11%|█         | 3/28 [00:02<00:14,  1.71it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.48it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.31it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.13it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.91it/s] 29%|██▊       | 8/28 [00:03<00:03,  5.60it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.18it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.66it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.04it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.32it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.53it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.81it/s] 57%|█████▋    | 16/28 [00:04<00:01,  7.88it/s] 61%|██████    | 17/28 [00:04<00:01,  7.94it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  8.00it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.03it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.05it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.94it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.97it/s] 86%|████████▌ | 24/28 [00:05<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:05<00:00,  7.71it/s] 93%|█████████▎| 26/28 [00:05<00:00,  7.82it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.89it/s]100%|██████████| 28/28 [00:05<00:00,  7.84it/s]100%|██████████| 28/28 [00:05<00:00,  4.92it/s]=> result
* total: 2,800
* correct: 2,312
* accuracy: 82.6%
* error: 17.4%
* macro_f1: 82.7%

epoch [8/30] batch [20/20] time 0.218 (0.266) data 0.000 (0.046) loss 0.9414 (0.4806) lr 8.3457e-03 eta 0:01:57
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:50,  1.88s/it]  7%|▋         | 2/28 [00:02<00:23,  1.09it/s] 11%|█         | 3/28 [00:02<00:15,  1.64it/s] 14%|█▍        | 4/28 [00:02<00:10,  2.37it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.18it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.00it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.79it/s] 29%|██▊       | 8/28 [00:03<00:03,  5.24it/s] 32%|███▏      | 9/28 [00:03<00:03,  5.88it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.42it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.85it/s] 43%|████▎     | 12/28 [00:03<00:02,  6.89it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.20it/s] 50%|█████     | 14/28 [00:03<00:01,  7.43it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.61it/s] 57%|█████▋    | 16/28 [00:04<00:01,  7.74it/s] 61%|██████    | 17/28 [00:04<00:01,  7.82it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.88it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.25it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.48it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.63it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.74it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.82it/s] 86%|████████▌ | 24/28 [00:05<00:00,  7.88it/s] 89%|████████▉ | 25/28 [00:05<00:00,  7.93it/s] 93%|█████████▎| 26/28 [00:05<00:00,  7.96it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.97it/s]100%|██████████| 28/28 [00:05<00:00,  7.99it/s]100%|██████████| 28/28 [00:05<00:00,  4.88it/s]=> result
* total: 2,800
* correct: 2,434
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/20] time 0.220 (0.273) data 0.000 (0.045) loss -0.2283 (0.4024) lr 7.9389e-03 eta 0:01:54
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:02<00:55,  2.05s/it]  7%|▋         | 2/28 [00:02<00:25,  1.02it/s] 11%|█         | 3/28 [00:02<00:15,  1.56it/s] 14%|█▍        | 4/28 [00:02<00:10,  2.29it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.09it/s] 21%|██▏       | 6/28 [00:02<00:05,  3.91it/s] 25%|██▌       | 7/28 [00:03<00:04,  4.70it/s] 29%|██▊       | 8/28 [00:03<00:03,  5.16it/s] 32%|███▏      | 9/28 [00:03<00:03,  5.82it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.36it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.80it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.13it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.39it/s] 50%|█████     | 14/28 [00:03<00:01,  7.20it/s] 54%|█████▎    | 15/28 [00:04<00:01,  7.43it/s] 57%|█████▋    | 16/28 [00:04<00:01,  6.96it/s] 61%|██████    | 17/28 [00:04<00:01,  7.25it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.48it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.64it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.76it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.78it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.86it/s] 82%|████████▏ | 23/28 [00:05<00:00,  7.92it/s] 86%|████████▌ | 24/28 [00:05<00:00,  7.96it/s] 89%|████████▉ | 25/28 [00:05<00:00,  7.98it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  4.76it/s]=> result
* total: 2,800
* correct: 2,377
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 84.8%

epoch [10/30] batch [20/20] time 0.216 (0.264) data 0.000 (0.045) loss 0.4155 (0.4236) lr 7.5000e-03 eta 0:01:45
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:51,  1.91s/it]  7%|▋         | 2/28 [00:02<00:22,  1.16it/s] 11%|█         | 3/28 [00:02<00:14,  1.71it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.45it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.26it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.09it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.87it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.57it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.15it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.62it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.99it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.27it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.47it/s] 50%|█████     | 14/28 [00:03<00:01,  7.63it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.73it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.82it/s] 61%|██████    | 17/28 [00:04<00:01,  7.86it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.91it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.93it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.95it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.96it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.98it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.00it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.00it/s]=> result
* total: 2,800
* correct: 2,259
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 80.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/20] time 0.216 (0.264) data 0.000 (0.045) loss -0.0215 (0.4305) lr 7.0337e-03 eta 0:01:40
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.80s/it]  7%|▋         | 2/28 [00:01<00:21,  1.21it/s] 11%|█         | 3/28 [00:02<00:12,  1.97it/s] 14%|█▍        | 4/28 [00:02<00:08,  2.81it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.67it/s] 21%|██▏       | 6/28 [00:02<00:04,  4.49it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.24it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.89it/s] 32%|███▏      | 9/28 [00:02<00:02,  6.42it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.84it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.16it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.41it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.58it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.91it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.95it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.97it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.99it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.00it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.99it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  5.23it/s]=> result
* total: 2,800
* correct: 2,294
* accuracy: 81.9%
* error: 18.1%
* macro_f1: 81.6%

epoch [12/30] batch [20/20] time 0.217 (0.262) data 0.000 (0.043) loss 0.6245 (0.3005) lr 6.5451e-03 eta 0:01:34
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.74s/it]  7%|▋         | 2/28 [00:01<00:22,  1.16it/s] 11%|█         | 3/28 [00:02<00:13,  1.81it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.60it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.44it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.27it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.04it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.71it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.27it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.72it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.06it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.34it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.54it/s] 50%|█████     | 14/28 [00:03<00:01,  7.68it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:03<00:01,  7.91it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.77it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.86it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.93it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.98it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  5.12it/s]=> result
* total: 2,800
* correct: 2,375
* accuracy: 84.8%
* error: 15.2%
* macro_f1: 84.9%

epoch [13/30] batch [20/20] time 0.219 (0.267) data 0.000 (0.046) loss 1.3867 (0.2447) lr 6.0396e-03 eta 0:01:30
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:51,  1.90s/it]  7%|▋         | 2/28 [00:02<00:24,  1.08it/s] 11%|█         | 3/28 [00:02<00:15,  1.66it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.41it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.22it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.05it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.83it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.53it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.13it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.61it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.74it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.10it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.36it/s] 50%|█████     | 14/28 [00:03<00:01,  7.46it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.63it/s] 57%|█████▋    | 16/28 [00:04<00:01,  7.74it/s] 61%|██████    | 17/28 [00:04<00:01,  7.83it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.89it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.64it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.76it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.83it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.89it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.94it/s] 86%|████████▌ | 24/28 [00:05<00:00,  7.95it/s] 89%|████████▉ | 25/28 [00:05<00:00,  7.98it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  4.93it/s]=> result
* total: 2,800
* correct: 2,387
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 85.2%

epoch [14/30] batch [20/20] time 0.219 (0.273) data 0.000 (0.045) loss -0.1362 (0.0917) lr 5.5226e-03 eta 0:01:27
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:49,  1.82s/it]  7%|▋         | 2/28 [00:02<00:23,  1.10it/s] 11%|█         | 3/28 [00:02<00:14,  1.68it/s] 14%|█▍        | 4/28 [00:02<00:10,  2.29it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.09it/s] 21%|██▏       | 6/28 [00:02<00:05,  3.91it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.65it/s] 29%|██▊       | 8/28 [00:03<00:03,  5.37it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.00it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.33it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.77it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.12it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.28it/s] 50%|█████     | 14/28 [00:03<00:01,  7.51it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.67it/s] 57%|█████▋    | 16/28 [00:04<00:01,  7.79it/s] 61%|██████    | 17/28 [00:04<00:01,  7.87it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.03it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.04it/s] 86%|████████▌ | 24/28 [00:05<00:00,  8.05it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.06it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  4.92it/s]=> result
* total: 2,800
* correct: 2,453
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 87.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/20] time 0.215 (0.263) data 0.000 (0.044) loss -0.2646 (0.0687) lr 5.0000e-03 eta 0:01:18
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:51,  1.92s/it]  7%|▋         | 2/28 [00:02<00:24,  1.07it/s] 11%|█         | 3/28 [00:02<00:14,  1.75it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.53it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.37it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.19it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.97it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.65it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.22it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.69it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.04it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.30it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.50it/s] 50%|█████     | 14/28 [00:03<00:01,  7.64it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.74it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.80it/s] 61%|██████    | 17/28 [00:04<00:01,  7.86it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.88it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.87it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.91it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.93it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.94it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.96it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.97it/s] 89%|████████▉ | 25/28 [00:05<00:00,  7.97it/s] 93%|█████████▎| 26/28 [00:05<00:00,  7.97it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.98it/s]100%|██████████| 28/28 [00:05<00:00,  7.98it/s]100%|██████████| 28/28 [00:05<00:00,  5.00it/s]=> result
* total: 2,800
* correct: 2,421
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 86.5%

epoch [16/30] batch [20/20] time 0.217 (0.261) data 0.000 (0.043) loss -0.0862 (0.2226) lr 4.4774e-03 eta 0:01:13
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:43,  1.60s/it]  7%|▋         | 2/28 [00:01<00:20,  1.24it/s] 11%|█         | 3/28 [00:02<00:13,  1.84it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.63it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.47it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.30it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.06it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.73it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.30it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.76it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.11it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.91it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.99it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  5.22it/s]=> result
* total: 2,800
* correct: 2,443
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 87.3%

epoch [17/30] batch [20/20] time 0.217 (0.267) data 0.000 (0.043) loss -0.0820 (0.2456) lr 3.9604e-03 eta 0:01:09
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.74s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:13,  1.89it/s] 14%|█▍        | 4/28 [00:02<00:08,  2.70it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.55it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.38it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.14it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.80it/s] 32%|███▏      | 9/28 [00:02<00:02,  6.34it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.78it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.12it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.54it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:03<00:01,  7.87it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.91it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.94it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.97it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.98it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.97it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.98it/s] 93%|█████████▎| 26/28 [00:04<00:00,  7.99it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.99it/s]100%|██████████| 28/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  5.18it/s]=> result
* total: 2,800
* correct: 2,499
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 89.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/20] time 0.219 (0.264) data 0.000 (0.043) loss -0.3079 (0.1170) lr 3.4549e-03 eta 0:01:03
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.76s/it]  7%|▋         | 2/28 [00:01<00:22,  1.16it/s] 11%|█         | 3/28 [00:02<00:13,  1.86it/s] 14%|█▍        | 4/28 [00:02<00:08,  2.67it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.52it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.35it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.12it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.79it/s] 32%|███▏      | 9/28 [00:02<00:02,  6.34it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.79it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.13it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.38it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.57it/s] 50%|█████     | 14/28 [00:03<00:01,  7.71it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.81it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.88it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.89it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.92it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.95it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.97it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.17it/s]=> result
* total: 2,800
* correct: 2,407
* accuracy: 86.0%
* error: 14.0%
* macro_f1: 85.9%

epoch [19/30] batch [20/20] time 0.215 (0.260) data 0.000 (0.042) loss 0.2500 (0.3054) lr 2.9663e-03 eta 0:00:57
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.77s/it]  7%|▋         | 2/28 [00:02<00:22,  1.14it/s] 11%|█         | 3/28 [00:02<00:13,  1.85it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.66it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.49it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.32it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.09it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.76it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.32it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.77it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.11it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.38it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.56it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.99it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.00it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.01it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.15it/s]=> result
* total: 2,800
* correct: 2,460
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 87.9%

epoch [20/30] batch [20/20] time 0.219 (0.263) data 0.000 (0.042) loss -0.4360 (0.0771) lr 2.5000e-03 eta 0:00:52
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:50,  1.87s/it]  7%|▋         | 2/28 [00:02<00:23,  1.10it/s] 11%|█         | 3/28 [00:02<00:13,  1.79it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.58it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.41it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.24it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.02it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.69it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.26it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.71it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.07it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.33it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.44it/s] 50%|█████     | 14/28 [00:03<00:01,  7.61it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.67it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.77it/s] 61%|██████    | 17/28 [00:04<00:01,  7.84it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.89it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.92it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.94it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.97it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.00it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  5.05it/s]=> result
* total: 2,800
* correct: 2,508
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 89.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/20] time 0.223 (0.264) data 0.000 (0.043) loss 0.2358 (0.0894) lr 2.0611e-03 eta 0:00:47
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.73s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:13,  1.87it/s] 14%|█▍        | 4/28 [00:02<00:08,  2.68it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.52it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.36it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.13it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.75it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.28it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.73it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.07it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.32it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.66it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.76it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.83it/s] 61%|██████    | 17/28 [00:03<00:01,  7.88it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.92it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.94it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.97it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.98it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.99it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.18it/s]=> result
* total: 2,800
* correct: 2,486
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 88.7%

epoch [22/30] batch [20/20] time 0.216 (0.265) data 0.000 (0.043) loss -0.2292 (0.2065) lr 1.6543e-03 eta 0:00:42
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:44,  1.63s/it]  7%|▋         | 2/28 [00:01<00:21,  1.22it/s] 11%|█         | 3/28 [00:02<00:13,  1.83it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.63it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.47it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.30it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.06it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.74it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.29it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.74it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.08it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.34it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.53it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.77it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:03<00:01,  7.89it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.92it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.95it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.00it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  5.21it/s]=> result
* total: 2,800
* correct: 2,462
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 87.9%

epoch [23/30] batch [20/20] time 0.218 (0.261) data 0.000 (0.042) loss 0.3579 (-0.0275) lr 1.2843e-03 eta 0:00:36
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.71s/it]  7%|▋         | 2/28 [00:01<00:22,  1.18it/s] 11%|█         | 3/28 [00:02<00:13,  1.91it/s] 14%|█▍        | 4/28 [00:02<00:08,  2.73it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.58it/s] 21%|██▏       | 6/28 [00:02<00:04,  4.41it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.17it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.83it/s] 32%|███▏      | 9/28 [00:02<00:02,  6.38it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.81it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.15it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.40it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.59it/s] 50%|█████     | 14/28 [00:03<00:01,  7.72it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.81it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.88it/s] 61%|██████    | 17/28 [00:03<00:01,  7.93it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.97it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.02it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.22it/s]=> result
* total: 2,800
* correct: 2,504
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 89.5%

epoch [24/30] batch [20/20] time 0.216 (0.261) data 0.000 (0.042) loss -0.4126 (0.2066) lr 9.5492e-04 eta 0:00:31
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.75s/it]  7%|▋         | 2/28 [00:01<00:22,  1.16it/s] 11%|█         | 3/28 [00:02<00:14,  1.73it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.51it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.33it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.15it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.93it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.61it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.18it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.64it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.95it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.23it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.44it/s] 50%|█████     | 14/28 [00:03<00:01,  7.60it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.71it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.79it/s] 61%|██████    | 17/28 [00:03<00:01,  7.85it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.90it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.92it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.93it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.95it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.97it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.97it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.98it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.98it/s] 93%|█████████▎| 26/28 [00:05<00:00,  7.98it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.99it/s]100%|██████████| 28/28 [00:05<00:00,  7.99it/s]100%|██████████| 28/28 [00:05<00:00,  5.07it/s]=> result
* total: 2,800
* correct: 2,481
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 88.6%

epoch [25/30] batch [20/20] time 0.218 (0.267) data 0.000 (0.043) loss -0.2761 (-0.1139) lr 6.6987e-04 eta 0:00:26
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.71s/it]  7%|▋         | 2/28 [00:01<00:22,  1.18it/s] 11%|█         | 3/28 [00:02<00:14,  1.74it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.51it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.34it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.16it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.94it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.63it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.20it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.66it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.03it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.30it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.49it/s] 50%|█████     | 14/28 [00:03<00:01,  7.63it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.75it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.82it/s] 61%|██████    | 17/28 [00:03<00:01,  7.87it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.90it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.88it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.90it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.92it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.95it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.96it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.97it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.98it/s] 93%|█████████▎| 26/28 [00:05<00:00,  7.99it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.99it/s]100%|██████████| 28/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  5.09it/s]=> result
* total: 2,800
* correct: 2,483
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 88.7%

epoch [26/30] batch [20/20] time 0.220 (0.263) data 0.000 (0.042) loss 1.2109 (-0.0370) lr 4.3227e-04 eta 0:00:21
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.71s/it]  7%|▋         | 2/28 [00:01<00:20,  1.24it/s] 11%|█         | 3/28 [00:02<00:13,  1.83it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.63it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.47it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.30it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.06it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.73it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.30it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.75it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.10it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.37it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.57it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.92it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.95it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.97it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.00it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  5.18it/s]=> result
* total: 2,800
* correct: 2,513
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 89.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [27/30] batch [20/20] time 0.217 (0.262) data 0.000 (0.043) loss -0.4590 (-0.2197) lr 2.4472e-04 eta 0:00:15
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.79s/it]  7%|▋         | 2/28 [00:02<00:22,  1.13it/s] 11%|█         | 3/28 [00:02<00:13,  1.80it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.60it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.44it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.27it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.04it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.72it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.29it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.75it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.35it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.54it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.88it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  5.12it/s]=> result
* total: 2,800
* correct: 2,519
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [28/30] batch [20/20] time 0.217 (0.261) data 0.000 (0.042) loss -0.2773 (-0.1294) lr 1.0926e-04 eta 0:00:10
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:50,  1.87s/it]  7%|▋         | 2/28 [00:02<00:23,  1.09it/s] 11%|█         | 3/28 [00:02<00:13,  1.80it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.59it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.43it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.26it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.02it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.70it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.27it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.73it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.08it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.34it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.53it/s] 50%|█████     | 14/28 [00:03<00:01,  7.68it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.00it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.02it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.08it/s]=> result
* total: 2,800
* correct: 2,519
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%

epoch [29/30] batch [20/20] time 0.215 (0.261) data 0.000 (0.043) loss 0.0337 (-0.1698) lr 2.7391e-05 eta 0:00:05
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.77s/it]  7%|▋         | 2/28 [00:02<00:22,  1.15it/s] 11%|█         | 3/28 [00:02<00:13,  1.79it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.59it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.42it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.25it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.03it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.71it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.28it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.74it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.35it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.02it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.04it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.04it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.05it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  5.13it/s]=> result
* total: 2,800
* correct: 2,520
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [30/30] batch [20/20] time 0.217 (0.267) data 0.000 (0.043) loss 0.2314 (-0.1561) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.74s/it]  7%|▋         | 2/28 [00:01<00:22,  1.16it/s] 11%|█         | 3/28 [00:02<00:13,  1.84it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.64it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.48it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.31it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.08it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.76it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.32it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.77it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.11it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.38it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.58it/s] 50%|█████     | 14/28 [00:03<00:01,  7.71it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.02it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.03it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.04it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.05it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  5.15it/s]
=> result
* total: 2,800
* correct: 2,520
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 29)
Evaluate on the *test* set
  0%|          | 0/42 [00:00<?, ?it/s]  2%|▏         | 1/42 [00:02<01:22,  2.01s/it]  5%|▍         | 2/42 [00:02<00:40,  1.02s/it]  7%|▋         | 3/42 [00:02<00:24,  1.57it/s] 10%|▉         | 4/42 [00:02<00:18,  2.08it/s] 12%|█▏        | 5/42 [00:02<00:13,  2.74it/s] 14%|█▍        | 6/42 [00:03<00:10,  3.44it/s] 17%|█▋        | 7/42 [00:03<00:08,  3.95it/s] 19%|█▉        | 8/42 [00:03<00:07,  4.51it/s] 21%|██▏       | 9/42 [00:03<00:06,  4.88it/s] 24%|██▍       | 10/42 [00:03<00:06,  4.71it/s] 26%|██▌       | 11/42 [00:03<00:06,  5.04it/s] 29%|██▊       | 12/42 [00:04<00:05,  5.68it/s] 31%|███       | 13/42 [00:04<00:04,  6.24it/s] 33%|███▎      | 14/42 [00:04<00:04,  6.69it/s] 36%|███▌      | 15/42 [00:04<00:03,  7.05it/s] 38%|███▊      | 16/42 [00:04<00:03,  7.32it/s] 40%|████      | 17/42 [00:04<00:03,  7.48it/s] 43%|████▎     | 18/42 [00:04<00:03,  7.64it/s] 45%|████▌     | 19/42 [00:04<00:02,  7.75it/s] 48%|████▊     | 20/42 [00:05<00:02,  7.84it/s] 50%|█████     | 21/42 [00:05<00:02,  7.89it/s] 52%|█████▏    | 22/42 [00:05<00:02,  7.94it/s] 55%|█████▍    | 23/42 [00:05<00:02,  7.97it/s] 57%|█████▋    | 24/42 [00:05<00:02,  7.99it/s] 60%|█████▉    | 25/42 [00:05<00:02,  8.00it/s] 62%|██████▏   | 26/42 [00:05<00:01,  8.01it/s] 64%|██████▍   | 27/42 [00:05<00:01,  8.03it/s] 67%|██████▋   | 28/42 [00:06<00:01,  8.03it/s] 69%|██████▉   | 29/42 [00:06<00:01,  8.03it/s] 71%|███████▏  | 30/42 [00:06<00:01,  8.02it/s] 74%|███████▍  | 31/42 [00:06<00:01,  8.03it/s] 76%|███████▌  | 32/42 [00:06<00:01,  8.03it/s] 79%|███████▊  | 33/42 [00:06<00:01,  8.04it/s] 81%|████████  | 34/42 [00:06<00:00,  8.04it/s] 83%|████████▎ | 35/42 [00:06<00:00,  8.04it/s] 86%|████████▌ | 36/42 [00:07<00:00,  8.03it/s] 88%|████████▊ | 37/42 [00:07<00:00,  8.03it/s] 90%|█████████ | 38/42 [00:07<00:00,  8.02it/s] 93%|█████████▎| 39/42 [00:07<00:00,  8.02it/s] 95%|█████████▌| 40/42 [00:07<00:00,  8.03it/s] 98%|█████████▊| 41/42 [00:07<00:00,  8.04it/s]100%|██████████| 42/42 [00:07<00:00,  7.97it/s]100%|██████████| 42/42 [00:07<00:00,  5.27it/s]
=> result
* total: 4,200
* correct: 3,789
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.1%
Elapsed: 0:05:40
+ sh scripts/rpo_prime/base2new_test_sdl.sh eurosat 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
80 2600 3900
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  5
# train_x  80
# val      2,600
# test     3,900
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 29)
Evaluate on the *test* set
  0%|          | 0/39 [00:00<?, ?it/s]  3%|▎         | 1/39 [00:04<02:49,  4.47s/it]  5%|▌         | 2/39 [00:04<01:10,  1.92s/it]  8%|▊         | 3/39 [00:04<00:41,  1.15s/it] 10%|█         | 4/39 [00:05<00:26,  1.30it/s] 13%|█▎        | 5/39 [00:05<00:19,  1.75it/s] 15%|█▌        | 6/39 [00:05<00:13,  2.37it/s] 18%|█▊        | 7/39 [00:05<00:10,  2.91it/s] 21%|██        | 8/39 [00:05<00:09,  3.35it/s] 23%|██▎       | 9/39 [00:05<00:07,  4.10it/s] 26%|██▌       | 10/39 [00:06<00:06,  4.83it/s] 28%|██▊       | 11/39 [00:06<00:05,  5.49it/s] 31%|███       | 12/39 [00:06<00:04,  6.07it/s] 33%|███▎      | 13/39 [00:06<00:03,  6.55it/s] 36%|███▌      | 14/39 [00:06<00:03,  6.93it/s] 38%|███▊      | 15/39 [00:06<00:03,  7.22it/s] 41%|████      | 16/39 [00:06<00:03,  7.44it/s] 44%|████▎     | 17/39 [00:06<00:02,  7.60it/s] 46%|████▌     | 18/39 [00:07<00:02,  7.72it/s] 49%|████▊     | 19/39 [00:07<00:02,  7.80it/s] 51%|█████▏    | 20/39 [00:07<00:02,  7.86it/s] 54%|█████▍    | 21/39 [00:07<00:02,  7.90it/s] 56%|█████▋    | 22/39 [00:07<00:02,  7.93it/s] 59%|█████▉    | 23/39 [00:07<00:02,  7.94it/s] 62%|██████▏   | 24/39 [00:07<00:01,  7.90it/s] 64%|██████▍   | 25/39 [00:07<00:01,  7.92it/s] 67%|██████▋   | 26/39 [00:08<00:01,  7.94it/s] 69%|██████▉   | 27/39 [00:08<00:01,  7.96it/s] 72%|███████▏  | 28/39 [00:08<00:01,  7.97it/s] 74%|███████▍  | 29/39 [00:08<00:01,  7.98it/s] 77%|███████▋  | 30/39 [00:08<00:01,  7.98it/s] 79%|███████▉  | 31/39 [00:08<00:01,  7.98it/s] 82%|████████▏ | 32/39 [00:08<00:00,  7.99it/s] 85%|████████▍ | 33/39 [00:08<00:00,  7.99it/s] 87%|████████▋ | 34/39 [00:09<00:00,  7.99it/s] 90%|████████▉ | 35/39 [00:09<00:00,  8.00it/s] 92%|█████████▏| 36/39 [00:09<00:00,  8.00it/s] 95%|█████████▍| 37/39 [00:09<00:00,  8.00it/s] 97%|█████████▋| 38/39 [00:09<00:00,  7.99it/s]100%|██████████| 39/39 [00:09<00:00,  7.98it/s]100%|██████████| 39/39 [00:09<00:00,  4.01it/s]
=> result
* total: 3,900
* correct: 2,922
* accuracy: 74.9%
* error: 25.1%
* macro_f1: 72.2%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh eurosat 2 0 main_tmp1_0.1sdl 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
80 2800 4200
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  5
# train_x  80
# val      2,800
# test     4,200
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/20] time 0.223 (0.357) data 0.000 (0.048) loss 2.2480 (2.4268) lr 9.9726e-03 eta 0:03:26
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:49,  1.85s/it]  7%|▋         | 2/28 [00:02<00:25,  1.02it/s] 11%|█         | 3/28 [00:02<00:17,  1.43it/s] 14%|█▍        | 4/28 [00:02<00:11,  2.04it/s] 18%|█▊        | 5/28 [00:02<00:08,  2.79it/s] 21%|██▏       | 6/28 [00:03<00:06,  3.59it/s] 25%|██▌       | 7/28 [00:03<00:04,  4.38it/s] 29%|██▊       | 8/28 [00:03<00:03,  5.12it/s] 32%|███▏      | 9/28 [00:03<00:03,  5.78it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.34it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.77it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.11it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.37it/s] 50%|█████     | 14/28 [00:04<00:01,  7.57it/s] 54%|█████▎    | 15/28 [00:04<00:01,  7.70it/s] 57%|█████▋    | 16/28 [00:04<00:01,  7.80it/s] 61%|██████    | 17/28 [00:04<00:01,  7.86it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.92it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.96it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.98it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.99it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:05<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:05<00:00,  7.97it/s] 89%|████████▉ | 25/28 [00:05<00:00,  7.97it/s] 93%|█████████▎| 26/28 [00:05<00:00,  7.99it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  4.73it/s]=> result
* total: 2,800
* correct: 1,798
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 63.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/20] time 0.220 (0.265) data 0.000 (0.040) loss 1.6035 (2.0840) lr 9.8907e-03 eta 0:02:28
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:51,  1.89s/it]  7%|▋         | 2/28 [00:02<00:24,  1.08it/s] 11%|█         | 3/28 [00:02<00:14,  1.78it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.57it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.41it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.24it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.02it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.68it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.24it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.70it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.06it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.32it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:04<00:01,  7.89it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.98it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.99it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.00it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.03it/s]=> result
* total: 2,800
* correct: 1,794
* accuracy: 64.1%
* error: 35.9%
* macro_f1: 59.8%

epoch [3/30] batch [20/20] time 0.222 (0.262) data 0.000 (0.040) loss 1.8760 (1.7819) lr 9.7553e-03 eta 0:02:21
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.71s/it]  7%|▋         | 2/28 [00:01<00:22,  1.14it/s] 11%|█         | 3/28 [00:02<00:14,  1.76it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.55it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.38it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.20it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.98it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.66it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.24it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.69it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.05it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.32it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.66it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.69it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.78it/s] 61%|██████    | 17/28 [00:03<00:01,  7.84it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.90it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.93it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.95it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.96it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.99it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.12it/s]=> result
* total: 2,800
* correct: 1,887
* accuracy: 67.4%
* error: 32.6%
* macro_f1: 64.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/20] time 0.223 (0.268) data 0.000 (0.041) loss 2.0215 (1.6935) lr 9.5677e-03 eta 0:02:19
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:45,  1.67s/it]  7%|▋         | 2/28 [00:01<00:21,  1.21it/s] 11%|█         | 3/28 [00:02<00:13,  1.79it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.54it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.38it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.20it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.98it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.67it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.24it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.70it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.06it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.26it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.48it/s] 50%|█████     | 14/28 [00:03<00:01,  7.64it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.76it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:03<00:01,  7.89it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.96it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.98it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.00it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.00it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.02it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.16it/s]=> result
* total: 2,800
* correct: 2,018
* accuracy: 72.1%
* error: 27.9%
* macro_f1: 72.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/20] time 0.223 (0.262) data 0.000 (0.039) loss 1.9854 (1.6484) lr 9.3301e-03 eta 0:02:11
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:49,  1.83s/it]  7%|▋         | 2/28 [00:02<00:23,  1.12it/s] 11%|█         | 3/28 [00:02<00:13,  1.80it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.60it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.43it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.27it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.04it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.72it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.28it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.74it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.10it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.81it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.98it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.10it/s]=> result
* total: 2,800
* correct: 2,056
* accuracy: 73.4%
* error: 26.6%
* macro_f1: 73.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/20] time 0.217 (0.261) data 0.000 (0.040) loss 1.4873 (1.4147) lr 9.0451e-03 eta 0:02:05
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.77s/it]  7%|▋         | 2/28 [00:02<00:22,  1.14it/s] 11%|█         | 3/28 [00:02<00:14,  1.71it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.46it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.28it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.11it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.89it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.58it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.17it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.64it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.01it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.29it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.50it/s] 50%|█████     | 14/28 [00:03<00:01,  7.64it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.75it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:04<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.96it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.01it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  5.06it/s]=> result
* total: 2,800
* correct: 2,138
* accuracy: 76.4%
* error: 23.6%
* macro_f1: 76.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/20] time 0.221 (0.262) data 0.000 (0.039) loss 0.9702 (1.1870) lr 8.7157e-03 eta 0:02:00
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.74s/it]  7%|▋         | 2/28 [00:01<00:20,  1.26it/s] 11%|█         | 3/28 [00:02<00:13,  1.86it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.61it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.45it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.28it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.06it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.74it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.30it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.75it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.10it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.77it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.83it/s] 61%|██████    | 17/28 [00:03<00:01,  7.89it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.92it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.94it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.00it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.00it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.02it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.20it/s]=> result
* total: 2,800
* correct: 2,255
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 80.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/20] time 0.219 (0.262) data 0.000 (0.040) loss 0.4844 (1.2185) lr 8.3457e-03 eta 0:01:55
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:02<00:55,  2.04s/it]  7%|▋         | 2/28 [00:02<00:25,  1.01it/s] 11%|█         | 3/28 [00:02<00:15,  1.65it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.41it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.22it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.04it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.82it/s] 29%|██▊       | 8/28 [00:03<00:03,  5.52it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.11it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.60it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.98it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.27it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.47it/s] 50%|█████     | 14/28 [00:03<00:01,  7.63it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.74it/s] 57%|█████▋    | 16/28 [00:04<00:01,  7.81it/s] 61%|██████    | 17/28 [00:04<00:01,  7.86it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.91it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.94it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.97it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:05<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:05<00:00,  7.99it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  4.90it/s]=> result
* total: 2,800
* correct: 2,270
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 81.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/20] time 0.219 (0.265) data 0.000 (0.039) loss 0.9663 (0.9724) lr 7.9389e-03 eta 0:01:51
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.77s/it]  7%|▋         | 2/28 [00:02<00:22,  1.15it/s] 11%|█         | 3/28 [00:02<00:14,  1.78it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.57it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.40it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.23it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.00it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.68it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.26it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.72it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.07it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.33it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.53it/s] 50%|█████     | 14/28 [00:03<00:01,  7.68it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.97it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.00it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  5.11it/s]=> result
* total: 2,800
* correct: 2,393
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 85.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/20] time 0.221 (0.262) data 0.000 (0.040) loss 1.3105 (0.8152) lr 7.5000e-03 eta 0:01:44
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.72s/it]  7%|▋         | 2/28 [00:01<00:21,  1.19it/s] 11%|█         | 3/28 [00:02<00:13,  1.79it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.58it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.42it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.24it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.02it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.69it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.26it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.71it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.06it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.32it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.77it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.83it/s] 61%|██████    | 17/28 [00:03<00:01,  7.88it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.95it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.97it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.00it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.01it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.13it/s]=> result
* total: 2,800
* correct: 2,178
* accuracy: 77.8%
* error: 22.2%
* macro_f1: 76.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/20] time 0.220 (0.261) data 0.000 (0.040) loss 0.2485 (0.6774) lr 7.0337e-03 eta 0:01:39
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.73s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:14,  1.75it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.53it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.36it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.19it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.96it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.65it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.22it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.68it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.03it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.30it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.50it/s] 50%|█████     | 14/28 [00:03<00:01,  7.64it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.75it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.83it/s] 61%|██████    | 17/28 [00:03<00:01,  7.88it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.92it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.95it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.97it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.00it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.01it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.99it/s]100%|██████████| 28/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  5.10it/s]=> result
* total: 2,800
* correct: 2,384
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 85.3%

epoch [12/30] batch [20/20] time 0.221 (0.265) data 0.000 (0.040) loss -0.0430 (1.1946) lr 6.5451e-03 eta 0:01:35
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.81s/it]  7%|▋         | 2/28 [00:02<00:22,  1.13it/s] 11%|█         | 3/28 [00:02<00:14,  1.78it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.57it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.40it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.23it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.01it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.70it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.27it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.73it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.08it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.35it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.54it/s] 50%|█████     | 14/28 [00:03<00:01,  7.68it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.77it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:03<00:01,  7.89it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.92it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.95it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.97it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.97it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.01it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  5.08it/s]=> result
* total: 2,800
* correct: 2,287
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 81.7%

epoch [13/30] batch [20/20] time 0.222 (0.263) data 0.000 (0.042) loss 0.5869 (0.7439) lr 6.0396e-03 eta 0:01:29
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:50,  1.86s/it]  7%|▋         | 2/28 [00:02<00:23,  1.10it/s] 11%|█         | 3/28 [00:02<00:13,  1.80it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.59it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.43it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.26it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.03it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.71it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.27it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.73it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.08it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.34it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.53it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.08it/s]=> result
* total: 2,800
* correct: 2,472
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 88.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [14/30] batch [20/20] time 0.218 (0.260) data 0.000 (0.039) loss -0.0234 (0.7137) lr 5.5226e-03 eta 0:01:23
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.77s/it]  7%|▋         | 2/28 [00:02<00:22,  1.15it/s] 11%|█         | 3/28 [00:02<00:14,  1.76it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.54it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.37it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.20it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.98it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.66it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.24it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.70it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.06it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.33it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.53it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.77it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:03<00:01,  7.89it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.80it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.86it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.91it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.93it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.96it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.99it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  5.09it/s]=> result
* total: 2,800
* correct: 2,451
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.6%

epoch [15/30] batch [20/20] time 0.220 (0.262) data 0.000 (0.040) loss 0.2192 (0.6260) lr 5.0000e-03 eta 0:01:18
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.78s/it]  7%|▋         | 2/28 [00:02<00:22,  1.14it/s] 11%|█         | 3/28 [00:02<00:14,  1.72it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.44it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.26it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.08it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.86it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.55it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.14it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.62it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.99it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.28it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.48it/s] 50%|█████     | 14/28 [00:03<00:01,  7.64it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.76it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.82it/s] 61%|██████    | 17/28 [00:04<00:01,  7.88it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.91it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.94it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.97it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.00it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.00it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.03it/s]=> result
* total: 2,800
* correct: 2,519
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [16/30] batch [20/20] time 0.220 (0.262) data 0.000 (0.040) loss 0.3086 (0.5784) lr 4.4774e-03 eta 0:01:13
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.73s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:13,  1.81it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.60it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.44it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.26it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.03it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.71it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.27it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.73it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.07it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.33it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.53it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.77it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:03<00:01,  7.88it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.86it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.90it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.94it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.00it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.13it/s]=> result
* total: 2,800
* correct: 2,309
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 82.1%

epoch [17/30] batch [20/20] time 0.218 (0.266) data 0.000 (0.040) loss 0.3804 (0.7175) lr 3.9604e-03 eta 0:01:09
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:49,  1.85s/it]  7%|▋         | 2/28 [00:02<00:23,  1.11it/s] 11%|█         | 3/28 [00:02<00:13,  1.83it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.63it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.47it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.30it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.07it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.74it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.30it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.76it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.11it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.37it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.96it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.98it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.99it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.00it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.01it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.68it/s] 93%|█████████▎| 26/28 [00:05<00:00,  7.78it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.84it/s]100%|██████████| 28/28 [00:05<00:00,  7.91it/s]100%|██████████| 28/28 [00:05<00:00,  5.10it/s]=> result
* total: 2,800
* correct: 2,533
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 90.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/20] time 0.219 (0.260) data 0.000 (0.040) loss 0.0000 (0.3559) lr 3.4549e-03 eta 0:01:02
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:49,  1.82s/it]  7%|▋         | 2/28 [00:02<00:23,  1.11it/s] 11%|█         | 3/28 [00:02<00:13,  1.83it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.64it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.48it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.30it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.07it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.74it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.30it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.75it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.35it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.68it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.95it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.97it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.99it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.00it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  7.91it/s]100%|██████████| 28/28 [00:05<00:00,  5.11it/s]=> result
* total: 2,800
* correct: 2,483
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 88.8%

epoch [19/30] batch [20/20] time 0.220 (0.261) data 0.000 (0.040) loss 0.7056 (0.4351) lr 2.9663e-03 eta 0:00:57
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.75s/it]  7%|▋         | 2/28 [00:01<00:21,  1.22it/s] 11%|█         | 3/28 [00:02<00:13,  1.81it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.56it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.40it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.22it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.00it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.68it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.25it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.70it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.06it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.32it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.66it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.76it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.95it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.97it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.00it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.12it/s]=> result
* total: 2,800
* correct: 2,532
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 90.4%

epoch [20/30] batch [20/20] time 0.219 (0.265) data 0.000 (0.040) loss 0.2285 (0.2400) lr 2.5000e-03 eta 0:00:53
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:43,  1.61s/it]  7%|▋         | 2/28 [00:01<00:21,  1.21it/s] 11%|█         | 3/28 [00:02<00:14,  1.78it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.53it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.36it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.19it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.97it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.65it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.23it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.70it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.06it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.32it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.51it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.17it/s]=> result
* total: 2,800
* correct: 2,541
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/20] time 0.219 (0.261) data 0.000 (0.040) loss 0.0688 (0.1880) lr 2.0611e-03 eta 0:00:46
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.74s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:14,  1.75it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.53it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.36it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.19it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.96it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.65it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.23it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.68it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.04it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.31it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.65it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.76it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.82it/s] 61%|██████    | 17/28 [00:03<00:01,  7.88it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.91it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.94it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.01it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  5.11it/s]=> result
* total: 2,800
* correct: 2,575
* accuracy: 92.0%
* error: 8.0%
* macro_f1: 91.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [22/30] batch [20/20] time 0.218 (0.261) data 0.000 (0.039) loss 0.0757 (0.1788) lr 1.6543e-03 eta 0:00:41
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.80s/it]  7%|▋         | 2/28 [00:02<00:22,  1.13it/s] 11%|█         | 3/28 [00:02<00:13,  1.80it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.60it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.43it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.26it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.04it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.71it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.27it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.72it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.07it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.22it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.46it/s] 50%|█████     | 14/28 [00:03<00:01,  7.62it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.74it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.82it/s] 61%|██████    | 17/28 [00:03<00:01,  7.88it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.92it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.94it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.95it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.97it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.98it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.98it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.98it/s] 93%|█████████▎| 26/28 [00:05<00:00,  7.99it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.98it/s]100%|██████████| 28/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  5.09it/s]=> result
* total: 2,800
* correct: 2,520
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.1%

epoch [23/30] batch [20/20] time 0.220 (0.262) data 0.000 (0.041) loss 0.0742 (0.3188) lr 1.2843e-03 eta 0:00:36
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.77s/it]  7%|▋         | 2/28 [00:02<00:22,  1.15it/s] 11%|█         | 3/28 [00:02<00:14,  1.78it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.58it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.41it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.24it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.01it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.70it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.26it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.72it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.08it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.35it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.54it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:03<00:01,  7.91it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.12it/s]=> result
* total: 2,800
* correct: 2,554
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 91.3%

epoch [24/30] batch [20/20] time 0.219 (0.259) data 0.000 (0.040) loss 0.3638 (0.2187) lr 9.5492e-04 eta 0:00:31
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.78s/it]  7%|▋         | 2/28 [00:02<00:22,  1.14it/s] 11%|█         | 3/28 [00:02<00:13,  1.80it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.59it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.43it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.26it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.03it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.71it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.27it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.73it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.07it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.33it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.11it/s]=> result
* total: 2,800
* correct: 2,561
* accuracy: 91.5%
* error: 8.5%
* macro_f1: 91.5%

epoch [25/30] batch [20/20] time 0.217 (0.264) data 0.000 (0.041) loss 0.1084 (0.1907) lr 6.6987e-04 eta 0:00:26
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.80s/it]  7%|▋         | 2/28 [00:02<00:23,  1.13it/s] 11%|█         | 3/28 [00:02<00:14,  1.70it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.43it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.25it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.07it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.85it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.54it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.13it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.61it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.98it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.27it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.47it/s] 50%|█████     | 14/28 [00:03<00:01,  7.63it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.73it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.81it/s] 61%|██████    | 17/28 [00:04<00:01,  7.87it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.92it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.94it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.97it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.00it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.00it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:05<00:00,  7.98it/s] 93%|█████████▎| 26/28 [00:05<00:00,  7.99it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.99it/s]100%|██████████| 28/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  5.01it/s]=> result
* total: 2,800
* correct: 2,568
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 91.7%

epoch [26/30] batch [20/20] time 0.221 (0.263) data 0.000 (0.040) loss 0.6543 (0.3690) lr 4.3227e-04 eta 0:00:21
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.74s/it]  7%|▋         | 2/28 [00:01<00:22,  1.16it/s] 11%|█         | 3/28 [00:02<00:14,  1.74it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.50it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.33it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.15it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.93it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.62it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.19it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.66it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.02it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.31it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.51it/s] 50%|█████     | 14/28 [00:03<00:01,  7.65it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.76it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:03<00:01,  7.88it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.95it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.97it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.98it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.98it/s] 86%|████████▌ | 24/28 [00:04<00:00,  7.99it/s] 89%|████████▉ | 25/28 [00:04<00:00,  7.99it/s] 93%|█████████▎| 26/28 [00:05<00:00,  7.99it/s] 96%|█████████▋| 27/28 [00:05<00:00,  7.98it/s]100%|██████████| 28/28 [00:05<00:00,  7.99it/s]100%|██████████| 28/28 [00:05<00:00,  5.07it/s]=> result
* total: 2,800
* correct: 2,569
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 91.7%

epoch [27/30] batch [20/20] time 0.219 (0.262) data 0.000 (0.040) loss 0.0942 (0.3163) lr 2.4472e-04 eta 0:00:15
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.73s/it]  7%|▋         | 2/28 [00:01<00:22,  1.16it/s] 11%|█         | 3/28 [00:02<00:14,  1.76it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.55it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.38it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.20it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.98it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.66it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.17it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.65it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.01it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.31it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.68it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.88it/s] 61%|██████    | 17/28 [00:03<00:01,  7.93it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.00it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.00it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.01it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.00it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.10it/s]=> result
* total: 2,800
* correct: 2,553
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 91.2%

epoch [28/30] batch [20/20] time 0.224 (0.265) data 0.000 (0.041) loss -0.3264 (0.0633) lr 1.0926e-04 eta 0:00:10
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.73s/it]  7%|▋         | 2/28 [00:01<00:21,  1.20it/s] 11%|█         | 3/28 [00:02<00:13,  1.79it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.54it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.37it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.20it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.96it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.64it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.22it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.69it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.04it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.31it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.51it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.95it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.96it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.97it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.00it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.01it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.11it/s]=> result
* total: 2,800
* correct: 2,554
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 91.2%

epoch [29/30] batch [20/20] time 0.218 (0.261) data 0.000 (0.041) loss -0.2451 (0.0281) lr 2.7391e-05 eta 0:00:05
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:52,  1.94s/it]  7%|▋         | 2/28 [00:02<00:24,  1.06it/s] 11%|█         | 3/28 [00:02<00:14,  1.72it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.50it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.32it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.15it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.93it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.62it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.21it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.68it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.04it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.31it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:04<00:01,  7.91it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  4.99it/s]=> result
* total: 2,800
* correct: 2,552
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 91.2%

epoch [30/30] batch [20/20] time 0.219 (0.263) data 0.000 (0.041) loss 0.4023 (0.1730) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:49,  1.84s/it]  7%|▋         | 2/28 [00:02<00:23,  1.11it/s] 11%|█         | 3/28 [00:02<00:13,  1.81it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.61it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.45it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.28it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.99it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.67it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.24it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.70it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.06it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.33it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.53it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:03<00:01,  7.89it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.96it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.98it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.98it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.01it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.01it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.10it/s]
=> result
* total: 2,800
* correct: 2,552
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 91.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 21)
Evaluate on the *test* set
  0%|          | 0/42 [00:00<?, ?it/s]  2%|▏         | 1/42 [00:02<01:22,  2.02s/it]  5%|▍         | 2/42 [00:02<00:40,  1.02s/it]  7%|▋         | 3/42 [00:02<00:26,  1.50it/s] 10%|▉         | 4/42 [00:02<00:17,  2.19it/s] 12%|█▏        | 5/42 [00:02<00:12,  2.94it/s] 14%|█▍        | 6/42 [00:03<00:10,  3.49it/s] 17%|█▋        | 7/42 [00:03<00:08,  3.89it/s] 19%|█▉        | 8/42 [00:03<00:07,  4.39it/s] 21%|██▏       | 9/42 [00:03<00:06,  4.96it/s] 24%|██▍       | 10/42 [00:03<00:05,  5.45it/s] 26%|██▌       | 11/42 [00:03<00:05,  5.69it/s] 29%|██▊       | 12/42 [00:03<00:04,  6.25it/s] 31%|███       | 13/42 [00:04<00:04,  6.71it/s] 33%|███▎      | 14/42 [00:04<00:03,  7.07it/s] 36%|███▌      | 15/42 [00:04<00:03,  7.34it/s] 38%|███▊      | 16/42 [00:04<00:03,  7.54it/s] 40%|████      | 17/42 [00:04<00:03,  7.69it/s] 43%|████▎     | 18/42 [00:04<00:03,  7.79it/s] 45%|████▌     | 19/42 [00:04<00:02,  7.87it/s] 48%|████▊     | 20/42 [00:04<00:02,  7.88it/s] 50%|█████     | 21/42 [00:05<00:02,  7.92it/s] 52%|█████▏    | 22/42 [00:05<00:02,  7.95it/s] 55%|█████▍    | 23/42 [00:05<00:02,  7.98it/s] 57%|█████▋    | 24/42 [00:05<00:02,  8.00it/s] 60%|█████▉    | 25/42 [00:05<00:02,  8.00it/s] 62%|██████▏   | 26/42 [00:05<00:01,  8.02it/s] 64%|██████▍   | 27/42 [00:05<00:01,  8.02it/s] 67%|██████▋   | 28/42 [00:05<00:01,  8.03it/s] 69%|██████▉   | 29/42 [00:06<00:01,  8.03it/s] 71%|███████▏  | 30/42 [00:06<00:01,  8.04it/s] 74%|███████▍  | 31/42 [00:06<00:01,  8.04it/s] 76%|███████▌  | 32/42 [00:06<00:01,  8.04it/s] 79%|███████▊  | 33/42 [00:06<00:01,  8.03it/s] 81%|████████  | 34/42 [00:06<00:00,  8.03it/s] 83%|████████▎ | 35/42 [00:06<00:00,  8.04it/s] 86%|████████▌ | 36/42 [00:06<00:00,  8.03it/s] 88%|████████▊ | 37/42 [00:07<00:00,  8.03it/s] 90%|█████████ | 38/42 [00:07<00:00,  8.03it/s] 93%|█████████▎| 39/42 [00:07<00:00,  8.04it/s] 95%|█████████▌| 40/42 [00:07<00:00,  8.05it/s] 98%|█████████▊| 41/42 [00:07<00:00,  8.04it/s]100%|██████████| 42/42 [00:07<00:00,  8.04it/s]100%|██████████| 42/42 [00:07<00:00,  5.35it/s]
=> result
* total: 4,200
* correct: 3,879
* accuracy: 92.4%
* error: 7.6%
* macro_f1: 92.3%
Elapsed: 0:05:37
+ sh scripts/rpo_prime/base2new_test_sdl.sh eurosat 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
80 2600 3900
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  5
# train_x  80
# val      2,600
# test     3,900
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 21)
Evaluate on the *test* set
  0%|          | 0/39 [00:00<?, ?it/s]  3%|▎         | 1/39 [00:04<02:54,  4.59s/it]  5%|▌         | 2/39 [00:04<01:12,  1.97s/it]  8%|▊         | 3/39 [00:04<00:41,  1.15s/it] 10%|█         | 4/39 [00:05<00:26,  1.33it/s] 13%|█▎        | 5/39 [00:05<00:18,  1.86it/s] 15%|█▌        | 6/39 [00:05<00:14,  2.32it/s] 18%|█▊        | 7/39 [00:05<00:10,  2.97it/s] 21%|██        | 8/39 [00:05<00:08,  3.69it/s] 23%|██▎       | 9/39 [00:05<00:06,  4.44it/s] 26%|██▌       | 10/39 [00:05<00:05,  5.15it/s] 28%|██▊       | 11/39 [00:06<00:04,  5.75it/s] 31%|███       | 12/39 [00:06<00:04,  6.29it/s] 33%|███▎      | 13/39 [00:06<00:03,  6.73it/s] 36%|███▌      | 14/39 [00:06<00:03,  7.07it/s] 38%|███▊      | 15/39 [00:06<00:03,  7.34it/s] 41%|████      | 16/39 [00:06<00:03,  7.53it/s] 44%|████▎     | 17/39 [00:06<00:02,  7.67it/s] 46%|████▌     | 18/39 [00:06<00:02,  7.77it/s] 49%|████▊     | 19/39 [00:07<00:02,  7.86it/s] 51%|█████▏    | 20/39 [00:07<00:02,  7.91it/s] 54%|█████▍    | 21/39 [00:07<00:02,  7.95it/s] 56%|█████▋    | 22/39 [00:07<00:02,  7.96it/s] 59%|█████▉    | 23/39 [00:07<00:02,  7.98it/s] 62%|██████▏   | 24/39 [00:07<00:01,  8.00it/s] 64%|██████▍   | 25/39 [00:07<00:01,  8.01it/s] 67%|██████▋   | 26/39 [00:07<00:01,  8.01it/s] 69%|██████▉   | 27/39 [00:08<00:01,  8.01it/s] 72%|███████▏  | 28/39 [00:08<00:01,  8.01it/s] 74%|███████▍  | 29/39 [00:08<00:01,  8.02it/s] 77%|███████▋  | 30/39 [00:08<00:01,  8.01it/s] 79%|███████▉  | 31/39 [00:08<00:00,  8.01it/s] 82%|████████▏ | 32/39 [00:08<00:00,  8.02it/s] 85%|████████▍ | 33/39 [00:08<00:00,  7.89it/s] 87%|████████▋ | 34/39 [00:08<00:00,  7.92it/s] 90%|████████▉ | 35/39 [00:09<00:00,  7.96it/s] 92%|█████████▏| 36/39 [00:09<00:00,  7.98it/s] 95%|█████████▍| 37/39 [00:09<00:00,  8.00it/s] 97%|█████████▋| 38/39 [00:09<00:00,  8.01it/s]100%|██████████| 39/39 [00:09<00:00,  8.01it/s]100%|██████████| 39/39 [00:09<00:00,  4.04it/s]
=> result
* total: 3,900
* correct: 2,485
* accuracy: 63.7%
* error: 36.3%
* macro_f1: 61.3%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh eurosat 3 0 main_tmp1_0.1sdl 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
80 2800 4200
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  5
# train_x  80
# val      2,800
# test     4,200
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/20] time 0.227 (0.359) data 0.000 (0.053) loss 2.2734 (1.9997) lr 9.9726e-03 eta 0:03:28
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:52,  1.94s/it]  7%|▋         | 2/28 [00:02<00:26,  1.01s/it] 11%|█         | 3/28 [00:02<00:18,  1.38it/s] 14%|█▍        | 4/28 [00:02<00:11,  2.02it/s] 18%|█▊        | 5/28 [00:02<00:08,  2.76it/s] 21%|██▏       | 6/28 [00:03<00:06,  3.56it/s] 25%|██▌       | 7/28 [00:03<00:04,  4.35it/s] 29%|██▊       | 8/28 [00:03<00:03,  5.09it/s] 32%|███▏      | 9/28 [00:03<00:03,  5.75it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.30it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.74it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.09it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.36it/s] 50%|█████     | 14/28 [00:04<00:01,  7.54it/s] 54%|█████▎    | 15/28 [00:04<00:01,  7.69it/s] 57%|█████▋    | 16/28 [00:04<00:01,  7.68it/s] 61%|██████    | 17/28 [00:04<00:01,  7.78it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.85it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.92it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.95it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.97it/s] 79%|███████▊  | 22/28 [00:05<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:05<00:00,  8.01it/s] 86%|████████▌ | 24/28 [00:05<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.02it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  4.69it/s]=> result
* total: 2,800
* correct: 1,826
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 63.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/20] time 0.226 (0.261) data 0.000 (0.042) loss 1.5742 (1.9718) lr 9.8907e-03 eta 0:02:26
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:45,  1.67s/it]  7%|▋         | 2/28 [00:01<00:20,  1.30it/s] 11%|█         | 3/28 [00:02<00:13,  1.90it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.44it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.17it/s] 21%|██▏       | 6/28 [00:02<00:05,  3.99it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.78it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.49it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.10it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.56it/s] 39%|███▉      | 11/28 [00:03<00:02,  6.95it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.26it/s] 46%|████▋     | 13/28 [00:03<00:02,  7.48it/s] 50%|█████     | 14/28 [00:03<00:01,  7.63it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.75it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.84it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.96it/s] 71%|███████▏  | 20/28 [00:04<00:01,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.17it/s]=> result
* total: 2,800
* correct: 1,968
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 69.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/20] time 0.217 (0.258) data 0.000 (0.039) loss 3.1504 (1.4963) lr 9.7553e-03 eta 0:02:19
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:42,  1.58s/it]  7%|▋         | 2/28 [00:01<00:20,  1.26it/s] 11%|█         | 3/28 [00:02<00:13,  1.86it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.66it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.51it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.34it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.11it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.79it/s] 32%|███▏      | 9/28 [00:02<00:02,  6.36it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.81it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.15it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.40it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.60it/s] 50%|█████     | 14/28 [00:03<00:01,  7.73it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.81it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.93it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.99it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.98it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  5.26it/s]=> result
* total: 2,800
* correct: 2,068
* accuracy: 73.9%
* error: 26.1%
* macro_f1: 73.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/20] time 0.224 (0.260) data 0.000 (0.040) loss 1.1816 (1.6128) lr 9.5677e-03 eta 0:02:14
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.71s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:13,  1.80it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.60it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.44it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.27it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.05it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.72it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.30it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.75it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.10it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.91it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.16it/s]=> result
* total: 2,800
* correct: 2,096
* accuracy: 74.9%
* error: 25.1%
* macro_f1: 74.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/20] time 0.222 (0.262) data 0.000 (0.039) loss 1.8164 (1.5101) lr 9.3301e-03 eta 0:02:11
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.73s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:13,  1.83it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.62it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.46it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.29it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.07it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.67it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.25it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.72it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.08it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.35it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.88it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.01it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.02it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.03it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.05it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.18it/s]=> result
* total: 2,800
* correct: 1,998
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 69.1%

epoch [6/30] batch [20/20] time 0.217 (0.258) data 0.000 (0.038) loss -0.0569 (1.2300) lr 9.0451e-03 eta 0:02:03
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.80s/it]  7%|▋         | 2/28 [00:02<00:23,  1.10it/s] 11%|█         | 3/28 [00:02<00:13,  1.82it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.62it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.47it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.30it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.07it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.75it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.32it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.77it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.11it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.38it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.57it/s] 50%|█████     | 14/28 [00:03<00:01,  7.72it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.82it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.88it/s] 61%|██████    | 17/28 [00:03<00:01,  7.93it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.98it/s] 68%|██████▊   | 19/28 [00:04<00:01,  8.00it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.95it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.96it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.99it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.01it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  5.12it/s]=> result
* total: 2,800
* correct: 2,110
* accuracy: 75.4%
* error: 24.6%
* macro_f1: 74.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/20] time 0.219 (0.256) data 0.000 (0.038) loss 2.4238 (1.2142) lr 8.7157e-03 eta 0:01:57
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:51,  1.90s/it]  7%|▋         | 2/28 [00:02<00:23,  1.08it/s] 11%|█         | 3/28 [00:02<00:13,  1.79it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.58it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.42it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.25it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.02it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.71it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.28it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.74it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.35it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:04<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.99it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.03it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.04it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.02it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.08it/s]=> result
* total: 2,800
* correct: 2,343
* accuracy: 83.7%
* error: 16.3%
* macro_f1: 83.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/20] time 0.218 (0.257) data 0.000 (0.039) loss 0.4570 (1.0682) lr 8.3457e-03 eta 0:01:52
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.78s/it]  7%|▋         | 2/28 [00:02<00:22,  1.14it/s] 11%|█         | 3/28 [00:02<00:13,  1.81it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.61it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.45it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.28it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.06it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.74it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.30it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.76it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.11it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.37it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.57it/s] 50%|█████     | 14/28 [00:03<00:01,  7.72it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.83it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.90it/s] 61%|██████    | 17/28 [00:03<00:01,  7.95it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.99it/s] 68%|██████▊   | 19/28 [00:04<00:01,  8.03it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.04it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.03it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.04it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.04it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.14it/s]=> result
* total: 2,800
* correct: 2,450
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/20] time 0.218 (0.263) data 0.000 (0.040) loss 0.2893 (0.8457) lr 7.9389e-03 eta 0:01:50
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:45,  1.68s/it]  7%|▋         | 2/28 [00:01<00:21,  1.20it/s] 11%|█         | 3/28 [00:02<00:13,  1.85it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.60it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.43it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.26it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.03it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.71it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.28it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.74it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.35it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.98it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.19it/s]=> result
* total: 2,800
* correct: 2,444
* accuracy: 87.3%
* error: 12.7%
* macro_f1: 87.1%

epoch [10/30] batch [20/20] time 0.215 (0.257) data 0.000 (0.039) loss 0.4727 (0.7086) lr 7.5000e-03 eta 0:01:42
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:45,  1.68s/it]  7%|▋         | 2/28 [00:01<00:21,  1.20it/s] 11%|█         | 3/28 [00:02<00:13,  1.79it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.58it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.41it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.25it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.02it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.70it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.27it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.73it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.02it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.03it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.17it/s]=> result
* total: 2,800
* correct: 2,506
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 89.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/20] time 0.217 (0.257) data 0.000 (0.038) loss 0.0210 (0.5665) lr 7.0337e-03 eta 0:01:37
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.73s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:13,  1.87it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.65it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.50it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.33it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.10it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.77it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.33it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.77it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.12it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.37it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.54it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.68it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.79it/s] 61%|██████    | 17/28 [00:03<00:01,  7.86it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.92it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.94it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.97it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.01it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.19it/s]=> result
* total: 2,800
* correct: 2,523
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/20] time 0.216 (0.259) data 0.000 (0.039) loss 0.1616 (0.5413) lr 6.5451e-03 eta 0:01:33
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.80s/it]  7%|▋         | 2/28 [00:02<00:22,  1.14it/s] 11%|█         | 3/28 [00:02<00:14,  1.71it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.46it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.28it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.11it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.90it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.59it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.19it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.66it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.03it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.32it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:04<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.05it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  5.05it/s]=> result
* total: 2,800
* correct: 2,479
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 88.5%

epoch [13/30] batch [20/20] time 0.217 (0.256) data 0.000 (0.038) loss 0.1919 (0.3958) lr 6.0396e-03 eta 0:01:27
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.72s/it]  7%|▋         | 2/28 [00:01<00:20,  1.26it/s] 11%|█         | 3/28 [00:02<00:13,  1.85it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.66it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.50it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.33it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.11it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.77it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.33it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.77it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.12it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.38it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.57it/s] 50%|█████     | 14/28 [00:03<00:01,  7.71it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.01it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.03it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.04it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.05it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.05it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.05it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.06it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.24it/s]=> result
* total: 2,800
* correct: 2,510
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 89.4%

epoch [14/30] batch [20/20] time 0.218 (0.262) data 0.000 (0.038) loss 0.2339 (0.4127) lr 5.5226e-03 eta 0:01:23
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.71s/it]  7%|▋         | 2/28 [00:01<00:22,  1.16it/s] 11%|█         | 3/28 [00:02<00:13,  1.87it/s] 14%|█▍        | 4/28 [00:02<00:08,  2.68it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.51it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.34it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.11it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.79it/s] 32%|███▏      | 9/28 [00:02<00:02,  6.34it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.79it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.13it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.40it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.59it/s] 50%|█████     | 14/28 [00:03<00:01,  7.72it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.82it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.89it/s] 61%|██████    | 17/28 [00:03<00:01,  7.95it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.98it/s] 68%|██████▊   | 19/28 [00:04<00:01,  8.01it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.02it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.03it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.05it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.05it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.05it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.06it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.05it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  5.21it/s]=> result
* total: 2,800
* correct: 2,502
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 89.5%

epoch [15/30] batch [20/20] time 0.217 (0.257) data 0.000 (0.040) loss -0.1790 (0.3744) lr 5.0000e-03 eta 0:01:17
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:44,  1.66s/it]  7%|▋         | 2/28 [00:01<00:21,  1.20it/s] 11%|█         | 3/28 [00:02<00:13,  1.79it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.58it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.41it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.24it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.01it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.69it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.26it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.71it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.06it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.33it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.67it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.96it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.98it/s] 75%|███████▌  | 21/28 [00:04<00:00,  7.96it/s] 79%|███████▊  | 22/28 [00:04<00:00,  7.97it/s] 82%|████████▏ | 23/28 [00:04<00:00,  7.99it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.00it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.00it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.19it/s]=> result
* total: 2,800
* correct: 2,532
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [16/30] batch [20/20] time 0.216 (0.257) data 0.000 (0.038) loss 1.3477 (0.4342) lr 4.4774e-03 eta 0:01:11
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.74s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:14,  1.73it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.47it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.29it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.12it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.90it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.60it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.19it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.67it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.04it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.32it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.54it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.93it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.97it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.99it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.01it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.03it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.04it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.05it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.05it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.05it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.06it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.07it/s]100%|██████████| 28/28 [00:05<00:00,  8.07it/s]100%|██████████| 28/28 [00:05<00:00,  5.10it/s]=> result
* total: 2,800
* correct: 2,524
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.0%

epoch [17/30] batch [20/20] time 0.215 (0.262) data 0.000 (0.039) loss 0.0469 (0.2333) lr 3.9604e-03 eta 0:01:08
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:44,  1.65s/it]  7%|▋         | 2/28 [00:01<00:21,  1.21it/s] 11%|█         | 3/28 [00:02<00:13,  1.91it/s] 14%|█▍        | 4/28 [00:02<00:08,  2.74it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.59it/s] 21%|██▏       | 6/28 [00:02<00:04,  4.43it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.19it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.86it/s] 32%|███▏      | 9/28 [00:02<00:02,  6.41it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.84it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.18it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.42it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.61it/s] 50%|█████     | 14/28 [00:03<00:01,  7.74it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.83it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.89it/s] 61%|██████    | 17/28 [00:03<00:01,  7.93it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.98it/s] 68%|██████▊   | 19/28 [00:04<00:01,  8.01it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.02it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.03it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.04it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.04it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.06it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.05it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.05it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  5.26it/s]=> result
* total: 2,800
* correct: 2,555
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 91.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/20] time 0.218 (0.260) data 0.000 (0.040) loss 0.2876 (0.3272) lr 3.4549e-03 eta 0:01:02
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:50,  1.87s/it]  7%|▋         | 2/28 [00:02<00:23,  1.12it/s] 11%|█         | 3/28 [00:02<00:13,  1.85it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.66it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.50it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.33it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.10it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.77it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.33it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.77it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.12it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.30it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.50it/s] 50%|█████     | 14/28 [00:03<00:01,  7.66it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  5.13it/s]=> result
* total: 2,800
* correct: 2,509
* accuracy: 89.6%
* error: 10.4%
* macro_f1: 89.6%

epoch [19/30] batch [20/20] time 0.218 (0.256) data 0.000 (0.039) loss 0.4731 (0.2866) lr 2.9663e-03 eta 0:00:56
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.78s/it]  7%|▋         | 2/28 [00:02<00:22,  1.15it/s] 11%|█         | 3/28 [00:02<00:13,  1.83it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.64it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.48it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.31it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.08it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.75it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.31it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.76it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.11it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.56it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.93it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.01it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.01it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.02it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.15it/s]=> result
* total: 2,800
* correct: 2,581
* accuracy: 92.2%
* error: 7.8%
* macro_f1: 92.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [20/30] batch [20/20] time 0.216 (0.256) data 0.000 (0.039) loss 0.1558 (0.0388) lr 2.5000e-03 eta 0:00:51
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.71s/it]  7%|▋         | 2/28 [00:01<00:20,  1.24it/s] 11%|█         | 3/28 [00:02<00:13,  1.83it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.62it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.47it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.29it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.06it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.74it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.30it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.75it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.10it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.37it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.56it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.99it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.02it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.02it/s]100%|██████████| 28/28 [00:05<00:00,  5.21it/s]=> result
* total: 2,800
* correct: 2,600
* accuracy: 92.9%
* error: 7.1%
* macro_f1: 92.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/20] time 0.216 (0.257) data 0.000 (0.039) loss 0.7939 (0.1023) lr 2.0611e-03 eta 0:00:46
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:50,  1.88s/it]  7%|▋         | 2/28 [00:02<00:23,  1.09it/s] 11%|█         | 3/28 [00:02<00:14,  1.78it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.57it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.41it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.24it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.01it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.70it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.27it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.72it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:04<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.09it/s]=> result
* total: 2,800
* correct: 2,557
* accuracy: 91.3%
* error: 8.7%
* macro_f1: 91.3%

epoch [22/30] batch [20/20] time 0.217 (0.262) data 0.000 (0.039) loss -0.3301 (0.1234) lr 1.6543e-03 eta 0:00:41
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:46,  1.73s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:13,  1.80it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.60it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.43it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.26it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.04it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.72it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.28it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.73it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:03<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.95it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.17it/s]=> result
* total: 2,800
* correct: 2,563
* accuracy: 91.5%
* error: 8.5%
* macro_f1: 91.5%

epoch [23/30] batch [20/20] time 0.219 (0.258) data 0.000 (0.038) loss -0.2261 (0.0737) lr 1.2843e-03 eta 0:00:36
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:44,  1.66s/it]  7%|▋         | 2/28 [00:01<00:21,  1.19it/s] 11%|█         | 3/28 [00:02<00:13,  1.80it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.60it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.43it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.26it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.04it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.72it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.29it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.74it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.56it/s] 50%|█████     | 14/28 [00:03<00:01,  7.70it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.88it/s] 61%|██████    | 17/28 [00:03<00:01,  7.94it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.97it/s] 68%|██████▊   | 19/28 [00:04<00:01,  8.00it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.01it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.03it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.03it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.04it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.04it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.05it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.05it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  5.18it/s]=> result
* total: 2,800
* correct: 2,593
* accuracy: 92.6%
* error: 7.4%
* macro_f1: 92.6%

epoch [24/30] batch [20/20] time 0.216 (0.256) data 0.000 (0.039) loss -0.2554 (0.0670) lr 9.5492e-04 eta 0:00:30
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:47,  1.75s/it]  7%|▋         | 2/28 [00:01<00:22,  1.17it/s] 11%|█         | 3/28 [00:02<00:14,  1.73it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.49it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.31it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.14it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.92it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.61it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.19it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.67it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.04it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.31it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.52it/s] 50%|█████     | 14/28 [00:03<00:01,  7.66it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:03<00:01,  7.91it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.02it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.09it/s]=> result
* total: 2,800
* correct: 2,603
* accuracy: 93.0%
* error: 7.0%
* macro_f1: 93.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [25/30] batch [20/20] time 0.222 (0.263) data 0.000 (0.039) loss 0.6992 (0.1990) lr 6.6987e-04 eta 0:00:26
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:48,  1.79s/it]  7%|▋         | 2/28 [00:02<00:22,  1.14it/s] 11%|█         | 3/28 [00:02<00:14,  1.71it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.45it/s] 18%|█▊        | 5/28 [00:02<00:07,  3.27it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.09it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.84it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.54it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.14it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.61it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.00it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.29it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.50it/s] 50%|█████     | 14/28 [00:03<00:01,  7.65it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.77it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.85it/s] 61%|██████    | 17/28 [00:04<00:01,  7.91it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.01it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.04it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.04it/s]=> result
* total: 2,800
* correct: 2,612
* accuracy: 93.3%
* error: 6.7%
* macro_f1: 93.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [26/30] batch [20/20] time 0.217 (0.259) data 0.000 (0.039) loss -0.1716 (0.1888) lr 4.3227e-04 eta 0:00:20
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:45,  1.68s/it]  7%|▋         | 2/28 [00:01<00:21,  1.21it/s] 11%|█         | 3/28 [00:02<00:13,  1.79it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.56it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.39it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.23it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.00it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.68it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.25it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.72it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.07it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.34it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.53it/s] 50%|█████     | 14/28 [00:03<00:01,  7.68it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.79it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:03<00:01,  7.90it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.98it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.99it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.01it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.01it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.01it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.03it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.02it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.17it/s]=> result
* total: 2,800
* correct: 2,592
* accuracy: 92.6%
* error: 7.4%
* macro_f1: 92.5%

epoch [27/30] batch [20/20] time 0.215 (0.257) data 0.000 (0.038) loss 0.0088 (0.1827) lr 2.4472e-04 eta 0:00:15
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:51,  1.89s/it]  7%|▋         | 2/28 [00:02<00:24,  1.08it/s] 11%|█         | 3/28 [00:02<00:14,  1.75it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.53it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.36it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.19it/s] 25%|██▌       | 7/28 [00:02<00:04,  4.97it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.65it/s] 32%|███▏      | 9/28 [00:03<00:03,  6.23it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.70it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.07it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.34it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.54it/s] 50%|█████     | 14/28 [00:03<00:01,  7.69it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.80it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.87it/s] 61%|██████    | 17/28 [00:04<00:01,  7.92it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.96it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.99it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.01it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.02it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.03it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.04it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.05it/s] 89%|████████▉ | 25/28 [00:05<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.00it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.01it/s]100%|██████████| 28/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  5.03it/s]=> result
* total: 2,800
* correct: 2,596
* accuracy: 92.7%
* error: 7.3%
* macro_f1: 92.7%

epoch [28/30] batch [20/20] time 0.219 (0.258) data 0.000 (0.038) loss -0.2771 (0.0125) lr 1.0926e-04 eta 0:00:10
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:42,  1.59s/it]  7%|▋         | 2/28 [00:01<00:20,  1.24it/s] 11%|█         | 3/28 [00:02<00:13,  1.83it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.62it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.46it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.29it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.06it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.73it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.30it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.74it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.36it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.68it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.78it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.86it/s] 61%|██████    | 17/28 [00:03<00:01,  7.91it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.94it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.97it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.00it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.02it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.03it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.03it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.04it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.05it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.05it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.24it/s]=> result
* total: 2,800
* correct: 2,593
* accuracy: 92.6%
* error: 7.4%
* macro_f1: 92.6%

epoch [29/30] batch [20/20] time 0.217 (0.256) data 0.000 (0.039) loss 0.0903 (-0.0039) lr 2.7391e-05 eta 0:00:05
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:49,  1.83s/it]  7%|▋         | 2/28 [00:02<00:23,  1.11it/s] 11%|█         | 3/28 [00:02<00:13,  1.83it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.64it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.48it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.31it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.08it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.76it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.33it/s] 36%|███▌      | 10/28 [00:03<00:02,  6.78it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.13it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.39it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.58it/s] 50%|█████     | 14/28 [00:03<00:01,  7.73it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.83it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.89it/s] 61%|██████    | 17/28 [00:03<00:01,  7.94it/s] 64%|██████▍   | 18/28 [00:04<00:01,  7.98it/s] 68%|██████▊   | 19/28 [00:04<00:01,  8.01it/s] 71%|███████▏  | 20/28 [00:04<00:00,  8.03it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.03it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.04it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.05it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.06it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.06it/s] 93%|█████████▎| 26/28 [00:05<00:00,  8.06it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  8.06it/s]100%|██████████| 28/28 [00:05<00:00,  5.14it/s]=> result
* total: 2,800
* correct: 2,594
* accuracy: 92.6%
* error: 7.4%
* macro_f1: 92.6%

epoch [30/30] batch [20/20] time 0.225 (0.263) data 0.000 (0.039) loss 0.5747 (0.0177) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/28 [00:00<?, ?it/s]  4%|▎         | 1/28 [00:01<00:44,  1.63s/it]  7%|▋         | 2/28 [00:01<00:20,  1.27it/s] 11%|█         | 3/28 [00:02<00:13,  1.87it/s] 14%|█▍        | 4/28 [00:02<00:09,  2.61it/s] 18%|█▊        | 5/28 [00:02<00:06,  3.46it/s] 21%|██▏       | 6/28 [00:02<00:05,  4.29it/s] 25%|██▌       | 7/28 [00:02<00:04,  5.06it/s] 29%|██▊       | 8/28 [00:02<00:03,  5.73it/s] 32%|███▏      | 9/28 [00:02<00:03,  6.29it/s] 36%|███▌      | 10/28 [00:02<00:02,  6.75it/s] 39%|███▉      | 11/28 [00:03<00:02,  7.09it/s] 43%|████▎     | 12/28 [00:03<00:02,  7.35it/s] 46%|████▋     | 13/28 [00:03<00:01,  7.55it/s] 50%|█████     | 14/28 [00:03<00:01,  7.65it/s] 54%|█████▎    | 15/28 [00:03<00:01,  7.75it/s] 57%|█████▋    | 16/28 [00:03<00:01,  7.83it/s] 61%|██████    | 17/28 [00:03<00:01,  7.89it/s] 64%|██████▍   | 18/28 [00:03<00:01,  7.93it/s] 68%|██████▊   | 19/28 [00:04<00:01,  7.96it/s] 71%|███████▏  | 20/28 [00:04<00:01,  7.98it/s] 75%|███████▌  | 21/28 [00:04<00:00,  8.00it/s] 79%|███████▊  | 22/28 [00:04<00:00,  8.02it/s] 82%|████████▏ | 23/28 [00:04<00:00,  8.03it/s] 86%|████████▌ | 24/28 [00:04<00:00,  8.02it/s] 89%|████████▉ | 25/28 [00:04<00:00,  8.02it/s] 93%|█████████▎| 26/28 [00:04<00:00,  8.03it/s] 96%|█████████▋| 27/28 [00:05<00:00,  8.03it/s]100%|██████████| 28/28 [00:05<00:00,  8.04it/s]100%|██████████| 28/28 [00:05<00:00,  5.25it/s]
=> result
* total: 2,800
* correct: 2,594
* accuracy: 92.6%
* error: 7.4%
* macro_f1: 92.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/42 [00:00<?, ?it/s]  2%|▏         | 1/42 [00:01<01:17,  1.88s/it]  5%|▍         | 2/42 [00:02<00:37,  1.08it/s]  7%|▋         | 3/42 [00:02<00:26,  1.49it/s] 10%|▉         | 4/42 [00:02<00:17,  2.14it/s] 12%|█▏        | 5/42 [00:02<00:12,  2.89it/s] 14%|█▍        | 6/42 [00:03<00:11,  3.23it/s] 17%|█▋        | 7/42 [00:03<00:08,  3.96it/s] 19%|█▉        | 8/42 [00:03<00:07,  4.58it/s] 21%|██▏       | 9/42 [00:03<00:06,  5.20it/s] 24%|██▍       | 10/42 [00:03<00:06,  4.83it/s] 26%|██▌       | 11/42 [00:03<00:05,  5.38it/s] 29%|██▊       | 12/42 [00:03<00:05,  5.97it/s] 31%|███       | 13/42 [00:04<00:04,  6.47it/s] 33%|███▎      | 14/42 [00:04<00:04,  6.88it/s] 36%|███▌      | 15/42 [00:04<00:03,  7.19it/s] 38%|███▊      | 16/42 [00:04<00:03,  7.42it/s] 40%|████      | 17/42 [00:04<00:03,  7.58it/s] 43%|████▎     | 18/42 [00:04<00:03,  7.71it/s] 45%|████▌     | 19/42 [00:04<00:02,  7.79it/s] 48%|████▊     | 20/42 [00:04<00:02,  7.85it/s] 50%|█████     | 21/42 [00:05<00:02,  7.90it/s] 52%|█████▏    | 22/42 [00:05<00:02,  7.93it/s] 55%|█████▍    | 23/42 [00:05<00:02,  7.96it/s] 57%|█████▋    | 24/42 [00:05<00:02,  7.97it/s] 60%|█████▉    | 25/42 [00:05<00:02,  7.98it/s] 62%|██████▏   | 26/42 [00:05<00:02,  8.00it/s] 64%|██████▍   | 27/42 [00:05<00:01,  8.00it/s] 67%|██████▋   | 28/42 [00:05<00:01,  8.00it/s] 69%|██████▉   | 29/42 [00:06<00:01,  7.97it/s] 71%|███████▏  | 30/42 [00:06<00:01,  7.99it/s] 74%|███████▍  | 31/42 [00:06<00:01,  8.00it/s] 76%|███████▌  | 32/42 [00:06<00:01,  7.99it/s] 79%|███████▊  | 33/42 [00:06<00:01,  8.00it/s] 81%|████████  | 34/42 [00:06<00:00,  8.02it/s] 83%|████████▎ | 35/42 [00:06<00:00,  8.02it/s] 86%|████████▌ | 36/42 [00:06<00:00,  8.02it/s] 88%|████████▊ | 37/42 [00:07<00:00,  8.01it/s] 90%|█████████ | 38/42 [00:07<00:00,  8.02it/s] 93%|█████████▎| 39/42 [00:07<00:00,  8.02it/s] 95%|█████████▌| 40/42 [00:07<00:00,  8.02it/s] 98%|█████████▊| 41/42 [00:07<00:00,  8.02it/s]100%|██████████| 42/42 [00:07<00:00,  8.02it/s]100%|██████████| 42/42 [00:07<00:00,  5.35it/s]
=> result
* total: 4,200
* correct: 3,917
* accuracy: 93.3%
* error: 6.7%
* macro_f1: 93.3%
Elapsed: 0:05:33
+ sh scripts/rpo_prime/base2new_test_sdl.sh eurosat 3 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
80 2600 3900
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  5
# train_x  80
# val      2,600
# test     3,900
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/eurosat/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/39 [00:00<?, ?it/s]  3%|▎         | 1/39 [00:04<02:51,  4.52s/it]  5%|▌         | 2/39 [00:04<01:12,  1.96s/it]  8%|▊         | 3/39 [00:04<00:42,  1.17s/it] 10%|█         | 4/39 [00:05<00:26,  1.31it/s] 13%|█▎        | 5/39 [00:05<00:18,  1.87it/s] 15%|█▌        | 6/39 [00:05<00:13,  2.46it/s] 18%|█▊        | 7/39 [00:05<00:10,  3.08it/s] 21%|██        | 8/39 [00:05<00:08,  3.80it/s] 23%|██▎       | 9/39 [00:05<00:06,  4.52it/s] 26%|██▌       | 10/39 [00:05<00:05,  5.23it/s] 28%|██▊       | 11/39 [00:06<00:04,  5.85it/s] 31%|███       | 12/39 [00:06<00:04,  6.38it/s] 33%|███▎      | 13/39 [00:06<00:03,  6.80it/s] 36%|███▌      | 14/39 [00:06<00:03,  7.13it/s] 38%|███▊      | 15/39 [00:06<00:03,  7.38it/s] 41%|████      | 16/39 [00:06<00:03,  7.58it/s] 44%|████▎     | 17/39 [00:06<00:02,  7.70it/s] 46%|████▌     | 18/39 [00:06<00:02,  7.79it/s] 49%|████▊     | 19/39 [00:07<00:02,  7.86it/s] 51%|█████▏    | 20/39 [00:07<00:02,  7.81it/s] 54%|█████▍    | 21/39 [00:07<00:02,  7.88it/s] 56%|█████▋    | 22/39 [00:07<00:02,  7.92it/s] 59%|█████▉    | 23/39 [00:07<00:02,  7.95it/s] 62%|██████▏   | 24/39 [00:07<00:01,  7.97it/s] 64%|██████▍   | 25/39 [00:07<00:01,  7.99it/s] 67%|██████▋   | 26/39 [00:07<00:01,  7.99it/s] 69%|██████▉   | 27/39 [00:08<00:01,  8.00it/s] 72%|███████▏  | 28/39 [00:08<00:01,  8.00it/s] 74%|███████▍  | 29/39 [00:08<00:01,  8.01it/s] 77%|███████▋  | 30/39 [00:08<00:01,  8.01it/s] 79%|███████▉  | 31/39 [00:08<00:00,  8.02it/s] 82%|████████▏ | 32/39 [00:08<00:00,  8.02it/s] 85%|████████▍ | 33/39 [00:08<00:00,  8.02it/s] 87%|████████▋ | 34/39 [00:08<00:00,  8.01it/s] 90%|████████▉ | 35/39 [00:09<00:00,  8.01it/s] 92%|█████████▏| 36/39 [00:09<00:00,  8.02it/s] 95%|█████████▍| 37/39 [00:09<00:00,  8.01it/s] 97%|█████████▋| 38/39 [00:09<00:00,  8.01it/s]100%|██████████| 39/39 [00:09<00:00,  8.00it/s]100%|██████████| 39/39 [00:09<00:00,  4.06it/s]
=> result
* total: 3,900
* correct: 2,877
* accuracy: 73.8%
* error: 26.2%
* macro_f1: 72.2%
+ for dataset in eurosat dtd oxford_flowers stanford_cars oxford_pets food101 ucf101 caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh dtd 1 0 main_tmp1_0.1sdl 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
384 576 864
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  24
# train_x  384
# val      576
# test     864
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/96] time 0.250 (0.399) data 0.000 (0.067) loss 1.3467 (2.4944) lr 1.0000e-02 eta 0:19:02
epoch [1/30] batch [40/96] time 0.249 (0.326) data 0.000 (0.034) loss 5.3086 (2.6154) lr 1.0000e-02 eta 0:15:25
epoch [1/30] batch [60/96] time 0.250 (0.301) data 0.000 (0.023) loss 1.3486 (2.8328) lr 1.0000e-02 eta 0:14:09
epoch [1/30] batch [80/96] time 0.233 (0.285) data 0.000 (0.017) loss 2.4434 (2.8942) lr 1.0000e-02 eta 0:13:17
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.98s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.12it/s] 50%|█████     | 3/6 [00:02<00:01,  1.83it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.63it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.46it/s]100%|██████████| 6/6 [00:02<00:00,  4.45it/s]100%|██████████| 6/6 [00:02<00:00,  2.19it/s]=> result
* total: 576
* correct: 351
* accuracy: 60.9%
* error: 39.1%
* macro_f1: 57.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/96] time 0.237 (0.290) data 0.000 (0.045) loss 3.9199 (2.2361) lr 9.9726e-03 eta 0:13:21
epoch [2/30] batch [40/96] time 0.246 (0.268) data 0.001 (0.023) loss 2.2676 (2.3482) lr 9.9726e-03 eta 0:12:15
epoch [2/30] batch [60/96] time 0.254 (0.260) data 0.000 (0.015) loss 2.5469 (2.3438) lr 9.9726e-03 eta 0:11:49
epoch [2/30] batch [80/96] time 0.228 (0.254) data 0.000 (0.011) loss 1.2402 (2.2350) lr 9.9726e-03 eta 0:11:25
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.75s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.25it/s] 50%|█████     | 3/6 [00:02<00:01,  2.02it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.85it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.70it/s]100%|██████████| 6/6 [00:02<00:00,  4.69it/s]100%|██████████| 6/6 [00:02<00:00,  2.40it/s]=> result
* total: 576
* correct: 367
* accuracy: 63.7%
* error: 36.3%
* macro_f1: 61.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/96] time 0.250 (0.295) data 0.000 (0.044) loss 2.2969 (2.2333) lr 9.8907e-03 eta 0:13:06
epoch [3/30] batch [40/96] time 0.252 (0.271) data 0.000 (0.022) loss 4.2148 (2.1255) lr 9.8907e-03 eta 0:11:58
epoch [3/30] batch [60/96] time 0.244 (0.263) data 0.000 (0.015) loss 1.3857 (2.0895) lr 9.8907e-03 eta 0:11:31
epoch [3/30] batch [80/96] time 0.232 (0.256) data 0.000 (0.011) loss 3.7695 (2.1813) lr 9.8907e-03 eta 0:11:08
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.80s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.98it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.81it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.65it/s]100%|██████████| 6/6 [00:02<00:00,  4.64it/s]100%|██████████| 6/6 [00:02<00:00,  2.36it/s]=> result
* total: 576
* correct: 377
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 63.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/96] time 0.333 (0.297) data 0.000 (0.044) loss 1.9629 (1.7272) lr 9.7553e-03 eta 0:12:45
epoch [4/30] batch [40/96] time 0.237 (0.272) data 0.000 (0.022) loss 1.4883 (1.6942) lr 9.7553e-03 eta 0:11:34
epoch [4/30] batch [60/96] time 0.251 (0.264) data 0.000 (0.015) loss 2.2656 (1.7827) lr 9.7553e-03 eta 0:11:07
epoch [4/30] batch [80/96] time 0.229 (0.257) data 0.000 (0.011) loss 2.6113 (1.8763) lr 9.7553e-03 eta 0:10:46
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.76s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.25it/s] 50%|█████     | 3/6 [00:02<00:01,  2.02it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.86it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.71it/s]100%|██████████| 6/6 [00:02<00:00,  4.70it/s]100%|██████████| 6/6 [00:02<00:00,  2.40it/s]=> result
* total: 576
* correct: 391
* accuracy: 67.9%
* error: 32.1%
* macro_f1: 66.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/96] time 0.244 (0.292) data 0.000 (0.043) loss 0.7061 (1.3685) lr 9.5677e-03 eta 0:12:01
epoch [5/30] batch [40/96] time 0.251 (0.269) data 0.000 (0.022) loss 1.4570 (1.5323) lr 9.5677e-03 eta 0:11:00
epoch [5/30] batch [60/96] time 0.239 (0.261) data 0.000 (0.015) loss 1.5332 (1.5755) lr 9.5677e-03 eta 0:10:36
epoch [5/30] batch [80/96] time 0.234 (0.256) data 0.000 (0.011) loss 0.6147 (1.5594) lr 9.5677e-03 eta 0:10:18
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.79s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.99it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.82it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.66it/s]100%|██████████| 6/6 [00:02<00:00,  4.65it/s]100%|██████████| 6/6 [00:02<00:00,  2.36it/s]=> result
* total: 576
* correct: 408
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 69.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/96] time 0.250 (0.295) data 0.000 (0.043) loss 2.5430 (1.6517) lr 9.3301e-03 eta 0:11:42
epoch [6/30] batch [40/96] time 0.252 (0.273) data 0.000 (0.022) loss 0.9209 (1.5897) lr 9.3301e-03 eta 0:10:43
epoch [6/30] batch [60/96] time 0.241 (0.264) data 0.000 (0.014) loss 1.5615 (1.6812) lr 9.3301e-03 eta 0:10:17
epoch [6/30] batch [80/96] time 0.230 (0.257) data 0.000 (0.011) loss 1.7344 (1.6119) lr 9.3301e-03 eta 0:09:55
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.79s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.23it/s] 50%|█████     | 3/6 [00:02<00:01,  1.99it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.83it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.68it/s]100%|██████████| 6/6 [00:02<00:00,  4.69it/s]100%|██████████| 6/6 [00:02<00:00,  2.37it/s]=> result
* total: 576
* correct: 404
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 68.3%

epoch [7/30] batch [20/96] time 0.240 (0.290) data 0.000 (0.042) loss 1.4434 (1.4180) lr 9.0451e-03 eta 0:11:02
epoch [7/30] batch [40/96] time 0.249 (0.268) data 0.000 (0.021) loss 0.2167 (1.1878) lr 9.0451e-03 eta 0:10:06
epoch [7/30] batch [60/96] time 0.244 (0.260) data 0.000 (0.014) loss 0.7158 (1.3058) lr 9.0451e-03 eta 0:09:43
epoch [7/30] batch [80/96] time 0.229 (0.253) data 0.000 (0.011) loss 0.3254 (1.3719) lr 9.0451e-03 eta 0:09:22
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.83s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.20it/s] 50%|█████     | 3/6 [00:02<00:01,  1.96it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.78it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.62it/s]100%|██████████| 6/6 [00:02<00:00,  4.61it/s]100%|██████████| 6/6 [00:02<00:00,  2.32it/s]=> result
* total: 576
* correct: 421
* accuracy: 73.1%
* error: 26.9%
* macro_f1: 71.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/96] time 0.246 (0.296) data 0.000 (0.044) loss 1.6143 (1.3113) lr 8.7157e-03 eta 0:10:46
epoch [8/30] batch [40/96] time 0.245 (0.271) data 0.000 (0.022) loss 0.7563 (1.1640) lr 8.7157e-03 eta 0:09:47
epoch [8/30] batch [60/96] time 0.250 (0.263) data 0.000 (0.015) loss 0.4431 (1.1935) lr 8.7157e-03 eta 0:09:25
epoch [8/30] batch [80/96] time 0.231 (0.256) data 0.000 (0.011) loss 1.1582 (1.2549) lr 8.7157e-03 eta 0:09:04
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.76s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.25it/s] 50%|█████     | 3/6 [00:02<00:01,  2.03it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.86it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.71it/s]100%|██████████| 6/6 [00:02<00:00,  4.70it/s]100%|██████████| 6/6 [00:02<00:00,  2.39it/s]=> result
* total: 576
* correct: 420
* accuracy: 72.9%
* error: 27.1%
* macro_f1: 71.4%

epoch [9/30] batch [20/96] time 0.254 (0.294) data 0.000 (0.044) loss 0.9893 (1.1258) lr 8.3457e-03 eta 0:10:15
epoch [9/30] batch [40/96] time 0.247 (0.273) data 0.000 (0.022) loss 0.2476 (1.0890) lr 8.3457e-03 eta 0:09:24
epoch [9/30] batch [60/96] time 0.248 (0.264) data 0.000 (0.015) loss 4.0859 (1.1605) lr 8.3457e-03 eta 0:09:02
epoch [9/30] batch [80/96] time 0.231 (0.257) data 0.000 (0.011) loss 2.8438 (1.2065) lr 8.3457e-03 eta 0:08:42
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.88s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.17it/s] 50%|█████     | 3/6 [00:02<00:01,  1.92it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.73it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.56it/s]100%|██████████| 6/6 [00:02<00:00,  4.54it/s]100%|██████████| 6/6 [00:02<00:00,  2.28it/s]=> result
* total: 576
* correct: 429
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/96] time 0.245 (0.293) data 0.000 (0.043) loss 1.8535 (1.1382) lr 7.9389e-03 eta 0:09:44
epoch [10/30] batch [40/96] time 0.241 (0.272) data 0.000 (0.022) loss 0.8838 (1.1124) lr 7.9389e-03 eta 0:08:56
epoch [10/30] batch [60/96] time 0.253 (0.263) data 0.000 (0.015) loss 1.3027 (1.0890) lr 7.9389e-03 eta 0:08:34
epoch [10/30] batch [80/96] time 0.233 (0.256) data 0.000 (0.011) loss 1.4609 (1.1716) lr 7.9389e-03 eta 0:08:15
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.89s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.16it/s] 50%|█████     | 3/6 [00:02<00:01,  1.89it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.70it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.53it/s]100%|██████████| 6/6 [00:02<00:00,  4.51it/s]100%|██████████| 6/6 [00:02<00:00,  2.26it/s]=> result
* total: 576
* correct: 426
* accuracy: 74.0%
* error: 26.0%
* macro_f1: 73.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/96] time 0.252 (0.292) data 0.000 (0.044) loss 0.2634 (0.9584) lr 7.5000e-03 eta 0:09:15
epoch [11/30] batch [40/96] time 0.245 (0.272) data 0.000 (0.022) loss 1.7051 (0.9319) lr 7.5000e-03 eta 0:08:31
epoch [11/30] batch [60/96] time 0.241 (0.264) data 0.000 (0.015) loss 0.3550 (0.8780) lr 7.5000e-03 eta 0:08:10
epoch [11/30] batch [80/96] time 0.233 (0.257) data 0.000 (0.011) loss 1.1982 (0.9470) lr 7.5000e-03 eta 0:07:52
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.78s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.98it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.79it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.63it/s]100%|██████████| 6/6 [00:02<00:00,  4.62it/s]100%|██████████| 6/6 [00:02<00:00,  2.36it/s]=> result
* total: 576
* correct: 434
* accuracy: 75.3%
* error: 24.7%
* macro_f1: 74.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/96] time 0.247 (0.294) data 0.000 (0.043) loss 0.8105 (0.8448) lr 7.0337e-03 eta 0:08:49
epoch [12/30] batch [40/96] time 0.239 (0.271) data 0.000 (0.022) loss 0.4802 (0.8471) lr 7.0337e-03 eta 0:08:04
epoch [12/30] batch [60/96] time 0.247 (0.264) data 0.000 (0.015) loss 0.9360 (0.8413) lr 7.0337e-03 eta 0:07:45
epoch [12/30] batch [80/96] time 0.231 (0.257) data 0.000 (0.011) loss 0.8408 (0.8093) lr 7.0337e-03 eta 0:07:27
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.82s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.21it/s] 50%|█████     | 3/6 [00:02<00:01,  1.97it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.80it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.65it/s]100%|██████████| 6/6 [00:02<00:00,  4.66it/s]100%|██████████| 6/6 [00:02<00:00,  2.34it/s]=> result
* total: 576
* correct: 433
* accuracy: 75.2%
* error: 24.8%
* macro_f1: 74.7%

epoch [13/30] batch [20/96] time 0.253 (0.291) data 0.000 (0.043) loss 0.7666 (0.8489) lr 6.5451e-03 eta 0:08:17
epoch [13/30] batch [40/96] time 0.243 (0.269) data 0.000 (0.022) loss 2.0645 (0.8370) lr 6.5451e-03 eta 0:07:34
epoch [13/30] batch [60/96] time 0.241 (0.262) data 0.000 (0.015) loss 1.9150 (0.8624) lr 6.5451e-03 eta 0:07:17
epoch [13/30] batch [80/96] time 0.230 (0.255) data 0.000 (0.011) loss 0.2505 (0.8661) lr 6.5451e-03 eta 0:07:00
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.78s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.21it/s] 50%|█████     | 3/6 [00:02<00:01,  1.97it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.80it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.64it/s]100%|██████████| 6/6 [00:02<00:00,  4.63it/s]100%|██████████| 6/6 [00:02<00:00,  2.36it/s]=> result
* total: 576
* correct: 439
* accuracy: 76.2%
* error: 23.8%
* macro_f1: 75.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [14/30] batch [20/96] time 0.239 (0.293) data 0.000 (0.042) loss 0.5361 (0.6032) lr 6.0396e-03 eta 0:07:53
epoch [14/30] batch [40/96] time 0.247 (0.271) data 0.000 (0.021) loss 0.8999 (0.7102) lr 6.0396e-03 eta 0:07:11
epoch [14/30] batch [60/96] time 0.246 (0.265) data 0.000 (0.014) loss 0.0233 (0.7417) lr 6.0396e-03 eta 0:06:55
epoch [14/30] batch [80/96] time 0.233 (0.258) data 0.000 (0.011) loss 1.1797 (0.7914) lr 6.0396e-03 eta 0:06:39
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.81s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.19it/s] 50%|█████     | 3/6 [00:02<00:01,  1.94it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.76it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.61it/s]100%|██████████| 6/6 [00:02<00:00,  4.61it/s]100%|██████████| 6/6 [00:02<00:00,  2.32it/s]=> result
* total: 576
* correct: 441
* accuracy: 76.6%
* error: 23.4%
* macro_f1: 75.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/96] time 0.255 (0.295) data 0.000 (0.043) loss 0.5791 (0.7006) lr 5.5226e-03 eta 0:07:27
epoch [15/30] batch [40/96] time 0.246 (0.269) data 0.000 (0.022) loss 0.2661 (0.7435) lr 5.5226e-03 eta 0:06:43
epoch [15/30] batch [60/96] time 0.254 (0.263) data 0.000 (0.015) loss 1.6113 (0.7989) lr 5.5226e-03 eta 0:06:27
epoch [15/30] batch [80/96] time 0.229 (0.255) data 0.000 (0.011) loss 1.4258 (0.8021) lr 5.5226e-03 eta 0:06:11
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.83s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.20it/s] 50%|█████     | 3/6 [00:02<00:01,  1.96it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.78it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.61it/s]100%|██████████| 6/6 [00:02<00:00,  4.60it/s]100%|██████████| 6/6 [00:02<00:00,  2.33it/s]=> result
* total: 576
* correct: 440
* accuracy: 76.4%
* error: 23.6%
* macro_f1: 75.7%

epoch [16/30] batch [20/96] time 0.249 (0.296) data 0.000 (0.043) loss 0.5381 (0.7338) lr 5.0000e-03 eta 0:07:00
epoch [16/30] batch [40/96] time 0.245 (0.272) data 0.000 (0.022) loss 0.9883 (0.7299) lr 5.0000e-03 eta 0:06:20
epoch [16/30] batch [60/96] time 0.256 (0.263) data 0.000 (0.015) loss 0.2319 (0.8130) lr 5.0000e-03 eta 0:06:03
epoch [16/30] batch [80/96] time 0.233 (0.257) data 0.000 (0.011) loss 1.1475 (0.7926) lr 5.0000e-03 eta 0:05:49
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.87s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.16it/s] 50%|█████     | 3/6 [00:02<00:01,  1.90it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.72it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.56it/s]100%|██████████| 6/6 [00:02<00:00,  2.27it/s]=> result
* total: 576
* correct: 440
* accuracy: 76.4%
* error: 23.6%
* macro_f1: 75.7%

epoch [17/30] batch [20/96] time 0.251 (0.292) data 0.000 (0.043) loss 0.3530 (0.8248) lr 4.4774e-03 eta 0:06:26
epoch [17/30] batch [40/96] time 0.244 (0.269) data 0.000 (0.021) loss 0.1221 (0.7712) lr 4.4774e-03 eta 0:05:50
epoch [17/30] batch [60/96] time 0.240 (0.260) data 0.000 (0.014) loss 0.1110 (0.7155) lr 4.4774e-03 eta 0:05:34
epoch [17/30] batch [80/96] time 0.228 (0.255) data 0.000 (0.011) loss 0.0318 (0.6985) lr 4.4774e-03 eta 0:05:21
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.74s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.26it/s] 50%|█████     | 3/6 [00:01<00:01,  2.04it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.88it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.73it/s]100%|██████████| 6/6 [00:02<00:00,  4.72it/s]100%|██████████| 6/6 [00:02<00:00,  2.41it/s]=> result
* total: 576
* correct: 445
* accuracy: 77.3%
* error: 22.7%
* macro_f1: 76.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/96] time 0.237 (0.293) data 0.000 (0.044) loss 0.1041 (0.5374) lr 3.9604e-03 eta 0:05:59
epoch [18/30] batch [40/96] time 0.256 (0.270) data 0.000 (0.022) loss 1.0254 (0.5831) lr 3.9604e-03 eta 0:05:26
epoch [18/30] batch [60/96] time 0.244 (0.264) data 0.000 (0.015) loss 0.4409 (0.6703) lr 3.9604e-03 eta 0:05:13
epoch [18/30] batch [80/96] time 0.233 (0.256) data 0.000 (0.011) loss 0.1841 (0.6924) lr 3.9604e-03 eta 0:04:59
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.84s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.20it/s] 50%|█████     | 3/6 [00:02<00:01,  1.95it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.78it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.63it/s]100%|██████████| 6/6 [00:02<00:00,  4.62it/s]100%|██████████| 6/6 [00:02<00:00,  2.31it/s]=> result
* total: 576
* correct: 449
* accuracy: 78.0%
* error: 22.0%
* macro_f1: 77.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/96] time 0.244 (0.292) data 0.000 (0.043) loss 0.7417 (0.4625) lr 3.4549e-03 eta 0:05:30
epoch [19/30] batch [40/96] time 0.238 (0.269) data 0.000 (0.022) loss 0.1735 (0.5140) lr 3.4549e-03 eta 0:04:58
epoch [19/30] batch [60/96] time 0.242 (0.262) data 0.000 (0.015) loss 0.6504 (0.5145) lr 3.4549e-03 eta 0:04:46
epoch [19/30] batch [80/96] time 0.230 (0.255) data 0.000 (0.011) loss 0.0142 (0.5343) lr 3.4549e-03 eta 0:04:33
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.78s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.23it/s] 50%|█████     | 3/6 [00:02<00:01,  2.00it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.83it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.67it/s]100%|██████████| 6/6 [00:02<00:00,  4.67it/s]100%|██████████| 6/6 [00:02<00:00,  2.38it/s]=> result
* total: 576
* correct: 455
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 78.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [20/30] batch [20/96] time 0.242 (0.293) data 0.000 (0.042) loss 0.0532 (0.6320) lr 2.9663e-03 eta 0:05:03
epoch [20/30] batch [40/96] time 0.260 (0.272) data 0.000 (0.021) loss 0.3149 (0.6185) lr 2.9663e-03 eta 0:04:36
epoch [20/30] batch [60/96] time 0.236 (0.263) data 0.000 (0.014) loss 0.3501 (0.5241) lr 2.9663e-03 eta 0:04:21
epoch [20/30] batch [80/96] time 0.237 (0.257) data 0.000 (0.011) loss 1.3438 (0.6140) lr 2.9663e-03 eta 0:04:10
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.78s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.24it/s] 50%|█████     | 3/6 [00:02<00:01,  2.01it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.84it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.68it/s]100%|██████████| 6/6 [00:02<00:00,  4.68it/s]100%|██████████| 6/6 [00:02<00:00,  2.37it/s]=> result
* total: 576
* correct: 444
* accuracy: 77.1%
* error: 22.9%
* macro_f1: 76.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/96] time 0.250 (0.293) data 0.000 (0.042) loss 0.4519 (0.6001) lr 2.5000e-03 eta 0:04:35
epoch [21/30] batch [40/96] time 0.238 (0.270) data 0.000 (0.021) loss 0.7002 (0.5563) lr 2.5000e-03 eta 0:04:07
epoch [21/30] batch [60/96] time 0.248 (0.262) data 0.000 (0.014) loss 1.0322 (0.5604) lr 2.5000e-03 eta 0:03:55
epoch [21/30] batch [80/96] time 0.232 (0.257) data 0.000 (0.011) loss 0.0274 (0.5440) lr 2.5000e-03 eta 0:03:45
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.78s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.99it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.81it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.66it/s]100%|██████████| 6/6 [00:02<00:00,  4.63it/s]100%|██████████| 6/6 [00:02<00:00,  2.37it/s]=> result
* total: 576
* correct: 451
* accuracy: 78.3%
* error: 21.7%
* macro_f1: 77.9%

epoch [22/30] batch [20/96] time 0.244 (0.291) data 0.000 (0.043) loss 0.4219 (0.2810) lr 2.0611e-03 eta 0:04:05
epoch [22/30] batch [40/96] time 0.318 (0.272) data 0.000 (0.022) loss 0.6201 (0.4621) lr 2.0611e-03 eta 0:03:44
epoch [22/30] batch [60/96] time 0.241 (0.263) data 0.000 (0.014) loss 0.5234 (0.5023) lr 2.0611e-03 eta 0:03:31
epoch [22/30] batch [80/96] time 0.232 (0.256) data 0.000 (0.011) loss 0.6597 (0.5064) lr 2.0611e-03 eta 0:03:21
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.83s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.19it/s] 50%|█████     | 3/6 [00:02<00:01,  1.94it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.76it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.60it/s]100%|██████████| 6/6 [00:02<00:00,  4.58it/s]100%|██████████| 6/6 [00:02<00:00,  2.31it/s]=> result
* total: 576
* correct: 455
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 78.3%

epoch [23/30] batch [20/96] time 0.281 (0.290) data 0.000 (0.045) loss 0.6362 (0.3463) lr 1.6543e-03 eta 0:03:37
epoch [23/30] batch [40/96] time 0.247 (0.269) data 0.000 (0.022) loss 0.3958 (0.3273) lr 1.6543e-03 eta 0:03:15
epoch [23/30] batch [60/96] time 0.248 (0.263) data 0.000 (0.015) loss 0.9668 (0.3629) lr 1.6543e-03 eta 0:03:06
epoch [23/30] batch [80/96] time 0.232 (0.256) data 0.000 (0.011) loss 1.1973 (0.4159) lr 1.6543e-03 eta 0:02:56
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.83s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.20it/s] 50%|█████     | 3/6 [00:02<00:01,  1.96it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.78it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.62it/s]100%|██████████| 6/6 [00:02<00:00,  4.61it/s]100%|██████████| 6/6 [00:02<00:00,  2.32it/s]=> result
* total: 576
* correct: 450
* accuracy: 78.1%
* error: 21.9%
* macro_f1: 77.9%

epoch [24/30] batch [20/96] time 0.250 (0.294) data 0.000 (0.044) loss 0.1747 (0.5930) lr 1.2843e-03 eta 0:03:11
epoch [24/30] batch [40/96] time 0.242 (0.271) data 0.000 (0.022) loss 0.0742 (0.4640) lr 1.2843e-03 eta 0:02:51
epoch [24/30] batch [60/96] time 0.249 (0.264) data 0.000 (0.015) loss 1.1143 (0.4800) lr 1.2843e-03 eta 0:02:41
epoch [24/30] batch [80/96] time 0.232 (0.257) data 0.000 (0.011) loss 0.5107 (0.4987) lr 1.2843e-03 eta 0:02:32
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.84s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.19it/s] 50%|█████     | 3/6 [00:02<00:01,  1.94it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.76it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.60it/s]100%|██████████| 6/6 [00:02<00:00,  4.59it/s]100%|██████████| 6/6 [00:02<00:00,  2.31it/s]=> result
* total: 576
* correct: 455
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 78.4%

epoch [25/30] batch [20/96] time 0.249 (0.297) data 0.000 (0.045) loss 0.3799 (0.4694) lr 9.5492e-04 eta 0:02:45
epoch [25/30] batch [40/96] time 0.243 (0.272) data 0.000 (0.023) loss 0.4402 (0.4860) lr 9.5492e-04 eta 0:02:25
epoch [25/30] batch [60/96] time 0.249 (0.264) data 0.000 (0.015) loss 0.2573 (0.4792) lr 9.5492e-04 eta 0:02:16
epoch [25/30] batch [80/96] time 0.232 (0.258) data 0.000 (0.011) loss 0.1841 (0.4384) lr 9.5492e-04 eta 0:02:07
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.99s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.10it/s] 50%|█████     | 3/6 [00:02<00:01,  1.81it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.59it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.41it/s]100%|██████████| 6/6 [00:02<00:00,  4.38it/s]100%|██████████| 6/6 [00:02<00:00,  2.18it/s]=> result
* total: 576
* correct: 462
* accuracy: 80.2%
* error: 19.8%
* macro_f1: 79.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [26/30] batch [20/96] time 0.251 (0.295) data 0.000 (0.042) loss 0.5879 (0.3090) lr 6.6987e-04 eta 0:02:15
epoch [26/30] batch [40/96] time 0.245 (0.271) data 0.000 (0.021) loss 0.4187 (0.3605) lr 6.6987e-04 eta 0:01:59
epoch [26/30] batch [60/96] time 0.260 (0.263) data 0.000 (0.014) loss 0.0580 (0.3576) lr 6.6987e-04 eta 0:01:50
epoch [26/30] batch [80/96] time 0.230 (0.256) data 0.000 (0.011) loss 0.1935 (0.3368) lr 6.6987e-04 eta 0:01:42
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.81s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.21it/s] 50%|█████     | 3/6 [00:02<00:01,  1.97it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.80it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.64it/s]100%|██████████| 6/6 [00:02<00:00,  4.62it/s]100%|██████████| 6/6 [00:02<00:00,  2.32it/s]=> result
* total: 576
* correct: 454
* accuracy: 78.8%
* error: 21.2%
* macro_f1: 78.3%

epoch [27/30] batch [20/96] time 0.282 (0.297) data 0.000 (0.044) loss 0.2219 (0.3468) lr 4.3227e-04 eta 0:01:48
epoch [27/30] batch [40/96] time 0.249 (0.272) data 0.000 (0.022) loss 1.0537 (0.3229) lr 4.3227e-04 eta 0:01:33
epoch [27/30] batch [60/96] time 0.253 (0.263) data 0.000 (0.015) loss 0.3584 (0.3383) lr 4.3227e-04 eta 0:01:25
epoch [27/30] batch [80/96] time 0.232 (0.256) data 0.000 (0.011) loss 0.9741 (0.3280) lr 4.3227e-04 eta 0:01:17
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.79s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.23it/s] 50%|█████     | 3/6 [00:02<00:01,  2.00it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.81it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.65it/s]100%|██████████| 6/6 [00:02<00:00,  4.64it/s]100%|██████████| 6/6 [00:02<00:00,  2.36it/s]=> result
* total: 576
* correct: 455
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 78.5%

epoch [28/30] batch [20/96] time 0.254 (0.300) data 0.001 (0.048) loss 0.0198 (0.4767) lr 2.4472e-04 eta 0:01:20
epoch [28/30] batch [40/96] time 0.250 (0.273) data 0.000 (0.024) loss 0.1081 (0.5291) lr 2.4472e-04 eta 0:01:07
epoch [28/30] batch [60/96] time 0.246 (0.265) data 0.000 (0.016) loss 0.0899 (0.4714) lr 2.4472e-04 eta 0:01:00
epoch [28/30] batch [80/96] time 0.243 (0.259) data 0.000 (0.012) loss 0.1963 (0.4332) lr 2.4472e-04 eta 0:00:53
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.78s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.24it/s] 50%|█████     | 3/6 [00:02<00:01,  2.01it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.85it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.70it/s]100%|██████████| 6/6 [00:02<00:00,  4.71it/s]100%|██████████| 6/6 [00:02<00:00,  2.38it/s]=> result
* total: 576
* correct: 455
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 78.5%

epoch [29/30] batch [20/96] time 0.244 (0.289) data 0.000 (0.045) loss 0.0144 (0.3992) lr 1.0926e-04 eta 0:00:49
epoch [29/30] batch [40/96] time 0.238 (0.267) data 0.000 (0.023) loss 1.1758 (0.4427) lr 1.0926e-04 eta 0:00:40
epoch [29/30] batch [60/96] time 0.248 (0.262) data 0.000 (0.015) loss 0.1423 (0.4129) lr 1.0926e-04 eta 0:00:34
epoch [29/30] batch [80/96] time 0.233 (0.255) data 0.000 (0.011) loss 0.2820 (0.3909) lr 1.0926e-04 eta 0:00:28
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.83s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.20it/s] 50%|█████     | 3/6 [00:02<00:01,  1.96it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.76it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.61it/s]100%|██████████| 6/6 [00:02<00:00,  4.55it/s]100%|██████████| 6/6 [00:02<00:00,  2.33it/s]=> result
* total: 576
* correct: 455
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 78.5%

epoch [30/30] batch [20/96] time 0.254 (0.293) data 0.000 (0.044) loss 0.9502 (0.3995) lr 2.7391e-05 eta 0:00:22
epoch [30/30] batch [40/96] time 0.246 (0.270) data 0.000 (0.022) loss 0.6782 (0.3705) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [60/96] time 0.250 (0.265) data 0.000 (0.015) loss 1.5898 (0.4062) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [80/96] time 0.231 (0.257) data 0.000 (0.011) loss 1.0322 (0.4200) lr 2.7391e-05 eta 0:00:04
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.83s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.20it/s] 50%|█████     | 3/6 [00:02<00:01,  1.95it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.77it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.60it/s]100%|██████████| 6/6 [00:02<00:00,  4.59it/s]100%|██████████| 6/6 [00:02<00:00,  2.32it/s]
=> result
* total: 576
* correct: 455
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 78.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:17,  2.16s/it] 22%|██▏       | 2/9 [00:02<00:06,  1.03it/s] 33%|███▎      | 3/9 [00:02<00:03,  1.71it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.47it/s] 56%|█████▌    | 5/9 [00:02<00:01,  3.28it/s] 67%|██████▋   | 6/9 [00:02<00:00,  4.08it/s] 78%|███████▊  | 7/9 [00:02<00:00,  4.83it/s] 89%|████████▉ | 8/9 [00:03<00:00,  5.49it/s]100%|██████████| 9/9 [00:03<00:00,  2.73it/s]
=> result
* total: 864
* correct: 709
* accuracy: 82.1%
* error: 17.9%
* macro_f1: 81.7%
Elapsed: 0:13:34
+ sh scripts/rpo_prime/base2new_test_sdl.sh dtd 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
368 552 828
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  23
# train_x  368
# val      552
# test     828
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:04<00:32,  4.11s/it] 22%|██▏       | 2/9 [00:04<00:12,  1.77s/it] 33%|███▎      | 3/9 [00:04<00:06,  1.02s/it] 44%|████▍     | 4/9 [00:04<00:03,  1.50it/s] 56%|█████▌    | 5/9 [00:04<00:01,  2.11it/s] 67%|██████▋   | 6/9 [00:04<00:01,  2.81it/s] 78%|███████▊  | 7/9 [00:04<00:00,  3.55it/s] 89%|████████▉ | 8/9 [00:05<00:00,  4.30it/s]100%|██████████| 9/9 [00:05<00:00,  1.72it/s]
=> result
* total: 828
* correct: 540
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 64.4%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh dtd 2 0 main_tmp1_0.1sdl 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
384 576 864
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  24
# train_x  384
# val      576
# test     864
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/96] time 0.241 (0.399) data 0.000 (0.070) loss 3.8477 (3.1958) lr 1.0000e-02 eta 0:18:59
epoch [1/30] batch [40/96] time 0.238 (0.324) data 0.000 (0.035) loss 2.5488 (2.9191) lr 1.0000e-02 eta 0:15:20
epoch [1/30] batch [60/96] time 0.252 (0.299) data 0.000 (0.024) loss 3.7207 (2.8250) lr 1.0000e-02 eta 0:14:03
epoch [1/30] batch [80/96] time 0.233 (0.284) data 0.000 (0.018) loss 1.1709 (2.8669) lr 1.0000e-02 eta 0:13:14
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.90s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.16it/s] 50%|█████     | 3/6 [00:02<00:01,  1.89it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.70it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.52it/s]100%|██████████| 6/6 [00:02<00:00,  4.51it/s]100%|██████████| 6/6 [00:02<00:00,  2.25it/s]=> result
* total: 576
* correct: 359
* accuracy: 62.3%
* error: 37.7%
* macro_f1: 59.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/96] time 0.243 (0.291) data 0.000 (0.042) loss 2.9629 (2.2523) lr 9.9726e-03 eta 0:13:24
epoch [2/30] batch [40/96] time 0.247 (0.270) data 0.000 (0.021) loss 1.3066 (2.1726) lr 9.9726e-03 eta 0:12:20
epoch [2/30] batch [60/96] time 0.254 (0.262) data 0.000 (0.014) loss 2.5859 (2.3292) lr 9.9726e-03 eta 0:11:54
epoch [2/30] batch [80/96] time 0.231 (0.256) data 0.000 (0.011) loss 0.8936 (2.3627) lr 9.9726e-03 eta 0:11:32
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.81s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.20it/s] 50%|█████     | 3/6 [00:02<00:01,  1.95it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.76it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.60it/s]100%|██████████| 6/6 [00:02<00:00,  4.58it/s]100%|██████████| 6/6 [00:02<00:00,  2.30it/s]=> result
* total: 576
* correct: 375
* accuracy: 65.1%
* error: 34.9%
* macro_f1: 61.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/96] time 0.243 (0.295) data 0.000 (0.042) loss 2.9395 (2.5824) lr 9.8907e-03 eta 0:13:06
epoch [3/30] batch [40/96] time 0.244 (0.270) data 0.000 (0.021) loss 0.7319 (2.4133) lr 9.8907e-03 eta 0:11:54
epoch [3/30] batch [60/96] time 0.239 (0.262) data 0.000 (0.014) loss 1.2363 (2.1285) lr 9.8907e-03 eta 0:11:27
epoch [3/30] batch [80/96] time 0.230 (0.255) data 0.000 (0.011) loss 0.6782 (2.1389) lr 9.8907e-03 eta 0:11:05
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.79s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.23it/s] 50%|█████     | 3/6 [00:02<00:01,  2.00it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.83it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.67it/s]100%|██████████| 6/6 [00:02<00:00,  4.66it/s]100%|██████████| 6/6 [00:02<00:00,  2.36it/s]=> result
* total: 576
* correct: 381
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 63.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/96] time 0.243 (0.291) data 0.000 (0.042) loss 1.2109 (1.9310) lr 9.7553e-03 eta 0:12:28
epoch [4/30] batch [40/96] time 0.243 (0.270) data 0.000 (0.021) loss 0.9907 (1.7721) lr 9.7553e-03 eta 0:11:28
epoch [4/30] batch [60/96] time 0.246 (0.263) data 0.000 (0.014) loss 0.5991 (1.8095) lr 9.7553e-03 eta 0:11:06
epoch [4/30] batch [80/96] time 0.232 (0.256) data 0.000 (0.011) loss 2.1426 (1.7658) lr 9.7553e-03 eta 0:10:44
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.79s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.99it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.81it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.64it/s]100%|██████████| 6/6 [00:02<00:00,  4.63it/s]100%|██████████| 6/6 [00:02<00:00,  2.36it/s]=> result
* total: 576
* correct: 387
* accuracy: 67.2%
* error: 32.8%
* macro_f1: 65.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/96] time 0.248 (0.294) data 0.000 (0.042) loss 1.1748 (1.3458) lr 9.5677e-03 eta 0:12:08
epoch [5/30] batch [40/96] time 0.239 (0.272) data 0.000 (0.021) loss 1.5615 (1.5559) lr 9.5677e-03 eta 0:11:09
epoch [5/30] batch [60/96] time 0.239 (0.264) data 0.000 (0.014) loss 0.0909 (1.6479) lr 9.5677e-03 eta 0:10:42
epoch [5/30] batch [80/96] time 0.230 (0.256) data 0.000 (0.011) loss 1.1387 (1.6764) lr 9.5677e-03 eta 0:10:17
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.81s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.98it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.80it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.64it/s]100%|██████████| 6/6 [00:02<00:00,  4.63it/s]100%|██████████| 6/6 [00:02<00:00,  2.33it/s]=> result
* total: 576
* correct: 381
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 64.1%

epoch [6/30] batch [20/96] time 0.241 (0.292) data 0.000 (0.044) loss 1.3252 (1.7965) lr 9.3301e-03 eta 0:11:34
epoch [6/30] batch [40/96] time 0.251 (0.269) data 0.000 (0.022) loss 2.9219 (1.5972) lr 9.3301e-03 eta 0:10:33
epoch [6/30] batch [60/96] time 0.257 (0.261) data 0.000 (0.015) loss 1.2988 (1.5093) lr 9.3301e-03 eta 0:10:10
epoch [6/30] batch [80/96] time 0.231 (0.255) data 0.000 (0.011) loss 1.5098 (1.4793) lr 9.3301e-03 eta 0:09:52
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.78s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.24it/s] 50%|█████     | 3/6 [00:02<00:01,  2.01it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.83it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.67it/s]100%|██████████| 6/6 [00:02<00:00,  4.66it/s]100%|██████████| 6/6 [00:02<00:00,  2.37it/s]=> result
* total: 576
* correct: 402
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 69.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/96] time 0.245 (0.291) data 0.000 (0.043) loss 0.7393 (1.0957) lr 9.0451e-03 eta 0:11:05
epoch [7/30] batch [40/96] time 0.242 (0.270) data 0.000 (0.022) loss 0.8232 (1.2992) lr 9.0451e-03 eta 0:10:10
epoch [7/30] batch [60/96] time 0.255 (0.263) data 0.000 (0.015) loss 2.3047 (1.2525) lr 9.0451e-03 eta 0:09:50
epoch [7/30] batch [80/96] time 0.231 (0.256) data 0.000 (0.011) loss 1.7568 (1.3020) lr 9.0451e-03 eta 0:09:28
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.76s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.24it/s] 50%|█████     | 3/6 [00:02<00:01,  2.01it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.85it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.68it/s]100%|██████████| 6/6 [00:02<00:00,  4.67it/s]100%|██████████| 6/6 [00:02<00:00,  2.39it/s]=> result
* total: 576
* correct: 410
* accuracy: 71.2%
* error: 28.8%
* macro_f1: 70.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/96] time 0.247 (0.295) data 0.000 (0.044) loss 2.3027 (1.8549) lr 8.7157e-03 eta 0:10:45
epoch [8/30] batch [40/96] time 0.249 (0.273) data 0.000 (0.022) loss 0.3511 (1.5763) lr 8.7157e-03 eta 0:09:52
epoch [8/30] batch [60/96] time 0.244 (0.264) data 0.000 (0.015) loss 0.3105 (1.4211) lr 8.7157e-03 eta 0:09:27
epoch [8/30] batch [80/96] time 0.233 (0.257) data 0.000 (0.011) loss 0.1537 (1.2642) lr 8.7157e-03 eta 0:09:06
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.85s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.19it/s] 50%|█████     | 3/6 [00:02<00:01,  1.94it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.76it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.60it/s]100%|██████████| 6/6 [00:02<00:00,  4.58it/s]100%|██████████| 6/6 [00:02<00:00,  2.30it/s]=> result
* total: 576
* correct: 425
* accuracy: 73.8%
* error: 26.2%
* macro_f1: 73.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/96] time 0.255 (0.292) data 0.000 (0.042) loss 0.1560 (1.1207) lr 8.3457e-03 eta 0:10:10
epoch [9/30] batch [40/96] time 0.242 (0.269) data 0.000 (0.021) loss 0.6133 (1.0861) lr 8.3457e-03 eta 0:09:17
epoch [9/30] batch [60/96] time 0.242 (0.262) data 0.000 (0.014) loss 0.7305 (1.1470) lr 8.3457e-03 eta 0:08:57
epoch [9/30] batch [80/96] time 0.229 (0.254) data 0.000 (0.011) loss 0.7290 (1.1541) lr 8.3457e-03 eta 0:08:36
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.74s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.25it/s] 50%|█████     | 3/6 [00:02<00:01,  2.02it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.86it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.70it/s]100%|██████████| 6/6 [00:02<00:00,  4.70it/s]100%|██████████| 6/6 [00:02<00:00,  2.39it/s]=> result
* total: 576
* correct: 426
* accuracy: 74.0%
* error: 26.0%
* macro_f1: 73.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/96] time 0.245 (0.295) data 0.000 (0.043) loss 0.3125 (1.0820) lr 7.9389e-03 eta 0:09:49
epoch [10/30] batch [40/96] time 0.241 (0.270) data 0.000 (0.021) loss 0.8013 (1.1208) lr 7.9389e-03 eta 0:08:53
epoch [10/30] batch [60/96] time 0.239 (0.262) data 0.000 (0.014) loss 0.5728 (0.9559) lr 7.9389e-03 eta 0:08:32
epoch [10/30] batch [80/96] time 0.229 (0.255) data 0.000 (0.011) loss 0.7764 (1.0037) lr 7.9389e-03 eta 0:08:13
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.79s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.98it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.80it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.64it/s]100%|██████████| 6/6 [00:02<00:00,  4.62it/s]100%|██████████| 6/6 [00:02<00:00,  2.35it/s]=> result
* total: 576
* correct: 430
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 74.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/96] time 0.253 (0.293) data 0.000 (0.043) loss 0.2384 (0.9797) lr 7.5000e-03 eta 0:09:17
epoch [11/30] batch [40/96] time 0.247 (0.270) data 0.000 (0.021) loss 2.8672 (1.0439) lr 7.5000e-03 eta 0:08:27
epoch [11/30] batch [60/96] time 0.244 (0.262) data 0.000 (0.014) loss 0.9819 (1.0607) lr 7.5000e-03 eta 0:08:07
epoch [11/30] batch [80/96] time 0.237 (0.255) data 0.000 (0.011) loss 1.3799 (1.0560) lr 7.5000e-03 eta 0:07:49
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.80s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.23it/s] 50%|█████     | 3/6 [00:02<00:01,  1.99it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.82it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.67it/s]100%|██████████| 6/6 [00:02<00:00,  4.67it/s]100%|██████████| 6/6 [00:02<00:00,  2.36it/s]=> result
* total: 576
* correct: 425
* accuracy: 73.8%
* error: 26.2%
* macro_f1: 73.3%

epoch [12/30] batch [20/96] time 0.244 (0.293) data 0.000 (0.044) loss 1.3213 (1.1527) lr 7.0337e-03 eta 0:08:47
epoch [12/30] batch [40/96] time 0.240 (0.269) data 0.000 (0.022) loss 0.1989 (0.9730) lr 7.0337e-03 eta 0:08:00
epoch [12/30] batch [60/96] time 0.240 (0.261) data 0.000 (0.015) loss 1.4316 (0.9933) lr 7.0337e-03 eta 0:07:39
epoch [12/30] batch [80/96] time 0.229 (0.254) data 0.000 (0.011) loss 0.6743 (0.9724) lr 7.0337e-03 eta 0:07:23
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.81s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.18it/s] 50%|█████     | 3/6 [00:02<00:01,  1.93it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.75it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.58it/s]100%|██████████| 6/6 [00:02<00:00,  4.56it/s]100%|██████████| 6/6 [00:02<00:00,  2.31it/s]=> result
* total: 576
* correct: 454
* accuracy: 78.8%
* error: 21.2%
* macro_f1: 78.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [13/30] batch [20/96] time 0.250 (0.291) data 0.000 (0.043) loss 1.0928 (0.8932) lr 6.5451e-03 eta 0:08:16
epoch [13/30] batch [40/96] time 0.246 (0.271) data 0.000 (0.022) loss 0.1726 (0.9677) lr 6.5451e-03 eta 0:07:37
epoch [13/30] batch [60/96] time 0.238 (0.263) data 0.000 (0.014) loss 0.3223 (0.9377) lr 6.5451e-03 eta 0:07:18
epoch [13/30] batch [80/96] time 0.228 (0.255) data 0.000 (0.011) loss 1.7314 (0.9345) lr 6.5451e-03 eta 0:07:00
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.79s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.98it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.80it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.64it/s]100%|██████████| 6/6 [00:02<00:00,  4.63it/s]100%|██████████| 6/6 [00:02<00:00,  2.36it/s]=> result
* total: 576
* correct: 434
* accuracy: 75.3%
* error: 24.7%
* macro_f1: 74.9%

epoch [14/30] batch [20/96] time 0.237 (0.292) data 0.000 (0.043) loss 1.5957 (0.7325) lr 6.0396e-03 eta 0:07:50
epoch [14/30] batch [40/96] time 0.240 (0.269) data 0.000 (0.022) loss 0.3384 (0.8474) lr 6.0396e-03 eta 0:07:08
epoch [14/30] batch [60/96] time 0.244 (0.263) data 0.000 (0.014) loss 0.3262 (0.8122) lr 6.0396e-03 eta 0:06:53
epoch [14/30] batch [80/96] time 0.231 (0.256) data 0.000 (0.011) loss 0.9976 (0.7965) lr 6.0396e-03 eta 0:06:37
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.82s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.21it/s] 50%|█████     | 3/6 [00:02<00:01,  1.97it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.79it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.63it/s]100%|██████████| 6/6 [00:02<00:00,  4.61it/s]100%|██████████| 6/6 [00:02<00:00,  2.32it/s]=> result
* total: 576
* correct: 442
* accuracy: 76.7%
* error: 23.3%
* macro_f1: 76.6%

epoch [15/30] batch [20/96] time 0.240 (0.295) data 0.000 (0.043) loss 0.3196 (0.9352) lr 5.5226e-03 eta 0:07:27
epoch [15/30] batch [40/96] time 0.255 (0.271) data 0.000 (0.022) loss 0.3403 (0.7938) lr 5.5226e-03 eta 0:06:44
epoch [15/30] batch [60/96] time 0.244 (0.263) data 0.000 (0.015) loss 0.1995 (0.8563) lr 5.5226e-03 eta 0:06:27
epoch [15/30] batch [80/96] time 0.295 (0.257) data 0.000 (0.011) loss 0.3547 (0.8194) lr 5.5226e-03 eta 0:06:13
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.88s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.18it/s] 50%|█████     | 3/6 [00:02<00:01,  1.92it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.73it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.56it/s]100%|██████████| 6/6 [00:02<00:00,  4.54it/s]100%|██████████| 6/6 [00:02<00:00,  2.28it/s]=> result
* total: 576
* correct: 447
* accuracy: 77.6%
* error: 22.4%
* macro_f1: 77.3%

epoch [16/30] batch [20/96] time 0.240 (0.290) data 0.000 (0.043) loss 0.1744 (0.6105) lr 5.0000e-03 eta 0:06:51
epoch [16/30] batch [40/96] time 0.246 (0.268) data 0.000 (0.021) loss 0.4431 (0.6135) lr 5.0000e-03 eta 0:06:14
epoch [16/30] batch [60/96] time 0.240 (0.261) data 0.000 (0.014) loss 2.0430 (0.6702) lr 5.0000e-03 eta 0:06:00
epoch [16/30] batch [80/96] time 0.231 (0.256) data 0.000 (0.011) loss 0.5806 (0.6853) lr 5.0000e-03 eta 0:05:48
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.77s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.24it/s] 50%|█████     | 3/6 [00:02<00:01,  2.02it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.85it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.69it/s]100%|██████████| 6/6 [00:02<00:00,  4.68it/s]100%|██████████| 6/6 [00:02<00:00,  2.38it/s]=> result
* total: 576
* correct: 441
* accuracy: 76.6%
* error: 23.4%
* macro_f1: 76.6%

epoch [17/30] batch [20/96] time 0.248 (0.293) data 0.001 (0.042) loss 0.0491 (0.4805) lr 4.4774e-03 eta 0:06:27
epoch [17/30] batch [40/96] time 0.246 (0.269) data 0.000 (0.021) loss 0.6528 (0.4963) lr 4.4774e-03 eta 0:05:51
epoch [17/30] batch [60/96] time 0.258 (0.263) data 0.000 (0.014) loss 2.7188 (0.6385) lr 4.4774e-03 eta 0:05:37
epoch [17/30] batch [80/96] time 0.230 (0.256) data 0.000 (0.011) loss 0.6440 (0.6291) lr 4.4774e-03 eta 0:05:24
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.80s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.98it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.80it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.64it/s]100%|██████████| 6/6 [00:02<00:00,  4.63it/s]100%|██████████| 6/6 [00:02<00:00,  2.33it/s]=> result
* total: 576
* correct: 455
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 78.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/96] time 0.242 (0.291) data 0.000 (0.042) loss 0.6831 (0.7098) lr 3.9604e-03 eta 0:05:57
epoch [18/30] batch [40/96] time 0.243 (0.269) data 0.000 (0.021) loss 0.8994 (0.6395) lr 3.9604e-03 eta 0:05:25
epoch [18/30] batch [60/96] time 0.244 (0.262) data 0.000 (0.014) loss 3.6035 (0.6787) lr 3.9604e-03 eta 0:05:10
epoch [18/30] batch [80/96] time 0.230 (0.256) data 0.000 (0.011) loss 0.7827 (0.6760) lr 3.9604e-03 eta 0:04:58
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.82s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.21it/s] 50%|█████     | 3/6 [00:02<00:01,  1.97it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.79it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.63it/s]100%|██████████| 6/6 [00:02<00:00,  4.61it/s]100%|██████████| 6/6 [00:02<00:00,  2.34it/s]=> result
* total: 576
* correct: 447
* accuracy: 77.6%
* error: 22.4%
* macro_f1: 77.6%

epoch [19/30] batch [20/96] time 0.244 (0.292) data 0.000 (0.042) loss 1.5684 (0.5065) lr 3.4549e-03 eta 0:05:29
epoch [19/30] batch [40/96] time 0.251 (0.270) data 0.001 (0.021) loss 0.0950 (0.7693) lr 3.4549e-03 eta 0:04:59
epoch [19/30] batch [60/96] time 0.250 (0.261) data 0.000 (0.014) loss 0.8970 (0.6520) lr 3.4549e-03 eta 0:04:45
epoch [19/30] batch [80/96] time 0.231 (0.254) data 0.000 (0.011) loss 0.6123 (0.6574) lr 3.4549e-03 eta 0:04:32
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.88s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.17it/s] 50%|█████     | 3/6 [00:02<00:01,  1.91it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.72it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.55it/s]100%|██████████| 6/6 [00:02<00:00,  4.53it/s]100%|██████████| 6/6 [00:02<00:00,  2.28it/s]=> result
* total: 576
* correct: 452
* accuracy: 78.5%
* error: 21.5%
* macro_f1: 78.5%

epoch [20/30] batch [20/96] time 0.242 (0.292) data 0.000 (0.042) loss 0.4189 (0.2912) lr 2.9663e-03 eta 0:05:02
epoch [20/30] batch [40/96] time 0.239 (0.269) data 0.000 (0.021) loss 0.4609 (0.4464) lr 2.9663e-03 eta 0:04:33
epoch [20/30] batch [60/96] time 0.239 (0.261) data 0.000 (0.014) loss 2.3848 (0.5582) lr 2.9663e-03 eta 0:04:19
epoch [20/30] batch [80/96] time 0.230 (0.255) data 0.000 (0.011) loss 0.6738 (0.5865) lr 2.9663e-03 eta 0:04:08
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.81s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.98it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.80it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.64it/s]100%|██████████| 6/6 [00:02<00:00,  4.63it/s]100%|██████████| 6/6 [00:02<00:00,  2.33it/s]=> result
* total: 576
* correct: 458
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 79.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/96] time 0.244 (0.292) data 0.000 (0.042) loss 0.2380 (0.4046) lr 2.5000e-03 eta 0:04:34
epoch [21/30] batch [40/96] time 0.364 (0.273) data 0.000 (0.021) loss -0.0219 (0.4499) lr 2.5000e-03 eta 0:04:10
epoch [21/30] batch [60/96] time 0.253 (0.264) data 0.000 (0.014) loss -0.0806 (0.5116) lr 2.5000e-03 eta 0:03:57
epoch [21/30] batch [80/96] time 0.231 (0.256) data 0.000 (0.011) loss 0.0175 (0.4986) lr 2.5000e-03 eta 0:03:45
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.82s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.20it/s] 50%|█████     | 3/6 [00:02<00:01,  1.96it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.78it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.62it/s]100%|██████████| 6/6 [00:02<00:00,  4.60it/s]100%|██████████| 6/6 [00:02<00:00,  2.32it/s]=> result
* total: 576
* correct: 454
* accuracy: 78.8%
* error: 21.2%
* macro_f1: 78.8%

epoch [22/30] batch [20/96] time 0.242 (0.292) data 0.000 (0.046) loss 0.1528 (0.3746) lr 2.0611e-03 eta 0:04:06
epoch [22/30] batch [40/96] time 0.242 (0.269) data 0.000 (0.023) loss 0.1272 (0.4344) lr 2.0611e-03 eta 0:03:41
epoch [22/30] batch [60/96] time 0.240 (0.263) data 0.000 (0.016) loss 0.0082 (0.4450) lr 2.0611e-03 eta 0:03:31
epoch [22/30] batch [80/96] time 0.233 (0.256) data 0.000 (0.012) loss 0.1587 (0.5058) lr 2.0611e-03 eta 0:03:20
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.82s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.20it/s] 50%|█████     | 3/6 [00:02<00:01,  1.96it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.78it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.61it/s]100%|██████████| 6/6 [00:02<00:00,  4.60it/s]100%|██████████| 6/6 [00:02<00:00,  2.32it/s]=> result
* total: 576
* correct: 450
* accuracy: 78.1%
* error: 21.9%
* macro_f1: 78.0%

epoch [23/30] batch [20/96] time 0.251 (0.292) data 0.000 (0.042) loss 0.4343 (0.4936) lr 1.6543e-03 eta 0:03:38
epoch [23/30] batch [40/96] time 0.247 (0.269) data 0.000 (0.021) loss 0.1012 (0.4584) lr 1.6543e-03 eta 0:03:15
epoch [23/30] batch [60/96] time 0.239 (0.263) data 0.000 (0.014) loss 0.5938 (0.4905) lr 1.6543e-03 eta 0:03:06
epoch [23/30] batch [80/96] time 0.231 (0.257) data 0.000 (0.011) loss 0.0435 (0.5222) lr 1.6543e-03 eta 0:02:56
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.83s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.20it/s] 50%|█████     | 3/6 [00:02<00:01,  1.95it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.78it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.62it/s]100%|██████████| 6/6 [00:02<00:00,  4.62it/s]100%|██████████| 6/6 [00:02<00:00,  2.32it/s]=> result
* total: 576
* correct: 454
* accuracy: 78.8%
* error: 21.2%
* macro_f1: 78.7%

epoch [24/30] batch [20/96] time 0.239 (0.287) data 0.000 (0.043) loss 0.3066 (0.3168) lr 1.2843e-03 eta 0:03:07
epoch [24/30] batch [40/96] time 0.243 (0.266) data 0.000 (0.021) loss 0.2107 (0.3808) lr 1.2843e-03 eta 0:02:48
epoch [24/30] batch [60/96] time 0.245 (0.260) data 0.000 (0.014) loss 1.1748 (0.4739) lr 1.2843e-03 eta 0:02:39
epoch [24/30] batch [80/96] time 0.230 (0.253) data 0.000 (0.011) loss 0.0462 (0.4580) lr 1.2843e-03 eta 0:02:29
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.74s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.26it/s] 50%|█████     | 3/6 [00:02<00:01,  2.03it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.86it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.70it/s]100%|██████████| 6/6 [00:02<00:00,  4.69it/s]100%|██████████| 6/6 [00:02<00:00,  2.39it/s]=> result
* total: 576
* correct: 453
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 78.7%

epoch [25/30] batch [20/96] time 0.241 (0.292) data 0.000 (0.042) loss 0.6440 (0.4170) lr 9.5492e-04 eta 0:02:42
epoch [25/30] batch [40/96] time 0.249 (0.270) data 0.000 (0.021) loss 0.1973 (0.4324) lr 9.5492e-04 eta 0:02:24
epoch [25/30] batch [60/96] time 0.326 (0.265) data 0.000 (0.014) loss 0.7354 (0.4450) lr 9.5492e-04 eta 0:02:16
epoch [25/30] batch [80/96] time 0.237 (0.258) data 0.000 (0.011) loss 0.1511 (0.5081) lr 9.5492e-04 eta 0:02:07
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.73s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.26it/s] 50%|█████     | 3/6 [00:01<00:01,  2.04it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.88it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.72it/s]100%|██████████| 6/6 [00:02<00:00,  4.71it/s]100%|██████████| 6/6 [00:02<00:00,  2.41it/s]=> result
* total: 576
* correct: 456
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 78.9%

epoch [26/30] batch [20/96] time 0.240 (0.295) data 0.000 (0.043) loss 0.0721 (0.5808) lr 6.6987e-04 eta 0:02:15
epoch [26/30] batch [40/96] time 0.245 (0.270) data 0.000 (0.022) loss 0.0452 (0.5603) lr 6.6987e-04 eta 0:01:58
epoch [26/30] batch [60/96] time 0.244 (0.263) data 0.000 (0.014) loss 0.1510 (0.5117) lr 6.6987e-04 eta 0:01:50
epoch [26/30] batch [80/96] time 0.230 (0.256) data 0.000 (0.011) loss 0.0442 (0.4978) lr 6.6987e-04 eta 0:01:42
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.76s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.22it/s] 50%|█████     | 3/6 [00:02<00:01,  1.98it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.81it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.65it/s]100%|██████████| 6/6 [00:02<00:00,  4.63it/s]100%|██████████| 6/6 [00:02<00:00,  2.36it/s]=> result
* total: 576
* correct: 457
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 79.3%

epoch [27/30] batch [20/96] time 0.238 (0.292) data 0.000 (0.042) loss 0.3213 (0.3677) lr 4.3227e-04 eta 0:01:46
epoch [27/30] batch [40/96] time 0.244 (0.268) data 0.000 (0.021) loss 1.2344 (0.3387) lr 4.3227e-04 eta 0:01:32
epoch [27/30] batch [60/96] time 0.243 (0.262) data 0.000 (0.014) loss 0.5156 (0.4016) lr 4.3227e-04 eta 0:01:24
epoch [27/30] batch [80/96] time 0.232 (0.256) data 0.000 (0.011) loss 1.5518 (0.4475) lr 4.3227e-04 eta 0:01:17
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.83s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.21it/s] 50%|█████     | 3/6 [00:02<00:01,  1.96it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.79it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.62it/s]100%|██████████| 6/6 [00:02<00:00,  4.61it/s]100%|██████████| 6/6 [00:02<00:00,  2.33it/s]=> result
* total: 576
* correct: 457
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 79.2%

epoch [28/30] batch [20/96] time 0.241 (0.291) data 0.000 (0.043) loss 0.1526 (0.4811) lr 2.4472e-04 eta 0:01:17
epoch [28/30] batch [40/96] time 0.243 (0.268) data 0.000 (0.022) loss 0.6562 (0.3685) lr 2.4472e-04 eta 0:01:06
epoch [28/30] batch [60/96] time 0.243 (0.262) data 0.000 (0.015) loss 0.3694 (0.3818) lr 2.4472e-04 eta 0:00:59
epoch [28/30] batch [80/96] time 0.232 (0.255) data 0.000 (0.011) loss 0.7861 (0.4151) lr 2.4472e-04 eta 0:00:53
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.85s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.16it/s] 50%|█████     | 3/6 [00:02<00:01,  1.89it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.71it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.54it/s]100%|██████████| 6/6 [00:02<00:00,  4.53it/s]100%|██████████| 6/6 [00:02<00:00,  2.28it/s]=> result
* total: 576
* correct: 457
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 79.2%

epoch [29/30] batch [20/96] time 0.241 (0.290) data 0.000 (0.043) loss 0.7939 (0.4268) lr 1.0926e-04 eta 0:00:49
epoch [29/30] batch [40/96] time 0.241 (0.267) data 0.000 (0.022) loss 0.6904 (0.4378) lr 1.0926e-04 eta 0:00:40
epoch [29/30] batch [60/96] time 0.237 (0.259) data 0.000 (0.015) loss 0.5356 (0.4855) lr 1.0926e-04 eta 0:00:34
epoch [29/30] batch [80/96] time 0.230 (0.253) data 0.000 (0.011) loss 0.0862 (0.4398) lr 1.0926e-04 eta 0:00:28
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.86s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.17it/s] 50%|█████     | 3/6 [00:02<00:01,  1.92it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.73it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.56it/s]100%|██████████| 6/6 [00:02<00:00,  4.54it/s]100%|██████████| 6/6 [00:02<00:00,  2.28it/s]=> result
* total: 576
* correct: 456
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 79.1%

epoch [30/30] batch [20/96] time 0.247 (0.293) data 0.000 (0.043) loss 0.1592 (0.2516) lr 2.7391e-05 eta 0:00:22
epoch [30/30] batch [40/96] time 0.249 (0.269) data 0.000 (0.022) loss 0.3613 (0.3544) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [60/96] time 0.243 (0.261) data 0.000 (0.015) loss 0.6016 (0.3078) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [80/96] time 0.232 (0.254) data 0.000 (0.011) loss 0.0934 (0.3423) lr 2.7391e-05 eta 0:00:04
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:08,  1.79s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.21it/s] 50%|█████     | 3/6 [00:02<00:01,  1.97it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.80it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.64it/s]100%|██████████| 6/6 [00:02<00:00,  4.62it/s]100%|██████████| 6/6 [00:02<00:00,  2.33it/s]
=> result
* total: 576
* correct: 456
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 79.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 20)
Evaluate on the *test* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:01<00:15,  1.91s/it] 22%|██▏       | 2/9 [00:02<00:06,  1.07it/s] 33%|███▎      | 3/9 [00:02<00:03,  1.77it/s] 44%|████▍     | 4/9 [00:02<00:01,  2.54it/s] 56%|█████▌    | 5/9 [00:02<00:01,  3.36it/s] 67%|██████▋   | 6/9 [00:02<00:00,  4.16it/s] 78%|███████▊  | 7/9 [00:02<00:00,  4.90it/s] 89%|████████▉ | 8/9 [00:02<00:00,  5.56it/s]100%|██████████| 9/9 [00:03<00:00,  2.86it/s]
=> result
* total: 864
* correct: 713
* accuracy: 82.5%
* error: 17.5%
* macro_f1: 82.5%
Elapsed: 0:13:32
+ sh scripts/rpo_prime/base2new_test_sdl.sh dtd 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
368 552 828
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  23
# train_x  368
# val      552
# test     828
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 20)
Evaluate on the *test* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:04<00:32,  4.11s/it] 22%|██▏       | 2/9 [00:04<00:12,  1.77s/it] 33%|███▎      | 3/9 [00:04<00:06,  1.02s/it] 44%|████▍     | 4/9 [00:04<00:03,  1.50it/s] 56%|█████▌    | 5/9 [00:04<00:01,  2.08it/s] 67%|██████▋   | 6/9 [00:04<00:01,  2.77it/s] 78%|███████▊  | 7/9 [00:04<00:00,  3.51it/s] 89%|████████▉ | 8/9 [00:05<00:00,  4.25it/s]100%|██████████| 9/9 [00:05<00:00,  1.71it/s]
=> result
* total: 828
* correct: 531
* accuracy: 64.1%
* error: 35.9%
* macro_f1: 63.0%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh dtd 3 0 main_tmp1_0.1sdl 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
384 576 864
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  24
# train_x  384
# val      576
# test     864
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/96] time 0.247 (0.397) data 0.000 (0.068) loss 3.4023 (2.8131) lr 1.0000e-02 eta 0:18:56
epoch [1/30] batch [40/96] time 0.245 (0.323) data 0.000 (0.034) loss 4.6875 (2.9767) lr 1.0000e-02 eta 0:15:18
epoch [1/30] batch [60/96] time 0.244 (0.298) data 0.000 (0.023) loss 1.5684 (2.9503) lr 1.0000e-02 eta 0:14:00
epoch [1/30] batch [80/96] time 0.230 (0.282) data 0.000 (0.017) loss 3.2402 (2.8893) lr 1.0000e-02 eta 0:13:10
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.94s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.14it/s] 50%|█████     | 3/6 [00:02<00:01,  1.87it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.67it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.50it/s]100%|██████████| 6/6 [00:02<00:00,  4.46it/s]100%|██████████| 6/6 [00:02<00:00,  2.22it/s]=> result
* total: 576
* correct: 353
* accuracy: 61.3%
* error: 38.7%
* macro_f1: 59.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/96] time 0.237 (0.300) data 0.000 (0.046) loss 0.9761 (2.5779) lr 9.9726e-03 eta 0:13:48
epoch [2/30] batch [40/96] time 0.241 (0.271) data 0.000 (0.023) loss 1.8848 (2.4983) lr 9.9726e-03 eta 0:12:24
epoch [2/30] batch [60/96] time 0.297 (0.263) data 0.000 (0.015) loss 0.9907 (2.4481) lr 9.9726e-03 eta 0:11:57
epoch [2/30] batch [80/96] time 0.228 (0.255) data 0.000 (0.012) loss 1.4971 (2.5454) lr 9.9726e-03 eta 0:11:30
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.95s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.12it/s] 50%|█████     | 3/6 [00:02<00:01,  1.84it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.64it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.47it/s]100%|██████████| 6/6 [00:02<00:00,  4.44it/s]100%|██████████| 6/6 [00:02<00:00,  2.18it/s]=> result
* total: 576
* correct: 359
* accuracy: 62.3%
* error: 37.7%
* macro_f1: 59.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/96] time 0.246 (0.298) data 0.000 (0.046) loss 1.6797 (2.6049) lr 9.8907e-03 eta 0:13:14
epoch [3/30] batch [40/96] time 0.253 (0.271) data 0.000 (0.023) loss 2.4180 (2.4499) lr 9.8907e-03 eta 0:11:58
epoch [3/30] batch [60/96] time 0.243 (0.262) data 0.000 (0.016) loss 5.0195 (2.3223) lr 9.8907e-03 eta 0:11:27
epoch [3/30] batch [80/96] time 0.231 (0.256) data 0.000 (0.012) loss 1.4668 (2.3364) lr 9.8907e-03 eta 0:11:08
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.88s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.14it/s] 50%|█████     | 3/6 [00:02<00:01,  1.87it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.67it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.50it/s]100%|██████████| 6/6 [00:02<00:00,  4.47it/s]100%|██████████| 6/6 [00:02<00:00,  2.23it/s]=> result
* total: 576
* correct: 372
* accuracy: 64.6%
* error: 35.4%
* macro_f1: 62.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/96] time 0.243 (0.295) data 0.000 (0.047) loss 1.2256 (1.9130) lr 9.7553e-03 eta 0:12:38
epoch [4/30] batch [40/96] time 0.236 (0.270) data 0.000 (0.024) loss 3.7129 (2.1236) lr 9.7553e-03 eta 0:11:30
epoch [4/30] batch [60/96] time 0.248 (0.262) data 0.000 (0.016) loss 1.6562 (2.1232) lr 9.7553e-03 eta 0:11:03
epoch [4/30] batch [80/96] time 0.228 (0.255) data 0.000 (0.012) loss 4.5703 (2.0835) lr 9.7553e-03 eta 0:10:39
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.93s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.15it/s] 50%|█████     | 3/6 [00:02<00:01,  1.87it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.68it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.50it/s]100%|██████████| 6/6 [00:02<00:00,  4.48it/s]100%|██████████| 6/6 [00:02<00:00,  2.22it/s]=> result
* total: 576
* correct: 384
* accuracy: 66.7%
* error: 33.3%
* macro_f1: 65.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/96] time 0.241 (0.298) data 0.000 (0.046) loss 2.4453 (1.5139) lr 9.5677e-03 eta 0:12:17
epoch [5/30] batch [40/96] time 0.249 (0.271) data 0.000 (0.023) loss 2.3984 (1.8567) lr 9.5677e-03 eta 0:11:04
epoch [5/30] batch [60/96] time 0.244 (0.261) data 0.000 (0.015) loss 4.1758 (1.8558) lr 9.5677e-03 eta 0:10:36
epoch [5/30] batch [80/96] time 0.228 (0.254) data 0.000 (0.012) loss 1.0654 (1.8647) lr 9.5677e-03 eta 0:10:14
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.96s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.12it/s] 50%|█████     | 3/6 [00:02<00:01,  1.84it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.63it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.45it/s]100%|██████████| 6/6 [00:02<00:00,  4.42it/s]100%|██████████| 6/6 [00:02<00:00,  2.18it/s]=> result
* total: 576
* correct: 415
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 70.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/96] time 0.239 (0.293) data 0.000 (0.046) loss 0.6875 (1.5544) lr 9.3301e-03 eta 0:11:36
epoch [6/30] batch [40/96] time 0.248 (0.270) data 0.000 (0.023) loss 0.9585 (1.6639) lr 9.3301e-03 eta 0:10:37
epoch [6/30] batch [60/96] time 0.244 (0.262) data 0.000 (0.015) loss 2.9629 (1.7293) lr 9.3301e-03 eta 0:10:13
epoch [6/30] batch [80/96] time 0.230 (0.255) data 0.000 (0.012) loss -0.0079 (1.7904) lr 9.3301e-03 eta 0:09:51
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.89s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.16it/s] 50%|█████     | 3/6 [00:02<00:01,  1.90it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.69it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.52it/s]100%|██████████| 6/6 [00:02<00:00,  4.50it/s]100%|██████████| 6/6 [00:02<00:00,  2.24it/s]=> result
* total: 576
* correct: 422
* accuracy: 73.3%
* error: 26.7%
* macro_f1: 72.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/96] time 0.233 (0.293) data 0.000 (0.047) loss 1.3965 (1.3731) lr 9.0451e-03 eta 0:11:09
epoch [7/30] batch [40/96] time 0.373 (0.271) data 0.000 (0.023) loss 0.6904 (1.7940) lr 9.0451e-03 eta 0:10:12
epoch [7/30] batch [60/96] time 0.235 (0.261) data 0.000 (0.016) loss 0.7661 (1.7581) lr 9.0451e-03 eta 0:09:45
epoch [7/30] batch [80/96] time 0.229 (0.254) data 0.000 (0.012) loss 0.2048 (1.6673) lr 9.0451e-03 eta 0:09:24
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.91s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.16it/s] 50%|█████     | 3/6 [00:02<00:01,  1.89it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.69it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.50it/s]100%|██████████| 6/6 [00:02<00:00,  4.48it/s]100%|██████████| 6/6 [00:02<00:00,  2.23it/s]=> result
* total: 576
* correct: 428
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/96] time 0.242 (0.300) data 0.000 (0.046) loss 1.7461 (1.2308) lr 8.7157e-03 eta 0:10:56
epoch [8/30] batch [40/96] time 0.245 (0.272) data 0.000 (0.023) loss 1.5547 (1.2776) lr 8.7157e-03 eta 0:09:49
epoch [8/30] batch [60/96] time 0.238 (0.263) data 0.000 (0.016) loss 1.8047 (1.2029) lr 8.7157e-03 eta 0:09:25
epoch [8/30] batch [80/96] time 0.230 (0.255) data 0.000 (0.012) loss 0.2668 (1.3495) lr 8.7157e-03 eta 0:09:03
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.89s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.16it/s] 50%|█████     | 3/6 [00:02<00:01,  1.90it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.70it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.53it/s]100%|██████████| 6/6 [00:02<00:00,  4.51it/s]100%|██████████| 6/6 [00:02<00:00,  2.23it/s]=> result
* total: 576
* correct: 443
* accuracy: 76.9%
* error: 23.1%
* macro_f1: 76.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/96] time 0.246 (0.293) data 0.000 (0.047) loss 1.1777 (1.4720) lr 8.3457e-03 eta 0:10:12
epoch [9/30] batch [40/96] time 0.241 (0.270) data 0.000 (0.023) loss 0.9810 (1.1837) lr 8.3457e-03 eta 0:09:18
epoch [9/30] batch [60/96] time 0.242 (0.260) data 0.000 (0.016) loss 1.7246 (1.1104) lr 8.3457e-03 eta 0:08:54
epoch [9/30] batch [80/96] time 0.231 (0.254) data 0.000 (0.012) loss 2.3750 (1.2625) lr 8.3457e-03 eta 0:08:35
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.86s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.18it/s] 50%|█████     | 3/6 [00:02<00:01,  1.93it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.73it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.56it/s]100%|██████████| 6/6 [00:02<00:00,  4.54it/s]100%|██████████| 6/6 [00:02<00:00,  2.26it/s]=> result
* total: 576
* correct: 443
* accuracy: 76.9%
* error: 23.1%
* macro_f1: 76.0%

epoch [10/30] batch [20/96] time 0.236 (0.293) data 0.000 (0.050) loss 1.4609 (1.3491) lr 7.9389e-03 eta 0:09:44
epoch [10/30] batch [40/96] time 0.241 (0.268) data 0.000 (0.025) loss 0.0042 (1.2018) lr 7.9389e-03 eta 0:08:49
epoch [10/30] batch [60/96] time 0.238 (0.260) data 0.000 (0.017) loss 0.9346 (1.2100) lr 7.9389e-03 eta 0:08:29
epoch [10/30] batch [80/96] time 0.232 (0.253) data 0.000 (0.013) loss 0.3638 (1.1922) lr 7.9389e-03 eta 0:08:09
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.91s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.13it/s] 50%|█████     | 3/6 [00:02<00:01,  1.85it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.65it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.43it/s]100%|██████████| 6/6 [00:02<00:00,  4.40it/s]100%|██████████| 6/6 [00:02<00:00,  2.20it/s]=> result
* total: 576
* correct: 446
* accuracy: 77.4%
* error: 22.6%
* macro_f1: 77.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/96] time 0.237 (0.301) data 0.000 (0.047) loss 0.8213 (1.2166) lr 7.5000e-03 eta 0:09:32
epoch [11/30] batch [40/96] time 0.239 (0.271) data 0.000 (0.023) loss 0.2351 (0.9380) lr 7.5000e-03 eta 0:08:29
epoch [11/30] batch [60/96] time 0.250 (0.262) data 0.000 (0.016) loss 1.5293 (1.0694) lr 7.5000e-03 eta 0:08:07
epoch [11/30] batch [80/96] time 0.233 (0.256) data 0.000 (0.012) loss 0.7817 (1.1295) lr 7.5000e-03 eta 0:07:50
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.88s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.15it/s] 50%|█████     | 3/6 [00:02<00:01,  1.89it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.69it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.50it/s]100%|██████████| 6/6 [00:02<00:00,  4.48it/s]100%|██████████| 6/6 [00:02<00:00,  2.24it/s]=> result
* total: 576
* correct: 437
* accuracy: 75.9%
* error: 24.1%
* macro_f1: 75.6%

epoch [12/30] batch [20/96] time 0.240 (0.290) data 0.000 (0.046) loss 0.7930 (1.0744) lr 7.0337e-03 eta 0:08:42
epoch [12/30] batch [40/96] time 0.256 (0.266) data 0.000 (0.023) loss 0.8594 (1.1052) lr 7.0337e-03 eta 0:07:54
epoch [12/30] batch [60/96] time 0.244 (0.260) data 0.000 (0.015) loss 0.5210 (1.0429) lr 7.0337e-03 eta 0:07:39
epoch [12/30] batch [80/96] time 0.230 (0.253) data 0.000 (0.012) loss 1.4453 (0.9728) lr 7.0337e-03 eta 0:07:22
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.89s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.17it/s] 50%|█████     | 3/6 [00:02<00:01,  1.91it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.68it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.51it/s]100%|██████████| 6/6 [00:02<00:00,  4.49it/s]100%|██████████| 6/6 [00:02<00:00,  2.24it/s]=> result
* total: 576
* correct: 455
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 78.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [13/30] batch [20/96] time 0.251 (0.297) data 0.000 (0.046) loss 2.0273 (0.9205) lr 6.5451e-03 eta 0:08:26
epoch [13/30] batch [40/96] time 0.241 (0.270) data 0.000 (0.023) loss 0.5435 (1.0234) lr 6.5451e-03 eta 0:07:35
epoch [13/30] batch [60/96] time 0.249 (0.262) data 0.000 (0.016) loss 1.1885 (1.0611) lr 6.5451e-03 eta 0:07:17
epoch [13/30] batch [80/96] time 0.232 (0.255) data 0.000 (0.012) loss 1.5967 (1.0729) lr 6.5451e-03 eta 0:07:00
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.86s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.16it/s] 50%|█████     | 3/6 [00:02<00:01,  1.90it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.71it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.54it/s]100%|██████████| 6/6 [00:02<00:00,  4.52it/s]100%|██████████| 6/6 [00:02<00:00,  2.25it/s]=> result
* total: 576
* correct: 451
* accuracy: 78.3%
* error: 21.7%
* macro_f1: 77.9%

epoch [14/30] batch [20/96] time 0.237 (0.293) data 0.000 (0.048) loss 3.4160 (0.8536) lr 6.0396e-03 eta 0:07:52
epoch [14/30] batch [40/96] time 0.245 (0.273) data 0.000 (0.024) loss 0.9663 (0.7976) lr 6.0396e-03 eta 0:07:13
epoch [14/30] batch [60/96] time 0.239 (0.262) data 0.000 (0.016) loss 0.0655 (1.0382) lr 6.0396e-03 eta 0:06:52
epoch [14/30] batch [80/96] time 0.231 (0.255) data 0.000 (0.012) loss 1.0869 (1.0263) lr 6.0396e-03 eta 0:06:35
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:02<00:10,  2.03s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.09it/s] 50%|█████     | 3/6 [00:02<00:01,  1.79it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.57it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.37it/s]100%|██████████| 6/6 [00:02<00:00,  4.34it/s]100%|██████████| 6/6 [00:02<00:00,  2.13it/s]=> result
* total: 576
* correct: 449
* accuracy: 78.0%
* error: 22.0%
* macro_f1: 77.7%

epoch [15/30] batch [20/96] time 0.252 (0.298) data 0.000 (0.050) loss 1.0605 (0.6134) lr 5.5226e-03 eta 0:07:31
epoch [15/30] batch [40/96] time 0.239 (0.271) data 0.000 (0.025) loss 1.5391 (0.6206) lr 5.5226e-03 eta 0:06:44
epoch [15/30] batch [60/96] time 0.241 (0.261) data 0.000 (0.017) loss 1.9580 (0.6724) lr 5.5226e-03 eta 0:06:25
epoch [15/30] batch [80/96] time 0.229 (0.255) data 0.000 (0.013) loss 1.0986 (0.7684) lr 5.5226e-03 eta 0:06:10
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.90s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.15it/s] 50%|█████     | 3/6 [00:02<00:01,  1.88it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.69it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.50it/s]100%|██████████| 6/6 [00:02<00:00,  4.48it/s]100%|██████████| 6/6 [00:02<00:00,  2.23it/s]=> result
* total: 576
* correct: 456
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 78.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [16/30] batch [20/96] time 0.255 (0.294) data 0.000 (0.046) loss 1.4688 (0.9005) lr 5.0000e-03 eta 0:06:56
epoch [16/30] batch [40/96] time 0.247 (0.268) data 0.000 (0.023) loss 0.8945 (0.8433) lr 5.0000e-03 eta 0:06:15
epoch [16/30] batch [60/96] time 0.234 (0.260) data 0.000 (0.016) loss 0.3564 (0.8536) lr 5.0000e-03 eta 0:05:58
epoch [16/30] batch [80/96] time 0.229 (0.253) data 0.000 (0.012) loss 0.4988 (0.9304) lr 5.0000e-03 eta 0:05:44
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.92s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.15it/s] 50%|█████     | 3/6 [00:02<00:01,  1.87it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.66it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.48it/s]100%|██████████| 6/6 [00:02<00:00,  4.45it/s]100%|██████████| 6/6 [00:02<00:00,  2.21it/s]=> result
* total: 576
* correct: 451
* accuracy: 78.3%
* error: 21.7%
* macro_f1: 78.1%

epoch [17/30] batch [20/96] time 0.248 (0.297) data 0.000 (0.047) loss 0.4893 (0.6864) lr 4.4774e-03 eta 0:06:32
epoch [17/30] batch [40/96] time 0.240 (0.270) data 0.000 (0.024) loss 1.1855 (0.7379) lr 4.4774e-03 eta 0:05:52
epoch [17/30] batch [60/96] time 0.244 (0.262) data 0.000 (0.016) loss 0.1215 (0.6663) lr 4.4774e-03 eta 0:05:36
epoch [17/30] batch [80/96] time 0.229 (0.254) data 0.000 (0.012) loss 0.1952 (0.7286) lr 4.4774e-03 eta 0:05:21
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.86s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.19it/s] 50%|█████     | 3/6 [00:02<00:01,  1.93it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.74it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.57it/s]100%|██████████| 6/6 [00:02<00:00,  4.55it/s]100%|██████████| 6/6 [00:02<00:00,  2.28it/s]=> result
* total: 576
* correct: 459
* accuracy: 79.7%
* error: 20.3%
* macro_f1: 79.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/96] time 0.240 (0.295) data 0.000 (0.048) loss 0.1338 (0.9490) lr 3.9604e-03 eta 0:06:02
epoch [18/30] batch [40/96] time 0.251 (0.272) data 0.000 (0.024) loss 0.2135 (0.8438) lr 3.9604e-03 eta 0:05:28
epoch [18/30] batch [60/96] time 0.249 (0.263) data 0.000 (0.016) loss 0.5796 (0.8013) lr 3.9604e-03 eta 0:05:12
epoch [18/30] batch [80/96] time 0.234 (0.256) data 0.000 (0.012) loss 1.5977 (0.7055) lr 3.9604e-03 eta 0:04:59
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.90s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.16it/s] 50%|█████     | 3/6 [00:02<00:01,  1.89it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.67it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.50it/s]100%|██████████| 6/6 [00:02<00:00,  4.47it/s]100%|██████████| 6/6 [00:02<00:00,  2.22it/s]=> result
* total: 576
* correct: 465
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 80.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/96] time 0.241 (0.298) data 0.000 (0.050) loss 0.8335 (0.8205) lr 3.4549e-03 eta 0:05:36
epoch [19/30] batch [40/96] time 0.240 (0.273) data 0.000 (0.025) loss 0.3672 (0.6943) lr 3.4549e-03 eta 0:05:03
epoch [19/30] batch [60/96] time 0.242 (0.262) data 0.000 (0.017) loss 0.8643 (0.6259) lr 3.4549e-03 eta 0:04:45
epoch [19/30] batch [80/96] time 0.229 (0.254) data 0.000 (0.013) loss 0.3589 (0.6525) lr 3.4549e-03 eta 0:04:32
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.84s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.18it/s] 50%|█████     | 3/6 [00:02<00:01,  1.93it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.70it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.53it/s]100%|██████████| 6/6 [00:02<00:00,  4.51it/s]100%|██████████| 6/6 [00:02<00:00,  2.27it/s]=> result
* total: 576
* correct: 458
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 79.6%

epoch [20/30] batch [20/96] time 0.242 (0.297) data 0.000 (0.047) loss -0.0208 (0.6941) lr 2.9663e-03 eta 0:05:07
epoch [20/30] batch [40/96] time 0.245 (0.271) data 0.000 (0.024) loss 0.5923 (0.7382) lr 2.9663e-03 eta 0:04:34
epoch [20/30] batch [60/96] time 0.238 (0.263) data 0.000 (0.016) loss 0.1606 (0.7413) lr 2.9663e-03 eta 0:04:22
epoch [20/30] batch [80/96] time 0.231 (0.256) data 0.000 (0.012) loss 0.2358 (0.7654) lr 2.9663e-03 eta 0:04:09
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.87s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.18it/s] 50%|█████     | 3/6 [00:02<00:01,  1.92it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.73it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.56it/s]100%|██████████| 6/6 [00:02<00:00,  4.52it/s]100%|██████████| 6/6 [00:02<00:00,  2.26it/s]=> result
* total: 576
* correct: 459
* accuracy: 79.7%
* error: 20.3%
* macro_f1: 79.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/96] time 0.241 (0.297) data 0.000 (0.047) loss 0.4421 (0.6692) lr 2.5000e-03 eta 0:04:38
epoch [21/30] batch [40/96] time 0.236 (0.268) data 0.000 (0.024) loss 0.4292 (0.5220) lr 2.5000e-03 eta 0:04:06
epoch [21/30] batch [60/96] time 0.245 (0.261) data 0.000 (0.016) loss 0.0408 (0.5279) lr 2.5000e-03 eta 0:03:54
epoch [21/30] batch [80/96] time 0.227 (0.254) data 0.000 (0.012) loss 0.3608 (0.6193) lr 2.5000e-03 eta 0:03:43
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:02<00:10,  2.08s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.05it/s] 50%|█████     | 3/6 [00:02<00:01,  1.73it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.50it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.31it/s]100%|██████████| 6/6 [00:02<00:00,  4.27it/s]100%|██████████| 6/6 [00:02<00:00,  2.08it/s]=> result
* total: 576
* correct: 463
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 80.4%

epoch [22/30] batch [20/96] time 0.243 (0.300) data 0.000 (0.047) loss 0.3928 (0.5869) lr 2.0611e-03 eta 0:04:13
epoch [22/30] batch [40/96] time 0.237 (0.272) data 0.000 (0.023) loss 0.1316 (0.5202) lr 2.0611e-03 eta 0:03:44
epoch [22/30] batch [60/96] time 0.242 (0.262) data 0.000 (0.016) loss 0.2235 (0.5771) lr 2.0611e-03 eta 0:03:31
epoch [22/30] batch [80/96] time 0.232 (0.256) data 0.001 (0.012) loss 0.2180 (0.6030) lr 2.0611e-03 eta 0:03:20
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.92s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.14it/s] 50%|█████     | 3/6 [00:02<00:01,  1.87it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.67it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.49it/s]100%|██████████| 6/6 [00:02<00:00,  4.44it/s]100%|██████████| 6/6 [00:02<00:00,  2.20it/s]=> result
* total: 576
* correct: 465
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 80.7%

epoch [23/30] batch [20/96] time 0.245 (0.296) data 0.000 (0.049) loss 0.7466 (0.8160) lr 1.6543e-03 eta 0:03:41
epoch [23/30] batch [40/96] time 0.240 (0.269) data 0.000 (0.025) loss 0.4976 (0.6776) lr 1.6543e-03 eta 0:03:15
epoch [23/30] batch [60/96] time 0.237 (0.261) data 0.000 (0.016) loss 0.4771 (0.6237) lr 1.6543e-03 eta 0:03:04
epoch [23/30] batch [80/96] time 0.226 (0.253) data 0.000 (0.012) loss 0.1694 (0.5731) lr 1.6543e-03 eta 0:02:54
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.86s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.18it/s] 50%|█████     | 3/6 [00:02<00:01,  1.91it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.72it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.55it/s]100%|██████████| 6/6 [00:02<00:00,  4.53it/s]100%|██████████| 6/6 [00:02<00:00,  2.27it/s]=> result
* total: 576
* correct: 463
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 80.4%

epoch [24/30] batch [20/96] time 0.244 (0.300) data 0.000 (0.052) loss 0.4819 (0.7383) lr 1.2843e-03 eta 0:03:15
epoch [24/30] batch [40/96] time 0.249 (0.272) data 0.000 (0.026) loss 0.2900 (0.5902) lr 1.2843e-03 eta 0:02:52
epoch [24/30] batch [60/96] time 0.247 (0.264) data 0.000 (0.017) loss 0.1727 (0.6297) lr 1.2843e-03 eta 0:02:41
epoch [24/30] batch [80/96] time 0.234 (0.256) data 0.000 (0.013) loss 0.2443 (0.5595) lr 1.2843e-03 eta 0:02:31
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.90s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.16it/s] 50%|█████     | 3/6 [00:02<00:01,  1.90it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.68it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.51it/s]100%|██████████| 6/6 [00:02<00:00,  4.49it/s]100%|██████████| 6/6 [00:02<00:00,  2.24it/s]=> result
* total: 576
* correct: 471
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 81.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [25/30] batch [20/96] time 0.238 (0.296) data 0.000 (0.048) loss 0.3364 (0.3679) lr 9.5492e-04 eta 0:02:44
epoch [25/30] batch [40/96] time 0.247 (0.268) data 0.000 (0.024) loss 0.2177 (0.4905) lr 9.5492e-04 eta 0:02:23
epoch [25/30] batch [60/96] time 0.237 (0.259) data 0.000 (0.016) loss 0.4338 (0.4247) lr 9.5492e-04 eta 0:02:13
epoch [25/30] batch [80/96] time 0.228 (0.253) data 0.000 (0.012) loss 1.1973 (0.4807) lr 9.5492e-04 eta 0:02:05
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.86s/it] 33%|███▎      | 2/6 [00:01<00:03,  1.19it/s] 50%|█████     | 3/6 [00:02<00:01,  1.93it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.74it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.58it/s]100%|██████████| 6/6 [00:02<00:00,  4.53it/s]100%|██████████| 6/6 [00:02<00:00,  2.27it/s]=> result
* total: 576
* correct: 469
* accuracy: 81.4%
* error: 18.6%
* macro_f1: 81.4%

epoch [26/30] batch [20/96] time 0.257 (0.296) data 0.000 (0.046) loss 1.0459 (0.4741) lr 6.6987e-04 eta 0:02:16
epoch [26/30] batch [40/96] time 0.245 (0.270) data 0.000 (0.023) loss 0.0717 (0.4933) lr 6.6987e-04 eta 0:01:58
epoch [26/30] batch [60/96] time 0.249 (0.261) data 0.000 (0.015) loss -0.0151 (0.4466) lr 6.6987e-04 eta 0:01:49
epoch [26/30] batch [80/96] time 0.230 (0.254) data 0.000 (0.012) loss 0.2390 (0.4863) lr 6.6987e-04 eta 0:01:41
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.93s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.14it/s] 50%|█████     | 3/6 [00:02<00:01,  1.86it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.65it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.48it/s]100%|██████████| 6/6 [00:02<00:00,  4.45it/s]100%|██████████| 6/6 [00:02<00:00,  2.19it/s]=> result
* total: 576
* correct: 464
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 80.6%

epoch [27/30] batch [20/96] time 0.246 (0.294) data 0.000 (0.047) loss 1.2422 (0.4923) lr 4.3227e-04 eta 0:01:47
epoch [27/30] batch [40/96] time 0.242 (0.268) data 0.000 (0.023) loss 0.0480 (0.5682) lr 4.3227e-04 eta 0:01:32
epoch [27/30] batch [60/96] time 0.246 (0.260) data 0.000 (0.016) loss 0.4690 (0.5440) lr 4.3227e-04 eta 0:01:24
epoch [27/30] batch [80/96] time 0.229 (0.253) data 0.000 (0.012) loss 0.1967 (0.5813) lr 4.3227e-04 eta 0:01:16
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:02<00:10,  2.05s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.08it/s] 50%|█████     | 3/6 [00:02<00:01,  1.76it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.54it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.35it/s]100%|██████████| 6/6 [00:02<00:00,  4.31it/s]100%|██████████| 6/6 [00:02<00:00,  2.11it/s]=> result
* total: 576
* correct: 466
* accuracy: 80.9%
* error: 19.1%
* macro_f1: 80.9%

epoch [28/30] batch [20/96] time 0.240 (0.301) data 0.000 (0.048) loss 0.1392 (0.3134) lr 2.4472e-04 eta 0:01:20
epoch [28/30] batch [40/96] time 0.235 (0.271) data 0.000 (0.024) loss 0.0094 (0.4406) lr 2.4472e-04 eta 0:01:07
epoch [28/30] batch [60/96] time 0.241 (0.261) data 0.000 (0.016) loss 0.0867 (0.5140) lr 2.4472e-04 eta 0:00:59
epoch [28/30] batch [80/96] time 0.231 (0.254) data 0.000 (0.012) loss 1.6514 (0.5531) lr 2.4472e-04 eta 0:00:52
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.89s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.15it/s] 50%|█████     | 3/6 [00:02<00:01,  1.88it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.68it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.51it/s]100%|██████████| 6/6 [00:02<00:00,  4.49it/s]100%|██████████| 6/6 [00:02<00:00,  2.22it/s]=> result
* total: 576
* correct: 467
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 81.0%

epoch [29/30] batch [20/96] time 0.245 (0.301) data 0.000 (0.046) loss 0.5234 (0.6644) lr 1.0926e-04 eta 0:00:51
epoch [29/30] batch [40/96] time 0.240 (0.273) data 0.000 (0.023) loss 0.1225 (0.4596) lr 1.0926e-04 eta 0:00:41
epoch [29/30] batch [60/96] time 0.250 (0.264) data 0.000 (0.016) loss 0.3337 (0.4447) lr 1.0926e-04 eta 0:00:34
epoch [29/30] batch [80/96] time 0.228 (0.257) data 0.000 (0.012) loss 0.1925 (0.4543) lr 1.0926e-04 eta 0:00:28
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.96s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.13it/s] 50%|█████     | 3/6 [00:02<00:01,  1.85it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.64it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.47it/s]100%|██████████| 6/6 [00:02<00:00,  4.45it/s]100%|██████████| 6/6 [00:02<00:00,  2.19it/s]=> result
* total: 576
* correct: 467
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 81.0%

epoch [30/30] batch [20/96] time 0.237 (0.301) data 0.000 (0.050) loss 0.0932 (0.3837) lr 2.7391e-05 eta 0:00:22
epoch [30/30] batch [40/96] time 0.242 (0.273) data 0.000 (0.025) loss 0.5435 (0.4673) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [60/96] time 0.252 (0.266) data 0.000 (0.017) loss 1.2207 (0.4739) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [80/96] time 0.233 (0.258) data 0.000 (0.013) loss 0.5371 (0.4421) lr 2.7391e-05 eta 0:00:04
Evaluate on the *val* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:01<00:09,  1.96s/it] 33%|███▎      | 2/6 [00:02<00:03,  1.12it/s] 50%|█████     | 3/6 [00:02<00:01,  1.83it/s] 67%|██████▋   | 4/6 [00:02<00:00,  2.62it/s] 83%|████████▎ | 5/6 [00:02<00:00,  3.45it/s]100%|██████████| 6/6 [00:02<00:00,  4.43it/s]100%|██████████| 6/6 [00:02<00:00,  2.18it/s]
=> result
* total: 576
* correct: 468
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 81.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 24)
Evaluate on the *test* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:17,  2.20s/it] 22%|██▏       | 2/9 [00:02<00:06,  1.02it/s] 33%|███▎      | 3/9 [00:02<00:03,  1.68it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.42it/s] 56%|█████▌    | 5/9 [00:02<00:01,  3.22it/s] 67%|██████▋   | 6/9 [00:02<00:00,  4.03it/s] 78%|███████▊  | 7/9 [00:02<00:00,  4.79it/s] 89%|████████▉ | 8/9 [00:03<00:00,  5.47it/s]100%|██████████| 9/9 [00:03<00:00,  2.67it/s]
=> result
* total: 864
* correct: 712
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 81.9%
Elapsed: 0:13:34
+ sh scripts/rpo_prime/base2new_test_sdl.sh dtd 3 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
368 552 828
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  23
# train_x  368
# val      552
# test     828
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/dtd/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 24)
Evaluate on the *test* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:04<00:33,  4.23s/it] 22%|██▏       | 2/9 [00:04<00:12,  1.82s/it] 33%|███▎      | 3/9 [00:04<00:06,  1.05s/it] 44%|████▍     | 4/9 [00:04<00:03,  1.46it/s] 56%|█████▌    | 5/9 [00:04<00:01,  2.07it/s] 67%|██████▋   | 6/9 [00:04<00:01,  2.76it/s] 78%|███████▊  | 7/9 [00:05<00:00,  3.49it/s] 89%|████████▉ | 8/9 [00:05<00:00,  4.24it/s]100%|██████████| 9/9 [00:05<00:00,  1.68it/s]
=> result
* total: 828
* correct: 542
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 64.3%
+ for dataset in eurosat dtd oxford_flowers stanford_cars oxford_pets food101 ucf101 caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh oxford_flowers 1 0 main_tmp1_0.1sdl 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
816 696 1053
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      696
# test     1,053
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/204] time 0.266 (0.411) data 0.000 (0.058) loss 2.7148 (3.2298) lr 1.0000e-02 eta 0:41:45
epoch [1/30] batch [40/204] time 0.265 (0.340) data 0.000 (0.029) loss 1.5625 (3.0588) lr 1.0000e-02 eta 0:34:28
epoch [1/30] batch [60/204] time 0.279 (0.317) data 0.000 (0.020) loss 2.4375 (3.0373) lr 1.0000e-02 eta 0:31:58
epoch [1/30] batch [80/204] time 0.262 (0.305) data 0.000 (0.015) loss 0.7837 (2.8527) lr 1.0000e-02 eta 0:30:44
epoch [1/30] batch [100/204] time 0.267 (0.298) data 0.000 (0.012) loss 2.7656 (2.8892) lr 1.0000e-02 eta 0:29:56
epoch [1/30] batch [120/204] time 0.277 (0.295) data 0.000 (0.010) loss 1.9941 (2.8410) lr 1.0000e-02 eta 0:29:29
epoch [1/30] batch [140/204] time 0.269 (0.291) data 0.000 (0.009) loss 2.3008 (2.7947) lr 1.0000e-02 eta 0:29:00
epoch [1/30] batch [160/204] time 0.268 (0.288) data 0.000 (0.007) loss 1.5850 (2.7266) lr 1.0000e-02 eta 0:28:37
epoch [1/30] batch [180/204] time 0.253 (0.285) data 0.000 (0.007) loss 0.1393 (2.7076) lr 1.0000e-02 eta 0:28:14
epoch [1/30] batch [200/204] time 0.253 (0.283) data 0.000 (0.006) loss 3.2598 (2.7001) lr 1.0000e-02 eta 0:27:52
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:14,  2.42s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.08s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.55it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.25it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.01it/s] 86%|████████▌ | 6/7 [00:03<00:00,  3.77it/s]100%|██████████| 7/7 [00:03<00:00,  4.51it/s]100%|██████████| 7/7 [00:03<00:00,  2.08it/s]=> result
* total: 696
* correct: 514
* accuracy: 73.9%
* error: 26.1%
* macro_f1: 68.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/204] time 0.271 (0.325) data 0.000 (0.051) loss 1.9805 (2.3106) lr 9.9726e-03 eta 0:31:57
epoch [2/30] batch [40/204] time 0.267 (0.297) data 0.000 (0.025) loss 2.5605 (2.1010) lr 9.9726e-03 eta 0:29:03
epoch [2/30] batch [60/204] time 0.268 (0.288) data 0.000 (0.017) loss 3.9297 (2.0346) lr 9.9726e-03 eta 0:28:04
epoch [2/30] batch [80/204] time 0.278 (0.284) data 0.000 (0.013) loss 2.0605 (2.0557) lr 9.9726e-03 eta 0:27:39
epoch [2/30] batch [100/204] time 0.267 (0.281) data 0.000 (0.010) loss 1.7178 (2.0044) lr 9.9726e-03 eta 0:27:16
epoch [2/30] batch [120/204] time 0.264 (0.279) data 0.000 (0.009) loss 0.5679 (1.9909) lr 9.9726e-03 eta 0:26:57
epoch [2/30] batch [140/204] time 0.261 (0.278) data 0.000 (0.007) loss 1.4531 (2.0198) lr 9.9726e-03 eta 0:26:45
epoch [2/30] batch [160/204] time 0.273 (0.277) data 0.000 (0.007) loss 2.0098 (2.0704) lr 9.9726e-03 eta 0:26:34
epoch [2/30] batch [180/204] time 0.254 (0.275) data 0.000 (0.006) loss 0.1530 (2.0166) lr 9.9726e-03 eta 0:26:20
epoch [2/30] batch [200/204] time 0.251 (0.273) data 0.000 (0.005) loss 2.4512 (2.0095) lr 9.9726e-03 eta 0:26:02
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.25s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.01s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.64it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.37it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.13it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.90it/s]100%|██████████| 7/7 [00:03<00:00,  4.63it/s]100%|██████████| 7/7 [00:03<00:00,  2.17it/s]=> result
* total: 696
* correct: 547
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 74.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/204] time 0.268 (0.321) data 0.000 (0.049) loss 3.9258 (2.0642) lr 9.8907e-03 eta 0:30:26
epoch [3/30] batch [40/204] time 0.266 (0.297) data 0.000 (0.025) loss 1.2549 (1.9744) lr 9.8907e-03 eta 0:28:05
epoch [3/30] batch [60/204] time 0.264 (0.287) data 0.000 (0.017) loss 0.5005 (2.0264) lr 9.8907e-03 eta 0:27:02
epoch [3/30] batch [80/204] time 0.269 (0.282) data 0.000 (0.012) loss 6.1406 (1.9121) lr 9.8907e-03 eta 0:26:30
epoch [3/30] batch [100/204] time 0.270 (0.279) data 0.000 (0.010) loss 4.4219 (2.0386) lr 9.8907e-03 eta 0:26:05
epoch [3/30] batch [120/204] time 0.263 (0.277) data 0.000 (0.008) loss 1.8535 (1.9802) lr 9.8907e-03 eta 0:25:49
epoch [3/30] batch [140/204] time 0.265 (0.276) data 0.001 (0.007) loss 0.9316 (1.9351) lr 9.8907e-03 eta 0:25:38
epoch [3/30] batch [160/204] time 0.273 (0.276) data 0.000 (0.006) loss 0.6279 (1.9412) lr 9.8907e-03 eta 0:25:31
epoch [3/30] batch [180/204] time 0.254 (0.274) data 0.000 (0.006) loss 0.9736 (1.9400) lr 9.8907e-03 eta 0:25:18
epoch [3/30] batch [200/204] time 0.253 (0.273) data 0.000 (0.005) loss 0.9038 (1.9360) lr 9.8907e-03 eta 0:25:03
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.12s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.02it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.69it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.43it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.20it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.96it/s]100%|██████████| 7/7 [00:02<00:00,  4.69it/s]100%|██████████| 7/7 [00:03<00:00,  2.25it/s]=> result
* total: 696
* correct: 551
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 75.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/204] time 0.264 (0.324) data 0.000 (0.052) loss 2.0215 (1.6551) lr 9.7553e-03 eta 0:29:37
epoch [4/30] batch [40/204] time 0.267 (0.297) data 0.000 (0.026) loss 0.5640 (1.4566) lr 9.7553e-03 eta 0:27:02
epoch [4/30] batch [60/204] time 0.264 (0.287) data 0.000 (0.017) loss 0.3899 (1.7776) lr 9.7553e-03 eta 0:26:06
epoch [4/30] batch [80/204] time 0.274 (0.283) data 0.000 (0.013) loss 1.5273 (1.7728) lr 9.7553e-03 eta 0:25:35
epoch [4/30] batch [100/204] time 0.261 (0.282) data 0.000 (0.011) loss 0.2739 (1.7765) lr 9.7553e-03 eta 0:25:22
epoch [4/30] batch [120/204] time 0.264 (0.279) data 0.000 (0.009) loss 3.3281 (1.7742) lr 9.7553e-03 eta 0:25:05
epoch [4/30] batch [140/204] time 0.267 (0.278) data 0.000 (0.008) loss 0.8403 (1.7549) lr 9.7553e-03 eta 0:24:49
epoch [4/30] batch [160/204] time 0.269 (0.276) data 0.000 (0.007) loss 6.1055 (1.7473) lr 9.7553e-03 eta 0:24:37
epoch [4/30] batch [180/204] time 0.253 (0.275) data 0.000 (0.006) loss 3.1641 (1.7603) lr 9.7553e-03 eta 0:24:27
epoch [4/30] batch [200/204] time 0.253 (0.273) data 0.000 (0.005) loss 2.1211 (1.7313) lr 9.7553e-03 eta 0:24:10
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.14s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.02it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.68it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.40it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.18it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.93it/s]100%|██████████| 7/7 [00:02<00:00,  4.66it/s]100%|██████████| 7/7 [00:03<00:00,  2.24it/s]=> result
* total: 696
* correct: 572
* accuracy: 82.2%
* error: 17.8%
* macro_f1: 79.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/204] time 0.279 (0.326) data 0.000 (0.050) loss 1.4043 (1.8599) lr 9.5677e-03 eta 0:28:42
epoch [5/30] batch [40/204] time 0.268 (0.300) data 0.000 (0.025) loss 0.2014 (1.6977) lr 9.5677e-03 eta 0:26:18
epoch [5/30] batch [60/204] time 0.264 (0.289) data 0.000 (0.017) loss 2.2168 (1.6358) lr 9.5677e-03 eta 0:25:16
epoch [5/30] batch [80/204] time 0.267 (0.285) data 0.000 (0.013) loss 1.7002 (1.6778) lr 9.5677e-03 eta 0:24:49
epoch [5/30] batch [100/204] time 0.273 (0.282) data 0.000 (0.010) loss 1.8496 (1.6738) lr 9.5677e-03 eta 0:24:28
epoch [5/30] batch [120/204] time 0.277 (0.280) data 0.000 (0.009) loss 0.5693 (1.6136) lr 9.5677e-03 eta 0:24:11
epoch [5/30] batch [140/204] time 0.264 (0.278) data 0.000 (0.007) loss 1.7236 (1.6103) lr 9.5677e-03 eta 0:23:56
epoch [5/30] batch [160/204] time 0.265 (0.277) data 0.000 (0.006) loss 1.9395 (1.6363) lr 9.5677e-03 eta 0:23:42
epoch [5/30] batch [180/204] time 0.249 (0.275) data 0.000 (0.006) loss 2.4766 (1.6552) lr 9.5677e-03 eta 0:23:29
epoch [5/30] batch [200/204] time 0.250 (0.273) data 0.000 (0.005) loss 0.8110 (1.5965) lr 9.5677e-03 eta 0:23:14
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.28s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.02s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.62it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.34it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.10it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.87it/s]100%|██████████| 7/7 [00:03<00:00,  4.60it/s]100%|██████████| 7/7 [00:03<00:00,  2.17it/s]=> result
* total: 696
* correct: 579
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 80.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/204] time 0.275 (0.326) data 0.000 (0.050) loss 2.0879 (1.3773) lr 9.3301e-03 eta 0:27:38
epoch [6/30] batch [40/204] time 0.268 (0.298) data 0.000 (0.025) loss 1.5244 (1.3593) lr 9.3301e-03 eta 0:25:08
epoch [6/30] batch [60/204] time 0.268 (0.288) data 0.000 (0.017) loss 1.9990 (1.4120) lr 9.3301e-03 eta 0:24:12
epoch [6/30] batch [80/204] time 0.277 (0.284) data 0.000 (0.013) loss 1.2148 (1.4639) lr 9.3301e-03 eta 0:23:44
epoch [6/30] batch [100/204] time 0.275 (0.282) data 0.000 (0.010) loss 0.1234 (1.5009) lr 9.3301e-03 eta 0:23:32
epoch [6/30] batch [120/204] time 0.271 (0.280) data 0.000 (0.009) loss 1.2910 (1.4991) lr 9.3301e-03 eta 0:23:15
epoch [6/30] batch [140/204] time 0.271 (0.279) data 0.000 (0.007) loss 1.8262 (1.5024) lr 9.3301e-03 eta 0:23:01
epoch [6/30] batch [160/204] time 0.275 (0.277) data 0.000 (0.006) loss 0.3994 (1.4560) lr 9.3301e-03 eta 0:22:49
epoch [6/30] batch [180/204] time 0.255 (0.276) data 0.000 (0.006) loss 0.0823 (1.4170) lr 9.3301e-03 eta 0:22:38
epoch [6/30] batch [200/204] time 0.255 (0.274) data 0.000 (0.005) loss 0.6475 (1.4156) lr 9.3301e-03 eta 0:22:24
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:14,  2.33s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.08s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.54it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.24it/s] 71%|███████▏  | 5/7 [00:02<00:00,  2.99it/s] 86%|████████▌ | 6/7 [00:03<00:00,  3.75it/s]100%|██████████| 7/7 [00:03<00:00,  4.49it/s]100%|██████████| 7/7 [00:03<00:00,  2.08it/s]=> result
* total: 696
* correct: 595
* accuracy: 85.5%
* error: 14.5%
* macro_f1: 82.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/204] time 0.270 (0.327) data 0.000 (0.049) loss 0.7979 (1.4621) lr 9.0451e-03 eta 0:26:33
epoch [7/30] batch [40/204] time 0.271 (0.297) data 0.000 (0.024) loss 1.9570 (1.3022) lr 9.0451e-03 eta 0:24:04
epoch [7/30] batch [60/204] time 0.265 (0.287) data 0.000 (0.016) loss 0.4277 (1.2653) lr 9.0451e-03 eta 0:23:09
epoch [7/30] batch [80/204] time 0.275 (0.283) data 0.000 (0.012) loss 0.4685 (1.2673) lr 9.0451e-03 eta 0:22:43
epoch [7/30] batch [100/204] time 0.266 (0.282) data 0.000 (0.010) loss 0.5249 (1.2629) lr 9.0451e-03 eta 0:22:31
epoch [7/30] batch [120/204] time 0.273 (0.280) data 0.000 (0.008) loss 1.1045 (1.3205) lr 9.0451e-03 eta 0:22:16
epoch [7/30] batch [140/204] time 0.275 (0.279) data 0.000 (0.007) loss 0.1447 (1.2760) lr 9.0451e-03 eta 0:22:04
epoch [7/30] batch [160/204] time 0.275 (0.278) data 0.000 (0.006) loss 1.4053 (1.3652) lr 9.0451e-03 eta 0:21:56
epoch [7/30] batch [180/204] time 0.256 (0.277) data 0.000 (0.006) loss 1.4062 (1.3931) lr 9.0451e-03 eta 0:21:44
epoch [7/30] batch [200/204] time 0.251 (0.274) data 0.000 (0.005) loss 0.6558 (1.3726) lr 9.0451e-03 eta 0:21:27
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.27it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.03it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.30it/s]=> result
* total: 696
* correct: 596
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 83.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/204] time 0.267 (0.330) data 0.000 (0.051) loss 1.8477 (1.1848) lr 8.7157e-03 eta 0:25:43
epoch [8/30] batch [40/204] time 0.276 (0.301) data 0.000 (0.025) loss 0.3286 (1.2067) lr 8.7157e-03 eta 0:23:19
epoch [8/30] batch [60/204] time 0.271 (0.290) data 0.000 (0.017) loss 0.7729 (1.1616) lr 8.7157e-03 eta 0:22:25
epoch [8/30] batch [80/204] time 0.269 (0.287) data 0.000 (0.013) loss 0.2090 (1.0807) lr 8.7157e-03 eta 0:22:01
epoch [8/30] batch [100/204] time 0.265 (0.283) data 0.000 (0.010) loss 1.1641 (1.0678) lr 8.7157e-03 eta 0:21:41
epoch [8/30] batch [120/204] time 0.270 (0.281) data 0.001 (0.009) loss 0.6348 (1.1232) lr 8.7157e-03 eta 0:21:23
epoch [8/30] batch [140/204] time 0.270 (0.279) data 0.000 (0.007) loss 1.4746 (1.1390) lr 8.7157e-03 eta 0:21:11
epoch [8/30] batch [160/204] time 0.279 (0.278) data 0.000 (0.007) loss 3.7559 (1.1708) lr 8.7157e-03 eta 0:21:01
epoch [8/30] batch [180/204] time 0.253 (0.277) data 0.000 (0.006) loss 0.2205 (1.1920) lr 8.7157e-03 eta 0:20:48
epoch [8/30] batch [200/204] time 0.254 (0.274) data 0.000 (0.005) loss 0.7603 (1.1806) lr 8.7157e-03 eta 0:20:32
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.11s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.48it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.26it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.02it/s]100%|██████████| 7/7 [00:02<00:00,  4.75it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 594
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 83.4%

epoch [9/30] batch [20/204] time 0.265 (0.329) data 0.000 (0.052) loss 0.0224 (0.8406) lr 8.3457e-03 eta 0:24:31
epoch [9/30] batch [40/204] time 0.276 (0.300) data 0.000 (0.026) loss 1.9922 (1.1061) lr 8.3457e-03 eta 0:22:12
epoch [9/30] batch [60/204] time 0.266 (0.290) data 0.000 (0.018) loss 1.8477 (1.0900) lr 8.3457e-03 eta 0:21:25
epoch [9/30] batch [80/204] time 0.285 (0.287) data 0.000 (0.013) loss 1.7646 (1.1033) lr 8.3457e-03 eta 0:21:03
epoch [9/30] batch [100/204] time 0.268 (0.283) data 0.000 (0.011) loss 1.4248 (1.2052) lr 8.3457e-03 eta 0:20:43
epoch [9/30] batch [120/204] time 0.272 (0.281) data 0.000 (0.009) loss 1.5742 (1.1815) lr 8.3457e-03 eta 0:20:28
epoch [9/30] batch [140/204] time 0.271 (0.280) data 0.000 (0.008) loss 1.0566 (1.1865) lr 8.3457e-03 eta 0:20:15
epoch [9/30] batch [160/204] time 0.273 (0.279) data 0.000 (0.007) loss 2.1680 (1.1735) lr 8.3457e-03 eta 0:20:05
epoch [9/30] batch [180/204] time 0.254 (0.277) data 0.000 (0.006) loss 1.8750 (1.1672) lr 8.3457e-03 eta 0:19:54
epoch [9/30] batch [200/204] time 0.254 (0.275) data 0.000 (0.005) loss 3.0293 (1.1302) lr 8.3457e-03 eta 0:19:39
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.48it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.25it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.02it/s]100%|██████████| 7/7 [00:02<00:00,  4.74it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 632
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 88.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/204] time 0.266 (0.323) data 0.000 (0.049) loss 1.4844 (0.9857) lr 7.9389e-03 eta 0:22:58
epoch [10/30] batch [40/204] time 0.267 (0.297) data 0.000 (0.025) loss 0.9180 (1.1422) lr 7.9389e-03 eta 0:20:58
epoch [10/30] batch [60/204] time 0.271 (0.288) data 0.000 (0.017) loss 1.3301 (1.1472) lr 7.9389e-03 eta 0:20:16
epoch [10/30] batch [80/204] time 0.275 (0.283) data 0.000 (0.012) loss 1.2246 (1.1123) lr 7.9389e-03 eta 0:19:50
epoch [10/30] batch [100/204] time 0.278 (0.281) data 0.000 (0.010) loss 0.8794 (1.1098) lr 7.9389e-03 eta 0:19:33
epoch [10/30] batch [120/204] time 0.283 (0.280) data 0.000 (0.008) loss 0.9639 (1.0994) lr 7.9389e-03 eta 0:19:26
epoch [10/30] batch [140/204] time 0.274 (0.279) data 0.000 (0.007) loss 0.2966 (1.0774) lr 7.9389e-03 eta 0:19:15
epoch [10/30] batch [160/204] time 0.268 (0.278) data 0.000 (0.006) loss 1.4561 (1.0769) lr 7.9389e-03 eta 0:19:05
epoch [10/30] batch [180/204] time 0.257 (0.277) data 0.000 (0.006) loss 0.5723 (1.0502) lr 7.9389e-03 eta 0:18:56
epoch [10/30] batch [200/204] time 0.253 (0.275) data 0.000 (0.005) loss 0.9258 (1.0654) lr 7.9389e-03 eta 0:18:42
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.27it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.03it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.30it/s]=> result
* total: 696
* correct: 633
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 88.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/204] time 0.266 (0.325) data 0.000 (0.050) loss 0.7139 (1.0133) lr 7.5000e-03 eta 0:21:59
epoch [11/30] batch [40/204] time 0.266 (0.297) data 0.000 (0.025) loss 0.5034 (1.0369) lr 7.5000e-03 eta 0:20:01
epoch [11/30] batch [60/204] time 0.284 (0.288) data 0.000 (0.017) loss 1.0723 (1.0979) lr 7.5000e-03 eta 0:19:16
epoch [11/30] batch [80/204] time 0.268 (0.283) data 0.001 (0.013) loss 1.6162 (1.0636) lr 7.5000e-03 eta 0:18:53
epoch [11/30] batch [100/204] time 0.273 (0.282) data 0.000 (0.010) loss 0.3928 (1.0152) lr 7.5000e-03 eta 0:18:42
epoch [11/30] batch [120/204] time 0.267 (0.280) data 0.000 (0.009) loss 0.5752 (0.9669) lr 7.5000e-03 eta 0:18:28
epoch [11/30] batch [140/204] time 0.268 (0.278) data 0.000 (0.007) loss 1.2891 (0.9354) lr 7.5000e-03 eta 0:18:17
epoch [11/30] batch [160/204] time 0.266 (0.278) data 0.000 (0.006) loss 0.1919 (0.9580) lr 7.5000e-03 eta 0:18:10
epoch [11/30] batch [180/204] time 0.258 (0.276) data 0.000 (0.006) loss 7.2422 (0.9818) lr 7.5000e-03 eta 0:17:58
epoch [11/30] batch [200/204] time 0.261 (0.274) data 0.000 (0.005) loss 0.6196 (0.9796) lr 7.5000e-03 eta 0:17:44
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.23s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.00it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.65it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.38it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.15it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.91it/s]100%|██████████| 7/7 [00:03<00:00,  4.64it/s]100%|██████████| 7/7 [00:03<00:00,  2.19it/s]=> result
* total: 696
* correct: 638
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/204] time 0.275 (0.326) data 0.000 (0.052) loss 0.2219 (0.9199) lr 7.0337e-03 eta 0:20:58
epoch [12/30] batch [40/204] time 0.262 (0.298) data 0.000 (0.026) loss 0.5171 (0.8395) lr 7.0337e-03 eta 0:19:01
epoch [12/30] batch [60/204] time 0.268 (0.290) data 0.000 (0.018) loss 0.9360 (0.9216) lr 7.0337e-03 eta 0:18:26
epoch [12/30] batch [80/204] time 0.264 (0.284) data 0.000 (0.013) loss 0.3940 (0.9129) lr 7.0337e-03 eta 0:17:58
epoch [12/30] batch [100/204] time 0.290 (0.282) data 0.000 (0.011) loss 0.3479 (0.8768) lr 7.0337e-03 eta 0:17:43
epoch [12/30] batch [120/204] time 0.269 (0.279) data 0.000 (0.009) loss 0.0978 (0.8610) lr 7.0337e-03 eta 0:17:29
epoch [12/30] batch [140/204] time 0.272 (0.278) data 0.000 (0.008) loss 0.1000 (0.8321) lr 7.0337e-03 eta 0:17:19
epoch [12/30] batch [160/204] time 0.271 (0.277) data 0.000 (0.007) loss 0.4624 (0.8588) lr 7.0337e-03 eta 0:17:10
epoch [12/30] batch [180/204] time 0.253 (0.277) data 0.000 (0.006) loss 1.6377 (0.8734) lr 7.0337e-03 eta 0:17:02
epoch [12/30] batch [200/204] time 0.254 (0.274) data 0.000 (0.005) loss 0.4092 (0.8681) lr 7.0337e-03 eta 0:16:48
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.15s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.02it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.68it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.41it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.18it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.94it/s]100%|██████████| 7/7 [00:02<00:00,  4.67it/s]100%|██████████| 7/7 [00:03<00:00,  2.23it/s]=> result
* total: 696
* correct: 639
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 90.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [13/30] batch [20/204] time 0.268 (0.324) data 0.000 (0.052) loss 0.2930 (0.8455) lr 6.5451e-03 eta 0:19:42
epoch [13/30] batch [40/204] time 0.265 (0.297) data 0.000 (0.026) loss 0.9868 (0.7795) lr 6.5451e-03 eta 0:17:56
epoch [13/30] batch [60/204] time 0.270 (0.287) data 0.000 (0.018) loss 2.2285 (0.9214) lr 6.5451e-03 eta 0:17:17
epoch [13/30] batch [80/204] time 0.265 (0.284) data 0.000 (0.013) loss 1.0010 (0.8770) lr 6.5451e-03 eta 0:17:01
epoch [13/30] batch [100/204] time 0.278 (0.282) data 0.000 (0.011) loss 0.9951 (0.9095) lr 6.5451e-03 eta 0:16:46
epoch [13/30] batch [120/204] time 0.277 (0.280) data 0.000 (0.009) loss 2.8027 (0.9467) lr 6.5451e-03 eta 0:16:33
epoch [13/30] batch [140/204] time 0.274 (0.278) data 0.000 (0.008) loss 0.2932 (0.9068) lr 6.5451e-03 eta 0:16:23
epoch [13/30] batch [160/204] time 0.264 (0.278) data 0.000 (0.007) loss 0.1768 (0.9031) lr 6.5451e-03 eta 0:16:16
epoch [13/30] batch [180/204] time 0.259 (0.277) data 0.000 (0.006) loss 0.0911 (0.9249) lr 6.5451e-03 eta 0:16:05
epoch [13/30] batch [200/204] time 0.257 (0.274) data 0.000 (0.005) loss 0.3052 (0.8825) lr 6.5451e-03 eta 0:15:52
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.25s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.01s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.64it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.36it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.13it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.89it/s]100%|██████████| 7/7 [00:03<00:00,  4.62it/s]100%|██████████| 7/7 [00:03<00:00,  2.16it/s]=> result
* total: 696
* correct: 650
* accuracy: 93.4%
* error: 6.6%
* macro_f1: 91.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [14/30] batch [20/204] time 0.273 (0.328) data 0.000 (0.050) loss 0.1528 (0.6229) lr 6.0396e-03 eta 0:18:50
epoch [14/30] batch [40/204] time 0.270 (0.300) data 0.000 (0.025) loss 2.5312 (0.7260) lr 6.0396e-03 eta 0:17:07
epoch [14/30] batch [60/204] time 0.268 (0.290) data 0.000 (0.017) loss 0.3452 (0.7243) lr 6.0396e-03 eta 0:16:28
epoch [14/30] batch [80/204] time 0.268 (0.287) data 0.001 (0.013) loss 1.0420 (0.7754) lr 6.0396e-03 eta 0:16:12
epoch [14/30] batch [100/204] time 0.274 (0.284) data 0.000 (0.010) loss 1.1260 (0.7832) lr 6.0396e-03 eta 0:15:55
epoch [14/30] batch [120/204] time 0.267 (0.281) data 0.000 (0.009) loss 2.4531 (0.7748) lr 6.0396e-03 eta 0:15:41
epoch [14/30] batch [140/204] time 0.266 (0.279) data 0.000 (0.007) loss 0.7603 (0.8226) lr 6.0396e-03 eta 0:15:30
epoch [14/30] batch [160/204] time 0.268 (0.278) data 0.000 (0.006) loss 1.4014 (0.8303) lr 6.0396e-03 eta 0:15:20
epoch [14/30] batch [180/204] time 0.251 (0.276) data 0.000 (0.006) loss 0.1736 (0.8771) lr 6.0396e-03 eta 0:15:09
epoch [14/30] batch [200/204] time 0.252 (0.274) data 0.000 (0.005) loss 0.1687 (0.8646) lr 6.0396e-03 eta 0:14:55
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.50it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.26it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.02it/s]100%|██████████| 7/7 [00:02<00:00,  4.74it/s]100%|██████████| 7/7 [00:03<00:00,  2.29it/s]=> result
* total: 696
* correct: 649
* accuracy: 93.2%
* error: 6.8%
* macro_f1: 91.4%

epoch [15/30] batch [20/204] time 0.271 (0.333) data 0.000 (0.053) loss 0.6152 (0.4781) lr 5.5226e-03 eta 0:18:00
epoch [15/30] batch [40/204] time 0.274 (0.303) data 0.000 (0.026) loss 2.1016 (0.6288) lr 5.5226e-03 eta 0:16:16
epoch [15/30] batch [60/204] time 0.269 (0.292) data 0.000 (0.018) loss 0.5894 (0.7272) lr 5.5226e-03 eta 0:15:35
epoch [15/30] batch [80/204] time 0.269 (0.286) data 0.000 (0.013) loss 0.6426 (0.7323) lr 5.5226e-03 eta 0:15:12
epoch [15/30] batch [100/204] time 0.268 (0.283) data 0.000 (0.011) loss 0.5371 (0.7597) lr 5.5226e-03 eta 0:14:56
epoch [15/30] batch [120/204] time 0.272 (0.282) data 0.000 (0.009) loss 0.1460 (0.7344) lr 5.5226e-03 eta 0:14:45
epoch [15/30] batch [140/204] time 0.262 (0.280) data 0.000 (0.008) loss 1.4600 (0.7455) lr 5.5226e-03 eta 0:14:34
epoch [15/30] batch [160/204] time 0.272 (0.279) data 0.000 (0.007) loss 0.2786 (0.7271) lr 5.5226e-03 eta 0:14:24
epoch [15/30] batch [180/204] time 0.259 (0.277) data 0.000 (0.006) loss 0.1641 (0.7233) lr 5.5226e-03 eta 0:14:15
epoch [15/30] batch [200/204] time 0.254 (0.275) data 0.000 (0.005) loss 0.4150 (0.7513) lr 5.5226e-03 eta 0:14:03
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.16s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.03it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.70it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.44it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.21it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.97it/s]100%|██████████| 7/7 [00:02<00:00,  4.70it/s]100%|██████████| 7/7 [00:03<00:00,  2.24it/s]=> result
* total: 696
* correct: 652
* accuracy: 93.7%
* error: 6.3%
* macro_f1: 92.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [16/30] batch [20/204] time 0.268 (0.324) data 0.000 (0.049) loss 0.0733 (0.3967) lr 5.0000e-03 eta 0:16:24
epoch [16/30] batch [40/204] time 0.286 (0.298) data 0.000 (0.025) loss 0.1188 (0.7099) lr 5.0000e-03 eta 0:14:58
epoch [16/30] batch [60/204] time 0.268 (0.291) data 0.000 (0.017) loss 2.9004 (0.8282) lr 5.0000e-03 eta 0:14:33
epoch [16/30] batch [80/204] time 0.275 (0.286) data 0.000 (0.013) loss 1.3789 (0.8308) lr 5.0000e-03 eta 0:14:13
epoch [16/30] batch [100/204] time 0.268 (0.283) data 0.000 (0.010) loss 1.3135 (0.8218) lr 5.0000e-03 eta 0:13:57
epoch [16/30] batch [120/204] time 0.272 (0.281) data 0.000 (0.008) loss 0.5962 (0.7730) lr 5.0000e-03 eta 0:13:46
epoch [16/30] batch [140/204] time 0.266 (0.280) data 0.000 (0.007) loss 2.9883 (0.7650) lr 5.0000e-03 eta 0:13:36
epoch [16/30] batch [160/204] time 0.265 (0.278) data 0.000 (0.006) loss 0.3677 (0.7581) lr 5.0000e-03 eta 0:13:26
epoch [16/30] batch [180/204] time 0.248 (0.277) data 0.000 (0.006) loss 2.6465 (0.7315) lr 5.0000e-03 eta 0:13:17
epoch [16/30] batch [200/204] time 0.251 (0.275) data 0.000 (0.005) loss 0.1626 (0.7357) lr 5.0000e-03 eta 0:13:06
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.08s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.07it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.75it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.50it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.28it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.04it/s]100%|██████████| 7/7 [00:02<00:00,  4.77it/s]100%|██████████| 7/7 [00:03<00:00,  2.31it/s]=> result
* total: 696
* correct: 649
* accuracy: 93.2%
* error: 6.8%
* macro_f1: 91.8%

epoch [17/30] batch [20/204] time 0.269 (0.321) data 0.000 (0.050) loss 0.1172 (0.6560) lr 4.4774e-03 eta 0:15:11
epoch [17/30] batch [40/204] time 0.277 (0.296) data 0.000 (0.025) loss 0.4141 (0.7040) lr 4.4774e-03 eta 0:13:53
epoch [17/30] batch [60/204] time 0.272 (0.288) data 0.000 (0.017) loss 0.3862 (0.7011) lr 4.4774e-03 eta 0:13:24
epoch [17/30] batch [80/204] time 0.265 (0.283) data 0.000 (0.013) loss 0.6558 (0.6696) lr 4.4774e-03 eta 0:13:05
epoch [17/30] batch [100/204] time 0.268 (0.282) data 0.000 (0.010) loss 0.1659 (0.7115) lr 4.4774e-03 eta 0:12:56
epoch [17/30] batch [120/204] time 0.268 (0.279) data 0.000 (0.009) loss 2.5781 (0.6947) lr 4.4774e-03 eta 0:12:44
epoch [17/30] batch [140/204] time 0.267 (0.278) data 0.000 (0.007) loss 1.1572 (0.6847) lr 4.4774e-03 eta 0:12:35
epoch [17/30] batch [160/204] time 0.269 (0.278) data 0.000 (0.007) loss 0.7358 (0.6811) lr 4.4774e-03 eta 0:12:29
epoch [17/30] batch [180/204] time 0.257 (0.276) data 0.000 (0.006) loss 0.8896 (0.6838) lr 4.4774e-03 eta 0:12:19
epoch [17/30] batch [200/204] time 0.251 (0.274) data 0.000 (0.005) loss 0.2170 (0.6909) lr 4.4774e-03 eta 0:12:07
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.24s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.01s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.64it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.37it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.14it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.90it/s]100%|██████████| 7/7 [00:03<00:00,  4.63it/s]100%|██████████| 7/7 [00:03<00:00,  2.20it/s]=> result
* total: 696
* correct: 644
* accuracy: 92.5%
* error: 7.5%
* macro_f1: 91.2%

epoch [18/30] batch [20/204] time 0.261 (0.324) data 0.000 (0.050) loss 0.1205 (0.7214) lr 3.9604e-03 eta 0:14:12
epoch [18/30] batch [40/204] time 0.264 (0.297) data 0.000 (0.025) loss 0.1641 (0.6457) lr 3.9604e-03 eta 0:12:55
epoch [18/30] batch [60/204] time 0.264 (0.290) data 0.000 (0.017) loss 0.5317 (0.7294) lr 3.9604e-03 eta 0:12:32
epoch [18/30] batch [80/204] time 0.267 (0.286) data 0.000 (0.013) loss 0.3953 (0.6960) lr 3.9604e-03 eta 0:12:14
epoch [18/30] batch [100/204] time 0.280 (0.283) data 0.000 (0.010) loss 0.8008 (0.7171) lr 3.9604e-03 eta 0:12:01
epoch [18/30] batch [120/204] time 0.270 (0.280) data 0.000 (0.009) loss 0.6621 (0.7529) lr 3.9604e-03 eta 0:11:48
epoch [18/30] batch [140/204] time 0.276 (0.278) data 0.000 (0.007) loss 0.0489 (0.7704) lr 3.9604e-03 eta 0:11:39
epoch [18/30] batch [160/204] time 0.276 (0.278) data 0.000 (0.006) loss 1.3564 (0.7676) lr 3.9604e-03 eta 0:11:31
epoch [18/30] batch [180/204] time 0.253 (0.276) data 0.000 (0.006) loss 0.9590 (0.7659) lr 3.9604e-03 eta 0:11:23
epoch [18/30] batch [200/204] time 0.251 (0.274) data 0.000 (0.005) loss 0.6323 (0.7461) lr 3.9604e-03 eta 0:11:12
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.08s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.75it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.50it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.28it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.04it/s]100%|██████████| 7/7 [00:02<00:00,  4.77it/s]100%|██████████| 7/7 [00:03<00:00,  2.31it/s]=> result
* total: 696
* correct: 655
* accuracy: 94.1%
* error: 5.9%
* macro_f1: 93.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/204] time 0.271 (0.325) data 0.000 (0.051) loss 0.6016 (0.4287) lr 3.4549e-03 eta 0:13:08
epoch [19/30] batch [40/204] time 0.266 (0.298) data 0.000 (0.025) loss 0.2549 (0.5084) lr 3.4549e-03 eta 0:11:57
epoch [19/30] batch [60/204] time 0.268 (0.288) data 0.000 (0.017) loss 1.3994 (0.5230) lr 3.4549e-03 eta 0:11:27
epoch [19/30] batch [80/204] time 0.284 (0.285) data 0.000 (0.013) loss 0.1350 (0.6749) lr 3.4549e-03 eta 0:11:15
epoch [19/30] batch [100/204] time 0.270 (0.282) data 0.000 (0.010) loss 2.3672 (0.6730) lr 3.4549e-03 eta 0:11:01
epoch [19/30] batch [120/204] time 0.264 (0.279) data 0.000 (0.009) loss 0.9307 (0.7045) lr 3.4549e-03 eta 0:10:50
epoch [19/30] batch [140/204] time 0.264 (0.278) data 0.000 (0.007) loss 0.3945 (0.7196) lr 3.4549e-03 eta 0:10:41
epoch [19/30] batch [160/204] time 0.275 (0.278) data 0.000 (0.007) loss 0.4683 (0.7060) lr 3.4549e-03 eta 0:10:35
epoch [19/30] batch [180/204] time 0.263 (0.276) data 0.000 (0.006) loss 1.4111 (0.7093) lr 3.4549e-03 eta 0:10:26
epoch [19/30] batch [200/204] time 0.253 (0.274) data 0.000 (0.005) loss 0.0333 (0.6785) lr 3.4549e-03 eta 0:10:15
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.21s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.01it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.66it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.39it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.16it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.92it/s]100%|██████████| 7/7 [00:03<00:00,  4.65it/s]100%|██████████| 7/7 [00:03<00:00,  2.20it/s]=> result
* total: 696
* correct: 654
* accuracy: 94.0%
* error: 6.0%
* macro_f1: 92.4%

epoch [20/30] batch [20/204] time 0.268 (0.335) data 0.000 (0.051) loss 0.1823 (1.2345) lr 2.9663e-03 eta 0:12:25
epoch [20/30] batch [40/204] time 0.263 (0.302) data 0.000 (0.026) loss 0.1558 (0.8591) lr 2.9663e-03 eta 0:11:05
epoch [20/30] batch [60/204] time 0.271 (0.291) data 0.000 (0.017) loss 1.3525 (0.7732) lr 2.9663e-03 eta 0:10:35
epoch [20/30] batch [80/204] time 0.267 (0.286) data 0.000 (0.013) loss 0.1887 (0.7533) lr 2.9663e-03 eta 0:10:19
epoch [20/30] batch [100/204] time 0.269 (0.283) data 0.000 (0.010) loss 4.7188 (0.7773) lr 2.9663e-03 eta 0:10:07
epoch [20/30] batch [120/204] time 0.266 (0.281) data 0.000 (0.009) loss 0.0546 (0.7652) lr 2.9663e-03 eta 0:09:56
epoch [20/30] batch [140/204] time 0.269 (0.279) data 0.000 (0.008) loss 0.0079 (0.7685) lr 2.9663e-03 eta 0:09:46
epoch [20/30] batch [160/204] time 0.273 (0.278) data 0.000 (0.007) loss 0.1650 (0.7349) lr 2.9663e-03 eta 0:09:38
epoch [20/30] batch [180/204] time 0.251 (0.276) data 0.000 (0.006) loss 2.5664 (0.7403) lr 2.9663e-03 eta 0:09:29
epoch [20/30] batch [200/204] time 0.249 (0.274) data 0.000 (0.005) loss 0.0178 (0.6961) lr 2.9663e-03 eta 0:09:19
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.47it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.24it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.01it/s]100%|██████████| 7/7 [00:02<00:00,  4.73it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 661
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 93.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/204] time 0.261 (0.331) data 0.000 (0.055) loss 1.1807 (0.5333) lr 2.5000e-03 eta 0:11:07
epoch [21/30] batch [40/204] time 0.268 (0.300) data 0.000 (0.027) loss 0.1070 (0.6039) lr 2.5000e-03 eta 0:10:00
epoch [21/30] batch [60/204] time 0.272 (0.290) data 0.000 (0.018) loss 1.0996 (0.5985) lr 2.5000e-03 eta 0:09:34
epoch [21/30] batch [80/204] time 0.268 (0.285) data 0.000 (0.014) loss 0.4441 (0.6117) lr 2.5000e-03 eta 0:09:18
epoch [21/30] batch [100/204] time 0.275 (0.282) data 0.000 (0.011) loss 0.0736 (0.5588) lr 2.5000e-03 eta 0:09:06
epoch [21/30] batch [120/204] time 0.261 (0.279) data 0.000 (0.009) loss 0.2502 (0.6215) lr 2.5000e-03 eta 0:08:55
epoch [21/30] batch [140/204] time 0.264 (0.278) data 0.000 (0.008) loss 1.5723 (0.6079) lr 2.5000e-03 eta 0:08:48
epoch [21/30] batch [160/204] time 0.266 (0.277) data 0.000 (0.007) loss 0.4194 (0.6064) lr 2.5000e-03 eta 0:08:40
epoch [21/30] batch [180/204] time 0.250 (0.275) data 0.000 (0.006) loss 0.0492 (0.5855) lr 2.5000e-03 eta 0:08:31
epoch [21/30] batch [200/204] time 0.251 (0.273) data 0.000 (0.006) loss 0.0539 (0.5858) lr 2.5000e-03 eta 0:08:21
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.28it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.04it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.30it/s]=> result
* total: 696
* correct: 660
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 93.6%

epoch [22/30] batch [20/204] time 0.264 (0.328) data 0.000 (0.050) loss 0.6235 (0.6717) lr 2.0611e-03 eta 0:09:56
epoch [22/30] batch [40/204] time 0.274 (0.299) data 0.000 (0.025) loss 0.0227 (0.5572) lr 2.0611e-03 eta 0:08:57
epoch [22/30] batch [60/204] time 0.270 (0.290) data 0.000 (0.017) loss 0.9507 (0.5158) lr 2.0611e-03 eta 0:08:34
epoch [22/30] batch [80/204] time 0.270 (0.286) data 0.000 (0.013) loss 0.3359 (0.4622) lr 2.0611e-03 eta 0:08:21
epoch [22/30] batch [100/204] time 0.272 (0.283) data 0.000 (0.010) loss 0.6064 (0.4713) lr 2.0611e-03 eta 0:08:10
epoch [22/30] batch [120/204] time 0.274 (0.281) data 0.000 (0.009) loss 0.7061 (0.4832) lr 2.0611e-03 eta 0:08:01
epoch [22/30] batch [140/204] time 0.286 (0.280) data 0.000 (0.007) loss 1.1953 (0.5259) lr 2.0611e-03 eta 0:07:54
epoch [22/30] batch [160/204] time 0.267 (0.278) data 0.000 (0.007) loss 0.7275 (0.5400) lr 2.0611e-03 eta 0:07:46
epoch [22/30] batch [180/204] time 0.259 (0.276) data 0.000 (0.006) loss 0.5664 (0.5621) lr 2.0611e-03 eta 0:07:37
epoch [22/30] batch [200/204] time 0.253 (0.274) data 0.000 (0.005) loss 0.8433 (0.5786) lr 2.0611e-03 eta 0:07:27
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.11s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.47it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.25it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.01it/s]100%|██████████| 7/7 [00:02<00:00,  4.74it/s]100%|██████████| 7/7 [00:03<00:00,  2.29it/s]=> result
* total: 696
* correct: 659
* accuracy: 94.7%
* error: 5.3%
* macro_f1: 93.4%

epoch [23/30] batch [20/204] time 0.264 (0.323) data 0.000 (0.054) loss 0.2069 (0.4860) lr 1.6543e-03 eta 0:08:41
epoch [23/30] batch [40/204] time 0.265 (0.298) data 0.000 (0.027) loss 0.2827 (0.5391) lr 1.6543e-03 eta 0:07:54
epoch [23/30] batch [60/204] time 0.266 (0.288) data 0.000 (0.018) loss 0.3843 (0.6152) lr 1.6543e-03 eta 0:07:32
epoch [23/30] batch [80/204] time 0.263 (0.283) data 0.000 (0.014) loss 0.3547 (0.7344) lr 1.6543e-03 eta 0:07:19
epoch [23/30] batch [100/204] time 0.268 (0.281) data 0.000 (0.011) loss 0.1725 (0.7571) lr 1.6543e-03 eta 0:07:09
epoch [23/30] batch [120/204] time 0.274 (0.279) data 0.000 (0.009) loss 0.1948 (0.7451) lr 1.6543e-03 eta 0:07:01
epoch [23/30] batch [140/204] time 0.287 (0.277) data 0.000 (0.008) loss 0.0815 (0.6803) lr 1.6543e-03 eta 0:06:53
epoch [23/30] batch [160/204] time 0.270 (0.277) data 0.000 (0.007) loss 0.3162 (0.6720) lr 1.6543e-03 eta 0:06:47
epoch [23/30] batch [180/204] time 0.251 (0.276) data 0.000 (0.006) loss 0.0710 (0.6591) lr 1.6543e-03 eta 0:06:40
epoch [23/30] batch [200/204] time 0.253 (0.273) data 0.000 (0.006) loss 0.3013 (0.6516) lr 1.6543e-03 eta 0:06:31
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.28it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.04it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.31it/s]=> result
* total: 696
* correct: 658
* accuracy: 94.5%
* error: 5.5%
* macro_f1: 93.4%

epoch [24/30] batch [20/204] time 0.272 (0.321) data 0.000 (0.049) loss 0.7178 (0.5226) lr 1.2843e-03 eta 0:07:31
epoch [24/30] batch [40/204] time 0.268 (0.298) data 0.000 (0.024) loss 0.1428 (0.5342) lr 1.2843e-03 eta 0:06:53
epoch [24/30] batch [60/204] time 0.262 (0.289) data 0.000 (0.016) loss 0.0762 (0.5871) lr 1.2843e-03 eta 0:06:35
epoch [24/30] batch [80/204] time 0.271 (0.284) data 0.000 (0.012) loss 0.1978 (0.5327) lr 1.2843e-03 eta 0:06:22
epoch [24/30] batch [100/204] time 0.277 (0.281) data 0.000 (0.010) loss 0.0148 (0.5307) lr 1.2843e-03 eta 0:06:13
epoch [24/30] batch [120/204] time 0.265 (0.279) data 0.000 (0.008) loss 0.0863 (0.5071) lr 1.2843e-03 eta 0:06:04
epoch [24/30] batch [140/204] time 0.269 (0.278) data 0.000 (0.007) loss 0.0334 (0.5147) lr 1.2843e-03 eta 0:05:57
epoch [24/30] batch [160/204] time 0.267 (0.277) data 0.000 (0.006) loss 0.8242 (0.5275) lr 1.2843e-03 eta 0:05:50
epoch [24/30] batch [180/204] time 0.258 (0.275) data 0.000 (0.006) loss 0.1846 (0.5337) lr 1.2843e-03 eta 0:05:43
epoch [24/30] batch [200/204] time 0.251 (0.273) data 0.000 (0.005) loss 0.3940 (0.5580) lr 1.2843e-03 eta 0:05:35
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.69it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.43it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.20it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.95it/s]100%|██████████| 7/7 [00:02<00:00,  4.68it/s]100%|██████████| 7/7 [00:03<00:00,  2.26it/s]=> result
* total: 696
* correct: 659
* accuracy: 94.7%
* error: 5.3%
* macro_f1: 93.7%

epoch [25/30] batch [20/204] time 0.263 (0.323) data 0.000 (0.050) loss 0.8125 (0.6894) lr 9.5492e-04 eta 0:06:29
epoch [25/30] batch [40/204] time 0.270 (0.296) data 0.000 (0.025) loss 0.1263 (0.5953) lr 9.5492e-04 eta 0:05:50
epoch [25/30] batch [60/204] time 0.269 (0.287) data 0.000 (0.017) loss 1.5146 (0.6009) lr 9.5492e-04 eta 0:05:34
epoch [25/30] batch [80/204] time 0.274 (0.283) data 0.000 (0.013) loss 0.5195 (0.5685) lr 9.5492e-04 eta 0:05:23
epoch [25/30] batch [100/204] time 0.267 (0.281) data 0.000 (0.010) loss 0.2324 (0.5765) lr 9.5492e-04 eta 0:05:15
epoch [25/30] batch [120/204] time 0.270 (0.279) data 0.000 (0.009) loss 0.1190 (0.5289) lr 9.5492e-04 eta 0:05:07
epoch [25/30] batch [140/204] time 0.269 (0.278) data 0.000 (0.007) loss 0.2345 (0.5066) lr 9.5492e-04 eta 0:05:00
epoch [25/30] batch [160/204] time 0.271 (0.277) data 0.000 (0.006) loss 0.1028 (0.5231) lr 9.5492e-04 eta 0:04:54
epoch [25/30] batch [180/204] time 0.254 (0.276) data 0.000 (0.006) loss 2.6191 (0.5349) lr 9.5492e-04 eta 0:04:47
epoch [25/30] batch [200/204] time 0.249 (0.273) data 0.000 (0.005) loss 0.1945 (0.5283) lr 9.5492e-04 eta 0:04:39
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.25s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.01s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.64it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.37it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.14it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.90it/s]100%|██████████| 7/7 [00:03<00:00,  4.64it/s]100%|██████████| 7/7 [00:03<00:00,  2.19it/s]=> result
* total: 696
* correct: 657
* accuracy: 94.4%
* error: 5.6%
* macro_f1: 93.1%

epoch [26/30] batch [20/204] time 0.271 (0.324) data 0.000 (0.050) loss 1.0820 (0.5312) lr 6.6987e-04 eta 0:05:24
epoch [26/30] batch [40/204] time 0.264 (0.296) data 0.000 (0.025) loss 0.0558 (0.5253) lr 6.6987e-04 eta 0:04:50
epoch [26/30] batch [60/204] time 0.268 (0.289) data 0.000 (0.017) loss 0.1935 (0.5380) lr 6.6987e-04 eta 0:04:37
epoch [26/30] batch [80/204] time 0.264 (0.284) data 0.000 (0.013) loss 0.1194 (0.4849) lr 6.6987e-04 eta 0:04:26
epoch [26/30] batch [100/204] time 0.262 (0.281) data 0.000 (0.010) loss 0.4929 (0.5343) lr 6.6987e-04 eta 0:04:18
epoch [26/30] batch [120/204] time 0.266 (0.279) data 0.000 (0.009) loss 2.2168 (0.5505) lr 6.6987e-04 eta 0:04:10
epoch [26/30] batch [140/204] time 0.264 (0.277) data 0.000 (0.007) loss 0.9912 (0.6136) lr 6.6987e-04 eta 0:04:04
epoch [26/30] batch [160/204] time 0.267 (0.276) data 0.000 (0.006) loss 0.8994 (0.6307) lr 6.6987e-04 eta 0:03:57
epoch [26/30] batch [180/204] time 0.251 (0.275) data 0.000 (0.006) loss 0.7285 (0.5953) lr 6.6987e-04 eta 0:03:51
epoch [26/30] batch [200/204] time 0.258 (0.273) data 0.000 (0.005) loss 0.1000 (0.5899) lr 6.6987e-04 eta 0:03:43
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.12s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.72it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.47it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.24it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.00it/s]100%|██████████| 7/7 [00:02<00:00,  4.73it/s]100%|██████████| 7/7 [00:03<00:00,  2.27it/s]=> result
* total: 696
* correct: 665
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 94.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [27/30] batch [20/204] time 0.269 (0.331) data 0.000 (0.057) loss 0.2705 (0.4566) lr 4.3227e-04 eta 0:04:23
epoch [27/30] batch [40/204] time 0.271 (0.301) data 0.000 (0.029) loss 0.0851 (0.5079) lr 4.3227e-04 eta 0:03:53
epoch [27/30] batch [60/204] time 0.268 (0.292) data 0.000 (0.019) loss 0.2722 (0.5768) lr 4.3227e-04 eta 0:03:41
epoch [27/30] batch [80/204] time 0.274 (0.287) data 0.000 (0.014) loss 0.2559 (0.5403) lr 4.3227e-04 eta 0:03:31
epoch [27/30] batch [100/204] time 0.265 (0.284) data 0.000 (0.012) loss 0.0834 (0.5227) lr 4.3227e-04 eta 0:03:23
epoch [27/30] batch [120/204] time 0.270 (0.282) data 0.000 (0.010) loss 2.8320 (0.5513) lr 4.3227e-04 eta 0:03:15
epoch [27/30] batch [140/204] time 0.270 (0.280) data 0.000 (0.008) loss 0.2274 (0.5336) lr 4.3227e-04 eta 0:03:09
epoch [27/30] batch [160/204] time 0.265 (0.279) data 0.000 (0.007) loss 0.4094 (0.5460) lr 4.3227e-04 eta 0:03:03
epoch [27/30] batch [180/204] time 0.250 (0.277) data 0.000 (0.007) loss 0.7690 (0.5531) lr 4.3227e-04 eta 0:02:56
epoch [27/30] batch [200/204] time 0.249 (0.275) data 0.000 (0.006) loss 0.2031 (0.5274) lr 4.3227e-04 eta 0:02:49
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.33s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.04s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.59it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.30it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.06it/s] 86%|████████▌ | 6/7 [00:03<00:00,  3.82it/s]100%|██████████| 7/7 [00:03<00:00,  4.55it/s]100%|██████████| 7/7 [00:03<00:00,  2.12it/s]=> result
* total: 696
* correct: 659
* accuracy: 94.7%
* error: 5.3%
* macro_f1: 93.6%

epoch [28/30] batch [20/204] time 0.269 (0.321) data 0.000 (0.049) loss 0.0969 (0.6265) lr 2.4472e-04 eta 0:03:09
epoch [28/30] batch [40/204] time 0.264 (0.293) data 0.000 (0.024) loss 0.0264 (0.6219) lr 2.4472e-04 eta 0:02:47
epoch [28/30] batch [60/204] time 0.269 (0.287) data 0.000 (0.016) loss 0.4263 (0.5846) lr 2.4472e-04 eta 0:02:38
epoch [28/30] batch [80/204] time 0.277 (0.282) data 0.000 (0.012) loss 0.3557 (0.5829) lr 2.4472e-04 eta 0:02:30
epoch [28/30] batch [100/204] time 0.266 (0.280) data 0.000 (0.010) loss 0.2629 (0.5290) lr 2.4472e-04 eta 0:02:23
epoch [28/30] batch [120/204] time 0.294 (0.278) data 0.000 (0.008) loss 0.6118 (0.5095) lr 2.4472e-04 eta 0:02:16
epoch [28/30] batch [140/204] time 0.269 (0.277) data 0.000 (0.007) loss 0.5557 (0.5204) lr 2.4472e-04 eta 0:02:10
epoch [28/30] batch [160/204] time 0.266 (0.276) data 0.000 (0.006) loss 0.3677 (0.5246) lr 2.4472e-04 eta 0:02:04
epoch [28/30] batch [180/204] time 0.251 (0.275) data 0.000 (0.006) loss 0.0468 (0.5480) lr 2.4472e-04 eta 0:01:58
epoch [28/30] batch [200/204] time 0.252 (0.272) data 0.000 (0.005) loss 1.3008 (0.5731) lr 2.4472e-04 eta 0:01:52
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.20s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.01it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.67it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.41it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.18it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.94it/s]100%|██████████| 7/7 [00:03<00:00,  4.67it/s]100%|██████████| 7/7 [00:03<00:00,  2.22it/s]=> result
* total: 696
* correct: 663
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 94.0%

epoch [29/30] batch [20/204] time 0.268 (0.330) data 0.000 (0.051) loss 0.5845 (0.4006) lr 1.0926e-04 eta 0:02:08
epoch [29/30] batch [40/204] time 0.270 (0.300) data 0.000 (0.026) loss 0.8052 (0.4145) lr 1.0926e-04 eta 0:01:50
epoch [29/30] batch [60/204] time 0.270 (0.290) data 0.000 (0.017) loss 0.1338 (0.4712) lr 1.0926e-04 eta 0:01:40
epoch [29/30] batch [80/204] time 0.269 (0.286) data 0.000 (0.013) loss 1.5771 (0.4648) lr 1.0926e-04 eta 0:01:33
epoch [29/30] batch [100/204] time 0.269 (0.282) data 0.000 (0.010) loss 0.5376 (0.4340) lr 1.0926e-04 eta 0:01:26
epoch [29/30] batch [120/204] time 0.273 (0.280) data 0.000 (0.009) loss 0.6206 (0.4679) lr 1.0926e-04 eta 0:01:20
epoch [29/30] batch [140/204] time 0.277 (0.279) data 0.000 (0.008) loss 0.4365 (0.4984) lr 1.0926e-04 eta 0:01:14
epoch [29/30] batch [160/204] time 0.274 (0.278) data 0.000 (0.007) loss 8.1875 (0.5525) lr 1.0926e-04 eta 0:01:08
epoch [29/30] batch [180/204] time 0.250 (0.276) data 0.000 (0.006) loss 0.1163 (0.5555) lr 1.0926e-04 eta 0:01:03
epoch [29/30] batch [200/204] time 0.251 (0.274) data 0.000 (0.005) loss 0.4504 (0.5459) lr 1.0926e-04 eta 0:00:56
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.28it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.04it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.30it/s]=> result
* total: 696
* correct: 663
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 94.0%

epoch [30/30] batch [20/204] time 0.267 (0.328) data 0.000 (0.051) loss 0.3225 (0.4094) lr 2.7391e-05 eta 0:01:00
epoch [30/30] batch [40/204] time 0.270 (0.298) data 0.000 (0.026) loss 0.5874 (0.4667) lr 2.7391e-05 eta 0:00:48
epoch [30/30] batch [60/204] time 0.266 (0.288) data 0.000 (0.017) loss 0.2642 (0.4720) lr 2.7391e-05 eta 0:00:41
epoch [30/30] batch [80/204] time 0.265 (0.283) data 0.000 (0.013) loss 0.1765 (0.5297) lr 2.7391e-05 eta 0:00:35
epoch [30/30] batch [100/204] time 0.266 (0.280) data 0.000 (0.010) loss 0.1329 (0.5320) lr 2.7391e-05 eta 0:00:29
epoch [30/30] batch [120/204] time 0.267 (0.277) data 0.000 (0.009) loss 0.2156 (0.5088) lr 2.7391e-05 eta 0:00:23
epoch [30/30] batch [140/204] time 0.280 (0.276) data 0.000 (0.008) loss 0.0751 (0.5057) lr 2.7391e-05 eta 0:00:17
epoch [30/30] batch [160/204] time 0.382 (0.275) data 0.000 (0.007) loss 0.8403 (0.4955) lr 2.7391e-05 eta 0:00:12
epoch [30/30] batch [180/204] time 0.250 (0.274) data 0.000 (0.006) loss 0.2607 (0.4938) lr 2.7391e-05 eta 0:00:06
epoch [30/30] batch [200/204] time 0.253 (0.272) data 0.000 (0.005) loss 0.0665 (0.4941) lr 2.7391e-05 eta 0:00:01
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.13s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.03it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.70it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.44it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.21it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.95it/s]100%|██████████| 7/7 [00:02<00:00,  4.68it/s]100%|██████████| 7/7 [00:03<00:00,  2.25it/s]
=> result
* total: 696
* correct: 663
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 94.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 26)
Evaluate on the *test* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:02<00:25,  2.52s/it] 18%|█▊        | 2/11 [00:02<00:10,  1.12s/it] 27%|██▋       | 3/11 [00:02<00:05,  1.49it/s] 36%|███▋      | 4/11 [00:02<00:03,  2.18it/s] 45%|████▌     | 5/11 [00:03<00:02,  2.92it/s] 55%|█████▍    | 6/11 [00:03<00:01,  3.67it/s] 64%|██████▎   | 7/11 [00:03<00:00,  4.36it/s] 73%|███████▎  | 8/11 [00:03<00:00,  4.99it/s] 82%|████████▏ | 9/11 [00:03<00:00,  5.55it/s] 91%|█████████ | 10/11 [00:03<00:00,  6.01it/s]100%|██████████| 11/11 [00:03<00:00,  2.76it/s]
=> result
* total: 1,053
* correct: 1,025
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%
Elapsed: 0:29:39
+ sh scripts/rpo_prime/base2new_test_sdl.sh oxford_flowers 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
816 937 1410
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      937
# test     1,410
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 26)
Evaluate on the *test* set
  0%|          | 0/15 [00:00<?, ?it/s]  7%|▋         | 1/15 [00:04<01:06,  4.73s/it] 13%|█▎        | 2/15 [00:04<00:26,  2.03s/it] 20%|██        | 3/15 [00:05<00:13,  1.16s/it] 27%|██▋       | 4/15 [00:05<00:08,  1.32it/s] 33%|███▎      | 5/15 [00:05<00:05,  1.87it/s] 40%|████      | 6/15 [00:05<00:03,  2.51it/s] 47%|████▋     | 7/15 [00:05<00:02,  3.20it/s] 53%|█████▎    | 8/15 [00:05<00:01,  3.90it/s] 60%|██████    | 9/15 [00:05<00:01,  4.58it/s] 67%|██████▋   | 10/15 [00:05<00:00,  5.18it/s] 73%|███████▎  | 11/15 [00:06<00:00,  5.69it/s] 80%|████████  | 12/15 [00:06<00:00,  6.12it/s] 87%|████████▋ | 13/15 [00:06<00:00,  6.45it/s] 93%|█████████▎| 14/15 [00:06<00:00,  6.70it/s]100%|██████████| 15/15 [00:06<00:00,  2.26it/s]
=> result
* total: 1,410
* correct: 1,068
* accuracy: 75.7%
* error: 24.3%
* macro_f1: 70.1%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh oxford_flowers 2 0 main_tmp1_0.1sdl 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
816 696 1053
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      696
# test     1,053
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/204] time 0.277 (0.418) data 0.000 (0.064) loss 1.2637 (4.0062) lr 1.0000e-02 eta 0:42:27
epoch [1/30] batch [40/204] time 0.262 (0.344) data 0.000 (0.032) loss 1.4648 (3.2026) lr 1.0000e-02 eta 0:34:51
epoch [1/30] batch [60/204] time 0.261 (0.319) data 0.000 (0.022) loss 2.5840 (3.0332) lr 1.0000e-02 eta 0:32:10
epoch [1/30] batch [80/204] time 0.391 (0.308) data 0.000 (0.016) loss 0.9014 (2.9274) lr 1.0000e-02 eta 0:30:57
epoch [1/30] batch [100/204] time 0.269 (0.300) data 0.000 (0.013) loss 1.7900 (2.8877) lr 1.0000e-02 eta 0:30:05
epoch [1/30] batch [120/204] time 0.259 (0.294) data 0.000 (0.011) loss 1.9453 (2.8351) lr 1.0000e-02 eta 0:29:25
epoch [1/30] batch [140/204] time 0.267 (0.290) data 0.000 (0.009) loss 1.7529 (2.7678) lr 1.0000e-02 eta 0:28:56
epoch [1/30] batch [160/204] time 0.268 (0.288) data 0.000 (0.008) loss 3.5566 (2.7534) lr 1.0000e-02 eta 0:28:36
epoch [1/30] batch [180/204] time 0.249 (0.285) data 0.000 (0.007) loss 0.8271 (2.6926) lr 1.0000e-02 eta 0:28:11
epoch [1/30] batch [200/204] time 0.253 (0.282) data 0.000 (0.007) loss 3.0117 (2.6270) lr 1.0000e-02 eta 0:27:48
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.26s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.01s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.63it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.36it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.12it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.89it/s]100%|██████████| 7/7 [00:03<00:00,  4.57it/s]100%|██████████| 7/7 [00:03<00:00,  2.17it/s]=> result
* total: 696
* correct: 513
* accuracy: 73.7%
* error: 26.3%
* macro_f1: 68.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/204] time 0.261 (0.328) data 0.000 (0.049) loss 3.7090 (2.1387) lr 9.9726e-03 eta 0:32:12
epoch [2/30] batch [40/204] time 0.265 (0.297) data 0.000 (0.025) loss 0.7090 (2.0586) lr 9.9726e-03 eta 0:29:06
epoch [2/30] batch [60/204] time 0.269 (0.288) data 0.000 (0.017) loss 2.0352 (1.9484) lr 9.9726e-03 eta 0:28:04
epoch [2/30] batch [80/204] time 0.268 (0.283) data 0.000 (0.013) loss 3.7207 (1.9391) lr 9.9726e-03 eta 0:27:32
epoch [2/30] batch [100/204] time 0.274 (0.281) data 0.000 (0.010) loss 0.8110 (2.0674) lr 9.9726e-03 eta 0:27:16
epoch [2/30] batch [120/204] time 0.266 (0.279) data 0.000 (0.009) loss 1.7881 (2.0709) lr 9.9726e-03 eta 0:26:58
epoch [2/30] batch [140/204] time 0.267 (0.278) data 0.000 (0.007) loss 1.3799 (2.0587) lr 9.9726e-03 eta 0:26:43
epoch [2/30] batch [160/204] time 0.263 (0.276) data 0.000 (0.006) loss 1.2695 (2.1093) lr 9.9726e-03 eta 0:26:30
epoch [2/30] batch [180/204] time 0.249 (0.275) data 0.000 (0.006) loss 1.7070 (2.0469) lr 9.9726e-03 eta 0:26:15
epoch [2/30] batch [200/204] time 0.248 (0.272) data 0.000 (0.005) loss 1.2988 (2.0598) lr 9.9726e-03 eta 0:25:55
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.27it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.04it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.29it/s]=> result
* total: 696
* correct: 532
* accuracy: 76.4%
* error: 23.6%
* macro_f1: 71.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/204] time 0.264 (0.334) data 0.000 (0.050) loss 5.2422 (2.0225) lr 9.8907e-03 eta 0:31:38
epoch [3/30] batch [40/204] time 0.267 (0.300) data 0.000 (0.025) loss 1.4893 (2.1464) lr 9.8907e-03 eta 0:28:18
epoch [3/30] batch [60/204] time 0.269 (0.289) data 0.000 (0.017) loss 1.9375 (1.9638) lr 9.8907e-03 eta 0:27:14
epoch [3/30] batch [80/204] time 0.263 (0.285) data 0.000 (0.013) loss 0.8979 (1.9154) lr 9.8907e-03 eta 0:26:44
epoch [3/30] batch [100/204] time 0.272 (0.282) data 0.000 (0.010) loss 4.0469 (1.9139) lr 9.8907e-03 eta 0:26:21
epoch [3/30] batch [120/204] time 0.264 (0.279) data 0.000 (0.009) loss 3.1621 (1.8821) lr 9.8907e-03 eta 0:26:02
epoch [3/30] batch [140/204] time 0.263 (0.278) data 0.000 (0.007) loss 0.5278 (1.8587) lr 9.8907e-03 eta 0:25:50
epoch [3/30] batch [160/204] time 0.278 (0.277) data 0.000 (0.007) loss 1.6650 (1.8380) lr 9.8907e-03 eta 0:25:38
epoch [3/30] batch [180/204] time 0.253 (0.275) data 0.000 (0.006) loss 1.9785 (1.8352) lr 9.8907e-03 eta 0:25:23
epoch [3/30] batch [200/204] time 0.252 (0.273) data 0.000 (0.005) loss 4.1289 (1.8219) lr 9.8907e-03 eta 0:25:06
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.13s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.72it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.46it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.24it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.00it/s]100%|██████████| 7/7 [00:02<00:00,  4.73it/s]100%|██████████| 7/7 [00:03<00:00,  2.27it/s]=> result
* total: 696
* correct: 553
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 75.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/204] time 0.271 (0.329) data 0.000 (0.049) loss 2.5273 (1.9536) lr 9.7553e-03 eta 0:30:07
epoch [4/30] batch [40/204] time 0.263 (0.298) data 0.000 (0.025) loss 2.2891 (1.6824) lr 9.7553e-03 eta 0:27:10
epoch [4/30] batch [60/204] time 0.268 (0.289) data 0.000 (0.017) loss 3.0059 (1.7833) lr 9.7553e-03 eta 0:26:11
epoch [4/30] batch [80/204] time 0.260 (0.283) data 0.000 (0.013) loss 1.7910 (1.7721) lr 9.7553e-03 eta 0:25:38
epoch [4/30] batch [100/204] time 0.276 (0.281) data 0.000 (0.010) loss 0.2922 (1.7057) lr 9.7553e-03 eta 0:25:17
epoch [4/30] batch [120/204] time 0.271 (0.280) data 0.000 (0.009) loss 0.2444 (1.6414) lr 9.7553e-03 eta 0:25:08
epoch [4/30] batch [140/204] time 0.261 (0.278) data 0.000 (0.007) loss 2.1758 (1.6616) lr 9.7553e-03 eta 0:24:53
epoch [4/30] batch [160/204] time 0.265 (0.277) data 0.000 (0.006) loss 2.6660 (1.6475) lr 9.7553e-03 eta 0:24:42
epoch [4/30] batch [180/204] time 0.253 (0.276) data 0.000 (0.006) loss 0.9492 (1.6412) lr 9.7553e-03 eta 0:24:30
epoch [4/30] batch [200/204] time 0.252 (0.274) data 0.000 (0.005) loss 2.3613 (1.6350) lr 9.7553e-03 eta 0:24:12
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.75it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.50it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.28it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.04it/s]100%|██████████| 7/7 [00:02<00:00,  4.77it/s]100%|██████████| 7/7 [00:03<00:00,  2.30it/s]=> result
* total: 696
* correct: 581
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 81.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/204] time 0.264 (0.325) data 0.000 (0.050) loss 0.0748 (1.3493) lr 9.5677e-03 eta 0:28:37
epoch [5/30] batch [40/204] time 0.272 (0.297) data 0.000 (0.025) loss 0.3462 (1.2996) lr 9.5677e-03 eta 0:26:03
epoch [5/30] batch [60/204] time 0.269 (0.290) data 0.000 (0.017) loss 2.1484 (1.3979) lr 9.5677e-03 eta 0:25:18
epoch [5/30] batch [80/204] time 0.262 (0.284) data 0.000 (0.013) loss 3.0625 (1.4706) lr 9.5677e-03 eta 0:24:45
epoch [5/30] batch [100/204] time 0.264 (0.281) data 0.000 (0.010) loss 2.0293 (1.4927) lr 9.5677e-03 eta 0:24:22
epoch [5/30] batch [120/204] time 0.264 (0.279) data 0.000 (0.009) loss 0.6846 (1.4356) lr 9.5677e-03 eta 0:24:07
epoch [5/30] batch [140/204] time 0.257 (0.278) data 0.000 (0.007) loss 2.7285 (1.4230) lr 9.5677e-03 eta 0:23:53
epoch [5/30] batch [160/204] time 0.271 (0.276) data 0.000 (0.006) loss 2.9297 (1.4794) lr 9.5677e-03 eta 0:23:41
epoch [5/30] batch [180/204] time 0.252 (0.275) data 0.000 (0.006) loss 0.6353 (1.4657) lr 9.5677e-03 eta 0:23:28
epoch [5/30] batch [200/204] time 0.256 (0.273) data 0.000 (0.005) loss 0.3655 (1.4299) lr 9.5677e-03 eta 0:23:12
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.19s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.02it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.68it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.41it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.19it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.95it/s]100%|██████████| 7/7 [00:03<00:00,  4.68it/s]100%|██████████| 7/7 [00:03<00:00,  2.23it/s]=> result
* total: 696
* correct: 604
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 83.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/204] time 0.267 (0.332) data 0.000 (0.050) loss 3.8301 (1.6970) lr 9.3301e-03 eta 0:28:05
epoch [6/30] batch [40/204] time 0.269 (0.300) data 0.000 (0.025) loss 2.6523 (1.4151) lr 9.3301e-03 eta 0:25:19
epoch [6/30] batch [60/204] time 0.263 (0.289) data 0.000 (0.017) loss 0.5879 (1.3621) lr 9.3301e-03 eta 0:24:18
epoch [6/30] batch [80/204] time 0.269 (0.284) data 0.000 (0.013) loss 0.3875 (1.3709) lr 9.3301e-03 eta 0:23:43
epoch [6/30] batch [100/204] time 0.268 (0.281) data 0.000 (0.010) loss 3.4570 (1.3948) lr 9.3301e-03 eta 0:23:22
epoch [6/30] batch [120/204] time 0.267 (0.279) data 0.000 (0.009) loss 1.2773 (1.4007) lr 9.3301e-03 eta 0:23:10
epoch [6/30] batch [140/204] time 0.264 (0.278) data 0.000 (0.007) loss 2.0410 (1.4177) lr 9.3301e-03 eta 0:22:58
epoch [6/30] batch [160/204] time 0.266 (0.277) data 0.000 (0.006) loss 2.3730 (1.3838) lr 9.3301e-03 eta 0:22:47
epoch [6/30] batch [180/204] time 0.252 (0.275) data 0.000 (0.006) loss 3.4609 (1.3859) lr 9.3301e-03 eta 0:22:34
epoch [6/30] batch [200/204] time 0.254 (0.273) data 0.000 (0.005) loss 0.5918 (1.3692) lr 9.3301e-03 eta 0:22:20
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.16s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.02it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.68it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.41it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.19it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.95it/s]100%|██████████| 7/7 [00:02<00:00,  4.68it/s]100%|██████████| 7/7 [00:03<00:00,  2.24it/s]=> result
* total: 696
* correct: 615
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 86.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/204] time 0.267 (0.323) data 0.000 (0.050) loss 1.6016 (1.2811) lr 9.0451e-03 eta 0:26:12
epoch [7/30] batch [40/204] time 0.272 (0.296) data 0.000 (0.025) loss 0.0718 (1.2362) lr 9.0451e-03 eta 0:23:59
epoch [7/30] batch [60/204] time 0.271 (0.287) data 0.000 (0.017) loss 3.3750 (1.1977) lr 9.0451e-03 eta 0:23:09
epoch [7/30] batch [80/204] time 0.331 (0.285) data 0.000 (0.013) loss 1.4053 (1.1936) lr 9.0451e-03 eta 0:22:50
epoch [7/30] batch [100/204] time 0.277 (0.281) data 0.000 (0.010) loss 2.0020 (1.1943) lr 9.0451e-03 eta 0:22:30
epoch [7/30] batch [120/204] time 0.265 (0.279) data 0.000 (0.009) loss 2.0176 (1.1900) lr 9.0451e-03 eta 0:22:13
epoch [7/30] batch [140/204] time 0.268 (0.278) data 0.000 (0.007) loss 1.7754 (1.1546) lr 9.0451e-03 eta 0:22:03
epoch [7/30] batch [160/204] time 0.274 (0.278) data 0.000 (0.006) loss 0.3308 (1.1658) lr 9.0451e-03 eta 0:21:56
epoch [7/30] batch [180/204] time 0.253 (0.276) data 0.000 (0.006) loss 1.5303 (1.1484) lr 9.0451e-03 eta 0:21:43
epoch [7/30] batch [200/204] time 0.256 (0.274) data 0.001 (0.005) loss 1.6494 (1.1216) lr 9.0451e-03 eta 0:21:26
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.23s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.00it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.65it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.37it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.14it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.90it/s]100%|██████████| 7/7 [00:03<00:00,  4.63it/s]100%|██████████| 7/7 [00:03<00:00,  2.19it/s]=> result
* total: 696
* correct: 611
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 85.0%

epoch [8/30] batch [20/204] time 0.269 (0.322) data 0.000 (0.050) loss 1.6670 (1.2630) lr 8.7157e-03 eta 0:25:06
epoch [8/30] batch [40/204] time 0.274 (0.296) data 0.000 (0.025) loss 0.2500 (1.3240) lr 8.7157e-03 eta 0:22:58
epoch [8/30] batch [60/204] time 0.269 (0.289) data 0.000 (0.017) loss 1.0098 (1.2624) lr 8.7157e-03 eta 0:22:18
epoch [8/30] batch [80/204] time 0.269 (0.284) data 0.000 (0.013) loss 0.9199 (1.2653) lr 8.7157e-03 eta 0:21:51
epoch [8/30] batch [100/204] time 0.272 (0.281) data 0.000 (0.010) loss 1.4951 (1.2217) lr 8.7157e-03 eta 0:21:30
epoch [8/30] batch [120/204] time 0.268 (0.279) data 0.000 (0.009) loss 0.1213 (1.2045) lr 8.7157e-03 eta 0:21:14
epoch [8/30] batch [140/204] time 0.270 (0.277) data 0.000 (0.007) loss 1.3936 (1.1749) lr 8.7157e-03 eta 0:21:01
epoch [8/30] batch [160/204] time 0.269 (0.276) data 0.001 (0.007) loss 3.1406 (1.1758) lr 8.7157e-03 eta 0:20:51
epoch [8/30] batch [180/204] time 0.253 (0.275) data 0.000 (0.006) loss 0.5171 (1.1672) lr 8.7157e-03 eta 0:20:39
epoch [8/30] batch [200/204] time 0.248 (0.273) data 0.000 (0.005) loss 0.2227 (1.1545) lr 8.7157e-03 eta 0:20:25
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.11s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.48it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.26it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.02it/s]100%|██████████| 7/7 [00:02<00:00,  4.74it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 623
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 88.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/204] time 0.268 (0.323) data 0.000 (0.050) loss 2.0078 (1.2094) lr 8.3457e-03 eta 0:24:03
epoch [9/30] batch [40/204] time 0.276 (0.296) data 0.000 (0.025) loss 0.6040 (1.1543) lr 8.3457e-03 eta 0:21:55
epoch [9/30] batch [60/204] time 0.266 (0.287) data 0.000 (0.017) loss 1.2969 (1.0666) lr 8.3457e-03 eta 0:21:12
epoch [9/30] batch [80/204] time 0.259 (0.284) data 0.000 (0.013) loss 1.8164 (1.1371) lr 8.3457e-03 eta 0:20:53
epoch [9/30] batch [100/204] time 0.267 (0.281) data 0.000 (0.010) loss 0.9209 (1.1185) lr 8.3457e-03 eta 0:20:33
epoch [9/30] batch [120/204] time 0.270 (0.279) data 0.000 (0.009) loss 1.1289 (1.0476) lr 8.3457e-03 eta 0:20:19
epoch [9/30] batch [140/204] time 0.275 (0.278) data 0.000 (0.007) loss 1.2021 (1.0308) lr 8.3457e-03 eta 0:20:07
epoch [9/30] batch [160/204] time 0.272 (0.277) data 0.000 (0.007) loss 0.8447 (1.0670) lr 8.3457e-03 eta 0:20:00
epoch [9/30] batch [180/204] time 0.255 (0.276) data 0.000 (0.006) loss 1.6279 (1.1136) lr 8.3457e-03 eta 0:19:47
epoch [9/30] batch [200/204] time 0.252 (0.273) data 0.000 (0.005) loss 1.0049 (1.0966) lr 8.3457e-03 eta 0:19:32
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.48it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.25it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.01it/s]100%|██████████| 7/7 [00:02<00:00,  4.74it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 625
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 88.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/204] time 0.267 (0.321) data 0.000 (0.051) loss 1.5645 (0.8863) lr 7.9389e-03 eta 0:22:49
epoch [10/30] batch [40/204] time 0.265 (0.295) data 0.000 (0.026) loss 0.9272 (0.9388) lr 7.9389e-03 eta 0:20:51
epoch [10/30] batch [60/204] time 0.270 (0.288) data 0.000 (0.017) loss 1.9248 (0.9728) lr 7.9389e-03 eta 0:20:15
epoch [10/30] batch [80/204] time 0.265 (0.284) data 0.000 (0.013) loss 3.5195 (1.0864) lr 7.9389e-03 eta 0:19:53
epoch [10/30] batch [100/204] time 0.268 (0.281) data 0.000 (0.010) loss 0.2343 (1.0681) lr 7.9389e-03 eta 0:19:34
epoch [10/30] batch [120/204] time 0.266 (0.279) data 0.000 (0.009) loss 0.2622 (1.0399) lr 7.9389e-03 eta 0:19:21
epoch [10/30] batch [140/204] time 0.265 (0.277) data 0.000 (0.008) loss 1.5332 (0.9969) lr 7.9389e-03 eta 0:19:08
epoch [10/30] batch [160/204] time 0.268 (0.276) data 0.000 (0.007) loss 0.8652 (0.9947) lr 7.9389e-03 eta 0:18:58
epoch [10/30] batch [180/204] time 0.252 (0.274) data 0.000 (0.006) loss 1.5254 (0.9501) lr 7.9389e-03 eta 0:18:46
epoch [10/30] batch [200/204] time 0.251 (0.272) data 0.000 (0.005) loss 1.4424 (0.9606) lr 7.9389e-03 eta 0:18:31
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.25s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.01s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.64it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.36it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.13it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.89it/s]100%|██████████| 7/7 [00:03<00:00,  4.62it/s]100%|██████████| 7/7 [00:03<00:00,  2.18it/s]=> result
* total: 696
* correct: 638
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 89.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/204] time 0.268 (0.327) data 0.000 (0.050) loss 0.3721 (0.8302) lr 7.5000e-03 eta 0:22:09
epoch [11/30] batch [40/204] time 0.265 (0.297) data 0.000 (0.025) loss 1.4033 (0.8569) lr 7.5000e-03 eta 0:20:01
epoch [11/30] batch [60/204] time 0.269 (0.288) data 0.000 (0.017) loss 0.5596 (0.9885) lr 7.5000e-03 eta 0:19:17
epoch [11/30] batch [80/204] time 0.268 (0.283) data 0.001 (0.013) loss 1.3076 (0.9942) lr 7.5000e-03 eta 0:18:51
epoch [11/30] batch [100/204] time 0.269 (0.280) data 0.000 (0.010) loss 1.7959 (1.0567) lr 7.5000e-03 eta 0:18:35
epoch [11/30] batch [120/204] time 0.267 (0.278) data 0.000 (0.009) loss 1.3320 (1.1342) lr 7.5000e-03 eta 0:18:20
epoch [11/30] batch [140/204] time 0.261 (0.276) data 0.000 (0.007) loss 0.5063 (1.1027) lr 7.5000e-03 eta 0:18:09
epoch [11/30] batch [160/204] time 0.271 (0.275) data 0.000 (0.007) loss 0.6045 (1.0813) lr 7.5000e-03 eta 0:17:59
epoch [11/30] batch [180/204] time 0.253 (0.275) data 0.000 (0.006) loss 0.8457 (1.0794) lr 7.5000e-03 eta 0:17:50
epoch [11/30] batch [200/204] time 0.253 (0.272) data 0.000 (0.005) loss 0.1941 (1.0519) lr 7.5000e-03 eta 0:17:37
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.24s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.00s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.65it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.38it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.14it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.91it/s]100%|██████████| 7/7 [00:03<00:00,  4.64it/s]100%|██████████| 7/7 [00:03<00:00,  2.19it/s]=> result
* total: 696
* correct: 643
* accuracy: 92.4%
* error: 7.6%
* macro_f1: 90.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/204] time 0.265 (0.324) data 0.000 (0.050) loss 0.2291 (0.9511) lr 7.0337e-03 eta 0:20:47
epoch [12/30] batch [40/204] time 0.266 (0.297) data 0.000 (0.025) loss 0.1931 (0.9885) lr 7.0337e-03 eta 0:18:59
epoch [12/30] batch [60/204] time 0.264 (0.290) data 0.000 (0.017) loss 1.4775 (0.8504) lr 7.0337e-03 eta 0:18:25
epoch [12/30] batch [80/204] time 0.267 (0.285) data 0.000 (0.013) loss 0.7080 (0.8091) lr 7.0337e-03 eta 0:18:00
epoch [12/30] batch [100/204] time 0.282 (0.281) data 0.000 (0.010) loss 0.0201 (0.8686) lr 7.0337e-03 eta 0:17:42
epoch [12/30] batch [120/204] time 0.276 (0.280) data 0.000 (0.009) loss 1.1748 (0.8457) lr 7.0337e-03 eta 0:17:32
epoch [12/30] batch [140/204] time 0.273 (0.279) data 0.000 (0.007) loss 1.6484 (0.8711) lr 7.0337e-03 eta 0:17:23
epoch [12/30] batch [160/204] time 0.272 (0.278) data 0.000 (0.007) loss 0.2144 (0.8945) lr 7.0337e-03 eta 0:17:13
epoch [12/30] batch [180/204] time 0.248 (0.276) data 0.000 (0.006) loss 0.5547 (0.8628) lr 7.0337e-03 eta 0:17:01
epoch [12/30] batch [200/204] time 0.250 (0.274) data 0.000 (0.005) loss 0.1307 (0.8930) lr 7.0337e-03 eta 0:16:48
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.14s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.71it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.45it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.23it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.99it/s]100%|██████████| 7/7 [00:02<00:00,  4.71it/s]100%|██████████| 7/7 [00:03<00:00,  2.26it/s]=> result
* total: 696
* correct: 646
* accuracy: 92.8%
* error: 7.2%
* macro_f1: 92.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [13/30] batch [20/204] time 0.270 (0.323) data 0.000 (0.049) loss 0.1733 (0.6820) lr 6.5451e-03 eta 0:19:40
epoch [13/30] batch [40/204] time 0.264 (0.295) data 0.000 (0.025) loss 0.2939 (0.6068) lr 6.5451e-03 eta 0:17:51
epoch [13/30] batch [60/204] time 0.269 (0.288) data 0.000 (0.017) loss 0.6143 (0.6716) lr 6.5451e-03 eta 0:17:21
epoch [13/30] batch [80/204] time 0.292 (0.284) data 0.000 (0.013) loss 0.6235 (0.7958) lr 6.5451e-03 eta 0:16:59
epoch [13/30] batch [100/204] time 0.279 (0.281) data 0.000 (0.010) loss 2.3438 (0.8496) lr 6.5451e-03 eta 0:16:43
epoch [13/30] batch [120/204] time 0.267 (0.279) data 0.000 (0.008) loss 0.0452 (0.8189) lr 6.5451e-03 eta 0:16:31
epoch [13/30] batch [140/204] time 0.265 (0.278) data 0.000 (0.007) loss 0.6221 (0.8015) lr 6.5451e-03 eta 0:16:20
epoch [13/30] batch [160/204] time 0.283 (0.277) data 0.000 (0.006) loss 1.1875 (0.8427) lr 6.5451e-03 eta 0:16:13
epoch [13/30] batch [180/204] time 0.253 (0.276) data 0.000 (0.006) loss 0.3992 (0.8263) lr 6.5451e-03 eta 0:16:02
epoch [13/30] batch [200/204] time 0.252 (0.273) data 0.000 (0.005) loss 0.9927 (0.8332) lr 6.5451e-03 eta 0:15:48
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.13s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.71it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.46it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.23it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.99it/s]100%|██████████| 7/7 [00:02<00:00,  4.72it/s]100%|██████████| 7/7 [00:03<00:00,  2.26it/s]=> result
* total: 696
* correct: 651
* accuracy: 93.5%
* error: 6.5%
* macro_f1: 91.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [14/30] batch [20/204] time 0.276 (0.331) data 0.000 (0.053) loss 0.3120 (0.6414) lr 6.0396e-03 eta 0:18:59
epoch [14/30] batch [40/204] time 0.265 (0.301) data 0.000 (0.027) loss 0.2012 (0.6694) lr 6.0396e-03 eta 0:17:11
epoch [14/30] batch [60/204] time 0.269 (0.290) data 0.000 (0.018) loss 0.4282 (0.6390) lr 6.0396e-03 eta 0:16:28
epoch [14/30] batch [80/204] time 0.270 (0.287) data 0.000 (0.013) loss 0.8525 (0.6449) lr 6.0396e-03 eta 0:16:10
epoch [14/30] batch [100/204] time 0.263 (0.283) data 0.000 (0.011) loss 2.0469 (0.7724) lr 6.0396e-03 eta 0:15:52
epoch [14/30] batch [120/204] time 0.271 (0.281) data 0.000 (0.009) loss 0.1987 (0.7918) lr 6.0396e-03 eta 0:15:40
epoch [14/30] batch [140/204] time 0.265 (0.279) data 0.000 (0.008) loss 1.1348 (0.8706) lr 6.0396e-03 eta 0:15:29
epoch [14/30] batch [160/204] time 0.273 (0.278) data 0.000 (0.007) loss 2.0508 (0.8680) lr 6.0396e-03 eta 0:15:19
epoch [14/30] batch [180/204] time 0.251 (0.276) data 0.000 (0.006) loss 0.8579 (0.8463) lr 6.0396e-03 eta 0:15:08
epoch [14/30] batch [200/204] time 0.250 (0.274) data 0.000 (0.006) loss 0.1565 (0.8309) lr 6.0396e-03 eta 0:14:54
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.20s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.01it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.67it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.40it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.17it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.93it/s]100%|██████████| 7/7 [00:03<00:00,  4.66it/s]100%|██████████| 7/7 [00:03<00:00,  2.21it/s]=> result
* total: 696
* correct: 655
* accuracy: 94.1%
* error: 5.9%
* macro_f1: 92.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/204] time 0.267 (0.331) data 0.000 (0.053) loss 0.3057 (0.4930) lr 5.5226e-03 eta 0:17:53
epoch [15/30] batch [40/204] time 0.274 (0.299) data 0.000 (0.027) loss 0.1838 (0.4620) lr 5.5226e-03 eta 0:16:05
epoch [15/30] batch [60/204] time 0.271 (0.289) data 0.000 (0.018) loss 0.1522 (0.5434) lr 5.5226e-03 eta 0:15:27
epoch [15/30] batch [80/204] time 0.267 (0.284) data 0.000 (0.013) loss 0.1218 (0.6247) lr 5.5226e-03 eta 0:15:04
epoch [15/30] batch [100/204] time 0.269 (0.281) data 0.000 (0.011) loss 2.5234 (0.6347) lr 5.5226e-03 eta 0:14:48
epoch [15/30] batch [120/204] time 0.263 (0.279) data 0.000 (0.009) loss 0.7349 (0.6306) lr 5.5226e-03 eta 0:14:37
epoch [15/30] batch [140/204] time 0.363 (0.278) data 0.000 (0.008) loss 0.5996 (0.6633) lr 5.5226e-03 eta 0:14:28
epoch [15/30] batch [160/204] time 0.266 (0.277) data 0.000 (0.007) loss 0.1978 (0.7189) lr 5.5226e-03 eta 0:14:19
epoch [15/30] batch [180/204] time 0.253 (0.275) data 0.000 (0.006) loss 1.6973 (0.7152) lr 5.5226e-03 eta 0:14:09
epoch [15/30] batch [200/204] time 0.253 (0.273) data 0.000 (0.006) loss 3.0020 (0.7359) lr 5.5226e-03 eta 0:13:57
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.11s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.47it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.25it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.01it/s]100%|██████████| 7/7 [00:02<00:00,  4.74it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 655
* accuracy: 94.1%
* error: 5.9%
* macro_f1: 92.8%

epoch [16/30] batch [20/204] time 0.265 (0.331) data 0.000 (0.052) loss 0.2380 (0.5670) lr 5.0000e-03 eta 0:16:46
epoch [16/30] batch [40/204] time 0.279 (0.301) data 0.000 (0.026) loss 0.0677 (0.5889) lr 5.0000e-03 eta 0:15:09
epoch [16/30] batch [60/204] time 0.292 (0.290) data 0.000 (0.018) loss 0.3118 (0.6043) lr 5.0000e-03 eta 0:14:30
epoch [16/30] batch [80/204] time 0.263 (0.286) data 0.000 (0.013) loss 0.1807 (0.6041) lr 5.0000e-03 eta 0:14:11
epoch [16/30] batch [100/204] time 0.270 (0.284) data 0.000 (0.011) loss 2.3789 (0.6657) lr 5.0000e-03 eta 0:13:59
epoch [16/30] batch [120/204] time 0.279 (0.281) data 0.000 (0.009) loss 0.7393 (0.6871) lr 5.0000e-03 eta 0:13:47
epoch [16/30] batch [140/204] time 0.315 (0.280) data 0.000 (0.008) loss 0.1688 (0.7082) lr 5.0000e-03 eta 0:13:37
epoch [16/30] batch [160/204] time 0.273 (0.279) data 0.000 (0.007) loss 0.0668 (0.6865) lr 5.0000e-03 eta 0:13:29
epoch [16/30] batch [180/204] time 0.255 (0.277) data 0.000 (0.006) loss 0.8237 (0.6821) lr 5.0000e-03 eta 0:13:18
epoch [16/30] batch [200/204] time 0.252 (0.275) data 0.000 (0.005) loss 0.5645 (0.6875) lr 5.0000e-03 eta 0:13:06
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.13s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.71it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.46it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.23it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.99it/s]100%|██████████| 7/7 [00:02<00:00,  4.72it/s]100%|██████████| 7/7 [00:03<00:00,  2.26it/s]=> result
* total: 696
* correct: 652
* accuracy: 93.7%
* error: 6.3%
* macro_f1: 92.4%

epoch [17/30] batch [20/204] time 0.277 (0.326) data 0.000 (0.050) loss 0.4324 (0.8880) lr 4.4774e-03 eta 0:15:23
epoch [17/30] batch [40/204] time 0.268 (0.297) data 0.000 (0.025) loss 0.2350 (0.7603) lr 4.4774e-03 eta 0:13:55
epoch [17/30] batch [60/204] time 0.270 (0.289) data 0.000 (0.017) loss 0.0776 (0.6791) lr 4.4774e-03 eta 0:13:29
epoch [17/30] batch [80/204] time 0.277 (0.284) data 0.000 (0.013) loss 1.9170 (0.6391) lr 4.4774e-03 eta 0:13:08
epoch [17/30] batch [100/204] time 0.267 (0.281) data 0.000 (0.010) loss 0.1875 (0.6758) lr 4.4774e-03 eta 0:12:54
epoch [17/30] batch [120/204] time 0.260 (0.279) data 0.000 (0.009) loss 0.3362 (0.6624) lr 4.4774e-03 eta 0:12:42
epoch [17/30] batch [140/204] time 0.270 (0.278) data 0.000 (0.007) loss 0.2258 (0.7251) lr 4.4774e-03 eta 0:12:34
epoch [17/30] batch [160/204] time 0.261 (0.277) data 0.000 (0.007) loss 1.5488 (0.7298) lr 4.4774e-03 eta 0:12:25
epoch [17/30] batch [180/204] time 0.254 (0.275) data 0.000 (0.006) loss 0.8394 (0.7161) lr 4.4774e-03 eta 0:12:16
epoch [17/30] batch [200/204] time 0.253 (0.273) data 0.000 (0.005) loss 1.1484 (0.7141) lr 4.4774e-03 eta 0:12:05
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.48it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.26it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.03it/s]100%|██████████| 7/7 [00:02<00:00,  4.75it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 655
* accuracy: 94.1%
* error: 5.9%
* macro_f1: 93.3%

epoch [18/30] batch [20/204] time 0.265 (0.330) data 0.000 (0.050) loss 0.1367 (0.3557) lr 3.9604e-03 eta 0:14:28
epoch [18/30] batch [40/204] time 0.269 (0.299) data 0.000 (0.025) loss 1.1406 (0.6490) lr 3.9604e-03 eta 0:13:01
epoch [18/30] batch [60/204] time 0.274 (0.290) data 0.000 (0.017) loss 0.5127 (0.7474) lr 3.9604e-03 eta 0:12:30
epoch [18/30] batch [80/204] time 0.272 (0.284) data 0.000 (0.013) loss 1.8672 (0.6952) lr 3.9604e-03 eta 0:12:11
epoch [18/30] batch [100/204] time 0.263 (0.282) data 0.000 (0.010) loss 0.4778 (0.6614) lr 3.9604e-03 eta 0:11:58
epoch [18/30] batch [120/204] time 0.378 (0.280) data 0.000 (0.009) loss 0.7422 (0.6381) lr 3.9604e-03 eta 0:11:50
epoch [18/30] batch [140/204] time 0.271 (0.279) data 0.000 (0.007) loss 0.8545 (0.6327) lr 3.9604e-03 eta 0:11:40
epoch [18/30] batch [160/204] time 0.271 (0.278) data 0.000 (0.007) loss 0.0853 (0.6357) lr 3.9604e-03 eta 0:11:32
epoch [18/30] batch [180/204] time 0.253 (0.276) data 0.000 (0.006) loss 0.1763 (0.6452) lr 3.9604e-03 eta 0:11:22
epoch [18/30] batch [200/204] time 0.251 (0.274) data 0.000 (0.005) loss 0.5645 (0.6692) lr 3.9604e-03 eta 0:11:12
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.27it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.03it/s]100%|██████████| 7/7 [00:02<00:00,  4.75it/s]100%|██████████| 7/7 [00:03<00:00,  2.29it/s]=> result
* total: 696
* correct: 653
* accuracy: 93.8%
* error: 6.2%
* macro_f1: 92.7%

epoch [19/30] batch [20/204] time 0.278 (0.325) data 0.000 (0.051) loss 0.2595 (0.3833) lr 3.4549e-03 eta 0:13:09
epoch [19/30] batch [40/204] time 0.281 (0.297) data 0.000 (0.026) loss 0.3435 (0.5668) lr 3.4549e-03 eta 0:11:54
epoch [19/30] batch [60/204] time 0.266 (0.287) data 0.000 (0.017) loss 1.4346 (0.6313) lr 3.4549e-03 eta 0:11:26
epoch [19/30] batch [80/204] time 0.273 (0.284) data 0.000 (0.013) loss -0.0106 (0.5710) lr 3.4549e-03 eta 0:11:13
epoch [19/30] batch [100/204] time 0.303 (0.282) data 0.000 (0.011) loss 0.0551 (0.5905) lr 3.4549e-03 eta 0:11:01
epoch [19/30] batch [120/204] time 0.268 (0.280) data 0.000 (0.009) loss 1.1885 (0.6064) lr 3.4549e-03 eta 0:10:51
epoch [19/30] batch [140/204] time 0.275 (0.279) data 0.000 (0.008) loss 0.0447 (0.6114) lr 3.4549e-03 eta 0:10:44
epoch [19/30] batch [160/204] time 0.268 (0.278) data 0.000 (0.007) loss 1.5967 (0.6120) lr 3.4549e-03 eta 0:10:36
epoch [19/30] batch [180/204] time 0.250 (0.276) data 0.000 (0.006) loss 0.0871 (0.5779) lr 3.4549e-03 eta 0:10:26
epoch [19/30] batch [200/204] time 0.251 (0.274) data 0.000 (0.005) loss 2.0527 (0.5922) lr 3.4549e-03 eta 0:10:15
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.13s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.71it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.45it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.23it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.98it/s]100%|██████████| 7/7 [00:02<00:00,  4.71it/s]100%|██████████| 7/7 [00:03<00:00,  2.25it/s]=> result
* total: 696
* correct: 659
* accuracy: 94.7%
* error: 5.3%
* macro_f1: 93.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [20/30] batch [20/204] time 0.263 (0.327) data 0.000 (0.051) loss 1.5547 (0.7206) lr 2.9663e-03 eta 0:12:08
epoch [20/30] batch [40/204] time 0.258 (0.297) data 0.000 (0.026) loss 0.5283 (0.4775) lr 2.9663e-03 eta 0:10:53
epoch [20/30] batch [60/204] time 0.298 (0.288) data 0.000 (0.017) loss 0.2401 (0.4751) lr 2.9663e-03 eta 0:10:28
epoch [20/30] batch [80/204] time 0.267 (0.284) data 0.000 (0.013) loss 0.1313 (0.5164) lr 2.9663e-03 eta 0:10:14
epoch [20/30] batch [100/204] time 0.262 (0.280) data 0.000 (0.010) loss 0.1209 (0.5083) lr 2.9663e-03 eta 0:10:00
epoch [20/30] batch [120/204] time 0.272 (0.279) data 0.001 (0.009) loss 0.1422 (0.5078) lr 2.9663e-03 eta 0:09:53
epoch [20/30] batch [140/204] time 0.270 (0.278) data 0.000 (0.007) loss 1.1533 (0.5568) lr 2.9663e-03 eta 0:09:44
epoch [20/30] batch [160/204] time 0.274 (0.276) data 0.000 (0.007) loss 1.7402 (0.5478) lr 2.9663e-03 eta 0:09:35
epoch [20/30] batch [180/204] time 0.250 (0.275) data 0.000 (0.006) loss -0.0339 (0.5313) lr 2.9663e-03 eta 0:09:27
epoch [20/30] batch [200/204] time 0.249 (0.273) data 0.000 (0.005) loss 0.2305 (0.5349) lr 2.9663e-03 eta 0:09:17
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.11s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.48it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.26it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.02it/s]100%|██████████| 7/7 [00:02<00:00,  4.75it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 660
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 94.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/204] time 0.264 (0.321) data 0.000 (0.051) loss 0.4124 (0.6224) lr 2.5000e-03 eta 0:10:48
epoch [21/30] batch [40/204] time 0.265 (0.295) data 0.000 (0.026) loss 0.4590 (0.5489) lr 2.5000e-03 eta 0:09:49
epoch [21/30] batch [60/204] time 0.261 (0.287) data 0.000 (0.017) loss 0.0850 (0.5706) lr 2.5000e-03 eta 0:09:29
epoch [21/30] batch [80/204] time 0.264 (0.282) data 0.000 (0.013) loss 0.1509 (0.5505) lr 2.5000e-03 eta 0:09:12
epoch [21/30] batch [100/204] time 0.263 (0.279) data 0.000 (0.010) loss 0.3032 (0.5059) lr 2.5000e-03 eta 0:09:01
epoch [21/30] batch [120/204] time 0.278 (0.277) data 0.000 (0.009) loss 1.2832 (0.5832) lr 2.5000e-03 eta 0:08:51
epoch [21/30] batch [140/204] time 0.272 (0.276) data 0.000 (0.008) loss 0.4226 (0.5724) lr 2.5000e-03 eta 0:08:43
epoch [21/30] batch [160/204] time 0.263 (0.274) data 0.000 (0.007) loss 2.1914 (0.6026) lr 2.5000e-03 eta 0:08:35
epoch [21/30] batch [180/204] time 0.251 (0.273) data 0.000 (0.006) loss 0.8667 (0.6056) lr 2.5000e-03 eta 0:08:27
epoch [21/30] batch [200/204] time 0.251 (0.271) data 0.000 (0.005) loss 0.8320 (0.6040) lr 2.5000e-03 eta 0:08:17
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.27it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.03it/s]100%|██████████| 7/7 [00:02<00:00,  4.75it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 652
* accuracy: 93.7%
* error: 6.3%
* macro_f1: 92.4%

epoch [22/30] batch [20/204] time 0.258 (0.323) data 0.000 (0.054) loss 0.0086 (0.4453) lr 2.0611e-03 eta 0:09:46
epoch [22/30] batch [40/204] time 0.273 (0.295) data 0.000 (0.027) loss 0.8208 (0.5236) lr 2.0611e-03 eta 0:08:50
epoch [22/30] batch [60/204] time 0.269 (0.288) data 0.000 (0.018) loss 0.1462 (0.5378) lr 2.0611e-03 eta 0:08:32
epoch [22/30] batch [80/204] time 0.263 (0.283) data 0.000 (0.014) loss 1.7949 (0.6302) lr 2.0611e-03 eta 0:08:17
epoch [22/30] batch [100/204] time 0.261 (0.280) data 0.000 (0.011) loss 2.1406 (0.6336) lr 2.0611e-03 eta 0:08:06
epoch [22/30] batch [120/204] time 0.263 (0.278) data 0.001 (0.009) loss 0.0125 (0.6500) lr 2.0611e-03 eta 0:07:57
epoch [22/30] batch [140/204] time 0.265 (0.277) data 0.000 (0.008) loss 0.3933 (0.6327) lr 2.0611e-03 eta 0:07:48
epoch [22/30] batch [160/204] time 0.265 (0.275) data 0.000 (0.007) loss 0.1898 (0.6499) lr 2.0611e-03 eta 0:07:41
epoch [22/30] batch [180/204] time 0.258 (0.275) data 0.000 (0.006) loss 0.1204 (0.6278) lr 2.0611e-03 eta 0:07:35
epoch [22/30] batch [200/204] time 0.253 (0.273) data 0.000 (0.006) loss 0.8848 (0.6425) lr 2.0611e-03 eta 0:07:25
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.21s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.00s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.65it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.38it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.15it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.91it/s]100%|██████████| 7/7 [00:03<00:00,  4.64it/s]100%|██████████| 7/7 [00:03<00:00,  2.20it/s]=> result
* total: 696
* correct: 657
* accuracy: 94.4%
* error: 5.6%
* macro_f1: 93.5%

epoch [23/30] batch [20/204] time 0.269 (0.322) data 0.000 (0.050) loss 0.3108 (0.7683) lr 1.6543e-03 eta 0:08:38
epoch [23/30] batch [40/204] time 0.261 (0.294) data 0.000 (0.025) loss 1.3740 (0.6569) lr 1.6543e-03 eta 0:07:48
epoch [23/30] batch [60/204] time 0.267 (0.288) data 0.000 (0.017) loss 0.5283 (0.5917) lr 1.6543e-03 eta 0:07:32
epoch [23/30] batch [80/204] time 0.260 (0.283) data 0.000 (0.013) loss 1.1729 (0.6427) lr 1.6543e-03 eta 0:07:18
epoch [23/30] batch [100/204] time 0.282 (0.280) data 0.000 (0.010) loss 0.2664 (0.6306) lr 1.6543e-03 eta 0:07:09
epoch [23/30] batch [120/204] time 0.265 (0.279) data 0.000 (0.009) loss 0.4441 (0.5856) lr 1.6543e-03 eta 0:07:02
epoch [23/30] batch [140/204] time 0.263 (0.277) data 0.000 (0.007) loss 0.2002 (0.6452) lr 1.6543e-03 eta 0:06:53
epoch [23/30] batch [160/204] time 0.268 (0.276) data 0.000 (0.006) loss 0.4473 (0.6321) lr 1.6543e-03 eta 0:06:46
epoch [23/30] batch [180/204] time 0.252 (0.274) data 0.000 (0.006) loss 0.4902 (0.6231) lr 1.6543e-03 eta 0:06:38
epoch [23/30] batch [200/204] time 0.250 (0.272) data 0.000 (0.005) loss 1.8525 (0.6605) lr 1.6543e-03 eta 0:06:29
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.15s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.03it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.70it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.44it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.21it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.98it/s]100%|██████████| 7/7 [00:02<00:00,  4.70it/s]100%|██████████| 7/7 [00:03<00:00,  2.25it/s]=> result
* total: 696
* correct: 658
* accuracy: 94.5%
* error: 5.5%
* macro_f1: 93.5%

epoch [24/30] batch [20/204] time 0.265 (0.324) data 0.000 (0.049) loss 0.5474 (0.6216) lr 1.2843e-03 eta 0:07:36
epoch [24/30] batch [40/204] time 0.262 (0.298) data 0.000 (0.025) loss 0.1017 (0.5656) lr 1.2843e-03 eta 0:06:53
epoch [24/30] batch [60/204] time 0.278 (0.289) data 0.000 (0.017) loss 0.3787 (0.5866) lr 1.2843e-03 eta 0:06:34
epoch [24/30] batch [80/204] time 0.271 (0.283) data 0.000 (0.012) loss 0.0872 (0.5636) lr 1.2843e-03 eta 0:06:21
epoch [24/30] batch [100/204] time 0.273 (0.280) data 0.000 (0.010) loss 0.0428 (0.6058) lr 1.2843e-03 eta 0:06:11
epoch [24/30] batch [120/204] time 0.259 (0.278) data 0.000 (0.008) loss 0.1083 (0.6249) lr 1.2843e-03 eta 0:06:03
epoch [24/30] batch [140/204] time 0.267 (0.276) data 0.000 (0.007) loss 0.0942 (0.6285) lr 1.2843e-03 eta 0:05:55
epoch [24/30] batch [160/204] time 0.263 (0.274) data 0.000 (0.006) loss 0.2947 (0.6219) lr 1.2843e-03 eta 0:05:48
epoch [24/30] batch [180/204] time 0.252 (0.274) data 0.000 (0.006) loss 0.0115 (0.6111) lr 1.2843e-03 eta 0:05:41
epoch [24/30] batch [200/204] time 0.249 (0.271) data 0.000 (0.005) loss 0.3718 (0.6213) lr 1.2843e-03 eta 0:05:33
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.15s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.70it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.45it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.22it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.98it/s]100%|██████████| 7/7 [00:02<00:00,  4.71it/s]100%|██████████| 7/7 [00:03<00:00,  2.25it/s]=> result
* total: 696
* correct: 661
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 94.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [25/30] batch [20/204] time 0.267 (0.321) data 0.001 (0.049) loss 0.2251 (0.3768) lr 9.5492e-04 eta 0:06:26
epoch [25/30] batch [40/204] time 0.269 (0.294) data 0.001 (0.025) loss 2.0078 (0.3939) lr 9.5492e-04 eta 0:05:48
epoch [25/30] batch [60/204] time 0.271 (0.285) data 0.000 (0.017) loss 2.1406 (0.4335) lr 9.5492e-04 eta 0:05:31
epoch [25/30] batch [80/204] time 0.261 (0.282) data 0.000 (0.012) loss 0.0478 (0.4506) lr 9.5492e-04 eta 0:05:22
epoch [25/30] batch [100/204] time 0.270 (0.279) data 0.000 (0.010) loss 0.2607 (0.4446) lr 9.5492e-04 eta 0:05:13
epoch [25/30] batch [120/204] time 0.266 (0.277) data 0.000 (0.008) loss 0.0044 (0.4099) lr 9.5492e-04 eta 0:05:05
epoch [25/30] batch [140/204] time 0.278 (0.276) data 0.000 (0.007) loss 0.6006 (0.4201) lr 9.5492e-04 eta 0:04:58
epoch [25/30] batch [160/204] time 0.263 (0.275) data 0.000 (0.006) loss 0.0892 (0.4486) lr 9.5492e-04 eta 0:04:52
epoch [25/30] batch [180/204] time 0.252 (0.274) data 0.000 (0.006) loss 1.0967 (0.4372) lr 9.5492e-04 eta 0:04:45
epoch [25/30] batch [200/204] time 0.253 (0.272) data 0.000 (0.005) loss 0.2126 (0.4339) lr 9.5492e-04 eta 0:04:38
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.14s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.03it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.70it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.44it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.21it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.97it/s]100%|██████████| 7/7 [00:02<00:00,  4.71it/s]100%|██████████| 7/7 [00:03<00:00,  2.25it/s]=> result
* total: 696
* correct: 658
* accuracy: 94.5%
* error: 5.5%
* macro_f1: 93.5%

epoch [26/30] batch [20/204] time 0.278 (0.328) data 0.000 (0.049) loss 0.0641 (0.5788) lr 6.6987e-04 eta 0:05:27
epoch [26/30] batch [40/204] time 0.271 (0.299) data 0.000 (0.024) loss 0.0327 (0.5654) lr 6.6987e-04 eta 0:04:53
epoch [26/30] batch [60/204] time 0.269 (0.288) data 0.000 (0.016) loss 0.1792 (0.5502) lr 6.6987e-04 eta 0:04:36
epoch [26/30] batch [80/204] time 0.265 (0.284) data 0.000 (0.012) loss 1.5068 (0.5286) lr 6.6987e-04 eta 0:04:26
epoch [26/30] batch [100/204] time 0.275 (0.281) data 0.000 (0.010) loss 0.0246 (0.5352) lr 6.6987e-04 eta 0:04:18
epoch [26/30] batch [120/204] time 0.264 (0.279) data 0.000 (0.008) loss 0.0327 (0.5583) lr 6.6987e-04 eta 0:04:10
epoch [26/30] batch [140/204] time 0.262 (0.277) data 0.000 (0.007) loss 0.2092 (0.5238) lr 6.6987e-04 eta 0:04:03
epoch [26/30] batch [160/204] time 0.270 (0.276) data 0.000 (0.006) loss 0.2776 (0.5155) lr 6.6987e-04 eta 0:03:57
epoch [26/30] batch [180/204] time 0.248 (0.274) data 0.000 (0.006) loss 1.0430 (0.5241) lr 6.6987e-04 eta 0:03:50
epoch [26/30] batch [200/204] time 0.250 (0.271) data 0.000 (0.005) loss 1.3945 (0.5349) lr 6.6987e-04 eta 0:03:42
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.50it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.28it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.04it/s]100%|██████████| 7/7 [00:02<00:00,  4.77it/s]100%|██████████| 7/7 [00:03<00:00,  2.30it/s]=> result
* total: 696
* correct: 659
* accuracy: 94.7%
* error: 5.3%
* macro_f1: 93.6%

epoch [27/30] batch [20/204] time 0.265 (0.324) data 0.000 (0.050) loss 0.0314 (0.5533) lr 4.3227e-04 eta 0:04:17
epoch [27/30] batch [40/204] time 0.266 (0.296) data 0.000 (0.025) loss 0.0539 (0.4521) lr 4.3227e-04 eta 0:03:49
epoch [27/30] batch [60/204] time 0.274 (0.287) data 0.000 (0.017) loss 0.3596 (0.5850) lr 4.3227e-04 eta 0:03:37
epoch [27/30] batch [80/204] time 0.270 (0.282) data 0.000 (0.013) loss 0.0889 (0.5510) lr 4.3227e-04 eta 0:03:27
epoch [27/30] batch [100/204] time 0.263 (0.279) data 0.000 (0.010) loss 0.6597 (0.5054) lr 4.3227e-04 eta 0:03:20
epoch [27/30] batch [120/204] time 0.263 (0.277) data 0.000 (0.008) loss 0.5581 (0.5174) lr 4.3227e-04 eta 0:03:13
epoch [27/30] batch [140/204] time 0.260 (0.276) data 0.001 (0.007) loss 0.5713 (0.5034) lr 4.3227e-04 eta 0:03:06
epoch [27/30] batch [160/204] time 0.369 (0.275) data 0.000 (0.006) loss 0.5161 (0.4849) lr 4.3227e-04 eta 0:03:00
epoch [27/30] batch [180/204] time 0.248 (0.273) data 0.000 (0.006) loss 0.0682 (0.4774) lr 4.3227e-04 eta 0:02:53
epoch [27/30] batch [200/204] time 0.249 (0.271) data 0.000 (0.005) loss 0.0452 (0.4576) lr 4.3227e-04 eta 0:02:46
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.22s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.02s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.62it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.34it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.10it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.86it/s]100%|██████████| 7/7 [00:03<00:00,  4.56it/s]100%|██████████| 7/7 [00:03<00:00,  2.16it/s]=> result
* total: 696
* correct: 660
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 93.9%

epoch [28/30] batch [20/204] time 0.263 (0.319) data 0.000 (0.048) loss 0.0509 (0.4114) lr 2.4472e-04 eta 0:03:08
epoch [28/30] batch [40/204] time 0.269 (0.294) data 0.000 (0.024) loss 0.3796 (0.4289) lr 2.4472e-04 eta 0:02:48
epoch [28/30] batch [60/204] time 0.265 (0.287) data 0.000 (0.016) loss 0.0824 (0.4340) lr 2.4472e-04 eta 0:02:38
epoch [28/30] batch [80/204] time 0.268 (0.283) data 0.000 (0.012) loss 0.2573 (0.4142) lr 2.4472e-04 eta 0:02:30
epoch [28/30] batch [100/204] time 0.263 (0.280) data 0.000 (0.010) loss 2.5762 (0.4714) lr 2.4472e-04 eta 0:02:23
epoch [28/30] batch [120/204] time 0.262 (0.279) data 0.000 (0.008) loss 0.7178 (0.5018) lr 2.4472e-04 eta 0:02:17
epoch [28/30] batch [140/204] time 0.266 (0.277) data 0.000 (0.007) loss 2.0879 (0.4919) lr 2.4472e-04 eta 0:02:10
epoch [28/30] batch [160/204] time 0.260 (0.276) data 0.000 (0.006) loss 0.3391 (0.4987) lr 2.4472e-04 eta 0:02:04
epoch [28/30] batch [180/204] time 0.252 (0.275) data 0.000 (0.006) loss 0.9941 (0.4925) lr 2.4472e-04 eta 0:01:58
epoch [28/30] batch [200/204] time 0.250 (0.273) data 0.000 (0.005) loss 0.2783 (0.4771) lr 2.4472e-04 eta 0:01:52
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.24s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.00s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.65it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.37it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.14it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.90it/s]100%|██████████| 7/7 [00:03<00:00,  4.63it/s]100%|██████████| 7/7 [00:03<00:00,  2.18it/s]=> result
* total: 696
* correct: 661
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 94.0%

epoch [29/30] batch [20/204] time 0.267 (0.319) data 0.000 (0.050) loss -0.0054 (0.4089) lr 1.0926e-04 eta 0:02:03
epoch [29/30] batch [40/204] time 0.265 (0.292) data 0.000 (0.025) loss 0.2820 (0.3942) lr 1.0926e-04 eta 0:01:47
epoch [29/30] batch [60/204] time 0.271 (0.285) data 0.000 (0.017) loss 0.2600 (0.4973) lr 1.0926e-04 eta 0:01:39
epoch [29/30] batch [80/204] time 0.264 (0.280) data 0.000 (0.013) loss 0.9609 (0.5143) lr 1.0926e-04 eta 0:01:31
epoch [29/30] batch [100/204] time 0.266 (0.277) data 0.000 (0.010) loss 0.2090 (0.5377) lr 1.0926e-04 eta 0:01:25
epoch [29/30] batch [120/204] time 0.264 (0.276) data 0.000 (0.009) loss 2.2520 (0.5292) lr 1.0926e-04 eta 0:01:19
epoch [29/30] batch [140/204] time 0.293 (0.274) data 0.001 (0.007) loss 0.0023 (0.5046) lr 1.0926e-04 eta 0:01:13
epoch [29/30] batch [160/204] time 0.259 (0.273) data 0.000 (0.006) loss -0.0268 (0.4978) lr 1.0926e-04 eta 0:01:07
epoch [29/30] batch [180/204] time 0.247 (0.272) data 0.000 (0.006) loss -0.0220 (0.4820) lr 1.0926e-04 eta 0:01:01
epoch [29/30] batch [200/204] time 0.247 (0.269) data 0.000 (0.005) loss 0.0317 (0.4691) lr 1.0926e-04 eta 0:00:56
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.06s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.07it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.75it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.51it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.29it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.98it/s]100%|██████████| 7/7 [00:02<00:00,  4.71it/s]100%|██████████| 7/7 [00:03<00:00,  2.31it/s]=> result
* total: 696
* correct: 660
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 93.9%

epoch [30/30] batch [20/204] time 0.262 (0.317) data 0.000 (0.051) loss 0.0244 (0.3848) lr 2.7391e-05 eta 0:00:58
epoch [30/30] batch [40/204] time 0.266 (0.291) data 0.000 (0.026) loss 0.0315 (0.4080) lr 2.7391e-05 eta 0:00:47
epoch [30/30] batch [60/204] time 0.270 (0.283) data 0.000 (0.017) loss 0.1610 (0.4441) lr 2.7391e-05 eta 0:00:40
epoch [30/30] batch [80/204] time 0.259 (0.279) data 0.000 (0.013) loss 0.0045 (0.4251) lr 2.7391e-05 eta 0:00:34
epoch [30/30] batch [100/204] time 0.258 (0.277) data 0.000 (0.011) loss 0.4539 (0.4288) lr 2.7391e-05 eta 0:00:28
epoch [30/30] batch [120/204] time 0.261 (0.275) data 0.000 (0.009) loss 0.3701 (0.4125) lr 2.7391e-05 eta 0:00:23
epoch [30/30] batch [140/204] time 0.264 (0.274) data 0.000 (0.008) loss 0.2120 (0.4457) lr 2.7391e-05 eta 0:00:17
epoch [30/30] batch [160/204] time 0.268 (0.273) data 0.000 (0.007) loss 1.1006 (0.4570) lr 2.7391e-05 eta 0:00:12
epoch [30/30] batch [180/204] time 0.247 (0.272) data 0.000 (0.006) loss 0.1193 (0.4567) lr 2.7391e-05 eta 0:00:06
epoch [30/30] batch [200/204] time 0.246 (0.269) data 0.000 (0.005) loss 1.3457 (0.4651) lr 2.7391e-05 eta 0:00:01
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.27it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.03it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.30it/s]
=> result
* total: 696
* correct: 660
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 93.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 24)
Evaluate on the *test* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:02<00:22,  2.24s/it] 18%|█▊        | 2/11 [00:02<00:09,  1.10s/it] 27%|██▋       | 3/11 [00:02<00:05,  1.52it/s] 36%|███▋      | 4/11 [00:02<00:03,  2.22it/s] 45%|████▌     | 5/11 [00:02<00:02,  2.96it/s] 55%|█████▍    | 6/11 [00:03<00:01,  3.72it/s] 64%|██████▎   | 7/11 [00:03<00:00,  4.43it/s] 73%|███████▎  | 8/11 [00:03<00:00,  5.07it/s] 82%|████████▏ | 9/11 [00:03<00:00,  5.61it/s] 91%|█████████ | 10/11 [00:03<00:00,  6.06it/s]100%|██████████| 11/11 [00:03<00:00,  2.84it/s]
=> result
* total: 1,053
* correct: 1,020
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 96.7%
Elapsed: 0:29:31
+ sh scripts/rpo_prime/base2new_test_sdl.sh oxford_flowers 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
816 937 1410
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      937
# test     1,410
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 24)
Evaluate on the *test* set
  0%|          | 0/15 [00:00<?, ?it/s]  7%|▋         | 1/15 [00:04<01:09,  4.94s/it] 13%|█▎        | 2/15 [00:05<00:27,  2.12s/it] 20%|██        | 3/15 [00:05<00:14,  1.21s/it] 27%|██▋       | 4/15 [00:05<00:08,  1.27it/s] 33%|███▎      | 5/15 [00:05<00:05,  1.81it/s] 40%|████      | 6/15 [00:05<00:03,  2.44it/s] 47%|████▋     | 7/15 [00:05<00:02,  3.12it/s] 53%|█████▎    | 8/15 [00:05<00:01,  3.82it/s] 60%|██████    | 9/15 [00:06<00:01,  4.50it/s] 67%|██████▋   | 10/15 [00:06<00:00,  5.11it/s] 73%|███████▎  | 11/15 [00:06<00:00,  5.64it/s] 80%|████████  | 12/15 [00:06<00:00,  6.02it/s] 87%|████████▋ | 13/15 [00:06<00:00,  6.37it/s] 93%|█████████▎| 14/15 [00:06<00:00,  6.65it/s]100%|██████████| 15/15 [00:06<00:00,  2.19it/s]
=> result
* total: 1,410
* correct: 1,076
* accuracy: 76.3%
* error: 23.7%
* macro_f1: 71.5%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh oxford_flowers 3 0 main_tmp1_0.1sdl 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
816 696 1053
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      696
# test     1,053
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/204] time 0.272 (0.411) data 0.000 (0.060) loss 2.4258 (2.9589) lr 1.0000e-02 eta 0:41:45
epoch [1/30] batch [40/204] time 0.270 (0.341) data 0.000 (0.030) loss 6.0469 (2.9953) lr 1.0000e-02 eta 0:34:35
epoch [1/30] batch [60/204] time 0.265 (0.317) data 0.000 (0.020) loss 1.1826 (2.8392) lr 1.0000e-02 eta 0:32:04
epoch [1/30] batch [80/204] time 0.269 (0.307) data 0.000 (0.015) loss 0.9463 (2.8223) lr 1.0000e-02 eta 0:30:54
epoch [1/30] batch [100/204] time 0.272 (0.300) data 0.000 (0.012) loss 4.5273 (2.8838) lr 1.0000e-02 eta 0:30:04
epoch [1/30] batch [120/204] time 0.271 (0.295) data 0.000 (0.010) loss 3.0371 (2.7925) lr 1.0000e-02 eta 0:29:31
epoch [1/30] batch [140/204] time 0.272 (0.291) data 0.000 (0.009) loss 0.9673 (2.7082) lr 1.0000e-02 eta 0:29:02
epoch [1/30] batch [160/204] time 0.266 (0.289) data 0.000 (0.008) loss 2.5977 (2.6215) lr 1.0000e-02 eta 0:28:44
epoch [1/30] batch [180/204] time 0.254 (0.287) data 0.000 (0.007) loss 1.2637 (2.5507) lr 1.0000e-02 eta 0:28:22
epoch [1/30] batch [200/204] time 0.253 (0.283) data 0.000 (0.006) loss 1.5850 (2.5363) lr 1.0000e-02 eta 0:27:56
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.32s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.04s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.60it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.31it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.07it/s] 86%|████████▌ | 6/7 [00:03<00:00,  3.81it/s]100%|██████████| 7/7 [00:03<00:00,  4.55it/s]100%|██████████| 7/7 [00:03<00:00,  2.13it/s]=> result
* total: 696
* correct: 514
* accuracy: 73.9%
* error: 26.1%
* macro_f1: 68.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/204] time 0.264 (0.323) data 0.000 (0.051) loss 1.1621 (1.9145) lr 9.9726e-03 eta 0:31:43
epoch [2/30] batch [40/204] time 0.274 (0.296) data 0.000 (0.026) loss 0.9580 (2.0127) lr 9.9726e-03 eta 0:28:59
epoch [2/30] batch [60/204] time 0.268 (0.290) data 0.000 (0.017) loss 2.8691 (2.1553) lr 9.9726e-03 eta 0:28:16
epoch [2/30] batch [80/204] time 0.274 (0.285) data 0.000 (0.013) loss 4.0352 (2.1241) lr 9.9726e-03 eta 0:27:41
epoch [2/30] batch [100/204] time 0.270 (0.281) data 0.000 (0.010) loss 2.6465 (2.1285) lr 9.9726e-03 eta 0:27:16
epoch [2/30] batch [120/204] time 0.272 (0.280) data 0.000 (0.009) loss 1.2705 (2.1438) lr 9.9726e-03 eta 0:27:02
epoch [2/30] batch [140/204] time 0.273 (0.280) data 0.000 (0.008) loss 2.5176 (2.1643) lr 9.9726e-03 eta 0:26:55
epoch [2/30] batch [160/204] time 0.275 (0.279) data 0.000 (0.007) loss 2.4395 (2.1631) lr 9.9726e-03 eta 0:26:43
epoch [2/30] batch [180/204] time 0.255 (0.277) data 0.000 (0.006) loss 1.8174 (2.1550) lr 9.9726e-03 eta 0:26:28
epoch [2/30] batch [200/204] time 0.254 (0.275) data 0.000 (0.005) loss 2.6699 (2.1647) lr 9.9726e-03 eta 0:26:10
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.08s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.07it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.75it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.50it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.28it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.04it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.30it/s]=> result
* total: 696
* correct: 541
* accuracy: 77.7%
* error: 22.3%
* macro_f1: 73.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/204] time 0.267 (0.334) data 0.000 (0.052) loss 1.8398 (1.6328) lr 9.8907e-03 eta 0:31:39
epoch [3/30] batch [40/204] time 0.269 (0.303) data 0.000 (0.026) loss 2.1797 (2.1016) lr 9.8907e-03 eta 0:28:38
epoch [3/30] batch [60/204] time 0.308 (0.294) data 0.000 (0.017) loss 1.8291 (2.1578) lr 9.8907e-03 eta 0:27:41
epoch [3/30] batch [80/204] time 0.267 (0.288) data 0.000 (0.013) loss 3.3418 (2.0969) lr 9.8907e-03 eta 0:27:03
epoch [3/30] batch [100/204] time 0.272 (0.285) data 0.000 (0.011) loss 1.1816 (1.9947) lr 9.8907e-03 eta 0:26:38
epoch [3/30] batch [120/204] time 0.275 (0.283) data 0.000 (0.009) loss 1.4932 (1.9573) lr 9.8907e-03 eta 0:26:24
epoch [3/30] batch [140/204] time 0.271 (0.282) data 0.000 (0.008) loss 0.8354 (1.9316) lr 9.8907e-03 eta 0:26:10
epoch [3/30] batch [160/204] time 0.264 (0.280) data 0.000 (0.007) loss 0.6572 (1.9367) lr 9.8907e-03 eta 0:25:54
epoch [3/30] batch [180/204] time 0.251 (0.279) data 0.000 (0.006) loss 2.5645 (1.9454) lr 9.8907e-03 eta 0:25:40
epoch [3/30] batch [200/204] time 0.250 (0.276) data 0.000 (0.005) loss 2.1406 (1.9257) lr 9.8907e-03 eta 0:25:20
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.29s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.03s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.62it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.33it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.10it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.86it/s]100%|██████████| 7/7 [00:03<00:00,  4.59it/s]100%|██████████| 7/7 [00:03<00:00,  2.15it/s]=> result
* total: 696
* correct: 566
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 77.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/204] time 0.265 (0.326) data 0.000 (0.052) loss 2.1426 (1.7949) lr 9.7553e-03 eta 0:29:48
epoch [4/30] batch [40/204] time 0.274 (0.298) data 0.000 (0.026) loss 1.1514 (1.8382) lr 9.7553e-03 eta 0:27:09
epoch [4/30] batch [60/204] time 0.270 (0.290) data 0.000 (0.018) loss 0.9399 (1.6899) lr 9.7553e-03 eta 0:26:22
epoch [4/30] batch [80/204] time 0.263 (0.285) data 0.000 (0.013) loss 3.0625 (1.7420) lr 9.7553e-03 eta 0:25:45
epoch [4/30] batch [100/204] time 0.265 (0.281) data 0.001 (0.011) loss 3.8555 (1.7474) lr 9.7553e-03 eta 0:25:19
epoch [4/30] batch [120/204] time 0.268 (0.279) data 0.000 (0.009) loss 0.5127 (1.7184) lr 9.7553e-03 eta 0:25:03
epoch [4/30] batch [140/204] time 0.275 (0.278) data 0.000 (0.008) loss 1.0664 (1.6810) lr 9.7553e-03 eta 0:24:51
epoch [4/30] batch [160/204] time 0.267 (0.276) data 0.000 (0.007) loss 3.2324 (1.6642) lr 9.7553e-03 eta 0:24:37
epoch [4/30] batch [180/204] time 0.253 (0.275) data 0.000 (0.006) loss 1.1787 (1.6541) lr 9.7553e-03 eta 0:24:27
epoch [4/30] batch [200/204] time 0.254 (0.273) data 0.000 (0.005) loss 2.9082 (1.6181) lr 9.7553e-03 eta 0:24:10
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.26s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.01s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.63it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.36it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.12it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.88it/s]100%|██████████| 7/7 [00:03<00:00,  4.61it/s]100%|██████████| 7/7 [00:03<00:00,  2.17it/s]=> result
* total: 696
* correct: 565
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 77.6%

epoch [5/30] batch [20/204] time 0.270 (0.325) data 0.000 (0.051) loss 0.9004 (1.4484) lr 9.5677e-03 eta 0:28:39
epoch [5/30] batch [40/204] time 0.271 (0.298) data 0.000 (0.026) loss 1.9072 (1.4693) lr 9.5677e-03 eta 0:26:07
epoch [5/30] batch [60/204] time 0.260 (0.288) data 0.000 (0.017) loss 1.0166 (1.4799) lr 9.5677e-03 eta 0:25:11
epoch [5/30] batch [80/204] time 0.271 (0.285) data 0.000 (0.013) loss 2.3555 (1.5422) lr 9.5677e-03 eta 0:24:50
epoch [5/30] batch [100/204] time 0.265 (0.282) data 0.000 (0.010) loss 2.6660 (1.5281) lr 9.5677e-03 eta 0:24:27
epoch [5/30] batch [120/204] time 0.266 (0.280) data 0.000 (0.009) loss 1.7451 (1.5436) lr 9.5677e-03 eta 0:24:10
epoch [5/30] batch [140/204] time 0.266 (0.279) data 0.000 (0.008) loss 1.8350 (1.5454) lr 9.5677e-03 eta 0:24:01
epoch [5/30] batch [160/204] time 0.279 (0.278) data 0.000 (0.007) loss 0.5059 (1.6033) lr 9.5677e-03 eta 0:23:49
epoch [5/30] batch [180/204] time 0.252 (0.276) data 0.000 (0.006) loss 3.4336 (1.5927) lr 9.5677e-03 eta 0:23:34
epoch [5/30] batch [200/204] time 0.249 (0.274) data 0.000 (0.005) loss 1.6055 (1.5918) lr 9.5677e-03 eta 0:23:16
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.14s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.71it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.45it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.23it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.99it/s]100%|██████████| 7/7 [00:02<00:00,  4.72it/s]100%|██████████| 7/7 [00:03<00:00,  2.27it/s]=> result
* total: 696
* correct: 599
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 83.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/204] time 0.274 (0.322) data 0.000 (0.049) loss 0.3486 (1.1023) lr 9.3301e-03 eta 0:27:15
epoch [6/30] batch [40/204] time 0.273 (0.295) data 0.000 (0.025) loss 0.5103 (1.3064) lr 9.3301e-03 eta 0:24:54
epoch [6/30] batch [60/204] time 0.269 (0.289) data 0.000 (0.017) loss 1.1230 (1.4612) lr 9.3301e-03 eta 0:24:16
epoch [6/30] batch [80/204] time 0.268 (0.284) data 0.000 (0.012) loss 0.3337 (1.3804) lr 9.3301e-03 eta 0:23:45
epoch [6/30] batch [100/204] time 0.279 (0.281) data 0.000 (0.010) loss 0.5156 (1.3997) lr 9.3301e-03 eta 0:23:24
epoch [6/30] batch [120/204] time 0.266 (0.280) data 0.000 (0.008) loss 0.2452 (1.3797) lr 9.3301e-03 eta 0:23:12
epoch [6/30] batch [140/204] time 0.263 (0.278) data 0.000 (0.007) loss 0.7202 (1.3274) lr 9.3301e-03 eta 0:22:57
epoch [6/30] batch [160/204] time 0.267 (0.277) data 0.000 (0.006) loss 1.7139 (1.3179) lr 9.3301e-03 eta 0:22:48
epoch [6/30] batch [180/204] time 0.253 (0.275) data 0.000 (0.006) loss 0.3430 (1.2834) lr 9.3301e-03 eta 0:22:34
epoch [6/30] batch [200/204] time 0.254 (0.273) data 0.000 (0.005) loss 0.4099 (1.2671) lr 9.3301e-03 eta 0:22:18
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.50it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.28it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.04it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.31it/s]=> result
* total: 696
* correct: 608
* accuracy: 87.4%
* error: 12.6%
* macro_f1: 84.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/204] time 0.268 (0.321) data 0.000 (0.051) loss 1.8506 (1.4840) lr 9.0451e-03 eta 0:26:03
epoch [7/30] batch [40/204] time 0.267 (0.298) data 0.000 (0.026) loss 0.8711 (1.3495) lr 9.0451e-03 eta 0:24:07
epoch [7/30] batch [60/204] time 0.268 (0.288) data 0.000 (0.017) loss 0.7280 (1.5136) lr 9.0451e-03 eta 0:23:15
epoch [7/30] batch [80/204] time 0.268 (0.284) data 0.000 (0.013) loss 0.8628 (1.4777) lr 9.0451e-03 eta 0:22:47
epoch [7/30] batch [100/204] time 0.294 (0.281) data 0.000 (0.010) loss 3.9004 (1.4519) lr 9.0451e-03 eta 0:22:28
epoch [7/30] batch [120/204] time 0.267 (0.279) data 0.000 (0.009) loss 0.2795 (1.4599) lr 9.0451e-03 eta 0:22:14
epoch [7/30] batch [140/204] time 0.274 (0.278) data 0.000 (0.008) loss 1.9980 (1.5114) lr 9.0451e-03 eta 0:22:01
epoch [7/30] batch [160/204] time 0.278 (0.278) data 0.000 (0.007) loss 0.9653 (1.4607) lr 9.0451e-03 eta 0:21:54
epoch [7/30] batch [180/204] time 0.253 (0.276) data 0.000 (0.006) loss 0.5044 (1.4488) lr 9.0451e-03 eta 0:21:41
epoch [7/30] batch [200/204] time 0.253 (0.274) data 0.000 (0.005) loss 0.6548 (1.4000) lr 9.0451e-03 eta 0:21:26
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.13s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.71it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.45it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.23it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.99it/s]100%|██████████| 7/7 [00:02<00:00,  4.72it/s]100%|██████████| 7/7 [00:03<00:00,  2.26it/s]=> result
* total: 696
* correct: 611
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 85.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/204] time 0.267 (0.322) data 0.000 (0.050) loss 0.9570 (1.1016) lr 8.7157e-03 eta 0:25:02
epoch [8/30] batch [40/204] time 0.273 (0.294) data 0.000 (0.025) loss 2.6562 (1.1461) lr 8.7157e-03 eta 0:22:48
epoch [8/30] batch [60/204] time 0.273 (0.289) data 0.000 (0.017) loss 0.1771 (1.1053) lr 8.7157e-03 eta 0:22:19
epoch [8/30] batch [80/204] time 0.324 (0.285) data 0.000 (0.013) loss 2.8789 (1.1460) lr 8.7157e-03 eta 0:21:54
epoch [8/30] batch [100/204] time 0.275 (0.282) data 0.000 (0.010) loss 0.2615 (1.0820) lr 8.7157e-03 eta 0:21:33
epoch [8/30] batch [120/204] time 0.267 (0.280) data 0.000 (0.009) loss 1.5557 (1.1204) lr 8.7157e-03 eta 0:21:19
epoch [8/30] batch [140/204] time 0.265 (0.278) data 0.000 (0.007) loss 0.5435 (1.1824) lr 8.7157e-03 eta 0:21:05
epoch [8/30] batch [160/204] time 0.268 (0.277) data 0.000 (0.006) loss 0.4873 (1.2252) lr 8.7157e-03 eta 0:20:53
epoch [8/30] batch [180/204] time 0.251 (0.275) data 0.000 (0.006) loss 0.5591 (1.2565) lr 8.7157e-03 eta 0:20:40
epoch [8/30] batch [200/204] time 0.251 (0.273) data 0.000 (0.005) loss 0.3857 (1.2416) lr 8.7157e-03 eta 0:20:24
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:14,  2.34s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.05s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.59it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.30it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.05it/s] 86%|████████▌ | 6/7 [00:03<00:00,  3.81it/s]100%|██████████| 7/7 [00:03<00:00,  4.55it/s]100%|██████████| 7/7 [00:03<00:00,  2.12it/s]=> result
* total: 696
* correct: 624
* accuracy: 89.7%
* error: 10.3%
* macro_f1: 87.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/204] time 0.268 (0.324) data 0.000 (0.049) loss 0.3433 (1.1347) lr 8.3457e-03 eta 0:24:07
epoch [9/30] batch [40/204] time 0.273 (0.300) data 0.000 (0.025) loss 1.1865 (1.1275) lr 8.3457e-03 eta 0:22:13
epoch [9/30] batch [60/204] time 0.268 (0.290) data 0.000 (0.017) loss 0.9248 (1.1305) lr 8.3457e-03 eta 0:21:24
epoch [9/30] batch [80/204] time 0.269 (0.285) data 0.000 (0.012) loss 1.8906 (1.1299) lr 8.3457e-03 eta 0:20:55
epoch [9/30] batch [100/204] time 0.272 (0.283) data 0.000 (0.010) loss 0.7412 (1.0947) lr 8.3457e-03 eta 0:20:40
epoch [9/30] batch [120/204] time 0.266 (0.281) data 0.000 (0.008) loss 0.1809 (1.0879) lr 8.3457e-03 eta 0:20:25
epoch [9/30] batch [140/204] time 0.270 (0.279) data 0.000 (0.007) loss 0.2708 (1.0755) lr 8.3457e-03 eta 0:20:12
epoch [9/30] batch [160/204] time 0.270 (0.278) data 0.000 (0.006) loss 1.1016 (1.1005) lr 8.3457e-03 eta 0:20:01
epoch [9/30] batch [180/204] time 0.250 (0.276) data 0.000 (0.006) loss 0.2571 (1.0706) lr 8.3457e-03 eta 0:19:48
epoch [9/30] batch [200/204] time 0.252 (0.273) data 0.000 (0.005) loss 0.4036 (1.0743) lr 8.3457e-03 eta 0:19:32
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.07s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.07it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.76it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.51it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.30it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.06it/s]100%|██████████| 7/7 [00:02<00:00,  4.79it/s]100%|██████████| 7/7 [00:03<00:00,  2.31it/s]=> result
* total: 696
* correct: 622
* accuracy: 89.4%
* error: 10.6%
* macro_f1: 86.8%

epoch [10/30] batch [20/204] time 0.265 (0.323) data 0.000 (0.049) loss 0.3027 (0.8636) lr 7.9389e-03 eta 0:22:58
epoch [10/30] batch [40/204] time 0.264 (0.298) data 0.000 (0.025) loss 0.0992 (0.9082) lr 7.9389e-03 eta 0:21:04
epoch [10/30] batch [60/204] time 0.265 (0.288) data 0.000 (0.017) loss 0.5352 (0.9393) lr 7.9389e-03 eta 0:20:14
epoch [10/30] batch [80/204] time 0.268 (0.283) data 0.000 (0.012) loss 0.5566 (0.8789) lr 7.9389e-03 eta 0:19:49
epoch [10/30] batch [100/204] time 0.272 (0.280) data 0.000 (0.010) loss 0.0386 (0.9124) lr 7.9389e-03 eta 0:19:32
epoch [10/30] batch [120/204] time 0.273 (0.278) data 0.000 (0.008) loss 0.8120 (0.9171) lr 7.9389e-03 eta 0:19:19
epoch [10/30] batch [140/204] time 0.263 (0.278) data 0.000 (0.007) loss 0.6372 (0.9552) lr 7.9389e-03 eta 0:19:11
epoch [10/30] batch [160/204] time 0.268 (0.276) data 0.000 (0.006) loss 1.8438 (0.9569) lr 7.9389e-03 eta 0:18:59
epoch [10/30] batch [180/204] time 0.252 (0.275) data 0.000 (0.006) loss 1.7148 (0.9647) lr 7.9389e-03 eta 0:18:48
epoch [10/30] batch [200/204] time 0.251 (0.273) data 0.000 (0.005) loss 1.2842 (0.9983) lr 7.9389e-03 eta 0:18:36
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.07s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.07it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.75it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.51it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.29it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.05it/s]100%|██████████| 7/7 [00:02<00:00,  4.77it/s]100%|██████████| 7/7 [00:03<00:00,  2.32it/s]=> result
* total: 696
* correct: 620
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 88.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/204] time 0.268 (0.325) data 0.000 (0.050) loss 0.5146 (0.8919) lr 7.5000e-03 eta 0:22:01
epoch [11/30] batch [40/204] time 0.272 (0.298) data 0.000 (0.025) loss 2.4141 (1.0535) lr 7.5000e-03 eta 0:20:04
epoch [11/30] batch [60/204] time 0.270 (0.288) data 0.000 (0.017) loss 1.4492 (1.0337) lr 7.5000e-03 eta 0:19:17
epoch [11/30] batch [80/204] time 0.273 (0.285) data 0.000 (0.013) loss 0.8613 (1.0098) lr 7.5000e-03 eta 0:19:00
epoch [11/30] batch [100/204] time 0.265 (0.282) data 0.000 (0.010) loss 0.2178 (0.9712) lr 7.5000e-03 eta 0:18:42
epoch [11/30] batch [120/204] time 0.276 (0.280) data 0.000 (0.008) loss 0.5049 (0.9793) lr 7.5000e-03 eta 0:18:29
epoch [11/30] batch [140/204] time 0.266 (0.279) data 0.000 (0.007) loss 0.2891 (0.9828) lr 7.5000e-03 eta 0:18:20
epoch [11/30] batch [160/204] time 0.263 (0.278) data 0.000 (0.006) loss 0.1914 (0.9532) lr 7.5000e-03 eta 0:18:09
epoch [11/30] batch [180/204] time 0.250 (0.276) data 0.000 (0.006) loss 0.4006 (0.9709) lr 7.5000e-03 eta 0:17:57
epoch [11/30] batch [200/204] time 0.254 (0.274) data 0.000 (0.005) loss 0.4634 (0.9558) lr 7.5000e-03 eta 0:17:42
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.27it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.02it/s]100%|██████████| 7/7 [00:02<00:00,  4.75it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 640
* accuracy: 92.0%
* error: 8.0%
* macro_f1: 90.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/204] time 0.278 (0.327) data 0.000 (0.050) loss 1.3701 (1.1759) lr 7.0337e-03 eta 0:21:01
epoch [12/30] batch [40/204] time 0.270 (0.303) data 0.000 (0.025) loss 1.7227 (1.0372) lr 7.0337e-03 eta 0:19:20
epoch [12/30] batch [60/204] time 0.261 (0.292) data 0.000 (0.017) loss 3.2598 (1.1600) lr 7.0337e-03 eta 0:18:32
epoch [12/30] batch [80/204] time 0.270 (0.286) data 0.000 (0.013) loss 0.5693 (1.1075) lr 7.0337e-03 eta 0:18:04
epoch [12/30] batch [100/204] time 0.267 (0.283) data 0.000 (0.010) loss 0.9810 (1.0812) lr 7.0337e-03 eta 0:17:47
epoch [12/30] batch [120/204] time 0.271 (0.281) data 0.000 (0.009) loss 0.1078 (1.0718) lr 7.0337e-03 eta 0:17:33
epoch [12/30] batch [140/204] time 0.270 (0.279) data 0.000 (0.007) loss 0.2610 (1.0349) lr 7.0337e-03 eta 0:17:22
epoch [12/30] batch [160/204] time 0.266 (0.279) data 0.000 (0.007) loss 0.2998 (1.0244) lr 7.0337e-03 eta 0:17:16
epoch [12/30] batch [180/204] time 0.250 (0.277) data 0.000 (0.006) loss 0.7715 (0.9844) lr 7.0337e-03 eta 0:17:03
epoch [12/30] batch [200/204] time 0.255 (0.275) data 0.000 (0.005) loss 0.6743 (0.9542) lr 7.0337e-03 eta 0:16:49
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.12s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.72it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.47it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.24it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.00it/s]100%|██████████| 7/7 [00:02<00:00,  4.73it/s]100%|██████████| 7/7 [00:03<00:00,  2.27it/s]=> result
* total: 696
* correct: 644
* accuracy: 92.5%
* error: 7.5%
* macro_f1: 91.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [13/30] batch [20/204] time 0.269 (0.324) data 0.000 (0.050) loss 0.3804 (0.7740) lr 6.5451e-03 eta 0:19:44
epoch [13/30] batch [40/204] time 0.274 (0.298) data 0.000 (0.025) loss 0.1584 (0.7451) lr 6.5451e-03 eta 0:18:03
epoch [13/30] batch [60/204] time 0.270 (0.292) data 0.000 (0.017) loss 1.6094 (0.9116) lr 6.5451e-03 eta 0:17:33
epoch [13/30] batch [80/204] time 0.271 (0.286) data 0.000 (0.013) loss 0.5171 (0.8253) lr 6.5451e-03 eta 0:17:08
epoch [13/30] batch [100/204] time 0.267 (0.284) data 0.000 (0.010) loss 3.0332 (0.8478) lr 6.5451e-03 eta 0:16:53
epoch [13/30] batch [120/204] time 0.279 (0.283) data 0.000 (0.009) loss 0.0621 (0.8363) lr 6.5451e-03 eta 0:16:43
epoch [13/30] batch [140/204] time 0.269 (0.281) data 0.000 (0.007) loss 2.0586 (0.8459) lr 6.5451e-03 eta 0:16:32
epoch [13/30] batch [160/204] time 0.262 (0.279) data 0.000 (0.007) loss 2.0117 (0.8663) lr 6.5451e-03 eta 0:16:21
epoch [13/30] batch [180/204] time 0.254 (0.278) data 0.000 (0.006) loss 0.0526 (0.8683) lr 6.5451e-03 eta 0:16:09
epoch [13/30] batch [200/204] time 0.258 (0.276) data 0.000 (0.005) loss 0.8042 (0.8696) lr 6.5451e-03 eta 0:15:57
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.13s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.71it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.46it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.23it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.99it/s]100%|██████████| 7/7 [00:02<00:00,  4.72it/s]100%|██████████| 7/7 [00:03<00:00,  2.25it/s]=> result
* total: 696
* correct: 645
* accuracy: 92.7%
* error: 7.3%
* macro_f1: 90.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [14/30] batch [20/204] time 0.275 (0.327) data 0.000 (0.049) loss 0.5361 (0.8113) lr 6.0396e-03 eta 0:18:48
epoch [14/30] batch [40/204] time 0.316 (0.302) data 0.000 (0.025) loss 0.5278 (0.9397) lr 6.0396e-03 eta 0:17:16
epoch [14/30] batch [60/204] time 0.261 (0.292) data 0.000 (0.017) loss 2.0957 (0.9740) lr 6.0396e-03 eta 0:16:35
epoch [14/30] batch [80/204] time 0.275 (0.286) data 0.000 (0.013) loss 0.1282 (0.8662) lr 6.0396e-03 eta 0:16:09
epoch [14/30] batch [100/204] time 0.267 (0.283) data 0.000 (0.010) loss 3.4590 (0.8755) lr 6.0396e-03 eta 0:15:53
epoch [14/30] batch [120/204] time 0.269 (0.281) data 0.000 (0.009) loss 0.4983 (0.8334) lr 6.0396e-03 eta 0:15:39
epoch [14/30] batch [140/204] time 0.264 (0.279) data 0.000 (0.007) loss 0.0319 (0.8445) lr 6.0396e-03 eta 0:15:28
epoch [14/30] batch [160/204] time 0.267 (0.278) data 0.000 (0.006) loss 0.3240 (0.8279) lr 6.0396e-03 eta 0:15:19
epoch [14/30] batch [180/204] time 0.250 (0.277) data 0.000 (0.006) loss 1.2168 (0.8273) lr 6.0396e-03 eta 0:15:10
epoch [14/30] batch [200/204] time 0.258 (0.274) data 0.000 (0.005) loss 0.2744 (0.8451) lr 6.0396e-03 eta 0:14:56
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.08s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.07it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.75it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.51it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.29it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.05it/s]100%|██████████| 7/7 [00:02<00:00,  4.77it/s]100%|██████████| 7/7 [00:03<00:00,  2.30it/s]=> result
* total: 696
* correct: 654
* accuracy: 94.0%
* error: 6.0%
* macro_f1: 92.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/204] time 0.270 (0.327) data 0.000 (0.049) loss 0.8179 (0.7760) lr 5.5226e-03 eta 0:17:40
epoch [15/30] batch [40/204] time 0.278 (0.300) data 0.000 (0.025) loss 1.2041 (0.8010) lr 5.5226e-03 eta 0:16:08
epoch [15/30] batch [60/204] time 0.278 (0.293) data 0.000 (0.017) loss 0.3367 (0.6803) lr 5.5226e-03 eta 0:15:38
epoch [15/30] batch [80/204] time 0.267 (0.287) data 0.000 (0.013) loss 0.5972 (0.6960) lr 5.5226e-03 eta 0:15:15
epoch [15/30] batch [100/204] time 0.269 (0.283) data 0.000 (0.010) loss 0.9287 (0.6846) lr 5.5226e-03 eta 0:14:56
epoch [15/30] batch [120/204] time 0.265 (0.282) data 0.000 (0.008) loss 0.5688 (0.6909) lr 5.5226e-03 eta 0:14:45
epoch [15/30] batch [140/204] time 0.278 (0.280) data 0.000 (0.007) loss 0.6724 (0.6800) lr 5.5226e-03 eta 0:14:34
epoch [15/30] batch [160/204] time 0.270 (0.278) data 0.000 (0.006) loss 0.1133 (0.6719) lr 5.5226e-03 eta 0:14:23
epoch [15/30] batch [180/204] time 0.255 (0.276) data 0.000 (0.006) loss 0.1812 (0.6461) lr 5.5226e-03 eta 0:14:12
epoch [15/30] batch [200/204] time 0.249 (0.274) data 0.000 (0.005) loss 0.4011 (0.7125) lr 5.5226e-03 eta 0:13:59
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.32s/it] 29%|██▊       | 2/7 [00:02<00:05,  1.10s/it] 43%|████▎     | 3/7 [00:02<00:02,  1.50it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.19it/s] 71%|███████▏  | 5/7 [00:02<00:00,  2.93it/s] 86%|████████▌ | 6/7 [00:03<00:00,  3.69it/s]100%|██████████| 7/7 [00:03<00:00,  4.43it/s]100%|██████████| 7/7 [00:03<00:00,  2.06it/s]=> result
* total: 696
* correct: 651
* accuracy: 93.5%
* error: 6.5%
* macro_f1: 92.2%

epoch [16/30] batch [20/204] time 0.268 (0.323) data 0.000 (0.052) loss 2.2344 (0.7097) lr 5.0000e-03 eta 0:16:21
epoch [16/30] batch [40/204] time 0.265 (0.300) data 0.000 (0.026) loss 0.1367 (0.5678) lr 5.0000e-03 eta 0:15:04
epoch [16/30] batch [60/204] time 0.267 (0.290) data 0.000 (0.017) loss 1.8916 (0.6081) lr 5.0000e-03 eta 0:14:28
epoch [16/30] batch [80/204] time 0.264 (0.285) data 0.000 (0.013) loss 0.0382 (0.6412) lr 5.0000e-03 eta 0:14:09
epoch [16/30] batch [100/204] time 0.286 (0.282) data 0.000 (0.011) loss 1.3994 (0.6574) lr 5.0000e-03 eta 0:13:55
epoch [16/30] batch [120/204] time 0.269 (0.280) data 0.000 (0.009) loss 1.3252 (0.6948) lr 5.0000e-03 eta 0:13:42
epoch [16/30] batch [140/204] time 0.266 (0.278) data 0.000 (0.008) loss 1.0381 (0.6824) lr 5.0000e-03 eta 0:13:32
epoch [16/30] batch [160/204] time 0.278 (0.277) data 0.000 (0.007) loss 0.4595 (0.6929) lr 5.0000e-03 eta 0:13:23
epoch [16/30] batch [180/204] time 0.253 (0.276) data 0.000 (0.006) loss 0.5088 (0.7110) lr 5.0000e-03 eta 0:13:15
epoch [16/30] batch [200/204] time 0.253 (0.274) data 0.000 (0.005) loss 0.5327 (0.7189) lr 5.0000e-03 eta 0:13:03
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.08s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.07it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.75it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.51it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.27it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.03it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.29it/s]=> result
* total: 696
* correct: 651
* accuracy: 93.5%
* error: 6.5%
* macro_f1: 91.9%

epoch [17/30] batch [20/204] time 0.270 (0.327) data 0.000 (0.052) loss 3.3223 (0.8930) lr 4.4774e-03 eta 0:15:27
epoch [17/30] batch [40/204] time 0.273 (0.298) data 0.000 (0.026) loss 0.4717 (0.8670) lr 4.4774e-03 eta 0:13:59
epoch [17/30] batch [60/204] time 0.272 (0.289) data 0.000 (0.018) loss 0.6821 (0.8223) lr 4.4774e-03 eta 0:13:28
epoch [17/30] batch [80/204] time 0.278 (0.286) data 0.000 (0.013) loss 0.2695 (0.7521) lr 4.4774e-03 eta 0:13:13
epoch [17/30] batch [100/204] time 0.269 (0.283) data 0.000 (0.011) loss 0.2096 (0.8245) lr 4.4774e-03 eta 0:12:59
epoch [17/30] batch [120/204] time 0.265 (0.281) data 0.000 (0.009) loss 2.0215 (0.8150) lr 4.4774e-03 eta 0:12:48
epoch [17/30] batch [140/204] time 0.271 (0.279) data 0.000 (0.008) loss 0.9990 (0.7889) lr 4.4774e-03 eta 0:12:38
epoch [17/30] batch [160/204] time 0.272 (0.279) data 0.000 (0.007) loss 0.0273 (0.7663) lr 4.4774e-03 eta 0:12:30
epoch [17/30] batch [180/204] time 0.250 (0.277) data 0.000 (0.006) loss 0.3394 (0.7741) lr 4.4774e-03 eta 0:12:20
epoch [17/30] batch [200/204] time 0.252 (0.274) data 0.000 (0.005) loss 1.1348 (0.7805) lr 4.4774e-03 eta 0:12:08
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.15s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.03it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.70it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.43it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.21it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.97it/s]100%|██████████| 7/7 [00:02<00:00,  4.69it/s]100%|██████████| 7/7 [00:03<00:00,  2.25it/s]=> result
* total: 696
* correct: 653
* accuracy: 93.8%
* error: 6.2%
* macro_f1: 92.4%

epoch [18/30] batch [20/204] time 0.271 (0.331) data 0.000 (0.052) loss 0.0373 (0.7344) lr 3.9604e-03 eta 0:14:30
epoch [18/30] batch [40/204] time 0.268 (0.299) data 0.000 (0.026) loss 0.3760 (0.7161) lr 3.9604e-03 eta 0:13:01
epoch [18/30] batch [60/204] time 0.264 (0.289) data 0.000 (0.018) loss 0.6865 (0.6172) lr 3.9604e-03 eta 0:12:30
epoch [18/30] batch [80/204] time 0.271 (0.285) data 0.000 (0.013) loss 0.8486 (0.6533) lr 3.9604e-03 eta 0:12:12
epoch [18/30] batch [100/204] time 0.265 (0.282) data 0.000 (0.011) loss 0.3962 (0.6448) lr 3.9604e-03 eta 0:11:59
epoch [18/30] batch [120/204] time 0.271 (0.280) data 0.000 (0.009) loss 0.1926 (0.6589) lr 3.9604e-03 eta 0:11:47
epoch [18/30] batch [140/204] time 0.266 (0.278) data 0.000 (0.008) loss 0.1554 (0.6548) lr 3.9604e-03 eta 0:11:38
epoch [18/30] batch [160/204] time 0.274 (0.277) data 0.000 (0.007) loss 0.1438 (0.6352) lr 3.9604e-03 eta 0:11:29
epoch [18/30] batch [180/204] time 0.254 (0.275) data 0.000 (0.006) loss -0.0233 (0.6486) lr 3.9604e-03 eta 0:11:20
epoch [18/30] batch [200/204] time 0.254 (0.273) data 0.000 (0.005) loss 0.9248 (0.6435) lr 3.9604e-03 eta 0:11:09
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.09s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.06it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.74it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.49it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.27it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.03it/s]100%|██████████| 7/7 [00:02<00:00,  4.76it/s]100%|██████████| 7/7 [00:03<00:00,  2.30it/s]=> result
* total: 696
* correct: 659
* accuracy: 94.7%
* error: 5.3%
* macro_f1: 93.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/204] time 0.260 (0.330) data 0.000 (0.051) loss 1.9863 (0.9654) lr 3.4549e-03 eta 0:13:20
epoch [19/30] batch [40/204] time 0.263 (0.298) data 0.000 (0.026) loss 0.3296 (0.7722) lr 3.4549e-03 eta 0:11:58
epoch [19/30] batch [60/204] time 0.267 (0.287) data 0.000 (0.017) loss 0.2391 (0.7162) lr 3.4549e-03 eta 0:11:26
epoch [19/30] batch [80/204] time 0.265 (0.284) data 0.000 (0.013) loss 0.1384 (0.7466) lr 3.4549e-03 eta 0:11:11
epoch [19/30] batch [100/204] time 0.262 (0.281) data 0.000 (0.010) loss 0.6885 (0.7165) lr 3.4549e-03 eta 0:10:59
epoch [19/30] batch [120/204] time 0.268 (0.278) data 0.000 (0.009) loss 1.9746 (0.7207) lr 3.4549e-03 eta 0:10:48
epoch [19/30] batch [140/204] time 0.273 (0.278) data 0.000 (0.008) loss 0.1597 (0.7195) lr 3.4549e-03 eta 0:10:40
epoch [19/30] batch [160/204] time 0.266 (0.277) data 0.000 (0.007) loss 0.8027 (0.7184) lr 3.4549e-03 eta 0:10:32
epoch [19/30] batch [180/204] time 0.257 (0.275) data 0.000 (0.006) loss 0.6450 (0.7045) lr 3.4549e-03 eta 0:10:23
epoch [19/30] batch [200/204] time 0.252 (0.273) data 0.000 (0.005) loss 0.2847 (0.7025) lr 3.4549e-03 eta 0:10:14
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.13s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.72it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.46it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.24it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.00it/s]100%|██████████| 7/7 [00:02<00:00,  4.69it/s]100%|██████████| 7/7 [00:03<00:00,  2.26it/s]=> result
* total: 696
* correct: 655
* accuracy: 94.1%
* error: 5.9%
* macro_f1: 92.6%

epoch [20/30] batch [20/204] time 0.260 (0.321) data 0.000 (0.049) loss 1.8682 (0.4982) lr 2.9663e-03 eta 0:11:54
epoch [20/30] batch [40/204] time 0.269 (0.295) data 0.000 (0.025) loss 0.8789 (0.4972) lr 2.9663e-03 eta 0:10:49
epoch [20/30] batch [60/204] time 0.266 (0.286) data 0.000 (0.017) loss 0.2681 (0.4685) lr 2.9663e-03 eta 0:10:23
epoch [20/30] batch [80/204] time 0.267 (0.283) data 0.000 (0.013) loss 0.4514 (0.4374) lr 2.9663e-03 eta 0:10:12
epoch [20/30] batch [100/204] time 0.283 (0.280) data 0.000 (0.010) loss 0.1025 (0.4639) lr 2.9663e-03 eta 0:10:01
epoch [20/30] batch [120/204] time 0.264 (0.278) data 0.000 (0.008) loss 0.1851 (0.4824) lr 2.9663e-03 eta 0:09:51
epoch [20/30] batch [140/204] time 0.265 (0.277) data 0.000 (0.007) loss 0.7183 (0.5285) lr 2.9663e-03 eta 0:09:43
epoch [20/30] batch [160/204] time 0.272 (0.277) data 0.000 (0.006) loss 1.5771 (0.5289) lr 2.9663e-03 eta 0:09:36
epoch [20/30] batch [180/204] time 0.252 (0.275) data 0.000 (0.006) loss 1.5488 (0.5460) lr 2.9663e-03 eta 0:09:27
epoch [20/30] batch [200/204] time 0.252 (0.273) data 0.000 (0.005) loss 1.7744 (0.5603) lr 2.9663e-03 eta 0:09:17
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.10s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.48it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.26it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.02it/s]100%|██████████| 7/7 [00:02<00:00,  4.75it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 651
* accuracy: 93.5%
* error: 6.5%
* macro_f1: 92.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/204] time 0.270 (0.316) data 0.000 (0.049) loss 2.7129 (0.8323) lr 2.5000e-03 eta 0:10:39
epoch [21/30] batch [40/204] time 0.261 (0.291) data 0.000 (0.025) loss 0.8491 (0.5942) lr 2.5000e-03 eta 0:09:41
epoch [21/30] batch [60/204] time 0.266 (0.283) data 0.000 (0.017) loss 0.4758 (0.6107) lr 2.5000e-03 eta 0:09:19
epoch [21/30] batch [80/204] time 0.269 (0.279) data 0.000 (0.013) loss 2.6914 (0.6316) lr 2.5000e-03 eta 0:09:06
epoch [21/30] batch [100/204] time 0.263 (0.276) data 0.000 (0.010) loss 0.0309 (0.6036) lr 2.5000e-03 eta 0:08:56
epoch [21/30] batch [120/204] time 0.266 (0.275) data 0.000 (0.008) loss 1.2627 (0.5810) lr 2.5000e-03 eta 0:08:48
epoch [21/30] batch [140/204] time 0.264 (0.275) data 0.000 (0.007) loss 0.0786 (0.6197) lr 2.5000e-03 eta 0:08:41
epoch [21/30] batch [160/204] time 0.271 (0.274) data 0.000 (0.006) loss 1.6543 (0.6406) lr 2.5000e-03 eta 0:08:34
epoch [21/30] batch [180/204] time 0.253 (0.272) data 0.000 (0.006) loss 1.1895 (0.6288) lr 2.5000e-03 eta 0:08:26
epoch [21/30] batch [200/204] time 0.251 (0.270) data 0.000 (0.005) loss 0.0570 (0.6233) lr 2.5000e-03 eta 0:08:17
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.11s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.48it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.26it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.02it/s]100%|██████████| 7/7 [00:02<00:00,  4.74it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 661
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 93.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [22/30] batch [20/204] time 0.262 (0.321) data 0.000 (0.049) loss 1.5010 (0.6412) lr 2.0611e-03 eta 0:09:42
epoch [22/30] batch [40/204] time 0.261 (0.291) data 0.000 (0.024) loss 0.4138 (0.5446) lr 2.0611e-03 eta 0:08:43
epoch [22/30] batch [60/204] time 0.264 (0.282) data 0.000 (0.016) loss 0.0918 (0.5840) lr 2.0611e-03 eta 0:08:20
epoch [22/30] batch [80/204] time 0.261 (0.277) data 0.000 (0.012) loss 0.3252 (0.5894) lr 2.0611e-03 eta 0:08:06
epoch [22/30] batch [100/204] time 0.267 (0.275) data 0.000 (0.010) loss 0.4504 (0.5534) lr 2.0611e-03 eta 0:07:56
epoch [22/30] batch [120/204] time 0.265 (0.274) data 0.000 (0.008) loss 0.3901 (0.5446) lr 2.0611e-03 eta 0:07:49
epoch [22/30] batch [140/204] time 0.273 (0.272) data 0.000 (0.007) loss 0.0013 (0.5600) lr 2.0611e-03 eta 0:07:41
epoch [22/30] batch [160/204] time 0.264 (0.271) data 0.000 (0.006) loss 0.3291 (0.5660) lr 2.0611e-03 eta 0:07:33
epoch [22/30] batch [180/204] time 0.248 (0.270) data 0.000 (0.006) loss 0.1080 (0.5734) lr 2.0611e-03 eta 0:07:26
epoch [22/30] batch [200/204] time 0.248 (0.267) data 0.000 (0.005) loss 0.0685 (0.5569) lr 2.0611e-03 eta 0:07:17
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.06s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.08it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.76it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.52it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.31it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.07it/s]100%|██████████| 7/7 [00:02<00:00,  4.79it/s]100%|██████████| 7/7 [00:03<00:00,  2.32it/s]=> result
* total: 696
* correct: 658
* accuracy: 94.5%
* error: 5.5%
* macro_f1: 93.2%

epoch [23/30] batch [20/204] time 0.264 (0.315) data 0.000 (0.050) loss 0.5562 (0.6656) lr 1.6543e-03 eta 0:08:28
epoch [23/30] batch [40/204] time 0.256 (0.289) data 0.000 (0.025) loss 0.0283 (0.4821) lr 1.6543e-03 eta 0:07:39
epoch [23/30] batch [60/204] time 0.285 (0.283) data 0.000 (0.017) loss 0.4041 (0.5031) lr 1.6543e-03 eta 0:07:24
epoch [23/30] batch [80/204] time 0.272 (0.279) data 0.000 (0.013) loss 0.1748 (0.4844) lr 1.6543e-03 eta 0:07:12
epoch [23/30] batch [100/204] time 0.264 (0.276) data 0.000 (0.010) loss 1.2559 (0.5039) lr 1.6543e-03 eta 0:07:02
epoch [23/30] batch [120/204] time 0.264 (0.274) data 0.000 (0.009) loss 0.2106 (0.5406) lr 1.6543e-03 eta 0:06:54
epoch [23/30] batch [140/204] time 0.264 (0.272) data 0.000 (0.007) loss 0.0396 (0.5267) lr 1.6543e-03 eta 0:06:46
epoch [23/30] batch [160/204] time 0.262 (0.271) data 0.000 (0.006) loss 1.3184 (0.5325) lr 1.6543e-03 eta 0:06:38
epoch [23/30] batch [180/204] time 0.247 (0.269) data 0.000 (0.006) loss 3.3867 (0.5642) lr 1.6543e-03 eta 0:06:31
epoch [23/30] batch [200/204] time 0.246 (0.267) data 0.000 (0.005) loss 2.5859 (0.5652) lr 1.6543e-03 eta 0:06:22
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.14s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.04it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.71it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.46it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.23it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.00it/s]100%|██████████| 7/7 [00:02<00:00,  4.72it/s]100%|██████████| 7/7 [00:03<00:00,  2.26it/s]=> result
* total: 696
* correct: 664
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 94.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [24/30] batch [20/204] time 0.254 (0.319) data 0.000 (0.050) loss 0.1737 (0.5938) lr 1.2843e-03 eta 0:07:29
epoch [24/30] batch [40/204] time 0.265 (0.290) data 0.000 (0.025) loss 0.2150 (0.5331) lr 1.2843e-03 eta 0:06:42
epoch [24/30] batch [60/204] time 0.258 (0.281) data 0.000 (0.017) loss 0.5205 (0.4836) lr 1.2843e-03 eta 0:06:24
epoch [24/30] batch [80/204] time 0.266 (0.276) data 0.000 (0.013) loss 0.5464 (0.5214) lr 1.2843e-03 eta 0:06:12
epoch [24/30] batch [100/204] time 0.267 (0.274) data 0.000 (0.010) loss 0.0334 (0.4969) lr 1.2843e-03 eta 0:06:03
epoch [24/30] batch [120/204] time 0.262 (0.272) data 0.000 (0.009) loss 0.0544 (0.5490) lr 1.2843e-03 eta 0:05:55
epoch [24/30] batch [140/204] time 0.268 (0.271) data 0.000 (0.007) loss 0.0748 (0.5349) lr 1.2843e-03 eta 0:05:49
epoch [24/30] batch [160/204] time 0.266 (0.271) data 0.000 (0.006) loss 0.2311 (0.5080) lr 1.2843e-03 eta 0:05:43
epoch [24/30] batch [180/204] time 0.248 (0.270) data 0.000 (0.006) loss 0.3477 (0.5413) lr 1.2843e-03 eta 0:05:36
epoch [24/30] batch [200/204] time 0.248 (0.268) data 0.000 (0.005) loss 1.3604 (0.5362) lr 1.2843e-03 eta 0:05:28
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.12s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.05it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.73it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.48it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.26it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.02it/s]100%|██████████| 7/7 [00:02<00:00,  4.75it/s]100%|██████████| 7/7 [00:03<00:00,  2.28it/s]=> result
* total: 696
* correct: 662
* accuracy: 95.1%
* error: 4.9%
* macro_f1: 94.0%

epoch [25/30] batch [20/204] time 0.260 (0.325) data 0.000 (0.048) loss 0.1172 (0.5799) lr 9.5492e-04 eta 0:06:31
epoch [25/30] batch [40/204] time 0.264 (0.295) data 0.000 (0.024) loss 0.0486 (0.5887) lr 9.5492e-04 eta 0:05:48
epoch [25/30] batch [60/204] time 0.265 (0.285) data 0.000 (0.016) loss 0.0746 (0.6205) lr 9.5492e-04 eta 0:05:31
epoch [25/30] batch [80/204] time 0.258 (0.280) data 0.000 (0.012) loss 0.1765 (0.5395) lr 9.5492e-04 eta 0:05:20
epoch [25/30] batch [100/204] time 0.273 (0.277) data 0.000 (0.010) loss 3.0703 (0.5721) lr 9.5492e-04 eta 0:05:11
epoch [25/30] batch [120/204] time 0.265 (0.276) data 0.000 (0.008) loss 0.1730 (0.5484) lr 9.5492e-04 eta 0:05:04
epoch [25/30] batch [140/204] time 0.264 (0.274) data 0.000 (0.007) loss 1.2666 (0.5119) lr 9.5492e-04 eta 0:04:57
epoch [25/30] batch [160/204] time 0.275 (0.274) data 0.001 (0.006) loss 0.7271 (0.5162) lr 9.5492e-04 eta 0:04:51
epoch [25/30] batch [180/204] time 0.251 (0.272) data 0.000 (0.006) loss 2.7812 (0.5215) lr 9.5492e-04 eta 0:04:43
epoch [25/30] batch [200/204] time 0.248 (0.270) data 0.000 (0.005) loss 0.1565 (0.5259) lr 9.5492e-04 eta 0:04:36
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.18s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.02it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.68it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.42it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.19it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.95it/s]100%|██████████| 7/7 [00:02<00:00,  4.68it/s]100%|██████████| 7/7 [00:03<00:00,  2.23it/s]=> result
* total: 696
* correct: 665
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 94.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [26/30] batch [20/204] time 0.261 (0.314) data 0.000 (0.051) loss 0.1313 (0.5532) lr 6.6987e-04 eta 0:05:14
epoch [26/30] batch [40/204] time 0.258 (0.288) data 0.000 (0.025) loss 0.0360 (0.5779) lr 6.6987e-04 eta 0:04:41
epoch [26/30] batch [60/204] time 0.276 (0.281) data 0.000 (0.017) loss 0.5381 (0.5225) lr 6.6987e-04 eta 0:04:29
epoch [26/30] batch [80/204] time 0.260 (0.278) data 0.000 (0.013) loss 0.1159 (0.4517) lr 6.6987e-04 eta 0:04:21
epoch [26/30] batch [100/204] time 0.260 (0.275) data 0.000 (0.010) loss -0.0104 (0.5020) lr 6.6987e-04 eta 0:04:12
epoch [26/30] batch [120/204] time 0.259 (0.273) data 0.000 (0.009) loss 0.3940 (0.5265) lr 6.6987e-04 eta 0:04:05
epoch [26/30] batch [140/204] time 0.255 (0.271) data 0.000 (0.007) loss 0.2571 (0.5161) lr 6.6987e-04 eta 0:03:58
epoch [26/30] batch [160/204] time 0.262 (0.270) data 0.000 (0.007) loss 0.1919 (0.5171) lr 6.6987e-04 eta 0:03:52
epoch [26/30] batch [180/204] time 0.252 (0.268) data 0.000 (0.006) loss 0.1821 (0.4992) lr 6.6987e-04 eta 0:03:45
epoch [26/30] batch [200/204] time 0.246 (0.267) data 0.000 (0.005) loss 0.1860 (0.4888) lr 6.6987e-04 eta 0:03:38
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.04s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.09it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.78it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.54it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.32it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.09it/s]100%|██████████| 7/7 [00:02<00:00,  4.81it/s]100%|██████████| 7/7 [00:02<00:00,  2.34it/s]=> result
* total: 696
* correct: 665
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 94.6%

epoch [27/30] batch [20/204] time 0.264 (0.316) data 0.000 (0.050) loss 0.1218 (0.4220) lr 4.3227e-04 eta 0:04:11
epoch [27/30] batch [40/204] time 0.255 (0.289) data 0.000 (0.025) loss 0.0706 (0.4360) lr 4.3227e-04 eta 0:03:44
epoch [27/30] batch [60/204] time 0.262 (0.280) data 0.000 (0.017) loss 0.0061 (0.4712) lr 4.3227e-04 eta 0:03:31
epoch [27/30] batch [80/204] time 0.266 (0.276) data 0.000 (0.013) loss 0.0472 (0.4469) lr 4.3227e-04 eta 0:03:23
epoch [27/30] batch [100/204] time 0.258 (0.274) data 0.000 (0.010) loss 0.1324 (0.4906) lr 4.3227e-04 eta 0:03:16
epoch [27/30] batch [120/204] time 0.261 (0.273) data 0.000 (0.009) loss 0.0858 (0.4797) lr 4.3227e-04 eta 0:03:10
epoch [27/30] batch [140/204] time 0.271 (0.272) data 0.000 (0.007) loss 0.1904 (0.4555) lr 4.3227e-04 eta 0:03:03
epoch [27/30] batch [160/204] time 0.263 (0.271) data 0.000 (0.007) loss 0.9258 (0.4714) lr 4.3227e-04 eta 0:02:57
epoch [27/30] batch [180/204] time 0.249 (0.269) data 0.000 (0.006) loss 0.0632 (0.4796) lr 4.3227e-04 eta 0:02:51
epoch [27/30] batch [200/204] time 0.246 (0.268) data 0.000 (0.005) loss 0.1884 (0.4871) lr 4.3227e-04 eta 0:02:44
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.17s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.03it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.69it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.43it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.20it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.96it/s]100%|██████████| 7/7 [00:02<00:00,  4.69it/s]100%|██████████| 7/7 [00:03<00:00,  2.24it/s]=> result
* total: 696
* correct: 663
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 94.3%

epoch [28/30] batch [20/204] time 0.265 (0.322) data 0.000 (0.050) loss 1.0752 (0.4157) lr 2.4472e-04 eta 0:03:10
epoch [28/30] batch [40/204] time 0.268 (0.295) data 0.000 (0.025) loss 0.0291 (0.4253) lr 2.4472e-04 eta 0:02:48
epoch [28/30] batch [60/204] time 0.262 (0.286) data 0.000 (0.017) loss 2.6680 (0.4992) lr 2.4472e-04 eta 0:02:37
epoch [28/30] batch [80/204] time 0.268 (0.283) data 0.000 (0.013) loss 2.7344 (0.5527) lr 2.4472e-04 eta 0:02:30
epoch [28/30] batch [100/204] time 0.268 (0.280) data 0.000 (0.010) loss 0.0832 (0.5310) lr 2.4472e-04 eta 0:02:23
epoch [28/30] batch [120/204] time 0.273 (0.279) data 0.000 (0.009) loss 0.0455 (0.5124) lr 2.4472e-04 eta 0:02:17
epoch [28/30] batch [140/204] time 0.262 (0.277) data 0.000 (0.007) loss 0.0776 (0.4951) lr 2.4472e-04 eta 0:02:10
epoch [28/30] batch [160/204] time 0.273 (0.276) data 0.000 (0.007) loss 0.1156 (0.4967) lr 2.4472e-04 eta 0:02:04
epoch [28/30] batch [180/204] time 0.253 (0.275) data 0.000 (0.006) loss 0.6992 (0.5121) lr 2.4472e-04 eta 0:01:58
epoch [28/30] batch [200/204] time 0.254 (0.272) data 0.000 (0.005) loss 0.0344 (0.5107) lr 2.4472e-04 eta 0:01:52
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:13,  2.18s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.02it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.69it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.43it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.20it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.96it/s]100%|██████████| 7/7 [00:02<00:00,  4.69it/s]100%|██████████| 7/7 [00:03<00:00,  2.23it/s]=> result
* total: 696
* correct: 663
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 94.5%

epoch [29/30] batch [20/204] time 0.262 (0.328) data 0.000 (0.051) loss 0.1611 (0.8571) lr 1.0926e-04 eta 0:02:07
epoch [29/30] batch [40/204] time 0.264 (0.298) data 0.000 (0.026) loss 1.5781 (0.7636) lr 1.0926e-04 eta 0:01:49
epoch [29/30] batch [60/204] time 0.274 (0.288) data 0.000 (0.017) loss -0.0189 (0.6940) lr 1.0926e-04 eta 0:01:40
epoch [29/30] batch [80/204] time 0.274 (0.283) data 0.000 (0.013) loss -0.0048 (0.6236) lr 1.0926e-04 eta 0:01:32
epoch [29/30] batch [100/204] time 0.265 (0.280) data 0.000 (0.010) loss 0.6113 (0.5613) lr 1.0926e-04 eta 0:01:26
epoch [29/30] batch [120/204] time 0.264 (0.278) data 0.000 (0.009) loss 0.5723 (0.5967) lr 1.0926e-04 eta 0:01:20
epoch [29/30] batch [140/204] time 0.269 (0.277) data 0.000 (0.007) loss 0.0338 (0.6277) lr 1.0926e-04 eta 0:01:14
epoch [29/30] batch [160/204] time 0.262 (0.276) data 0.000 (0.007) loss 0.1210 (0.5998) lr 1.0926e-04 eta 0:01:08
epoch [29/30] batch [180/204] time 0.251 (0.274) data 0.000 (0.006) loss 0.0951 (0.5611) lr 1.0926e-04 eta 0:01:02
epoch [29/30] batch [200/204] time 0.252 (0.272) data 0.000 (0.005) loss 0.0259 (0.5425) lr 1.0926e-04 eta 0:00:56
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.16s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.03it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.70it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.44it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.19it/s] 86%|████████▌ | 6/7 [00:02<00:00,  3.95it/s]100%|██████████| 7/7 [00:02<00:00,  4.68it/s]100%|██████████| 7/7 [00:03<00:00,  2.25it/s]=> result
* total: 696
* correct: 664
* accuracy: 95.4%
* error: 4.6%
* macro_f1: 94.7%

epoch [30/30] batch [20/204] time 0.270 (0.321) data 0.000 (0.049) loss 0.4670 (0.3526) lr 2.7391e-05 eta 0:00:59
epoch [30/30] batch [40/204] time 0.269 (0.294) data 0.000 (0.025) loss 0.1957 (0.5571) lr 2.7391e-05 eta 0:00:48
epoch [30/30] batch [60/204] time 0.261 (0.285) data 0.000 (0.016) loss 0.0417 (0.5001) lr 2.7391e-05 eta 0:00:41
epoch [30/30] batch [80/204] time 0.263 (0.280) data 0.000 (0.012) loss 0.3364 (0.4695) lr 2.7391e-05 eta 0:00:34
epoch [30/30] batch [100/204] time 0.267 (0.278) data 0.000 (0.010) loss 1.0811 (0.4842) lr 2.7391e-05 eta 0:00:28
epoch [30/30] batch [120/204] time 0.265 (0.276) data 0.000 (0.008) loss 0.2114 (0.4805) lr 2.7391e-05 eta 0:00:23
epoch [30/30] batch [140/204] time 0.268 (0.275) data 0.000 (0.007) loss 0.3909 (0.4650) lr 2.7391e-05 eta 0:00:17
epoch [30/30] batch [160/204] time 0.265 (0.275) data 0.000 (0.006) loss 0.7783 (0.4569) lr 2.7391e-05 eta 0:00:12
epoch [30/30] batch [180/204] time 0.253 (0.273) data 0.000 (0.006) loss 0.2361 (0.4405) lr 2.7391e-05 eta 0:00:06
epoch [30/30] batch [200/204] time 0.253 (0.271) data 0.001 (0.005) loss 0.0522 (0.4480) lr 2.7391e-05 eta 0:00:01
Evaluate on the *val* set
  0%|          | 0/7 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:02<00:12,  2.07s/it] 29%|██▊       | 2/7 [00:02<00:04,  1.07it/s] 43%|████▎     | 3/7 [00:02<00:02,  1.75it/s] 57%|█████▋    | 4/7 [00:02<00:01,  2.51it/s] 71%|███████▏  | 5/7 [00:02<00:00,  3.29it/s] 86%|████████▌ | 6/7 [00:02<00:00,  4.06it/s]100%|██████████| 7/7 [00:02<00:00,  4.78it/s]100%|██████████| 7/7 [00:03<00:00,  2.31it/s]
=> result
* total: 696
* correct: 663
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 94.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:02<00:25,  2.53s/it] 18%|█▊        | 2/11 [00:02<00:10,  1.12s/it] 27%|██▋       | 3/11 [00:02<00:05,  1.49it/s] 36%|███▋      | 4/11 [00:02<00:03,  2.17it/s] 45%|████▌     | 5/11 [00:03<00:02,  2.90it/s] 55%|█████▍    | 6/11 [00:03<00:01,  3.65it/s] 64%|██████▎   | 7/11 [00:03<00:00,  4.37it/s] 73%|███████▎  | 8/11 [00:03<00:00,  5.02it/s] 82%|████████▏ | 9/11 [00:03<00:00,  5.57it/s] 91%|█████████ | 10/11 [00:03<00:00,  6.02it/s]100%|██████████| 11/11 [00:04<00:00,  2.74it/s]
=> result
* total: 1,053
* correct: 1,027
* accuracy: 97.5%
* error: 2.5%
* macro_f1: 97.6%
Elapsed: 0:29:30
+ sh scripts/rpo_prime/base2new_test_sdl.sh oxford_flowers 3 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
816 937 1410
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      937
# test     1,410
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/15 [00:00<?, ?it/s]  7%|▋         | 1/15 [00:04<01:04,  4.58s/it] 13%|█▎        | 2/15 [00:04<00:25,  1.96s/it] 20%|██        | 3/15 [00:04<00:13,  1.13s/it] 27%|██▋       | 4/15 [00:04<00:08,  1.35it/s] 33%|███▎      | 5/15 [00:05<00:05,  1.92it/s] 40%|████      | 6/15 [00:05<00:03,  2.56it/s] 47%|████▋     | 7/15 [00:05<00:02,  3.26it/s] 53%|█████▎    | 8/15 [00:05<00:01,  3.96it/s] 60%|██████    | 9/15 [00:05<00:01,  4.63it/s] 67%|██████▋   | 10/15 [00:05<00:00,  5.23it/s] 73%|███████▎  | 11/15 [00:05<00:00,  5.75it/s] 80%|████████  | 12/15 [00:06<00:00,  6.17it/s] 87%|████████▋ | 13/15 [00:06<00:00,  6.46it/s] 93%|█████████▎| 14/15 [00:06<00:00,  6.71it/s]100%|██████████| 15/15 [00:06<00:00,  2.31it/s]
=> result
* total: 1,410
* correct: 1,061
* accuracy: 75.2%
* error: 24.8%
* macro_f1: 70.1%
+ for dataset in eurosat dtd oxford_flowers stanford_cars oxford_pets food101 ucf101 caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh stanford_cars 1 0 main_tmp1_0.1sdl 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
1568 812 4002
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      812
# test     4,002
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/392] time 0.289 (0.450) data 0.000 (0.065) loss 3.1465 (4.1331) lr 1.0000e-02 eta 1:27:58
epoch [1/30] batch [40/392] time 0.295 (0.376) data 0.000 (0.033) loss 4.1367 (3.9186) lr 1.0000e-02 eta 1:13:24
epoch [1/30] batch [60/392] time 0.298 (0.356) data 0.000 (0.022) loss 3.1855 (3.5502) lr 1.0000e-02 eta 1:09:19
epoch [1/30] batch [80/392] time 0.304 (0.344) data 0.000 (0.017) loss 1.1904 (3.3964) lr 1.0000e-02 eta 1:06:53
epoch [1/30] batch [100/392] time 0.308 (0.335) data 0.000 (0.013) loss 1.8096 (3.2985) lr 1.0000e-02 eta 1:05:04
epoch [1/30] batch [120/392] time 0.310 (0.330) data 0.000 (0.011) loss 2.6895 (3.2344) lr 1.0000e-02 eta 1:04:05
epoch [1/30] batch [140/392] time 0.292 (0.328) data 0.000 (0.010) loss 2.6895 (3.2582) lr 1.0000e-02 eta 1:03:31
epoch [1/30] batch [160/392] time 0.290 (0.326) data 0.000 (0.008) loss 3.0742 (3.2512) lr 1.0000e-02 eta 1:02:56
epoch [1/30] batch [180/392] time 0.309 (0.323) data 0.000 (0.008) loss 2.4961 (3.2028) lr 1.0000e-02 eta 1:02:21
epoch [1/30] batch [200/392] time 0.398 (0.322) data 0.000 (0.007) loss 2.2012 (3.1382) lr 1.0000e-02 eta 1:01:57
epoch [1/30] batch [220/392] time 0.302 (0.320) data 0.000 (0.006) loss 4.1875 (3.0946) lr 1.0000e-02 eta 1:01:34
epoch [1/30] batch [240/392] time 0.296 (0.319) data 0.001 (0.006) loss 1.7217 (3.0847) lr 1.0000e-02 eta 1:01:09
epoch [1/30] batch [260/392] time 0.308 (0.317) data 0.000 (0.005) loss 2.9609 (3.0826) lr 1.0000e-02 eta 1:00:46
epoch [1/30] batch [280/392] time 0.301 (0.316) data 0.000 (0.005) loss 3.2500 (3.0842) lr 1.0000e-02 eta 1:00:30
epoch [1/30] batch [300/392] time 0.287 (0.316) data 0.000 (0.005) loss 3.1406 (3.0915) lr 1.0000e-02 eta 1:00:15
epoch [1/30] batch [320/392] time 0.300 (0.314) data 0.000 (0.004) loss 3.3867 (3.0913) lr 1.0000e-02 eta 0:59:57
epoch [1/30] batch [340/392] time 0.297 (0.314) data 0.000 (0.004) loss 1.9150 (3.0494) lr 1.0000e-02 eta 0:59:47
epoch [1/30] batch [360/392] time 0.336 (0.314) data 0.000 (0.004) loss 1.7715 (3.0460) lr 1.0000e-02 eta 0:59:36
epoch [1/30] batch [380/392] time 0.281 (0.312) data 0.000 (0.004) loss 3.5859 (3.0315) lr 1.0000e-02 eta 0:59:10
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:23,  2.94s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.31s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.28it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.87it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.52it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.19it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.84it/s] 89%|████████▉ | 8/9 [00:04<00:00,  4.42it/s]100%|██████████| 9/9 [00:04<00:00,  2.13it/s]=> result
* total: 812
* correct: 546
* accuracy: 67.2%
* error: 32.8%
* macro_f1: 65.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/392] time 0.308 (0.379) data 0.000 (0.057) loss 2.3164 (3.2224) lr 9.9726e-03 eta 1:11:42
epoch [2/30] batch [40/392] time 0.292 (0.340) data 0.000 (0.029) loss 2.0703 (2.9168) lr 9.9726e-03 eta 1:04:08
epoch [2/30] batch [60/392] time 0.298 (0.330) data 0.000 (0.019) loss 4.8789 (2.9293) lr 9.9726e-03 eta 1:02:07
epoch [2/30] batch [80/392] time 0.302 (0.324) data 0.000 (0.015) loss 2.6465 (2.8668) lr 9.9726e-03 eta 1:01:02
epoch [2/30] batch [100/392] time 0.291 (0.321) data 0.000 (0.012) loss 1.0645 (2.8179) lr 9.9726e-03 eta 1:00:11
epoch [2/30] batch [120/392] time 0.301 (0.318) data 0.000 (0.010) loss 3.0195 (2.9239) lr 9.9726e-03 eta 0:59:34
epoch [2/30] batch [140/392] time 0.305 (0.316) data 0.000 (0.008) loss 3.1094 (2.8753) lr 9.9726e-03 eta 0:59:07
epoch [2/30] batch [160/392] time 0.306 (0.315) data 0.000 (0.007) loss 1.8311 (2.8626) lr 9.9726e-03 eta 0:58:49
epoch [2/30] batch [180/392] time 0.290 (0.314) data 0.000 (0.007) loss 2.1211 (2.8153) lr 9.9726e-03 eta 0:58:30
epoch [2/30] batch [200/392] time 0.342 (0.314) data 0.001 (0.006) loss 4.1992 (2.8025) lr 9.9726e-03 eta 0:58:25
epoch [2/30] batch [220/392] time 0.315 (0.313) data 0.000 (0.006) loss 3.8730 (2.7763) lr 9.9726e-03 eta 0:58:13
epoch [2/30] batch [240/392] time 0.302 (0.312) data 0.000 (0.005) loss 3.8945 (2.7509) lr 9.9726e-03 eta 0:57:57
epoch [2/30] batch [260/392] time 0.307 (0.313) data 0.000 (0.005) loss 3.4922 (2.7327) lr 9.9726e-03 eta 0:57:52
epoch [2/30] batch [280/392] time 0.298 (0.312) data 0.000 (0.004) loss 2.4668 (2.6989) lr 9.9726e-03 eta 0:57:39
epoch [2/30] batch [300/392] time 0.293 (0.311) data 0.000 (0.004) loss 1.1992 (2.7165) lr 9.9726e-03 eta 0:57:27
epoch [2/30] batch [320/392] time 0.297 (0.311) data 0.000 (0.004) loss 1.3867 (2.6804) lr 9.9726e-03 eta 0:57:14
epoch [2/30] batch [340/392] time 0.311 (0.311) data 0.000 (0.004) loss 2.5508 (2.6795) lr 9.9726e-03 eta 0:57:05
epoch [2/30] batch [360/392] time 0.292 (0.310) data 0.000 (0.003) loss 3.5352 (2.7060) lr 9.9726e-03 eta 0:56:57
epoch [2/30] batch [380/392] time 0.284 (0.309) data 0.000 (0.003) loss 1.0986 (2.7242) lr 9.9726e-03 eta 0:56:37
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.84s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.26s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.33it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.94it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.60it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.27it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.91it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.48it/s]100%|██████████| 9/9 [00:04<00:00,  2.19it/s]=> result
* total: 812
* correct: 547
* accuracy: 67.4%
* error: 32.6%
* macro_f1: 64.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/392] time 0.287 (0.364) data 0.000 (0.050) loss 2.2402 (2.9844) lr 9.8907e-03 eta 1:06:31
epoch [3/30] batch [40/392] time 0.319 (0.331) data 0.001 (0.025) loss 1.9014 (2.8546) lr 9.8907e-03 eta 1:00:23
epoch [3/30] batch [60/392] time 0.304 (0.321) data 0.000 (0.017) loss 2.4082 (2.9905) lr 9.8907e-03 eta 0:58:22
epoch [3/30] batch [80/392] time 0.294 (0.316) data 0.000 (0.013) loss 2.0156 (2.9012) lr 9.8907e-03 eta 0:57:21
epoch [3/30] batch [100/392] time 0.308 (0.312) data 0.000 (0.010) loss 5.2500 (2.9285) lr 9.8907e-03 eta 0:56:33
epoch [3/30] batch [120/392] time 0.311 (0.312) data 0.000 (0.009) loss 1.6338 (2.9008) lr 9.8907e-03 eta 0:56:32
epoch [3/30] batch [140/392] time 0.295 (0.312) data 0.000 (0.007) loss 1.3926 (2.8587) lr 9.8907e-03 eta 0:56:16
epoch [3/30] batch [160/392] time 0.298 (0.310) data 0.000 (0.007) loss 0.9458 (2.8639) lr 9.8907e-03 eta 0:55:55
epoch [3/30] batch [180/392] time 0.286 (0.309) data 0.000 (0.006) loss 3.7266 (2.8286) lr 9.8907e-03 eta 0:55:37
epoch [3/30] batch [200/392] time 0.293 (0.309) data 0.000 (0.005) loss 1.8184 (2.8409) lr 9.8907e-03 eta 0:55:28
epoch [3/30] batch [220/392] time 0.309 (0.308) data 0.000 (0.005) loss 2.5586 (2.8703) lr 9.8907e-03 eta 0:55:15
epoch [3/30] batch [240/392] time 0.295 (0.308) data 0.000 (0.004) loss 1.6191 (2.8719) lr 9.8907e-03 eta 0:55:03
epoch [3/30] batch [260/392] time 0.304 (0.307) data 0.000 (0.004) loss 1.1230 (2.8501) lr 9.8907e-03 eta 0:54:54
epoch [3/30] batch [280/392] time 0.315 (0.307) data 0.000 (0.004) loss 1.6924 (2.8639) lr 9.8907e-03 eta 0:54:43
epoch [3/30] batch [300/392] time 0.291 (0.306) data 0.000 (0.004) loss 3.2324 (2.8697) lr 9.8907e-03 eta 0:54:28
epoch [3/30] batch [320/392] time 0.298 (0.306) data 0.000 (0.003) loss 5.0586 (2.8591) lr 9.8907e-03 eta 0:54:25
epoch [3/30] batch [340/392] time 0.297 (0.306) data 0.000 (0.003) loss 1.7061 (2.8273) lr 9.8907e-03 eta 0:54:18
epoch [3/30] batch [360/392] time 0.342 (0.306) data 0.000 (0.003) loss 0.1320 (2.8177) lr 9.8907e-03 eta 0:54:11
epoch [3/30] batch [380/392] time 0.284 (0.306) data 0.000 (0.003) loss 3.9180 (2.8153) lr 9.8907e-03 eta 0:53:57
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.84s/it] 22%|██▏       | 2/9 [00:03<00:08,  1.27s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.32it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.92it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.58it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.25it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.90it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.47it/s]100%|██████████| 9/9 [00:04<00:00,  2.18it/s]=> result
* total: 812
* correct: 546
* accuracy: 67.2%
* error: 32.8%
* macro_f1: 65.8%

epoch [4/30] batch [20/392] time 0.293 (0.366) data 0.000 (0.053) loss 1.8838 (2.7590) lr 9.7553e-03 eta 1:04:29
epoch [4/30] batch [40/392] time 0.313 (0.335) data 0.000 (0.027) loss 2.0078 (2.6882) lr 9.7553e-03 eta 0:58:48
epoch [4/30] batch [60/392] time 0.344 (0.324) data 0.000 (0.018) loss 4.2773 (2.5925) lr 9.7553e-03 eta 0:56:51
epoch [4/30] batch [80/392] time 0.292 (0.321) data 0.000 (0.013) loss 2.5566 (2.6924) lr 9.7553e-03 eta 0:56:16
epoch [4/30] batch [100/392] time 0.306 (0.318) data 0.000 (0.011) loss 4.0586 (2.6549) lr 9.7553e-03 eta 0:55:29
epoch [4/30] batch [120/392] time 0.304 (0.315) data 0.000 (0.009) loss 4.0078 (2.6187) lr 9.7553e-03 eta 0:54:59
epoch [4/30] batch [140/392] time 0.297 (0.313) data 0.000 (0.008) loss 3.6777 (2.6550) lr 9.7553e-03 eta 0:54:33
epoch [4/30] batch [160/392] time 0.293 (0.313) data 0.000 (0.007) loss 3.8809 (2.6825) lr 9.7553e-03 eta 0:54:18
epoch [4/30] batch [180/392] time 0.292 (0.312) data 0.000 (0.006) loss 1.6641 (2.7069) lr 9.7553e-03 eta 0:54:02
epoch [4/30] batch [200/392] time 0.287 (0.311) data 0.000 (0.006) loss 0.2256 (2.6442) lr 9.7553e-03 eta 0:53:45
epoch [4/30] batch [220/392] time 0.338 (0.311) data 0.000 (0.005) loss 1.6846 (2.7114) lr 9.7553e-03 eta 0:53:42
epoch [4/30] batch [240/392] time 0.322 (0.310) data 0.000 (0.005) loss 3.1797 (2.7103) lr 9.7553e-03 eta 0:53:30
epoch [4/30] batch [260/392] time 0.312 (0.310) data 0.000 (0.004) loss 3.4629 (2.7561) lr 9.7553e-03 eta 0:53:17
epoch [4/30] batch [280/392] time 0.295 (0.309) data 0.000 (0.004) loss 2.4414 (2.7617) lr 9.7553e-03 eta 0:53:04
epoch [4/30] batch [300/392] time 0.314 (0.309) data 0.000 (0.004) loss 4.0820 (2.7603) lr 9.7553e-03 eta 0:52:56
epoch [4/30] batch [320/392] time 0.302 (0.309) data 0.000 (0.004) loss 4.9961 (2.7530) lr 9.7553e-03 eta 0:52:47
epoch [4/30] batch [340/392] time 0.294 (0.308) data 0.000 (0.003) loss 4.3086 (2.7434) lr 9.7553e-03 eta 0:52:36
epoch [4/30] batch [360/392] time 0.313 (0.308) data 0.000 (0.003) loss 3.9121 (2.7222) lr 9.7553e-03 eta 0:52:27
epoch [4/30] batch [380/392] time 0.285 (0.307) data 0.000 (0.003) loss 3.2598 (2.7624) lr 9.7553e-03 eta 0:52:08
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:23,  2.97s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.32s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.28it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.87it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.51it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.18it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.82it/s] 89%|████████▉ | 8/9 [00:04<00:00,  4.41it/s]100%|██████████| 9/9 [00:04<00:00,  2.12it/s]=> result
* total: 812
* correct: 558
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 67.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/392] time 0.310 (0.364) data 0.000 (0.050) loss 3.0156 (2.8799) lr 9.5677e-03 eta 1:01:38
epoch [5/30] batch [40/392] time 0.293 (0.336) data 0.000 (0.025) loss 0.9136 (2.8963) lr 9.5677e-03 eta 0:56:48
epoch [5/30] batch [60/392] time 0.303 (0.326) data 0.000 (0.017) loss 2.6074 (2.7808) lr 9.5677e-03 eta 0:55:02
epoch [5/30] batch [80/392] time 0.305 (0.320) data 0.000 (0.013) loss 3.3203 (2.8364) lr 9.5677e-03 eta 0:53:55
epoch [5/30] batch [100/392] time 0.301 (0.316) data 0.000 (0.010) loss 2.9375 (2.8458) lr 9.5677e-03 eta 0:53:07
epoch [5/30] batch [120/392] time 0.307 (0.313) data 0.000 (0.009) loss 2.2754 (2.8823) lr 9.5677e-03 eta 0:52:34
epoch [5/30] batch [140/392] time 0.294 (0.311) data 0.000 (0.007) loss 2.4980 (2.8064) lr 9.5677e-03 eta 0:52:09
epoch [5/30] batch [160/392] time 0.289 (0.310) data 0.000 (0.007) loss 4.1289 (2.8078) lr 9.5677e-03 eta 0:51:53
epoch [5/30] batch [180/392] time 0.315 (0.310) data 0.000 (0.006) loss 1.9258 (2.7962) lr 9.5677e-03 eta 0:51:42
epoch [5/30] batch [200/392] time 0.290 (0.309) data 0.000 (0.005) loss 3.1113 (2.8542) lr 9.5677e-03 eta 0:51:27
epoch [5/30] batch [220/392] time 0.311 (0.308) data 0.000 (0.005) loss 3.7246 (2.7978) lr 9.5677e-03 eta 0:51:12
epoch [5/30] batch [240/392] time 0.297 (0.308) data 0.000 (0.004) loss 1.0811 (2.7956) lr 9.5677e-03 eta 0:51:02
epoch [5/30] batch [260/392] time 0.305 (0.308) data 0.000 (0.004) loss 2.4473 (2.7919) lr 9.5677e-03 eta 0:50:57
epoch [5/30] batch [280/392] time 0.309 (0.308) data 0.000 (0.004) loss 2.2305 (2.7843) lr 9.5677e-03 eta 0:50:48
epoch [5/30] batch [300/392] time 0.304 (0.307) data 0.000 (0.004) loss 4.2930 (2.7522) lr 9.5677e-03 eta 0:50:36
epoch [5/30] batch [320/392] time 0.304 (0.307) data 0.000 (0.003) loss 1.3887 (2.7443) lr 9.5677e-03 eta 0:50:30
epoch [5/30] batch [340/392] time 0.332 (0.307) data 0.000 (0.003) loss 1.2832 (2.7367) lr 9.5677e-03 eta 0:50:22
epoch [5/30] batch [360/392] time 0.296 (0.307) data 0.000 (0.003) loss 1.3262 (2.7194) lr 9.5677e-03 eta 0:50:16
epoch [5/30] batch [380/392] time 0.284 (0.306) data 0.000 (0.003) loss 1.7783 (2.7053) lr 9.5677e-03 eta 0:50:00
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.66s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.23s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.34it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.94it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.60it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.27it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.91it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.49it/s]100%|██████████| 9/9 [00:04<00:00,  2.22it/s]=> result
* total: 812
* correct: 559
* accuracy: 68.8%
* error: 31.2%
* macro_f1: 66.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/392] time 0.298 (0.356) data 0.000 (0.049) loss 5.2266 (2.5189) lr 9.3301e-03 eta 0:58:05
epoch [6/30] batch [40/392] time 0.296 (0.330) data 0.000 (0.025) loss 2.1758 (2.5190) lr 9.3301e-03 eta 0:53:41
epoch [6/30] batch [60/392] time 0.292 (0.322) data 0.000 (0.016) loss 2.0059 (2.5923) lr 9.3301e-03 eta 0:52:11
epoch [6/30] batch [80/392] time 0.297 (0.317) data 0.000 (0.012) loss 1.9141 (2.5946) lr 9.3301e-03 eta 0:51:25
epoch [6/30] batch [100/392] time 0.293 (0.316) data 0.000 (0.010) loss 2.2891 (2.6547) lr 9.3301e-03 eta 0:51:02
epoch [6/30] batch [120/392] time 0.299 (0.315) data 0.000 (0.008) loss 0.4885 (2.6407) lr 9.3301e-03 eta 0:50:53
epoch [6/30] batch [140/392] time 0.291 (0.314) data 0.000 (0.007) loss 5.2266 (2.7044) lr 9.3301e-03 eta 0:50:30
epoch [6/30] batch [160/392] time 0.301 (0.313) data 0.000 (0.006) loss 4.0156 (2.6927) lr 9.3301e-03 eta 0:50:13
epoch [6/30] batch [180/392] time 0.297 (0.312) data 0.000 (0.006) loss 3.6816 (2.7071) lr 9.3301e-03 eta 0:50:02
epoch [6/30] batch [200/392] time 0.298 (0.312) data 0.000 (0.005) loss 2.3125 (2.6736) lr 9.3301e-03 eta 0:49:50
epoch [6/30] batch [220/392] time 0.333 (0.311) data 0.000 (0.005) loss 2.0059 (2.6663) lr 9.3301e-03 eta 0:49:37
epoch [6/30] batch [240/392] time 0.295 (0.310) data 0.000 (0.004) loss 0.1399 (2.6869) lr 9.3301e-03 eta 0:49:27
epoch [6/30] batch [260/392] time 0.300 (0.310) data 0.001 (0.004) loss 6.0781 (2.6761) lr 9.3301e-03 eta 0:49:14
epoch [6/30] batch [280/392] time 0.300 (0.310) data 0.000 (0.004) loss 2.5312 (2.6494) lr 9.3301e-03 eta 0:49:09
epoch [6/30] batch [300/392] time 0.297 (0.310) data 0.000 (0.004) loss 2.7461 (2.6474) lr 9.3301e-03 eta 0:49:00
epoch [6/30] batch [320/392] time 0.351 (0.310) data 0.000 (0.003) loss 2.2188 (2.6836) lr 9.3301e-03 eta 0:48:57
epoch [6/30] batch [340/392] time 0.297 (0.309) data 0.000 (0.003) loss 3.0352 (2.7095) lr 9.3301e-03 eta 0:48:47
epoch [6/30] batch [360/392] time 0.327 (0.310) data 0.000 (0.003) loss 2.6621 (2.6906) lr 9.3301e-03 eta 0:48:41
epoch [6/30] batch [380/392] time 0.283 (0.308) data 0.000 (0.003) loss 3.8926 (2.7029) lr 9.3301e-03 eta 0:48:25
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.70s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.22s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.37it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.99it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.66it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.34it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.98it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.56it/s]100%|██████████| 9/9 [00:03<00:00,  2.25it/s]=> result
* total: 812
* correct: 563
* accuracy: 69.3%
* error: 30.7%
* macro_f1: 67.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/392] time 0.325 (0.368) data 0.000 (0.053) loss 1.6270 (2.5974) lr 9.0451e-03 eta 0:57:30
epoch [7/30] batch [40/392] time 0.302 (0.340) data 0.000 (0.027) loss 1.6191 (2.4585) lr 9.0451e-03 eta 0:53:04
epoch [7/30] batch [60/392] time 0.304 (0.327) data 0.000 (0.018) loss 1.7959 (2.5456) lr 9.0451e-03 eta 0:51:00
epoch [7/30] batch [80/392] time 0.298 (0.321) data 0.000 (0.014) loss 3.5449 (2.5444) lr 9.0451e-03 eta 0:49:56
epoch [7/30] batch [100/392] time 0.319 (0.319) data 0.000 (0.011) loss 5.3828 (2.5476) lr 9.0451e-03 eta 0:49:32
epoch [7/30] batch [120/392] time 0.335 (0.317) data 0.000 (0.009) loss 1.9307 (2.5288) lr 9.0451e-03 eta 0:49:08
epoch [7/30] batch [140/392] time 0.305 (0.316) data 0.000 (0.008) loss 1.8447 (2.5681) lr 9.0451e-03 eta 0:48:52
epoch [7/30] batch [160/392] time 0.319 (0.315) data 0.000 (0.007) loss 4.0938 (2.5727) lr 9.0451e-03 eta 0:48:32
epoch [7/30] batch [180/392] time 0.294 (0.313) data 0.000 (0.006) loss 1.9902 (2.6050) lr 9.0451e-03 eta 0:48:09
epoch [7/30] batch [200/392] time 0.310 (0.312) data 0.000 (0.006) loss 2.1543 (2.5780) lr 9.0451e-03 eta 0:47:55
epoch [7/30] batch [220/392] time 0.301 (0.312) data 0.000 (0.005) loss 2.9941 (2.5566) lr 9.0451e-03 eta 0:47:43
epoch [7/30] batch [240/392] time 0.300 (0.312) data 0.000 (0.005) loss 2.0352 (2.5521) lr 9.0451e-03 eta 0:47:36
epoch [7/30] batch [260/392] time 0.299 (0.311) data 0.000 (0.004) loss 0.6724 (2.5765) lr 9.0451e-03 eta 0:47:24
epoch [7/30] batch [280/392] time 0.307 (0.311) data 0.000 (0.004) loss 4.3828 (2.5695) lr 9.0451e-03 eta 0:47:14
epoch [7/30] batch [300/392] time 0.300 (0.310) data 0.000 (0.004) loss 6.3164 (2.5988) lr 9.0451e-03 eta 0:47:06
epoch [7/30] batch [320/392] time 0.299 (0.310) data 0.000 (0.004) loss 1.5840 (2.6050) lr 9.0451e-03 eta 0:46:59
epoch [7/30] batch [340/392] time 0.345 (0.310) data 0.000 (0.003) loss 1.5039 (2.6466) lr 9.0451e-03 eta 0:46:52
epoch [7/30] batch [360/392] time 0.309 (0.310) data 0.000 (0.003) loss 1.3066 (2.6542) lr 9.0451e-03 eta 0:46:44
epoch [7/30] batch [380/392] time 0.286 (0.309) data 0.000 (0.003) loss 1.8340 (2.6681) lr 9.0451e-03 eta 0:46:28
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.87s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.29s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.30it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.90it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.55it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.22it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.86it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.44it/s]100%|██████████| 9/9 [00:04<00:00,  2.15it/s]=> result
* total: 812
* correct: 572
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 69.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/392] time 0.311 (0.363) data 0.000 (0.050) loss 3.0938 (3.0298) lr 8.7157e-03 eta 0:54:24
epoch [8/30] batch [40/392] time 0.310 (0.341) data 0.000 (0.025) loss 0.8774 (2.6438) lr 8.7157e-03 eta 0:51:05
epoch [8/30] batch [60/392] time 0.305 (0.329) data 0.000 (0.017) loss 1.3818 (2.6001) lr 8.7157e-03 eta 0:49:04
epoch [8/30] batch [80/392] time 0.291 (0.321) data 0.000 (0.013) loss 3.0020 (2.6479) lr 8.7157e-03 eta 0:47:52
epoch [8/30] batch [100/392] time 0.324 (0.318) data 0.000 (0.010) loss 2.2598 (2.6501) lr 8.7157e-03 eta 0:47:18
epoch [8/30] batch [120/392] time 0.303 (0.316) data 0.000 (0.009) loss 3.1719 (2.5671) lr 8.7157e-03 eta 0:46:48
epoch [8/30] batch [140/392] time 0.295 (0.315) data 0.000 (0.007) loss 4.6797 (2.5814) lr 8.7157e-03 eta 0:46:34
epoch [8/30] batch [160/392] time 0.305 (0.314) data 0.000 (0.007) loss 2.1699 (2.6372) lr 8.7157e-03 eta 0:46:16
epoch [8/30] batch [180/392] time 0.293 (0.313) data 0.000 (0.006) loss 2.6230 (2.6126) lr 8.7157e-03 eta 0:46:04
epoch [8/30] batch [200/392] time 0.298 (0.312) data 0.000 (0.005) loss 1.5859 (2.5854) lr 8.7157e-03 eta 0:45:53
epoch [8/30] batch [220/392] time 0.298 (0.311) data 0.000 (0.005) loss 1.9268 (2.5827) lr 8.7157e-03 eta 0:45:39
epoch [8/30] batch [240/392] time 0.312 (0.312) data 0.000 (0.005) loss 3.0195 (2.5554) lr 8.7157e-03 eta 0:45:34
epoch [8/30] batch [260/392] time 0.290 (0.311) data 0.000 (0.004) loss 3.0234 (2.5630) lr 8.7157e-03 eta 0:45:22
epoch [8/30] batch [280/392] time 0.301 (0.310) data 0.000 (0.004) loss 2.0957 (2.5396) lr 8.7157e-03 eta 0:45:10
epoch [8/30] batch [300/392] time 0.300 (0.310) data 0.000 (0.004) loss 0.7002 (2.5500) lr 8.7157e-03 eta 0:45:05
epoch [8/30] batch [320/392] time 0.309 (0.310) data 0.000 (0.003) loss 1.4746 (2.5763) lr 8.7157e-03 eta 0:44:58
epoch [8/30] batch [340/392] time 0.307 (0.310) data 0.000 (0.003) loss 1.3184 (2.5336) lr 8.7157e-03 eta 0:44:46
epoch [8/30] batch [360/392] time 0.303 (0.310) data 0.000 (0.003) loss 4.4023 (2.5242) lr 8.7157e-03 eta 0:44:39
epoch [8/30] batch [380/392] time 0.281 (0.308) data 0.000 (0.003) loss 2.4375 (2.5271) lr 8.7157e-03 eta 0:44:22
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.61s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.22s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.35it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.97it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.63it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.31it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.94it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.51it/s]100%|██████████| 9/9 [00:04<00:00,  2.25it/s]=> result
* total: 812
* correct: 574
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 69.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/392] time 0.292 (0.372) data 0.000 (0.054) loss 1.1514 (2.1207) lr 8.3457e-03 eta 0:53:24
epoch [9/30] batch [40/392] time 0.302 (0.341) data 0.000 (0.027) loss 4.3906 (2.2651) lr 8.3457e-03 eta 0:48:43
epoch [9/30] batch [60/392] time 0.297 (0.328) data 0.000 (0.018) loss 2.4570 (2.4731) lr 8.3457e-03 eta 0:46:48
epoch [9/30] batch [80/392] time 0.300 (0.321) data 0.000 (0.014) loss 1.5146 (2.4897) lr 8.3457e-03 eta 0:45:45
epoch [9/30] batch [100/392] time 0.310 (0.319) data 0.000 (0.011) loss 1.6025 (2.4084) lr 8.3457e-03 eta 0:45:22
epoch [9/30] batch [120/392] time 0.308 (0.318) data 0.000 (0.009) loss 3.0352 (2.5248) lr 8.3457e-03 eta 0:45:00
epoch [9/30] batch [140/392] time 0.309 (0.316) data 0.000 (0.008) loss 1.1182 (2.5484) lr 8.3457e-03 eta 0:44:41
epoch [9/30] batch [160/392] time 0.294 (0.315) data 0.000 (0.007) loss 1.2588 (2.5458) lr 8.3457e-03 eta 0:44:23
epoch [9/30] batch [180/392] time 0.291 (0.314) data 0.000 (0.006) loss 1.9805 (2.5890) lr 8.3457e-03 eta 0:44:08
epoch [9/30] batch [200/392] time 0.293 (0.312) data 0.000 (0.006) loss 1.0107 (2.5867) lr 8.3457e-03 eta 0:43:51
epoch [9/30] batch [220/392] time 0.317 (0.312) data 0.000 (0.005) loss 1.5430 (2.5611) lr 8.3457e-03 eta 0:43:41
epoch [9/30] batch [240/392] time 0.326 (0.311) data 0.000 (0.005) loss 1.7803 (2.5673) lr 8.3457e-03 eta 0:43:30
epoch [9/30] batch [260/392] time 0.309 (0.311) data 0.000 (0.004) loss 2.7617 (2.5825) lr 8.3457e-03 eta 0:43:21
epoch [9/30] batch [280/392] time 0.300 (0.311) data 0.000 (0.004) loss 1.8477 (2.5713) lr 8.3457e-03 eta 0:43:10
epoch [9/30] batch [300/392] time 0.291 (0.310) data 0.000 (0.004) loss 2.0117 (2.5556) lr 8.3457e-03 eta 0:43:04
epoch [9/30] batch [320/392] time 0.296 (0.310) data 0.000 (0.004) loss 0.9097 (2.5391) lr 8.3457e-03 eta 0:42:56
epoch [9/30] batch [340/392] time 0.304 (0.310) data 0.000 (0.004) loss 0.5801 (2.5371) lr 8.3457e-03 eta 0:42:46
epoch [9/30] batch [360/392] time 0.303 (0.310) data 0.001 (0.003) loss 2.3828 (2.5479) lr 8.3457e-03 eta 0:42:42
epoch [9/30] batch [380/392] time 0.286 (0.309) data 0.000 (0.003) loss 2.0352 (2.5563) lr 8.3457e-03 eta 0:42:25
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.66s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.21s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.37it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.00it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.67it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.34it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.98it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.56it/s]100%|██████████| 9/9 [00:03<00:00,  2.26it/s]=> result
* total: 812
* correct: 578
* accuracy: 71.2%
* error: 28.8%
* macro_f1: 70.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/392] time 0.342 (0.365) data 0.000 (0.049) loss 0.5791 (2.1880) lr 7.9389e-03 eta 0:49:55
epoch [10/30] batch [40/392] time 0.303 (0.337) data 0.000 (0.025) loss 2.3945 (2.6617) lr 7.9389e-03 eta 0:46:01
epoch [10/30] batch [60/392] time 0.291 (0.326) data 0.000 (0.016) loss 0.6694 (2.6238) lr 7.9389e-03 eta 0:44:20
epoch [10/30] batch [80/392] time 0.295 (0.323) data 0.000 (0.012) loss 2.6250 (2.5597) lr 7.9389e-03 eta 0:43:49
epoch [10/30] batch [100/392] time 0.302 (0.319) data 0.000 (0.010) loss 3.6445 (2.5144) lr 7.9389e-03 eta 0:43:15
epoch [10/30] batch [120/392] time 0.297 (0.316) data 0.000 (0.008) loss 0.7402 (2.4689) lr 7.9389e-03 eta 0:42:45
epoch [10/30] batch [140/392] time 0.320 (0.314) data 0.000 (0.007) loss 0.8433 (2.4243) lr 7.9389e-03 eta 0:42:23
epoch [10/30] batch [160/392] time 0.312 (0.314) data 0.000 (0.006) loss 0.8965 (2.4116) lr 7.9389e-03 eta 0:42:15
epoch [10/30] batch [180/392] time 0.298 (0.313) data 0.001 (0.006) loss 4.2695 (2.4283) lr 7.9389e-03 eta 0:41:58
epoch [10/30] batch [200/392] time 0.318 (0.312) data 0.000 (0.005) loss 3.7871 (2.4079) lr 7.9389e-03 eta 0:41:45
epoch [10/30] batch [220/392] time 0.308 (0.311) data 0.000 (0.005) loss 2.6133 (2.4137) lr 7.9389e-03 eta 0:41:33
epoch [10/30] batch [240/392] time 0.303 (0.310) data 0.000 (0.004) loss 2.8262 (2.4383) lr 7.9389e-03 eta 0:41:20
epoch [10/30] batch [260/392] time 0.297 (0.310) data 0.000 (0.004) loss 2.8223 (2.4267) lr 7.9389e-03 eta 0:41:08
epoch [10/30] batch [280/392] time 0.321 (0.310) data 0.000 (0.004) loss 3.0977 (2.4513) lr 7.9389e-03 eta 0:41:01
epoch [10/30] batch [300/392] time 0.344 (0.309) data 0.000 (0.004) loss 2.7715 (2.4299) lr 7.9389e-03 eta 0:40:54
epoch [10/30] batch [320/392] time 0.298 (0.309) data 0.000 (0.003) loss 1.2979 (2.4353) lr 7.9389e-03 eta 0:40:48
epoch [10/30] batch [340/392] time 0.298 (0.309) data 0.000 (0.003) loss 3.0508 (2.4242) lr 7.9389e-03 eta 0:40:41
epoch [10/30] batch [360/392] time 0.412 (0.309) data 0.000 (0.003) loss 4.1523 (2.4622) lr 7.9389e-03 eta 0:40:34
epoch [10/30] batch [380/392] time 0.289 (0.308) data 0.000 (0.003) loss 3.2168 (2.4703) lr 7.9389e-03 eta 0:40:19
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.70s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.26s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.32it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.93it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.59it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.26it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.90it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.49it/s]100%|██████████| 9/9 [00:04<00:00,  2.20it/s]=> result
* total: 812
* correct: 580
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 70.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/392] time 0.316 (0.365) data 0.000 (0.051) loss 3.5410 (2.3107) lr 7.5000e-03 eta 0:47:36
epoch [11/30] batch [40/392] time 0.302 (0.335) data 0.000 (0.025) loss 1.5693 (2.4380) lr 7.5000e-03 eta 0:43:29
epoch [11/30] batch [60/392] time 0.313 (0.327) data 0.000 (0.017) loss 1.6953 (2.4240) lr 7.5000e-03 eta 0:42:25
epoch [11/30] batch [80/392] time 0.303 (0.322) data 0.000 (0.013) loss 1.1230 (2.3854) lr 7.5000e-03 eta 0:41:37
epoch [11/30] batch [100/392] time 0.309 (0.319) data 0.000 (0.010) loss 4.4102 (2.4711) lr 7.5000e-03 eta 0:41:08
epoch [11/30] batch [120/392] time 0.308 (0.318) data 0.000 (0.009) loss 2.2285 (2.4622) lr 7.5000e-03 eta 0:40:53
epoch [11/30] batch [140/392] time 0.287 (0.316) data 0.000 (0.008) loss 2.1816 (2.4760) lr 7.5000e-03 eta 0:40:34
epoch [11/30] batch [160/392] time 0.301 (0.315) data 0.000 (0.007) loss 0.7397 (2.4269) lr 7.5000e-03 eta 0:40:16
epoch [11/30] batch [180/392] time 0.303 (0.313) data 0.000 (0.006) loss 4.7070 (2.4121) lr 7.5000e-03 eta 0:39:59
epoch [11/30] batch [200/392] time 0.295 (0.312) data 0.000 (0.005) loss 1.7852 (2.4902) lr 7.5000e-03 eta 0:39:45
epoch [11/30] batch [220/392] time 0.299 (0.311) data 0.000 (0.005) loss 2.3926 (2.4829) lr 7.5000e-03 eta 0:39:33
epoch [11/30] batch [240/392] time 0.310 (0.311) data 0.000 (0.005) loss 2.4668 (2.5234) lr 7.5000e-03 eta 0:39:22
epoch [11/30] batch [260/392] time 0.292 (0.310) data 0.000 (0.004) loss 5.3906 (2.5444) lr 7.5000e-03 eta 0:39:09
epoch [11/30] batch [280/392] time 0.303 (0.310) data 0.000 (0.004) loss 3.4004 (2.5333) lr 7.5000e-03 eta 0:39:00
epoch [11/30] batch [300/392] time 0.293 (0.310) data 0.000 (0.004) loss 2.6543 (2.5360) lr 7.5000e-03 eta 0:38:56
epoch [11/30] batch [320/392] time 0.288 (0.309) data 0.000 (0.004) loss 2.6699 (2.5324) lr 7.5000e-03 eta 0:38:44
epoch [11/30] batch [340/392] time 0.344 (0.309) data 0.000 (0.003) loss 3.1875 (2.5301) lr 7.5000e-03 eta 0:38:37
epoch [11/30] batch [360/392] time 0.295 (0.309) data 0.000 (0.003) loss 2.5234 (2.5109) lr 7.5000e-03 eta 0:38:28
epoch [11/30] batch [380/392] time 0.289 (0.308) data 0.000 (0.003) loss 2.7832 (2.5267) lr 7.5000e-03 eta 0:38:16
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.79s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.25s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.33it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.94it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.60it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.27it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.91it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.47it/s]100%|██████████| 9/9 [00:04<00:00,  2.20it/s]=> result
* total: 812
* correct: 583
* accuracy: 71.8%
* error: 28.2%
* macro_f1: 70.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/392] time 0.362 (0.374) data 0.000 (0.051) loss 1.1406 (1.8612) lr 7.0337e-03 eta 0:46:15
epoch [12/30] batch [40/392] time 0.310 (0.339) data 0.000 (0.025) loss 1.9590 (2.1486) lr 7.0337e-03 eta 0:41:49
epoch [12/30] batch [60/392] time 0.296 (0.329) data 0.000 (0.017) loss 2.1523 (2.2488) lr 7.0337e-03 eta 0:40:27
epoch [12/30] batch [80/392] time 0.330 (0.324) data 0.000 (0.013) loss 1.7334 (2.2780) lr 7.0337e-03 eta 0:39:47
epoch [12/30] batch [100/392] time 0.298 (0.320) data 0.000 (0.010) loss 0.7588 (2.2556) lr 7.0337e-03 eta 0:39:12
epoch [12/30] batch [120/392] time 0.293 (0.318) data 0.000 (0.009) loss 1.6445 (2.2110) lr 7.0337e-03 eta 0:38:50
epoch [12/30] batch [140/392] time 0.297 (0.317) data 0.000 (0.008) loss 2.0488 (2.2834) lr 7.0337e-03 eta 0:38:34
epoch [12/30] batch [160/392] time 0.296 (0.315) data 0.000 (0.007) loss 4.6445 (2.3537) lr 7.0337e-03 eta 0:38:14
epoch [12/30] batch [180/392] time 0.293 (0.313) data 0.000 (0.006) loss 3.7793 (2.4059) lr 7.0337e-03 eta 0:37:55
epoch [12/30] batch [200/392] time 0.293 (0.312) data 0.000 (0.005) loss 4.0508 (2.4198) lr 7.0337e-03 eta 0:37:40
epoch [12/30] batch [220/392] time 0.293 (0.311) data 0.000 (0.005) loss 2.0586 (2.4097) lr 7.0337e-03 eta 0:37:29
epoch [12/30] batch [240/392] time 0.291 (0.311) data 0.000 (0.005) loss 4.4141 (2.4556) lr 7.0337e-03 eta 0:37:21
epoch [12/30] batch [260/392] time 0.307 (0.310) data 0.000 (0.004) loss 1.1250 (2.4462) lr 7.0337e-03 eta 0:37:10
epoch [12/30] batch [280/392] time 0.298 (0.310) data 0.000 (0.004) loss 3.1680 (2.4269) lr 7.0337e-03 eta 0:36:59
epoch [12/30] batch [300/392] time 0.406 (0.309) data 0.000 (0.004) loss 1.9307 (2.4248) lr 7.0337e-03 eta 0:36:51
epoch [12/30] batch [320/392] time 0.350 (0.309) data 0.000 (0.003) loss 1.8994 (2.4432) lr 7.0337e-03 eta 0:36:42
epoch [12/30] batch [340/392] time 0.304 (0.309) data 0.000 (0.003) loss 3.9844 (2.4594) lr 7.0337e-03 eta 0:36:33
epoch [12/30] batch [360/392] time 0.296 (0.309) data 0.000 (0.003) loss 2.0195 (2.4558) lr 7.0337e-03 eta 0:36:27
epoch [12/30] batch [380/392] time 0.285 (0.307) data 0.000 (0.003) loss 2.0859 (2.4425) lr 7.0337e-03 eta 0:36:11
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.82s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.25s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.33it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.95it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.61it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.28it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.91it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.48it/s]100%|██████████| 9/9 [00:04<00:00,  2.19it/s]=> result
* total: 812
* correct: 583
* accuracy: 71.8%
* error: 28.2%
* macro_f1: 70.5%

epoch [13/30] batch [20/392] time 0.316 (0.364) data 0.000 (0.051) loss 3.0352 (3.1483) lr 6.5451e-03 eta 0:42:39
epoch [13/30] batch [40/392] time 0.300 (0.338) data 0.000 (0.026) loss 4.3984 (2.9694) lr 6.5451e-03 eta 0:39:32
epoch [13/30] batch [60/392] time 0.315 (0.326) data 0.000 (0.017) loss 5.2383 (2.7358) lr 6.5451e-03 eta 0:37:59
epoch [13/30] batch [80/392] time 0.300 (0.320) data 0.000 (0.013) loss 1.0742 (2.6528) lr 6.5451e-03 eta 0:37:12
epoch [13/30] batch [100/392] time 0.327 (0.318) data 0.000 (0.010) loss 1.7432 (2.6229) lr 6.5451e-03 eta 0:36:53
epoch [13/30] batch [120/392] time 0.311 (0.317) data 0.000 (0.009) loss 3.4688 (2.6249) lr 6.5451e-03 eta 0:36:36
epoch [13/30] batch [140/392] time 0.288 (0.315) data 0.000 (0.008) loss 2.5195 (2.6082) lr 6.5451e-03 eta 0:36:17
epoch [13/30] batch [160/392] time 0.304 (0.314) data 0.000 (0.007) loss 2.7520 (2.6178) lr 6.5451e-03 eta 0:36:06
epoch [13/30] batch [180/392] time 0.299 (0.314) data 0.000 (0.006) loss 4.2969 (2.5956) lr 6.5451e-03 eta 0:35:57
epoch [13/30] batch [200/392] time 0.308 (0.313) data 0.000 (0.005) loss 1.6670 (2.5295) lr 6.5451e-03 eta 0:35:46
epoch [13/30] batch [220/392] time 0.288 (0.312) data 0.000 (0.005) loss 3.8125 (2.5239) lr 6.5451e-03 eta 0:35:32
epoch [13/30] batch [240/392] time 0.301 (0.312) data 0.000 (0.005) loss 3.2383 (2.5118) lr 6.5451e-03 eta 0:35:23
epoch [13/30] batch [260/392] time 0.308 (0.311) data 0.000 (0.004) loss 2.9883 (2.5476) lr 6.5451e-03 eta 0:35:15
epoch [13/30] batch [280/392] time 0.289 (0.311) data 0.000 (0.004) loss 0.1746 (2.5171) lr 6.5451e-03 eta 0:35:08
epoch [13/30] batch [300/392] time 0.301 (0.311) data 0.000 (0.004) loss 4.5977 (2.5447) lr 6.5451e-03 eta 0:35:01
epoch [13/30] batch [320/392] time 0.302 (0.310) data 0.000 (0.004) loss 1.3555 (2.5287) lr 6.5451e-03 eta 0:34:50
epoch [13/30] batch [340/392] time 0.298 (0.310) data 0.000 (0.003) loss 2.1934 (2.5418) lr 6.5451e-03 eta 0:34:41
epoch [13/30] batch [360/392] time 0.304 (0.310) data 0.000 (0.003) loss 1.3975 (2.5231) lr 6.5451e-03 eta 0:34:34
epoch [13/30] batch [380/392] time 0.285 (0.309) data 0.000 (0.003) loss 1.0059 (2.5314) lr 6.5451e-03 eta 0:34:19
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:23,  2.92s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.29s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.30it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.90it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.55it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.22it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.86it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.45it/s]100%|██████████| 9/9 [00:04<00:00,  2.15it/s]=> result
* total: 812
* correct: 582
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 70.5%

epoch [14/30] batch [20/392] time 0.297 (0.355) data 0.000 (0.048) loss 2.4785 (2.5931) lr 6.0396e-03 eta 0:39:21
epoch [14/30] batch [40/392] time 0.304 (0.330) data 0.000 (0.024) loss 2.4688 (2.4052) lr 6.0396e-03 eta 0:36:28
epoch [14/30] batch [60/392] time 0.295 (0.323) data 0.000 (0.016) loss 0.9521 (2.3903) lr 6.0396e-03 eta 0:35:30
epoch [14/30] batch [80/392] time 0.300 (0.318) data 0.000 (0.012) loss 2.7402 (2.4545) lr 6.0396e-03 eta 0:34:54
epoch [14/30] batch [100/392] time 0.289 (0.314) data 0.000 (0.010) loss 0.5190 (2.4375) lr 6.0396e-03 eta 0:34:23
epoch [14/30] batch [120/392] time 0.293 (0.312) data 0.000 (0.008) loss 1.7627 (2.4616) lr 6.0396e-03 eta 0:34:04
epoch [14/30] batch [140/392] time 0.310 (0.311) data 0.000 (0.007) loss 1.6533 (2.4448) lr 6.0396e-03 eta 0:33:47
epoch [14/30] batch [160/392] time 0.305 (0.309) data 0.000 (0.006) loss 1.0430 (2.4497) lr 6.0396e-03 eta 0:33:32
epoch [14/30] batch [180/392] time 0.294 (0.310) data 0.000 (0.006) loss 2.3164 (2.4272) lr 6.0396e-03 eta 0:33:26
epoch [14/30] batch [200/392] time 0.292 (0.309) data 0.000 (0.005) loss 3.8359 (2.4449) lr 6.0396e-03 eta 0:33:14
epoch [14/30] batch [220/392] time 0.330 (0.308) data 0.000 (0.005) loss 2.0742 (2.4443) lr 6.0396e-03 eta 0:33:05
epoch [14/30] batch [240/392] time 0.306 (0.308) data 0.000 (0.004) loss 2.0469 (2.4657) lr 6.0396e-03 eta 0:32:57
epoch [14/30] batch [260/392] time 0.327 (0.308) data 0.000 (0.004) loss 1.6260 (2.4631) lr 6.0396e-03 eta 0:32:52
epoch [14/30] batch [280/392] time 0.292 (0.308) data 0.000 (0.004) loss 1.1777 (2.4383) lr 6.0396e-03 eta 0:32:46
epoch [14/30] batch [300/392] time 0.296 (0.308) data 0.000 (0.003) loss 2.8496 (2.4416) lr 6.0396e-03 eta 0:32:37
epoch [14/30] batch [320/392] time 0.291 (0.307) data 0.000 (0.003) loss 2.7812 (2.4372) lr 6.0396e-03 eta 0:32:28
epoch [14/30] batch [340/392] time 0.310 (0.307) data 0.000 (0.003) loss 3.5156 (2.4481) lr 6.0396e-03 eta 0:32:19
epoch [14/30] batch [360/392] time 0.295 (0.306) data 0.000 (0.003) loss 2.9863 (2.4668) lr 6.0396e-03 eta 0:32:11
epoch [14/30] batch [380/392] time 0.282 (0.305) data 0.000 (0.003) loss 2.2305 (2.4742) lr 6.0396e-03 eta 0:31:59
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.64s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.23s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.34it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.96it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.62it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.29it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.93it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.50it/s]100%|██████████| 9/9 [00:04<00:00,  2.23it/s]=> result
* total: 812
* correct: 588
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 71.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/392] time 0.338 (0.360) data 0.000 (0.051) loss 1.8926 (2.0817) lr 5.5226e-03 eta 0:37:29
epoch [15/30] batch [40/392] time 0.303 (0.332) data 0.000 (0.026) loss 1.6836 (2.3019) lr 5.5226e-03 eta 0:34:27
epoch [15/30] batch [60/392] time 0.307 (0.322) data 0.000 (0.017) loss 2.5645 (2.3860) lr 5.5226e-03 eta 0:33:18
epoch [15/30] batch [80/392] time 0.296 (0.318) data 0.000 (0.013) loss 1.8701 (2.3409) lr 5.5226e-03 eta 0:32:46
epoch [15/30] batch [100/392] time 0.305 (0.316) data 0.000 (0.010) loss 2.5469 (2.3679) lr 5.5226e-03 eta 0:32:31
epoch [15/30] batch [120/392] time 0.309 (0.315) data 0.000 (0.009) loss 1.8848 (2.3012) lr 5.5226e-03 eta 0:32:18
epoch [15/30] batch [140/392] time 0.303 (0.313) data 0.000 (0.008) loss 3.2891 (2.3640) lr 5.5226e-03 eta 0:32:02
epoch [15/30] batch [160/392] time 0.291 (0.312) data 0.000 (0.007) loss 2.0293 (2.3668) lr 5.5226e-03 eta 0:31:48
epoch [15/30] batch [180/392] time 0.304 (0.311) data 0.000 (0.006) loss 5.0625 (2.3647) lr 5.5226e-03 eta 0:31:36
epoch [15/30] batch [200/392] time 0.321 (0.311) data 0.000 (0.005) loss 1.4268 (2.4156) lr 5.5226e-03 eta 0:31:27
epoch [15/30] batch [220/392] time 0.299 (0.311) data 0.000 (0.005) loss 1.7090 (2.4050) lr 5.5226e-03 eta 0:31:19
epoch [15/30] batch [240/392] time 0.303 (0.310) data 0.000 (0.005) loss 2.0488 (2.3910) lr 5.5226e-03 eta 0:31:12
epoch [15/30] batch [260/392] time 0.309 (0.310) data 0.000 (0.004) loss 2.4062 (2.3722) lr 5.5226e-03 eta 0:31:01
epoch [15/30] batch [280/392] time 0.296 (0.309) data 0.000 (0.004) loss 1.8438 (2.4267) lr 5.5226e-03 eta 0:30:51
epoch [15/30] batch [300/392] time 0.304 (0.309) data 0.000 (0.004) loss 2.2773 (2.4174) lr 5.5226e-03 eta 0:30:45
epoch [15/30] batch [320/392] time 0.299 (0.309) data 0.000 (0.004) loss 2.9648 (2.4449) lr 5.5226e-03 eta 0:30:37
epoch [15/30] batch [340/392] time 0.292 (0.308) data 0.000 (0.003) loss 1.3428 (2.4301) lr 5.5226e-03 eta 0:30:28
epoch [15/30] batch [360/392] time 0.293 (0.308) data 0.000 (0.003) loss 2.0918 (2.4404) lr 5.5226e-03 eta 0:30:21
epoch [15/30] batch [380/392] time 0.286 (0.307) data 0.000 (0.003) loss 1.5078 (2.4348) lr 5.5226e-03 eta 0:30:10
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.75s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.28s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.30it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.90it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.56it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.23it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.88it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.46it/s]100%|██████████| 9/9 [00:04<00:00,  2.18it/s]=> result
* total: 812
* correct: 579
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 69.8%

epoch [16/30] batch [20/392] time 0.299 (0.357) data 0.000 (0.049) loss 2.0020 (1.7914) lr 5.0000e-03 eta 0:34:50
epoch [16/30] batch [40/392] time 0.290 (0.332) data 0.000 (0.025) loss 3.0195 (2.2126) lr 5.0000e-03 eta 0:32:16
epoch [16/30] batch [60/392] time 0.287 (0.323) data 0.000 (0.017) loss 1.9277 (2.2775) lr 5.0000e-03 eta 0:31:19
epoch [16/30] batch [80/392] time 0.298 (0.318) data 0.000 (0.012) loss 3.3262 (2.2672) lr 5.0000e-03 eta 0:30:42
epoch [16/30] batch [100/392] time 0.298 (0.314) data 0.000 (0.010) loss 1.8936 (2.2029) lr 5.0000e-03 eta 0:30:15
epoch [16/30] batch [120/392] time 0.301 (0.312) data 0.000 (0.008) loss 2.2734 (2.1897) lr 5.0000e-03 eta 0:29:57
epoch [16/30] batch [140/392] time 0.333 (0.312) data 0.000 (0.007) loss 1.6211 (2.1838) lr 5.0000e-03 eta 0:29:49
epoch [16/30] batch [160/392] time 0.318 (0.311) data 0.000 (0.006) loss 3.5742 (2.2338) lr 5.0000e-03 eta 0:29:38
epoch [16/30] batch [180/392] time 0.307 (0.310) data 0.000 (0.006) loss 3.4023 (2.2161) lr 5.0000e-03 eta 0:29:27
epoch [16/30] batch [200/392] time 0.300 (0.310) data 0.000 (0.005) loss 2.2266 (2.2511) lr 5.0000e-03 eta 0:29:19
epoch [16/30] batch [220/392] time 0.296 (0.310) data 0.000 (0.005) loss 1.4238 (2.2338) lr 5.0000e-03 eta 0:29:11
epoch [16/30] batch [240/392] time 0.296 (0.309) data 0.000 (0.004) loss 0.2656 (2.2427) lr 5.0000e-03 eta 0:29:02
epoch [16/30] batch [260/392] time 0.299 (0.309) data 0.000 (0.004) loss 1.7988 (2.2393) lr 5.0000e-03 eta 0:28:56
epoch [16/30] batch [280/392] time 0.319 (0.308) data 0.000 (0.004) loss 2.9570 (2.2710) lr 5.0000e-03 eta 0:28:47
epoch [16/30] batch [300/392] time 0.318 (0.308) data 0.000 (0.004) loss 0.9189 (2.2525) lr 5.0000e-03 eta 0:28:40
epoch [16/30] batch [320/392] time 0.327 (0.308) data 0.000 (0.003) loss 3.9551 (2.2808) lr 5.0000e-03 eta 0:28:32
epoch [16/30] batch [340/392] time 0.337 (0.308) data 0.000 (0.003) loss 1.4785 (2.3063) lr 5.0000e-03 eta 0:28:24
epoch [16/30] batch [360/392] time 0.309 (0.308) data 0.000 (0.003) loss 1.0957 (2.3312) lr 5.0000e-03 eta 0:28:17
epoch [16/30] batch [380/392] time 0.284 (0.306) data 0.000 (0.003) loss 2.5293 (2.3378) lr 5.0000e-03 eta 0:28:05
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.61s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.22s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.34it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.96it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.62it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.29it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.92it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.49it/s]100%|██████████| 9/9 [00:04<00:00,  2.24it/s]=> result
* total: 812
* correct: 592
* accuracy: 72.9%
* error: 27.1%
* macro_f1: 71.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [17/30] batch [20/392] time 0.307 (0.369) data 0.000 (0.052) loss 2.4316 (2.6954) lr 4.4774e-03 eta 0:33:38
epoch [17/30] batch [40/392] time 0.308 (0.336) data 0.000 (0.026) loss 2.3965 (2.6474) lr 4.4774e-03 eta 0:30:31
epoch [17/30] batch [60/392] time 0.291 (0.324) data 0.000 (0.018) loss 1.6260 (2.5222) lr 4.4774e-03 eta 0:29:19
epoch [17/30] batch [80/392] time 0.338 (0.320) data 0.000 (0.013) loss 0.7212 (2.4343) lr 4.4774e-03 eta 0:28:48
epoch [17/30] batch [100/392] time 0.290 (0.316) data 0.001 (0.011) loss 0.8159 (2.3336) lr 4.4774e-03 eta 0:28:24
epoch [17/30] batch [120/392] time 0.290 (0.313) data 0.000 (0.009) loss 0.7378 (2.3957) lr 4.4774e-03 eta 0:28:02
epoch [17/30] batch [140/392] time 0.339 (0.312) data 0.000 (0.008) loss 1.4834 (2.3186) lr 4.4774e-03 eta 0:27:46
epoch [17/30] batch [160/392] time 0.312 (0.312) data 0.000 (0.007) loss 2.0840 (2.3279) lr 4.4774e-03 eta 0:27:41
epoch [17/30] batch [180/392] time 0.293 (0.311) data 0.000 (0.006) loss 1.9697 (2.3710) lr 4.4774e-03 eta 0:27:29
epoch [17/30] batch [200/392] time 0.303 (0.310) data 0.000 (0.005) loss 1.8506 (2.4084) lr 4.4774e-03 eta 0:27:18
epoch [17/30] batch [220/392] time 0.297 (0.309) data 0.000 (0.005) loss 1.5322 (2.4121) lr 4.4774e-03 eta 0:27:06
epoch [17/30] batch [240/392] time 0.310 (0.309) data 0.000 (0.005) loss 3.9863 (2.4083) lr 4.4774e-03 eta 0:26:59
epoch [17/30] batch [260/392] time 0.292 (0.308) data 0.000 (0.004) loss 1.3076 (2.3988) lr 4.4774e-03 eta 0:26:51
epoch [17/30] batch [280/392] time 0.304 (0.308) data 0.000 (0.004) loss 2.7891 (2.4156) lr 4.4774e-03 eta 0:26:45
epoch [17/30] batch [300/392] time 0.304 (0.308) data 0.000 (0.004) loss 1.0615 (2.4147) lr 4.4774e-03 eta 0:26:37
epoch [17/30] batch [320/392] time 0.305 (0.308) data 0.000 (0.004) loss 7.2383 (2.4197) lr 4.4774e-03 eta 0:26:30
epoch [17/30] batch [340/392] time 0.355 (0.308) data 0.000 (0.003) loss 5.0352 (2.4393) lr 4.4774e-03 eta 0:26:24
epoch [17/30] batch [360/392] time 0.294 (0.307) data 0.000 (0.003) loss 2.0156 (2.4074) lr 4.4774e-03 eta 0:26:16
epoch [17/30] batch [380/392] time 0.287 (0.306) data 0.000 (0.003) loss 3.2891 (2.4195) lr 4.4774e-03 eta 0:26:03
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.77s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.23s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.35it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.97it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.64it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.31it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.94it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.52it/s]100%|██████████| 9/9 [00:04<00:00,  2.22it/s]=> result
* total: 812
* correct: 593
* accuracy: 73.0%
* error: 27.0%
* macro_f1: 71.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/392] time 0.301 (0.362) data 0.000 (0.052) loss 2.6445 (2.8040) lr 3.9604e-03 eta 0:30:38
epoch [18/30] batch [40/392] time 0.305 (0.333) data 0.000 (0.026) loss 1.6855 (2.3707) lr 3.9604e-03 eta 0:28:03
epoch [18/30] batch [60/392] time 0.340 (0.324) data 0.000 (0.018) loss 3.6621 (2.4914) lr 3.9604e-03 eta 0:27:10
epoch [18/30] batch [80/392] time 0.308 (0.318) data 0.000 (0.013) loss 5.3828 (2.5145) lr 3.9604e-03 eta 0:26:35
epoch [18/30] batch [100/392] time 0.298 (0.316) data 0.000 (0.011) loss 4.5703 (2.6027) lr 3.9604e-03 eta 0:26:20
epoch [18/30] batch [120/392] time 0.305 (0.315) data 0.000 (0.009) loss 2.3594 (2.5012) lr 3.9604e-03 eta 0:26:06
epoch [18/30] batch [140/392] time 0.292 (0.313) data 0.000 (0.008) loss 1.6162 (2.4768) lr 3.9604e-03 eta 0:25:53
epoch [18/30] batch [160/392] time 0.288 (0.312) data 0.000 (0.007) loss 4.7500 (2.4431) lr 3.9604e-03 eta 0:25:40
epoch [18/30] batch [180/392] time 0.298 (0.311) data 0.000 (0.006) loss 0.8198 (2.4428) lr 3.9604e-03 eta 0:25:27
epoch [18/30] batch [200/392] time 0.307 (0.311) data 0.000 (0.005) loss 3.9082 (2.4626) lr 3.9604e-03 eta 0:25:20
epoch [18/30] batch [220/392] time 0.300 (0.310) data 0.000 (0.005) loss 0.7471 (2.4895) lr 3.9604e-03 eta 0:25:11
epoch [18/30] batch [240/392] time 0.308 (0.309) data 0.000 (0.005) loss 1.4570 (2.4792) lr 3.9604e-03 eta 0:25:01
epoch [18/30] batch [260/392] time 0.323 (0.309) data 0.000 (0.004) loss 1.6738 (2.4498) lr 3.9604e-03 eta 0:24:55
epoch [18/30] batch [280/392] time 0.305 (0.309) data 0.000 (0.004) loss 0.6299 (2.4648) lr 3.9604e-03 eta 0:24:45
epoch [18/30] batch [300/392] time 0.291 (0.308) data 0.000 (0.004) loss 1.7217 (2.4476) lr 3.9604e-03 eta 0:24:38
epoch [18/30] batch [320/392] time 0.300 (0.308) data 0.000 (0.004) loss 3.4785 (2.4558) lr 3.9604e-03 eta 0:24:30
epoch [18/30] batch [340/392] time 0.286 (0.308) data 0.000 (0.003) loss 1.7500 (2.4914) lr 3.9604e-03 eta 0:24:23
epoch [18/30] batch [360/392] time 0.288 (0.308) data 0.000 (0.003) loss 1.2061 (2.5080) lr 3.9604e-03 eta 0:24:17
epoch [18/30] batch [380/392] time 0.286 (0.307) data 0.000 (0.003) loss 5.3203 (2.5133) lr 3.9604e-03 eta 0:24:05
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.62s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.18s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.39it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.02it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.69it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.37it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.01it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.58it/s]100%|██████████| 9/9 [00:03<00:00,  2.29it/s]=> result
* total: 812
* correct: 594
* accuracy: 73.2%
* error: 26.8%
* macro_f1: 71.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/392] time 0.293 (0.360) data 0.000 (0.049) loss 2.4883 (2.2244) lr 3.4549e-03 eta 0:28:08
epoch [19/30] batch [40/392] time 0.298 (0.334) data 0.000 (0.025) loss 1.5576 (2.3990) lr 3.4549e-03 eta 0:25:59
epoch [19/30] batch [60/392] time 0.466 (0.324) data 0.000 (0.017) loss 1.5537 (2.5329) lr 3.4549e-03 eta 0:25:05
epoch [19/30] batch [80/392] time 0.298 (0.318) data 0.000 (0.013) loss 2.1895 (2.5498) lr 3.4549e-03 eta 0:24:30
epoch [19/30] batch [100/392] time 0.298 (0.315) data 0.000 (0.010) loss 0.6348 (2.4261) lr 3.4549e-03 eta 0:24:11
epoch [19/30] batch [120/392] time 0.345 (0.314) data 0.000 (0.008) loss 1.4727 (2.3371) lr 3.4549e-03 eta 0:24:00
epoch [19/30] batch [140/392] time 0.324 (0.313) data 0.000 (0.007) loss 2.6602 (2.3933) lr 3.4549e-03 eta 0:23:49
epoch [19/30] batch [160/392] time 0.290 (0.311) data 0.000 (0.006) loss 0.9971 (2.3731) lr 3.4549e-03 eta 0:23:34
epoch [19/30] batch [180/392] time 0.284 (0.310) data 0.000 (0.006) loss 1.5664 (2.3587) lr 3.4549e-03 eta 0:23:22
epoch [19/30] batch [200/392] time 0.300 (0.309) data 0.000 (0.005) loss 1.3359 (2.3725) lr 3.4549e-03 eta 0:23:12
epoch [19/30] batch [220/392] time 0.298 (0.309) data 0.000 (0.005) loss 2.9531 (2.3661) lr 3.4549e-03 eta 0:23:03
epoch [19/30] batch [240/392] time 0.298 (0.308) data 0.000 (0.004) loss 1.8545 (2.3437) lr 3.4549e-03 eta 0:22:55
epoch [19/30] batch [260/392] time 0.295 (0.308) data 0.000 (0.004) loss 3.0801 (2.3668) lr 3.4549e-03 eta 0:22:47
epoch [19/30] batch [280/392] time 0.304 (0.307) data 0.000 (0.004) loss 1.5977 (2.3634) lr 3.4549e-03 eta 0:22:38
epoch [19/30] batch [300/392] time 0.293 (0.307) data 0.000 (0.004) loss 3.1270 (2.3561) lr 3.4549e-03 eta 0:22:30
epoch [19/30] batch [320/392] time 0.289 (0.306) data 0.000 (0.003) loss 0.8325 (2.3217) lr 3.4549e-03 eta 0:22:23
epoch [19/30] batch [340/392] time 0.301 (0.306) data 0.000 (0.003) loss 3.3848 (2.3302) lr 3.4549e-03 eta 0:22:17
epoch [19/30] batch [360/392] time 0.323 (0.306) data 0.000 (0.003) loss 1.2754 (2.3374) lr 3.4549e-03 eta 0:22:09
epoch [19/30] batch [380/392] time 0.289 (0.305) data 0.000 (0.003) loss 1.9238 (2.3425) lr 3.4549e-03 eta 0:21:58
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.81s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.30s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.28it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.87it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.52it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.19it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.84it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.42it/s]100%|██████████| 9/9 [00:04<00:00,  2.15it/s]=> result
* total: 812
* correct: 604
* accuracy: 74.4%
* error: 25.6%
* macro_f1: 73.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [20/30] batch [20/392] time 0.294 (0.361) data 0.000 (0.050) loss 6.8867 (2.4846) lr 2.9663e-03 eta 0:25:50
epoch [20/30] batch [40/392] time 0.304 (0.331) data 0.000 (0.025) loss 2.2695 (2.3615) lr 2.9663e-03 eta 0:23:35
epoch [20/30] batch [60/392] time 0.292 (0.326) data 0.000 (0.017) loss 2.6152 (2.3389) lr 2.9663e-03 eta 0:23:05
epoch [20/30] batch [80/392] time 0.308 (0.320) data 0.000 (0.013) loss 1.8018 (2.3566) lr 2.9663e-03 eta 0:22:32
epoch [20/30] batch [100/392] time 0.297 (0.316) data 0.000 (0.010) loss 2.7949 (2.3581) lr 2.9663e-03 eta 0:22:10
epoch [20/30] batch [120/392] time 0.293 (0.314) data 0.000 (0.009) loss 2.6270 (2.3399) lr 2.9663e-03 eta 0:21:54
epoch [20/30] batch [140/392] time 0.305 (0.312) data 0.000 (0.007) loss 1.5312 (2.3648) lr 2.9663e-03 eta 0:21:42
epoch [20/30] batch [160/392] time 0.304 (0.312) data 0.000 (0.007) loss 1.3643 (2.3246) lr 2.9663e-03 eta 0:21:34
epoch [20/30] batch [180/392] time 0.293 (0.311) data 0.000 (0.006) loss 1.4922 (2.3068) lr 2.9663e-03 eta 0:21:26
epoch [20/30] batch [200/392] time 0.293 (0.310) data 0.000 (0.005) loss 4.3164 (2.3178) lr 2.9663e-03 eta 0:21:15
epoch [20/30] batch [220/392] time 0.289 (0.310) data 0.000 (0.005) loss 5.4258 (2.3496) lr 2.9663e-03 eta 0:21:10
epoch [20/30] batch [240/392] time 0.318 (0.310) data 0.000 (0.004) loss 0.9697 (2.3623) lr 2.9663e-03 eta 0:21:00
epoch [20/30] batch [260/392] time 0.295 (0.309) data 0.000 (0.004) loss 1.8457 (2.3569) lr 2.9663e-03 eta 0:20:52
epoch [20/30] batch [280/392] time 0.294 (0.309) data 0.000 (0.004) loss 1.0928 (2.3732) lr 2.9663e-03 eta 0:20:46
epoch [20/30] batch [300/392] time 0.296 (0.309) data 0.000 (0.004) loss 2.3184 (2.3830) lr 2.9663e-03 eta 0:20:38
epoch [20/30] batch [320/392] time 0.291 (0.308) data 0.000 (0.003) loss 4.2227 (2.3780) lr 2.9663e-03 eta 0:20:29
epoch [20/30] batch [340/392] time 0.304 (0.308) data 0.000 (0.003) loss 2.5859 (2.4059) lr 2.9663e-03 eta 0:20:22
epoch [20/30] batch [360/392] time 0.324 (0.308) data 0.000 (0.003) loss 2.6133 (2.4071) lr 2.9663e-03 eta 0:20:17
epoch [20/30] batch [380/392] time 0.282 (0.307) data 0.000 (0.003) loss 1.4600 (2.3991) lr 2.9663e-03 eta 0:20:05
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.75s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.22s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.36it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.98it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.65it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.32it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.97it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.54it/s]100%|██████████| 9/9 [00:04<00:00,  2.24it/s]=> result
* total: 812
* correct: 598
* accuracy: 73.6%
* error: 26.4%
* macro_f1: 72.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/392] time 0.312 (0.358) data 0.000 (0.048) loss 2.4785 (2.3482) lr 2.5000e-03 eta 0:23:17
epoch [21/30] batch [40/392] time 0.291 (0.330) data 0.000 (0.024) loss 3.1211 (2.4116) lr 2.5000e-03 eta 0:21:22
epoch [21/30] batch [60/392] time 0.294 (0.323) data 0.000 (0.016) loss 1.7109 (2.3425) lr 2.5000e-03 eta 0:20:45
epoch [21/30] batch [80/392] time 0.314 (0.320) data 0.000 (0.012) loss 3.1816 (2.2846) lr 2.5000e-03 eta 0:20:29
epoch [21/30] batch [100/392] time 0.292 (0.317) data 0.000 (0.010) loss 1.8145 (2.2788) lr 2.5000e-03 eta 0:20:09
epoch [21/30] batch [120/392] time 0.328 (0.315) data 0.000 (0.008) loss 2.4648 (2.3155) lr 2.5000e-03 eta 0:19:55
epoch [21/30] batch [140/392] time 0.307 (0.313) data 0.000 (0.007) loss 0.9453 (2.2845) lr 2.5000e-03 eta 0:19:41
epoch [21/30] batch [160/392] time 0.288 (0.311) data 0.000 (0.006) loss 4.2617 (2.3028) lr 2.5000e-03 eta 0:19:29
epoch [21/30] batch [180/392] time 0.302 (0.310) data 0.000 (0.006) loss 1.8379 (2.2577) lr 2.5000e-03 eta 0:19:20
epoch [21/30] batch [200/392] time 0.307 (0.310) data 0.000 (0.005) loss 2.3379 (2.2141) lr 2.5000e-03 eta 0:19:11
epoch [21/30] batch [220/392] time 0.318 (0.309) data 0.000 (0.005) loss 0.5303 (2.2399) lr 2.5000e-03 eta 0:19:02
epoch [21/30] batch [240/392] time 0.298 (0.308) data 0.000 (0.004) loss 3.3047 (2.2789) lr 2.5000e-03 eta 0:18:52
epoch [21/30] batch [260/392] time 0.294 (0.308) data 0.000 (0.004) loss 1.3398 (2.2586) lr 2.5000e-03 eta 0:18:45
epoch [21/30] batch [280/392] time 0.302 (0.307) data 0.000 (0.004) loss 5.1562 (2.3206) lr 2.5000e-03 eta 0:18:38
epoch [21/30] batch [300/392] time 0.402 (0.307) data 0.000 (0.003) loss 1.0361 (2.3400) lr 2.5000e-03 eta 0:18:30
epoch [21/30] batch [320/392] time 0.290 (0.306) data 0.000 (0.003) loss 3.6680 (2.3528) lr 2.5000e-03 eta 0:18:22
epoch [21/30] batch [340/392] time 0.295 (0.306) data 0.000 (0.003) loss 2.3184 (2.3335) lr 2.5000e-03 eta 0:18:16
epoch [21/30] batch [360/392] time 0.290 (0.306) data 0.000 (0.003) loss 1.4316 (2.3360) lr 2.5000e-03 eta 0:18:09
epoch [21/30] batch [380/392] time 0.279 (0.305) data 0.000 (0.003) loss 1.2070 (2.3378) lr 2.5000e-03 eta 0:17:59
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.68s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.25s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.32it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.93it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.58it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.26it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.88it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.44it/s]100%|██████████| 9/9 [00:04<00:00,  2.20it/s]=> result
* total: 812
* correct: 601
* accuracy: 74.0%
* error: 26.0%
* macro_f1: 72.7%

epoch [22/30] batch [20/392] time 0.296 (0.370) data 0.000 (0.050) loss 3.2109 (2.3912) lr 2.0611e-03 eta 0:21:36
epoch [22/30] batch [40/392] time 0.297 (0.335) data 0.000 (0.025) loss 1.4619 (2.2993) lr 2.0611e-03 eta 0:19:27
epoch [22/30] batch [60/392] time 0.299 (0.323) data 0.001 (0.017) loss 2.8301 (2.3279) lr 2.0611e-03 eta 0:18:40
epoch [22/30] batch [80/392] time 0.329 (0.317) data 0.000 (0.013) loss 5.0742 (2.3511) lr 2.0611e-03 eta 0:18:14
epoch [22/30] batch [100/392] time 0.309 (0.315) data 0.000 (0.010) loss 2.4883 (2.3341) lr 2.0611e-03 eta 0:17:58
epoch [22/30] batch [120/392] time 0.290 (0.311) data 0.000 (0.009) loss 1.4102 (2.3048) lr 2.0611e-03 eta 0:17:40
epoch [22/30] batch [140/392] time 0.317 (0.311) data 0.000 (0.007) loss 7.9766 (2.3193) lr 2.0611e-03 eta 0:17:33
epoch [22/30] batch [160/392] time 0.306 (0.310) data 0.000 (0.007) loss 1.9492 (2.3165) lr 2.0611e-03 eta 0:17:25
epoch [22/30] batch [180/392] time 0.289 (0.310) data 0.000 (0.006) loss 2.3164 (2.2814) lr 2.0611e-03 eta 0:17:16
epoch [22/30] batch [200/392] time 0.284 (0.309) data 0.000 (0.005) loss 0.8379 (2.2798) lr 2.0611e-03 eta 0:17:08
epoch [22/30] batch [220/392] time 0.297 (0.309) data 0.000 (0.005) loss 3.6152 (2.2952) lr 2.0611e-03 eta 0:17:01
epoch [22/30] batch [240/392] time 0.293 (0.308) data 0.000 (0.004) loss 1.8965 (2.2680) lr 2.0611e-03 eta 0:16:53
epoch [22/30] batch [260/392] time 0.306 (0.308) data 0.000 (0.004) loss 3.8574 (2.2693) lr 2.0611e-03 eta 0:16:46
epoch [22/30] batch [280/392] time 0.300 (0.308) data 0.000 (0.004) loss 1.3770 (2.2722) lr 2.0611e-03 eta 0:16:41
epoch [22/30] batch [300/392] time 0.306 (0.308) data 0.000 (0.004) loss 1.5527 (2.2595) lr 2.0611e-03 eta 0:16:34
epoch [22/30] batch [320/392] time 0.300 (0.308) data 0.000 (0.003) loss 2.8457 (2.2840) lr 2.0611e-03 eta 0:16:26
epoch [22/30] batch [340/392] time 0.287 (0.307) data 0.000 (0.003) loss 4.0547 (2.2950) lr 2.0611e-03 eta 0:16:18
epoch [22/30] batch [360/392] time 0.290 (0.307) data 0.000 (0.003) loss 1.2285 (2.2992) lr 2.0611e-03 eta 0:16:11
epoch [22/30] batch [380/392] time 0.282 (0.305) data 0.000 (0.003) loss 1.4971 (2.2761) lr 2.0611e-03 eta 0:16:01
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.68s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.25s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.32it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.93it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.59it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.26it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.90it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.48it/s]100%|██████████| 9/9 [00:04<00:00,  2.21it/s]=> result
* total: 812
* correct: 600
* accuracy: 73.9%
* error: 26.1%
* macro_f1: 72.7%

epoch [23/30] batch [20/392] time 0.293 (0.354) data 0.000 (0.049) loss 1.0498 (2.3199) lr 1.6543e-03 eta 0:18:24
epoch [23/30] batch [40/392] time 0.300 (0.328) data 0.000 (0.025) loss 0.8345 (2.6132) lr 1.6543e-03 eta 0:16:56
epoch [23/30] batch [60/392] time 0.295 (0.320) data 0.000 (0.017) loss 3.0156 (2.3867) lr 1.6543e-03 eta 0:16:25
epoch [23/30] batch [80/392] time 0.287 (0.315) data 0.000 (0.012) loss 1.6436 (2.3495) lr 1.6543e-03 eta 0:16:02
epoch [23/30] batch [100/392] time 0.309 (0.313) data 0.000 (0.010) loss 1.5830 (2.3218) lr 1.6543e-03 eta 0:15:49
epoch [23/30] batch [120/392] time 0.314 (0.312) data 0.000 (0.008) loss 3.0352 (2.3771) lr 1.6543e-03 eta 0:15:42
epoch [23/30] batch [140/392] time 0.297 (0.311) data 0.000 (0.007) loss 3.0449 (2.3800) lr 1.6543e-03 eta 0:15:32
epoch [23/30] batch [160/392] time 0.304 (0.310) data 0.000 (0.006) loss 1.7070 (2.4215) lr 1.6543e-03 eta 0:15:23
epoch [23/30] batch [180/392] time 0.320 (0.310) data 0.000 (0.006) loss 1.7051 (2.3995) lr 1.6543e-03 eta 0:15:15
epoch [23/30] batch [200/392] time 0.295 (0.309) data 0.000 (0.005) loss 3.3301 (2.4372) lr 1.6543e-03 eta 0:15:07
epoch [23/30] batch [220/392] time 0.304 (0.309) data 0.000 (0.005) loss 0.5190 (2.4333) lr 1.6543e-03 eta 0:15:00
epoch [23/30] batch [240/392] time 0.295 (0.308) data 0.000 (0.004) loss 4.9141 (2.4335) lr 1.6543e-03 eta 0:14:52
epoch [23/30] batch [260/392] time 0.357 (0.308) data 0.001 (0.004) loss 1.3018 (2.4172) lr 1.6543e-03 eta 0:14:45
epoch [23/30] batch [280/392] time 0.342 (0.308) data 0.000 (0.004) loss 2.7969 (2.4184) lr 1.6543e-03 eta 0:14:40
epoch [23/30] batch [300/392] time 0.296 (0.308) data 0.000 (0.004) loss 1.1211 (2.4134) lr 1.6543e-03 eta 0:14:32
epoch [23/30] batch [320/392] time 0.295 (0.307) data 0.000 (0.003) loss 4.4297 (2.4103) lr 1.6543e-03 eta 0:14:25
epoch [23/30] batch [340/392] time 0.285 (0.307) data 0.000 (0.003) loss 3.8418 (2.4267) lr 1.6543e-03 eta 0:14:18
epoch [23/30] batch [360/392] time 0.292 (0.307) data 0.000 (0.003) loss 2.8711 (2.4260) lr 1.6543e-03 eta 0:14:11
epoch [23/30] batch [380/392] time 0.280 (0.305) data 0.000 (0.003) loss 1.5303 (2.4127) lr 1.6543e-03 eta 0:14:01
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.71s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.27s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.31it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.92it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.58it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.25it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.89it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.47it/s]100%|██████████| 9/9 [00:04<00:00,  2.20it/s]=> result
* total: 812
* correct: 605
* accuracy: 74.5%
* error: 25.5%
* macro_f1: 73.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [24/30] batch [20/392] time 0.434 (0.371) data 0.000 (0.053) loss 3.8516 (2.4808) lr 1.2843e-03 eta 0:16:49
epoch [24/30] batch [40/392] time 0.293 (0.337) data 0.000 (0.027) loss 1.3623 (2.3935) lr 1.2843e-03 eta 0:15:11
epoch [24/30] batch [60/392] time 0.307 (0.325) data 0.000 (0.018) loss 2.4980 (2.5040) lr 1.2843e-03 eta 0:14:32
epoch [24/30] batch [80/392] time 0.302 (0.320) data 0.000 (0.013) loss 1.8604 (2.4169) lr 1.2843e-03 eta 0:14:12
epoch [24/30] batch [100/392] time 0.297 (0.318) data 0.000 (0.011) loss 3.0605 (2.4217) lr 1.2843e-03 eta 0:14:00
epoch [24/30] batch [120/392] time 0.304 (0.315) data 0.000 (0.009) loss 1.9189 (2.3484) lr 1.2843e-03 eta 0:13:45
epoch [24/30] batch [140/392] time 0.316 (0.314) data 0.000 (0.008) loss 3.3086 (2.3812) lr 1.2843e-03 eta 0:13:37
epoch [24/30] batch [160/392] time 0.335 (0.312) data 0.000 (0.007) loss 1.6992 (2.3220) lr 1.2843e-03 eta 0:13:27
epoch [24/30] batch [180/392] time 0.290 (0.311) data 0.000 (0.006) loss 2.7285 (2.3640) lr 1.2843e-03 eta 0:13:18
epoch [24/30] batch [200/392] time 0.304 (0.311) data 0.000 (0.006) loss 1.6279 (2.3617) lr 1.2843e-03 eta 0:13:11
epoch [24/30] batch [220/392] time 0.301 (0.310) data 0.000 (0.005) loss 1.7969 (2.3983) lr 1.2843e-03 eta 0:13:02
epoch [24/30] batch [240/392] time 0.288 (0.309) data 0.000 (0.005) loss 1.7871 (2.3960) lr 1.2843e-03 eta 0:12:54
epoch [24/30] batch [260/392] time 0.303 (0.309) data 0.000 (0.004) loss 2.3418 (2.3671) lr 1.2843e-03 eta 0:12:46
epoch [24/30] batch [280/392] time 0.298 (0.308) data 0.000 (0.004) loss 1.9746 (2.3551) lr 1.2843e-03 eta 0:12:39
epoch [24/30] batch [300/392] time 0.297 (0.308) data 0.000 (0.004) loss 2.5430 (2.3357) lr 1.2843e-03 eta 0:12:31
epoch [24/30] batch [320/392] time 0.291 (0.307) data 0.000 (0.004) loss 0.5669 (2.3377) lr 1.2843e-03 eta 0:12:24
epoch [24/30] batch [340/392] time 0.287 (0.307) data 0.000 (0.003) loss 3.2637 (2.3424) lr 1.2843e-03 eta 0:12:17
epoch [24/30] batch [360/392] time 0.299 (0.307) data 0.000 (0.003) loss 3.0625 (2.3440) lr 1.2843e-03 eta 0:12:11
epoch [24/30] batch [380/392] time 0.285 (0.306) data 0.000 (0.003) loss 0.8643 (2.3243) lr 1.2843e-03 eta 0:12:02
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.62s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.19s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.40it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.03it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.70it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.37it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.02it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.59it/s]100%|██████████| 9/9 [00:03<00:00,  2.29it/s]=> result
* total: 812
* correct: 612
* accuracy: 75.4%
* error: 24.6%
* macro_f1: 74.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [25/30] batch [20/392] time 0.297 (0.361) data 0.000 (0.053) loss 1.4229 (2.6105) lr 9.5492e-04 eta 0:14:02
epoch [25/30] batch [40/392] time 0.302 (0.333) data 0.000 (0.027) loss 1.8057 (2.2766) lr 9.5492e-04 eta 0:12:50
epoch [25/30] batch [60/392] time 0.312 (0.326) data 0.000 (0.018) loss 1.0889 (2.4266) lr 9.5492e-04 eta 0:12:27
epoch [25/30] batch [80/392] time 0.295 (0.321) data 0.000 (0.014) loss 1.7920 (2.2389) lr 9.5492e-04 eta 0:12:10
epoch [25/30] batch [100/392] time 0.329 (0.318) data 0.000 (0.011) loss 3.0938 (2.3240) lr 9.5492e-04 eta 0:11:56
epoch [25/30] batch [120/392] time 0.308 (0.316) data 0.000 (0.009) loss 0.8682 (2.3056) lr 9.5492e-04 eta 0:11:45
epoch [25/30] batch [140/392] time 0.296 (0.314) data 0.000 (0.008) loss 1.7578 (2.2551) lr 9.5492e-04 eta 0:11:34
epoch [25/30] batch [160/392] time 0.289 (0.313) data 0.000 (0.007) loss 3.4727 (2.2988) lr 9.5492e-04 eta 0:11:26
epoch [25/30] batch [180/392] time 0.295 (0.311) data 0.000 (0.006) loss 2.0410 (2.3234) lr 9.5492e-04 eta 0:11:16
epoch [25/30] batch [200/392] time 0.291 (0.312) data 0.000 (0.006) loss 1.4854 (2.2620) lr 9.5492e-04 eta 0:11:10
epoch [25/30] batch [220/392] time 0.292 (0.311) data 0.000 (0.005) loss 2.0566 (2.2740) lr 9.5492e-04 eta 0:11:02
epoch [25/30] batch [240/392] time 0.311 (0.310) data 0.000 (0.005) loss 1.6807 (2.2606) lr 9.5492e-04 eta 0:10:54
epoch [25/30] batch [260/392] time 0.307 (0.310) data 0.000 (0.004) loss 1.3105 (2.2462) lr 9.5492e-04 eta 0:10:47
epoch [25/30] batch [280/392] time 0.291 (0.309) data 0.000 (0.004) loss 1.6445 (2.2339) lr 9.5492e-04 eta 0:10:41
epoch [25/30] batch [300/392] time 0.311 (0.309) data 0.000 (0.004) loss 0.6978 (2.2260) lr 9.5492e-04 eta 0:10:34
epoch [25/30] batch [320/392] time 0.397 (0.309) data 0.000 (0.004) loss 2.1855 (2.2225) lr 9.5492e-04 eta 0:10:28
epoch [25/30] batch [340/392] time 0.288 (0.309) data 0.000 (0.003) loss 4.5508 (2.2130) lr 9.5492e-04 eta 0:10:21
epoch [25/30] batch [360/392] time 0.289 (0.308) data 0.000 (0.003) loss 0.8452 (2.2324) lr 9.5492e-04 eta 0:10:13
epoch [25/30] batch [380/392] time 0.278 (0.307) data 0.000 (0.003) loss 2.3945 (2.2582) lr 9.5492e-04 eta 0:10:04
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.77s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.27s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.31it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.92it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.58it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.25it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.89it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.47it/s]100%|██████████| 9/9 [00:04<00:00,  2.18it/s]=> result
* total: 812
* correct: 617
* accuracy: 76.0%
* error: 24.0%
* macro_f1: 75.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [26/30] batch [20/392] time 0.297 (0.358) data 0.000 (0.052) loss 2.2871 (2.2847) lr 6.6987e-04 eta 0:11:34
epoch [26/30] batch [40/392] time 0.294 (0.331) data 0.000 (0.026) loss 1.0684 (2.1240) lr 6.6987e-04 eta 0:10:35
epoch [26/30] batch [60/392] time 0.298 (0.323) data 0.000 (0.017) loss 6.4688 (2.1789) lr 6.6987e-04 eta 0:10:12
epoch [26/30] batch [80/392] time 0.293 (0.317) data 0.000 (0.013) loss 0.5713 (2.1063) lr 6.6987e-04 eta 0:09:55
epoch [26/30] batch [100/392] time 0.298 (0.316) data 0.000 (0.011) loss 1.4277 (2.1502) lr 6.6987e-04 eta 0:09:47
epoch [26/30] batch [120/392] time 0.298 (0.314) data 0.000 (0.009) loss 2.4980 (2.1707) lr 6.6987e-04 eta 0:09:38
epoch [26/30] batch [140/392] time 0.294 (0.313) data 0.000 (0.008) loss 4.8633 (2.2347) lr 6.6987e-04 eta 0:09:28
epoch [26/30] batch [160/392] time 0.328 (0.312) data 0.000 (0.007) loss 3.2656 (2.2116) lr 6.6987e-04 eta 0:09:20
epoch [26/30] batch [180/392] time 0.292 (0.311) data 0.000 (0.006) loss 1.2031 (2.1849) lr 6.6987e-04 eta 0:09:13
epoch [26/30] batch [200/392] time 0.308 (0.310) data 0.000 (0.005) loss 3.3926 (2.2210) lr 6.6987e-04 eta 0:09:05
epoch [26/30] batch [220/392] time 0.305 (0.310) data 0.000 (0.005) loss 3.9668 (2.2197) lr 6.6987e-04 eta 0:08:58
epoch [26/30] batch [240/392] time 0.311 (0.309) data 0.000 (0.005) loss 3.7754 (2.2581) lr 6.6987e-04 eta 0:08:51
epoch [26/30] batch [260/392] time 0.316 (0.309) data 0.000 (0.004) loss 2.7852 (2.2235) lr 6.6987e-04 eta 0:08:44
epoch [26/30] batch [280/392] time 0.298 (0.308) data 0.000 (0.004) loss 3.2324 (2.2453) lr 6.6987e-04 eta 0:08:38
epoch [26/30] batch [300/392] time 0.321 (0.308) data 0.000 (0.004) loss 1.8945 (2.2218) lr 6.6987e-04 eta 0:08:31
epoch [26/30] batch [320/392] time 0.298 (0.308) data 0.000 (0.004) loss 2.9863 (2.2260) lr 6.6987e-04 eta 0:08:25
epoch [26/30] batch [340/392] time 0.310 (0.308) data 0.000 (0.003) loss 2.5137 (2.2097) lr 6.6987e-04 eta 0:08:18
epoch [26/30] batch [360/392] time 0.299 (0.307) data 0.000 (0.003) loss 3.5215 (2.2063) lr 6.6987e-04 eta 0:08:11
epoch [26/30] batch [380/392] time 0.280 (0.306) data 0.000 (0.003) loss 2.7754 (2.1961) lr 6.6987e-04 eta 0:08:03
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.78s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.24s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.35it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.96it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.63it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.31it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.95it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.52it/s]100%|██████████| 9/9 [00:04<00:00,  2.21it/s]=> result
* total: 812
* correct: 609
* accuracy: 75.0%
* error: 25.0%
* macro_f1: 74.1%

epoch [27/30] batch [20/392] time 0.301 (0.362) data 0.000 (0.055) loss 1.6250 (2.0831) lr 4.3227e-04 eta 0:09:20
epoch [27/30] batch [40/392] time 0.302 (0.335) data 0.000 (0.028) loss 3.5879 (2.3548) lr 4.3227e-04 eta 0:08:31
epoch [27/30] batch [60/392] time 0.297 (0.324) data 0.000 (0.019) loss 2.3535 (2.3528) lr 4.3227e-04 eta 0:08:08
epoch [27/30] batch [80/392] time 0.305 (0.322) data 0.000 (0.014) loss 1.9346 (2.2422) lr 4.3227e-04 eta 0:07:58
epoch [27/30] batch [100/392] time 0.297 (0.318) data 0.000 (0.011) loss 1.2217 (2.1988) lr 4.3227e-04 eta 0:07:46
epoch [27/30] batch [120/392] time 0.298 (0.316) data 0.000 (0.009) loss 0.7021 (2.1843) lr 4.3227e-04 eta 0:07:37
epoch [27/30] batch [140/392] time 0.304 (0.314) data 0.000 (0.008) loss 1.5420 (2.1808) lr 4.3227e-04 eta 0:07:28
epoch [27/30] batch [160/392] time 0.297 (0.313) data 0.000 (0.007) loss 2.1836 (2.1817) lr 4.3227e-04 eta 0:07:20
epoch [27/30] batch [180/392] time 0.293 (0.311) data 0.000 (0.006) loss 2.8379 (2.1793) lr 4.3227e-04 eta 0:07:12
epoch [27/30] batch [200/392] time 0.295 (0.310) data 0.000 (0.006) loss 2.2793 (2.2140) lr 4.3227e-04 eta 0:07:04
epoch [27/30] batch [220/392] time 0.302 (0.310) data 0.000 (0.005) loss 3.2148 (2.2297) lr 4.3227e-04 eta 0:06:58
epoch [27/30] batch [240/392] time 0.295 (0.310) data 0.000 (0.005) loss 0.3206 (2.1973) lr 4.3227e-04 eta 0:06:51
epoch [27/30] batch [260/392] time 0.286 (0.309) data 0.000 (0.005) loss 2.3086 (2.2149) lr 4.3227e-04 eta 0:06:44
epoch [27/30] batch [280/392] time 0.330 (0.309) data 0.000 (0.004) loss 4.4922 (2.2141) lr 4.3227e-04 eta 0:06:37
epoch [27/30] batch [300/392] time 0.310 (0.308) data 0.000 (0.004) loss 4.7617 (2.2137) lr 4.3227e-04 eta 0:06:30
epoch [27/30] batch [320/392] time 0.303 (0.308) data 0.000 (0.004) loss 2.9824 (2.2306) lr 4.3227e-04 eta 0:06:24
epoch [27/30] batch [340/392] time 0.295 (0.308) data 0.000 (0.004) loss 0.4526 (2.2240) lr 4.3227e-04 eta 0:06:18
epoch [27/30] batch [360/392] time 0.291 (0.308) data 0.000 (0.003) loss 3.7715 (2.2236) lr 4.3227e-04 eta 0:06:11
epoch [27/30] batch [380/392] time 0.280 (0.307) data 0.000 (0.003) loss 1.1670 (2.2099) lr 4.3227e-04 eta 0:06:04
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.77s/it] 22%|██▏       | 2/9 [00:03<00:08,  1.28s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.30it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.91it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.56it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.23it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.88it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.45it/s]100%|██████████| 9/9 [00:04<00:00,  2.18it/s]=> result
* total: 812
* correct: 609
* accuracy: 75.0%
* error: 25.0%
* macro_f1: 74.1%

epoch [28/30] batch [20/392] time 0.297 (0.359) data 0.000 (0.050) loss 2.7246 (2.4807) lr 2.4472e-04 eta 0:06:55
epoch [28/30] batch [40/392] time 0.296 (0.333) data 0.000 (0.025) loss 2.4004 (2.1358) lr 2.4472e-04 eta 0:06:18
epoch [28/30] batch [60/392] time 0.316 (0.322) data 0.001 (0.017) loss 2.8457 (2.2782) lr 2.4472e-04 eta 0:05:59
epoch [28/30] batch [80/392] time 0.296 (0.318) data 0.000 (0.013) loss 1.7158 (2.3777) lr 2.4472e-04 eta 0:05:48
epoch [28/30] batch [100/392] time 0.301 (0.315) data 0.000 (0.010) loss 1.8125 (2.3449) lr 2.4472e-04 eta 0:05:39
epoch [28/30] batch [120/392] time 0.308 (0.315) data 0.000 (0.009) loss 3.1289 (2.2829) lr 2.4472e-04 eta 0:05:32
epoch [28/30] batch [140/392] time 0.292 (0.313) data 0.000 (0.007) loss 0.8828 (2.2450) lr 2.4472e-04 eta 0:05:23
epoch [28/30] batch [160/392] time 0.301 (0.312) data 0.000 (0.007) loss 1.0811 (2.2064) lr 2.4472e-04 eta 0:05:16
epoch [28/30] batch [180/392] time 0.304 (0.312) data 0.000 (0.006) loss 2.2969 (2.1667) lr 2.4472e-04 eta 0:05:10
epoch [28/30] batch [200/392] time 0.312 (0.311) data 0.000 (0.005) loss 2.0098 (2.1536) lr 2.4472e-04 eta 0:05:03
epoch [28/30] batch [220/392] time 0.307 (0.311) data 0.000 (0.005) loss 3.0410 (2.1793) lr 2.4472e-04 eta 0:04:57
epoch [28/30] batch [240/392] time 0.343 (0.311) data 0.000 (0.004) loss 2.0176 (2.1605) lr 2.4472e-04 eta 0:04:51
epoch [28/30] batch [260/392] time 0.300 (0.311) data 0.000 (0.004) loss 0.8945 (2.1497) lr 2.4472e-04 eta 0:04:44
epoch [28/30] batch [280/392] time 0.293 (0.311) data 0.000 (0.004) loss 1.3711 (2.1487) lr 2.4472e-04 eta 0:04:38
epoch [28/30] batch [300/392] time 0.293 (0.310) data 0.000 (0.004) loss 1.4541 (2.1342) lr 2.4472e-04 eta 0:04:31
epoch [28/30] batch [320/392] time 0.297 (0.309) data 0.000 (0.003) loss 2.6230 (2.1770) lr 2.4472e-04 eta 0:04:24
epoch [28/30] batch [340/392] time 0.322 (0.309) data 0.000 (0.003) loss 0.7827 (2.1736) lr 2.4472e-04 eta 0:04:18
epoch [28/30] batch [360/392] time 0.298 (0.309) data 0.000 (0.003) loss 1.6650 (2.1972) lr 2.4472e-04 eta 0:04:12
epoch [28/30] batch [380/392] time 0.285 (0.308) data 0.000 (0.003) loss 1.3271 (2.1981) lr 2.4472e-04 eta 0:04:05
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.63s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.21s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.37it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.99it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.66it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.33it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.97it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.55it/s]100%|██████████| 9/9 [00:03<00:00,  2.27it/s]=> result
* total: 812
* correct: 609
* accuracy: 75.0%
* error: 25.0%
* macro_f1: 74.2%

epoch [29/30] batch [20/392] time 0.312 (0.362) data 0.000 (0.049) loss 0.8203 (2.0261) lr 1.0926e-04 eta 0:04:36
epoch [29/30] batch [40/392] time 0.309 (0.333) data 0.000 (0.024) loss 3.3887 (2.0166) lr 1.0926e-04 eta 0:04:07
epoch [29/30] batch [60/392] time 0.292 (0.325) data 0.000 (0.016) loss 3.5918 (2.0910) lr 1.0926e-04 eta 0:03:55
epoch [29/30] batch [80/392] time 0.307 (0.320) data 0.000 (0.012) loss 1.8623 (2.0543) lr 1.0926e-04 eta 0:03:44
epoch [29/30] batch [100/392] time 0.297 (0.316) data 0.000 (0.010) loss 3.6172 (2.1372) lr 1.0926e-04 eta 0:03:36
epoch [29/30] batch [120/392] time 0.292 (0.314) data 0.000 (0.008) loss 1.9385 (2.1378) lr 1.0926e-04 eta 0:03:28
epoch [29/30] batch [140/392] time 0.305 (0.312) data 0.000 (0.007) loss 2.3574 (2.0978) lr 1.0926e-04 eta 0:03:20
epoch [29/30] batch [160/392] time 0.304 (0.311) data 0.000 (0.006) loss 3.2207 (2.1199) lr 1.0926e-04 eta 0:03:13
epoch [29/30] batch [180/392] time 0.313 (0.311) data 0.000 (0.006) loss 0.7559 (2.1111) lr 1.0926e-04 eta 0:03:07
epoch [29/30] batch [200/392] time 0.291 (0.310) data 0.000 (0.005) loss 1.1514 (2.1021) lr 1.0926e-04 eta 0:03:00
epoch [29/30] batch [220/392] time 0.295 (0.309) data 0.000 (0.005) loss 3.5176 (2.1068) lr 1.0926e-04 eta 0:02:54
epoch [29/30] batch [240/392] time 0.299 (0.309) data 0.000 (0.004) loss 1.5518 (2.0988) lr 1.0926e-04 eta 0:02:48
epoch [29/30] batch [260/392] time 0.295 (0.308) data 0.000 (0.004) loss 1.7422 (2.1101) lr 1.0926e-04 eta 0:02:41
epoch [29/30] batch [280/392] time 0.291 (0.308) data 0.000 (0.004) loss 2.2969 (2.1231) lr 1.0926e-04 eta 0:02:35
epoch [29/30] batch [300/392] time 0.298 (0.308) data 0.000 (0.004) loss 2.4043 (2.1562) lr 1.0926e-04 eta 0:02:29
epoch [29/30] batch [320/392] time 0.310 (0.308) data 0.000 (0.003) loss 2.0977 (2.1846) lr 1.0926e-04 eta 0:02:22
epoch [29/30] batch [340/392] time 0.290 (0.308) data 0.000 (0.003) loss 1.3301 (2.2002) lr 1.0926e-04 eta 0:02:16
epoch [29/30] batch [360/392] time 0.304 (0.308) data 0.000 (0.003) loss 1.8174 (2.1751) lr 1.0926e-04 eta 0:02:10
epoch [29/30] batch [380/392] time 0.280 (0.306) data 0.000 (0.003) loss 2.3320 (2.1937) lr 1.0926e-04 eta 0:02:03
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:23,  2.90s/it] 22%|██▏       | 2/9 [00:03<00:08,  1.28s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.30it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.91it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.56it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.23it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.88it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.46it/s]100%|██████████| 9/9 [00:04<00:00,  2.16it/s]=> result
* total: 812
* correct: 608
* accuracy: 74.9%
* error: 25.1%
* macro_f1: 74.1%

epoch [30/30] batch [20/392] time 0.301 (0.368) data 0.000 (0.049) loss 3.7578 (2.2703) lr 2.7391e-05 eta 0:02:16
epoch [30/30] batch [40/392] time 0.302 (0.338) data 0.000 (0.024) loss 3.4062 (2.0632) lr 2.7391e-05 eta 0:01:59
epoch [30/30] batch [60/392] time 0.301 (0.327) data 0.000 (0.016) loss 4.8438 (2.1952) lr 2.7391e-05 eta 0:01:48
epoch [30/30] batch [80/392] time 0.304 (0.321) data 0.000 (0.012) loss 0.9409 (2.2696) lr 2.7391e-05 eta 0:01:40
epoch [30/30] batch [100/392] time 0.317 (0.318) data 0.000 (0.010) loss 1.3750 (2.2245) lr 2.7391e-05 eta 0:01:32
epoch [30/30] batch [120/392] time 0.292 (0.316) data 0.000 (0.008) loss 1.7910 (2.2385) lr 2.7391e-05 eta 0:01:25
epoch [30/30] batch [140/392] time 0.292 (0.314) data 0.000 (0.007) loss 1.2920 (2.2158) lr 2.7391e-05 eta 0:01:19
epoch [30/30] batch [160/392] time 0.313 (0.313) data 0.000 (0.006) loss 0.6543 (2.1860) lr 2.7391e-05 eta 0:01:12
epoch [30/30] batch [180/392] time 0.304 (0.311) data 0.000 (0.006) loss 0.7314 (2.1953) lr 2.7391e-05 eta 0:01:06
epoch [30/30] batch [200/392] time 0.288 (0.310) data 0.000 (0.005) loss 5.3398 (2.2324) lr 2.7391e-05 eta 0:00:59
epoch [30/30] batch [220/392] time 0.312 (0.310) data 0.000 (0.005) loss 1.8008 (2.2318) lr 2.7391e-05 eta 0:00:53
epoch [30/30] batch [240/392] time 0.286 (0.309) data 0.000 (0.004) loss 5.7148 (2.2491) lr 2.7391e-05 eta 0:00:47
epoch [30/30] batch [260/392] time 0.321 (0.309) data 0.000 (0.004) loss 6.1680 (2.2691) lr 2.7391e-05 eta 0:00:40
epoch [30/30] batch [280/392] time 0.297 (0.308) data 0.000 (0.004) loss 2.3008 (2.2629) lr 2.7391e-05 eta 0:00:34
epoch [30/30] batch [300/392] time 0.302 (0.308) data 0.000 (0.004) loss 1.0439 (2.2290) lr 2.7391e-05 eta 0:00:28
epoch [30/30] batch [320/392] time 0.304 (0.308) data 0.000 (0.003) loss 3.0820 (2.2109) lr 2.7391e-05 eta 0:00:22
epoch [30/30] batch [340/392] time 0.304 (0.308) data 0.000 (0.003) loss 1.5439 (2.2054) lr 2.7391e-05 eta 0:00:16
epoch [30/30] batch [360/392] time 0.297 (0.308) data 0.000 (0.003) loss 3.3984 (2.2247) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [380/392] time 0.282 (0.306) data 0.000 (0.003) loss 1.2139 (2.2322) lr 2.7391e-05 eta 0:00:03
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.73s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.22s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.37it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.99it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.63it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.30it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.92it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.50it/s]100%|██████████| 9/9 [00:04<00:00,  2.23it/s]
=> result
* total: 812
* correct: 608
* accuracy: 74.9%
* error: 25.1%
* macro_f1: 74.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/41 [00:00<?, ?it/s]  2%|▏         | 1/41 [00:03<02:08,  3.22s/it]  5%|▍         | 2/41 [00:04<01:09,  1.79s/it]  7%|▋         | 3/41 [00:04<00:48,  1.29s/it] 10%|▉         | 4/41 [00:05<00:39,  1.07s/it] 12%|█▏        | 5/41 [00:06<00:32,  1.12it/s] 15%|█▍        | 6/41 [00:06<00:24,  1.43it/s] 17%|█▋        | 7/41 [00:06<00:20,  1.65it/s] 20%|█▉        | 8/41 [00:07<00:17,  1.93it/s] 22%|██▏       | 9/41 [00:07<00:14,  2.26it/s] 24%|██▍       | 10/41 [00:07<00:12,  2.51it/s] 27%|██▋       | 11/41 [00:07<00:10,  2.80it/s] 29%|██▉       | 12/41 [00:08<00:09,  3.04it/s] 32%|███▏      | 13/41 [00:08<00:08,  3.29it/s] 34%|███▍      | 14/41 [00:08<00:06,  3.88it/s] 37%|███▋      | 15/41 [00:08<00:05,  4.43it/s] 39%|███▉      | 16/41 [00:08<00:05,  4.91it/s] 41%|████▏     | 17/41 [00:09<00:04,  5.32it/s] 44%|████▍     | 18/41 [00:09<00:04,  5.64it/s] 46%|████▋     | 19/41 [00:09<00:03,  5.89it/s] 49%|████▉     | 20/41 [00:09<00:03,  6.06it/s] 51%|█████     | 21/41 [00:09<00:03,  6.20it/s] 54%|█████▎    | 22/41 [00:09<00:03,  6.31it/s] 56%|█████▌    | 23/41 [00:09<00:02,  6.38it/s] 59%|█████▊    | 24/41 [00:10<00:02,  6.43it/s] 61%|██████    | 25/41 [00:10<00:02,  6.48it/s] 63%|██████▎   | 26/41 [00:10<00:02,  6.49it/s] 66%|██████▌   | 27/41 [00:10<00:02,  6.52it/s] 68%|██████▊   | 28/41 [00:10<00:01,  6.54it/s] 71%|███████   | 29/41 [00:10<00:01,  6.55it/s] 73%|███████▎  | 30/41 [00:11<00:01,  6.53it/s] 76%|███████▌  | 31/41 [00:11<00:01,  6.54it/s] 78%|███████▊  | 32/41 [00:11<00:01,  6.53it/s] 80%|████████  | 33/41 [00:11<00:01,  6.55it/s] 83%|████████▎ | 34/41 [00:11<00:01,  6.54it/s] 85%|████████▌ | 35/41 [00:11<00:00,  6.51it/s] 88%|████████▊ | 36/41 [00:11<00:00,  6.54it/s] 90%|█████████ | 37/41 [00:12<00:00,  6.53it/s] 93%|█████████▎| 38/41 [00:12<00:00,  6.53it/s] 95%|█████████▌| 39/41 [00:12<00:00,  6.54it/s] 98%|█████████▊| 40/41 [00:12<00:00,  6.34it/s]100%|██████████| 41/41 [00:12<00:00,  3.20it/s]
=> result
* total: 4,002
* correct: 3,043
* accuracy: 76.0%
* error: 24.0%
* macro_f1: 75.5%
Elapsed: 1:02:26
+ sh scripts/rpo_prime/base2new_test_sdl.sh stanford_cars 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
1568 823 4039
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      823
# test     4,039
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/41 [00:00<?, ?it/s]  2%|▏         | 1/41 [00:07<04:54,  7.35s/it]  5%|▍         | 2/41 [00:07<02:03,  3.18s/it]  7%|▋         | 3/41 [00:07<01:10,  1.84s/it] 10%|▉         | 4/41 [00:08<00:45,  1.22s/it] 12%|█▏        | 5/41 [00:08<00:31,  1.13it/s] 15%|█▍        | 6/41 [00:08<00:23,  1.48it/s] 17%|█▋        | 7/41 [00:08<00:18,  1.84it/s] 20%|█▉        | 8/41 [00:09<00:15,  2.16it/s] 22%|██▏       | 9/41 [00:09<00:13,  2.44it/s] 24%|██▍       | 10/41 [00:09<00:11,  2.67it/s] 27%|██▋       | 11/41 [00:10<00:10,  2.87it/s] 29%|██▉       | 12/41 [00:10<00:09,  3.08it/s] 32%|███▏      | 13/41 [00:10<00:08,  3.31it/s] 34%|███▍      | 14/41 [00:10<00:06,  3.88it/s] 37%|███▋      | 15/41 [00:10<00:05,  4.43it/s] 39%|███▉      | 16/41 [00:11<00:05,  4.92it/s] 41%|████▏     | 17/41 [00:11<00:04,  5.33it/s] 44%|████▍     | 18/41 [00:11<00:04,  5.66it/s] 46%|████▋     | 19/41 [00:11<00:03,  5.92it/s] 49%|████▉     | 20/41 [00:11<00:03,  6.12it/s] 51%|█████     | 21/41 [00:11<00:03,  6.27it/s] 54%|█████▎    | 22/41 [00:12<00:02,  6.38it/s] 56%|█████▌    | 23/41 [00:12<00:02,  6.46it/s] 59%|█████▊    | 24/41 [00:12<00:02,  6.51it/s] 61%|██████    | 25/41 [00:12<00:02,  6.56it/s] 63%|██████▎   | 26/41 [00:12<00:02,  6.57it/s] 66%|██████▌   | 27/41 [00:12<00:02,  6.60it/s] 68%|██████▊   | 28/41 [00:12<00:01,  6.58it/s] 71%|███████   | 29/41 [00:13<00:01,  6.60it/s] 73%|███████▎  | 30/41 [00:13<00:01,  6.62it/s] 76%|███████▌  | 31/41 [00:13<00:01,  6.62it/s] 78%|███████▊  | 32/41 [00:13<00:01,  6.64it/s] 80%|████████  | 33/41 [00:13<00:01,  6.65it/s] 83%|████████▎ | 34/41 [00:13<00:01,  6.64it/s] 85%|████████▌ | 35/41 [00:13<00:00,  6.64it/s] 88%|████████▊ | 36/41 [00:14<00:00,  6.64it/s] 90%|█████████ | 37/41 [00:14<00:00,  6.65it/s] 93%|█████████▎| 38/41 [00:14<00:00,  6.64it/s] 95%|█████████▌| 39/41 [00:14<00:00,  6.62it/s] 98%|█████████▊| 40/41 [00:14<00:00,  6.62it/s]100%|██████████| 41/41 [00:14<00:00,  2.74it/s]
=> result
* total: 4,039
* correct: 3,000
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.4%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh stanford_cars 2 0 main_tmp1_0.1sdl 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
1568 812 4002
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      812
# test     4,002
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/392] time 0.294 (0.458) data 0.000 (0.066) loss 2.8281 (3.7125) lr 1.0000e-02 eta 1:29:36
epoch [1/30] batch [40/392] time 0.294 (0.381) data 0.000 (0.033) loss 4.2695 (3.4705) lr 1.0000e-02 eta 1:14:30
epoch [1/30] batch [60/392] time 0.292 (0.355) data 0.000 (0.022) loss 1.9775 (3.3346) lr 1.0000e-02 eta 1:09:13
epoch [1/30] batch [80/392] time 0.286 (0.341) data 0.000 (0.017) loss 3.6660 (3.2477) lr 1.0000e-02 eta 1:06:26
epoch [1/30] batch [100/392] time 0.303 (0.334) data 0.000 (0.013) loss 3.1074 (3.2104) lr 1.0000e-02 eta 1:04:56
epoch [1/30] batch [120/392] time 0.296 (0.329) data 0.000 (0.011) loss 2.9023 (3.1852) lr 1.0000e-02 eta 1:03:48
epoch [1/30] batch [140/392] time 0.290 (0.326) data 0.000 (0.010) loss 3.2422 (3.0786) lr 1.0000e-02 eta 1:03:12
epoch [1/30] batch [160/392] time 0.326 (0.323) data 0.000 (0.008) loss 6.0977 (3.1065) lr 1.0000e-02 eta 1:02:30
epoch [1/30] batch [180/392] time 0.292 (0.320) data 0.000 (0.008) loss 2.3047 (3.0628) lr 1.0000e-02 eta 1:01:51
epoch [1/30] batch [200/392] time 0.283 (0.319) data 0.000 (0.007) loss 3.1797 (3.0079) lr 1.0000e-02 eta 1:01:30
epoch [1/30] batch [220/392] time 0.301 (0.317) data 0.000 (0.006) loss 5.2695 (3.0435) lr 1.0000e-02 eta 1:00:59
epoch [1/30] batch [240/392] time 0.324 (0.316) data 0.000 (0.006) loss 2.9082 (3.0637) lr 1.0000e-02 eta 1:00:35
epoch [1/30] batch [260/392] time 0.306 (0.315) data 0.000 (0.005) loss 3.1504 (3.0788) lr 1.0000e-02 eta 1:00:19
epoch [1/30] batch [280/392] time 0.299 (0.314) data 0.000 (0.005) loss 2.8418 (3.0992) lr 1.0000e-02 eta 1:00:01
epoch [1/30] batch [300/392] time 0.301 (0.313) data 0.000 (0.005) loss 2.1758 (3.0953) lr 1.0000e-02 eta 0:59:42
epoch [1/30] batch [320/392] time 0.294 (0.312) data 0.000 (0.004) loss 1.7490 (3.0791) lr 1.0000e-02 eta 0:59:29
epoch [1/30] batch [340/392] time 0.293 (0.311) data 0.000 (0.004) loss 2.8203 (3.0709) lr 1.0000e-02 eta 0:59:16
epoch [1/30] batch [360/392] time 0.313 (0.311) data 0.000 (0.004) loss 0.5815 (3.0522) lr 1.0000e-02 eta 0:59:05
epoch [1/30] batch [380/392] time 0.279 (0.309) data 0.000 (0.004) loss 2.1953 (3.0343) lr 1.0000e-02 eta 0:58:40
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:23,  2.96s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.31s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.28it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.88it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.54it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.21it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.86it/s] 89%|████████▉ | 8/9 [00:04<00:00,  4.45it/s]100%|██████████| 9/9 [00:04<00:00,  2.12it/s]=> result
* total: 812
* correct: 536
* accuracy: 66.0%
* error: 34.0%
* macro_f1: 64.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/392] time 0.289 (0.354) data 0.000 (0.056) loss 1.3311 (3.0601) lr 9.9726e-03 eta 1:06:56
epoch [2/30] batch [40/392] time 0.287 (0.327) data 0.000 (0.028) loss 1.5820 (2.9881) lr 9.9726e-03 eta 1:01:42
epoch [2/30] batch [60/392] time 0.285 (0.318) data 0.000 (0.019) loss 2.5547 (2.8600) lr 9.9726e-03 eta 1:00:00
epoch [2/30] batch [80/392] time 0.301 (0.314) data 0.000 (0.014) loss 4.2617 (2.9548) lr 9.9726e-03 eta 0:59:07
epoch [2/30] batch [100/392] time 0.291 (0.311) data 0.000 (0.011) loss 4.0391 (2.9942) lr 9.9726e-03 eta 0:58:25
epoch [2/30] batch [120/392] time 0.306 (0.309) data 0.000 (0.010) loss 1.6826 (3.0022) lr 9.9726e-03 eta 0:57:56
epoch [2/30] batch [140/392] time 0.341 (0.309) data 0.000 (0.008) loss 2.1484 (2.9822) lr 9.9726e-03 eta 0:57:53
epoch [2/30] batch [160/392] time 0.320 (0.308) data 0.000 (0.007) loss 1.8682 (2.9206) lr 9.9726e-03 eta 0:57:30
epoch [2/30] batch [180/392] time 0.301 (0.307) data 0.000 (0.006) loss 4.0273 (2.9113) lr 9.9726e-03 eta 0:57:16
epoch [2/30] batch [200/392] time 0.293 (0.307) data 0.000 (0.006) loss 1.1182 (2.8393) lr 9.9726e-03 eta 0:57:06
epoch [2/30] batch [220/392] time 0.348 (0.307) data 0.000 (0.005) loss 3.3262 (2.8516) lr 9.9726e-03 eta 0:56:57
epoch [2/30] batch [240/392] time 0.293 (0.306) data 0.000 (0.005) loss 3.6758 (2.8680) lr 9.9726e-03 eta 0:56:42
epoch [2/30] batch [260/392] time 0.309 (0.306) data 0.000 (0.005) loss 3.4375 (2.8997) lr 9.9726e-03 eta 0:56:44
epoch [2/30] batch [280/392] time 0.298 (0.306) data 0.000 (0.004) loss 2.8359 (2.8937) lr 9.9726e-03 eta 0:56:37
epoch [2/30] batch [300/392] time 0.298 (0.306) data 0.000 (0.004) loss 3.2441 (2.8923) lr 9.9726e-03 eta 0:56:29
epoch [2/30] batch [320/392] time 0.301 (0.306) data 0.000 (0.004) loss 4.3086 (2.9222) lr 9.9726e-03 eta 0:56:23
epoch [2/30] batch [340/392] time 0.297 (0.306) data 0.000 (0.004) loss 1.7529 (2.9123) lr 9.9726e-03 eta 0:56:17
epoch [2/30] batch [360/392] time 0.303 (0.306) data 0.000 (0.003) loss 3.2246 (2.9196) lr 9.9726e-03 eta 0:56:05
epoch [2/30] batch [380/392] time 0.383 (0.305) data 0.000 (0.003) loss 1.7080 (2.9189) lr 9.9726e-03 eta 0:55:49
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.87s/it] 22%|██▏       | 2/9 [00:03<00:08,  1.28s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.31it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.91it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.57it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.25it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.90it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.48it/s]100%|██████████| 9/9 [00:04<00:00,  2.15it/s]=> result
* total: 812
* correct: 548
* accuracy: 67.5%
* error: 32.5%
* macro_f1: 65.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/392] time 0.293 (0.366) data 0.000 (0.053) loss 2.8691 (2.6475) lr 9.8907e-03 eta 1:06:48
epoch [3/30] batch [40/392] time 0.309 (0.335) data 0.000 (0.027) loss 3.8223 (2.5118) lr 9.8907e-03 eta 1:01:07
epoch [3/30] batch [60/392] time 0.420 (0.326) data 0.000 (0.018) loss 3.5918 (2.5777) lr 9.8907e-03 eta 0:59:15
epoch [3/30] batch [80/392] time 0.303 (0.321) data 0.000 (0.014) loss 2.9453 (2.5001) lr 9.8907e-03 eta 0:58:20
epoch [3/30] batch [100/392] time 0.295 (0.317) data 0.000 (0.011) loss 2.3691 (2.5205) lr 9.8907e-03 eta 0:57:28
epoch [3/30] batch [120/392] time 0.294 (0.314) data 0.001 (0.009) loss 3.7949 (2.5660) lr 9.8907e-03 eta 0:56:46
epoch [3/30] batch [140/392] time 0.291 (0.312) data 0.000 (0.008) loss 0.9312 (2.5794) lr 9.8907e-03 eta 0:56:21
epoch [3/30] batch [160/392] time 0.300 (0.311) data 0.000 (0.007) loss 3.3535 (2.6372) lr 9.8907e-03 eta 0:56:01
epoch [3/30] batch [180/392] time 0.289 (0.309) data 0.000 (0.006) loss 4.7812 (2.7030) lr 9.8907e-03 eta 0:55:38
epoch [3/30] batch [200/392] time 0.295 (0.309) data 0.000 (0.006) loss 3.4805 (2.7000) lr 9.8907e-03 eta 0:55:26
epoch [3/30] batch [220/392] time 0.301 (0.308) data 0.000 (0.005) loss 2.7168 (2.7472) lr 9.8907e-03 eta 0:55:13
epoch [3/30] batch [240/392] time 0.337 (0.308) data 0.000 (0.005) loss 5.1289 (2.7427) lr 9.8907e-03 eta 0:55:06
epoch [3/30] batch [260/392] time 0.292 (0.307) data 0.000 (0.004) loss 2.1875 (2.7555) lr 9.8907e-03 eta 0:54:51
epoch [3/30] batch [280/392] time 0.295 (0.306) data 0.000 (0.004) loss 4.0469 (2.7413) lr 9.8907e-03 eta 0:54:37
epoch [3/30] batch [300/392] time 0.293 (0.306) data 0.001 (0.004) loss 2.8906 (2.7656) lr 9.8907e-03 eta 0:54:28
epoch [3/30] batch [320/392] time 0.307 (0.306) data 0.000 (0.004) loss 2.9160 (2.7726) lr 9.8907e-03 eta 0:54:18
epoch [3/30] batch [340/392] time 0.321 (0.306) data 0.000 (0.003) loss 3.6836 (2.7647) lr 9.8907e-03 eta 0:54:12
epoch [3/30] batch [360/392] time 0.297 (0.306) data 0.000 (0.003) loss 2.6211 (2.7777) lr 9.8907e-03 eta 0:54:07
epoch [3/30] batch [380/392] time 0.281 (0.305) data 0.000 (0.003) loss 3.8691 (2.7896) lr 9.8907e-03 eta 0:53:47
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.86s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.29s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.29it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.89it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.55it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.23it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.87it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.46it/s]100%|██████████| 9/9 [00:04<00:00,  2.14it/s]=> result
* total: 812
* correct: 551
* accuracy: 67.9%
* error: 32.1%
* macro_f1: 66.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/392] time 0.298 (0.367) data 0.000 (0.052) loss 2.7969 (2.4167) lr 9.7553e-03 eta 1:04:35
epoch [4/30] batch [40/392] time 0.295 (0.334) data 0.000 (0.026) loss 3.5547 (2.8059) lr 9.7553e-03 eta 0:58:39
epoch [4/30] batch [60/392] time 0.288 (0.323) data 0.000 (0.018) loss 3.5352 (2.7667) lr 9.7553e-03 eta 0:56:39
epoch [4/30] batch [80/392] time 0.290 (0.317) data 0.000 (0.013) loss 2.5488 (2.7937) lr 9.7553e-03 eta 0:55:29
epoch [4/30] batch [100/392] time 0.293 (0.313) data 0.000 (0.011) loss 2.8418 (2.8404) lr 9.7553e-03 eta 0:54:40
epoch [4/30] batch [120/392] time 0.284 (0.311) data 0.000 (0.009) loss 1.9297 (2.8293) lr 9.7553e-03 eta 0:54:18
epoch [4/30] batch [140/392] time 0.290 (0.310) data 0.000 (0.008) loss 3.7305 (2.8231) lr 9.7553e-03 eta 0:53:55
epoch [4/30] batch [160/392] time 0.311 (0.310) data 0.000 (0.007) loss 1.0957 (2.7460) lr 9.7553e-03 eta 0:53:46
epoch [4/30] batch [180/392] time 0.307 (0.309) data 0.000 (0.006) loss 1.4287 (2.7062) lr 9.7553e-03 eta 0:53:37
epoch [4/30] batch [200/392] time 0.295 (0.308) data 0.000 (0.005) loss 1.2139 (2.7396) lr 9.7553e-03 eta 0:53:15
epoch [4/30] batch [220/392] time 0.291 (0.307) data 0.000 (0.005) loss 2.0762 (2.7833) lr 9.7553e-03 eta 0:53:03
epoch [4/30] batch [240/392] time 0.296 (0.306) data 0.000 (0.005) loss 1.5479 (2.7409) lr 9.7553e-03 eta 0:52:47
epoch [4/30] batch [260/392] time 0.285 (0.306) data 0.000 (0.004) loss 5.1680 (2.7515) lr 9.7553e-03 eta 0:52:35
epoch [4/30] batch [280/392] time 0.289 (0.305) data 0.000 (0.004) loss 2.1484 (2.7524) lr 9.7553e-03 eta 0:52:21
epoch [4/30] batch [300/392] time 0.291 (0.305) data 0.000 (0.004) loss 4.9375 (2.7469) lr 9.7553e-03 eta 0:52:12
epoch [4/30] batch [320/392] time 0.313 (0.304) data 0.000 (0.004) loss 0.4514 (2.7079) lr 9.7553e-03 eta 0:52:02
epoch [4/30] batch [340/392] time 0.292 (0.304) data 0.000 (0.003) loss 1.9473 (2.7094) lr 9.7553e-03 eta 0:51:50
epoch [4/30] batch [360/392] time 0.286 (0.303) data 0.000 (0.003) loss 2.9980 (2.6992) lr 9.7553e-03 eta 0:51:42
epoch [4/30] batch [380/392] time 0.276 (0.302) data 0.000 (0.003) loss 2.3730 (2.6995) lr 9.7553e-03 eta 0:51:21
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:23,  2.88s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.29s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.30it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.90it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.56it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.24it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.89it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.47it/s]100%|██████████| 9/9 [00:04<00:00,  2.15it/s]=> result
* total: 812
* correct: 557
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 66.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/392] time 0.273 (0.351) data 0.000 (0.051) loss 2.9004 (2.2614) lr 9.5677e-03 eta 0:59:33
epoch [5/30] batch [40/392] time 0.278 (0.320) data 0.000 (0.026) loss 1.9717 (2.7560) lr 9.5677e-03 eta 0:54:05
epoch [5/30] batch [60/392] time 0.287 (0.310) data 0.000 (0.017) loss 2.0430 (2.8987) lr 9.5677e-03 eta 0:52:19
epoch [5/30] batch [80/392] time 0.306 (0.308) data 0.000 (0.013) loss 5.1523 (2.8835) lr 9.5677e-03 eta 0:51:50
epoch [5/30] batch [100/392] time 0.295 (0.304) data 0.000 (0.010) loss 1.7256 (2.9612) lr 9.5677e-03 eta 0:51:09
epoch [5/30] batch [120/392] time 0.285 (0.302) data 0.000 (0.009) loss 3.9043 (2.8918) lr 9.5677e-03 eta 0:50:44
epoch [5/30] batch [140/392] time 0.281 (0.301) data 0.000 (0.008) loss 4.4922 (2.8176) lr 9.5677e-03 eta 0:50:23
epoch [5/30] batch [160/392] time 0.283 (0.299) data 0.000 (0.007) loss 2.4746 (2.8473) lr 9.5677e-03 eta 0:50:04
epoch [5/30] batch [180/392] time 0.283 (0.299) data 0.000 (0.006) loss 3.2695 (2.8335) lr 9.5677e-03 eta 0:49:53
epoch [5/30] batch [200/392] time 0.278 (0.298) data 0.000 (0.005) loss 5.3828 (2.8610) lr 9.5677e-03 eta 0:49:38
epoch [5/30] batch [220/392] time 0.291 (0.297) data 0.000 (0.005) loss 3.5391 (2.8135) lr 9.5677e-03 eta 0:49:24
epoch [5/30] batch [240/392] time 0.284 (0.296) data 0.000 (0.004) loss 2.5449 (2.8179) lr 9.5677e-03 eta 0:49:09
epoch [5/30] batch [260/392] time 0.281 (0.296) data 0.000 (0.004) loss 1.8379 (2.7817) lr 9.5677e-03 eta 0:49:02
epoch [5/30] batch [280/392] time 0.292 (0.296) data 0.000 (0.004) loss 1.5850 (2.7859) lr 9.5677e-03 eta 0:48:54
epoch [5/30] batch [300/392] time 0.299 (0.296) data 0.000 (0.004) loss 3.3516 (2.7912) lr 9.5677e-03 eta 0:48:45
epoch [5/30] batch [320/392] time 0.289 (0.296) data 0.000 (0.003) loss 5.4297 (2.7899) lr 9.5677e-03 eta 0:48:41
epoch [5/30] batch [340/392] time 0.284 (0.296) data 0.000 (0.003) loss 0.8745 (2.7909) lr 9.5677e-03 eta 0:48:34
epoch [5/30] batch [360/392] time 0.283 (0.295) data 0.000 (0.003) loss 3.0840 (2.7845) lr 9.5677e-03 eta 0:48:24
epoch [5/30] batch [380/392] time 0.272 (0.294) data 0.000 (0.003) loss 2.9023 (2.7974) lr 9.5677e-03 eta 0:48:06
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.70s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.21s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.38it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.01it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.69it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.37it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.03it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.62it/s]100%|██████████| 9/9 [00:03<00:00,  2.27it/s]=> result
* total: 812
* correct: 558
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 66.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/392] time 0.323 (0.346) data 0.000 (0.050) loss 2.3672 (3.2399) lr 9.3301e-03 eta 0:56:27
epoch [6/30] batch [40/392] time 0.285 (0.322) data 0.000 (0.025) loss 3.0332 (2.8658) lr 9.3301e-03 eta 0:52:24
epoch [6/30] batch [60/392] time 0.297 (0.313) data 0.000 (0.017) loss 1.0088 (2.7162) lr 9.3301e-03 eta 0:50:48
epoch [6/30] batch [80/392] time 0.284 (0.307) data 0.000 (0.013) loss 2.0176 (2.7277) lr 9.3301e-03 eta 0:49:39
epoch [6/30] batch [100/392] time 0.290 (0.303) data 0.000 (0.010) loss 2.6523 (2.7183) lr 9.3301e-03 eta 0:49:00
epoch [6/30] batch [120/392] time 0.289 (0.301) data 0.000 (0.009) loss 5.4922 (2.7457) lr 9.3301e-03 eta 0:48:37
epoch [6/30] batch [140/392] time 0.284 (0.301) data 0.000 (0.007) loss 1.2676 (2.7150) lr 9.3301e-03 eta 0:48:24
epoch [6/30] batch [160/392] time 0.301 (0.299) data 0.000 (0.006) loss 3.0508 (2.7096) lr 9.3301e-03 eta 0:48:05
epoch [6/30] batch [180/392] time 0.301 (0.298) data 0.000 (0.006) loss 2.5371 (2.6900) lr 9.3301e-03 eta 0:47:49
epoch [6/30] batch [200/392] time 0.282 (0.299) data 0.000 (0.005) loss 2.2129 (2.7024) lr 9.3301e-03 eta 0:47:46
epoch [6/30] batch [220/392] time 0.287 (0.298) data 0.000 (0.005) loss 1.9395 (2.6879) lr 9.3301e-03 eta 0:47:32
epoch [6/30] batch [240/392] time 0.277 (0.297) data 0.000 (0.004) loss 0.7007 (2.6671) lr 9.3301e-03 eta 0:47:19
epoch [6/30] batch [260/392] time 0.278 (0.296) data 0.000 (0.004) loss 4.2578 (2.6690) lr 9.3301e-03 eta 0:47:08
epoch [6/30] batch [280/392] time 0.312 (0.296) data 0.000 (0.004) loss 3.4570 (2.6363) lr 9.3301e-03 eta 0:46:57
epoch [6/30] batch [300/392] time 0.293 (0.296) data 0.000 (0.004) loss 5.2930 (2.6516) lr 9.3301e-03 eta 0:46:48
epoch [6/30] batch [320/392] time 0.278 (0.296) data 0.000 (0.003) loss 3.1445 (2.6742) lr 9.3301e-03 eta 0:46:42
epoch [6/30] batch [340/392] time 0.293 (0.295) data 0.000 (0.003) loss 0.8838 (2.6355) lr 9.3301e-03 eta 0:46:35
epoch [6/30] batch [360/392] time 0.289 (0.295) data 0.000 (0.003) loss 1.4912 (2.6571) lr 9.3301e-03 eta 0:46:25
epoch [6/30] batch [380/392] time 0.269 (0.294) data 0.000 (0.003) loss 3.6035 (2.6575) lr 9.3301e-03 eta 0:46:09
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:23,  2.88s/it] 22%|██▏       | 2/9 [00:03<00:08,  1.28s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.31it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.92it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.57it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.25it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.90it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.48it/s]100%|██████████| 9/9 [00:04<00:00,  2.16it/s]=> result
* total: 812
* correct: 564
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 67.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/392] time 0.283 (0.346) data 0.000 (0.049) loss 4.0391 (2.7023) lr 9.0451e-03 eta 0:54:03
epoch [7/30] batch [40/392] time 0.321 (0.320) data 0.000 (0.025) loss 1.1162 (2.9123) lr 9.0451e-03 eta 0:49:57
epoch [7/30] batch [60/392] time 0.385 (0.313) data 0.000 (0.017) loss 1.2041 (2.7908) lr 9.0451e-03 eta 0:48:41
epoch [7/30] batch [80/392] time 0.301 (0.307) data 0.000 (0.013) loss 1.3389 (2.8377) lr 9.0451e-03 eta 0:47:47
epoch [7/30] batch [100/392] time 0.283 (0.303) data 0.000 (0.010) loss 2.5117 (2.7948) lr 9.0451e-03 eta 0:47:03
epoch [7/30] batch [120/392] time 0.295 (0.302) data 0.000 (0.008) loss 1.6465 (2.8256) lr 9.0451e-03 eta 0:46:42
epoch [7/30] batch [140/392] time 0.290 (0.300) data 0.000 (0.007) loss 3.1758 (2.7577) lr 9.0451e-03 eta 0:46:20
epoch [7/30] batch [160/392] time 0.281 (0.299) data 0.000 (0.006) loss 0.8379 (2.7266) lr 9.0451e-03 eta 0:46:02
epoch [7/30] batch [180/392] time 0.279 (0.298) data 0.000 (0.006) loss 4.3594 (2.6826) lr 9.0451e-03 eta 0:45:47
epoch [7/30] batch [200/392] time 0.300 (0.297) data 0.000 (0.005) loss 2.5508 (2.6805) lr 9.0451e-03 eta 0:45:37
epoch [7/30] batch [220/392] time 0.296 (0.297) data 0.000 (0.005) loss 3.6289 (2.6573) lr 9.0451e-03 eta 0:45:24
epoch [7/30] batch [240/392] time 0.295 (0.297) data 0.000 (0.004) loss 3.5684 (2.6892) lr 9.0451e-03 eta 0:45:18
epoch [7/30] batch [260/392] time 0.297 (0.297) data 0.000 (0.004) loss 2.5918 (2.6951) lr 9.0451e-03 eta 0:45:15
epoch [7/30] batch [280/392] time 0.280 (0.296) data 0.000 (0.004) loss 1.8516 (2.6873) lr 9.0451e-03 eta 0:45:05
epoch [7/30] batch [300/392] time 0.304 (0.296) data 0.000 (0.004) loss 1.4111 (2.7081) lr 9.0451e-03 eta 0:44:57
epoch [7/30] batch [320/392] time 0.315 (0.296) data 0.000 (0.003) loss 4.5195 (2.6950) lr 9.0451e-03 eta 0:44:50
epoch [7/30] batch [340/392] time 0.284 (0.296) data 0.000 (0.003) loss 1.3438 (2.6695) lr 9.0451e-03 eta 0:44:42
epoch [7/30] batch [360/392] time 0.316 (0.295) data 0.000 (0.003) loss 1.3555 (2.6743) lr 9.0451e-03 eta 0:44:33
epoch [7/30] batch [380/392] time 0.273 (0.294) data 0.000 (0.003) loss 2.7500 (2.6763) lr 9.0451e-03 eta 0:44:17
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.70s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.20s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.39it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.02it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.70it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.38it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.03it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.57it/s]100%|██████████| 9/9 [00:03<00:00,  2.27it/s]=> result
* total: 812
* correct: 577
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 70.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/392] time 0.333 (0.350) data 0.000 (0.051) loss 3.1328 (2.6956) lr 8.7157e-03 eta 0:52:27
epoch [8/30] batch [40/392] time 0.299 (0.323) data 0.000 (0.025) loss 0.4609 (2.5445) lr 8.7157e-03 eta 0:48:17
epoch [8/30] batch [60/392] time 0.300 (0.313) data 0.000 (0.017) loss 1.0303 (2.6249) lr 8.7157e-03 eta 0:46:45
epoch [8/30] batch [80/392] time 0.325 (0.309) data 0.000 (0.013) loss 2.6406 (2.6502) lr 8.7157e-03 eta 0:46:04
epoch [8/30] batch [100/392] time 0.296 (0.305) data 0.000 (0.010) loss 0.8862 (2.5898) lr 8.7157e-03 eta 0:45:20
epoch [8/30] batch [120/392] time 0.288 (0.302) data 0.000 (0.009) loss 2.4023 (2.6116) lr 8.7157e-03 eta 0:44:50
epoch [8/30] batch [140/392] time 0.280 (0.302) data 0.000 (0.007) loss 1.0098 (2.6014) lr 8.7157e-03 eta 0:44:39
epoch [8/30] batch [160/392] time 0.297 (0.300) data 0.000 (0.007) loss 4.4102 (2.6417) lr 8.7157e-03 eta 0:44:19
epoch [8/30] batch [180/392] time 0.287 (0.299) data 0.000 (0.006) loss 1.0049 (2.6952) lr 8.7157e-03 eta 0:44:04
epoch [8/30] batch [200/392] time 0.286 (0.298) data 0.000 (0.005) loss 0.9033 (2.6965) lr 8.7157e-03 eta 0:43:47
epoch [8/30] batch [220/392] time 0.283 (0.298) data 0.000 (0.005) loss 4.2148 (2.6635) lr 8.7157e-03 eta 0:43:39
epoch [8/30] batch [240/392] time 0.290 (0.297) data 0.000 (0.004) loss 2.8730 (2.6323) lr 8.7157e-03 eta 0:43:27
epoch [8/30] batch [260/392] time 0.278 (0.297) data 0.000 (0.004) loss 3.0352 (2.6446) lr 8.7157e-03 eta 0:43:20
epoch [8/30] batch [280/392] time 0.281 (0.296) data 0.000 (0.004) loss 4.3789 (2.6603) lr 8.7157e-03 eta 0:43:09
epoch [8/30] batch [300/392] time 0.285 (0.296) data 0.000 (0.004) loss 1.0723 (2.6739) lr 8.7157e-03 eta 0:43:00
epoch [8/30] batch [320/392] time 0.285 (0.296) data 0.000 (0.003) loss 5.0312 (2.6757) lr 8.7157e-03 eta 0:42:53
epoch [8/30] batch [340/392] time 0.285 (0.296) data 0.000 (0.003) loss 2.3691 (2.6812) lr 8.7157e-03 eta 0:42:44
epoch [8/30] batch [360/392] time 0.286 (0.295) data 0.000 (0.003) loss 2.6562 (2.6953) lr 8.7157e-03 eta 0:42:33
epoch [8/30] batch [380/392] time 0.271 (0.294) data 0.000 (0.003) loss 1.6025 (2.6863) lr 8.7157e-03 eta 0:42:17
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.79s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.29s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.29it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.90it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.56it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.23it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.88it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.48it/s]100%|██████████| 9/9 [00:04<00:00,  2.17it/s]=> result
* total: 812
* correct: 565
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 68.3%

epoch [9/30] batch [20/392] time 0.291 (0.346) data 0.000 (0.052) loss 3.6055 (2.4327) lr 8.3457e-03 eta 0:49:38
epoch [9/30] batch [40/392] time 0.284 (0.320) data 0.000 (0.026) loss 2.7363 (2.4478) lr 8.3457e-03 eta 0:45:49
epoch [9/30] batch [60/392] time 0.288 (0.310) data 0.000 (0.017) loss 3.1133 (2.4976) lr 8.3457e-03 eta 0:44:13
epoch [9/30] batch [80/392] time 0.309 (0.304) data 0.000 (0.013) loss 4.7500 (2.6126) lr 8.3457e-03 eta 0:43:21
epoch [9/30] batch [100/392] time 0.281 (0.301) data 0.000 (0.011) loss 2.7520 (2.6057) lr 8.3457e-03 eta 0:42:47
epoch [9/30] batch [120/392] time 0.317 (0.300) data 0.000 (0.009) loss 2.7793 (2.5809) lr 8.3457e-03 eta 0:42:28
epoch [9/30] batch [140/392] time 0.288 (0.299) data 0.000 (0.008) loss 2.4316 (2.5477) lr 8.3457e-03 eta 0:42:12
epoch [9/30] batch [160/392] time 0.323 (0.298) data 0.000 (0.007) loss 1.1094 (2.4956) lr 8.3457e-03 eta 0:42:05
epoch [9/30] batch [180/392] time 0.332 (0.298) data 0.000 (0.006) loss 1.5322 (2.4702) lr 8.3457e-03 eta 0:41:52
epoch [9/30] batch [200/392] time 0.282 (0.297) data 0.000 (0.005) loss 1.6484 (2.4989) lr 8.3457e-03 eta 0:41:40
epoch [9/30] batch [220/392] time 0.295 (0.296) data 0.000 (0.005) loss 1.9365 (2.4879) lr 8.3457e-03 eta 0:41:30
epoch [9/30] batch [240/392] time 0.296 (0.296) data 0.000 (0.005) loss 3.0840 (2.4742) lr 8.3457e-03 eta 0:41:23
epoch [9/30] batch [260/392] time 0.285 (0.296) data 0.000 (0.004) loss 1.8564 (2.5032) lr 8.3457e-03 eta 0:41:13
epoch [9/30] batch [280/392] time 0.284 (0.295) data 0.000 (0.004) loss 6.9375 (2.4795) lr 8.3457e-03 eta 0:41:05
epoch [9/30] batch [300/392] time 0.283 (0.295) data 0.000 (0.004) loss 2.6348 (2.4933) lr 8.3457e-03 eta 0:40:55
epoch [9/30] batch [320/392] time 0.365 (0.295) data 0.000 (0.003) loss 2.2012 (2.5047) lr 8.3457e-03 eta 0:40:51
epoch [9/30] batch [340/392] time 0.284 (0.295) data 0.000 (0.003) loss 1.8271 (2.5045) lr 8.3457e-03 eta 0:40:41
epoch [9/30] batch [360/392] time 0.286 (0.294) data 0.000 (0.003) loss 4.4492 (2.5195) lr 8.3457e-03 eta 0:40:32
epoch [9/30] batch [380/392] time 0.268 (0.293) data 0.000 (0.003) loss 4.3320 (2.5294) lr 8.3457e-03 eta 0:40:17
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.76s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.23s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.36it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.98it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.65it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.34it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.99it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.58it/s]100%|██████████| 9/9 [00:04<00:00,  2.23it/s]=> result
* total: 812
* correct: 570
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 68.3%

epoch [10/30] batch [20/392] time 0.288 (0.346) data 0.000 (0.051) loss 1.8682 (2.2136) lr 7.9389e-03 eta 0:47:23
epoch [10/30] batch [40/392] time 0.308 (0.319) data 0.000 (0.026) loss 2.5391 (2.4332) lr 7.9389e-03 eta 0:43:30
epoch [10/30] batch [60/392] time 0.288 (0.309) data 0.000 (0.017) loss 3.2852 (2.6901) lr 7.9389e-03 eta 0:42:04
epoch [10/30] batch [80/392] time 0.284 (0.304) data 0.000 (0.013) loss 2.8672 (2.6216) lr 7.9389e-03 eta 0:41:19
epoch [10/30] batch [100/392] time 0.284 (0.301) data 0.000 (0.011) loss 1.8008 (2.6392) lr 7.9389e-03 eta 0:40:46
epoch [10/30] batch [120/392] time 0.281 (0.299) data 0.000 (0.009) loss 2.3438 (2.6512) lr 7.9389e-03 eta 0:40:28
epoch [10/30] batch [140/392] time 0.310 (0.298) data 0.000 (0.008) loss 1.4277 (2.6250) lr 7.9389e-03 eta 0:40:11
epoch [10/30] batch [160/392] time 0.286 (0.298) data 0.000 (0.007) loss 1.2725 (2.5561) lr 7.9389e-03 eta 0:40:01
epoch [10/30] batch [180/392] time 0.325 (0.297) data 0.000 (0.006) loss 2.0801 (2.5404) lr 7.9389e-03 eta 0:39:49
epoch [10/30] batch [200/392] time 0.301 (0.296) data 0.000 (0.005) loss 3.8105 (2.5817) lr 7.9389e-03 eta 0:39:39
epoch [10/30] batch [220/392] time 0.279 (0.296) data 0.000 (0.005) loss 2.2969 (2.5530) lr 7.9389e-03 eta 0:39:32
epoch [10/30] batch [240/392] time 0.276 (0.296) data 0.000 (0.005) loss 2.7051 (2.6059) lr 7.9389e-03 eta 0:39:22
epoch [10/30] batch [260/392] time 0.290 (0.295) data 0.000 (0.004) loss 0.9541 (2.6006) lr 7.9389e-03 eta 0:39:13
epoch [10/30] batch [280/392] time 0.296 (0.295) data 0.000 (0.004) loss 2.5137 (2.6063) lr 7.9389e-03 eta 0:39:05
epoch [10/30] batch [300/392] time 0.279 (0.294) data 0.000 (0.004) loss 3.3164 (2.6141) lr 7.9389e-03 eta 0:38:55
epoch [10/30] batch [320/392] time 0.287 (0.295) data 0.000 (0.003) loss 1.2705 (2.6145) lr 7.9389e-03 eta 0:38:51
epoch [10/30] batch [340/392] time 0.292 (0.294) data 0.000 (0.003) loss 3.3418 (2.6027) lr 7.9389e-03 eta 0:38:42
epoch [10/30] batch [360/392] time 0.302 (0.294) data 0.000 (0.003) loss 3.8828 (2.5848) lr 7.9389e-03 eta 0:38:36
epoch [10/30] batch [380/392] time 0.270 (0.293) data 0.000 (0.003) loss 3.4355 (2.5805) lr 7.9389e-03 eta 0:38:20
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.73s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.22s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.37it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.00it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.67it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.36it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.01it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.59it/s]100%|██████████| 9/9 [00:03<00:00,  2.26it/s]=> result
* total: 812
* correct: 572
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 69.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/392] time 0.289 (0.354) data 0.000 (0.050) loss 4.4766 (2.5071) lr 7.5000e-03 eta 0:46:07
epoch [11/30] batch [40/392] time 0.283 (0.324) data 0.000 (0.025) loss 2.5176 (2.3660) lr 7.5000e-03 eta 0:42:07
epoch [11/30] batch [60/392] time 0.293 (0.313) data 0.001 (0.017) loss 2.8555 (2.4156) lr 7.5000e-03 eta 0:40:36
epoch [11/30] batch [80/392] time 0.286 (0.308) data 0.000 (0.013) loss 2.8203 (2.5594) lr 7.5000e-03 eta 0:39:47
epoch [11/30] batch [100/392] time 0.282 (0.304) data 0.000 (0.010) loss 1.0146 (2.5171) lr 7.5000e-03 eta 0:39:15
epoch [11/30] batch [120/392] time 0.298 (0.302) data 0.000 (0.009) loss 1.5312 (2.5457) lr 7.5000e-03 eta 0:38:49
epoch [11/30] batch [140/392] time 0.300 (0.302) data 0.000 (0.007) loss 4.3281 (2.4818) lr 7.5000e-03 eta 0:38:43
epoch [11/30] batch [160/392] time 0.286 (0.300) data 0.000 (0.006) loss 1.7441 (2.4817) lr 7.5000e-03 eta 0:38:26
epoch [11/30] batch [180/392] time 0.324 (0.299) data 0.000 (0.006) loss 1.2510 (2.5138) lr 7.5000e-03 eta 0:38:12
epoch [11/30] batch [200/392] time 0.298 (0.299) data 0.000 (0.005) loss 1.6797 (2.4963) lr 7.5000e-03 eta 0:38:03
epoch [11/30] batch [220/392] time 0.294 (0.299) data 0.000 (0.005) loss 4.9297 (2.5282) lr 7.5000e-03 eta 0:37:55
epoch [11/30] batch [240/392] time 0.287 (0.299) data 0.000 (0.004) loss 5.2344 (2.5255) lr 7.5000e-03 eta 0:37:49
epoch [11/30] batch [260/392] time 0.283 (0.298) data 0.000 (0.004) loss 4.5898 (2.5302) lr 7.5000e-03 eta 0:37:39
epoch [11/30] batch [280/392] time 0.318 (0.298) data 0.000 (0.004) loss 7.3203 (2.5388) lr 7.5000e-03 eta 0:37:30
epoch [11/30] batch [300/392] time 0.283 (0.297) data 0.000 (0.004) loss 1.9600 (2.5117) lr 7.5000e-03 eta 0:37:22
epoch [11/30] batch [320/392] time 0.284 (0.297) data 0.000 (0.003) loss 2.7070 (2.5127) lr 7.5000e-03 eta 0:37:15
epoch [11/30] batch [340/392] time 0.287 (0.297) data 0.000 (0.003) loss 1.3213 (2.5310) lr 7.5000e-03 eta 0:37:05
epoch [11/30] batch [360/392] time 0.310 (0.297) data 0.000 (0.003) loss 2.6289 (2.5327) lr 7.5000e-03 eta 0:36:58
epoch [11/30] batch [380/392] time 0.271 (0.295) data 0.000 (0.003) loss 2.5605 (2.5382) lr 7.5000e-03 eta 0:36:42
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.65s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.18s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.40it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.04it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.72it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.41it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.05it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.63it/s]100%|██████████| 9/9 [00:03<00:00,  2.29it/s]=> result
* total: 812
* correct: 570
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 69.1%

epoch [12/30] batch [20/392] time 0.334 (0.352) data 0.000 (0.053) loss 1.8271 (3.0760) lr 7.0337e-03 eta 0:43:35
epoch [12/30] batch [40/392] time 0.300 (0.324) data 0.000 (0.026) loss 1.1201 (2.5987) lr 7.0337e-03 eta 0:40:00
epoch [12/30] batch [60/392] time 0.283 (0.312) data 0.000 (0.018) loss 1.8457 (2.4512) lr 7.0337e-03 eta 0:38:28
epoch [12/30] batch [80/392] time 0.299 (0.307) data 0.000 (0.013) loss 5.6992 (2.5266) lr 7.0337e-03 eta 0:37:42
epoch [12/30] batch [100/392] time 0.290 (0.303) data 0.000 (0.011) loss 5.1211 (2.4903) lr 7.0337e-03 eta 0:37:09
epoch [12/30] batch [120/392] time 0.278 (0.301) data 0.000 (0.009) loss 2.3594 (2.5054) lr 7.0337e-03 eta 0:36:46
epoch [12/30] batch [140/392] time 0.291 (0.299) data 0.000 (0.008) loss 3.1250 (2.5440) lr 7.0337e-03 eta 0:36:27
epoch [12/30] batch [160/392] time 0.300 (0.299) data 0.000 (0.007) loss 1.4932 (2.6199) lr 7.0337e-03 eta 0:36:19
epoch [12/30] batch [180/392] time 0.281 (0.298) data 0.000 (0.006) loss 2.4570 (2.6881) lr 7.0337e-03 eta 0:36:05
epoch [12/30] batch [200/392] time 0.281 (0.297) data 0.000 (0.005) loss 4.1719 (2.7064) lr 7.0337e-03 eta 0:35:55
epoch [12/30] batch [220/392] time 0.289 (0.297) data 0.000 (0.005) loss 1.9150 (2.7292) lr 7.0337e-03 eta 0:35:45
epoch [12/30] batch [240/392] time 0.277 (0.296) data 0.000 (0.005) loss 6.3203 (2.7728) lr 7.0337e-03 eta 0:35:36
epoch [12/30] batch [260/392] time 0.292 (0.297) data 0.000 (0.004) loss 2.8770 (2.7592) lr 7.0337e-03 eta 0:35:33
epoch [12/30] batch [280/392] time 0.275 (0.296) data 0.000 (0.004) loss 4.7656 (2.7405) lr 7.0337e-03 eta 0:35:22
epoch [12/30] batch [300/392] time 0.306 (0.296) data 0.000 (0.004) loss 3.0684 (2.7505) lr 7.0337e-03 eta 0:35:15
epoch [12/30] batch [320/392] time 0.290 (0.296) data 0.000 (0.004) loss 2.4551 (2.7097) lr 7.0337e-03 eta 0:35:10
epoch [12/30] batch [340/392] time 0.302 (0.296) data 0.000 (0.003) loss 2.2676 (2.7034) lr 7.0337e-03 eta 0:35:01
epoch [12/30] batch [360/392] time 0.283 (0.296) data 0.000 (0.003) loss 2.9844 (2.6903) lr 7.0337e-03 eta 0:34:55
epoch [12/30] batch [380/392] time 0.268 (0.294) data 0.000 (0.003) loss 0.7661 (2.6786) lr 7.0337e-03 eta 0:34:39
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.62s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.18s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.41it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.05it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.73it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.42it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.06it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.65it/s]100%|██████████| 9/9 [00:03<00:00,  2.30it/s]=> result
* total: 812
* correct: 587
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 71.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [13/30] batch [20/392] time 0.283 (0.346) data 0.000 (0.054) loss 1.3867 (2.3518) lr 6.5451e-03 eta 0:40:37
epoch [13/30] batch [40/392] time 0.281 (0.320) data 0.000 (0.027) loss 1.4727 (2.2471) lr 6.5451e-03 eta 0:37:28
epoch [13/30] batch [60/392] time 0.291 (0.311) data 0.000 (0.018) loss 2.9590 (2.3313) lr 6.5451e-03 eta 0:36:13
epoch [13/30] batch [80/392] time 0.280 (0.305) data 0.000 (0.014) loss 1.9775 (2.3189) lr 6.5451e-03 eta 0:35:25
epoch [13/30] batch [100/392] time 0.293 (0.302) data 0.000 (0.011) loss 1.6631 (2.3601) lr 6.5451e-03 eta 0:35:02
epoch [13/30] batch [120/392] time 0.288 (0.301) data 0.000 (0.009) loss 2.4473 (2.3312) lr 6.5451e-03 eta 0:34:44
epoch [13/30] batch [140/392] time 0.283 (0.299) data 0.000 (0.008) loss 5.7891 (2.4376) lr 6.5451e-03 eta 0:34:25
epoch [13/30] batch [160/392] time 0.285 (0.298) data 0.000 (0.007) loss 1.1855 (2.4985) lr 6.5451e-03 eta 0:34:13
epoch [13/30] batch [180/392] time 0.283 (0.297) data 0.000 (0.006) loss 2.0938 (2.4920) lr 6.5451e-03 eta 0:34:04
epoch [13/30] batch [200/392] time 0.284 (0.297) data 0.000 (0.006) loss 1.6182 (2.4872) lr 6.5451e-03 eta 0:33:57
epoch [13/30] batch [220/392] time 0.287 (0.297) data 0.000 (0.005) loss 2.1797 (2.4643) lr 6.5451e-03 eta 0:33:48
epoch [13/30] batch [240/392] time 0.281 (0.296) data 0.000 (0.005) loss 1.3320 (2.4406) lr 6.5451e-03 eta 0:33:39
epoch [13/30] batch [260/392] time 0.274 (0.297) data 0.000 (0.004) loss 1.1240 (2.4595) lr 6.5451e-03 eta 0:33:36
epoch [13/30] batch [280/392] time 0.290 (0.296) data 0.000 (0.004) loss 1.0576 (2.4443) lr 6.5451e-03 eta 0:33:27
epoch [13/30] batch [300/392] time 0.290 (0.296) data 0.000 (0.004) loss 2.3867 (2.4050) lr 6.5451e-03 eta 0:33:19
epoch [13/30] batch [320/392] time 0.280 (0.296) data 0.000 (0.004) loss 2.1621 (2.4073) lr 6.5451e-03 eta 0:33:11
epoch [13/30] batch [340/392] time 0.304 (0.295) data 0.000 (0.003) loss 1.2197 (2.4090) lr 6.5451e-03 eta 0:33:04
epoch [13/30] batch [360/392] time 0.324 (0.295) data 0.000 (0.003) loss 1.0039 (2.4160) lr 6.5451e-03 eta 0:32:57
epoch [13/30] batch [380/392] time 0.272 (0.294) data 0.000 (0.003) loss 1.7529 (2.4173) lr 6.5451e-03 eta 0:32:42
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.83s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.26s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.33it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.94it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.61it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.29it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.94it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.53it/s]100%|██████████| 9/9 [00:04<00:00,  2.19it/s]=> result
* total: 812
* correct: 585
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 70.8%

epoch [14/30] batch [20/392] time 0.290 (0.349) data 0.000 (0.049) loss 2.4492 (2.9676) lr 6.0396e-03 eta 0:38:37
epoch [14/30] batch [40/392] time 0.313 (0.322) data 0.000 (0.025) loss 1.2529 (2.5644) lr 6.0396e-03 eta 0:35:30
epoch [14/30] batch [60/392] time 0.293 (0.311) data 0.000 (0.017) loss 3.3926 (2.4260) lr 6.0396e-03 eta 0:34:14
epoch [14/30] batch [80/392] time 0.274 (0.307) data 0.000 (0.013) loss 2.4082 (2.3925) lr 6.0396e-03 eta 0:33:38
epoch [14/30] batch [100/392] time 0.289 (0.303) data 0.000 (0.010) loss 2.4883 (2.4229) lr 6.0396e-03 eta 0:33:08
epoch [14/30] batch [120/392] time 0.294 (0.301) data 0.000 (0.008) loss 1.3076 (2.3772) lr 6.0396e-03 eta 0:32:48
epoch [14/30] batch [140/392] time 0.320 (0.300) data 0.000 (0.007) loss 1.5381 (2.5340) lr 6.0396e-03 eta 0:32:37
epoch [14/30] batch [160/392] time 0.305 (0.299) data 0.000 (0.006) loss 1.8643 (2.4904) lr 6.0396e-03 eta 0:32:25
epoch [14/30] batch [180/392] time 0.295 (0.298) data 0.000 (0.006) loss 4.7070 (2.5066) lr 6.0396e-03 eta 0:32:12
epoch [14/30] batch [200/392] time 0.288 (0.297) data 0.000 (0.005) loss 4.8281 (2.5180) lr 6.0396e-03 eta 0:32:01
epoch [14/30] batch [220/392] time 0.293 (0.297) data 0.000 (0.005) loss 2.3828 (2.5087) lr 6.0396e-03 eta 0:31:55
epoch [14/30] batch [240/392] time 0.280 (0.297) data 0.000 (0.004) loss 0.7197 (2.4715) lr 6.0396e-03 eta 0:31:46
epoch [14/30] batch [260/392] time 0.296 (0.297) data 0.000 (0.004) loss 1.4668 (2.4520) lr 6.0396e-03 eta 0:31:39
epoch [14/30] batch [280/392] time 0.292 (0.296) data 0.000 (0.004) loss 1.5469 (2.4599) lr 6.0396e-03 eta 0:31:31
epoch [14/30] batch [300/392] time 0.292 (0.296) data 0.000 (0.004) loss 1.2891 (2.4350) lr 6.0396e-03 eta 0:31:24
epoch [14/30] batch [320/392] time 0.290 (0.296) data 0.000 (0.003) loss 1.3008 (2.4281) lr 6.0396e-03 eta 0:31:14
epoch [14/30] batch [340/392] time 0.279 (0.296) data 0.000 (0.003) loss 6.7812 (2.4586) lr 6.0396e-03 eta 0:31:09
epoch [14/30] batch [360/392] time 0.300 (0.296) data 0.000 (0.003) loss 4.6953 (2.4631) lr 6.0396e-03 eta 0:31:02
epoch [14/30] batch [380/392] time 0.272 (0.294) data 0.000 (0.003) loss 1.2725 (2.4786) lr 6.0396e-03 eta 0:30:49
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.53s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.18s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.35it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.96it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.63it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.31it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.96it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.55it/s]100%|██████████| 9/9 [00:03<00:00,  2.28it/s]=> result
* total: 812
* correct: 590
* accuracy: 72.7%
* error: 27.3%
* macro_f1: 71.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/392] time 0.278 (0.352) data 0.000 (0.051) loss 3.9141 (2.5217) lr 5.5226e-03 eta 0:36:38
epoch [15/30] batch [40/392] time 0.276 (0.320) data 0.000 (0.026) loss 0.9971 (2.2803) lr 5.5226e-03 eta 0:33:16
epoch [15/30] batch [60/392] time 0.282 (0.310) data 0.000 (0.017) loss 4.2461 (2.3036) lr 5.5226e-03 eta 0:32:03
epoch [15/30] batch [80/392] time 0.277 (0.305) data 0.000 (0.013) loss 4.9844 (2.3945) lr 5.5226e-03 eta 0:31:28
epoch [15/30] batch [100/392] time 0.292 (0.302) data 0.000 (0.010) loss 3.4727 (2.4480) lr 5.5226e-03 eta 0:31:02
epoch [15/30] batch [120/392] time 0.288 (0.300) data 0.000 (0.009) loss 3.5762 (2.4283) lr 5.5226e-03 eta 0:30:47
epoch [15/30] batch [140/392] time 0.281 (0.300) data 0.000 (0.008) loss 4.1406 (2.3645) lr 5.5226e-03 eta 0:30:38
epoch [15/30] batch [160/392] time 0.297 (0.299) data 0.000 (0.007) loss 1.2021 (2.3674) lr 5.5226e-03 eta 0:30:25
epoch [15/30] batch [180/392] time 0.294 (0.297) data 0.000 (0.006) loss 2.0430 (2.4094) lr 5.5226e-03 eta 0:30:09
epoch [15/30] batch [200/392] time 0.284 (0.296) data 0.000 (0.005) loss 2.1250 (2.4472) lr 5.5226e-03 eta 0:30:00
epoch [15/30] batch [220/392] time 0.295 (0.296) data 0.000 (0.005) loss 1.1611 (2.4561) lr 5.5226e-03 eta 0:29:50
epoch [15/30] batch [240/392] time 0.336 (0.296) data 0.000 (0.005) loss 2.3359 (2.4318) lr 5.5226e-03 eta 0:29:45
epoch [15/30] batch [260/392] time 0.293 (0.296) data 0.000 (0.004) loss 2.5508 (2.4039) lr 5.5226e-03 eta 0:29:37
epoch [15/30] batch [280/392] time 0.313 (0.295) data 0.000 (0.004) loss 3.1914 (2.3951) lr 5.5226e-03 eta 0:29:29
epoch [15/30] batch [300/392] time 0.296 (0.295) data 0.000 (0.004) loss 0.7007 (2.3914) lr 5.5226e-03 eta 0:29:21
epoch [15/30] batch [320/392] time 0.280 (0.294) data 0.000 (0.003) loss 3.7266 (2.4138) lr 5.5226e-03 eta 0:29:12
epoch [15/30] batch [340/392] time 0.301 (0.294) data 0.000 (0.003) loss 2.2676 (2.4288) lr 5.5226e-03 eta 0:29:05
epoch [15/30] batch [360/392] time 0.303 (0.294) data 0.000 (0.003) loss 4.7422 (2.4319) lr 5.5226e-03 eta 0:29:01
epoch [15/30] batch [380/392] time 0.271 (0.293) data 0.000 (0.003) loss 4.5391 (2.4225) lr 5.5226e-03 eta 0:28:48
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.59s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.16s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.43it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.08it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.76it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.45it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.09it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.67it/s]100%|██████████| 9/9 [00:03<00:00,  2.33it/s]=> result
* total: 812
* correct: 575
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 69.6%

epoch [16/30] batch [20/392] time 0.283 (0.346) data 0.000 (0.050) loss 2.1465 (2.4471) lr 5.0000e-03 eta 0:33:50
epoch [16/30] batch [40/392] time 0.287 (0.319) data 0.000 (0.025) loss 1.7871 (2.2417) lr 5.0000e-03 eta 0:31:04
epoch [16/30] batch [60/392] time 0.290 (0.310) data 0.000 (0.017) loss 2.7852 (2.2799) lr 5.0000e-03 eta 0:30:03
epoch [16/30] batch [80/392] time 0.285 (0.305) data 0.000 (0.013) loss 1.1309 (2.2367) lr 5.0000e-03 eta 0:29:28
epoch [16/30] batch [100/392] time 0.294 (0.303) data 0.000 (0.010) loss 2.3242 (2.2828) lr 5.0000e-03 eta 0:29:08
epoch [16/30] batch [120/392] time 0.308 (0.301) data 0.000 (0.009) loss 2.7012 (2.2841) lr 5.0000e-03 eta 0:28:52
epoch [16/30] batch [140/392] time 0.288 (0.300) data 0.000 (0.007) loss 3.0332 (2.3249) lr 5.0000e-03 eta 0:28:39
epoch [16/30] batch [160/392] time 0.302 (0.299) data 0.000 (0.007) loss 1.7803 (2.2813) lr 5.0000e-03 eta 0:28:27
epoch [16/30] batch [180/392] time 0.284 (0.297) data 0.000 (0.006) loss 2.8477 (2.3056) lr 5.0000e-03 eta 0:28:13
epoch [16/30] batch [200/392] time 0.294 (0.297) data 0.000 (0.005) loss 5.6016 (2.3563) lr 5.0000e-03 eta 0:28:05
epoch [16/30] batch [220/392] time 0.285 (0.296) data 0.000 (0.005) loss 4.6719 (2.4196) lr 5.0000e-03 eta 0:27:56
epoch [16/30] batch [240/392] time 0.326 (0.296) data 0.000 (0.004) loss 4.6680 (2.3883) lr 5.0000e-03 eta 0:27:48
epoch [16/30] batch [260/392] time 0.290 (0.296) data 0.000 (0.004) loss 4.6992 (2.4449) lr 5.0000e-03 eta 0:27:41
epoch [16/30] batch [280/392] time 0.337 (0.296) data 0.000 (0.004) loss 2.9062 (2.4462) lr 5.0000e-03 eta 0:27:37
epoch [16/30] batch [300/392] time 0.279 (0.296) data 0.000 (0.004) loss 4.5781 (2.4721) lr 5.0000e-03 eta 0:27:31
epoch [16/30] batch [320/392] time 0.280 (0.296) data 0.000 (0.003) loss 3.4453 (2.4860) lr 5.0000e-03 eta 0:27:23
epoch [16/30] batch [340/392] time 0.289 (0.295) data 0.000 (0.003) loss 2.7617 (2.4760) lr 5.0000e-03 eta 0:27:15
epoch [16/30] batch [360/392] time 0.279 (0.295) data 0.000 (0.003) loss 3.7051 (2.4769) lr 5.0000e-03 eta 0:27:08
epoch [16/30] batch [380/392] time 0.270 (0.294) data 0.000 (0.003) loss 3.3184 (2.4721) lr 5.0000e-03 eta 0:26:56
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.67s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.20s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.39it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.03it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.71it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.39it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.04it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.63it/s]100%|██████████| 9/9 [00:03<00:00,  2.29it/s]=> result
* total: 812
* correct: 583
* accuracy: 71.8%
* error: 28.2%
* macro_f1: 70.8%

epoch [17/30] batch [20/392] time 0.283 (0.349) data 0.000 (0.051) loss 2.0078 (2.8331) lr 4.4774e-03 eta 0:31:50
epoch [17/30] batch [40/392] time 0.285 (0.318) data 0.000 (0.026) loss 5.1094 (2.6123) lr 4.4774e-03 eta 0:28:49
epoch [17/30] batch [60/392] time 0.288 (0.310) data 0.000 (0.017) loss 1.8857 (2.4540) lr 4.4774e-03 eta 0:28:02
epoch [17/30] batch [80/392] time 0.279 (0.305) data 0.000 (0.013) loss 1.3506 (2.3889) lr 4.4774e-03 eta 0:27:27
epoch [17/30] batch [100/392] time 0.281 (0.302) data 0.000 (0.010) loss 3.6484 (2.4335) lr 4.4774e-03 eta 0:27:04
epoch [17/30] batch [120/392] time 0.291 (0.300) data 0.000 (0.009) loss 5.0781 (2.4623) lr 4.4774e-03 eta 0:26:50
epoch [17/30] batch [140/392] time 0.279 (0.298) data 0.000 (0.008) loss 1.0088 (2.4494) lr 4.4774e-03 eta 0:26:35
epoch [17/30] batch [160/392] time 0.301 (0.297) data 0.000 (0.007) loss 3.2461 (2.4726) lr 4.4774e-03 eta 0:26:23
epoch [17/30] batch [180/392] time 0.286 (0.297) data 0.000 (0.006) loss 0.3418 (2.4722) lr 4.4774e-03 eta 0:26:15
epoch [17/30] batch [200/392] time 0.291 (0.297) data 0.000 (0.005) loss 2.6719 (2.4797) lr 4.4774e-03 eta 0:26:08
epoch [17/30] batch [220/392] time 0.283 (0.297) data 0.000 (0.005) loss 2.7227 (2.5420) lr 4.4774e-03 eta 0:26:01
epoch [17/30] batch [240/392] time 0.304 (0.296) data 0.000 (0.004) loss 1.5166 (2.5181) lr 4.4774e-03 eta 0:25:51
epoch [17/30] batch [260/392] time 0.282 (0.295) data 0.000 (0.004) loss 2.0547 (2.4897) lr 4.4774e-03 eta 0:25:43
epoch [17/30] batch [280/392] time 0.294 (0.295) data 0.000 (0.004) loss 2.1543 (2.4949) lr 4.4774e-03 eta 0:25:37
epoch [17/30] batch [300/392] time 0.286 (0.295) data 0.000 (0.004) loss 0.7720 (2.4983) lr 4.4774e-03 eta 0:25:28
epoch [17/30] batch [320/392] time 0.325 (0.295) data 0.000 (0.003) loss 1.1816 (2.4728) lr 4.4774e-03 eta 0:25:22
epoch [17/30] batch [340/392] time 0.291 (0.295) data 0.000 (0.003) loss 0.5703 (2.4721) lr 4.4774e-03 eta 0:25:17
epoch [17/30] batch [360/392] time 0.311 (0.295) data 0.001 (0.003) loss 2.3398 (2.4974) lr 4.4774e-03 eta 0:25:11
epoch [17/30] batch [380/392] time 0.270 (0.294) data 0.000 (0.003) loss 2.2246 (2.4892) lr 4.4774e-03 eta 0:24:59
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.77s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.25s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.34it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.96it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.60it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.28it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.92it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.51it/s]100%|██████████| 9/9 [00:04<00:00,  2.20it/s]=> result
* total: 812
* correct: 595
* accuracy: 73.3%
* error: 26.7%
* macro_f1: 72.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/392] time 0.292 (0.371) data 0.000 (0.066) loss 1.5635 (1.7829) lr 3.9604e-03 eta 0:31:23
epoch [18/30] batch [40/392] time 0.284 (0.330) data 0.000 (0.033) loss 3.7812 (2.0559) lr 3.9604e-03 eta 0:27:49
epoch [18/30] batch [60/392] time 0.291 (0.318) data 0.000 (0.022) loss 2.4336 (2.1742) lr 3.9604e-03 eta 0:26:39
epoch [18/30] batch [80/392] time 0.305 (0.311) data 0.000 (0.017) loss 1.1914 (2.2179) lr 3.9604e-03 eta 0:26:00
epoch [18/30] batch [100/392] time 0.284 (0.306) data 0.000 (0.013) loss 3.1250 (2.2329) lr 3.9604e-03 eta 0:25:29
epoch [18/30] batch [120/392] time 0.283 (0.303) data 0.000 (0.011) loss 3.0391 (2.2334) lr 3.9604e-03 eta 0:25:07
epoch [18/30] batch [140/392] time 0.288 (0.301) data 0.000 (0.010) loss 4.1523 (2.2039) lr 3.9604e-03 eta 0:24:52
epoch [18/30] batch [160/392] time 0.290 (0.300) data 0.000 (0.009) loss 4.3672 (2.2677) lr 3.9604e-03 eta 0:24:41
epoch [18/30] batch [180/392] time 0.288 (0.300) data 0.000 (0.008) loss 0.3359 (2.2402) lr 3.9604e-03 eta 0:24:33
epoch [18/30] batch [200/392] time 0.286 (0.299) data 0.000 (0.007) loss 1.4580 (2.2463) lr 3.9604e-03 eta 0:24:25
epoch [18/30] batch [220/392] time 0.280 (0.298) data 0.000 (0.006) loss 1.0850 (2.2027) lr 3.9604e-03 eta 0:24:14
epoch [18/30] batch [240/392] time 0.297 (0.298) data 0.000 (0.006) loss 1.9385 (2.2265) lr 3.9604e-03 eta 0:24:05
epoch [18/30] batch [260/392] time 0.297 (0.297) data 0.000 (0.005) loss 2.8320 (2.2470) lr 3.9604e-03 eta 0:23:57
epoch [18/30] batch [280/392] time 0.299 (0.297) data 0.000 (0.005) loss 1.5010 (2.2397) lr 3.9604e-03 eta 0:23:50
epoch [18/30] batch [300/392] time 0.276 (0.297) data 0.000 (0.005) loss 2.6504 (2.2457) lr 3.9604e-03 eta 0:23:43
epoch [18/30] batch [320/392] time 0.296 (0.297) data 0.000 (0.004) loss 1.7373 (2.2634) lr 3.9604e-03 eta 0:23:36
epoch [18/30] batch [340/392] time 0.294 (0.296) data 0.000 (0.004) loss 2.0840 (2.2579) lr 3.9604e-03 eta 0:23:28
epoch [18/30] batch [360/392] time 0.280 (0.296) data 0.000 (0.004) loss 2.4375 (2.2764) lr 3.9604e-03 eta 0:23:21
epoch [18/30] batch [380/392] time 0.271 (0.295) data 0.000 (0.004) loss 3.4883 (2.2997) lr 3.9604e-03 eta 0:23:10
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.82s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.25s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.34it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.95it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.62it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.30it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.96it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.54it/s]100%|██████████| 9/9 [00:04<00:00,  2.20it/s]=> result
* total: 812
* correct: 601
* accuracy: 74.0%
* error: 26.0%
* macro_f1: 73.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/392] time 0.285 (0.350) data 0.000 (0.054) loss 3.0312 (2.4160) lr 3.4549e-03 eta 0:27:18
epoch [19/30] batch [40/392] time 0.315 (0.320) data 0.000 (0.027) loss 1.1377 (2.3389) lr 3.4549e-03 eta 0:24:50
epoch [19/30] batch [60/392] time 0.289 (0.309) data 0.000 (0.018) loss 3.2734 (2.4237) lr 3.4549e-03 eta 0:23:56
epoch [19/30] batch [80/392] time 0.296 (0.307) data 0.000 (0.014) loss 3.4570 (2.4915) lr 3.4549e-03 eta 0:23:38
epoch [19/30] batch [100/392] time 0.285 (0.303) data 0.000 (0.011) loss 5.3125 (2.4433) lr 3.4549e-03 eta 0:23:16
epoch [19/30] batch [120/392] time 0.285 (0.301) data 0.000 (0.009) loss 2.4824 (2.3299) lr 3.4549e-03 eta 0:23:01
epoch [19/30] batch [140/392] time 0.298 (0.301) data 0.000 (0.008) loss 1.3740 (2.3284) lr 3.4549e-03 eta 0:22:52
epoch [19/30] batch [160/392] time 0.281 (0.300) data 0.000 (0.007) loss 2.4629 (2.3100) lr 3.4549e-03 eta 0:22:42
epoch [19/30] batch [180/392] time 0.284 (0.298) data 0.000 (0.006) loss 2.3516 (2.2719) lr 3.4549e-03 eta 0:22:30
epoch [19/30] batch [200/392] time 0.285 (0.298) data 0.000 (0.006) loss 3.5527 (2.2920) lr 3.4549e-03 eta 0:22:22
epoch [19/30] batch [220/392] time 0.295 (0.297) data 0.000 (0.005) loss 1.7090 (2.2651) lr 3.4549e-03 eta 0:22:13
epoch [19/30] batch [240/392] time 0.291 (0.297) data 0.000 (0.005) loss 4.2812 (2.2809) lr 3.4549e-03 eta 0:22:04
epoch [19/30] batch [260/392] time 0.281 (0.296) data 0.000 (0.004) loss 2.8164 (2.3140) lr 3.4549e-03 eta 0:21:56
epoch [19/30] batch [280/392] time 0.284 (0.296) data 0.000 (0.004) loss 1.8389 (2.3397) lr 3.4549e-03 eta 0:21:48
epoch [19/30] batch [300/392] time 0.281 (0.295) data 0.000 (0.004) loss 2.1367 (2.3428) lr 3.4549e-03 eta 0:21:40
epoch [19/30] batch [320/392] time 0.280 (0.295) data 0.000 (0.004) loss 2.2969 (2.3480) lr 3.4549e-03 eta 0:21:32
epoch [19/30] batch [340/392] time 0.282 (0.295) data 0.000 (0.003) loss 1.8398 (2.3531) lr 3.4549e-03 eta 0:21:25
epoch [19/30] batch [360/392] time 0.286 (0.295) data 0.000 (0.003) loss 0.6572 (2.3515) lr 3.4549e-03 eta 0:21:20
epoch [19/30] batch [380/392] time 0.275 (0.294) data 0.000 (0.003) loss 2.8184 (2.3407) lr 3.4549e-03 eta 0:21:09
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.86s/it] 22%|██▏       | 2/9 [00:03<00:08,  1.27s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.32it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.93it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.59it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.27it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.92it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.52it/s]100%|██████████| 9/9 [00:04<00:00,  2.18it/s]=> result
* total: 812
* correct: 594
* accuracy: 73.2%
* error: 26.8%
* macro_f1: 72.2%

epoch [20/30] batch [20/392] time 0.299 (0.354) data 0.000 (0.053) loss 3.9141 (2.5186) lr 2.9663e-03 eta 0:25:18
epoch [20/30] batch [40/392] time 0.300 (0.324) data 0.000 (0.026) loss 1.2539 (2.3726) lr 2.9663e-03 eta 0:23:05
epoch [20/30] batch [60/392] time 0.278 (0.313) data 0.000 (0.018) loss 1.1699 (2.4388) lr 2.9663e-03 eta 0:22:09
epoch [20/30] batch [80/392] time 0.317 (0.307) data 0.000 (0.013) loss 5.0703 (2.3365) lr 2.9663e-03 eta 0:21:40
epoch [20/30] batch [100/392] time 0.280 (0.304) data 0.000 (0.011) loss 1.0596 (2.2920) lr 2.9663e-03 eta 0:21:20
epoch [20/30] batch [120/392] time 0.277 (0.302) data 0.000 (0.009) loss 2.0840 (2.4048) lr 2.9663e-03 eta 0:21:04
epoch [20/30] batch [140/392] time 0.295 (0.300) data 0.000 (0.008) loss 2.0918 (2.3938) lr 2.9663e-03 eta 0:20:50
epoch [20/30] batch [160/392] time 0.285 (0.299) data 0.000 (0.007) loss 2.6895 (2.3830) lr 2.9663e-03 eta 0:20:41
epoch [20/30] batch [180/392] time 0.282 (0.298) data 0.000 (0.006) loss 3.9355 (2.3754) lr 2.9663e-03 eta 0:20:30
epoch [20/30] batch [200/392] time 0.291 (0.297) data 0.000 (0.006) loss 1.6875 (2.3954) lr 2.9663e-03 eta 0:20:20
epoch [20/30] batch [220/392] time 0.288 (0.296) data 0.000 (0.005) loss 1.5498 (2.4345) lr 2.9663e-03 eta 0:20:10
epoch [20/30] batch [240/392] time 0.283 (0.295) data 0.000 (0.005) loss 1.3145 (2.4472) lr 2.9663e-03 eta 0:20:02
epoch [20/30] batch [260/392] time 0.279 (0.295) data 0.000 (0.004) loss 3.1973 (2.4226) lr 2.9663e-03 eta 0:19:54
epoch [20/30] batch [280/392] time 0.283 (0.295) data 0.000 (0.004) loss 1.8584 (2.4269) lr 2.9663e-03 eta 0:19:48
epoch [20/30] batch [300/392] time 0.308 (0.295) data 0.000 (0.004) loss 2.1504 (2.4283) lr 2.9663e-03 eta 0:19:42
epoch [20/30] batch [320/392] time 0.294 (0.294) data 0.000 (0.004) loss 4.0469 (2.4330) lr 2.9663e-03 eta 0:19:34
epoch [20/30] batch [340/392] time 0.305 (0.294) data 0.001 (0.003) loss 1.3818 (2.4312) lr 2.9663e-03 eta 0:19:28
epoch [20/30] batch [360/392] time 0.290 (0.295) data 0.000 (0.003) loss 0.4521 (2.4346) lr 2.9663e-03 eta 0:19:24
epoch [20/30] batch [380/392] time 0.269 (0.293) data 0.000 (0.003) loss 3.1719 (2.4156) lr 2.9663e-03 eta 0:19:13
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.58s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.18s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.41it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.04it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.73it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.41it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.06it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.63it/s]100%|██████████| 9/9 [00:03<00:00,  2.31it/s]=> result
* total: 812
* correct: 592
* accuracy: 72.9%
* error: 27.1%
* macro_f1: 72.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/392] time 0.293 (0.349) data 0.000 (0.053) loss 1.5996 (2.3783) lr 2.5000e-03 eta 0:22:40
epoch [21/30] batch [40/392] time 0.283 (0.321) data 0.000 (0.027) loss 3.5898 (2.3598) lr 2.5000e-03 eta 0:20:45
epoch [21/30] batch [60/392] time 0.299 (0.309) data 0.000 (0.018) loss 2.0996 (2.3865) lr 2.5000e-03 eta 0:19:53
epoch [21/30] batch [80/392] time 0.286 (0.305) data 0.000 (0.014) loss 1.7686 (2.3258) lr 2.5000e-03 eta 0:19:33
epoch [21/30] batch [100/392] time 0.281 (0.303) data 0.000 (0.011) loss 2.4297 (2.3553) lr 2.5000e-03 eta 0:19:17
epoch [21/30] batch [120/392] time 0.293 (0.302) data 0.000 (0.009) loss 0.9121 (2.3036) lr 2.5000e-03 eta 0:19:05
epoch [21/30] batch [140/392] time 0.283 (0.300) data 0.000 (0.008) loss 3.0117 (2.2940) lr 2.5000e-03 eta 0:18:52
epoch [21/30] batch [160/392] time 0.287 (0.299) data 0.000 (0.007) loss 1.3760 (2.3097) lr 2.5000e-03 eta 0:18:45
epoch [21/30] batch [180/392] time 0.293 (0.299) data 0.000 (0.006) loss 2.1211 (2.3037) lr 2.5000e-03 eta 0:18:36
epoch [21/30] batch [200/392] time 0.282 (0.298) data 0.000 (0.006) loss 4.7070 (2.3060) lr 2.5000e-03 eta 0:18:27
epoch [21/30] batch [220/392] time 0.281 (0.297) data 0.000 (0.005) loss 1.7236 (2.2958) lr 2.5000e-03 eta 0:18:18
epoch [21/30] batch [240/392] time 0.277 (0.296) data 0.000 (0.005) loss 1.0352 (2.2572) lr 2.5000e-03 eta 0:18:10
epoch [21/30] batch [260/392] time 0.278 (0.296) data 0.000 (0.004) loss 1.7979 (2.2605) lr 2.5000e-03 eta 0:18:02
epoch [21/30] batch [280/392] time 0.295 (0.295) data 0.000 (0.004) loss 1.1504 (2.2701) lr 2.5000e-03 eta 0:17:55
epoch [21/30] batch [300/392] time 0.290 (0.296) data 0.000 (0.004) loss 2.9121 (2.3029) lr 2.5000e-03 eta 0:17:50
epoch [21/30] batch [320/392] time 0.282 (0.295) data 0.000 (0.004) loss 2.9688 (2.3461) lr 2.5000e-03 eta 0:17:43
epoch [21/30] batch [340/392] time 0.285 (0.295) data 0.000 (0.003) loss 1.3945 (2.3461) lr 2.5000e-03 eta 0:17:36
epoch [21/30] batch [360/392] time 0.309 (0.295) data 0.000 (0.003) loss 1.7832 (2.3453) lr 2.5000e-03 eta 0:17:29
epoch [21/30] batch [380/392] time 0.271 (0.294) data 0.000 (0.003) loss 1.6826 (2.3472) lr 2.5000e-03 eta 0:17:19
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.58s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.16s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.42it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.07it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.75it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.44it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.08it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.66it/s]100%|██████████| 9/9 [00:03<00:00,  2.33it/s]=> result
* total: 812
* correct: 597
* accuracy: 73.5%
* error: 26.5%
* macro_f1: 72.8%

epoch [22/30] batch [20/392] time 0.291 (0.345) data 0.000 (0.054) loss 4.2070 (3.1841) lr 2.0611e-03 eta 0:20:09
epoch [22/30] batch [40/392] time 0.276 (0.320) data 0.000 (0.027) loss 2.7383 (2.8983) lr 2.0611e-03 eta 0:18:35
epoch [22/30] batch [60/392] time 0.288 (0.312) data 0.000 (0.018) loss 1.4170 (2.6291) lr 2.0611e-03 eta 0:18:02
epoch [22/30] batch [80/392] time 0.285 (0.307) data 0.000 (0.014) loss 0.9551 (2.5702) lr 2.0611e-03 eta 0:17:38
epoch [22/30] batch [100/392] time 0.291 (0.305) data 0.000 (0.011) loss 5.0391 (2.4981) lr 2.0611e-03 eta 0:17:24
epoch [22/30] batch [120/392] time 0.279 (0.302) data 0.000 (0.009) loss 3.2383 (2.4981) lr 2.0611e-03 eta 0:17:08
epoch [22/30] batch [140/392] time 0.287 (0.300) data 0.000 (0.008) loss 1.1084 (2.4311) lr 2.0611e-03 eta 0:16:56
epoch [22/30] batch [160/392] time 0.281 (0.299) data 0.000 (0.007) loss 0.2639 (2.4340) lr 2.0611e-03 eta 0:16:46
epoch [22/30] batch [180/392] time 0.295 (0.297) data 0.000 (0.006) loss 3.3184 (2.5189) lr 2.0611e-03 eta 0:16:35
epoch [22/30] batch [200/392] time 0.276 (0.297) data 0.000 (0.006) loss 1.8125 (2.4834) lr 2.0611e-03 eta 0:16:28
epoch [22/30] batch [220/392] time 0.298 (0.297) data 0.000 (0.005) loss 2.3320 (2.4941) lr 2.0611e-03 eta 0:16:22
epoch [22/30] batch [240/392] time 0.307 (0.297) data 0.000 (0.005) loss 2.1270 (2.4641) lr 2.0611e-03 eta 0:16:16
epoch [22/30] batch [260/392] time 0.289 (0.297) data 0.000 (0.004) loss 0.9321 (2.4287) lr 2.0611e-03 eta 0:16:09
epoch [22/30] batch [280/392] time 0.286 (0.296) data 0.000 (0.004) loss 2.7734 (2.4562) lr 2.0611e-03 eta 0:16:01
epoch [22/30] batch [300/392] time 0.283 (0.296) data 0.000 (0.004) loss 0.9434 (2.4379) lr 2.0611e-03 eta 0:15:54
epoch [22/30] batch [320/392] time 0.291 (0.295) data 0.000 (0.004) loss 1.4697 (2.4111) lr 2.0611e-03 eta 0:15:46
epoch [22/30] batch [340/392] time 0.293 (0.295) data 0.000 (0.003) loss 0.9736 (2.3644) lr 2.0611e-03 eta 0:15:41
epoch [22/30] batch [360/392] time 0.298 (0.295) data 0.000 (0.003) loss 1.5684 (2.3586) lr 2.0611e-03 eta 0:15:35
epoch [22/30] batch [380/392] time 0.272 (0.294) data 0.000 (0.003) loss 4.2227 (2.3700) lr 2.0611e-03 eta 0:15:25
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:23,  2.93s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.29s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.30it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.90it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.56it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.23it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.83it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.42it/s]100%|██████████| 9/9 [00:04<00:00,  2.14it/s]=> result
* total: 812
* correct: 591
* accuracy: 72.8%
* error: 27.2%
* macro_f1: 71.7%

epoch [23/30] batch [20/392] time 0.286 (0.353) data 0.000 (0.050) loss 0.8838 (2.2251) lr 1.6543e-03 eta 0:18:20
epoch [23/30] batch [40/392] time 0.310 (0.321) data 0.000 (0.025) loss 4.1328 (2.2355) lr 1.6543e-03 eta 0:16:32
epoch [23/30] batch [60/392] time 0.282 (0.310) data 0.000 (0.017) loss 1.5518 (2.1115) lr 1.6543e-03 eta 0:15:52
epoch [23/30] batch [80/392] time 0.285 (0.306) data 0.000 (0.013) loss 2.4453 (2.1273) lr 1.6543e-03 eta 0:15:36
epoch [23/30] batch [100/392] time 0.295 (0.302) data 0.000 (0.010) loss 1.1104 (2.1561) lr 1.6543e-03 eta 0:15:17
epoch [23/30] batch [120/392] time 0.288 (0.300) data 0.000 (0.009) loss 1.1074 (2.2330) lr 1.6543e-03 eta 0:15:05
epoch [23/30] batch [140/392] time 0.279 (0.298) data 0.000 (0.007) loss 2.9961 (2.1988) lr 1.6543e-03 eta 0:14:54
epoch [23/30] batch [160/392] time 0.289 (0.298) data 0.000 (0.007) loss 0.7925 (2.1638) lr 1.6543e-03 eta 0:14:46
epoch [23/30] batch [180/392] time 0.300 (0.297) data 0.000 (0.006) loss 1.2500 (2.2035) lr 1.6543e-03 eta 0:14:38
epoch [23/30] batch [200/392] time 0.288 (0.297) data 0.000 (0.005) loss 2.3164 (2.2350) lr 1.6543e-03 eta 0:14:31
epoch [23/30] batch [220/392] time 0.292 (0.296) data 0.000 (0.005) loss 2.6816 (2.2166) lr 1.6543e-03 eta 0:14:24
epoch [23/30] batch [240/392] time 0.275 (0.296) data 0.000 (0.004) loss 1.3018 (2.2577) lr 1.6543e-03 eta 0:14:16
epoch [23/30] batch [260/392] time 0.292 (0.296) data 0.000 (0.004) loss 1.8037 (2.2724) lr 1.6543e-03 eta 0:14:10
epoch [23/30] batch [280/392] time 0.279 (0.296) data 0.000 (0.004) loss 4.4297 (2.2666) lr 1.6543e-03 eta 0:14:04
epoch [23/30] batch [300/392] time 0.288 (0.295) data 0.000 (0.004) loss 2.8672 (2.2679) lr 1.6543e-03 eta 0:13:56
epoch [23/30] batch [320/392] time 0.286 (0.295) data 0.000 (0.003) loss 1.9053 (2.2666) lr 1.6543e-03 eta 0:13:50
epoch [23/30] batch [340/392] time 0.282 (0.295) data 0.000 (0.003) loss 1.5791 (2.2360) lr 1.6543e-03 eta 0:13:43
epoch [23/30] batch [360/392] time 0.278 (0.294) data 0.000 (0.003) loss 2.2285 (2.2360) lr 1.6543e-03 eta 0:13:37
epoch [23/30] batch [380/392] time 0.273 (0.293) data 0.000 (0.003) loss 2.4512 (2.2464) lr 1.6543e-03 eta 0:13:28
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:23,  2.96s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.31s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.28it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.89it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.54it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.22it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.88it/s] 89%|████████▉ | 8/9 [00:04<00:00,  4.48it/s]100%|██████████| 9/9 [00:04<00:00,  2.13it/s]=> result
* total: 812
* correct: 596
* accuracy: 73.4%
* error: 26.6%
* macro_f1: 72.7%

epoch [24/30] batch [20/392] time 0.272 (0.342) data 0.000 (0.050) loss 2.1113 (2.3211) lr 1.2843e-03 eta 0:15:30
epoch [24/30] batch [40/392] time 0.317 (0.318) data 0.000 (0.025) loss 2.4023 (2.1299) lr 1.2843e-03 eta 0:14:21
epoch [24/30] batch [60/392] time 0.283 (0.309) data 0.000 (0.017) loss 1.2207 (2.0799) lr 1.2843e-03 eta 0:13:49
epoch [24/30] batch [80/392] time 0.294 (0.305) data 0.000 (0.013) loss 2.4141 (2.2064) lr 1.2843e-03 eta 0:13:32
epoch [24/30] batch [100/392] time 0.291 (0.303) data 0.000 (0.010) loss 0.5444 (2.1948) lr 1.2843e-03 eta 0:13:21
epoch [24/30] batch [120/392] time 0.289 (0.301) data 0.000 (0.009) loss 3.7617 (2.3438) lr 1.2843e-03 eta 0:13:09
epoch [24/30] batch [140/392] time 0.283 (0.300) data 0.000 (0.007) loss 2.3086 (2.3084) lr 1.2843e-03 eta 0:13:01
epoch [24/30] batch [160/392] time 0.297 (0.300) data 0.000 (0.007) loss 2.4668 (2.2925) lr 1.2843e-03 eta 0:12:54
epoch [24/30] batch [180/392] time 0.287 (0.299) data 0.001 (0.006) loss 1.6992 (2.2606) lr 1.2843e-03 eta 0:12:46
epoch [24/30] batch [200/392] time 0.287 (0.298) data 0.000 (0.005) loss 2.6445 (2.2611) lr 1.2843e-03 eta 0:12:38
epoch [24/30] batch [220/392] time 0.297 (0.298) data 0.000 (0.005) loss 1.4951 (2.2761) lr 1.2843e-03 eta 0:12:30
epoch [24/30] batch [240/392] time 0.302 (0.297) data 0.000 (0.004) loss 2.8496 (2.2711) lr 1.2843e-03 eta 0:12:23
epoch [24/30] batch [260/392] time 0.281 (0.296) data 0.000 (0.004) loss 2.4590 (2.2480) lr 1.2843e-03 eta 0:12:16
epoch [24/30] batch [280/392] time 0.286 (0.296) data 0.000 (0.004) loss 2.9902 (2.2668) lr 1.2843e-03 eta 0:12:09
epoch [24/30] batch [300/392] time 0.277 (0.296) data 0.000 (0.004) loss 3.1113 (2.2506) lr 1.2843e-03 eta 0:12:02
epoch [24/30] batch [320/392] time 0.289 (0.296) data 0.000 (0.003) loss 0.3054 (2.2484) lr 1.2843e-03 eta 0:11:56
epoch [24/30] batch [340/392] time 0.292 (0.296) data 0.000 (0.003) loss 4.2109 (2.2492) lr 1.2843e-03 eta 0:11:50
epoch [24/30] batch [360/392] time 0.289 (0.295) data 0.000 (0.003) loss 0.1389 (2.2404) lr 1.2843e-03 eta 0:11:44
epoch [24/30] batch [380/392] time 0.272 (0.294) data 0.000 (0.003) loss 3.0996 (2.2632) lr 1.2843e-03 eta 0:11:35
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.81s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.25s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.33it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.95it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.62it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.29it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.94it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.53it/s]100%|██████████| 9/9 [00:04<00:00,  2.20it/s]=> result
* total: 812
* correct: 606
* accuracy: 74.6%
* error: 25.4%
* macro_f1: 73.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [25/30] batch [20/392] time 0.296 (0.353) data 0.000 (0.050) loss 0.9150 (1.8657) lr 9.5492e-04 eta 0:13:44
epoch [25/30] batch [40/392] time 0.286 (0.322) data 0.000 (0.025) loss 2.9902 (2.2340) lr 9.5492e-04 eta 0:12:24
epoch [25/30] batch [60/392] time 0.295 (0.311) data 0.000 (0.017) loss 0.4380 (2.2632) lr 9.5492e-04 eta 0:11:52
epoch [25/30] batch [80/392] time 0.283 (0.306) data 0.000 (0.013) loss 1.6592 (2.3254) lr 9.5492e-04 eta 0:11:35
epoch [25/30] batch [100/392] time 0.285 (0.303) data 0.000 (0.010) loss 0.5029 (2.3105) lr 9.5492e-04 eta 0:11:22
epoch [25/30] batch [120/392] time 0.283 (0.300) data 0.000 (0.009) loss 2.2578 (2.2799) lr 9.5492e-04 eta 0:11:10
epoch [25/30] batch [140/392] time 0.294 (0.300) data 0.000 (0.007) loss 3.2266 (2.2545) lr 9.5492e-04 eta 0:11:03
epoch [25/30] batch [160/392] time 0.284 (0.299) data 0.000 (0.007) loss 1.5811 (2.2494) lr 9.5492e-04 eta 0:10:55
epoch [25/30] batch [180/392] time 0.276 (0.297) data 0.000 (0.006) loss 1.0400 (2.2499) lr 9.5492e-04 eta 0:10:45
epoch [25/30] batch [200/392] time 0.284 (0.297) data 0.000 (0.005) loss 1.7617 (2.2389) lr 9.5492e-04 eta 0:10:38
epoch [25/30] batch [220/392] time 0.282 (0.297) data 0.000 (0.005) loss 0.9507 (2.2556) lr 9.5492e-04 eta 0:10:32
epoch [25/30] batch [240/392] time 0.282 (0.296) data 0.000 (0.004) loss 2.9434 (2.2771) lr 9.5492e-04 eta 0:10:26
epoch [25/30] batch [260/392] time 0.281 (0.296) data 0.001 (0.004) loss 1.1396 (2.2633) lr 9.5492e-04 eta 0:10:19
epoch [25/30] batch [280/392] time 0.302 (0.296) data 0.000 (0.004) loss 0.7661 (2.2720) lr 9.5492e-04 eta 0:10:12
epoch [25/30] batch [300/392] time 0.283 (0.295) data 0.000 (0.004) loss 3.1113 (2.2833) lr 9.5492e-04 eta 0:10:06
epoch [25/30] batch [320/392] time 0.284 (0.295) data 0.000 (0.003) loss 2.9336 (2.2771) lr 9.5492e-04 eta 0:10:00
epoch [25/30] batch [340/392] time 0.284 (0.295) data 0.000 (0.003) loss 2.9766 (2.2539) lr 9.5492e-04 eta 0:09:53
epoch [25/30] batch [360/392] time 0.282 (0.295) data 0.000 (0.003) loss 1.1934 (2.2597) lr 9.5492e-04 eta 0:09:47
epoch [25/30] batch [380/392] time 0.276 (0.294) data 0.000 (0.003) loss 1.8896 (2.2709) lr 9.5492e-04 eta 0:09:39
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.60s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.19s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.40it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.04it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.71it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.40it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.04it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.62it/s]100%|██████████| 9/9 [00:03<00:00,  2.30it/s]=> result
* total: 812
* correct: 610
* accuracy: 75.1%
* error: 24.9%
* macro_f1: 74.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [26/30] batch [20/392] time 0.281 (0.341) data 0.000 (0.050) loss 1.3701 (2.3679) lr 6.6987e-04 eta 0:11:01
epoch [26/30] batch [40/392] time 0.291 (0.318) data 0.000 (0.025) loss 3.8574 (2.3284) lr 6.6987e-04 eta 0:10:09
epoch [26/30] batch [60/392] time 0.291 (0.309) data 0.000 (0.017) loss 1.1797 (2.2717) lr 6.6987e-04 eta 0:09:47
epoch [26/30] batch [80/392] time 0.280 (0.304) data 0.000 (0.013) loss 1.7832 (2.2904) lr 6.6987e-04 eta 0:09:32
epoch [26/30] batch [100/392] time 0.281 (0.301) data 0.000 (0.010) loss 0.7090 (2.2356) lr 6.6987e-04 eta 0:09:20
epoch [26/30] batch [120/392] time 0.298 (0.301) data 0.000 (0.009) loss 5.0352 (2.2802) lr 6.6987e-04 eta 0:09:13
epoch [26/30] batch [140/392] time 0.282 (0.299) data 0.000 (0.007) loss 2.0938 (2.2662) lr 6.6987e-04 eta 0:09:03
epoch [26/30] batch [160/392] time 0.286 (0.298) data 0.000 (0.007) loss 1.4795 (2.2488) lr 6.6987e-04 eta 0:08:56
epoch [26/30] batch [180/392] time 0.289 (0.298) data 0.000 (0.006) loss 3.1230 (2.2776) lr 6.6987e-04 eta 0:08:49
epoch [26/30] batch [200/392] time 0.288 (0.297) data 0.000 (0.005) loss 3.4199 (2.2363) lr 6.6987e-04 eta 0:08:43
epoch [26/30] batch [220/392] time 0.285 (0.297) data 0.000 (0.005) loss 3.1094 (2.2028) lr 6.6987e-04 eta 0:08:36
epoch [26/30] batch [240/392] time 0.306 (0.296) data 0.000 (0.004) loss 2.0664 (2.1631) lr 6.6987e-04 eta 0:08:29
epoch [26/30] batch [260/392] time 0.284 (0.296) data 0.000 (0.004) loss 3.0117 (2.1565) lr 6.6987e-04 eta 0:08:23
epoch [26/30] batch [280/392] time 0.284 (0.296) data 0.000 (0.004) loss 2.7227 (2.1718) lr 6.6987e-04 eta 0:08:16
epoch [26/30] batch [300/392] time 0.285 (0.295) data 0.000 (0.004) loss 2.5000 (2.1746) lr 6.6987e-04 eta 0:08:10
epoch [26/30] batch [320/392] time 0.280 (0.295) data 0.000 (0.003) loss 1.8438 (2.1757) lr 6.6987e-04 eta 0:08:04
epoch [26/30] batch [340/392] time 0.287 (0.295) data 0.000 (0.003) loss 1.1211 (2.1607) lr 6.6987e-04 eta 0:07:58
epoch [26/30] batch [360/392] time 0.299 (0.295) data 0.000 (0.003) loss 3.9727 (2.1629) lr 6.6987e-04 eta 0:07:52
epoch [26/30] batch [380/392] time 0.270 (0.294) data 0.000 (0.003) loss 1.8135 (2.1517) lr 6.6987e-04 eta 0:07:44
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.87s/it] 22%|██▏       | 2/9 [00:03<00:09,  1.32s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.26it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.86it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.51it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.19it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.84it/s] 89%|████████▉ | 8/9 [00:04<00:00,  4.44it/s]100%|██████████| 9/9 [00:04<00:00,  2.13it/s]=> result
* total: 812
* correct: 597
* accuracy: 73.5%
* error: 26.5%
* macro_f1: 72.8%

epoch [27/30] batch [20/392] time 0.326 (0.350) data 0.000 (0.053) loss 1.3701 (2.7070) lr 4.3227e-04 eta 0:09:01
epoch [27/30] batch [40/392] time 0.326 (0.320) data 0.000 (0.027) loss 0.6499 (2.5016) lr 4.3227e-04 eta 0:08:09
epoch [27/30] batch [60/392] time 0.279 (0.312) data 0.000 (0.018) loss 1.4961 (2.3883) lr 4.3227e-04 eta 0:07:51
epoch [27/30] batch [80/392] time 0.331 (0.307) data 0.000 (0.013) loss 1.6602 (2.2615) lr 4.3227e-04 eta 0:07:36
epoch [27/30] batch [100/392] time 0.291 (0.304) data 0.000 (0.011) loss 1.6211 (2.2022) lr 4.3227e-04 eta 0:07:26
epoch [27/30] batch [120/392] time 0.319 (0.302) data 0.000 (0.009) loss 1.8740 (2.1691) lr 4.3227e-04 eta 0:07:17
epoch [27/30] batch [140/392] time 0.297 (0.301) data 0.000 (0.008) loss 1.5400 (2.1802) lr 4.3227e-04 eta 0:07:09
epoch [27/30] batch [160/392] time 0.299 (0.299) data 0.000 (0.007) loss 2.4746 (2.1432) lr 4.3227e-04 eta 0:07:01
epoch [27/30] batch [180/392] time 0.277 (0.298) data 0.000 (0.006) loss 2.1914 (2.1505) lr 4.3227e-04 eta 0:06:53
epoch [27/30] batch [200/392] time 0.311 (0.298) data 0.000 (0.006) loss 3.2344 (2.1736) lr 4.3227e-04 eta 0:06:47
epoch [27/30] batch [220/392] time 0.291 (0.297) data 0.000 (0.005) loss 0.9048 (2.1591) lr 4.3227e-04 eta 0:06:40
epoch [27/30] batch [240/392] time 0.281 (0.296) data 0.000 (0.005) loss 5.4961 (2.1679) lr 4.3227e-04 eta 0:06:33
epoch [27/30] batch [260/392] time 0.284 (0.296) data 0.000 (0.004) loss 1.6885 (2.2036) lr 4.3227e-04 eta 0:06:27
epoch [27/30] batch [280/392] time 0.295 (0.296) data 0.000 (0.004) loss 1.3340 (2.1986) lr 4.3227e-04 eta 0:06:20
epoch [27/30] batch [300/392] time 0.284 (0.295) data 0.000 (0.004) loss 0.8506 (2.2248) lr 4.3227e-04 eta 0:06:14
epoch [27/30] batch [320/392] time 0.296 (0.295) data 0.000 (0.004) loss 2.7930 (2.2319) lr 4.3227e-04 eta 0:06:07
epoch [27/30] batch [340/392] time 0.278 (0.294) data 0.000 (0.003) loss 1.3564 (2.2344) lr 4.3227e-04 eta 0:06:01
epoch [27/30] batch [360/392] time 0.326 (0.294) data 0.000 (0.003) loss 0.6357 (2.2586) lr 4.3227e-04 eta 0:05:55
epoch [27/30] batch [380/392] time 0.271 (0.293) data 0.000 (0.003) loss 2.1465 (2.2752) lr 4.3227e-04 eta 0:05:48
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:22,  2.81s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.25s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.34it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.95it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.62it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.30it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.95it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.53it/s]100%|██████████| 9/9 [00:04<00:00,  2.21it/s]=> result
* total: 812
* correct: 603
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 73.6%

epoch [28/30] batch [20/392] time 0.280 (0.355) data 0.000 (0.051) loss 2.3789 (2.5174) lr 2.4472e-04 eta 0:06:50
epoch [28/30] batch [40/392] time 0.278 (0.323) data 0.000 (0.026) loss 1.4434 (2.4228) lr 2.4472e-04 eta 0:06:07
epoch [28/30] batch [60/392] time 0.331 (0.313) data 0.000 (0.017) loss 1.2061 (2.4455) lr 2.4472e-04 eta 0:05:49
epoch [28/30] batch [80/392] time 0.287 (0.306) data 0.000 (0.013) loss 0.3701 (2.3267) lr 2.4472e-04 eta 0:05:35
epoch [28/30] batch [100/392] time 0.283 (0.304) data 0.000 (0.010) loss 3.7754 (2.2402) lr 2.4472e-04 eta 0:05:26
epoch [28/30] batch [120/392] time 0.277 (0.302) data 0.000 (0.009) loss 2.4199 (2.1679) lr 2.4472e-04 eta 0:05:19
epoch [28/30] batch [140/392] time 0.285 (0.300) data 0.000 (0.008) loss 4.1836 (2.2454) lr 2.4472e-04 eta 0:05:10
epoch [28/30] batch [160/392] time 0.279 (0.299) data 0.000 (0.007) loss 4.8711 (2.2246) lr 2.4472e-04 eta 0:05:03
epoch [28/30] batch [180/392] time 0.305 (0.299) data 0.000 (0.006) loss 0.8813 (2.1691) lr 2.4472e-04 eta 0:04:57
epoch [28/30] batch [200/392] time 0.282 (0.298) data 0.000 (0.005) loss 2.5742 (2.1695) lr 2.4472e-04 eta 0:04:51
epoch [28/30] batch [220/392] time 0.314 (0.297) data 0.000 (0.005) loss 1.3818 (2.1745) lr 2.4472e-04 eta 0:04:44
epoch [28/30] batch [240/392] time 0.296 (0.297) data 0.000 (0.005) loss 1.0322 (2.2118) lr 2.4472e-04 eta 0:04:37
epoch [28/30] batch [260/392] time 0.290 (0.296) data 0.000 (0.004) loss 0.5903 (2.2179) lr 2.4472e-04 eta 0:04:31
epoch [28/30] batch [280/392] time 0.290 (0.296) data 0.000 (0.004) loss 1.8223 (2.2810) lr 2.4472e-04 eta 0:04:25
epoch [28/30] batch [300/392] time 0.280 (0.296) data 0.000 (0.004) loss 2.7793 (2.3076) lr 2.4472e-04 eta 0:04:19
epoch [28/30] batch [320/392] time 0.287 (0.295) data 0.000 (0.003) loss 0.9268 (2.3172) lr 2.4472e-04 eta 0:04:12
epoch [28/30] batch [340/392] time 0.296 (0.295) data 0.000 (0.003) loss 2.3633 (2.2978) lr 2.4472e-04 eta 0:04:06
epoch [28/30] batch [360/392] time 0.277 (0.295) data 0.000 (0.003) loss 3.5352 (2.2857) lr 2.4472e-04 eta 0:04:00
epoch [28/30] batch [380/392] time 0.270 (0.294) data 0.000 (0.003) loss 2.1230 (2.2984) lr 2.4472e-04 eta 0:03:53
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.62s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.21s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.38it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.01it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.68it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.36it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.01it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.60it/s]100%|██████████| 9/9 [00:03<00:00,  2.28it/s]=> result
* total: 812
* correct: 602
* accuracy: 74.1%
* error: 25.9%
* macro_f1: 73.3%

epoch [29/30] batch [20/392] time 0.280 (0.347) data 0.000 (0.051) loss 3.2441 (2.4802) lr 1.0926e-04 eta 0:04:25
epoch [29/30] batch [40/392] time 0.344 (0.318) data 0.000 (0.026) loss 3.1953 (2.3589) lr 1.0926e-04 eta 0:03:56
epoch [29/30] batch [60/392] time 0.280 (0.306) data 0.000 (0.017) loss 1.9326 (2.5003) lr 1.0926e-04 eta 0:03:41
epoch [29/30] batch [80/392] time 0.298 (0.303) data 0.000 (0.013) loss 3.0273 (2.4273) lr 1.0926e-04 eta 0:03:33
epoch [29/30] batch [100/392] time 0.297 (0.300) data 0.000 (0.010) loss 2.1523 (2.4598) lr 1.0926e-04 eta 0:03:24
epoch [29/30] batch [120/392] time 0.288 (0.298) data 0.000 (0.009) loss 2.2656 (2.4107) lr 1.0926e-04 eta 0:03:17
epoch [29/30] batch [140/392] time 0.289 (0.297) data 0.000 (0.008) loss 4.0195 (2.4041) lr 1.0926e-04 eta 0:03:11
epoch [29/30] batch [160/392] time 0.297 (0.296) data 0.000 (0.007) loss 2.1328 (2.3367) lr 1.0926e-04 eta 0:03:04
epoch [29/30] batch [180/392] time 0.281 (0.296) data 0.000 (0.006) loss 1.5059 (2.3509) lr 1.0926e-04 eta 0:02:58
epoch [29/30] batch [200/392] time 0.285 (0.296) data 0.000 (0.005) loss 2.2305 (2.3296) lr 1.0926e-04 eta 0:02:52
epoch [29/30] batch [220/392] time 0.295 (0.295) data 0.000 (0.005) loss 2.2773 (2.3042) lr 1.0926e-04 eta 0:02:46
epoch [29/30] batch [240/392] time 0.290 (0.295) data 0.000 (0.004) loss 2.2734 (2.2592) lr 1.0926e-04 eta 0:02:40
epoch [29/30] batch [260/392] time 0.283 (0.294) data 0.000 (0.004) loss 3.6445 (2.2685) lr 1.0926e-04 eta 0:02:34
epoch [29/30] batch [280/392] time 0.286 (0.294) data 0.000 (0.004) loss 2.2480 (2.2479) lr 1.0926e-04 eta 0:02:28
epoch [29/30] batch [300/392] time 0.279 (0.294) data 0.000 (0.004) loss 0.7358 (2.2205) lr 1.0926e-04 eta 0:02:22
epoch [29/30] batch [320/392] time 0.321 (0.294) data 0.000 (0.003) loss 2.4453 (2.2281) lr 1.0926e-04 eta 0:02:16
epoch [29/30] batch [340/392] time 0.328 (0.295) data 0.000 (0.003) loss 1.2910 (2.2405) lr 1.0926e-04 eta 0:02:10
epoch [29/30] batch [360/392] time 0.301 (0.294) data 0.000 (0.003) loss 1.5830 (2.2569) lr 1.0926e-04 eta 0:02:04
epoch [29/30] batch [380/392] time 0.270 (0.293) data 0.000 (0.003) loss 3.1504 (2.2792) lr 1.0926e-04 eta 0:01:58
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.59s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.21s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.36it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.98it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.66it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.34it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.99it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.58it/s]100%|██████████| 9/9 [00:03<00:00,  2.27it/s]=> result
* total: 812
* correct: 602
* accuracy: 74.1%
* error: 25.9%
* macro_f1: 73.3%

epoch [30/30] batch [20/392] time 0.286 (0.352) data 0.000 (0.050) loss 1.6689 (2.0952) lr 2.7391e-05 eta 0:02:10
epoch [30/30] batch [40/392] time 0.282 (0.322) data 0.000 (0.025) loss 3.5312 (2.1810) lr 2.7391e-05 eta 0:01:53
epoch [30/30] batch [60/392] time 0.282 (0.311) data 0.000 (0.017) loss 0.9600 (2.2057) lr 2.7391e-05 eta 0:01:43
epoch [30/30] batch [80/392] time 0.299 (0.306) data 0.000 (0.013) loss 1.3516 (2.2838) lr 2.7391e-05 eta 0:01:35
epoch [30/30] batch [100/392] time 0.281 (0.304) data 0.000 (0.010) loss 1.2158 (2.3847) lr 2.7391e-05 eta 0:01:28
epoch [30/30] batch [120/392] time 0.283 (0.301) data 0.000 (0.008) loss 0.6465 (2.3200) lr 2.7391e-05 eta 0:01:21
epoch [30/30] batch [140/392] time 0.293 (0.299) data 0.000 (0.007) loss 3.1816 (2.2993) lr 2.7391e-05 eta 0:01:15
epoch [30/30] batch [160/392] time 0.286 (0.298) data 0.000 (0.006) loss 3.8203 (2.2745) lr 2.7391e-05 eta 0:01:09
epoch [30/30] batch [180/392] time 0.286 (0.297) data 0.000 (0.006) loss 3.0801 (2.2951) lr 2.7391e-05 eta 0:01:03
epoch [30/30] batch [200/392] time 0.320 (0.297) data 0.000 (0.005) loss 5.0938 (2.2934) lr 2.7391e-05 eta 0:00:56
epoch [30/30] batch [220/392] time 0.300 (0.297) data 0.000 (0.005) loss 0.2742 (2.2565) lr 2.7391e-05 eta 0:00:51
epoch [30/30] batch [240/392] time 0.283 (0.296) data 0.000 (0.004) loss 0.8628 (2.2767) lr 2.7391e-05 eta 0:00:45
epoch [30/30] batch [260/392] time 0.346 (0.296) data 0.000 (0.004) loss 2.0508 (2.2873) lr 2.7391e-05 eta 0:00:39
epoch [30/30] batch [280/392] time 0.286 (0.296) data 0.000 (0.004) loss 1.9893 (2.2716) lr 2.7391e-05 eta 0:00:33
epoch [30/30] batch [300/392] time 0.284 (0.296) data 0.000 (0.004) loss 1.5889 (2.2737) lr 2.7391e-05 eta 0:00:27
epoch [30/30] batch [320/392] time 0.288 (0.295) data 0.000 (0.003) loss 1.6924 (2.2923) lr 2.7391e-05 eta 0:00:21
epoch [30/30] batch [340/392] time 0.283 (0.295) data 0.000 (0.003) loss 2.1465 (2.3039) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [360/392] time 0.299 (0.294) data 0.000 (0.003) loss 2.8730 (2.3007) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [380/392] time 0.270 (0.293) data 0.000 (0.003) loss 1.7139 (2.2799) lr 2.7391e-05 eta 0:00:03
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.63s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.23s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.35it/s] 44%|████▍     | 4/9 [00:03<00:02,  1.98it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.65it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.33it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.98it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.55it/s]100%|██████████| 9/9 [00:04<00:00,  2.25it/s]
=> result
* total: 812
* correct: 602
* accuracy: 74.1%
* error: 25.9%
* macro_f1: 73.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/41 [00:00<?, ?it/s]  2%|▏         | 1/41 [00:03<02:06,  3.16s/it]  5%|▍         | 2/41 [00:03<01:04,  1.65s/it]  7%|▋         | 3/41 [00:04<00:46,  1.22s/it] 10%|▉         | 4/41 [00:05<00:35,  1.04it/s] 12%|█▏        | 5/41 [00:05<00:27,  1.30it/s] 15%|█▍        | 6/41 [00:05<00:21,  1.62it/s] 17%|█▋        | 7/41 [00:06<00:17,  1.95it/s] 20%|█▉        | 8/41 [00:06<00:15,  2.20it/s] 22%|██▏       | 9/41 [00:06<00:12,  2.51it/s] 24%|██▍       | 10/41 [00:07<00:11,  2.68it/s] 27%|██▋       | 11/41 [00:07<00:10,  2.94it/s] 29%|██▉       | 12/41 [00:07<00:08,  3.28it/s] 32%|███▏      | 13/41 [00:07<00:08,  3.44it/s] 34%|███▍      | 14/41 [00:07<00:07,  3.59it/s] 37%|███▋      | 15/41 [00:08<00:06,  4.14it/s] 39%|███▉      | 16/41 [00:08<00:05,  4.67it/s] 41%|████▏     | 17/41 [00:08<00:04,  5.14it/s] 44%|████▍     | 18/41 [00:08<00:04,  5.52it/s] 46%|████▋     | 19/41 [00:08<00:03,  5.85it/s] 49%|████▉     | 20/41 [00:08<00:03,  6.06it/s] 51%|█████     | 21/41 [00:09<00:03,  6.24it/s] 54%|█████▎    | 22/41 [00:09<00:02,  6.37it/s] 56%|█████▌    | 23/41 [00:09<00:02,  6.46it/s] 59%|█████▊    | 24/41 [00:09<00:02,  6.54it/s] 61%|██████    | 25/41 [00:09<00:02,  6.59it/s] 63%|██████▎   | 26/41 [00:09<00:02,  6.62it/s] 66%|██████▌   | 27/41 [00:09<00:02,  6.64it/s] 68%|██████▊   | 28/41 [00:10<00:01,  6.65it/s] 71%|███████   | 29/41 [00:10<00:01,  6.66it/s] 73%|███████▎  | 30/41 [00:10<00:01,  6.66it/s] 76%|███████▌  | 31/41 [00:10<00:01,  6.65it/s] 78%|███████▊  | 32/41 [00:10<00:01,  6.66it/s] 80%|████████  | 33/41 [00:10<00:01,  6.66it/s] 83%|████████▎ | 34/41 [00:10<00:01,  6.65it/s] 85%|████████▌ | 35/41 [00:11<00:00,  6.64it/s] 88%|████████▊ | 36/41 [00:11<00:00,  6.66it/s] 90%|█████████ | 37/41 [00:11<00:00,  6.65it/s] 93%|█████████▎| 38/41 [00:11<00:00,  6.67it/s] 95%|█████████▌| 39/41 [00:11<00:00,  6.67it/s] 98%|█████████▊| 40/41 [00:11<00:00,  6.68it/s]100%|██████████| 41/41 [00:12<00:00,  3.38it/s]
=> result
* total: 4,002
* correct: 3,040
* accuracy: 76.0%
* error: 24.0%
* macro_f1: 75.3%
Elapsed: 1:00:06
+ sh scripts/rpo_prime/base2new_test_sdl.sh stanford_cars 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
1568 823 4039
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      823
# test     4,039
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/41 [00:00<?, ?it/s]  2%|▏         | 1/41 [00:06<04:27,  6.68s/it]  5%|▍         | 2/41 [00:06<01:53,  2.90s/it]  7%|▋         | 3/41 [00:07<01:04,  1.70s/it] 10%|▉         | 4/41 [00:07<00:41,  1.13s/it] 12%|█▏        | 5/41 [00:07<00:29,  1.22it/s] 15%|█▍        | 6/41 [00:08<00:22,  1.57it/s] 17%|█▋        | 7/41 [00:08<00:17,  1.93it/s] 20%|█▉        | 8/41 [00:08<00:14,  2.24it/s] 22%|██▏       | 9/41 [00:08<00:12,  2.53it/s] 24%|██▍       | 10/41 [00:09<00:11,  2.77it/s] 27%|██▋       | 11/41 [00:09<00:10,  2.95it/s] 29%|██▉       | 12/41 [00:09<00:09,  3.16it/s] 32%|███▏      | 13/41 [00:09<00:07,  3.63it/s] 34%|███▍      | 14/41 [00:10<00:06,  4.20it/s] 37%|███▋      | 15/41 [00:10<00:05,  4.73it/s] 39%|███▉      | 16/41 [00:10<00:04,  5.18it/s] 41%|████▏     | 17/41 [00:10<00:04,  5.54it/s] 44%|████▍     | 18/41 [00:10<00:03,  5.83it/s] 46%|████▋     | 19/41 [00:10<00:03,  6.04it/s] 49%|████▉     | 20/41 [00:10<00:03,  6.14it/s] 51%|█████     | 21/41 [00:11<00:03,  6.28it/s] 54%|█████▎    | 22/41 [00:11<00:02,  6.38it/s] 56%|█████▌    | 23/41 [00:11<00:02,  6.45it/s] 59%|█████▊    | 24/41 [00:11<00:02,  6.51it/s] 61%|██████    | 25/41 [00:11<00:02,  6.55it/s] 63%|██████▎   | 26/41 [00:11<00:02,  6.57it/s] 66%|██████▌   | 27/41 [00:12<00:02,  6.59it/s] 68%|██████▊   | 28/41 [00:12<00:01,  6.60it/s] 71%|███████   | 29/41 [00:12<00:01,  6.55it/s] 73%|███████▎  | 30/41 [00:12<00:01,  6.57it/s] 76%|███████▌  | 31/41 [00:12<00:01,  6.58it/s] 78%|███████▊  | 32/41 [00:12<00:01,  6.59it/s] 80%|████████  | 33/41 [00:12<00:01,  6.60it/s] 83%|████████▎ | 34/41 [00:13<00:01,  6.60it/s] 85%|████████▌ | 35/41 [00:13<00:00,  6.63it/s] 88%|████████▊ | 36/41 [00:13<00:00,  6.61it/s] 90%|█████████ | 37/41 [00:13<00:00,  6.61it/s] 93%|█████████▎| 38/41 [00:13<00:00,  6.37it/s] 95%|█████████▌| 39/41 [00:13<00:00,  6.45it/s] 98%|█████████▊| 40/41 [00:13<00:00,  6.50it/s]100%|██████████| 41/41 [00:14<00:00,  2.89it/s]
=> result
* total: 4,039
* correct: 2,979
* accuracy: 73.8%
* error: 26.2%
* macro_f1: 73.0%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh stanford_cars 3 0 main_tmp1_0.1sdl 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
1568 812 4002
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      812
# test     4,002
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/392] time 0.288 (0.413) data 0.000 (0.053) loss 2.8203 (3.4122) lr 1.0000e-02 eta 1:20:48
epoch [1/30] batch [40/392] time 0.278 (0.354) data 0.000 (0.026) loss 2.2422 (3.4284) lr 1.0000e-02 eta 1:09:05
epoch [1/30] batch [60/392] time 0.301 (0.334) data 0.000 (0.018) loss 4.8203 (3.4206) lr 1.0000e-02 eta 1:05:06
epoch [1/30] batch [80/392] time 0.280 (0.323) data 0.000 (0.013) loss 3.3496 (3.3197) lr 1.0000e-02 eta 1:02:48
epoch [1/30] batch [100/392] time 0.299 (0.316) data 0.000 (0.011) loss 2.9746 (3.2671) lr 1.0000e-02 eta 1:01:29
epoch [1/30] batch [120/392] time 0.328 (0.312) data 0.000 (0.009) loss 2.1348 (3.1889) lr 1.0000e-02 eta 1:00:36
epoch [1/30] batch [140/392] time 0.288 (0.311) data 0.000 (0.008) loss 1.6836 (3.1106) lr 1.0000e-02 eta 1:00:13
epoch [1/30] batch [160/392] time 0.290 (0.308) data 0.000 (0.007) loss 2.6113 (3.0713) lr 1.0000e-02 eta 0:59:31
epoch [1/30] batch [180/392] time 0.287 (0.306) data 0.000 (0.006) loss 2.8008 (3.0747) lr 1.0000e-02 eta 0:59:03
epoch [1/30] batch [200/392] time 0.296 (0.305) data 0.000 (0.006) loss 4.8203 (3.0643) lr 1.0000e-02 eta 0:58:45
epoch [1/30] batch [220/392] time 0.289 (0.304) data 0.000 (0.005) loss 3.0352 (3.0557) lr 1.0000e-02 eta 0:58:25
epoch [1/30] batch [240/392] time 0.290 (0.303) data 0.000 (0.005) loss 2.1738 (3.0461) lr 1.0000e-02 eta 0:58:09
epoch [1/30] batch [260/392] time 0.281 (0.302) data 0.000 (0.004) loss 1.9385 (3.0161) lr 1.0000e-02 eta 0:57:51
epoch [1/30] batch [280/392] time 0.290 (0.301) data 0.000 (0.004) loss 5.3516 (2.9951) lr 1.0000e-02 eta 0:57:40
epoch [1/30] batch [300/392] time 0.302 (0.301) data 0.000 (0.004) loss 2.2031 (2.9915) lr 1.0000e-02 eta 0:57:25
epoch [1/30] batch [320/392] time 0.282 (0.300) data 0.000 (0.004) loss 1.1865 (2.9903) lr 1.0000e-02 eta 0:57:13
epoch [1/30] batch [340/392] time 0.287 (0.300) data 0.000 (0.003) loss 1.2188 (3.0059) lr 1.0000e-02 eta 0:57:00
epoch [1/30] batch [360/392] time 0.299 (0.299) data 0.000 (0.003) loss 4.4922 (2.9974) lr 1.0000e-02 eta 0:56:52
epoch [1/30] batch [380/392] time 0.275 (0.298) data 0.000 (0.003) loss 1.2568 (2.9802) lr 1.0000e-02 eta 0:56:31
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.35s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.07s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.54it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.21it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.92it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.61it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.24it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.80it/s]100%|██████████| 9/9 [00:03<00:00,  2.51it/s]=> result
* total: 812
* correct: 543
* accuracy: 66.9%
* error: 33.1%
* macro_f1: 65.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/392] time 0.288 (0.325) data 0.000 (0.034) loss 2.4883 (2.9643) lr 9.9726e-03 eta 1:01:31
epoch [2/30] batch [40/392] time 0.284 (0.307) data 0.000 (0.017) loss 6.9648 (3.1353) lr 9.9726e-03 eta 0:58:02
epoch [2/30] batch [60/392] time 0.287 (0.302) data 0.000 (0.012) loss 3.4980 (3.0324) lr 9.9726e-03 eta 0:56:54
epoch [2/30] batch [80/392] time 0.283 (0.299) data 0.000 (0.009) loss 4.1094 (3.0204) lr 9.9726e-03 eta 0:56:09
epoch [2/30] batch [100/392] time 0.282 (0.298) data 0.000 (0.007) loss 3.2051 (3.0303) lr 9.9726e-03 eta 0:56:03
epoch [2/30] batch [120/392] time 0.298 (0.297) data 0.000 (0.006) loss 6.8477 (3.0951) lr 9.9726e-03 eta 0:55:39
epoch [2/30] batch [140/392] time 0.295 (0.296) data 0.000 (0.005) loss 1.9160 (3.0831) lr 9.9726e-03 eta 0:55:24
epoch [2/30] batch [160/392] time 0.287 (0.295) data 0.000 (0.005) loss 1.0889 (3.0439) lr 9.9726e-03 eta 0:55:11
epoch [2/30] batch [180/392] time 0.280 (0.294) data 0.000 (0.004) loss 1.6699 (2.9948) lr 9.9726e-03 eta 0:54:54
epoch [2/30] batch [200/392] time 0.287 (0.295) data 0.001 (0.004) loss 2.9297 (3.0193) lr 9.9726e-03 eta 0:54:49
epoch [2/30] batch [220/392] time 0.284 (0.294) data 0.000 (0.003) loss 4.4453 (2.9877) lr 9.9726e-03 eta 0:54:37
epoch [2/30] batch [240/392] time 0.282 (0.294) data 0.000 (0.003) loss 4.3438 (3.0077) lr 9.9726e-03 eta 0:54:33
epoch [2/30] batch [260/392] time 0.284 (0.294) data 0.000 (0.003) loss 1.3174 (2.9904) lr 9.9726e-03 eta 0:54:22
epoch [2/30] batch [280/392] time 0.281 (0.294) data 0.000 (0.003) loss 1.0732 (2.9719) lr 9.9726e-03 eta 0:54:17
epoch [2/30] batch [300/392] time 0.283 (0.294) data 0.000 (0.003) loss 1.9678 (2.9653) lr 9.9726e-03 eta 0:54:13
epoch [2/30] batch [320/392] time 0.289 (0.294) data 0.000 (0.002) loss 1.7812 (2.9419) lr 9.9726e-03 eta 0:54:06
epoch [2/30] batch [340/392] time 0.294 (0.294) data 0.000 (0.002) loss 2.6914 (2.9390) lr 9.9726e-03 eta 0:53:59
epoch [2/30] batch [360/392] time 0.288 (0.294) data 0.000 (0.002) loss 2.9668 (2.9243) lr 9.9726e-03 eta 0:53:52
epoch [2/30] batch [380/392] time 0.271 (0.293) data 0.000 (0.002) loss 3.5254 (2.9542) lr 9.9726e-03 eta 0:53:35
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:19,  2.44s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.12s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.39it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.00it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.68it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.35it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.00it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.57it/s]100%|██████████| 9/9 [00:03<00:00,  2.37it/s]=> result
* total: 812
* correct: 547
* accuracy: 67.4%
* error: 32.6%
* macro_f1: 65.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/392] time 0.288 (0.333) data 0.000 (0.033) loss 5.5234 (2.7200) lr 9.8907e-03 eta 1:00:43
epoch [3/30] batch [40/392] time 0.303 (0.312) data 0.000 (0.017) loss 3.0527 (2.7859) lr 9.8907e-03 eta 0:56:49
epoch [3/30] batch [60/392] time 0.314 (0.305) data 0.000 (0.011) loss 2.1250 (2.9131) lr 9.8907e-03 eta 0:55:28
epoch [3/30] batch [80/392] time 0.285 (0.302) data 0.000 (0.008) loss 4.0156 (2.8644) lr 9.8907e-03 eta 0:54:50
epoch [3/30] batch [100/392] time 0.299 (0.300) data 0.000 (0.007) loss 2.9648 (2.7504) lr 9.8907e-03 eta 0:54:27
epoch [3/30] batch [120/392] time 0.289 (0.299) data 0.000 (0.006) loss 2.7090 (2.7745) lr 9.8907e-03 eta 0:54:03
epoch [3/30] batch [140/392] time 0.282 (0.298) data 0.000 (0.005) loss 3.1719 (2.7739) lr 9.8907e-03 eta 0:53:46
epoch [3/30] batch [160/392] time 0.289 (0.298) data 0.000 (0.004) loss 3.5215 (2.7218) lr 9.8907e-03 eta 0:53:39
epoch [3/30] batch [180/392] time 0.283 (0.297) data 0.000 (0.004) loss 2.1484 (2.7498) lr 9.8907e-03 eta 0:53:26
epoch [3/30] batch [200/392] time 0.290 (0.297) data 0.000 (0.004) loss 3.1113 (2.7756) lr 9.8907e-03 eta 0:53:15
epoch [3/30] batch [220/392] time 0.291 (0.296) data 0.000 (0.003) loss 2.6914 (2.7532) lr 9.8907e-03 eta 0:52:58
epoch [3/30] batch [240/392] time 0.284 (0.296) data 0.000 (0.003) loss 3.6426 (2.7846) lr 9.8907e-03 eta 0:52:58
epoch [3/30] batch [260/392] time 0.280 (0.296) data 0.000 (0.003) loss 6.0547 (2.7990) lr 9.8907e-03 eta 0:52:51
epoch [3/30] batch [280/392] time 0.283 (0.296) data 0.000 (0.003) loss 1.9443 (2.7939) lr 9.8907e-03 eta 0:52:41
epoch [3/30] batch [300/392] time 0.287 (0.296) data 0.000 (0.002) loss 2.3242 (2.7945) lr 9.8907e-03 eta 0:52:35
epoch [3/30] batch [320/392] time 0.284 (0.295) data 0.000 (0.002) loss 3.8672 (2.7903) lr 9.8907e-03 eta 0:52:28
epoch [3/30] batch [340/392] time 0.290 (0.295) data 0.000 (0.002) loss 1.1191 (2.7789) lr 9.8907e-03 eta 0:52:19
epoch [3/30] batch [360/392] time 0.285 (0.295) data 0.000 (0.002) loss 0.8662 (2.7532) lr 9.8907e-03 eta 0:52:10
epoch [3/30] batch [380/392] time 0.275 (0.294) data 0.000 (0.002) loss 1.1152 (2.7549) lr 9.8907e-03 eta 0:51:54
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.33s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.06s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.54it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.21it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.92it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.62it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.25it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.81it/s]100%|██████████| 9/9 [00:03<00:00,  2.52it/s]=> result
* total: 812
* correct: 549
* accuracy: 67.6%
* error: 32.4%
* macro_f1: 66.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/392] time 0.285 (0.340) data 0.000 (0.036) loss 0.8418 (3.2378) lr 9.7553e-03 eta 0:59:47
epoch [4/30] batch [40/392] time 0.293 (0.314) data 0.000 (0.018) loss 1.9492 (3.1611) lr 9.7553e-03 eta 0:55:15
epoch [4/30] batch [60/392] time 0.292 (0.307) data 0.000 (0.012) loss 2.5605 (2.9290) lr 9.7553e-03 eta 0:53:53
epoch [4/30] batch [80/392] time 0.307 (0.303) data 0.000 (0.009) loss 4.5625 (2.9856) lr 9.7553e-03 eta 0:53:04
epoch [4/30] batch [100/392] time 0.284 (0.300) data 0.000 (0.007) loss 1.9023 (2.9261) lr 9.7553e-03 eta 0:52:26
epoch [4/30] batch [120/392] time 0.283 (0.299) data 0.000 (0.006) loss 3.9121 (2.9387) lr 9.7553e-03 eta 0:52:12
epoch [4/30] batch [140/392] time 0.285 (0.298) data 0.000 (0.005) loss 1.9805 (2.9000) lr 9.7553e-03 eta 0:51:55
epoch [4/30] batch [160/392] time 0.285 (0.297) data 0.000 (0.005) loss 4.3984 (2.8812) lr 9.7553e-03 eta 0:51:39
epoch [4/30] batch [180/392] time 0.297 (0.296) data 0.000 (0.004) loss 2.6230 (2.8701) lr 9.7553e-03 eta 0:51:22
epoch [4/30] batch [200/392] time 0.322 (0.296) data 0.000 (0.004) loss 3.4277 (2.8710) lr 9.7553e-03 eta 0:51:15
epoch [4/30] batch [220/392] time 0.286 (0.295) data 0.000 (0.003) loss 2.8398 (2.8749) lr 9.7553e-03 eta 0:51:00
epoch [4/30] batch [240/392] time 0.295 (0.295) data 0.000 (0.003) loss 2.9375 (2.8586) lr 9.7553e-03 eta 0:50:52
epoch [4/30] batch [260/392] time 0.282 (0.295) data 0.000 (0.003) loss 1.6289 (2.8655) lr 9.7553e-03 eta 0:50:42
epoch [4/30] batch [280/392] time 0.285 (0.294) data 0.000 (0.003) loss 2.4121 (2.8861) lr 9.7553e-03 eta 0:50:32
epoch [4/30] batch [300/392] time 0.283 (0.294) data 0.000 (0.003) loss 2.6191 (2.8930) lr 9.7553e-03 eta 0:50:24
epoch [4/30] batch [320/392] time 0.283 (0.294) data 0.000 (0.002) loss 0.7715 (2.8966) lr 9.7553e-03 eta 0:50:17
epoch [4/30] batch [340/392] time 0.336 (0.294) data 0.000 (0.002) loss 2.5449 (2.9107) lr 9.7553e-03 eta 0:50:13
epoch [4/30] batch [360/392] time 0.299 (0.294) data 0.000 (0.002) loss 3.0742 (2.9042) lr 9.7553e-03 eta 0:50:08
epoch [4/30] batch [380/392] time 0.276 (0.293) data 0.000 (0.002) loss 2.1289 (2.9122) lr 9.7553e-03 eta 0:49:51
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.27s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.05s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.56it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.23it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.93it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.63it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.26it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.82it/s]100%|██████████| 9/9 [00:03<00:00,  2.55it/s]=> result
* total: 812
* correct: 543
* accuracy: 66.9%
* error: 33.1%
* macro_f1: 65.1%

epoch [5/30] batch [20/392] time 0.283 (0.334) data 0.000 (0.034) loss 4.1094 (2.7658) lr 9.5677e-03 eta 0:56:33
epoch [5/30] batch [40/392] time 0.340 (0.310) data 0.000 (0.017) loss 2.0742 (2.5996) lr 9.5677e-03 eta 0:52:31
epoch [5/30] batch [60/392] time 0.286 (0.306) data 0.000 (0.012) loss 5.1836 (2.6733) lr 9.5677e-03 eta 0:51:40
epoch [5/30] batch [80/392] time 0.282 (0.302) data 0.000 (0.009) loss 2.6113 (2.7532) lr 9.5677e-03 eta 0:50:55
epoch [5/30] batch [100/392] time 0.291 (0.300) data 0.000 (0.007) loss 1.1426 (2.6801) lr 9.5677e-03 eta 0:50:31
epoch [5/30] batch [120/392] time 0.287 (0.299) data 0.000 (0.006) loss 4.7148 (2.6869) lr 9.5677e-03 eta 0:50:07
epoch [5/30] batch [140/392] time 0.314 (0.297) data 0.000 (0.005) loss 3.1797 (2.6431) lr 9.5677e-03 eta 0:49:49
epoch [5/30] batch [160/392] time 0.320 (0.297) data 0.000 (0.005) loss 1.6240 (2.6845) lr 9.5677e-03 eta 0:49:39
epoch [5/30] batch [180/392] time 0.284 (0.296) data 0.000 (0.004) loss 3.0645 (2.7614) lr 9.5677e-03 eta 0:49:22
epoch [5/30] batch [200/392] time 0.278 (0.295) data 0.000 (0.004) loss 4.4883 (2.7848) lr 9.5677e-03 eta 0:49:07
epoch [5/30] batch [220/392] time 0.283 (0.294) data 0.000 (0.003) loss 2.7051 (2.7573) lr 9.5677e-03 eta 0:48:50
epoch [5/30] batch [240/392] time 0.293 (0.294) data 0.000 (0.003) loss 0.8184 (2.7719) lr 9.5677e-03 eta 0:48:43
epoch [5/30] batch [260/392] time 0.283 (0.293) data 0.000 (0.003) loss 1.0762 (2.7876) lr 9.5677e-03 eta 0:48:34
epoch [5/30] batch [280/392] time 0.280 (0.293) data 0.000 (0.003) loss 3.9746 (2.7988) lr 9.5677e-03 eta 0:48:26
epoch [5/30] batch [300/392] time 0.287 (0.293) data 0.000 (0.003) loss 1.5586 (2.7810) lr 9.5677e-03 eta 0:48:20
epoch [5/30] batch [320/392] time 0.282 (0.293) data 0.000 (0.002) loss 4.2812 (2.7940) lr 9.5677e-03 eta 0:48:12
epoch [5/30] batch [340/392] time 0.280 (0.293) data 0.000 (0.002) loss 1.4512 (2.8116) lr 9.5677e-03 eta 0:48:05
epoch [5/30] batch [360/392] time 0.314 (0.293) data 0.000 (0.002) loss 2.4766 (2.7940) lr 9.5677e-03 eta 0:47:58
epoch [5/30] batch [380/392] time 0.273 (0.292) data 0.000 (0.002) loss 2.0684 (2.7846) lr 9.5677e-03 eta 0:47:42
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:19,  2.43s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.09s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.51it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.18it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.87it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.57it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.21it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.77it/s]100%|██████████| 9/9 [00:03<00:00,  2.47it/s]=> result
* total: 812
* correct: 558
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 67.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/392] time 0.293 (0.336) data 0.000 (0.034) loss 1.1299 (2.4116) lr 9.3301e-03 eta 0:54:46
epoch [6/30] batch [40/392] time 0.314 (0.314) data 0.000 (0.017) loss 1.0312 (2.4013) lr 9.3301e-03 eta 0:51:09
epoch [6/30] batch [60/392] time 0.284 (0.307) data 0.000 (0.011) loss 1.5498 (2.5453) lr 9.3301e-03 eta 0:49:53
epoch [6/30] batch [80/392] time 0.288 (0.303) data 0.000 (0.009) loss 4.6523 (2.5295) lr 9.3301e-03 eta 0:49:06
epoch [6/30] batch [100/392] time 0.293 (0.300) data 0.000 (0.007) loss 2.3594 (2.5092) lr 9.3301e-03 eta 0:48:32
epoch [6/30] batch [120/392] time 0.287 (0.299) data 0.000 (0.006) loss 3.9941 (2.5292) lr 9.3301e-03 eta 0:48:11
epoch [6/30] batch [140/392] time 0.275 (0.297) data 0.000 (0.005) loss 2.7168 (2.5215) lr 9.3301e-03 eta 0:47:53
epoch [6/30] batch [160/392] time 0.299 (0.296) data 0.000 (0.004) loss 2.9277 (2.5931) lr 9.3301e-03 eta 0:47:36
epoch [6/30] batch [180/392] time 0.276 (0.295) data 0.000 (0.004) loss 3.1484 (2.5887) lr 9.3301e-03 eta 0:47:18
epoch [6/30] batch [200/392] time 0.281 (0.294) data 0.000 (0.004) loss 5.3555 (2.5844) lr 9.3301e-03 eta 0:47:06
epoch [6/30] batch [220/392] time 0.279 (0.294) data 0.000 (0.003) loss 2.1211 (2.5485) lr 9.3301e-03 eta 0:46:59
epoch [6/30] batch [240/392] time 0.284 (0.294) data 0.000 (0.003) loss 3.2695 (2.5517) lr 9.3301e-03 eta 0:46:50
epoch [6/30] batch [260/392] time 0.286 (0.294) data 0.000 (0.003) loss 1.7090 (2.5438) lr 9.3301e-03 eta 0:46:41
epoch [6/30] batch [280/392] time 0.291 (0.294) data 0.000 (0.003) loss 4.1719 (2.5610) lr 9.3301e-03 eta 0:46:35
epoch [6/30] batch [300/392] time 0.289 (0.293) data 0.000 (0.002) loss 3.9570 (2.6040) lr 9.3301e-03 eta 0:46:26
epoch [6/30] batch [320/392] time 0.300 (0.293) data 0.000 (0.002) loss 1.6064 (2.6396) lr 9.3301e-03 eta 0:46:21
epoch [6/30] batch [340/392] time 0.292 (0.293) data 0.000 (0.002) loss 3.9922 (2.6680) lr 9.3301e-03 eta 0:46:15
epoch [6/30] batch [360/392] time 0.299 (0.293) data 0.000 (0.002) loss 1.9688 (2.7082) lr 9.3301e-03 eta 0:46:07
epoch [6/30] batch [380/392] time 0.273 (0.292) data 0.000 (0.002) loss 1.3018 (2.7422) lr 9.3301e-03 eta 0:45:53
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:19,  2.42s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.09s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.50it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.16it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.86it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.55it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.19it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.75it/s]100%|██████████| 9/9 [00:03<00:00,  2.46it/s]=> result
* total: 812
* correct: 565
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 68.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/392] time 0.279 (0.333) data 0.000 (0.033) loss 5.7617 (3.0780) lr 9.0451e-03 eta 0:52:10
epoch [7/30] batch [40/392] time 0.281 (0.311) data 0.000 (0.017) loss 1.4893 (2.7355) lr 9.0451e-03 eta 0:48:30
epoch [7/30] batch [60/392] time 0.292 (0.303) data 0.000 (0.011) loss 3.1914 (2.6176) lr 9.0451e-03 eta 0:47:08
epoch [7/30] batch [80/392] time 0.281 (0.299) data 0.000 (0.009) loss 7.9141 (2.7088) lr 9.0451e-03 eta 0:46:30
epoch [7/30] batch [100/392] time 0.287 (0.297) data 0.000 (0.007) loss 3.8730 (2.7175) lr 9.0451e-03 eta 0:46:02
epoch [7/30] batch [120/392] time 0.285 (0.295) data 0.000 (0.006) loss 2.8359 (2.7078) lr 9.0451e-03 eta 0:45:43
epoch [7/30] batch [140/392] time 0.299 (0.295) data 0.000 (0.005) loss 2.4727 (2.6847) lr 9.0451e-03 eta 0:45:38
epoch [7/30] batch [160/392] time 0.283 (0.295) data 0.000 (0.004) loss 1.4414 (2.6828) lr 9.0451e-03 eta 0:45:26
epoch [7/30] batch [180/392] time 0.282 (0.295) data 0.000 (0.004) loss 3.0215 (2.6991) lr 9.0451e-03 eta 0:45:18
epoch [7/30] batch [200/392] time 0.290 (0.294) data 0.000 (0.004) loss 2.9609 (2.6879) lr 9.0451e-03 eta 0:45:06
epoch [7/30] batch [220/392] time 0.289 (0.294) data 0.000 (0.003) loss 3.9785 (2.6782) lr 9.0451e-03 eta 0:44:57
epoch [7/30] batch [240/392] time 0.281 (0.293) data 0.000 (0.003) loss 3.2598 (2.6605) lr 9.0451e-03 eta 0:44:49
epoch [7/30] batch [260/392] time 0.295 (0.293) data 0.000 (0.003) loss 1.4717 (2.6408) lr 9.0451e-03 eta 0:44:39
epoch [7/30] batch [280/392] time 0.287 (0.293) data 0.000 (0.003) loss 6.3398 (2.6397) lr 9.0451e-03 eta 0:44:37
epoch [7/30] batch [300/392] time 0.282 (0.293) data 0.000 (0.002) loss 2.1523 (2.6300) lr 9.0451e-03 eta 0:44:28
epoch [7/30] batch [320/392] time 0.296 (0.293) data 0.000 (0.002) loss 1.0703 (2.6192) lr 9.0451e-03 eta 0:44:22
epoch [7/30] batch [340/392] time 0.300 (0.293) data 0.000 (0.002) loss 3.0645 (2.6257) lr 9.0451e-03 eta 0:44:16
epoch [7/30] batch [360/392] time 0.297 (0.293) data 0.001 (0.002) loss 2.3008 (2.6364) lr 9.0451e-03 eta 0:44:07
epoch [7/30] batch [380/392] time 0.270 (0.292) data 0.000 (0.002) loss 2.4180 (2.6457) lr 9.0451e-03 eta 0:43:52
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:17,  2.20s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.05s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.56it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.23it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.94it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.63it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.26it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.81it/s]100%|██████████| 9/9 [00:03<00:00,  2.56it/s]=> result
* total: 812
* correct: 570
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 68.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/392] time 0.282 (0.326) data 0.000 (0.034) loss 2.0859 (2.7930) lr 8.7157e-03 eta 0:48:50
epoch [8/30] batch [40/392] time 0.305 (0.308) data 0.000 (0.017) loss 3.6016 (2.5931) lr 8.7157e-03 eta 0:46:08
epoch [8/30] batch [60/392] time 0.306 (0.303) data 0.000 (0.012) loss 1.6006 (2.6769) lr 8.7157e-03 eta 0:45:09
epoch [8/30] batch [80/392] time 0.281 (0.299) data 0.000 (0.009) loss 1.5908 (2.6616) lr 8.7157e-03 eta 0:44:28
epoch [8/30] batch [100/392] time 0.312 (0.297) data 0.000 (0.007) loss 3.2715 (2.6729) lr 8.7157e-03 eta 0:44:10
epoch [8/30] batch [120/392] time 0.276 (0.296) data 0.000 (0.006) loss 4.9297 (2.6694) lr 8.7157e-03 eta 0:43:56
epoch [8/30] batch [140/392] time 0.288 (0.295) data 0.000 (0.005) loss 4.9609 (2.6992) lr 8.7157e-03 eta 0:43:42
epoch [8/30] batch [160/392] time 0.282 (0.295) data 0.000 (0.004) loss 1.1758 (2.6534) lr 8.7157e-03 eta 0:43:28
epoch [8/30] batch [180/392] time 0.328 (0.294) data 0.000 (0.004) loss 2.5430 (2.5909) lr 8.7157e-03 eta 0:43:17
epoch [8/30] batch [200/392] time 0.320 (0.294) data 0.000 (0.004) loss 0.6377 (2.6079) lr 8.7157e-03 eta 0:43:09
epoch [8/30] batch [220/392] time 0.289 (0.294) data 0.000 (0.003) loss 1.5684 (2.6275) lr 8.7157e-03 eta 0:43:04
epoch [8/30] batch [240/392] time 0.309 (0.294) data 0.000 (0.003) loss 2.7734 (2.5909) lr 8.7157e-03 eta 0:42:58
epoch [8/30] batch [260/392] time 0.299 (0.294) data 0.000 (0.003) loss 3.8711 (2.5950) lr 8.7157e-03 eta 0:42:52
epoch [8/30] batch [280/392] time 0.277 (0.294) data 0.000 (0.003) loss 1.2070 (2.5685) lr 8.7157e-03 eta 0:42:45
epoch [8/30] batch [300/392] time 0.292 (0.293) data 0.000 (0.003) loss 4.8203 (2.5790) lr 8.7157e-03 eta 0:42:37
epoch [8/30] batch [320/392] time 0.295 (0.293) data 0.000 (0.002) loss 2.3926 (2.5838) lr 8.7157e-03 eta 0:42:31
epoch [8/30] batch [340/392] time 0.288 (0.293) data 0.000 (0.002) loss 1.8281 (2.5912) lr 8.7157e-03 eta 0:42:24
epoch [8/30] batch [360/392] time 0.281 (0.293) data 0.000 (0.002) loss 2.7773 (2.5913) lr 8.7157e-03 eta 0:42:15
epoch [8/30] batch [380/392] time 0.270 (0.292) data 0.000 (0.002) loss 2.7324 (2.6156) lr 8.7157e-03 eta 0:42:01
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.36s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.06s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.55it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.22it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.93it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.62it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.26it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.82it/s]100%|██████████| 9/9 [00:03<00:00,  2.53it/s]=> result
* total: 812
* correct: 561
* accuracy: 69.1%
* error: 30.9%
* macro_f1: 68.1%

epoch [9/30] batch [20/392] time 0.282 (0.326) data 0.000 (0.034) loss 1.1299 (1.9565) lr 8.3457e-03 eta 0:46:41
epoch [9/30] batch [40/392] time 0.288 (0.308) data 0.000 (0.017) loss 2.7324 (2.2528) lr 8.3457e-03 eta 0:44:03
epoch [9/30] batch [60/392] time 0.382 (0.303) data 0.000 (0.011) loss 5.6484 (2.4626) lr 8.3457e-03 eta 0:43:12
epoch [9/30] batch [80/392] time 0.287 (0.299) data 0.000 (0.009) loss 1.5391 (2.5537) lr 8.3457e-03 eta 0:42:38
epoch [9/30] batch [100/392] time 0.279 (0.296) data 0.000 (0.007) loss 1.6982 (2.5680) lr 8.3457e-03 eta 0:42:05
epoch [9/30] batch [120/392] time 0.331 (0.295) data 0.000 (0.006) loss 1.8008 (2.5218) lr 8.3457e-03 eta 0:41:51
epoch [9/30] batch [140/392] time 0.278 (0.295) data 0.000 (0.005) loss 1.8203 (2.4873) lr 8.3457e-03 eta 0:41:44
epoch [9/30] batch [160/392] time 0.300 (0.294) data 0.000 (0.004) loss 1.2285 (2.4704) lr 8.3457e-03 eta 0:41:31
epoch [9/30] batch [180/392] time 0.305 (0.294) data 0.000 (0.004) loss 3.2910 (2.4927) lr 8.3457e-03 eta 0:41:23
epoch [9/30] batch [200/392] time 0.282 (0.294) data 0.000 (0.004) loss 3.0352 (2.5220) lr 8.3457e-03 eta 0:41:13
epoch [9/30] batch [220/392] time 0.295 (0.293) data 0.000 (0.003) loss 1.7754 (2.5123) lr 8.3457e-03 eta 0:41:05
epoch [9/30] batch [240/392] time 0.292 (0.293) data 0.000 (0.003) loss 3.7988 (2.5056) lr 8.3457e-03 eta 0:40:58
epoch [9/30] batch [260/392] time 0.287 (0.293) data 0.000 (0.003) loss 4.6406 (2.5148) lr 8.3457e-03 eta 0:40:49
epoch [9/30] batch [280/392] time 0.288 (0.293) data 0.000 (0.003) loss 1.9893 (2.5284) lr 8.3457e-03 eta 0:40:41
epoch [9/30] batch [300/392] time 0.286 (0.292) data 0.000 (0.003) loss 2.5957 (2.5171) lr 8.3457e-03 eta 0:40:31
epoch [9/30] batch [320/392] time 0.334 (0.292) data 0.000 (0.002) loss 0.4756 (2.5329) lr 8.3457e-03 eta 0:40:26
epoch [9/30] batch [340/392] time 0.285 (0.292) data 0.000 (0.002) loss 2.8359 (2.5518) lr 8.3457e-03 eta 0:40:20
epoch [9/30] batch [360/392] time 0.302 (0.292) data 0.000 (0.002) loss 6.4062 (2.5359) lr 8.3457e-03 eta 0:40:13
epoch [9/30] batch [380/392] time 0.270 (0.291) data 0.000 (0.002) loss 2.9023 (2.5625) lr 8.3457e-03 eta 0:39:58
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.33s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.05s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.56it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.24it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.94it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.64it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.27it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.83it/s]100%|██████████| 9/9 [00:03<00:00,  2.53it/s]=> result
* total: 812
* correct: 579
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 70.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/392] time 0.394 (0.331) data 0.000 (0.037) loss 3.4062 (2.5324) lr 7.9389e-03 eta 0:45:15
epoch [10/30] batch [40/392] time 0.278 (0.312) data 0.000 (0.019) loss 2.5840 (2.5197) lr 7.9389e-03 eta 0:42:35
epoch [10/30] batch [60/392] time 0.287 (0.305) data 0.000 (0.013) loss 2.1914 (2.5318) lr 7.9389e-03 eta 0:41:32
epoch [10/30] batch [80/392] time 0.280 (0.302) data 0.000 (0.010) loss 2.6523 (2.4346) lr 7.9389e-03 eta 0:41:00
epoch [10/30] batch [100/392] time 0.295 (0.300) data 0.000 (0.008) loss 1.7979 (2.4027) lr 7.9389e-03 eta 0:40:36
epoch [10/30] batch [120/392] time 0.289 (0.297) data 0.000 (0.006) loss 7.9453 (2.4874) lr 7.9389e-03 eta 0:40:12
epoch [10/30] batch [140/392] time 0.282 (0.296) data 0.000 (0.006) loss 1.7871 (2.5137) lr 7.9389e-03 eta 0:39:53
epoch [10/30] batch [160/392] time 0.317 (0.295) data 0.000 (0.005) loss 2.9863 (2.5540) lr 7.9389e-03 eta 0:39:39
epoch [10/30] batch [180/392] time 0.276 (0.294) data 0.000 (0.004) loss 2.1230 (2.5358) lr 7.9389e-03 eta 0:39:28
epoch [10/30] batch [200/392] time 0.284 (0.294) data 0.000 (0.004) loss 3.0566 (2.5789) lr 7.9389e-03 eta 0:39:17
epoch [10/30] batch [220/392] time 0.311 (0.293) data 0.001 (0.004) loss 0.5117 (2.5940) lr 7.9389e-03 eta 0:39:10
epoch [10/30] batch [240/392] time 0.285 (0.293) data 0.000 (0.003) loss 1.0273 (2.5749) lr 7.9389e-03 eta 0:39:00
epoch [10/30] batch [260/392] time 0.301 (0.292) data 0.000 (0.003) loss 1.5488 (2.5930) lr 7.9389e-03 eta 0:38:50
epoch [10/30] batch [280/392] time 0.320 (0.293) data 0.000 (0.003) loss 1.8799 (2.5956) lr 7.9389e-03 eta 0:38:48
epoch [10/30] batch [300/392] time 0.290 (0.293) data 0.000 (0.003) loss 1.7275 (2.5732) lr 7.9389e-03 eta 0:38:41
epoch [10/30] batch [320/392] time 0.285 (0.293) data 0.000 (0.003) loss 2.7090 (2.6031) lr 7.9389e-03 eta 0:38:34
epoch [10/30] batch [340/392] time 0.307 (0.292) data 0.000 (0.002) loss 1.2305 (2.5794) lr 7.9389e-03 eta 0:38:26
epoch [10/30] batch [360/392] time 0.281 (0.292) data 0.000 (0.002) loss 4.6953 (2.5861) lr 7.9389e-03 eta 0:38:21
epoch [10/30] batch [380/392] time 0.270 (0.291) data 0.000 (0.002) loss 2.3945 (2.5741) lr 7.9389e-03 eta 0:38:06
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:17,  2.24s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.02s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.60it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.29it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.99it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.68it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.30it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.84it/s]100%|██████████| 9/9 [00:03<00:00,  2.58it/s]=> result
* total: 812
* correct: 581
* accuracy: 71.6%
* error: 28.4%
* macro_f1: 70.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/392] time 0.274 (0.337) data 0.000 (0.035) loss 1.3672 (2.2605) lr 7.5000e-03 eta 0:43:52
epoch [11/30] batch [40/392] time 0.302 (0.317) data 0.000 (0.018) loss 3.7031 (2.3085) lr 7.5000e-03 eta 0:41:15
epoch [11/30] batch [60/392] time 0.292 (0.311) data 0.000 (0.012) loss 1.6348 (2.4723) lr 7.5000e-03 eta 0:40:19
epoch [11/30] batch [80/392] time 0.314 (0.307) data 0.000 (0.009) loss 0.8823 (2.4231) lr 7.5000e-03 eta 0:39:38
epoch [11/30] batch [100/392] time 0.300 (0.305) data 0.000 (0.007) loss 2.8359 (2.4285) lr 7.5000e-03 eta 0:39:18
epoch [11/30] batch [120/392] time 0.293 (0.303) data 0.000 (0.006) loss 1.0605 (2.4747) lr 7.5000e-03 eta 0:38:58
epoch [11/30] batch [140/392] time 0.290 (0.302) data 0.000 (0.005) loss 5.2734 (2.4777) lr 7.5000e-03 eta 0:38:42
epoch [11/30] batch [160/392] time 0.323 (0.300) data 0.000 (0.005) loss 2.0449 (2.4594) lr 7.5000e-03 eta 0:38:27
epoch [11/30] batch [180/392] time 0.284 (0.299) data 0.000 (0.004) loss 1.5342 (2.4364) lr 7.5000e-03 eta 0:38:10
epoch [11/30] batch [200/392] time 0.289 (0.299) data 0.000 (0.004) loss 2.7734 (2.4504) lr 7.5000e-03 eta 0:38:01
epoch [11/30] batch [220/392] time 0.303 (0.299) data 0.000 (0.003) loss 3.6895 (2.4847) lr 7.5000e-03 eta 0:37:55
epoch [11/30] batch [240/392] time 0.289 (0.299) data 0.000 (0.003) loss 3.7090 (2.5185) lr 7.5000e-03 eta 0:37:48
epoch [11/30] batch [260/392] time 0.299 (0.298) data 0.000 (0.003) loss 1.4131 (2.4949) lr 7.5000e-03 eta 0:37:38
epoch [11/30] batch [280/392] time 0.308 (0.298) data 0.000 (0.003) loss 2.7383 (2.4842) lr 7.5000e-03 eta 0:37:30
epoch [11/30] batch [300/392] time 0.307 (0.297) data 0.000 (0.003) loss 3.7188 (2.4938) lr 7.5000e-03 eta 0:37:22
epoch [11/30] batch [320/392] time 0.304 (0.297) data 0.000 (0.002) loss 2.3418 (2.5030) lr 7.5000e-03 eta 0:37:14
epoch [11/30] batch [340/392] time 0.290 (0.297) data 0.000 (0.002) loss 1.6250 (2.4951) lr 7.5000e-03 eta 0:37:06
epoch [11/30] batch [360/392] time 0.283 (0.297) data 0.000 (0.002) loss 3.1035 (2.4710) lr 7.5000e-03 eta 0:37:03
epoch [11/30] batch [380/392] time 0.282 (0.296) data 0.000 (0.002) loss 1.7920 (2.4705) lr 7.5000e-03 eta 0:36:49
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.27s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.08s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.53it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.20it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.90it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.59it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.23it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.79it/s]100%|██████████| 9/9 [00:03<00:00,  2.52it/s]=> result
* total: 812
* correct: 582
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 70.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/392] time 0.285 (0.334) data 0.000 (0.034) loss 3.2754 (2.4424) lr 7.0337e-03 eta 0:41:23
epoch [12/30] batch [40/392] time 0.289 (0.313) data 0.000 (0.017) loss 5.5547 (2.6959) lr 7.0337e-03 eta 0:38:40
epoch [12/30] batch [60/392] time 0.339 (0.308) data 0.000 (0.012) loss 2.6250 (2.5986) lr 7.0337e-03 eta 0:37:51
epoch [12/30] batch [80/392] time 0.287 (0.304) data 0.000 (0.009) loss 3.0684 (2.5821) lr 7.0337e-03 eta 0:37:18
epoch [12/30] batch [100/392] time 0.286 (0.302) data 0.000 (0.007) loss 4.2617 (2.6028) lr 7.0337e-03 eta 0:36:56
epoch [12/30] batch [120/392] time 0.292 (0.299) data 0.000 (0.006) loss 1.8164 (2.5915) lr 7.0337e-03 eta 0:36:31
epoch [12/30] batch [140/392] time 0.291 (0.298) data 0.000 (0.005) loss 3.2129 (2.5631) lr 7.0337e-03 eta 0:36:16
epoch [12/30] batch [160/392] time 0.297 (0.297) data 0.000 (0.004) loss 3.3477 (2.5748) lr 7.0337e-03 eta 0:36:02
epoch [12/30] batch [180/392] time 0.295 (0.296) data 0.000 (0.004) loss 0.6816 (2.5500) lr 7.0337e-03 eta 0:35:53
epoch [12/30] batch [200/392] time 0.293 (0.296) data 0.000 (0.004) loss 2.2617 (2.5319) lr 7.0337e-03 eta 0:35:45
epoch [12/30] batch [220/392] time 0.290 (0.296) data 0.000 (0.003) loss 0.4980 (2.5268) lr 7.0337e-03 eta 0:35:41
epoch [12/30] batch [240/392] time 0.300 (0.296) data 0.000 (0.003) loss 2.3340 (2.5655) lr 7.0337e-03 eta 0:35:34
epoch [12/30] batch [260/392] time 0.309 (0.296) data 0.000 (0.003) loss 3.9238 (2.5190) lr 7.0337e-03 eta 0:35:28
epoch [12/30] batch [280/392] time 0.295 (0.296) data 0.000 (0.003) loss 3.6699 (2.5268) lr 7.0337e-03 eta 0:35:21
epoch [12/30] batch [300/392] time 0.289 (0.296) data 0.000 (0.003) loss 2.1934 (2.5596) lr 7.0337e-03 eta 0:35:13
epoch [12/30] batch [320/392] time 0.287 (0.295) data 0.000 (0.002) loss 1.2012 (2.5420) lr 7.0337e-03 eta 0:35:05
epoch [12/30] batch [340/392] time 0.287 (0.295) data 0.001 (0.002) loss 1.4463 (2.5609) lr 7.0337e-03 eta 0:34:58
epoch [12/30] batch [360/392] time 0.290 (0.295) data 0.000 (0.002) loss 3.3555 (2.5487) lr 7.0337e-03 eta 0:34:51
epoch [12/30] batch [380/392] time 0.274 (0.294) data 0.000 (0.002) loss 1.3672 (2.5247) lr 7.0337e-03 eta 0:34:38
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.33s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.10s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.50it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.15it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.83it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.51it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.14it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.70it/s]100%|██████████| 9/9 [00:03<00:00,  2.47it/s]=> result
* total: 812
* correct: 582
* accuracy: 71.7%
* error: 28.3%
* macro_f1: 70.4%

epoch [13/30] batch [20/392] time 0.287 (0.337) data 0.000 (0.037) loss 3.2637 (2.7512) lr 6.5451e-03 eta 0:39:31
epoch [13/30] batch [40/392] time 0.286 (0.315) data 0.000 (0.018) loss 0.7583 (2.6188) lr 6.5451e-03 eta 0:36:49
epoch [13/30] batch [60/392] time 0.291 (0.311) data 0.000 (0.012) loss 2.3906 (2.7155) lr 6.5451e-03 eta 0:36:12
epoch [13/30] batch [80/392] time 0.286 (0.305) data 0.000 (0.009) loss 4.1758 (2.7191) lr 6.5451e-03 eta 0:35:30
epoch [13/30] batch [100/392] time 0.298 (0.303) data 0.000 (0.008) loss 1.6152 (2.6151) lr 6.5451e-03 eta 0:35:06
epoch [13/30] batch [120/392] time 0.298 (0.302) data 0.000 (0.006) loss 1.2188 (2.5272) lr 6.5451e-03 eta 0:34:51
epoch [13/30] batch [140/392] time 0.305 (0.300) data 0.000 (0.005) loss 4.0117 (2.5436) lr 6.5451e-03 eta 0:34:36
epoch [13/30] batch [160/392] time 0.328 (0.300) data 0.000 (0.005) loss 3.9219 (2.5883) lr 6.5451e-03 eta 0:34:28
epoch [13/30] batch [180/392] time 0.283 (0.299) data 0.000 (0.004) loss 1.9121 (2.5399) lr 6.5451e-03 eta 0:34:15
epoch [13/30] batch [200/392] time 0.281 (0.298) data 0.000 (0.004) loss 0.8418 (2.5233) lr 6.5451e-03 eta 0:34:05
epoch [13/30] batch [220/392] time 0.286 (0.297) data 0.000 (0.004) loss 1.2793 (2.5269) lr 6.5451e-03 eta 0:33:52
epoch [13/30] batch [240/392] time 0.295 (0.297) data 0.000 (0.003) loss 3.9121 (2.5148) lr 6.5451e-03 eta 0:33:44
epoch [13/30] batch [260/392] time 0.329 (0.297) data 0.000 (0.003) loss 1.9150 (2.4828) lr 6.5451e-03 eta 0:33:38
epoch [13/30] batch [280/392] time 0.292 (0.297) data 0.000 (0.003) loss 2.6875 (2.4861) lr 6.5451e-03 eta 0:33:31
epoch [13/30] batch [300/392] time 0.306 (0.297) data 0.000 (0.003) loss 0.7480 (2.4902) lr 6.5451e-03 eta 0:33:24
epoch [13/30] batch [320/392] time 0.285 (0.297) data 0.000 (0.003) loss 6.2305 (2.4965) lr 6.5451e-03 eta 0:33:17
epoch [13/30] batch [340/392] time 0.330 (0.296) data 0.000 (0.002) loss 2.1484 (2.5102) lr 6.5451e-03 eta 0:33:10
epoch [13/30] batch [360/392] time 0.289 (0.296) data 0.000 (0.002) loss 2.2363 (2.4884) lr 6.5451e-03 eta 0:33:04
epoch [13/30] batch [380/392] time 0.277 (0.295) data 0.000 (0.002) loss 1.0830 (2.4782) lr 6.5451e-03 eta 0:32:50
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.29s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.09s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.51it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.18it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.88it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.57it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.20it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.76it/s]100%|██████████| 9/9 [00:03<00:00,  2.50it/s]=> result
* total: 812
* correct: 590
* accuracy: 72.7%
* error: 27.3%
* macro_f1: 71.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [14/30] batch [20/392] time 0.294 (0.333) data 0.000 (0.036) loss 5.3789 (2.4272) lr 6.0396e-03 eta 0:36:51
epoch [14/30] batch [40/392] time 0.289 (0.311) data 0.000 (0.018) loss 4.8125 (2.3028) lr 6.0396e-03 eta 0:34:16
epoch [14/30] batch [60/392] time 0.293 (0.306) data 0.000 (0.012) loss 1.3496 (2.4710) lr 6.0396e-03 eta 0:33:38
epoch [14/30] batch [80/392] time 0.286 (0.301) data 0.000 (0.009) loss 0.8457 (2.3254) lr 6.0396e-03 eta 0:33:03
epoch [14/30] batch [100/392] time 0.283 (0.298) data 0.000 (0.007) loss 2.1016 (2.3911) lr 6.0396e-03 eta 0:32:37
epoch [14/30] batch [120/392] time 0.277 (0.297) data 0.000 (0.006) loss 3.0020 (2.4593) lr 6.0396e-03 eta 0:32:23
epoch [14/30] batch [140/392] time 0.308 (0.296) data 0.000 (0.005) loss 1.5547 (2.5428) lr 6.0396e-03 eta 0:32:13
epoch [14/30] batch [160/392] time 0.286 (0.296) data 0.000 (0.005) loss 1.7227 (2.4850) lr 6.0396e-03 eta 0:32:05
epoch [14/30] batch [180/392] time 0.288 (0.295) data 0.000 (0.004) loss 4.5430 (2.5374) lr 6.0396e-03 eta 0:31:55
epoch [14/30] batch [200/392] time 0.289 (0.296) data 0.000 (0.004) loss 1.6855 (2.5165) lr 6.0396e-03 eta 0:31:51
epoch [14/30] batch [220/392] time 0.299 (0.296) data 0.000 (0.003) loss 1.4492 (2.5106) lr 6.0396e-03 eta 0:31:47
epoch [14/30] batch [240/392] time 0.285 (0.296) data 0.000 (0.003) loss 1.7178 (2.4721) lr 6.0396e-03 eta 0:31:41
epoch [14/30] batch [260/392] time 0.315 (0.296) data 0.000 (0.003) loss 1.8965 (2.4403) lr 6.0396e-03 eta 0:31:37
epoch [14/30] batch [280/392] time 0.284 (0.296) data 0.000 (0.003) loss 1.6631 (2.4193) lr 6.0396e-03 eta 0:31:29
epoch [14/30] batch [300/392] time 0.291 (0.296) data 0.000 (0.003) loss 3.8379 (2.4185) lr 6.0396e-03 eta 0:31:24
epoch [14/30] batch [320/392] time 0.289 (0.296) data 0.000 (0.002) loss 1.9316 (2.4530) lr 6.0396e-03 eta 0:31:15
epoch [14/30] batch [340/392] time 0.282 (0.295) data 0.000 (0.002) loss 1.4980 (2.4538) lr 6.0396e-03 eta 0:31:08
epoch [14/30] batch [360/392] time 0.291 (0.295) data 0.000 (0.002) loss 5.2891 (2.4432) lr 6.0396e-03 eta 0:31:01
epoch [14/30] batch [380/392] time 0.275 (0.295) data 0.000 (0.002) loss 1.1377 (2.4235) lr 6.0396e-03 eta 0:30:51
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.29s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.08s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.48it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.13it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.83it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.49it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.14it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.70it/s]100%|██████████| 9/9 [00:03<00:00,  2.47it/s]=> result
* total: 812
* correct: 584
* accuracy: 71.9%
* error: 28.1%
* macro_f1: 70.9%

epoch [15/30] batch [20/392] time 0.288 (0.327) data 0.000 (0.033) loss 3.5430 (2.1810) lr 5.5226e-03 eta 0:34:03
epoch [15/30] batch [40/392] time 0.291 (0.308) data 0.000 (0.017) loss 1.1133 (2.4374) lr 5.5226e-03 eta 0:32:01
epoch [15/30] batch [60/392] time 0.381 (0.305) data 0.000 (0.011) loss 5.5391 (2.4528) lr 5.5226e-03 eta 0:31:35
epoch [15/30] batch [80/392] time 0.306 (0.302) data 0.000 (0.009) loss 2.1895 (2.4868) lr 5.5226e-03 eta 0:31:07
epoch [15/30] batch [100/392] time 0.298 (0.300) data 0.000 (0.007) loss 2.2324 (2.5057) lr 5.5226e-03 eta 0:30:49
epoch [15/30] batch [120/392] time 0.281 (0.299) data 0.000 (0.006) loss 2.0117 (2.5115) lr 5.5226e-03 eta 0:30:37
epoch [15/30] batch [140/392] time 0.286 (0.298) data 0.000 (0.005) loss 1.3955 (2.4906) lr 5.5226e-03 eta 0:30:25
epoch [15/30] batch [160/392] time 0.285 (0.297) data 0.000 (0.004) loss 1.6172 (2.4699) lr 5.5226e-03 eta 0:30:14
epoch [15/30] batch [180/392] time 0.288 (0.297) data 0.000 (0.004) loss 0.6543 (2.4844) lr 5.5226e-03 eta 0:30:08
epoch [15/30] batch [200/392] time 0.330 (0.297) data 0.000 (0.004) loss 2.0664 (2.4712) lr 5.5226e-03 eta 0:30:03
epoch [15/30] batch [220/392] time 0.304 (0.296) data 0.000 (0.003) loss 2.0293 (2.4362) lr 5.5226e-03 eta 0:29:53
epoch [15/30] batch [240/392] time 0.304 (0.296) data 0.000 (0.003) loss 4.0039 (2.4381) lr 5.5226e-03 eta 0:29:45
epoch [15/30] batch [260/392] time 0.284 (0.296) data 0.000 (0.003) loss 0.5532 (2.4183) lr 5.5226e-03 eta 0:29:39
epoch [15/30] batch [280/392] time 0.312 (0.296) data 0.000 (0.003) loss 0.8491 (2.4011) lr 5.5226e-03 eta 0:29:31
epoch [15/30] batch [300/392] time 0.280 (0.295) data 0.000 (0.002) loss 0.4924 (2.3757) lr 5.5226e-03 eta 0:29:22
epoch [15/30] batch [320/392] time 0.289 (0.295) data 0.000 (0.002) loss 1.0713 (2.3778) lr 5.5226e-03 eta 0:29:15
epoch [15/30] batch [340/392] time 0.288 (0.295) data 0.000 (0.002) loss 1.5732 (2.3964) lr 5.5226e-03 eta 0:29:09
epoch [15/30] batch [360/392] time 0.294 (0.295) data 0.000 (0.002) loss 2.9941 (2.3842) lr 5.5226e-03 eta 0:29:02
epoch [15/30] batch [380/392] time 0.272 (0.294) data 0.000 (0.002) loss 0.8848 (2.3803) lr 5.5226e-03 eta 0:28:51
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:17,  2.23s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.06s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.54it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.21it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.92it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.61it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.25it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.81it/s]100%|██████████| 9/9 [00:03<00:00,  2.53it/s]=> result
* total: 812
* correct: 583
* accuracy: 71.8%
* error: 28.2%
* macro_f1: 70.7%

epoch [16/30] batch [20/392] time 0.281 (0.324) data 0.000 (0.033) loss 2.1445 (2.2354) lr 5.0000e-03 eta 0:31:41
epoch [16/30] batch [40/392] time 0.281 (0.307) data 0.000 (0.017) loss 1.9941 (2.5052) lr 5.0000e-03 eta 0:29:53
epoch [16/30] batch [60/392] time 0.282 (0.304) data 0.000 (0.011) loss 3.2207 (2.4587) lr 5.0000e-03 eta 0:29:27
epoch [16/30] batch [80/392] time 0.294 (0.301) data 0.000 (0.008) loss 1.3936 (2.3920) lr 5.0000e-03 eta 0:29:05
epoch [16/30] batch [100/392] time 0.290 (0.300) data 0.000 (0.007) loss 3.6309 (2.3725) lr 5.0000e-03 eta 0:28:52
epoch [16/30] batch [120/392] time 0.279 (0.298) data 0.000 (0.006) loss 4.4922 (2.3938) lr 5.0000e-03 eta 0:28:35
epoch [16/30] batch [140/392] time 0.287 (0.297) data 0.000 (0.005) loss 2.4512 (2.4172) lr 5.0000e-03 eta 0:28:23
epoch [16/30] batch [160/392] time 0.289 (0.296) data 0.000 (0.004) loss 0.8184 (2.4203) lr 5.0000e-03 eta 0:28:10
epoch [16/30] batch [180/392] time 0.301 (0.295) data 0.000 (0.004) loss 3.4727 (2.4082) lr 5.0000e-03 eta 0:28:02
epoch [16/30] batch [200/392] time 0.284 (0.295) data 0.000 (0.004) loss 2.5117 (2.4599) lr 5.0000e-03 eta 0:27:54
epoch [16/30] batch [220/392] time 0.283 (0.295) data 0.000 (0.003) loss 2.7148 (2.4694) lr 5.0000e-03 eta 0:27:48
epoch [16/30] batch [240/392] time 0.377 (0.295) data 0.000 (0.003) loss 1.4131 (2.4559) lr 5.0000e-03 eta 0:27:42
epoch [16/30] batch [260/392] time 0.289 (0.294) data 0.000 (0.003) loss 1.2490 (2.4380) lr 5.0000e-03 eta 0:27:33
epoch [16/30] batch [280/392] time 0.303 (0.294) data 0.000 (0.003) loss 1.2773 (2.4461) lr 5.0000e-03 eta 0:27:26
epoch [16/30] batch [300/392] time 0.286 (0.294) data 0.000 (0.002) loss 2.1934 (2.4363) lr 5.0000e-03 eta 0:27:20
epoch [16/30] batch [320/392] time 0.283 (0.294) data 0.000 (0.002) loss 1.6377 (2.4661) lr 5.0000e-03 eta 0:27:14
epoch [16/30] batch [340/392] time 0.313 (0.294) data 0.000 (0.002) loss 2.8574 (2.4751) lr 5.0000e-03 eta 0:27:07
epoch [16/30] batch [360/392] time 0.306 (0.294) data 0.000 (0.002) loss 1.9580 (2.4534) lr 5.0000e-03 eta 0:27:01
epoch [16/30] batch [380/392] time 0.272 (0.293) data 0.000 (0.002) loss 1.4180 (2.4547) lr 5.0000e-03 eta 0:26:50
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.55s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.20s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.39it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.02it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.70it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.39it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.04it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.62it/s]100%|██████████| 9/9 [00:03<00:00,  2.33it/s]=> result
* total: 812
* correct: 580
* accuracy: 71.4%
* error: 28.6%
* macro_f1: 70.3%

epoch [17/30] batch [20/392] time 0.285 (0.335) data 0.000 (0.040) loss 3.9102 (2.5258) lr 4.4774e-03 eta 0:30:32
epoch [17/30] batch [40/392] time 0.296 (0.313) data 0.000 (0.020) loss 4.2578 (2.5124) lr 4.4774e-03 eta 0:28:25
epoch [17/30] batch [60/392] time 0.295 (0.309) data 0.000 (0.013) loss 1.1738 (2.5442) lr 4.4774e-03 eta 0:27:59
epoch [17/30] batch [80/392] time 0.352 (0.306) data 0.000 (0.010) loss 3.3789 (2.4916) lr 4.4774e-03 eta 0:27:37
epoch [17/30] batch [100/392] time 0.287 (0.303) data 0.000 (0.008) loss 1.6055 (2.5156) lr 4.4774e-03 eta 0:27:11
epoch [17/30] batch [120/392] time 0.298 (0.301) data 0.000 (0.007) loss 5.7656 (2.5187) lr 4.4774e-03 eta 0:26:53
epoch [17/30] batch [140/392] time 0.288 (0.300) data 0.000 (0.006) loss 3.1699 (2.4409) lr 4.4774e-03 eta 0:26:41
epoch [17/30] batch [160/392] time 0.279 (0.298) data 0.000 (0.005) loss 5.5977 (2.4737) lr 4.4774e-03 eta 0:26:29
epoch [17/30] batch [180/392] time 0.302 (0.297) data 0.000 (0.005) loss 2.4316 (2.4530) lr 4.4774e-03 eta 0:26:17
epoch [17/30] batch [200/392] time 0.288 (0.297) data 0.000 (0.004) loss 1.4658 (2.4656) lr 4.4774e-03 eta 0:26:08
epoch [17/30] batch [220/392] time 0.279 (0.296) data 0.000 (0.004) loss 0.3318 (2.4581) lr 4.4774e-03 eta 0:26:00
epoch [17/30] batch [240/392] time 0.303 (0.295) data 0.000 (0.004) loss 3.5000 (2.4489) lr 4.4774e-03 eta 0:25:50
epoch [17/30] batch [260/392] time 0.288 (0.295) data 0.000 (0.003) loss 1.9268 (2.4639) lr 4.4774e-03 eta 0:25:40
epoch [17/30] batch [280/392] time 0.312 (0.294) data 0.000 (0.003) loss 4.1914 (2.4745) lr 4.4774e-03 eta 0:25:32
epoch [17/30] batch [300/392] time 0.288 (0.294) data 0.000 (0.003) loss 0.7690 (2.4466) lr 4.4774e-03 eta 0:25:23
epoch [17/30] batch [320/392] time 0.284 (0.293) data 0.000 (0.003) loss 1.6299 (2.4203) lr 4.4774e-03 eta 0:25:16
epoch [17/30] batch [340/392] time 0.299 (0.294) data 0.000 (0.003) loss 1.5977 (2.4106) lr 4.4774e-03 eta 0:25:11
epoch [17/30] batch [360/392] time 0.287 (0.294) data 0.000 (0.002) loss 6.1328 (2.4593) lr 4.4774e-03 eta 0:25:05
epoch [17/30] batch [380/392] time 0.271 (0.292) data 0.000 (0.002) loss 1.5811 (2.4513) lr 4.4774e-03 eta 0:24:53
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.26s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.03s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.59it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.28it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.98it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.67it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.31it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.86it/s]100%|██████████| 9/9 [00:03<00:00,  2.58it/s]=> result
* total: 812
* correct: 596
* accuracy: 73.4%
* error: 26.6%
* macro_f1: 72.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/392] time 0.299 (0.327) data 0.000 (0.033) loss 2.7578 (2.1215) lr 3.9604e-03 eta 0:27:39
epoch [18/30] batch [40/392] time 0.337 (0.312) data 0.000 (0.017) loss 2.0234 (1.8838) lr 3.9604e-03 eta 0:26:18
epoch [18/30] batch [60/392] time 0.285 (0.304) data 0.000 (0.011) loss 2.7812 (2.0134) lr 3.9604e-03 eta 0:25:28
epoch [18/30] batch [80/392] time 0.285 (0.301) data 0.000 (0.009) loss 1.7695 (2.0158) lr 3.9604e-03 eta 0:25:10
epoch [18/30] batch [100/392] time 0.300 (0.299) data 0.000 (0.007) loss 1.4131 (2.1563) lr 3.9604e-03 eta 0:24:55
epoch [18/30] batch [120/392] time 0.287 (0.298) data 0.000 (0.006) loss 3.1680 (2.1755) lr 3.9604e-03 eta 0:24:43
epoch [18/30] batch [140/392] time 0.278 (0.297) data 0.000 (0.005) loss 3.9941 (2.1989) lr 3.9604e-03 eta 0:24:34
epoch [18/30] batch [160/392] time 0.288 (0.297) data 0.000 (0.004) loss 2.9492 (2.1965) lr 3.9604e-03 eta 0:24:25
epoch [18/30] batch [180/392] time 0.284 (0.296) data 0.000 (0.004) loss 0.8926 (2.2211) lr 3.9604e-03 eta 0:24:14
epoch [18/30] batch [200/392] time 0.295 (0.295) data 0.000 (0.004) loss 4.2891 (2.2413) lr 3.9604e-03 eta 0:24:06
epoch [18/30] batch [220/392] time 0.281 (0.295) data 0.000 (0.003) loss 0.6245 (2.2566) lr 3.9604e-03 eta 0:23:59
epoch [18/30] batch [240/392] time 0.336 (0.295) data 0.000 (0.003) loss 1.8066 (2.2632) lr 3.9604e-03 eta 0:23:50
epoch [18/30] batch [260/392] time 0.306 (0.295) data 0.000 (0.003) loss 2.9863 (2.3295) lr 3.9604e-03 eta 0:23:44
epoch [18/30] batch [280/392] time 0.310 (0.294) data 0.000 (0.003) loss 1.4688 (2.3471) lr 3.9604e-03 eta 0:23:37
epoch [18/30] batch [300/392] time 0.282 (0.294) data 0.000 (0.002) loss 2.9160 (2.3590) lr 3.9604e-03 eta 0:23:29
epoch [18/30] batch [320/392] time 0.287 (0.294) data 0.000 (0.002) loss 1.3223 (2.3684) lr 3.9604e-03 eta 0:23:23
epoch [18/30] batch [340/392] time 0.286 (0.294) data 0.000 (0.002) loss 0.8315 (2.3755) lr 3.9604e-03 eta 0:23:18
epoch [18/30] batch [360/392] time 0.314 (0.294) data 0.000 (0.002) loss 4.3008 (2.4010) lr 3.9604e-03 eta 0:23:11
epoch [18/30] batch [380/392] time 0.272 (0.293) data 0.000 (0.002) loss 0.6260 (2.3934) lr 3.9604e-03 eta 0:23:00
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:21,  2.70s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.20s/it] 33%|███▎      | 3/9 [00:03<00:04,  1.38it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.00it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.67it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.35it/s] 78%|███████▊  | 7/9 [00:03<00:00,  3.99it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.57it/s]100%|██████████| 9/9 [00:03<00:00,  2.29it/s]=> result
* total: 812
* correct: 590
* accuracy: 72.7%
* error: 27.3%
* macro_f1: 71.7%

epoch [19/30] batch [20/392] time 0.288 (0.336) data 0.000 (0.036) loss 1.2734 (2.1756) lr 3.4549e-03 eta 0:26:11
epoch [19/30] batch [40/392] time 0.279 (0.312) data 0.000 (0.018) loss 2.9727 (2.3364) lr 3.4549e-03 eta 0:24:17
epoch [19/30] batch [60/392] time 0.286 (0.304) data 0.000 (0.012) loss 3.0820 (2.4524) lr 3.4549e-03 eta 0:23:32
epoch [19/30] batch [80/392] time 0.323 (0.302) data 0.000 (0.009) loss 3.5215 (2.5918) lr 3.4549e-03 eta 0:23:16
epoch [19/30] batch [100/392] time 0.283 (0.301) data 0.000 (0.007) loss 4.5000 (2.5238) lr 3.4549e-03 eta 0:23:03
epoch [19/30] batch [120/392] time 0.292 (0.300) data 0.000 (0.006) loss 4.0703 (2.4939) lr 3.4549e-03 eta 0:22:54
epoch [19/30] batch [140/392] time 0.290 (0.299) data 0.000 (0.005) loss 1.1787 (2.5236) lr 3.4549e-03 eta 0:22:42
epoch [19/30] batch [160/392] time 0.286 (0.298) data 0.000 (0.005) loss 1.6338 (2.4899) lr 3.4549e-03 eta 0:22:32
epoch [19/30] batch [180/392] time 0.302 (0.297) data 0.000 (0.004) loss 2.7031 (2.5029) lr 3.4549e-03 eta 0:22:24
epoch [19/30] batch [200/392] time 0.283 (0.297) data 0.000 (0.004) loss 2.3066 (2.5140) lr 3.4549e-03 eta 0:22:19
epoch [19/30] batch [220/392] time 0.286 (0.297) data 0.000 (0.003) loss 1.4336 (2.4504) lr 3.4549e-03 eta 0:22:11
epoch [19/30] batch [240/392] time 0.280 (0.296) data 0.000 (0.003) loss 1.4053 (2.4667) lr 3.4549e-03 eta 0:22:03
epoch [19/30] batch [260/392] time 0.282 (0.296) data 0.000 (0.003) loss 1.8008 (2.4317) lr 3.4549e-03 eta 0:21:56
epoch [19/30] batch [280/392] time 0.286 (0.296) data 0.000 (0.003) loss 3.4277 (2.4037) lr 3.4549e-03 eta 0:21:51
epoch [19/30] batch [300/392] time 0.295 (0.296) data 0.000 (0.003) loss 1.5850 (2.4214) lr 3.4549e-03 eta 0:21:45
epoch [19/30] batch [320/392] time 0.281 (0.296) data 0.000 (0.002) loss 2.2754 (2.4273) lr 3.4549e-03 eta 0:21:37
epoch [19/30] batch [340/392] time 0.293 (0.295) data 0.000 (0.002) loss 7.6172 (2.4465) lr 3.4549e-03 eta 0:21:29
epoch [19/30] batch [360/392] time 0.298 (0.295) data 0.000 (0.002) loss 1.5371 (2.4162) lr 3.4549e-03 eta 0:21:22
epoch [19/30] batch [380/392] time 0.273 (0.294) data 0.000 (0.002) loss 2.9688 (2.4255) lr 3.4549e-03 eta 0:21:11
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:19,  2.47s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.13s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.46it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.12it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.81it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.51it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.16it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.73it/s]100%|██████████| 9/9 [00:03<00:00,  2.42it/s]=> result
* total: 812
* correct: 583
* accuracy: 71.8%
* error: 28.2%
* macro_f1: 70.4%

epoch [20/30] batch [20/392] time 0.286 (0.346) data 0.000 (0.035) loss 5.4375 (2.3971) lr 2.9663e-03 eta 0:24:46
epoch [20/30] batch [40/392] time 0.293 (0.319) data 0.000 (0.018) loss 1.7080 (2.2412) lr 2.9663e-03 eta 0:22:43
epoch [20/30] batch [60/392] time 0.282 (0.309) data 0.000 (0.012) loss 1.0137 (2.1938) lr 2.9663e-03 eta 0:21:52
epoch [20/30] batch [80/392] time 0.306 (0.307) data 0.000 (0.009) loss 0.6250 (2.2673) lr 2.9663e-03 eta 0:21:40
epoch [20/30] batch [100/392] time 0.278 (0.304) data 0.000 (0.007) loss 0.8125 (2.2553) lr 2.9663e-03 eta 0:21:18
epoch [20/30] batch [120/392] time 0.284 (0.301) data 0.000 (0.006) loss 2.3809 (2.2263) lr 2.9663e-03 eta 0:21:03
epoch [20/30] batch [140/392] time 0.311 (0.300) data 0.000 (0.005) loss 0.7158 (2.2706) lr 2.9663e-03 eta 0:20:51
epoch [20/30] batch [160/392] time 0.325 (0.299) data 0.000 (0.005) loss 2.0430 (2.2924) lr 2.9663e-03 eta 0:20:41
epoch [20/30] batch [180/392] time 0.295 (0.298) data 0.000 (0.004) loss 2.3027 (2.2530) lr 2.9663e-03 eta 0:20:31
epoch [20/30] batch [200/392] time 0.293 (0.298) data 0.000 (0.004) loss 2.5391 (2.2333) lr 2.9663e-03 eta 0:20:26
epoch [20/30] batch [220/392] time 0.291 (0.298) data 0.000 (0.003) loss 1.4209 (2.2671) lr 2.9663e-03 eta 0:20:20
epoch [20/30] batch [240/392] time 0.317 (0.298) data 0.000 (0.003) loss 2.7070 (2.2768) lr 2.9663e-03 eta 0:20:13
epoch [20/30] batch [260/392] time 0.289 (0.298) data 0.000 (0.003) loss 2.0664 (2.2862) lr 2.9663e-03 eta 0:20:05
epoch [20/30] batch [280/392] time 0.284 (0.297) data 0.000 (0.003) loss 3.6816 (2.3135) lr 2.9663e-03 eta 0:19:58
epoch [20/30] batch [300/392] time 0.288 (0.297) data 0.000 (0.003) loss 1.8242 (2.3123) lr 2.9663e-03 eta 0:19:50
epoch [20/30] batch [320/392] time 0.329 (0.297) data 0.000 (0.002) loss 4.3945 (2.3377) lr 2.9663e-03 eta 0:19:44
epoch [20/30] batch [340/392] time 0.288 (0.296) data 0.000 (0.002) loss 2.3867 (2.3380) lr 2.9663e-03 eta 0:19:36
epoch [20/30] batch [360/392] time 0.288 (0.296) data 0.000 (0.002) loss 1.4502 (2.3557) lr 2.9663e-03 eta 0:19:31
epoch [20/30] batch [380/392] time 0.276 (0.295) data 0.000 (0.002) loss 3.1465 (2.3771) lr 2.9663e-03 eta 0:19:20
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.55s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.14s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.45it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.10it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.79it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.47it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.12it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.68it/s]100%|██████████| 9/9 [00:03<00:00,  2.38it/s]=> result
* total: 812
* correct: 599
* accuracy: 73.8%
* error: 26.2%
* macro_f1: 72.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/392] time 0.304 (0.335) data 0.000 (0.035) loss 4.6406 (2.1720) lr 2.5000e-03 eta 0:21:45
epoch [21/30] batch [40/392] time 0.284 (0.312) data 0.000 (0.018) loss 4.0781 (2.1723) lr 2.5000e-03 eta 0:20:11
epoch [21/30] batch [60/392] time 0.290 (0.306) data 0.000 (0.012) loss 1.4551 (2.1687) lr 2.5000e-03 eta 0:19:40
epoch [21/30] batch [80/392] time 0.319 (0.302) data 0.000 (0.009) loss 3.4102 (2.1011) lr 2.5000e-03 eta 0:19:19
epoch [21/30] batch [100/392] time 0.283 (0.301) data 0.000 (0.007) loss 3.7168 (2.1525) lr 2.5000e-03 eta 0:19:08
epoch [21/30] batch [120/392] time 0.279 (0.299) data 0.000 (0.006) loss 0.4587 (2.1769) lr 2.5000e-03 eta 0:18:57
epoch [21/30] batch [140/392] time 0.288 (0.299) data 0.000 (0.005) loss 5.6133 (2.2460) lr 2.5000e-03 eta 0:18:50
epoch [21/30] batch [160/392] time 0.288 (0.298) data 0.001 (0.005) loss 2.6250 (2.2680) lr 2.5000e-03 eta 0:18:39
epoch [21/30] batch [180/392] time 0.295 (0.297) data 0.000 (0.004) loss 7.3906 (2.3155) lr 2.5000e-03 eta 0:18:32
epoch [21/30] batch [200/392] time 0.289 (0.297) data 0.000 (0.004) loss 1.5498 (2.3086) lr 2.5000e-03 eta 0:18:24
epoch [21/30] batch [220/392] time 0.319 (0.297) data 0.000 (0.003) loss 1.2393 (2.3167) lr 2.5000e-03 eta 0:18:20
epoch [21/30] batch [240/392] time 0.284 (0.296) data 0.000 (0.003) loss 1.3262 (2.2990) lr 2.5000e-03 eta 0:18:10
epoch [21/30] batch [260/392] time 0.296 (0.296) data 0.000 (0.003) loss 0.8057 (2.2821) lr 2.5000e-03 eta 0:18:02
epoch [21/30] batch [280/392] time 0.293 (0.295) data 0.000 (0.003) loss 0.4700 (2.2871) lr 2.5000e-03 eta 0:17:55
epoch [21/30] batch [300/392] time 0.306 (0.295) data 0.000 (0.003) loss 7.0703 (2.3073) lr 2.5000e-03 eta 0:17:48
epoch [21/30] batch [320/392] time 0.280 (0.295) data 0.000 (0.002) loss 2.5273 (2.3055) lr 2.5000e-03 eta 0:17:42
epoch [21/30] batch [340/392] time 0.288 (0.295) data 0.000 (0.002) loss 2.2734 (2.3311) lr 2.5000e-03 eta 0:17:35
epoch [21/30] batch [360/392] time 0.283 (0.295) data 0.000 (0.002) loss 3.5957 (2.3356) lr 2.5000e-03 eta 0:17:29
epoch [21/30] batch [380/392] time 0.272 (0.294) data 0.000 (0.002) loss 1.6738 (2.3135) lr 2.5000e-03 eta 0:17:19
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.37s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.12s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.48it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.14it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.83it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.52it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.16it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.73it/s]100%|██████████| 9/9 [00:03<00:00,  2.45it/s]=> result
* total: 812
* correct: 595
* accuracy: 73.3%
* error: 26.7%
* macro_f1: 72.2%

epoch [22/30] batch [20/392] time 0.311 (0.333) data 0.000 (0.036) loss 6.2930 (2.2405) lr 2.0611e-03 eta 0:19:28
epoch [22/30] batch [40/392] time 0.286 (0.312) data 0.000 (0.018) loss 0.9604 (2.1986) lr 2.0611e-03 eta 0:18:09
epoch [22/30] batch [60/392] time 0.277 (0.307) data 0.000 (0.012) loss 1.5947 (2.2373) lr 2.0611e-03 eta 0:17:43
epoch [22/30] batch [80/392] time 0.287 (0.302) data 0.000 (0.009) loss 2.3027 (2.2274) lr 2.0611e-03 eta 0:17:22
epoch [22/30] batch [100/392] time 0.294 (0.300) data 0.000 (0.007) loss 4.1289 (2.1406) lr 2.0611e-03 eta 0:17:08
epoch [22/30] batch [120/392] time 0.288 (0.297) data 0.000 (0.006) loss 1.1865 (2.1824) lr 2.0611e-03 eta 0:16:53
epoch [22/30] batch [140/392] time 0.278 (0.297) data 0.000 (0.005) loss 3.3691 (2.2164) lr 2.0611e-03 eta 0:16:44
epoch [22/30] batch [160/392] time 0.337 (0.296) data 0.000 (0.005) loss 1.7529 (2.2296) lr 2.0611e-03 eta 0:16:35
epoch [22/30] batch [180/392] time 0.293 (0.295) data 0.000 (0.004) loss 1.3535 (2.2299) lr 2.0611e-03 eta 0:16:27
epoch [22/30] batch [200/392] time 0.281 (0.295) data 0.000 (0.004) loss 2.2402 (2.2247) lr 2.0611e-03 eta 0:16:20
epoch [22/30] batch [220/392] time 0.301 (0.294) data 0.000 (0.003) loss 1.7119 (2.2482) lr 2.0611e-03 eta 0:16:13
epoch [22/30] batch [240/392] time 0.299 (0.294) data 0.000 (0.003) loss 3.4512 (2.2719) lr 2.0611e-03 eta 0:16:08
epoch [22/30] batch [260/392] time 0.299 (0.294) data 0.000 (0.003) loss 3.1152 (2.2470) lr 2.0611e-03 eta 0:16:00
epoch [22/30] batch [280/392] time 0.280 (0.294) data 0.000 (0.003) loss 1.9658 (2.2398) lr 2.0611e-03 eta 0:15:53
epoch [22/30] batch [300/392] time 0.290 (0.294) data 0.000 (0.003) loss 1.1387 (2.2331) lr 2.0611e-03 eta 0:15:47
epoch [22/30] batch [320/392] time 0.284 (0.293) data 0.000 (0.002) loss 1.6270 (2.2356) lr 2.0611e-03 eta 0:15:41
epoch [22/30] batch [340/392] time 0.286 (0.294) data 0.000 (0.002) loss 4.1797 (2.2361) lr 2.0611e-03 eta 0:15:35
epoch [22/30] batch [360/392] time 0.286 (0.293) data 0.000 (0.002) loss 1.0000 (2.2518) lr 2.0611e-03 eta 0:15:29
epoch [22/30] batch [380/392] time 0.272 (0.292) data 0.000 (0.002) loss 1.1875 (2.2401) lr 2.0611e-03 eta 0:15:20
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:19,  2.42s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.10s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.51it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.17it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.88it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.57it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.22it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.77it/s]100%|██████████| 9/9 [00:03<00:00,  2.48it/s]=> result
* total: 812
* correct: 603
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 72.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [23/30] batch [20/392] time 0.289 (0.331) data 0.000 (0.034) loss 5.0938 (2.2997) lr 1.6543e-03 eta 0:17:12
epoch [23/30] batch [40/392] time 0.286 (0.314) data 0.000 (0.017) loss 2.7832 (2.3432) lr 1.6543e-03 eta 0:16:12
epoch [23/30] batch [60/392] time 0.288 (0.306) data 0.000 (0.011) loss 2.7148 (2.3867) lr 1.6543e-03 eta 0:15:40
epoch [23/30] batch [80/392] time 0.284 (0.303) data 0.000 (0.009) loss 1.7383 (2.2642) lr 1.6543e-03 eta 0:15:25
epoch [23/30] batch [100/392] time 0.296 (0.301) data 0.000 (0.007) loss 1.2129 (2.1849) lr 1.6543e-03 eta 0:15:14
epoch [23/30] batch [120/392] time 0.288 (0.299) data 0.000 (0.006) loss 2.2207 (2.1896) lr 1.6543e-03 eta 0:15:03
epoch [23/30] batch [140/392] time 0.278 (0.299) data 0.000 (0.005) loss 2.1523 (2.2125) lr 1.6543e-03 eta 0:14:55
epoch [23/30] batch [160/392] time 0.295 (0.299) data 0.000 (0.004) loss 2.5293 (2.2676) lr 1.6543e-03 eta 0:14:50
epoch [23/30] batch [180/392] time 0.299 (0.300) data 0.000 (0.004) loss 1.0068 (2.2645) lr 1.6543e-03 eta 0:14:45
epoch [23/30] batch [200/392] time 0.301 (0.299) data 0.000 (0.004) loss 1.4180 (2.2266) lr 1.6543e-03 eta 0:14:37
epoch [23/30] batch [220/392] time 0.297 (0.299) data 0.000 (0.003) loss 1.2393 (2.2142) lr 1.6543e-03 eta 0:14:30
epoch [23/30] batch [240/392] time 0.301 (0.298) data 0.000 (0.003) loss 0.9351 (2.2148) lr 1.6543e-03 eta 0:14:23
epoch [23/30] batch [260/392] time 0.327 (0.298) data 0.000 (0.003) loss 2.4043 (2.2239) lr 1.6543e-03 eta 0:14:16
epoch [23/30] batch [280/392] time 0.292 (0.297) data 0.000 (0.003) loss 0.3535 (2.1845) lr 1.6543e-03 eta 0:14:08
epoch [23/30] batch [300/392] time 0.278 (0.297) data 0.000 (0.003) loss 4.1211 (2.2132) lr 1.6543e-03 eta 0:14:01
epoch [23/30] batch [320/392] time 0.286 (0.297) data 0.000 (0.002) loss 1.7119 (2.2273) lr 1.6543e-03 eta 0:13:55
epoch [23/30] batch [340/392] time 0.360 (0.297) data 0.000 (0.002) loss 5.7930 (2.2479) lr 1.6543e-03 eta 0:13:49
epoch [23/30] batch [360/392] time 0.279 (0.296) data 0.000 (0.002) loss 2.9414 (2.2584) lr 1.6543e-03 eta 0:13:42
epoch [23/30] batch [380/392] time 0.279 (0.295) data 0.000 (0.002) loss 2.0234 (2.2480) lr 1.6543e-03 eta 0:13:33
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:19,  2.41s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.09s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.52it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.19it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.88it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.58it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.22it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.79it/s]100%|██████████| 9/9 [00:03<00:00,  2.48it/s]=> result
* total: 812
* correct: 602
* accuracy: 74.1%
* error: 25.9%
* macro_f1: 73.0%

epoch [24/30] batch [20/392] time 0.302 (0.331) data 0.000 (0.035) loss 0.5068 (2.2573) lr 1.2843e-03 eta 0:15:02
epoch [24/30] batch [40/392] time 0.291 (0.312) data 0.000 (0.018) loss 1.7520 (2.2963) lr 1.2843e-03 eta 0:14:03
epoch [24/30] batch [60/392] time 0.294 (0.306) data 0.000 (0.012) loss 0.8765 (2.2395) lr 1.2843e-03 eta 0:13:40
epoch [24/30] batch [80/392] time 0.286 (0.301) data 0.000 (0.009) loss 0.7720 (2.2297) lr 1.2843e-03 eta 0:13:22
epoch [24/30] batch [100/392] time 0.280 (0.299) data 0.000 (0.007) loss 2.7207 (2.2408) lr 1.2843e-03 eta 0:13:10
epoch [24/30] batch [120/392] time 0.288 (0.298) data 0.000 (0.006) loss 4.2930 (2.2558) lr 1.2843e-03 eta 0:13:01
epoch [24/30] batch [140/392] time 0.290 (0.297) data 0.000 (0.005) loss 2.0195 (2.2853) lr 1.2843e-03 eta 0:12:52
epoch [24/30] batch [160/392] time 0.301 (0.296) data 0.000 (0.005) loss 2.1953 (2.2159) lr 1.2843e-03 eta 0:12:46
epoch [24/30] batch [180/392] time 0.302 (0.296) data 0.000 (0.004) loss 2.7266 (2.2229) lr 1.2843e-03 eta 0:12:40
epoch [24/30] batch [200/392] time 0.308 (0.296) data 0.000 (0.004) loss 1.3848 (2.2193) lr 1.2843e-03 eta 0:12:33
epoch [24/30] batch [220/392] time 0.282 (0.296) data 0.000 (0.003) loss 1.1797 (2.1923) lr 1.2843e-03 eta 0:12:26
epoch [24/30] batch [240/392] time 0.284 (0.295) data 0.000 (0.003) loss 1.9229 (2.1790) lr 1.2843e-03 eta 0:12:18
epoch [24/30] batch [260/392] time 0.276 (0.294) data 0.000 (0.003) loss 1.5791 (2.2059) lr 1.2843e-03 eta 0:12:11
epoch [24/30] batch [280/392] time 0.285 (0.294) data 0.000 (0.003) loss 1.6885 (2.2116) lr 1.2843e-03 eta 0:12:04
epoch [24/30] batch [300/392] time 0.303 (0.294) data 0.000 (0.003) loss 2.8203 (2.2056) lr 1.2843e-03 eta 0:11:58
epoch [24/30] batch [320/392] time 0.287 (0.294) data 0.000 (0.002) loss 4.5820 (2.2358) lr 1.2843e-03 eta 0:11:53
epoch [24/30] batch [340/392] time 0.304 (0.294) data 0.000 (0.002) loss 2.6816 (2.2480) lr 1.2843e-03 eta 0:11:47
epoch [24/30] batch [360/392] time 0.311 (0.294) data 0.000 (0.002) loss 0.5430 (2.2283) lr 1.2843e-03 eta 0:11:41
epoch [24/30] batch [380/392] time 0.272 (0.293) data 0.000 (0.002) loss 2.2871 (2.2302) lr 1.2843e-03 eta 0:11:33
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:17,  2.25s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.07s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.50it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.17it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.86it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.55it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.20it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.78it/s]100%|██████████| 9/9 [00:03<00:00,  2.50it/s]=> result
* total: 812
* correct: 606
* accuracy: 74.6%
* error: 25.4%
* macro_f1: 73.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [25/30] batch [20/392] time 0.311 (0.331) data 0.000 (0.038) loss 2.6270 (2.2555) lr 9.5492e-04 eta 0:12:52
epoch [25/30] batch [40/392] time 0.287 (0.309) data 0.000 (0.019) loss 1.9492 (2.2858) lr 9.5492e-04 eta 0:11:54
epoch [25/30] batch [60/392] time 0.282 (0.303) data 0.000 (0.013) loss 0.0704 (2.2897) lr 9.5492e-04 eta 0:11:33
epoch [25/30] batch [80/392] time 0.281 (0.300) data 0.000 (0.010) loss 1.3066 (2.3615) lr 9.5492e-04 eta 0:11:22
epoch [25/30] batch [100/392] time 0.286 (0.298) data 0.000 (0.008) loss 1.6670 (2.3404) lr 9.5492e-04 eta 0:11:11
epoch [25/30] batch [120/392] time 0.304 (0.297) data 0.000 (0.007) loss 2.5898 (2.3185) lr 9.5492e-04 eta 0:11:03
epoch [25/30] batch [140/392] time 0.289 (0.296) data 0.000 (0.006) loss 2.2988 (2.3051) lr 9.5492e-04 eta 0:10:55
epoch [25/30] batch [160/392] time 0.277 (0.295) data 0.000 (0.005) loss 0.9092 (2.2947) lr 9.5492e-04 eta 0:10:47
epoch [25/30] batch [180/392] time 0.284 (0.295) data 0.000 (0.004) loss 5.2031 (2.3359) lr 9.5492e-04 eta 0:10:41
epoch [25/30] batch [200/392] time 0.281 (0.295) data 0.000 (0.004) loss 2.3125 (2.2972) lr 9.5492e-04 eta 0:10:35
epoch [25/30] batch [220/392] time 0.292 (0.295) data 0.000 (0.004) loss 0.8296 (2.3014) lr 9.5492e-04 eta 0:10:28
epoch [25/30] batch [240/392] time 0.283 (0.295) data 0.000 (0.003) loss 1.4375 (2.2691) lr 9.5492e-04 eta 0:10:22
epoch [25/30] batch [260/392] time 0.288 (0.295) data 0.000 (0.003) loss 3.4531 (2.3025) lr 9.5492e-04 eta 0:10:16
epoch [25/30] batch [280/392] time 0.302 (0.294) data 0.000 (0.003) loss 2.4824 (2.3357) lr 9.5492e-04 eta 0:10:09
epoch [25/30] batch [300/392] time 0.284 (0.294) data 0.000 (0.003) loss 7.2227 (2.3698) lr 9.5492e-04 eta 0:10:04
epoch [25/30] batch [320/392] time 0.311 (0.294) data 0.000 (0.003) loss 2.4004 (2.3958) lr 9.5492e-04 eta 0:09:58
epoch [25/30] batch [340/392] time 0.291 (0.294) data 0.000 (0.002) loss 3.9961 (2.3826) lr 9.5492e-04 eta 0:09:52
epoch [25/30] batch [360/392] time 0.290 (0.294) data 0.000 (0.002) loss 1.7666 (2.3668) lr 9.5492e-04 eta 0:09:46
epoch [25/30] batch [380/392] time 0.275 (0.293) data 0.000 (0.002) loss 0.4568 (2.3646) lr 9.5492e-04 eta 0:09:38
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.30s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.06s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.55it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.23it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.94it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.63it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.27it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.78it/s]100%|██████████| 9/9 [00:03<00:00,  2.54it/s]=> result
* total: 812
* correct: 616
* accuracy: 75.9%
* error: 24.1%
* macro_f1: 74.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [26/30] batch [20/392] time 0.281 (0.345) data 0.000 (0.039) loss 2.8105 (2.0843) lr 6.6987e-04 eta 0:11:08
epoch [26/30] batch [40/392] time 0.281 (0.320) data 0.000 (0.020) loss 1.9424 (2.1176) lr 6.6987e-04 eta 0:10:14
epoch [26/30] batch [60/392] time 0.278 (0.310) data 0.000 (0.013) loss 2.7734 (2.2254) lr 6.6987e-04 eta 0:09:49
epoch [26/30] batch [80/392] time 0.279 (0.305) data 0.000 (0.010) loss 2.0273 (2.2282) lr 6.6987e-04 eta 0:09:33
epoch [26/30] batch [100/392] time 0.293 (0.303) data 0.000 (0.008) loss 3.0156 (2.3814) lr 6.6987e-04 eta 0:09:22
epoch [26/30] batch [120/392] time 0.292 (0.301) data 0.000 (0.007) loss 1.7314 (2.3311) lr 6.6987e-04 eta 0:09:13
epoch [26/30] batch [140/392] time 0.294 (0.299) data 0.000 (0.006) loss 2.3145 (2.2927) lr 6.6987e-04 eta 0:09:04
epoch [26/30] batch [160/392] time 0.306 (0.298) data 0.000 (0.005) loss 2.9375 (2.2223) lr 6.6987e-04 eta 0:08:56
epoch [26/30] batch [180/392] time 0.284 (0.298) data 0.000 (0.005) loss 1.3018 (2.2144) lr 6.6987e-04 eta 0:08:49
epoch [26/30] batch [200/392] time 0.287 (0.297) data 0.000 (0.004) loss 2.0762 (2.2140) lr 6.6987e-04 eta 0:08:43
epoch [26/30] batch [220/392] time 0.293 (0.297) data 0.000 (0.004) loss 4.0664 (2.2104) lr 6.6987e-04 eta 0:08:35
epoch [26/30] batch [240/392] time 0.294 (0.297) data 0.000 (0.003) loss 1.3252 (2.2020) lr 6.6987e-04 eta 0:08:30
epoch [26/30] batch [260/392] time 0.283 (0.297) data 0.000 (0.003) loss 2.0508 (2.1890) lr 6.6987e-04 eta 0:08:24
epoch [26/30] batch [280/392] time 0.285 (0.296) data 0.000 (0.003) loss 0.3550 (2.1744) lr 6.6987e-04 eta 0:08:17
epoch [26/30] batch [300/392] time 0.292 (0.296) data 0.000 (0.003) loss 1.5381 (2.1998) lr 6.6987e-04 eta 0:08:11
epoch [26/30] batch [320/392] time 0.292 (0.296) data 0.000 (0.003) loss 8.3594 (2.2109) lr 6.6987e-04 eta 0:08:05
epoch [26/30] batch [340/392] time 0.316 (0.296) data 0.000 (0.003) loss 0.0524 (2.1924) lr 6.6987e-04 eta 0:07:59
epoch [26/30] batch [360/392] time 0.286 (0.296) data 0.000 (0.002) loss 5.4102 (2.2320) lr 6.6987e-04 eta 0:07:53
epoch [26/30] batch [380/392] time 0.274 (0.295) data 0.000 (0.002) loss 3.6035 (2.2589) lr 6.6987e-04 eta 0:07:45
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.36s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.07s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.54it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.22it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.92it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.61it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.25it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.78it/s]100%|██████████| 9/9 [00:03<00:00,  2.51it/s]=> result
* total: 812
* correct: 609
* accuracy: 75.0%
* error: 25.0%
* macro_f1: 74.0%

epoch [27/30] batch [20/392] time 0.317 (0.341) data 0.000 (0.037) loss 3.1621 (2.0202) lr 4.3227e-04 eta 0:08:47
epoch [27/30] batch [40/392] time 0.280 (0.317) data 0.000 (0.018) loss 2.1582 (2.0696) lr 4.3227e-04 eta 0:08:03
epoch [27/30] batch [60/392] time 0.294 (0.309) data 0.000 (0.012) loss 1.3145 (2.0221) lr 4.3227e-04 eta 0:07:45
epoch [27/30] batch [80/392] time 0.278 (0.305) data 0.000 (0.009) loss 1.4609 (2.0352) lr 4.3227e-04 eta 0:07:33
epoch [27/30] batch [100/392] time 0.286 (0.302) data 0.000 (0.008) loss 2.2383 (2.0548) lr 4.3227e-04 eta 0:07:23
epoch [27/30] batch [120/392] time 0.287 (0.301) data 0.000 (0.006) loss 0.0636 (2.0456) lr 4.3227e-04 eta 0:07:15
epoch [27/30] batch [140/392] time 0.283 (0.300) data 0.000 (0.005) loss 2.6797 (2.0945) lr 4.3227e-04 eta 0:07:08
epoch [27/30] batch [160/392] time 0.282 (0.298) data 0.000 (0.005) loss 2.1289 (2.0774) lr 4.3227e-04 eta 0:07:00
epoch [27/30] batch [180/392] time 0.277 (0.297) data 0.000 (0.004) loss 1.7217 (2.1044) lr 4.3227e-04 eta 0:06:52
epoch [27/30] batch [200/392] time 0.291 (0.297) data 0.000 (0.004) loss 4.3555 (2.1078) lr 4.3227e-04 eta 0:06:45
epoch [27/30] batch [220/392] time 0.296 (0.297) data 0.000 (0.004) loss 2.4316 (2.0951) lr 4.3227e-04 eta 0:06:39
epoch [27/30] batch [240/392] time 0.290 (0.296) data 0.000 (0.003) loss 2.8320 (2.0849) lr 4.3227e-04 eta 0:06:32
epoch [27/30] batch [260/392] time 0.285 (0.295) data 0.000 (0.003) loss 1.9570 (2.1187) lr 4.3227e-04 eta 0:06:26
epoch [27/30] batch [280/392] time 0.286 (0.295) data 0.000 (0.003) loss 0.4951 (2.1651) lr 4.3227e-04 eta 0:06:20
epoch [27/30] batch [300/392] time 0.314 (0.295) data 0.000 (0.003) loss 3.1855 (2.1601) lr 4.3227e-04 eta 0:06:14
epoch [27/30] batch [320/392] time 0.301 (0.295) data 0.000 (0.003) loss 1.4219 (2.1220) lr 4.3227e-04 eta 0:06:08
epoch [27/30] batch [340/392] time 0.296 (0.295) data 0.000 (0.002) loss 3.3145 (2.1547) lr 4.3227e-04 eta 0:06:02
epoch [27/30] batch [360/392] time 0.299 (0.295) data 0.000 (0.002) loss 0.5972 (2.1576) lr 4.3227e-04 eta 0:05:56
epoch [27/30] batch [380/392] time 0.277 (0.294) data 0.000 (0.002) loss 2.5391 (2.1353) lr 4.3227e-04 eta 0:05:49
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:20,  2.58s/it] 22%|██▏       | 2/9 [00:02<00:08,  1.15s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.44it/s] 44%|████▍     | 4/9 [00:03<00:02,  2.08it/s] 56%|█████▌    | 5/9 [00:03<00:01,  2.77it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.46it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.10it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.67it/s]100%|██████████| 9/9 [00:03<00:00,  2.37it/s]=> result
* total: 812
* correct: 607
* accuracy: 74.8%
* error: 25.2%
* macro_f1: 73.8%

epoch [28/30] batch [20/392] time 0.283 (0.335) data 0.000 (0.036) loss 2.2891 (2.1055) lr 2.4472e-04 eta 0:06:27
epoch [28/30] batch [40/392] time 0.295 (0.317) data 0.000 (0.018) loss 4.4727 (2.1794) lr 2.4472e-04 eta 0:05:59
epoch [28/30] batch [60/392] time 0.278 (0.308) data 0.001 (0.012) loss 1.7168 (2.2100) lr 2.4472e-04 eta 0:05:43
epoch [28/30] batch [80/392] time 0.284 (0.303) data 0.000 (0.009) loss 3.6738 (2.1510) lr 2.4472e-04 eta 0:05:32
epoch [28/30] batch [100/392] time 0.293 (0.301) data 0.000 (0.007) loss 3.2930 (2.1602) lr 2.4472e-04 eta 0:05:23
epoch [28/30] batch [120/392] time 0.293 (0.300) data 0.000 (0.006) loss 3.9570 (2.2021) lr 2.4472e-04 eta 0:05:16
epoch [28/30] batch [140/392] time 0.285 (0.298) data 0.000 (0.005) loss 0.3547 (2.1379) lr 2.4472e-04 eta 0:05:09
epoch [28/30] batch [160/392] time 0.294 (0.298) data 0.000 (0.005) loss 1.6504 (2.1009) lr 2.4472e-04 eta 0:05:03
epoch [28/30] batch [180/392] time 0.311 (0.298) data 0.000 (0.004) loss 1.5156 (2.1361) lr 2.4472e-04 eta 0:04:56
epoch [28/30] batch [200/392] time 0.334 (0.298) data 0.000 (0.004) loss 1.5527 (2.1374) lr 2.4472e-04 eta 0:04:50
epoch [28/30] batch [220/392] time 0.290 (0.297) data 0.000 (0.004) loss 1.5596 (2.1279) lr 2.4472e-04 eta 0:04:44
epoch [28/30] batch [240/392] time 0.301 (0.297) data 0.000 (0.003) loss 2.1523 (2.1552) lr 2.4472e-04 eta 0:04:37
epoch [28/30] batch [260/392] time 0.287 (0.297) data 0.000 (0.003) loss 4.5312 (2.1961) lr 2.4472e-04 eta 0:04:31
epoch [28/30] batch [280/392] time 0.284 (0.296) data 0.000 (0.003) loss 1.0186 (2.1980) lr 2.4472e-04 eta 0:04:25
epoch [28/30] batch [300/392] time 0.290 (0.296) data 0.000 (0.003) loss 1.3906 (2.1991) lr 2.4472e-04 eta 0:04:19
epoch [28/30] batch [320/392] time 0.294 (0.296) data 0.000 (0.003) loss 2.0352 (2.2047) lr 2.4472e-04 eta 0:04:13
epoch [28/30] batch [340/392] time 0.335 (0.296) data 0.000 (0.002) loss 0.7124 (2.1913) lr 2.4472e-04 eta 0:04:07
epoch [28/30] batch [360/392] time 0.293 (0.296) data 0.000 (0.002) loss 1.4736 (2.1923) lr 2.4472e-04 eta 0:04:01
epoch [28/30] batch [380/392] time 0.274 (0.295) data 0.000 (0.002) loss 0.5879 (2.1886) lr 2.4472e-04 eta 0:03:54
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:17,  2.24s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.07s/it] 33%|███▎      | 3/9 [00:02<00:04,  1.48it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.14it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.84it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.54it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.18it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.76it/s]100%|██████████| 9/9 [00:03<00:00,  2.50it/s]=> result
* total: 812
* correct: 611
* accuracy: 75.2%
* error: 24.8%
* macro_f1: 74.2%

epoch [29/30] batch [20/392] time 0.290 (0.328) data 0.000 (0.036) loss 0.6538 (2.6695) lr 1.0926e-04 eta 0:04:10
epoch [29/30] batch [40/392] time 0.293 (0.311) data 0.000 (0.018) loss 0.6011 (2.5280) lr 1.0926e-04 eta 0:03:51
epoch [29/30] batch [60/392] time 0.276 (0.303) data 0.000 (0.012) loss 2.2578 (2.4408) lr 1.0926e-04 eta 0:03:39
epoch [29/30] batch [80/392] time 0.285 (0.299) data 0.000 (0.009) loss 1.5703 (2.4141) lr 1.0926e-04 eta 0:03:30
epoch [29/30] batch [100/392] time 0.308 (0.299) data 0.000 (0.007) loss 0.8594 (2.3064) lr 1.0926e-04 eta 0:03:24
epoch [29/30] batch [120/392] time 0.305 (0.298) data 0.000 (0.006) loss 1.7246 (2.2881) lr 1.0926e-04 eta 0:03:17
epoch [29/30] batch [140/392] time 0.279 (0.297) data 0.000 (0.005) loss 0.9014 (2.3000) lr 1.0926e-04 eta 0:03:11
epoch [29/30] batch [160/392] time 0.285 (0.298) data 0.000 (0.005) loss 0.2827 (2.2466) lr 1.0926e-04 eta 0:03:05
epoch [29/30] batch [180/392] time 0.305 (0.297) data 0.000 (0.004) loss 3.6367 (2.2466) lr 1.0926e-04 eta 0:02:59
epoch [29/30] batch [200/392] time 0.291 (0.297) data 0.000 (0.004) loss 2.2930 (2.2129) lr 1.0926e-04 eta 0:02:53
epoch [29/30] batch [220/392] time 0.285 (0.296) data 0.000 (0.004) loss 3.0039 (2.2314) lr 1.0926e-04 eta 0:02:47
epoch [29/30] batch [240/392] time 0.288 (0.296) data 0.000 (0.003) loss 4.2656 (2.2479) lr 1.0926e-04 eta 0:02:41
epoch [29/30] batch [260/392] time 0.288 (0.295) data 0.000 (0.003) loss 1.2920 (2.2345) lr 1.0926e-04 eta 0:02:34
epoch [29/30] batch [280/392] time 0.282 (0.295) data 0.000 (0.003) loss 4.7227 (2.2380) lr 1.0926e-04 eta 0:02:28
epoch [29/30] batch [300/392] time 0.292 (0.295) data 0.001 (0.003) loss 2.1777 (2.2579) lr 1.0926e-04 eta 0:02:22
epoch [29/30] batch [320/392] time 0.290 (0.295) data 0.000 (0.003) loss 1.5566 (2.2628) lr 1.0926e-04 eta 0:02:17
epoch [29/30] batch [340/392] time 0.285 (0.295) data 0.000 (0.002) loss 1.3887 (2.2770) lr 1.0926e-04 eta 0:02:11
epoch [29/30] batch [360/392] time 0.284 (0.295) data 0.000 (0.002) loss 2.4512 (2.2577) lr 1.0926e-04 eta 0:02:05
epoch [29/30] batch [380/392] time 0.273 (0.294) data 0.000 (0.002) loss 1.4170 (2.2531) lr 1.0926e-04 eta 0:01:58
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:18,  2.32s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.06s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.55it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.22it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.93it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.62it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.26it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.81it/s]100%|██████████| 9/9 [00:03<00:00,  2.52it/s]=> result
* total: 812
* correct: 610
* accuracy: 75.1%
* error: 24.9%
* macro_f1: 74.1%

epoch [30/30] batch [20/392] time 0.288 (0.329) data 0.000 (0.034) loss 3.0547 (1.9740) lr 2.7391e-05 eta 0:02:02
epoch [30/30] batch [40/392] time 0.309 (0.311) data 0.000 (0.017) loss 1.4512 (2.1518) lr 2.7391e-05 eta 0:01:49
epoch [30/30] batch [60/392] time 0.287 (0.305) data 0.000 (0.011) loss 0.5835 (2.1241) lr 2.7391e-05 eta 0:01:41
epoch [30/30] batch [80/392] time 0.300 (0.304) data 0.000 (0.009) loss 2.7422 (2.1491) lr 2.7391e-05 eta 0:01:34
epoch [30/30] batch [100/392] time 0.286 (0.301) data 0.000 (0.007) loss 1.7656 (2.0991) lr 2.7391e-05 eta 0:01:27
epoch [30/30] batch [120/392] time 0.310 (0.299) data 0.000 (0.006) loss 3.1973 (2.1508) lr 2.7391e-05 eta 0:01:21
epoch [30/30] batch [140/392] time 0.281 (0.298) data 0.000 (0.005) loss 2.0684 (2.1256) lr 2.7391e-05 eta 0:01:15
epoch [30/30] batch [160/392] time 0.286 (0.298) data 0.000 (0.004) loss 1.1807 (2.1459) lr 2.7391e-05 eta 0:01:09
epoch [30/30] batch [180/392] time 0.287 (0.298) data 0.000 (0.004) loss 1.6084 (2.1355) lr 2.7391e-05 eta 0:01:03
epoch [30/30] batch [200/392] time 0.292 (0.297) data 0.000 (0.004) loss 3.7812 (2.1259) lr 2.7391e-05 eta 0:00:57
epoch [30/30] batch [220/392] time 0.289 (0.297) data 0.000 (0.003) loss 0.6621 (2.0821) lr 2.7391e-05 eta 0:00:51
epoch [30/30] batch [240/392] time 0.314 (0.296) data 0.000 (0.003) loss 1.4590 (2.0637) lr 2.7391e-05 eta 0:00:45
epoch [30/30] batch [260/392] time 0.297 (0.296) data 0.000 (0.003) loss 0.6362 (2.0669) lr 2.7391e-05 eta 0:00:39
epoch [30/30] batch [280/392] time 0.282 (0.296) data 0.000 (0.003) loss 1.1230 (2.0909) lr 2.7391e-05 eta 0:00:33
epoch [30/30] batch [300/392] time 0.278 (0.296) data 0.000 (0.003) loss 1.2900 (2.0901) lr 2.7391e-05 eta 0:00:27
epoch [30/30] batch [320/392] time 0.292 (0.296) data 0.000 (0.002) loss 0.7070 (2.0610) lr 2.7391e-05 eta 0:00:21
epoch [30/30] batch [340/392] time 0.302 (0.295) data 0.000 (0.002) loss 1.4619 (2.0709) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [360/392] time 0.287 (0.295) data 0.000 (0.002) loss 1.7969 (2.0603) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [380/392] time 0.270 (0.294) data 0.000 (0.002) loss 2.1621 (2.0655) lr 2.7391e-05 eta 0:00:03
Evaluate on the *val* set
  0%|          | 0/9 [00:00<?, ?it/s] 11%|█         | 1/9 [00:02<00:17,  2.25s/it] 22%|██▏       | 2/9 [00:02<00:07,  1.03s/it] 33%|███▎      | 3/9 [00:02<00:03,  1.59it/s] 44%|████▍     | 4/9 [00:02<00:02,  2.28it/s] 56%|█████▌    | 5/9 [00:02<00:01,  2.99it/s] 67%|██████▋   | 6/9 [00:03<00:00,  3.69it/s] 78%|███████▊  | 7/9 [00:03<00:00,  4.32it/s] 89%|████████▉ | 8/9 [00:03<00:00,  4.88it/s]100%|██████████| 9/9 [00:03<00:00,  2.58it/s]
=> result
* total: 812
* correct: 611
* accuracy: 75.2%
* error: 24.8%
* macro_f1: 74.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/41 [00:00<?, ?it/s]  2%|▏         | 1/41 [00:02<01:58,  2.97s/it]  5%|▍         | 2/41 [00:03<01:01,  1.56s/it]  7%|▋         | 3/41 [00:04<00:41,  1.10s/it] 10%|▉         | 4/41 [00:04<00:32,  1.13it/s] 12%|█▏        | 5/41 [00:05<00:28,  1.26it/s] 15%|█▍        | 6/41 [00:05<00:22,  1.53it/s] 17%|█▋        | 7/41 [00:06<00:19,  1.79it/s] 20%|█▉        | 8/41 [00:06<00:15,  2.12it/s] 22%|██▏       | 9/41 [00:06<00:13,  2.43it/s] 24%|██▍       | 10/41 [00:06<00:11,  2.59it/s] 27%|██▋       | 11/41 [00:07<00:10,  2.90it/s] 29%|██▉       | 12/41 [00:07<00:08,  3.25it/s] 32%|███▏      | 13/41 [00:07<00:08,  3.46it/s] 34%|███▍      | 14/41 [00:07<00:07,  3.77it/s] 37%|███▋      | 15/41 [00:08<00:05,  4.35it/s] 39%|███▉      | 16/41 [00:08<00:05,  4.86it/s] 41%|████▏     | 17/41 [00:08<00:04,  5.30it/s] 44%|████▍     | 18/41 [00:08<00:04,  5.64it/s] 46%|████▋     | 19/41 [00:08<00:03,  5.91it/s] 49%|████▉     | 20/41 [00:08<00:03,  6.12it/s] 51%|█████     | 21/41 [00:08<00:03,  6.27it/s] 54%|█████▎    | 22/41 [00:09<00:02,  6.38it/s] 56%|█████▌    | 23/41 [00:09<00:02,  6.46it/s] 59%|█████▊    | 24/41 [00:09<00:02,  6.53it/s] 61%|██████    | 25/41 [00:09<00:02,  6.56it/s] 63%|██████▎   | 26/41 [00:09<00:02,  6.59it/s] 66%|██████▌   | 27/41 [00:09<00:02,  6.61it/s] 68%|██████▊   | 28/41 [00:09<00:01,  6.63it/s] 71%|███████   | 29/41 [00:10<00:01,  6.64it/s] 73%|███████▎  | 30/41 [00:10<00:01,  6.65it/s] 76%|███████▌  | 31/41 [00:10<00:01,  6.65it/s] 78%|███████▊  | 32/41 [00:10<00:01,  6.65it/s] 80%|████████  | 33/41 [00:10<00:01,  6.65it/s] 83%|████████▎ | 34/41 [00:10<00:01,  6.66it/s] 85%|████████▌ | 35/41 [00:11<00:00,  6.64it/s] 88%|████████▊ | 36/41 [00:11<00:00,  6.66it/s] 90%|█████████ | 37/41 [00:11<00:00,  6.66it/s] 93%|█████████▎| 38/41 [00:11<00:00,  6.67it/s] 95%|█████████▌| 39/41 [00:11<00:00,  6.67it/s] 98%|█████████▊| 40/41 [00:11<00:00,  6.66it/s]100%|██████████| 41/41 [00:11<00:00,  3.43it/s]
=> result
* total: 4,002
* correct: 3,064
* accuracy: 76.6%
* error: 23.4%
* macro_f1: 75.9%
Elapsed: 0:59:33
+ sh scripts/rpo_prime/base2new_test_sdl.sh stanford_cars 3 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
1568 823 4039
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      823
# test     4,039
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/41 [00:00<?, ?it/s]  2%|▏         | 1/41 [00:06<04:21,  6.54s/it]  5%|▍         | 2/41 [00:06<01:50,  2.83s/it]  7%|▋         | 3/41 [00:07<01:02,  1.66s/it] 10%|▉         | 4/41 [00:07<00:41,  1.11s/it] 12%|█▏        | 5/41 [00:07<00:29,  1.24it/s] 15%|█▍        | 6/41 [00:07<00:22,  1.58it/s] 17%|█▋        | 7/41 [00:08<00:17,  1.94it/s] 20%|█▉        | 8/41 [00:08<00:14,  2.25it/s] 22%|██▏       | 9/41 [00:08<00:12,  2.53it/s] 24%|██▍       | 10/41 [00:09<00:11,  2.77it/s] 27%|██▋       | 11/41 [00:09<00:09,  3.01it/s] 29%|██▉       | 12/41 [00:09<00:09,  3.19it/s] 32%|███▏      | 13/41 [00:09<00:08,  3.40it/s] 34%|███▍      | 14/41 [00:09<00:06,  3.96it/s] 37%|███▋      | 15/41 [00:10<00:05,  4.50it/s] 39%|███▉      | 16/41 [00:10<00:05,  4.98it/s] 41%|████▏     | 17/41 [00:10<00:04,  5.38it/s] 44%|████▍     | 18/41 [00:10<00:04,  5.70it/s] 46%|████▋     | 19/41 [00:10<00:03,  5.95it/s] 49%|████▉     | 20/41 [00:10<00:03,  6.06it/s] 51%|█████     | 21/41 [00:11<00:03,  6.22it/s] 54%|█████▎    | 22/41 [00:11<00:03,  6.33it/s] 56%|█████▌    | 23/41 [00:11<00:02,  6.42it/s] 59%|█████▊    | 24/41 [00:11<00:02,  6.48it/s] 61%|██████    | 25/41 [00:11<00:02,  6.51it/s] 63%|██████▎   | 26/41 [00:11<00:02,  6.55it/s] 66%|██████▌   | 27/41 [00:11<00:02,  6.56it/s] 68%|██████▊   | 28/41 [00:12<00:01,  6.54it/s] 71%|███████   | 29/41 [00:12<00:01,  6.57it/s] 73%|███████▎  | 30/41 [00:12<00:01,  6.59it/s] 76%|███████▌  | 31/41 [00:12<00:01,  6.60it/s] 78%|███████▊  | 32/41 [00:12<00:01,  6.60it/s] 80%|████████  | 33/41 [00:12<00:01,  6.61it/s] 83%|████████▎ | 34/41 [00:12<00:01,  6.62it/s] 85%|████████▌ | 35/41 [00:13<00:00,  6.61it/s] 88%|████████▊ | 36/41 [00:13<00:00,  6.61it/s] 90%|█████████ | 37/41 [00:13<00:00,  6.48it/s] 93%|█████████▎| 38/41 [00:13<00:00,  6.52it/s] 95%|█████████▌| 39/41 [00:13<00:00,  6.55it/s] 98%|█████████▊| 40/41 [00:13<00:00,  6.56it/s]100%|██████████| 41/41 [00:14<00:00,  2.91it/s]
=> result
* total: 4,039
* correct: 3,022
* accuracy: 74.8%
* error: 25.2%
* macro_f1: 73.9%
+ for dataset in eurosat dtd oxford_flowers stanford_cars oxford_pets food101 ucf101 caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh oxford_pets 1 0 main_tmp1_0.1sdl 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
304 377 1881
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  19
# train_x  304
# val      377
# test     1,881
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/76] time 0.232 (0.363) data 0.000 (0.056) loss 3.1484 (1.8329) lr 1.0000e-02 eta 0:13:39
epoch [1/30] batch [40/76] time 0.232 (0.300) data 0.000 (0.028) loss 0.4414 (1.4906) lr 1.0000e-02 eta 0:11:11
epoch [1/30] batch [60/76] time 0.224 (0.276) data 0.000 (0.019) loss 2.7422 (1.3473) lr 1.0000e-02 eta 0:10:13
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:05,  1.87s/it] 50%|█████     | 2/4 [00:01<00:01,  1.18it/s] 75%|███████▌  | 3/4 [00:02<00:00,  1.94it/s]100%|██████████| 4/4 [00:02<00:00,  1.70it/s]=> result
* total: 377
* correct: 361
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 95.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/76] time 0.240 (0.283) data 0.000 (0.035) loss 0.2061 (0.6620) lr 9.9726e-03 eta 0:10:18
epoch [2/30] batch [40/76] time 0.236 (0.260) data 0.000 (0.017) loss 1.2148 (0.9338) lr 9.9726e-03 eta 0:09:23
epoch [2/30] batch [60/76] time 0.224 (0.250) data 0.000 (0.012) loss 1.0352 (1.0035) lr 9.9726e-03 eta 0:08:54
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.40it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 363
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/76] time 0.235 (0.275) data 0.000 (0.033) loss 2.4141 (0.7380) lr 9.8907e-03 eta 0:09:39
epoch [3/30] batch [40/76] time 0.242 (0.256) data 0.000 (0.017) loss 0.4038 (0.5985) lr 9.8907e-03 eta 0:08:54
epoch [3/30] batch [60/76] time 0.307 (0.248) data 0.000 (0.011) loss 0.6343 (0.6607) lr 9.8907e-03 eta 0:08:33
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.47it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.33it/s]100%|██████████| 4/4 [00:01<00:00,  2.07it/s]=> result
* total: 377
* correct: 363
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.2%

epoch [4/30] batch [20/76] time 0.247 (0.276) data 0.000 (0.034) loss 2.1523 (1.0457) lr 9.7553e-03 eta 0:09:20
epoch [4/30] batch [40/76] time 0.240 (0.256) data 0.000 (0.017) loss 0.2401 (0.7541) lr 9.7553e-03 eta 0:08:35
epoch [4/30] batch [60/76] time 0.228 (0.247) data 0.000 (0.012) loss 1.7012 (0.7906) lr 9.7553e-03 eta 0:08:12
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.13it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/76] time 0.231 (0.276) data 0.000 (0.034) loss 1.5625 (0.9827) lr 9.5677e-03 eta 0:09:00
epoch [5/30] batch [40/76] time 0.241 (0.258) data 0.000 (0.017) loss 0.7139 (0.8458) lr 9.5677e-03 eta 0:08:19
epoch [5/30] batch [60/76] time 0.224 (0.248) data 0.000 (0.011) loss 0.8101 (0.8438) lr 9.5677e-03 eta 0:07:55
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.41s/it] 50%|█████     | 2/4 [00:01<00:01,  1.53it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.42it/s]100%|██████████| 4/4 [00:01<00:00,  2.13it/s]=> result
* total: 377
* correct: 363
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.3%

epoch [6/30] batch [20/76] time 0.241 (0.277) data 0.000 (0.036) loss 1.4805 (0.4142) lr 9.3301e-03 eta 0:08:39
epoch [6/30] batch [40/76] time 0.237 (0.260) data 0.000 (0.018) loss -0.0740 (0.6334) lr 9.3301e-03 eta 0:08:04
epoch [6/30] batch [60/76] time 0.227 (0.250) data 0.000 (0.012) loss -0.0767 (0.6066) lr 9.3301e-03 eta 0:07:40
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.46s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.36it/s]100%|██████████| 4/4 [00:01<00:00,  2.08it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/76] time 0.236 (0.275) data 0.000 (0.034) loss 0.2910 (0.5047) lr 9.0451e-03 eta 0:08:15
epoch [7/30] batch [40/76] time 0.243 (0.257) data 0.000 (0.017) loss 0.2366 (0.6838) lr 9.0451e-03 eta 0:07:39
epoch [7/30] batch [60/76] time 0.226 (0.249) data 0.000 (0.011) loss 0.2559 (0.7695) lr 9.0451e-03 eta 0:07:19
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.08it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [8/30] batch [20/76] time 0.234 (0.276) data 0.000 (0.036) loss 1.5605 (0.8317) lr 8.7157e-03 eta 0:07:56
epoch [8/30] batch [40/76] time 0.239 (0.259) data 0.000 (0.018) loss 1.2969 (0.9419) lr 8.7157e-03 eta 0:07:21
epoch [8/30] batch [60/76] time 0.224 (0.249) data 0.000 (0.012) loss 0.4043 (0.7624) lr 8.7157e-03 eta 0:07:01
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.43it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [9/30] batch [20/76] time 0.239 (0.277) data 0.000 (0.035) loss 0.2163 (0.5048) lr 8.3457e-03 eta 0:07:36
epoch [9/30] batch [40/76] time 0.238 (0.258) data 0.000 (0.017) loss 0.2068 (0.5151) lr 8.3457e-03 eta 0:07:01
epoch [9/30] batch [60/76] time 0.224 (0.250) data 0.000 (0.012) loss 0.2269 (0.4688) lr 8.3457e-03 eta 0:06:42
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.10it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%

epoch [10/30] batch [20/76] time 0.239 (0.277) data 0.000 (0.034) loss 0.0419 (0.6934) lr 7.9389e-03 eta 0:07:17
epoch [10/30] batch [40/76] time 0.238 (0.259) data 0.000 (0.017) loss 0.8647 (0.6657) lr 7.9389e-03 eta 0:06:42
epoch [10/30] batch [60/76] time 0.225 (0.250) data 0.000 (0.011) loss 0.6089 (0.6648) lr 7.9389e-03 eta 0:06:23
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.08it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/76] time 0.238 (0.275) data 0.000 (0.035) loss 1.6973 (0.6171) lr 7.5000e-03 eta 0:06:53
epoch [11/30] batch [40/76] time 0.242 (0.257) data 0.000 (0.018) loss 0.3635 (0.5741) lr 7.5000e-03 eta 0:06:19
epoch [11/30] batch [60/76] time 0.226 (0.249) data 0.000 (0.012) loss 0.2773 (0.6260) lr 7.5000e-03 eta 0:06:03
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [12/30] batch [20/76] time 0.238 (0.275) data 0.000 (0.035) loss 0.2227 (0.7863) lr 7.0337e-03 eta 0:06:32
epoch [12/30] batch [40/76] time 0.235 (0.260) data 0.000 (0.017) loss -0.0517 (0.7125) lr 7.0337e-03 eta 0:06:05
epoch [12/30] batch [60/76] time 0.224 (0.250) data 0.000 (0.012) loss 0.7910 (0.6723) lr 7.0337e-03 eta 0:05:45
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.42it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [13/30] batch [20/76] time 0.237 (0.280) data 0.000 (0.034) loss 2.6660 (0.8596) lr 6.5451e-03 eta 0:06:17
epoch [13/30] batch [40/76] time 0.238 (0.258) data 0.000 (0.017) loss -0.1085 (0.7004) lr 6.5451e-03 eta 0:05:42
epoch [13/30] batch [60/76] time 0.228 (0.248) data 0.000 (0.012) loss -0.1056 (0.6733) lr 6.5451e-03 eta 0:05:24
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.46s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.35it/s]100%|██████████| 4/4 [00:01<00:00,  2.08it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [14/30] batch [20/76] time 0.237 (0.277) data 0.000 (0.037) loss 1.1250 (0.4351) lr 6.0396e-03 eta 0:05:52
epoch [14/30] batch [40/76] time 0.242 (0.260) data 0.000 (0.019) loss 1.4336 (0.5260) lr 6.0396e-03 eta 0:05:25
epoch [14/30] batch [60/76] time 0.225 (0.250) data 0.000 (0.012) loss 0.1073 (0.5556) lr 6.0396e-03 eta 0:05:07
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.40it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [15/30] batch [20/76] time 0.246 (0.276) data 0.000 (0.035) loss -0.1041 (0.4572) lr 5.5226e-03 eta 0:05:29
epoch [15/30] batch [40/76] time 0.241 (0.259) data 0.000 (0.018) loss -0.0211 (0.3963) lr 5.5226e-03 eta 0:05:04
epoch [15/30] batch [60/76] time 0.225 (0.249) data 0.000 (0.012) loss 2.5371 (0.5032) lr 5.5226e-03 eta 0:04:48
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.46s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.36it/s]100%|██████████| 4/4 [00:01<00:00,  2.09it/s]=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [16/30] batch [20/76] time 0.235 (0.274) data 0.000 (0.035) loss 0.0946 (0.5712) lr 5.0000e-03 eta 0:05:06
epoch [16/30] batch [40/76] time 0.236 (0.257) data 0.000 (0.017) loss 2.2598 (0.7930) lr 5.0000e-03 eta 0:04:42
epoch [16/30] batch [60/76] time 0.227 (0.248) data 0.000 (0.012) loss 2.4902 (0.7422) lr 5.0000e-03 eta 0:04:27
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.40it/s]100%|██████████| 4/4 [00:01<00:00,  2.10it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%

epoch [17/30] batch [20/76] time 0.238 (0.274) data 0.000 (0.034) loss 0.2402 (0.5744) lr 4.4774e-03 eta 0:04:46
epoch [17/30] batch [40/76] time 0.248 (0.259) data 0.000 (0.017) loss 0.4673 (0.4170) lr 4.4774e-03 eta 0:04:25
epoch [17/30] batch [60/76] time 0.226 (0.250) data 0.000 (0.012) loss 1.0918 (0.4351) lr 4.4774e-03 eta 0:04:11
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.09it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [18/30] batch [20/76] time 0.236 (0.277) data 0.000 (0.034) loss 0.8325 (0.6861) lr 3.9604e-03 eta 0:04:28
epoch [18/30] batch [40/76] time 0.241 (0.259) data 0.000 (0.017) loss 0.1458 (0.5711) lr 3.9604e-03 eta 0:04:05
epoch [18/30] batch [60/76] time 0.225 (0.248) data 0.000 (0.011) loss 0.5513 (0.5431) lr 3.9604e-03 eta 0:03:50
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.47s/it] 50%|█████     | 2/4 [00:01<00:01,  1.47it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.34it/s]100%|██████████| 4/4 [00:01<00:00,  2.08it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [19/30] batch [20/76] time 0.235 (0.275) data 0.000 (0.036) loss 0.3254 (0.7479) lr 3.4549e-03 eta 0:04:05
epoch [19/30] batch [40/76] time 0.242 (0.256) data 0.000 (0.018) loss 0.0380 (0.5856) lr 3.4549e-03 eta 0:03:43
epoch [19/30] batch [60/76] time 0.224 (0.247) data 0.000 (0.012) loss -0.0418 (0.5373) lr 3.4549e-03 eta 0:03:30
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.52it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.43it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%

epoch [20/30] batch [20/76] time 0.240 (0.282) data 0.000 (0.036) loss 2.1641 (0.6961) lr 2.9663e-03 eta 0:03:50
epoch [20/30] batch [40/76] time 0.239 (0.262) data 0.000 (0.018) loss 2.1348 (0.5575) lr 2.9663e-03 eta 0:03:28
epoch [20/30] batch [60/76] time 0.223 (0.250) data 0.000 (0.012) loss 0.1053 (0.6238) lr 2.9663e-03 eta 0:03:13
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.42it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/76] time 0.237 (0.280) data 0.000 (0.034) loss -0.0283 (0.4027) lr 2.5000e-03 eta 0:03:26
epoch [21/30] batch [40/76] time 0.231 (0.258) data 0.000 (0.017) loss 0.8486 (0.4725) lr 2.5000e-03 eta 0:03:05
epoch [21/30] batch [60/76] time 0.228 (0.249) data 0.000 (0.011) loss 0.1138 (0.4405) lr 2.5000e-03 eta 0:02:54
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [22/30] batch [20/76] time 0.237 (0.275) data 0.000 (0.033) loss -0.0967 (0.4514) lr 2.0611e-03 eta 0:03:02
epoch [22/30] batch [40/76] time 0.241 (0.258) data 0.000 (0.017) loss -0.1238 (0.5241) lr 2.0611e-03 eta 0:02:46
epoch [22/30] batch [60/76] time 0.224 (0.249) data 0.000 (0.011) loss 1.3057 (0.5137) lr 2.0611e-03 eta 0:02:35
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.46s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.35it/s]100%|██████████| 4/4 [00:01<00:00,  2.09it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [23/30] batch [20/76] time 0.237 (0.276) data 0.000 (0.034) loss 1.5908 (0.4714) lr 1.6543e-03 eta 0:02:42
epoch [23/30] batch [40/76] time 0.238 (0.257) data 0.000 (0.017) loss 1.7158 (0.6194) lr 1.6543e-03 eta 0:02:26
epoch [23/30] batch [60/76] time 0.226 (0.249) data 0.000 (0.011) loss -0.1239 (0.5559) lr 1.6543e-03 eta 0:02:16
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]100%|██████████| 4/4 [00:01<00:00,  2.08it/s]=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%

epoch [24/30] batch [20/76] time 0.232 (0.278) data 0.000 (0.035) loss 0.2147 (0.3480) lr 1.2843e-03 eta 0:02:22
epoch [24/30] batch [40/76] time 0.238 (0.259) data 0.000 (0.017) loss 0.1354 (0.5577) lr 1.2843e-03 eta 0:02:07
epoch [24/30] batch [60/76] time 0.225 (0.250) data 0.000 (0.012) loss -0.0717 (0.4891) lr 1.2843e-03 eta 0:01:58
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.48s/it] 50%|█████     | 2/4 [00:01<00:01,  1.46it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.33it/s]100%|██████████| 4/4 [00:01<00:00,  2.05it/s]=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%

epoch [25/30] batch [20/76] time 0.232 (0.280) data 0.000 (0.034) loss -0.1436 (0.3334) lr 9.5492e-04 eta 0:02:01
epoch [25/30] batch [40/76] time 0.232 (0.258) data 0.000 (0.017) loss 0.6948 (0.4137) lr 9.5492e-04 eta 0:01:47
epoch [25/30] batch [60/76] time 0.312 (0.249) data 0.000 (0.012) loss 1.3574 (0.4588) lr 9.5492e-04 eta 0:01:38
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.48s/it] 50%|█████     | 2/4 [00:01<00:01,  1.46it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.33it/s]100%|██████████| 4/4 [00:01<00:00,  3.34it/s]100%|██████████| 4/4 [00:01<00:00,  2.06it/s]=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%

epoch [26/30] batch [20/76] time 0.236 (0.276) data 0.000 (0.035) loss 0.3408 (0.5485) lr 6.6987e-04 eta 0:01:39
epoch [26/30] batch [40/76] time 0.239 (0.257) data 0.000 (0.018) loss -0.0773 (0.5261) lr 6.6987e-04 eta 0:01:27
epoch [26/30] batch [60/76] time 0.226 (0.247) data 0.000 (0.012) loss 2.3848 (0.5585) lr 6.6987e-04 eta 0:01:18
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]100%|██████████| 4/4 [00:01<00:00,  2.10it/s]=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%

epoch [27/30] batch [20/76] time 0.233 (0.281) data 0.000 (0.036) loss 0.2246 (0.4374) lr 4.3227e-04 eta 0:01:19
epoch [27/30] batch [40/76] time 0.236 (0.259) data 0.000 (0.018) loss 0.0470 (0.5552) lr 4.3227e-04 eta 0:01:08
epoch [27/30] batch [60/76] time 0.223 (0.248) data 0.000 (0.012) loss 0.6240 (0.5974) lr 4.3227e-04 eta 0:01:00
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.10it/s]=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%

epoch [28/30] batch [20/76] time 0.231 (0.273) data 0.000 (0.035) loss 0.4343 (0.5428) lr 2.4472e-04 eta 0:00:56
epoch [28/30] batch [40/76] time 0.237 (0.256) data 0.000 (0.018) loss 0.7598 (0.4468) lr 2.4472e-04 eta 0:00:48
epoch [28/30] batch [60/76] time 0.225 (0.248) data 0.000 (0.012) loss 0.1476 (0.4501) lr 2.4472e-04 eta 0:00:41
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.48s/it] 50%|█████     | 2/4 [00:01<00:01,  1.46it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.32it/s]100%|██████████| 4/4 [00:01<00:00,  3.33it/s]100%|██████████| 4/4 [00:01<00:00,  2.07it/s]=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%

epoch [29/30] batch [20/76] time 0.230 (0.275) data 0.000 (0.036) loss 0.9697 (0.4465) lr 1.0926e-04 eta 0:00:36
epoch [29/30] batch [40/76] time 0.240 (0.257) data 0.000 (0.018) loss 0.5488 (0.4552) lr 1.0926e-04 eta 0:00:28
epoch [29/30] batch [60/76] time 0.223 (0.248) data 0.000 (0.012) loss -0.0566 (0.3885) lr 1.0926e-04 eta 0:00:22
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.46s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.35it/s]100%|██████████| 4/4 [00:01<00:00,  3.37it/s]100%|██████████| 4/4 [00:01<00:00,  2.08it/s]=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%

epoch [30/30] batch [20/76] time 0.238 (0.276) data 0.000 (0.035) loss -0.0471 (0.3838) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [40/76] time 0.234 (0.258) data 0.000 (0.018) loss 1.6982 (0.5898) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [60/76] time 0.225 (0.249) data 0.000 (0.012) loss 1.1182 (0.5872) lr 2.7391e-05 eta 0:00:03
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.09it/s]
=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/19 [00:00<?, ?it/s]  5%|▌         | 1/19 [00:02<00:45,  2.51s/it] 11%|█         | 2/19 [00:02<00:20,  1.19s/it] 16%|█▌        | 3/19 [00:02<00:11,  1.42it/s] 21%|██        | 4/19 [00:03<00:07,  2.10it/s] 26%|██▋       | 5/19 [00:03<00:04,  2.86it/s] 32%|███▏      | 6/19 [00:03<00:03,  3.65it/s] 37%|███▋      | 7/19 [00:03<00:02,  4.44it/s] 42%|████▏     | 8/19 [00:03<00:02,  5.17it/s] 47%|████▋     | 9/19 [00:03<00:01,  5.80it/s] 53%|█████▎    | 10/19 [00:03<00:01,  6.25it/s] 58%|█████▊    | 11/19 [00:03<00:01,  6.67it/s] 63%|██████▎   | 12/19 [00:04<00:00,  7.02it/s] 68%|██████▊   | 13/19 [00:04<00:00,  7.18it/s] 74%|███████▎  | 14/19 [00:04<00:00,  7.40it/s] 79%|███████▉  | 15/19 [00:04<00:00,  7.46it/s] 84%|████████▍ | 16/19 [00:04<00:00,  7.60it/s] 89%|████████▉ | 17/19 [00:04<00:00,  7.70it/s] 95%|█████████▍| 18/19 [00:04<00:00,  7.77it/s]100%|██████████| 19/19 [00:04<00:00,  8.22it/s]100%|██████████| 19/19 [00:05<00:00,  3.76it/s]
=> result
* total: 1,881
* correct: 1,785
* accuracy: 94.9%
* error: 5.1%
* macro_f1: 94.9%
Elapsed: 0:10:25
+ sh scripts/rpo_prime/base2new_test_sdl.sh oxford_pets 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
288 359 1788
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  18
# train_x  288
# val      359
# test     1,788
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:04<01:15,  4.43s/it] 11%|█         | 2/18 [00:04<00:30,  1.90s/it] 17%|█▋        | 3/18 [00:04<00:16,  1.09s/it] 22%|██▏       | 4/18 [00:04<00:09,  1.41it/s] 28%|██▊       | 5/18 [00:04<00:06,  2.00it/s] 33%|███▎      | 6/18 [00:05<00:04,  2.68it/s] 39%|███▉      | 7/18 [00:05<00:03,  3.41it/s] 44%|████▍     | 8/18 [00:05<00:02,  4.14it/s] 50%|█████     | 9/18 [00:05<00:01,  4.86it/s] 56%|█████▌    | 10/18 [00:05<00:01,  5.51it/s] 61%|██████    | 11/18 [00:05<00:01,  6.07it/s] 67%|██████▋   | 12/18 [00:05<00:00,  6.51it/s] 72%|███████▏  | 13/18 [00:05<00:00,  6.88it/s] 78%|███████▊  | 14/18 [00:06<00:00,  7.12it/s] 83%|████████▎ | 15/18 [00:06<00:00,  7.35it/s] 89%|████████▉ | 16/18 [00:06<00:00,  7.49it/s] 94%|█████████▍| 17/18 [00:06<00:00,  7.59it/s]100%|██████████| 18/18 [00:06<00:00,  7.90it/s]100%|██████████| 18/18 [00:06<00:00,  2.69it/s]
=> result
* total: 1,788
* correct: 1,745
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh oxford_pets 2 0 main_tmp1_0.1sdl 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
304 377 1881
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  19
# train_x  304
# val      377
# test     1,881
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/76] time 0.231 (0.363) data 0.000 (0.058) loss -0.0878 (1.3996) lr 1.0000e-02 eta 0:13:39
epoch [1/30] batch [40/76] time 0.236 (0.301) data 0.000 (0.029) loss 2.5254 (1.2686) lr 1.0000e-02 eta 0:11:14
epoch [1/30] batch [60/76] time 0.226 (0.278) data 0.000 (0.020) loss 1.7510 (1.2413) lr 1.0000e-02 eta 0:10:17
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.50s/it] 50%|█████     | 2/4 [00:01<00:01,  1.44it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.31it/s]100%|██████████| 4/4 [00:01<00:00,  3.31it/s]100%|██████████| 4/4 [00:01<00:00,  2.04it/s]=> result
* total: 377
* correct: 357
* accuracy: 94.7%
* error: 5.3%
* macro_f1: 94.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/76] time 0.236 (0.276) data 0.000 (0.033) loss 0.6035 (1.0036) lr 9.9726e-03 eta 0:10:02
epoch [2/30] batch [40/76] time 0.235 (0.257) data 0.000 (0.017) loss 1.2119 (0.9159) lr 9.9726e-03 eta 0:09:16
epoch [2/30] batch [60/76] time 0.229 (0.248) data 0.000 (0.011) loss 1.7021 (0.8269) lr 9.9726e-03 eta 0:08:51
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.35it/s]100%|██████████| 4/4 [00:01<00:00,  2.09it/s]=> result
* total: 377
* correct: 363
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/76] time 0.242 (0.280) data 0.000 (0.034) loss 2.0918 (0.4897) lr 9.8907e-03 eta 0:09:49
epoch [3/30] batch [40/76] time 0.237 (0.259) data 0.000 (0.017) loss 0.0492 (0.7054) lr 9.8907e-03 eta 0:09:00
epoch [3/30] batch [60/76] time 0.226 (0.250) data 0.000 (0.011) loss 0.2998 (0.7087) lr 9.8907e-03 eta 0:08:36
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.40s/it] 50%|█████     | 2/4 [00:01<00:01,  1.53it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.43it/s]100%|██████████| 4/4 [00:01<00:00,  2.16it/s]=> result
* total: 377
* correct: 363
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.2%

epoch [4/30] batch [20/76] time 0.243 (0.280) data 0.000 (0.034) loss 0.1990 (0.5195) lr 9.7553e-03 eta 0:09:28
epoch [4/30] batch [40/76] time 0.246 (0.260) data 0.000 (0.017) loss 0.6104 (0.6152) lr 9.7553e-03 eta 0:08:43
epoch [4/30] batch [60/76] time 0.224 (0.250) data 0.000 (0.012) loss 1.7012 (0.6595) lr 9.7553e-03 eta 0:08:17
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.39s/it] 50%|█████     | 2/4 [00:01<00:01,  1.54it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.44it/s]100%|██████████| 4/4 [00:01<00:00,  3.47it/s]100%|██████████| 4/4 [00:01<00:00,  2.16it/s]=> result
* total: 377
* correct: 363
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.2%

epoch [5/30] batch [20/76] time 0.239 (0.275) data 0.000 (0.034) loss -0.0217 (0.5715) lr 9.5677e-03 eta 0:08:58
epoch [5/30] batch [40/76] time 0.237 (0.257) data 0.000 (0.017) loss 1.1973 (0.5686) lr 9.5677e-03 eta 0:08:16
epoch [5/30] batch [60/76] time 0.227 (0.249) data 0.000 (0.012) loss 0.0405 (0.7048) lr 9.5677e-03 eta 0:07:57
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.10it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/76] time 0.234 (0.273) data 0.000 (0.033) loss -0.0173 (0.9703) lr 9.3301e-03 eta 0:08:34
epoch [6/30] batch [40/76] time 0.236 (0.257) data 0.000 (0.017) loss 0.1099 (0.8530) lr 9.3301e-03 eta 0:07:58
epoch [6/30] batch [60/76] time 0.225 (0.247) data 0.000 (0.011) loss 1.0361 (0.7573) lr 9.3301e-03 eta 0:07:34
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [7/30] batch [20/76] time 0.241 (0.280) data 0.000 (0.034) loss -0.0272 (0.5987) lr 9.0451e-03 eta 0:08:24
epoch [7/30] batch [40/76] time 0.240 (0.259) data 0.000 (0.017) loss 0.4570 (0.7379) lr 9.0451e-03 eta 0:07:41
epoch [7/30] batch [60/76] time 0.228 (0.249) data 0.000 (0.012) loss -0.1169 (0.7921) lr 9.0451e-03 eta 0:07:19
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.40s/it] 50%|█████     | 2/4 [00:01<00:01,  1.53it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.43it/s]100%|██████████| 4/4 [00:01<00:00,  2.15it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [8/30] batch [20/76] time 0.237 (0.275) data 0.000 (0.034) loss -0.0868 (0.8395) lr 8.7157e-03 eta 0:07:54
epoch [8/30] batch [40/76] time 0.238 (0.259) data 0.000 (0.017) loss 0.2891 (0.6994) lr 8.7157e-03 eta 0:07:22
epoch [8/30] batch [60/76] time 0.226 (0.249) data 0.000 (0.011) loss -0.0278 (0.7760) lr 8.7157e-03 eta 0:06:59
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.10it/s]=> result
* total: 377
* correct: 363
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.3%

epoch [9/30] batch [20/76] time 0.236 (0.277) data 0.000 (0.033) loss 0.2227 (0.4510) lr 8.3457e-03 eta 0:07:37
epoch [9/30] batch [40/76] time 0.327 (0.260) data 0.001 (0.017) loss 0.7573 (0.5259) lr 8.3457e-03 eta 0:07:04
epoch [9/30] batch [60/76] time 0.223 (0.249) data 0.000 (0.011) loss 0.3174 (0.5493) lr 8.3457e-03 eta 0:06:42
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.52it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.44it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 362
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 95.9%

epoch [10/30] batch [20/76] time 0.233 (0.273) data 0.000 (0.035) loss -0.0413 (0.7484) lr 7.9389e-03 eta 0:07:09
epoch [10/30] batch [40/76] time 0.245 (0.257) data 0.000 (0.017) loss 0.4099 (0.5743) lr 7.9389e-03 eta 0:06:39
epoch [10/30] batch [60/76] time 0.227 (0.249) data 0.000 (0.012) loss 0.0326 (0.5285) lr 7.9389e-03 eta 0:06:22
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/76] time 0.246 (0.274) data 0.001 (0.035) loss 0.1501 (0.8143) lr 7.5000e-03 eta 0:06:50
epoch [11/30] batch [40/76] time 0.241 (0.257) data 0.000 (0.018) loss 1.0938 (0.5649) lr 7.5000e-03 eta 0:06:20
epoch [11/30] batch [60/76] time 0.225 (0.248) data 0.000 (0.012) loss -0.0264 (0.6368) lr 7.5000e-03 eta 0:06:01
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.41s/it] 50%|█████     | 2/4 [00:01<00:01,  1.52it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.13it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [12/30] batch [20/76] time 0.267 (0.278) data 0.000 (0.034) loss 0.3613 (0.7051) lr 7.0337e-03 eta 0:06:35
epoch [12/30] batch [40/76] time 0.234 (0.257) data 0.000 (0.017) loss 0.3926 (0.5884) lr 7.0337e-03 eta 0:06:01
epoch [12/30] batch [60/76] time 0.226 (0.248) data 0.000 (0.011) loss -0.1031 (0.6022) lr 7.0337e-03 eta 0:05:43
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%

epoch [13/30] batch [20/76] time 0.241 (0.283) data 0.000 (0.033) loss 0.6709 (0.6534) lr 6.5451e-03 eta 0:06:21
epoch [13/30] batch [40/76] time 0.238 (0.261) data 0.000 (0.016) loss 0.6045 (0.6762) lr 6.5451e-03 eta 0:05:46
epoch [13/30] batch [60/76] time 0.224 (0.250) data 0.000 (0.011) loss 2.6484 (0.6808) lr 6.5451e-03 eta 0:05:26
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [14/30] batch [20/76] time 0.243 (0.275) data 0.000 (0.034) loss 1.6699 (0.7162) lr 6.0396e-03 eta 0:05:49
epoch [14/30] batch [40/76] time 0.252 (0.256) data 0.000 (0.017) loss 0.2786 (0.5673) lr 6.0396e-03 eta 0:05:20
epoch [14/30] batch [60/76] time 0.226 (0.248) data 0.000 (0.011) loss 2.6426 (0.5627) lr 6.0396e-03 eta 0:05:05
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.41s/it] 50%|█████     | 2/4 [00:01<00:01,  1.53it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.45it/s]100%|██████████| 4/4 [00:01<00:00,  2.14it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [15/30] batch [20/76] time 0.234 (0.273) data 0.000 (0.034) loss -0.0286 (0.2850) lr 5.5226e-03 eta 0:05:26
epoch [15/30] batch [40/76] time 0.236 (0.257) data 0.000 (0.017) loss 0.1753 (0.4267) lr 5.5226e-03 eta 0:05:01
epoch [15/30] batch [60/76] time 0.227 (0.249) data 0.000 (0.011) loss 1.0049 (0.3233) lr 5.5226e-03 eta 0:04:47
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [16/30] batch [20/76] time 0.251 (0.275) data 0.000 (0.034) loss 0.0951 (0.5874) lr 5.0000e-03 eta 0:05:08
epoch [16/30] batch [40/76] time 0.232 (0.257) data 0.000 (0.017) loss 0.1808 (0.6646) lr 5.0000e-03 eta 0:04:42
epoch [16/30] batch [60/76] time 0.226 (0.249) data 0.000 (0.011) loss -0.0886 (0.5457) lr 5.0000e-03 eta 0:04:28
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.46s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.36it/s]100%|██████████| 4/4 [00:01<00:00,  2.07it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [17/30] batch [20/76] time 0.249 (0.276) data 0.000 (0.035) loss -0.0817 (0.4682) lr 4.4774e-03 eta 0:04:47
epoch [17/30] batch [40/76] time 0.236 (0.257) data 0.000 (0.018) loss -0.0761 (0.4808) lr 4.4774e-03 eta 0:04:23
epoch [17/30] batch [60/76] time 0.230 (0.249) data 0.000 (0.012) loss 0.9336 (0.4409) lr 4.4774e-03 eta 0:04:09
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.42it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%

epoch [18/30] batch [20/76] time 0.235 (0.277) data 0.000 (0.033) loss -0.0975 (0.2799) lr 3.9604e-03 eta 0:04:28
epoch [18/30] batch [40/76] time 0.243 (0.258) data 0.000 (0.017) loss 0.0815 (0.3423) lr 3.9604e-03 eta 0:04:04
epoch [18/30] batch [60/76] time 0.224 (0.250) data 0.000 (0.011) loss 1.1826 (0.4487) lr 3.9604e-03 eta 0:03:52
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.43it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.0%

epoch [19/30] batch [20/76] time 0.240 (0.273) data 0.000 (0.033) loss 0.1932 (0.5790) lr 3.4549e-03 eta 0:04:03
epoch [19/30] batch [40/76] time 0.237 (0.255) data 0.000 (0.017) loss 2.0312 (0.6403) lr 3.4549e-03 eta 0:03:42
epoch [19/30] batch [60/76] time 0.227 (0.246) data 0.000 (0.011) loss 0.2046 (0.6218) lr 3.4549e-03 eta 0:03:29
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.52it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.13it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [20/30] batch [20/76] time 0.236 (0.280) data 0.000 (0.033) loss -0.1138 (0.3527) lr 2.9663e-03 eta 0:03:48
epoch [20/30] batch [40/76] time 0.233 (0.259) data 0.000 (0.017) loss 0.0801 (0.4725) lr 2.9663e-03 eta 0:03:26
epoch [20/30] batch [60/76] time 0.229 (0.249) data 0.000 (0.011) loss 0.3604 (0.5170) lr 2.9663e-03 eta 0:03:13
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/76] time 0.236 (0.274) data 0.000 (0.034) loss -0.1453 (0.5824) lr 2.5000e-03 eta 0:03:23
epoch [21/30] batch [40/76] time 0.240 (0.257) data 0.000 (0.017) loss -0.1495 (0.4546) lr 2.5000e-03 eta 0:03:04
epoch [21/30] batch [60/76] time 0.229 (0.247) data 0.000 (0.012) loss 0.9102 (0.4515) lr 2.5000e-03 eta 0:02:53
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.35it/s]100%|██████████| 4/4 [00:01<00:00,  2.10it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%

epoch [22/30] batch [20/76] time 0.234 (0.275) data 0.000 (0.033) loss -0.1384 (0.6601) lr 2.0611e-03 eta 0:03:02
epoch [22/30] batch [40/76] time 0.238 (0.258) data 0.000 (0.017) loss -0.1006 (0.6172) lr 2.0611e-03 eta 0:02:46
epoch [22/30] batch [60/76] time 0.228 (0.248) data 0.000 (0.011) loss 0.9209 (0.5498) lr 2.0611e-03 eta 0:02:34
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.41s/it] 50%|█████     | 2/4 [00:01<00:01,  1.52it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.45it/s]100%|██████████| 4/4 [00:01<00:00,  2.15it/s]=> result
* total: 377
* correct: 368
* accuracy: 97.6%
* error: 2.4%
* macro_f1: 97.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [23/30] batch [20/76] time 0.236 (0.278) data 0.000 (0.033) loss 0.0479 (0.2752) lr 1.6543e-03 eta 0:02:43
epoch [23/30] batch [40/76] time 0.234 (0.257) data 0.000 (0.017) loss 0.3489 (0.2957) lr 1.6543e-03 eta 0:02:26
epoch [23/30] batch [60/76] time 0.224 (0.247) data 0.000 (0.011) loss -0.0399 (0.3214) lr 1.6543e-03 eta 0:02:15
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.43it/s]100%|██████████| 4/4 [00:01<00:00,  2.13it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [24/30] batch [20/76] time 0.248 (0.278) data 0.000 (0.034) loss 0.3347 (0.3202) lr 1.2843e-03 eta 0:02:22
epoch [24/30] batch [40/76] time 0.237 (0.260) data 0.000 (0.017) loss -0.0823 (0.4882) lr 1.2843e-03 eta 0:02:08
epoch [24/30] batch [60/76] time 0.229 (0.252) data 0.000 (0.011) loss 0.6133 (0.4177) lr 1.2843e-03 eta 0:01:58
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.52it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.43it/s]100%|██████████| 4/4 [00:01<00:00,  2.13it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%

epoch [25/30] batch [20/76] time 0.237 (0.277) data 0.000 (0.034) loss 0.1772 (0.5192) lr 9.5492e-04 eta 0:02:00
epoch [25/30] batch [40/76] time 0.240 (0.261) data 0.000 (0.017) loss 1.2090 (0.4385) lr 9.5492e-04 eta 0:01:48
epoch [25/30] batch [60/76] time 0.226 (0.250) data 0.000 (0.011) loss -0.1117 (0.3622) lr 9.5492e-04 eta 0:01:39
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%

epoch [26/30] batch [20/76] time 0.236 (0.276) data 0.000 (0.033) loss 0.1957 (0.4479) lr 6.6987e-04 eta 0:01:39
epoch [26/30] batch [40/76] time 0.233 (0.259) data 0.001 (0.017) loss -0.1085 (0.4863) lr 6.6987e-04 eta 0:01:28
epoch [26/30] batch [60/76] time 0.226 (0.249) data 0.000 (0.011) loss 1.3008 (0.5031) lr 6.6987e-04 eta 0:01:19
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.10it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [27/30] batch [20/76] time 0.234 (0.276) data 0.000 (0.034) loss 0.4392 (0.5991) lr 4.3227e-04 eta 0:01:18
epoch [27/30] batch [40/76] time 0.244 (0.260) data 0.000 (0.017) loss -0.0664 (0.4573) lr 4.3227e-04 eta 0:01:08
epoch [27/30] batch [60/76] time 0.227 (0.250) data 0.000 (0.011) loss 0.9189 (0.4216) lr 4.3227e-04 eta 0:01:00
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]100%|██████████| 4/4 [00:01<00:00,  2.08it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%

epoch [28/30] batch [20/76] time 0.236 (0.275) data 0.000 (0.035) loss 0.0468 (0.6025) lr 2.4472e-04 eta 0:00:57
epoch [28/30] batch [40/76] time 0.243 (0.257) data 0.000 (0.018) loss 0.1908 (0.4235) lr 2.4472e-04 eta 0:00:48
epoch [28/30] batch [60/76] time 0.226 (0.249) data 0.000 (0.012) loss 0.3687 (0.4631) lr 2.4472e-04 eta 0:00:41
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%

epoch [29/30] batch [20/76] time 0.239 (0.274) data 0.000 (0.033) loss 0.0516 (0.2807) lr 1.0926e-04 eta 0:00:36
epoch [29/30] batch [40/76] time 0.267 (0.259) data 0.000 (0.016) loss 1.9287 (0.3773) lr 1.0926e-04 eta 0:00:29
epoch [29/30] batch [60/76] time 0.225 (0.249) data 0.000 (0.011) loss -0.1364 (0.3686) lr 1.0926e-04 eta 0:00:22
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.52it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.15it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%

epoch [30/30] batch [20/76] time 0.241 (0.274) data 0.000 (0.034) loss 0.5483 (0.3122) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [40/76] time 0.238 (0.259) data 0.000 (0.017) loss -0.0067 (0.3813) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [60/76] time 0.227 (0.249) data 0.000 (0.012) loss -0.0543 (0.4288) lr 2.7391e-05 eta 0:00:03
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.40s/it] 50%|█████     | 2/4 [00:01<00:01,  1.53it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.43it/s]100%|██████████| 4/4 [00:01<00:00,  2.16it/s]
=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 22)
Evaluate on the *test* set
  0%|          | 0/19 [00:00<?, ?it/s]  5%|▌         | 1/19 [00:02<00:42,  2.37s/it] 11%|█         | 2/19 [00:02<00:20,  1.18s/it] 16%|█▌        | 3/19 [00:02<00:11,  1.42it/s] 21%|██        | 4/19 [00:02<00:07,  2.10it/s] 26%|██▋       | 5/19 [00:03<00:04,  2.85it/s] 32%|███▏      | 6/19 [00:03<00:03,  3.64it/s] 37%|███▋      | 7/19 [00:03<00:02,  4.43it/s] 42%|████▏     | 8/19 [00:03<00:02,  5.15it/s] 47%|████▋     | 9/19 [00:03<00:01,  5.78it/s] 53%|█████▎    | 10/19 [00:03<00:01,  6.31it/s] 58%|█████▊    | 11/19 [00:03<00:01,  6.72it/s] 63%|██████▎   | 12/19 [00:03<00:00,  7.05it/s] 68%|██████▊   | 13/19 [00:04<00:00,  7.29it/s] 74%|███████▎  | 14/19 [00:04<00:00,  7.46it/s] 79%|███████▉  | 15/19 [00:04<00:00,  7.58it/s] 84%|████████▍ | 16/19 [00:04<00:00,  7.68it/s] 89%|████████▉ | 17/19 [00:04<00:00,  7.74it/s] 95%|█████████▍| 18/19 [00:04<00:00,  7.78it/s]100%|██████████| 19/19 [00:04<00:00,  8.21it/s]100%|██████████| 19/19 [00:04<00:00,  3.82it/s]
=> result
* total: 1,881
* correct: 1,783
* accuracy: 94.8%
* error: 5.2%
* macro_f1: 94.8%
Elapsed: 0:10:24
+ sh scripts/rpo_prime/base2new_test_sdl.sh oxford_pets 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
288 359 1788
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  18
# train_x  288
# val      359
# test     1,788
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 23)
Evaluate on the *test* set
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:04<01:15,  4.44s/it] 11%|█         | 2/18 [00:04<00:30,  1.91s/it] 17%|█▋        | 3/18 [00:04<00:16,  1.09s/it] 22%|██▏       | 4/18 [00:04<00:09,  1.40it/s] 28%|██▊       | 5/18 [00:04<00:06,  1.99it/s] 33%|███▎      | 6/18 [00:05<00:04,  2.66it/s] 39%|███▉      | 7/18 [00:05<00:03,  3.39it/s] 44%|████▍     | 8/18 [00:05<00:02,  4.13it/s] 50%|█████     | 9/18 [00:05<00:01,  4.85it/s] 56%|█████▌    | 10/18 [00:05<00:01,  5.49it/s] 61%|██████    | 11/18 [00:05<00:01,  6.05it/s] 67%|██████▋   | 12/18 [00:05<00:00,  6.50it/s] 72%|███████▏  | 13/18 [00:05<00:00,  6.85it/s] 78%|███████▊  | 14/18 [00:06<00:00,  7.13it/s] 83%|████████▎ | 15/18 [00:06<00:00,  7.33it/s] 89%|████████▉ | 16/18 [00:06<00:00,  7.47it/s] 94%|█████████▍| 17/18 [00:06<00:00,  7.56it/s]100%|██████████| 18/18 [00:06<00:00,  7.85it/s]100%|██████████| 18/18 [00:06<00:00,  2.69it/s]
=> result
* total: 1,788
* correct: 1,747
* accuracy: 97.7%
* error: 2.3%
* macro_f1: 97.7%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh oxford_pets 3 0 main_tmp1_0.1sdl 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
304 377 1881
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  19
# train_x  304
# val      377
# test     1,881
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/76] time 0.238 (0.365) data 0.000 (0.064) loss 0.9336 (1.3565) lr 1.0000e-02 eta 0:13:46
epoch [1/30] batch [40/76] time 0.230 (0.300) data 0.000 (0.032) loss 0.8896 (1.2778) lr 1.0000e-02 eta 0:11:12
epoch [1/30] batch [60/76] time 0.225 (0.276) data 0.000 (0.022) loss 1.6172 (1.1455) lr 1.0000e-02 eta 0:10:13
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.49s/it] 50%|█████     | 2/4 [00:01<00:01,  1.45it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.31it/s]100%|██████████| 4/4 [00:01<00:00,  3.32it/s]100%|██████████| 4/4 [00:01<00:00,  2.06it/s]=> result
* total: 377
* correct: 360
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 95.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/76] time 0.230 (0.280) data 0.000 (0.035) loss -0.0468 (0.8825) lr 9.9726e-03 eta 0:10:11
epoch [2/30] batch [40/76] time 0.238 (0.258) data 0.000 (0.018) loss 1.3301 (0.9010) lr 9.9726e-03 eta 0:09:18
epoch [2/30] batch [60/76] time 0.227 (0.248) data 0.000 (0.012) loss 1.0986 (0.8533) lr 9.9726e-03 eta 0:08:51
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.52it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 359
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.2%

epoch [3/30] batch [20/76] time 0.240 (0.275) data 0.000 (0.033) loss 0.6494 (0.9662) lr 9.8907e-03 eta 0:09:39
epoch [3/30] batch [40/76] time 0.244 (0.257) data 0.000 (0.017) loss 0.1896 (0.7533) lr 9.8907e-03 eta 0:08:55
epoch [3/30] batch [60/76] time 0.225 (0.249) data 0.000 (0.011) loss 0.1312 (0.7073) lr 9.8907e-03 eta 0:08:34
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/76] time 0.243 (0.274) data 0.000 (0.034) loss 0.5620 (1.1574) lr 9.7553e-03 eta 0:09:15
epoch [4/30] batch [40/76] time 0.238 (0.256) data 0.000 (0.017) loss 0.4934 (1.0341) lr 9.7553e-03 eta 0:08:35
epoch [4/30] batch [60/76] time 0.226 (0.247) data 0.000 (0.011) loss 0.8408 (0.8317) lr 9.7553e-03 eta 0:08:12
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 363
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.3%

epoch [5/30] batch [20/76] time 0.237 (0.278) data 0.000 (0.035) loss 1.0654 (0.7460) lr 9.5677e-03 eta 0:09:03
epoch [5/30] batch [40/76] time 0.239 (0.257) data 0.000 (0.018) loss 2.1992 (0.7022) lr 9.5677e-03 eta 0:08:17
epoch [5/30] batch [60/76] time 0.226 (0.247) data 0.000 (0.012) loss 1.3857 (0.6029) lr 9.5677e-03 eta 0:07:53
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 361
* accuracy: 95.8%
* error: 4.2%
* macro_f1: 95.7%

epoch [6/30] batch [20/76] time 0.235 (0.274) data 0.000 (0.033) loss 0.2334 (0.6427) lr 9.3301e-03 eta 0:08:35
epoch [6/30] batch [40/76] time 0.237 (0.260) data 0.000 (0.017) loss 1.6836 (0.8026) lr 9.3301e-03 eta 0:08:03
epoch [6/30] batch [60/76] time 0.225 (0.250) data 0.000 (0.011) loss 0.0002 (0.8052) lr 9.3301e-03 eta 0:07:39
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.52it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 360
* accuracy: 95.5%
* error: 4.5%
* macro_f1: 95.5%

epoch [7/30] batch [20/76] time 0.233 (0.272) data 0.000 (0.034) loss 0.5103 (0.7352) lr 9.0451e-03 eta 0:08:11
epoch [7/30] batch [40/76] time 0.236 (0.255) data 0.000 (0.017) loss 0.3960 (0.8373) lr 9.0451e-03 eta 0:07:34
epoch [7/30] batch [60/76] time 0.225 (0.247) data 0.000 (0.012) loss 0.1539 (0.8167) lr 9.0451e-03 eta 0:07:16
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.41s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 362
* accuracy: 96.0%
* error: 4.0%
* macro_f1: 96.0%

epoch [8/30] batch [20/76] time 0.235 (0.273) data 0.000 (0.033) loss -0.0575 (0.5220) lr 8.7157e-03 eta 0:07:52
epoch [8/30] batch [40/76] time 0.228 (0.254) data 0.000 (0.017) loss 0.1099 (0.4804) lr 8.7157e-03 eta 0:07:14
epoch [8/30] batch [60/76] time 0.224 (0.245) data 0.000 (0.011) loss 0.4641 (0.5302) lr 8.7157e-03 eta 0:06:53
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]100%|██████████| 4/4 [00:01<00:00,  2.09it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [9/30] batch [20/76] time 0.242 (0.279) data 0.000 (0.034) loss -0.0528 (0.7599) lr 8.3457e-03 eta 0:07:41
epoch [9/30] batch [40/76] time 0.232 (0.259) data 0.001 (0.017) loss 1.1221 (0.6587) lr 8.3457e-03 eta 0:07:02
epoch [9/30] batch [60/76] time 0.230 (0.249) data 0.000 (0.011) loss 1.6016 (0.6748) lr 8.3457e-03 eta 0:06:41
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.40it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 367
* accuracy: 97.3%
* error: 2.7%
* macro_f1: 97.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/76] time 0.237 (0.274) data 0.000 (0.034) loss 2.4258 (0.5279) lr 7.9389e-03 eta 0:07:12
epoch [10/30] batch [40/76] time 0.235 (0.258) data 0.000 (0.017) loss -0.0859 (0.5889) lr 7.9389e-03 eta 0:06:41
epoch [10/30] batch [60/76] time 0.226 (0.248) data 0.000 (0.012) loss 1.1631 (0.5947) lr 7.9389e-03 eta 0:06:20
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.41s/it] 50%|█████     | 2/4 [00:01<00:01,  1.53it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.45it/s]100%|██████████| 4/4 [00:01<00:00,  2.14it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/76] time 0.235 (0.275) data 0.000 (0.034) loss -0.0502 (0.5715) lr 7.5000e-03 eta 0:06:52
epoch [11/30] batch [40/76] time 0.237 (0.256) data 0.000 (0.017) loss 0.0470 (0.5051) lr 7.5000e-03 eta 0:06:19
epoch [11/30] batch [60/76] time 0.224 (0.248) data 0.000 (0.012) loss 0.6123 (0.5413) lr 7.5000e-03 eta 0:06:01
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.44s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [12/30] batch [20/76] time 0.238 (0.274) data 0.000 (0.035) loss -0.0836 (0.3505) lr 7.0337e-03 eta 0:06:30
epoch [12/30] batch [40/76] time 0.237 (0.256) data 0.000 (0.018) loss -0.0587 (0.4789) lr 7.0337e-03 eta 0:05:59
epoch [12/30] batch [60/76] time 0.312 (0.248) data 0.000 (0.012) loss -0.1243 (0.5690) lr 7.0337e-03 eta 0:05:43
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.35it/s]100%|██████████| 4/4 [00:01<00:00,  2.07it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [13/30] batch [20/76] time 0.246 (0.275) data 0.000 (0.034) loss -0.0186 (0.5538) lr 6.5451e-03 eta 0:06:10
epoch [13/30] batch [40/76] time 0.234 (0.255) data 0.000 (0.017) loss 0.3792 (0.5863) lr 6.5451e-03 eta 0:05:38
epoch [13/30] batch [60/76] time 0.227 (0.248) data 0.000 (0.011) loss 0.3076 (0.6017) lr 6.5451e-03 eta 0:05:23
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.43it/s]100%|██████████| 4/4 [00:01<00:00,  2.14it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [14/30] batch [20/76] time 0.235 (0.275) data 0.000 (0.033) loss 0.9990 (0.4643) lr 6.0396e-03 eta 0:05:50
epoch [14/30] batch [40/76] time 0.236 (0.256) data 0.000 (0.017) loss 0.0458 (0.5486) lr 6.0396e-03 eta 0:05:20
epoch [14/30] batch [60/76] time 0.222 (0.246) data 0.000 (0.011) loss 0.4053 (0.6312) lr 6.0396e-03 eta 0:05:03
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.09it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [15/30] batch [20/76] time 0.237 (0.281) data 0.000 (0.035) loss -0.0171 (0.7059) lr 5.5226e-03 eta 0:05:35
epoch [15/30] batch [40/76] time 0.236 (0.260) data 0.000 (0.018) loss 0.8438 (0.6593) lr 5.5226e-03 eta 0:05:05
epoch [15/30] batch [60/76] time 0.226 (0.249) data 0.000 (0.012) loss 1.4307 (0.6075) lr 5.5226e-03 eta 0:04:48
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.35it/s]100%|██████████| 4/4 [00:01<00:00,  2.09it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [16/30] batch [20/76] time 0.237 (0.274) data 0.000 (0.034) loss 0.5610 (0.4343) lr 5.0000e-03 eta 0:05:06
epoch [16/30] batch [40/76] time 0.240 (0.255) data 0.000 (0.017) loss 1.0234 (0.4976) lr 5.0000e-03 eta 0:04:40
epoch [16/30] batch [60/76] time 0.225 (0.248) data 0.000 (0.011) loss 0.2096 (0.5376) lr 5.0000e-03 eta 0:04:27
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [17/30] batch [20/76] time 0.234 (0.275) data 0.000 (0.033) loss 0.4895 (0.5574) lr 4.4774e-03 eta 0:04:47
epoch [17/30] batch [40/76] time 0.233 (0.257) data 0.000 (0.017) loss 0.4268 (0.5667) lr 4.4774e-03 eta 0:04:22
epoch [17/30] batch [60/76] time 0.221 (0.247) data 0.000 (0.011) loss -0.1066 (0.5244) lr 4.4774e-03 eta 0:04:07
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.47s/it] 50%|█████     | 2/4 [00:01<00:01,  1.46it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.33it/s]100%|██████████| 4/4 [00:01<00:00,  2.07it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [18/30] batch [20/76] time 0.239 (0.283) data 0.000 (0.033) loss 0.5581 (0.3357) lr 3.9604e-03 eta 0:04:33
epoch [18/30] batch [40/76] time 0.236 (0.260) data 0.000 (0.017) loss -0.0054 (0.2680) lr 3.9604e-03 eta 0:04:06
epoch [18/30] batch [60/76] time 0.226 (0.250) data 0.000 (0.011) loss 0.1997 (0.3580) lr 3.9604e-03 eta 0:03:51
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.49it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]100%|██████████| 4/4 [00:01<00:00,  3.39it/s]100%|██████████| 4/4 [00:01<00:00,  2.10it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [19/30] batch [20/76] time 0.236 (0.279) data 0.000 (0.033) loss -0.1065 (0.5173) lr 3.4549e-03 eta 0:04:08
epoch [19/30] batch [40/76] time 0.232 (0.257) data 0.000 (0.017) loss 1.9189 (0.6792) lr 3.4549e-03 eta 0:03:44
epoch [19/30] batch [60/76] time 0.230 (0.248) data 0.000 (0.011) loss 0.1138 (0.6577) lr 3.4549e-03 eta 0:03:31
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 363
* accuracy: 96.3%
* error: 3.7%
* macro_f1: 96.3%

epoch [20/30] batch [20/76] time 0.232 (0.273) data 0.000 (0.035) loss 0.6377 (0.6162) lr 2.9663e-03 eta 0:03:43
epoch [20/30] batch [40/76] time 0.233 (0.258) data 0.000 (0.018) loss 0.9629 (0.4443) lr 2.9663e-03 eta 0:03:25
epoch [20/30] batch [60/76] time 0.222 (0.248) data 0.000 (0.012) loss 0.9990 (0.5500) lr 2.9663e-03 eta 0:03:12
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.46s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.09it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/76] time 0.235 (0.276) data 0.000 (0.033) loss 0.5010 (0.5014) lr 2.5000e-03 eta 0:03:24
epoch [21/30] batch [40/76] time 0.236 (0.258) data 0.000 (0.017) loss 0.9893 (0.5188) lr 2.5000e-03 eta 0:03:05
epoch [21/30] batch [60/76] time 0.224 (0.249) data 0.000 (0.011) loss 0.0282 (0.4659) lr 2.5000e-03 eta 0:02:54
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.41s/it] 50%|█████     | 2/4 [00:01<00:01,  1.53it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.42it/s]100%|██████████| 4/4 [00:01<00:00,  3.45it/s]100%|██████████| 4/4 [00:01<00:00,  2.14it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [22/30] batch [20/76] time 0.238 (0.276) data 0.000 (0.036) loss 1.1973 (0.5494) lr 2.0611e-03 eta 0:03:03
epoch [22/30] batch [40/76] time 0.233 (0.256) data 0.000 (0.018) loss 1.0898 (0.5886) lr 2.0611e-03 eta 0:02:44
epoch [22/30] batch [60/76] time 0.227 (0.248) data 0.000 (0.012) loss 0.4644 (0.7023) lr 2.0611e-03 eta 0:02:34
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.41s/it] 50%|█████     | 2/4 [00:01<00:01,  1.52it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.41it/s]100%|██████████| 4/4 [00:01<00:00,  3.45it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [23/30] batch [20/76] time 0.242 (0.275) data 0.000 (0.034) loss -0.0927 (0.4732) lr 1.6543e-03 eta 0:02:41
epoch [23/30] batch [40/76] time 0.237 (0.256) data 0.000 (0.017) loss -0.0076 (0.5470) lr 1.6543e-03 eta 0:02:25
epoch [23/30] batch [60/76] time 0.225 (0.249) data 0.000 (0.011) loss 0.0204 (0.5759) lr 1.6543e-03 eta 0:02:16
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [24/30] batch [20/76] time 0.235 (0.274) data 0.000 (0.034) loss 0.5039 (0.6289) lr 1.2843e-03 eta 0:02:20
epoch [24/30] batch [40/76] time 0.240 (0.255) data 0.000 (0.017) loss 0.0419 (0.5525) lr 1.2843e-03 eta 0:02:05
epoch [24/30] batch [60/76] time 0.229 (0.246) data 0.000 (0.011) loss 1.4648 (0.5356) lr 1.2843e-03 eta 0:01:56
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.36it/s]100%|██████████| 4/4 [00:01<00:00,  2.07it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [25/30] batch [20/76] time 0.235 (0.275) data 0.000 (0.035) loss -0.1228 (0.5892) lr 9.5492e-04 eta 0:01:59
epoch [25/30] batch [40/76] time 0.236 (0.256) data 0.001 (0.018) loss 0.2289 (0.5929) lr 9.5492e-04 eta 0:01:46
epoch [25/30] batch [60/76] time 0.228 (0.247) data 0.000 (0.012) loss -0.0105 (0.5818) lr 9.5492e-04 eta 0:01:37
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 366
* accuracy: 97.1%
* error: 2.9%
* macro_f1: 97.1%

epoch [26/30] batch [20/76] time 0.320 (0.279) data 0.000 (0.033) loss -0.1035 (0.3318) lr 6.6987e-04 eta 0:01:40
epoch [26/30] batch [40/76] time 0.237 (0.258) data 0.000 (0.017) loss 0.9575 (0.4697) lr 6.6987e-04 eta 0:01:27
epoch [26/30] batch [60/76] time 0.227 (0.249) data 0.000 (0.011) loss 0.2903 (0.4942) lr 6.6987e-04 eta 0:01:19
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.38it/s]100%|██████████| 4/4 [00:01<00:00,  2.08it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [27/30] batch [20/76] time 0.240 (0.274) data 0.000 (0.034) loss 1.8320 (0.7099) lr 4.3227e-04 eta 0:01:17
epoch [27/30] batch [40/76] time 0.242 (0.258) data 0.000 (0.017) loss -0.0848 (0.5618) lr 4.3227e-04 eta 0:01:08
epoch [27/30] batch [60/76] time 0.226 (0.248) data 0.000 (0.011) loss 0.1055 (0.4869) lr 4.3227e-04 eta 0:01:00
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.51it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]100%|██████████| 4/4 [00:01<00:00,  3.43it/s]100%|██████████| 4/4 [00:01<00:00,  2.12it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [28/30] batch [20/76] time 0.240 (0.274) data 0.000 (0.035) loss -0.0338 (0.4894) lr 2.4472e-04 eta 0:00:57
epoch [28/30] batch [40/76] time 0.233 (0.257) data 0.000 (0.017) loss 0.7944 (0.4591) lr 2.4472e-04 eta 0:00:48
epoch [28/30] batch [60/76] time 0.228 (0.247) data 0.000 (0.012) loss 0.0219 (0.4524) lr 2.4472e-04 eta 0:00:41
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.40s/it] 50%|█████     | 2/4 [00:01<00:01,  1.53it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.42it/s]100%|██████████| 4/4 [00:01<00:00,  2.14it/s]=> result
* total: 377
* correct: 364
* accuracy: 96.6%
* error: 3.4%
* macro_f1: 96.5%

epoch [29/30] batch [20/76] time 0.233 (0.275) data 0.000 (0.035) loss 0.3323 (0.6578) lr 1.0926e-04 eta 0:00:36
epoch [29/30] batch [40/76] time 0.234 (0.256) data 0.000 (0.017) loss 2.2441 (0.5878) lr 1.0926e-04 eta 0:00:28
epoch [29/30] batch [60/76] time 0.223 (0.248) data 0.000 (0.012) loss -0.0137 (0.5335) lr 1.0926e-04 eta 0:00:22
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it] 50%|█████     | 2/4 [00:01<00:01,  1.50it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]100%|██████████| 4/4 [00:01<00:00,  3.41it/s]100%|██████████| 4/4 [00:01<00:00,  2.11it/s]=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%

epoch [30/30] batch [20/76] time 0.240 (0.276) data 0.000 (0.034) loss 1.3691 (0.2229) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [40/76] time 0.239 (0.256) data 0.000 (0.017) loss 0.2998 (0.5304) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [60/76] time 0.227 (0.247) data 0.000 (0.012) loss 0.0482 (0.4383) lr 2.7391e-05 eta 0:00:03
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it] 50%|█████     | 2/4 [00:01<00:01,  1.48it/s] 75%|███████▌  | 3/4 [00:01<00:00,  2.36it/s]100%|██████████| 4/4 [00:01<00:00,  2.08it/s]
=> result
* total: 377
* correct: 365
* accuracy: 96.8%
* error: 3.2%
* macro_f1: 96.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 13)
Evaluate on the *test* set
  0%|          | 0/19 [00:00<?, ?it/s]  5%|▌         | 1/19 [00:02<00:45,  2.51s/it] 11%|█         | 2/19 [00:02<00:19,  1.16s/it] 16%|█▌        | 3/19 [00:02<00:11,  1.43it/s] 21%|██        | 4/19 [00:03<00:07,  2.12it/s] 26%|██▋       | 5/19 [00:03<00:04,  2.88it/s] 32%|███▏      | 6/19 [00:03<00:03,  3.67it/s] 37%|███▋      | 7/19 [00:03<00:02,  4.46it/s] 42%|████▏     | 8/19 [00:03<00:02,  5.18it/s] 47%|████▋     | 9/19 [00:03<00:01,  5.80it/s] 53%|█████▎    | 10/19 [00:03<00:01,  6.33it/s] 58%|█████▊    | 11/19 [00:03<00:01,  6.73it/s] 63%|██████▎   | 12/19 [00:04<00:00,  7.04it/s] 68%|██████▊   | 13/19 [00:04<00:00,  7.28it/s] 74%|███████▎  | 14/19 [00:04<00:00,  7.45it/s] 79%|███████▉  | 15/19 [00:04<00:00,  7.58it/s] 84%|████████▍ | 16/19 [00:04<00:00,  7.67it/s] 89%|████████▉ | 17/19 [00:04<00:00,  7.74it/s] 95%|█████████▍| 18/19 [00:04<00:00,  7.78it/s]100%|██████████| 19/19 [00:04<00:00,  8.19it/s]100%|██████████| 19/19 [00:05<00:00,  3.78it/s]
=> result
* total: 1,881
* correct: 1,790
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.2%
Elapsed: 0:10:22
+ sh scripts/rpo_prime/base2new_test_sdl.sh oxford_pets 3 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
288 359 1788
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  18
# train_x  288
# val      359
# test     1,788
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 13)
Evaluate on the *test* set
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:04<01:15,  4.43s/it] 11%|█         | 2/18 [00:04<00:30,  1.90s/it] 17%|█▋        | 3/18 [00:04<00:16,  1.09s/it] 22%|██▏       | 4/18 [00:04<00:09,  1.41it/s] 28%|██▊       | 5/18 [00:04<00:06,  2.00it/s] 33%|███▎      | 6/18 [00:05<00:04,  2.67it/s] 39%|███▉      | 7/18 [00:05<00:03,  3.40it/s] 44%|████▍     | 8/18 [00:05<00:02,  4.15it/s] 50%|█████     | 9/18 [00:05<00:01,  4.86it/s] 56%|█████▌    | 10/18 [00:05<00:01,  5.51it/s] 61%|██████    | 11/18 [00:05<00:01,  6.07it/s] 67%|██████▋   | 12/18 [00:05<00:00,  6.51it/s] 72%|███████▏  | 13/18 [00:05<00:00,  6.87it/s] 78%|███████▊  | 14/18 [00:06<00:00,  7.13it/s] 83%|████████▎ | 15/18 [00:06<00:00,  7.34it/s] 89%|████████▉ | 16/18 [00:06<00:00,  7.50it/s] 94%|█████████▍| 17/18 [00:06<00:00,  7.51it/s]100%|██████████| 18/18 [00:06<00:00,  7.81it/s]100%|██████████| 18/18 [00:06<00:00,  2.69it/s]
=> result
* total: 1,788
* correct: 1,752
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 98.0%
+ for dataset in eurosat dtd oxford_flowers stanford_cars oxford_pets food101 ucf101 caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh food101 1 0 main_tmp1_0.1sdl 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
816 10200 15300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  51
# train_x  816
# val      10,200
# test     15,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/204] time 0.260 (0.378) data 0.000 (0.051) loss 1.4570 (2.2479) lr 1.0000e-02 eta 0:38:24
epoch [1/30] batch [40/204] time 0.253 (0.317) data 0.000 (0.026) loss 0.3735 (1.8211) lr 1.0000e-02 eta 0:32:08
epoch [1/30] batch [60/204] time 0.260 (0.296) data 0.000 (0.017) loss 3.9414 (1.8803) lr 1.0000e-02 eta 0:29:55
epoch [1/30] batch [80/204] time 0.254 (0.287) data 0.000 (0.013) loss 0.3472 (1.7566) lr 1.0000e-02 eta 0:28:50
epoch [1/30] batch [100/204] time 0.257 (0.281) data 0.000 (0.010) loss 0.4937 (1.6132) lr 1.0000e-02 eta 0:28:12
epoch [1/30] batch [120/204] time 0.254 (0.277) data 0.000 (0.009) loss 1.2432 (1.5728) lr 1.0000e-02 eta 0:27:39
epoch [1/30] batch [140/204] time 0.253 (0.274) data 0.000 (0.008) loss 3.1953 (1.5566) lr 1.0000e-02 eta 0:27:15
epoch [1/30] batch [160/204] time 0.253 (0.272) data 0.000 (0.007) loss 0.1031 (1.4969) lr 1.0000e-02 eta 0:26:58
epoch [1/30] batch [180/204] time 0.249 (0.269) data 0.000 (0.006) loss 1.3145 (1.4748) lr 1.0000e-02 eta 0:26:40
epoch [1/30] batch [200/204] time 0.245 (0.267) data 0.000 (0.005) loss 0.0572 (1.4545) lr 1.0000e-02 eta 0:26:20
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:35,  2.73s/it]  2%|▏         | 2/102 [00:03<02:35,  1.56s/it]  3%|▎         | 3/102 [00:03<01:45,  1.07s/it]  4%|▍         | 4/102 [00:04<01:13,  1.33it/s]  5%|▍         | 5/102 [00:04<00:54,  1.79it/s]  6%|▌         | 6/102 [00:04<00:43,  2.19it/s]  7%|▋         | 7/102 [00:04<00:36,  2.58it/s]  8%|▊         | 8/102 [00:05<00:32,  2.90it/s]  9%|▉         | 9/102 [00:05<00:29,  3.12it/s] 10%|▉         | 10/102 [00:05<00:27,  3.32it/s] 11%|█         | 11/102 [00:05<00:26,  3.48it/s] 12%|█▏        | 12/102 [00:06<00:25,  3.59it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.67it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:07<00:23,  3.78it/s] 16%|█▌        | 16/102 [00:07<00:21,  3.97it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.91it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.87it/s] 19%|█▊        | 19/102 [00:08<00:21,  3.87it/s] 20%|█▉        | 20/102 [00:08<00:21,  3.88it/s] 21%|██        | 21/102 [00:08<00:20,  3.97it/s] 22%|██▏       | 22/102 [00:08<00:19,  4.17it/s] 23%|██▎       | 23/102 [00:08<00:19,  4.15it/s] 24%|██▎       | 24/102 [00:09<00:19,  4.02it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.94it/s] 25%|██▌       | 26/102 [00:09<00:18,  4.05it/s] 26%|██▋       | 27/102 [00:09<00:18,  4.00it/s] 27%|██▋       | 28/102 [00:10<00:18,  3.99it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.95it/s] 29%|██▉       | 30/102 [00:10<00:17,  4.08it/s] 30%|███       | 31/102 [00:10<00:16,  4.25it/s] 31%|███▏      | 32/102 [00:11<00:16,  4.12it/s] 32%|███▏      | 33/102 [00:11<00:17,  4.02it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.98it/s] 34%|███▍      | 35/102 [00:11<00:16,  3.95it/s] 35%|███▌      | 36/102 [00:12<00:16,  3.96it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.95it/s] 37%|███▋      | 38/102 [00:12<00:15,  4.10it/s] 38%|███▊      | 39/102 [00:12<00:15,  4.01it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.96it/s] 40%|████      | 41/102 [00:13<00:15,  3.89it/s] 41%|████      | 42/102 [00:13<00:15,  3.99it/s] 42%|████▏     | 43/102 [00:13<00:14,  3.94it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.84it/s] 44%|████▍     | 45/102 [00:14<00:13,  4.09it/s] 45%|████▌     | 46/102 [00:14<00:13,  4.02it/s] 46%|████▌     | 47/102 [00:14<00:13,  3.97it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.98it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.93it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.90it/s] 50%|█████     | 51/102 [00:16<00:13,  3.91it/s] 51%|█████     | 52/102 [00:16<00:12,  3.97it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.92it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.94it/s] 54%|█████▍    | 55/102 [00:16<00:11,  4.09it/s] 55%|█████▍    | 56/102 [00:17<00:10,  4.27it/s] 56%|█████▌    | 57/102 [00:17<00:10,  4.11it/s] 57%|█████▋    | 58/102 [00:17<00:10,  4.02it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.28it/s] 59%|█████▉    | 60/102 [00:18<00:09,  4.55it/s] 60%|█████▉    | 61/102 [00:18<00:09,  4.30it/s] 61%|██████    | 62/102 [00:18<00:09,  4.13it/s] 62%|██████▏   | 63/102 [00:18<00:09,  4.05it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.98it/s] 64%|██████▎   | 65/102 [00:19<00:09,  4.03it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.01it/s] 66%|██████▌   | 67/102 [00:19<00:08,  3.95it/s] 67%|██████▋   | 68/102 [00:20<00:08,  4.06it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.97it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.92it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.93it/s] 71%|███████   | 72/102 [00:21<00:06,  4.32it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.27it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.86it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.44it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.93it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.33it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.63it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.87it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.04it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.38it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.41it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.44it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.45it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.46it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.47it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.48it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.47it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.47it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.48it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.48it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.46it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.48it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.49it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.48it/s]100%|██████████| 102/102 [00:25<00:00,  7.48it/s]100%|██████████| 102/102 [00:25<00:00,  4.02it/s]=> result
* total: 10,200
* correct: 9,170
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/204] time 0.253 (0.294) data 0.000 (0.035) loss 0.2054 (1.4706) lr 9.9726e-03 eta 0:28:54
epoch [2/30] batch [40/204] time 0.258 (0.274) data 0.000 (0.018) loss 1.0293 (1.1912) lr 9.9726e-03 eta 0:26:51
epoch [2/30] batch [60/204] time 0.254 (0.268) data 0.000 (0.012) loss 0.5635 (1.1778) lr 9.9726e-03 eta 0:26:11
epoch [2/30] batch [80/204] time 0.254 (0.266) data 0.000 (0.009) loss -0.0413 (1.1991) lr 9.9726e-03 eta 0:25:51
epoch [2/30] batch [100/204] time 0.255 (0.264) data 0.000 (0.007) loss 1.2295 (1.1594) lr 9.9726e-03 eta 0:25:35
epoch [2/30] batch [120/204] time 0.249 (0.262) data 0.000 (0.006) loss 0.1631 (1.2559) lr 9.9726e-03 eta 0:25:19
epoch [2/30] batch [140/204] time 0.253 (0.261) data 0.000 (0.005) loss 0.1064 (1.2713) lr 9.9726e-03 eta 0:25:09
epoch [2/30] batch [160/204] time 0.256 (0.261) data 0.000 (0.005) loss 0.6436 (1.2877) lr 9.9726e-03 eta 0:25:01
epoch [2/30] batch [180/204] time 0.246 (0.260) data 0.000 (0.004) loss 4.2266 (1.2885) lr 9.9726e-03 eta 0:24:53
epoch [2/30] batch [200/204] time 0.245 (0.259) data 0.000 (0.004) loss 4.8242 (1.3032) lr 9.9726e-03 eta 0:24:39
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:36,  2.73s/it]  2%|▏         | 2/102 [00:03<02:20,  1.41s/it]  3%|▎         | 3/102 [00:03<01:35,  1.03it/s]  4%|▍         | 4/102 [00:03<01:07,  1.45it/s]  5%|▍         | 5/102 [00:04<00:50,  1.90it/s]  6%|▌         | 6/102 [00:04<00:42,  2.28it/s]  7%|▋         | 7/102 [00:04<00:36,  2.60it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:05<00:29,  3.15it/s] 10%|▉         | 10/102 [00:05<00:27,  3.34it/s] 11%|█         | 11/102 [00:05<00:26,  3.49it/s] 12%|█▏        | 12/102 [00:06<00:25,  3.55it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.70it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.75it/s] 16%|█▌        | 16/102 [00:07<00:22,  3.82it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.82it/s] 18%|█▊        | 18/102 [00:07<00:20,  4.02it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.92it/s] 20%|█▉        | 20/102 [00:08<00:20,  3.96it/s] 21%|██        | 21/102 [00:08<00:20,  3.90it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.88it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.87it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.89it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.88it/s] 26%|██▋       | 27/102 [00:09<00:18,  4.01it/s] 27%|██▋       | 28/102 [00:10<00:18,  3.97it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.92it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.84it/s] 30%|███       | 31/102 [00:10<00:16,  4.26it/s] 31%|███▏      | 32/102 [00:10<00:15,  4.51it/s] 32%|███▏      | 33/102 [00:11<00:16,  4.29it/s] 33%|███▎      | 34/102 [00:11<00:16,  4.16it/s] 34%|███▍      | 35/102 [00:11<00:16,  4.12it/s] 35%|███▌      | 36/102 [00:12<00:16,  4.02it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.97it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.96it/s] 38%|███▊      | 39/102 [00:12<00:15,  3.96it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.92it/s] 40%|████      | 41/102 [00:13<00:15,  3.92it/s] 41%|████      | 42/102 [00:13<00:15,  3.90it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.93it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.93it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.90it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.98it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.93it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.85it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.92it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.93it/s] 50%|█████     | 51/102 [00:15<00:13,  3.92it/s] 51%|█████     | 52/102 [00:16<00:12,  3.92it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.93it/s] 54%|█████▍    | 55/102 [00:16<00:11,  3.95it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.86it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.83it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.88it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.87it/s] 59%|█████▉    | 60/102 [00:18<00:11,  3.78it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.79it/s] 61%|██████    | 62/102 [00:18<00:10,  3.80it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.80it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.83it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.86it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.84it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.82it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.87it/s] 71%|███████   | 72/102 [00:21<00:07,  3.90it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.55it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.15it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.68it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.12it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.46it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.53it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.79it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.99it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.13it/s] 80%|████████  | 82/102 [00:22<00:02,  7.23it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.30it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.48it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.47it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.47it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  4.01it/s]=> result
* total: 10,200
* correct: 9,179
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/204] time 0.255 (0.296) data 0.000 (0.035) loss 0.8535 (1.0442) lr 9.8907e-03 eta 0:28:05
epoch [3/30] batch [40/204] time 0.260 (0.277) data 0.000 (0.018) loss 0.7563 (1.1917) lr 9.8907e-03 eta 0:26:10
epoch [3/30] batch [60/204] time 0.249 (0.270) data 0.000 (0.012) loss 1.7578 (1.1743) lr 9.8907e-03 eta 0:25:24
epoch [3/30] batch [80/204] time 0.263 (0.268) data 0.000 (0.009) loss 0.1558 (1.2316) lr 9.8907e-03 eta 0:25:10
epoch [3/30] batch [100/204] time 0.252 (0.266) data 0.000 (0.007) loss 1.9951 (1.2028) lr 9.8907e-03 eta 0:24:54
epoch [3/30] batch [120/204] time 0.257 (0.265) data 0.000 (0.006) loss 2.0879 (1.2141) lr 9.8907e-03 eta 0:24:40
epoch [3/30] batch [140/204] time 0.255 (0.264) data 0.000 (0.005) loss 0.1772 (1.1418) lr 9.8907e-03 eta 0:24:30
epoch [3/30] batch [160/204] time 0.258 (0.263) data 0.000 (0.005) loss 0.1283 (1.1993) lr 9.8907e-03 eta 0:24:21
epoch [3/30] batch [180/204] time 0.243 (0.262) data 0.000 (0.004) loss 0.3325 (1.2780) lr 9.8907e-03 eta 0:24:08
epoch [3/30] batch [200/204] time 0.243 (0.260) data 0.000 (0.004) loss 3.9160 (1.2651) lr 9.8907e-03 eta 0:23:53
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:10,  2.48s/it]  2%|▏         | 2/102 [00:03<02:20,  1.41s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:03,  1.55it/s]  5%|▍         | 5/102 [00:03<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:05<00:29,  3.21it/s] 10%|▉         | 10/102 [00:05<00:27,  3.38it/s] 11%|█         | 11/102 [00:05<00:26,  3.49it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.61it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.72it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.77it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.80it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.82it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.82it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.84it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.82it/s] 21%|██        | 21/102 [00:08<00:21,  3.83it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.82it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.81it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.79it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.81it/s] 25%|██▌       | 26/102 [00:09<00:20,  3.80it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.77it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.80it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.82it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.80it/s] 30%|███       | 31/102 [00:10<00:18,  3.77it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.79it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.78it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.83it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.83it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.81it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.81it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.80it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.85it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.88it/s] 40%|████      | 41/102 [00:13<00:15,  3.89it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.89it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.91it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.87it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.83it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.81it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.79it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.86it/s] 50%|█████     | 51/102 [00:15<00:13,  3.86it/s] 51%|█████     | 52/102 [00:16<00:12,  3.87it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.86it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.88it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.86it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.89it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.88it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.91it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.90it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.83it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.78it/s] 61%|██████    | 62/102 [00:18<00:10,  3.79it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.79it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.81it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.81it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.78it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.80it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.79it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.88it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.87it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.83it/s] 71%|███████   | 72/102 [00:21<00:07,  3.87it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.53it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.13it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.66it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.11it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.46it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.73it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.93it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.37it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.40it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.43it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.45it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.46it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.42it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,163
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 89.8%

epoch [4/30] batch [20/204] time 0.249 (0.296) data 0.000 (0.036) loss 0.4185 (1.0904) lr 9.7553e-03 eta 0:27:02
epoch [4/30] batch [40/204] time 0.264 (0.279) data 0.000 (0.018) loss 0.5889 (1.1700) lr 9.7553e-03 eta 0:25:25
epoch [4/30] batch [60/204] time 0.261 (0.272) data 0.000 (0.012) loss 2.0449 (1.1513) lr 9.7553e-03 eta 0:24:42
epoch [4/30] batch [80/204] time 0.261 (0.269) data 0.000 (0.009) loss 3.6074 (1.1606) lr 9.7553e-03 eta 0:24:18
epoch [4/30] batch [100/204] time 0.254 (0.266) data 0.000 (0.007) loss 2.5332 (1.2379) lr 9.7553e-03 eta 0:24:00
epoch [4/30] batch [120/204] time 0.260 (0.265) data 0.000 (0.006) loss 2.1621 (1.2218) lr 9.7553e-03 eta 0:23:46
epoch [4/30] batch [140/204] time 0.256 (0.263) data 0.000 (0.005) loss 0.3643 (1.1853) lr 9.7553e-03 eta 0:23:32
epoch [4/30] batch [160/204] time 0.254 (0.262) data 0.000 (0.005) loss 0.2800 (1.2010) lr 9.7553e-03 eta 0:23:22
epoch [4/30] batch [180/204] time 0.243 (0.262) data 0.000 (0.004) loss 2.7109 (1.2226) lr 9.7553e-03 eta 0:23:13
epoch [4/30] batch [200/204] time 0.243 (0.260) data 0.000 (0.004) loss 0.6274 (1.2196) lr 9.7553e-03 eta 0:23:00
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:16,  2.54s/it]  2%|▏         | 2/102 [00:03<02:22,  1.42s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:04<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.31it/s]  7%|▋         | 7/102 [00:04<00:35,  2.70it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:05<00:29,  3.20it/s] 10%|▉         | 10/102 [00:05<00:27,  3.41it/s] 11%|█         | 11/102 [00:05<00:25,  3.52it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.63it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.69it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.74it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.74it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.81it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.83it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.80it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.87it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.84it/s] 21%|██        | 21/102 [00:08<00:21,  3.84it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.84it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.84it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.78it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.84it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.87it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.85it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.86it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.87it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.85it/s] 30%|███       | 31/102 [00:10<00:18,  3.86it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.86it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.85it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.87it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.86it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.81it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.83it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.83it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.85it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.88it/s] 40%|████      | 41/102 [00:13<00:15,  3.87it/s] 41%|████      | 42/102 [00:13<00:15,  3.89it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.85it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.80it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.82it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.85it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.81it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.81it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.83it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.83it/s] 50%|█████     | 51/102 [00:15<00:13,  3.85it/s] 51%|█████     | 52/102 [00:16<00:12,  3.89it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.87it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.86it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.84it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.89it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.87it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.87it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.86it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.84it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.81it/s] 61%|██████    | 62/102 [00:18<00:10,  3.86it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.88it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.88it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.87it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.86it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.88it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.90it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.90it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.91it/s] 71%|███████   | 72/102 [00:21<00:07,  3.96it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.38it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.00it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.55it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.01it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.39it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.67it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.90it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.46it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,184
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/204] time 0.258 (0.296) data 0.000 (0.037) loss 0.5103 (1.2582) lr 9.5677e-03 eta 0:26:05
epoch [5/30] batch [40/204] time 0.256 (0.277) data 0.000 (0.018) loss 2.0469 (1.0810) lr 9.5677e-03 eta 0:24:18
epoch [5/30] batch [60/204] time 0.261 (0.270) data 0.001 (0.012) loss 0.5352 (1.1760) lr 9.5677e-03 eta 0:23:35
epoch [5/30] batch [80/204] time 0.260 (0.266) data 0.000 (0.009) loss 1.2920 (1.1886) lr 9.5677e-03 eta 0:23:09
epoch [5/30] batch [100/204] time 0.254 (0.265) data 0.000 (0.008) loss 1.4053 (1.1083) lr 9.5677e-03 eta 0:22:59
epoch [5/30] batch [120/204] time 0.253 (0.264) data 0.000 (0.006) loss 0.0276 (1.1501) lr 9.5677e-03 eta 0:22:48
epoch [5/30] batch [140/204] time 0.254 (0.263) data 0.000 (0.005) loss 0.2966 (1.1172) lr 9.5677e-03 eta 0:22:38
epoch [5/30] batch [160/204] time 0.254 (0.262) data 0.000 (0.005) loss 1.6631 (1.1324) lr 9.5677e-03 eta 0:22:28
epoch [5/30] batch [180/204] time 0.247 (0.262) data 0.000 (0.004) loss 3.2695 (1.1828) lr 9.5677e-03 eta 0:22:20
epoch [5/30] batch [200/204] time 0.249 (0.260) data 0.000 (0.004) loss 2.1387 (1.1603) lr 9.5677e-03 eta 0:22:07
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:18,  2.56s/it]  2%|▏         | 2/102 [00:03<02:23,  1.43s/it]  3%|▎         | 3/102 [00:03<01:28,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.54it/s]  5%|▍         | 5/102 [00:04<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:40,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.70it/s]  8%|▊         | 8/102 [00:04<00:31,  2.97it/s]  9%|▉         | 9/102 [00:05<00:28,  3.22it/s] 10%|▉         | 10/102 [00:05<00:27,  3.38it/s] 11%|█         | 11/102 [00:05<00:25,  3.54it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.65it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.69it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.70it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.72it/s] 16%|█▌        | 16/102 [00:06<00:23,  3.73it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.75it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.80it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.81it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.81it/s] 21%|██        | 21/102 [00:08<00:21,  3.84it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.83it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.84it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.81it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.82it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.86it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.85it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.84it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.85it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.91it/s] 30%|███       | 31/102 [00:10<00:18,  3.92it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.89it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.88it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.83it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.81it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.84it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.83it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.91it/s] 40%|████      | 41/102 [00:13<00:15,  3.92it/s] 41%|████      | 42/102 [00:13<00:15,  3.92it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.87it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.87it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.87it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.98it/s] 46%|████▌     | 47/102 [00:14<00:13,  4.10it/s] 47%|████▋     | 48/102 [00:15<00:13,  4.15it/s] 48%|████▊     | 49/102 [00:15<00:13,  4.04it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.97it/s] 50%|█████     | 51/102 [00:15<00:12,  3.96it/s] 51%|█████     | 52/102 [00:16<00:12,  3.95it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.95it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.90it/s] 54%|█████▍    | 55/102 [00:16<00:11,  3.98it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.98it/s] 56%|█████▌    | 57/102 [00:17<00:10,  4.32it/s] 57%|█████▋    | 58/102 [00:17<00:10,  4.16it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.09it/s] 59%|█████▉    | 60/102 [00:18<00:10,  4.06it/s] 60%|█████▉    | 61/102 [00:18<00:10,  4.03it/s] 61%|██████    | 62/102 [00:18<00:09,  4.07it/s] 62%|██████▏   | 63/102 [00:18<00:09,  4.23it/s] 63%|██████▎   | 64/102 [00:19<00:09,  4.11it/s] 64%|██████▎   | 65/102 [00:19<00:09,  4.05it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.00it/s] 66%|██████▌   | 67/102 [00:19<00:08,  3.96it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.94it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.92it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.87it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.93it/s] 71%|███████   | 72/102 [00:21<00:07,  4.00it/s] 72%|███████▏  | 73/102 [00:21<00:07,  4.11it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.76it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.34it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.84it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.25it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.57it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.81it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.99it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.13it/s] 80%|████████  | 82/102 [00:22<00:02,  7.23it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.46it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.35it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.38it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.41it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.42it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,185
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/204] time 0.256 (0.295) data 0.000 (0.035) loss 1.1211 (0.8450) lr 9.3301e-03 eta 0:24:57
epoch [6/30] batch [40/204] time 0.254 (0.276) data 0.000 (0.017) loss 3.7734 (1.0122) lr 9.3301e-03 eta 0:23:15
epoch [6/30] batch [60/204] time 0.265 (0.270) data 0.000 (0.012) loss 1.9805 (1.2135) lr 9.3301e-03 eta 0:22:40
epoch [6/30] batch [80/204] time 0.259 (0.268) data 0.000 (0.009) loss 0.3901 (1.1806) lr 9.3301e-03 eta 0:22:25
epoch [6/30] batch [100/204] time 0.264 (0.266) data 0.000 (0.007) loss 0.0356 (1.1326) lr 9.3301e-03 eta 0:22:09
epoch [6/30] batch [120/204] time 0.255 (0.264) data 0.000 (0.006) loss 0.0430 (1.0933) lr 9.3301e-03 eta 0:21:55
epoch [6/30] batch [140/204] time 0.248 (0.263) data 0.000 (0.005) loss 0.2517 (1.0379) lr 9.3301e-03 eta 0:21:43
epoch [6/30] batch [160/204] time 0.256 (0.263) data 0.000 (0.005) loss 0.1394 (1.0252) lr 9.3301e-03 eta 0:21:37
epoch [6/30] batch [180/204] time 0.245 (0.262) data 0.000 (0.004) loss 1.3438 (1.0016) lr 9.3301e-03 eta 0:21:26
epoch [6/30] batch [200/204] time 0.246 (0.260) data 0.000 (0.004) loss 3.7188 (1.0952) lr 9.3301e-03 eta 0:21:13
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:20,  2.58s/it]  2%|▏         | 2/102 [00:03<02:17,  1.37s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:03,  1.54it/s]  5%|▍         | 5/102 [00:03<00:49,  1.96it/s]  6%|▌         | 6/102 [00:04<00:41,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:30,  3.10it/s]  9%|▉         | 9/102 [00:04<00:28,  3.30it/s] 10%|▉         | 10/102 [00:05<00:26,  3.50it/s] 11%|█         | 11/102 [00:05<00:25,  3.64it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.74it/s] 13%|█▎        | 13/102 [00:05<00:23,  3.79it/s] 14%|█▎        | 14/102 [00:06<00:22,  3.84it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.86it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.87it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.84it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.85it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.84it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.84it/s] 21%|██        | 21/102 [00:08<00:21,  3.82it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:19,  3.97it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.93it/s] 25%|██▍       | 25/102 [00:09<00:19,  4.03it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.97it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.94it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.90it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.96it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.98it/s] 30%|███       | 31/102 [00:10<00:17,  3.95it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.91it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.87it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.85it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.86it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.87it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.90it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.90it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.92it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.87it/s] 40%|████      | 41/102 [00:13<00:15,  3.82it/s] 41%|████      | 42/102 [00:13<00:15,  3.83it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.82it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.82it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.82it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.88it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.91it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.84it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.81it/s] 50%|█████     | 51/102 [00:15<00:13,  3.83it/s] 51%|█████     | 52/102 [00:16<00:12,  3.86it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.85it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.83it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.90it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.86it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.83it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.81it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.79it/s] 59%|█████▉    | 60/102 [00:18<00:11,  3.81it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.82it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.83it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.84it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.83it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.81it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.89it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.87it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.94it/s] 71%|███████   | 72/102 [00:21<00:07,  4.17it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.48it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.07it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.61it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.06it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.42it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.71it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.92it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.02it/s]=> result
* total: 10,200
* correct: 9,187
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/204] time 0.264 (0.296) data 0.000 (0.035) loss 0.0395 (0.7183) lr 9.0451e-03 eta 0:24:00
epoch [7/30] batch [40/204] time 0.260 (0.276) data 0.000 (0.018) loss 4.6680 (1.0950) lr 9.0451e-03 eta 0:22:19
epoch [7/30] batch [60/204] time 0.259 (0.269) data 0.000 (0.012) loss 0.3245 (1.0722) lr 9.0451e-03 eta 0:21:42
epoch [7/30] batch [80/204] time 0.255 (0.267) data 0.000 (0.009) loss 0.6021 (1.0558) lr 9.0451e-03 eta 0:21:26
epoch [7/30] batch [100/204] time 0.251 (0.265) data 0.000 (0.007) loss 0.1449 (0.9829) lr 9.0451e-03 eta 0:21:12
epoch [7/30] batch [120/204] time 0.254 (0.264) data 0.000 (0.006) loss 0.8701 (1.0492) lr 9.0451e-03 eta 0:21:00
epoch [7/30] batch [140/204] time 0.257 (0.263) data 0.000 (0.005) loss 0.5825 (1.0883) lr 9.0451e-03 eta 0:20:48
epoch [7/30] batch [160/204] time 0.256 (0.262) data 0.000 (0.005) loss 2.1426 (1.0944) lr 9.0451e-03 eta 0:20:38
epoch [7/30] batch [180/204] time 0.315 (0.261) data 0.000 (0.004) loss 0.4321 (1.0952) lr 9.0451e-03 eta 0:20:29
epoch [7/30] batch [200/204] time 0.243 (0.259) data 0.000 (0.004) loss 0.0053 (1.0766) lr 9.0451e-03 eta 0:20:16
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:07,  2.45s/it]  2%|▏         | 2/102 [00:02<02:12,  1.33s/it]  3%|▎         | 3/102 [00:03<01:33,  1.06it/s]  4%|▍         | 4/102 [00:03<01:06,  1.47it/s]  5%|▍         | 5/102 [00:04<00:52,  1.87it/s]  6%|▌         | 6/102 [00:04<00:42,  2.24it/s]  7%|▋         | 7/102 [00:04<00:36,  2.61it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:05<00:29,  3.15it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:26,  3.49it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.57it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.70it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.80it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.86it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.86it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.83it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.87it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.86it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.86it/s] 21%|██        | 21/102 [00:08<00:21,  3.83it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.78it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.79it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.79it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.80it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.81it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.83it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.83it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.83it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.85it/s] 30%|███       | 31/102 [00:10<00:18,  3.88it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.83it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.82it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.82it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.79it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.86it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.84it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.82it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.81it/s] 40%|████      | 41/102 [00:13<00:16,  3.80it/s] 41%|████      | 42/102 [00:13<00:15,  3.90it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.82it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.87it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.88it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.83it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.91it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.91it/s] 50%|█████     | 51/102 [00:15<00:12,  3.93it/s] 51%|█████     | 52/102 [00:16<00:12,  3.88it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.85it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.85it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.84it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.83it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.82it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.89it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.85it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.88it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.85it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.88it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.89it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.93it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.90it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.87it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.87it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.84it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.87it/s] 71%|███████   | 72/102 [00:21<00:07,  3.94it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.58it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.18it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.69it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.12it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.48it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.75it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.93it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.25it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.39it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.42it/s]100%|██████████| 102/102 [00:25<00:00,  7.39it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,199
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/204] time 0.257 (0.293) data 0.000 (0.034) loss 1.9990 (1.2862) lr 8.7157e-03 eta 0:22:51
epoch [8/30] batch [40/204] time 0.254 (0.275) data 0.000 (0.017) loss 4.2188 (1.2043) lr 8.7157e-03 eta 0:21:20
epoch [8/30] batch [60/204] time 0.257 (0.269) data 0.000 (0.012) loss 2.5156 (1.1296) lr 8.7157e-03 eta 0:20:45
epoch [8/30] batch [80/204] time 0.254 (0.266) data 0.000 (0.009) loss 4.4727 (1.2087) lr 8.7157e-03 eta 0:20:24
epoch [8/30] batch [100/204] time 0.259 (0.265) data 0.000 (0.007) loss 0.9902 (1.0923) lr 8.7157e-03 eta 0:20:15
epoch [8/30] batch [120/204] time 0.257 (0.263) data 0.000 (0.006) loss 0.1357 (1.0102) lr 8.7157e-03 eta 0:20:02
epoch [8/30] batch [140/204] time 0.249 (0.262) data 0.000 (0.005) loss 0.1235 (1.1487) lr 8.7157e-03 eta 0:19:52
epoch [8/30] batch [160/204] time 0.267 (0.261) data 0.000 (0.005) loss -0.0527 (1.0991) lr 8.7157e-03 eta 0:19:43
epoch [8/30] batch [180/204] time 0.244 (0.260) data 0.000 (0.004) loss 0.7119 (1.1468) lr 8.7157e-03 eta 0:19:33
epoch [8/30] batch [200/204] time 0.246 (0.259) data 0.000 (0.004) loss 1.6348 (1.1325) lr 8.7157e-03 eta 0:19:24
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<03:53,  2.31s/it]  2%|▏         | 2/102 [00:02<02:07,  1.28s/it]  3%|▎         | 3/102 [00:03<01:26,  1.15it/s]  4%|▍         | 4/102 [00:03<01:02,  1.58it/s]  5%|▍         | 5/102 [00:03<00:48,  1.99it/s]  6%|▌         | 6/102 [00:04<00:40,  2.36it/s]  7%|▋         | 7/102 [00:04<00:34,  2.72it/s]  8%|▊         | 8/102 [00:04<00:31,  3.01it/s]  9%|▉         | 9/102 [00:04<00:28,  3.23it/s] 10%|▉         | 10/102 [00:05<00:27,  3.40it/s] 11%|█         | 11/102 [00:05<00:25,  3.53it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.62it/s] 13%|█▎        | 13/102 [00:05<00:24,  3.69it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.74it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.75it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.80it/s] 17%|█▋        | 17/102 [00:06<00:21,  3.87it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.84it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.87it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.82it/s] 21%|██        | 21/102 [00:07<00:21,  3.81it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.83it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.87it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.84it/s] 25%|██▍       | 25/102 [00:08<00:19,  3.86it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.88it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.89it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.85it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.86it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.90it/s] 30%|███       | 31/102 [00:10<00:18,  3.91it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.88it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.84it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.86it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.82it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.84it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.83it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.82it/s] 40%|████      | 41/102 [00:13<00:15,  3.84it/s] 41%|████      | 42/102 [00:13<00:15,  3.84it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.89it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.85it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.88it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.86it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.88it/s] 50%|█████     | 51/102 [00:15<00:13,  3.90it/s] 51%|█████     | 52/102 [00:15<00:12,  3.86it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.86it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.83it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.87it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.84it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.83it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.86it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.83it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.82it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.84it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.80it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.83it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.82it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.83it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.82it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.83it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.84it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.89it/s] 71%|███████   | 72/102 [00:21<00:07,  3.92it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.23it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.87it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.44it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.93it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.33it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.63it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.88it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.05it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.38it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.42it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.44it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.44it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.47it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.46it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.46it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.46it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.48it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.47it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.48it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.48it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.48it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.49it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.48it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  7.48it/s]100%|██████████| 102/102 [00:25<00:00,  4.02it/s]=> result
* total: 10,200
* correct: 9,203
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/204] time 0.269 (0.295) data 0.000 (0.036) loss -0.0080 (1.2996) lr 8.3457e-03 eta 0:21:57
epoch [9/30] batch [40/204] time 0.256 (0.276) data 0.000 (0.018) loss 3.2930 (1.2080) lr 8.3457e-03 eta 0:20:28
epoch [9/30] batch [60/204] time 0.251 (0.270) data 0.000 (0.012) loss 0.9912 (1.1548) lr 8.3457e-03 eta 0:19:54
epoch [9/30] batch [80/204] time 0.256 (0.266) data 0.000 (0.009) loss 1.4004 (1.0833) lr 8.3457e-03 eta 0:19:33
epoch [9/30] batch [100/204] time 0.255 (0.264) data 0.000 (0.007) loss 0.3931 (1.0998) lr 8.3457e-03 eta 0:19:19
epoch [9/30] batch [120/204] time 0.256 (0.264) data 0.000 (0.006) loss 4.0430 (1.0880) lr 8.3457e-03 eta 0:19:15
epoch [9/30] batch [140/204] time 0.259 (0.264) data 0.000 (0.005) loss 1.8408 (1.0832) lr 8.3457e-03 eta 0:19:05
epoch [9/30] batch [160/204] time 0.250 (0.263) data 0.000 (0.005) loss 0.0262 (1.0486) lr 8.3457e-03 eta 0:18:57
epoch [9/30] batch [180/204] time 0.243 (0.262) data 0.000 (0.004) loss 0.5747 (1.1019) lr 8.3457e-03 eta 0:18:46
epoch [9/30] batch [200/204] time 0.243 (0.260) data 0.000 (0.004) loss 2.0723 (1.0665) lr 8.3457e-03 eta 0:18:35
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:22,  2.60s/it]  2%|▏         | 2/102 [00:03<02:19,  1.40s/it]  3%|▎         | 3/102 [00:03<01:27,  1.13it/s]  4%|▍         | 4/102 [00:03<01:03,  1.55it/s]  5%|▍         | 5/102 [00:03<00:48,  2.02it/s]  6%|▌         | 6/102 [00:04<00:38,  2.50it/s]  7%|▋         | 7/102 [00:04<00:33,  2.82it/s]  8%|▊         | 8/102 [00:04<00:29,  3.18it/s]  9%|▉         | 9/102 [00:04<00:27,  3.37it/s] 10%|▉         | 10/102 [00:05<00:24,  3.73it/s] 11%|█         | 11/102 [00:05<00:23,  3.80it/s] 12%|█▏        | 12/102 [00:05<00:23,  3.83it/s] 13%|█▎        | 13/102 [00:05<00:22,  3.90it/s] 14%|█▎        | 14/102 [00:06<00:21,  4.10it/s] 15%|█▍        | 15/102 [00:06<00:21,  3.98it/s] 16%|█▌        | 16/102 [00:06<00:21,  3.93it/s] 17%|█▋        | 17/102 [00:06<00:21,  3.89it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.90it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.89it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.87it/s] 21%|██        | 21/102 [00:07<00:21,  3.85it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.88it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:08<00:19,  4.06it/s] 25%|██▍       | 25/102 [00:08<00:19,  3.97it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.96it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.94it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.90it/s] 28%|██▊       | 29/102 [00:09<00:18,  3.85it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.94it/s] 30%|███       | 31/102 [00:10<00:18,  3.86it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.86it/s] 32%|███▏      | 33/102 [00:10<00:18,  3.82it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.82it/s] 35%|███▌      | 36/102 [00:11<00:16,  3.94it/s] 36%|███▋      | 37/102 [00:11<00:16,  3.93it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.90it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.90it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.87it/s] 40%|████      | 41/102 [00:13<00:15,  3.93it/s] 41%|████      | 42/102 [00:13<00:15,  3.90it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.88it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.87it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.88it/s] 46%|████▌     | 47/102 [00:14<00:13,  3.98it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.96it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.89it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.88it/s] 50%|█████     | 51/102 [00:15<00:13,  3.87it/s] 51%|█████     | 52/102 [00:15<00:12,  3.85it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.96it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.96it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.90it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.88it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.83it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.83it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.89it/s] 59%|█████▉    | 60/102 [00:17<00:10,  3.92it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.89it/s] 61%|██████    | 62/102 [00:18<00:09,  4.09it/s] 62%|██████▏   | 63/102 [00:18<00:09,  4.09it/s] 63%|██████▎   | 64/102 [00:18<00:09,  4.06it/s] 64%|██████▎   | 65/102 [00:19<00:09,  4.02it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.93it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.88it/s] 67%|██████▋   | 68/102 [00:19<00:07,  4.32it/s] 68%|██████▊   | 69/102 [00:20<00:07,  4.22it/s] 69%|██████▊   | 70/102 [00:20<00:07,  4.10it/s] 70%|██████▉   | 71/102 [00:20<00:07,  4.03it/s] 71%|███████   | 72/102 [00:20<00:07,  3.99it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.40it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.02it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.57it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.04it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.38it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.67it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.89it/s] 78%|███████▊  | 80/102 [00:21<00:03,  7.05it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:23<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.47it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.47it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.37it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.40it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.42it/s]100%|██████████| 102/102 [00:24<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.07it/s]=> result
* total: 10,200
* correct: 9,194
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%

epoch [10/30] batch [20/204] time 0.256 (0.298) data 0.000 (0.035) loss 0.4583 (1.2688) lr 7.9389e-03 eta 0:21:08
epoch [10/30] batch [40/204] time 0.260 (0.278) data 0.000 (0.018) loss -0.0498 (1.1655) lr 7.9389e-03 eta 0:19:39
epoch [10/30] batch [60/204] time 0.256 (0.272) data 0.000 (0.012) loss 0.6270 (1.2748) lr 7.9389e-03 eta 0:19:09
epoch [10/30] batch [80/204] time 0.260 (0.269) data 0.000 (0.009) loss -0.0037 (1.2961) lr 7.9389e-03 eta 0:18:48
epoch [10/30] batch [100/204] time 0.256 (0.267) data 0.000 (0.007) loss 1.3623 (1.2107) lr 7.9389e-03 eta 0:18:38
epoch [10/30] batch [120/204] time 0.261 (0.266) data 0.000 (0.006) loss 1.7129 (1.1688) lr 7.9389e-03 eta 0:18:25
epoch [10/30] batch [140/204] time 0.257 (0.264) data 0.000 (0.005) loss 1.5967 (1.1353) lr 7.9389e-03 eta 0:18:14
epoch [10/30] batch [160/204] time 0.250 (0.263) data 0.000 (0.005) loss 0.2366 (1.0890) lr 7.9389e-03 eta 0:18:06
epoch [10/30] batch [180/204] time 0.249 (0.262) data 0.000 (0.004) loss 1.5547 (1.0725) lr 7.9389e-03 eta 0:17:55
epoch [10/30] batch [200/204] time 0.244 (0.260) data 0.000 (0.004) loss 0.3674 (1.0989) lr 7.9389e-03 eta 0:17:43
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:14,  2.52s/it]  2%|▏         | 2/102 [00:03<02:20,  1.40s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:03,  1.53it/s]  5%|▍         | 5/102 [00:03<00:50,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.30it/s]  7%|▋         | 7/102 [00:04<00:35,  2.64it/s]  8%|▊         | 8/102 [00:04<00:31,  2.96it/s]  9%|▉         | 9/102 [00:05<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.33it/s] 11%|█         | 11/102 [00:05<00:26,  3.43it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.52it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.76it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.75it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.75it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.75it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.77it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.78it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.81it/s] 21%|██        | 21/102 [00:08<00:21,  3.85it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.86it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.89it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.83it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.79it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.78it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.82it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.83it/s] 30%|███       | 31/102 [00:10<00:18,  3.86it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.85it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.81it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.87it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.88it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.85it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.90it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.88it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.88it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.87it/s] 40%|████      | 41/102 [00:13<00:15,  3.84it/s] 41%|████      | 42/102 [00:13<00:15,  3.87it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.92it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.87it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.89it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.88it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.85it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.87it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.89it/s] 50%|█████     | 51/102 [00:15<00:13,  3.92it/s] 51%|█████     | 52/102 [00:16<00:12,  3.88it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.78it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.81it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.86it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.84it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.86it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.88it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.83it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.81it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.83it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.90it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.92it/s] 66%|██████▌   | 67/102 [00:20<00:08,  3.89it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.85it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.86it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.86it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.95it/s] 71%|███████   | 72/102 [00:21<00:07,  3.98it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.55it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.15it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.68it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.12it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.46it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.73it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.92it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.37it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.43it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.45it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,199
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/204] time 0.257 (0.296) data 0.000 (0.036) loss 0.3591 (1.1478) lr 7.5000e-03 eta 0:20:02
epoch [11/30] batch [40/204] time 0.258 (0.277) data 0.000 (0.018) loss 2.3594 (1.2258) lr 7.5000e-03 eta 0:18:38
epoch [11/30] batch [60/204] time 0.258 (0.271) data 0.001 (0.012) loss 0.5664 (1.1737) lr 7.5000e-03 eta 0:18:10
epoch [11/30] batch [80/204] time 0.259 (0.268) data 0.000 (0.009) loss 2.0410 (1.2141) lr 7.5000e-03 eta 0:17:51
epoch [11/30] batch [100/204] time 0.252 (0.265) data 0.000 (0.008) loss 0.1151 (1.1185) lr 7.5000e-03 eta 0:17:36
epoch [11/30] batch [120/204] time 0.251 (0.264) data 0.000 (0.006) loss 1.0615 (1.1579) lr 7.5000e-03 eta 0:17:25
epoch [11/30] batch [140/204] time 0.251 (0.263) data 0.000 (0.005) loss 3.1602 (1.0877) lr 7.5000e-03 eta 0:17:15
epoch [11/30] batch [160/204] time 0.252 (0.262) data 0.000 (0.005) loss -0.0477 (1.0469) lr 7.5000e-03 eta 0:17:07
epoch [11/30] batch [180/204] time 0.245 (0.261) data 0.000 (0.004) loss 2.9414 (1.0946) lr 7.5000e-03 eta 0:16:57
epoch [11/30] batch [200/204] time 0.245 (0.259) data 0.000 (0.004) loss 2.0879 (1.1039) lr 7.5000e-03 eta 0:16:45
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:04,  2.42s/it]  2%|▏         | 2/102 [00:02<02:12,  1.33s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:03,  1.53it/s]  5%|▍         | 5/102 [00:03<00:50,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.64it/s]  8%|▊         | 8/102 [00:04<00:32,  2.93it/s]  9%|▉         | 9/102 [00:04<00:29,  3.14it/s] 10%|▉         | 10/102 [00:05<00:27,  3.31it/s] 11%|█         | 11/102 [00:05<00:26,  3.43it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.55it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.63it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.70it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.75it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.77it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.79it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.85it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.80it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.83it/s] 21%|██        | 21/102 [00:08<00:21,  3.80it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.85it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.82it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.83it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.81it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.84it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.84it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.88it/s] 30%|███       | 31/102 [00:10<00:18,  3.91it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.84it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.82it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.79it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.83it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.83it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.81it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.81it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.85it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.83it/s] 40%|████      | 41/102 [00:13<00:15,  3.86it/s] 41%|████      | 42/102 [00:13<00:15,  3.87it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.84it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.89it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.82it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.82it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.84it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.80it/s] 50%|█████     | 51/102 [00:15<00:13,  3.83it/s] 51%|█████     | 52/102 [00:16<00:12,  3.89it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.88it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.89it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.89it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.87it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.88it/s] 58%|█████▊    | 59/102 [00:17<00:10,  3.92it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.91it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.88it/s] 61%|██████    | 62/102 [00:18<00:10,  3.88it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.88it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.84it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.82it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.88it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.83it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.80it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.86it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.84it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.85it/s] 71%|███████   | 72/102 [00:21<00:07,  3.96it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.58it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.18it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.71it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.16it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.50it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.77it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.97it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.10it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.22it/s] 80%|████████  | 82/102 [00:22<00:02,  7.30it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.35it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.40it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.43it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.43it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.46it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.46it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.48it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.48it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.48it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.49it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.48it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.47it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.48it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.47it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.47it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,207
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/204] time 0.255 (0.299) data 0.000 (0.036) loss -0.0211 (0.8953) lr 7.0337e-03 eta 0:19:12
epoch [12/30] batch [40/204] time 0.256 (0.277) data 0.000 (0.018) loss 0.0457 (0.8937) lr 7.0337e-03 eta 0:17:41
epoch [12/30] batch [60/204] time 0.257 (0.270) data 0.000 (0.012) loss 0.0316 (1.0949) lr 7.0337e-03 eta 0:17:11
epoch [12/30] batch [80/204] time 0.259 (0.268) data 0.000 (0.009) loss 2.5117 (1.1241) lr 7.0337e-03 eta 0:16:57
epoch [12/30] batch [100/204] time 0.262 (0.266) data 0.000 (0.007) loss 0.6929 (1.0716) lr 7.0337e-03 eta 0:16:43
epoch [12/30] batch [120/204] time 0.251 (0.264) data 0.000 (0.006) loss 2.0156 (1.0430) lr 7.0337e-03 eta 0:16:30
epoch [12/30] batch [140/204] time 0.258 (0.263) data 0.000 (0.005) loss 1.2334 (1.1052) lr 7.0337e-03 eta 0:16:20
epoch [12/30] batch [160/204] time 0.260 (0.262) data 0.000 (0.005) loss -0.0346 (1.1513) lr 7.0337e-03 eta 0:16:14
epoch [12/30] batch [180/204] time 0.244 (0.261) data 0.000 (0.004) loss -0.0276 (1.0988) lr 7.0337e-03 eta 0:16:05
epoch [12/30] batch [200/204] time 0.245 (0.260) data 0.000 (0.004) loss 0.3347 (1.1176) lr 7.0337e-03 eta 0:15:55
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:16,  2.53s/it]  2%|▏         | 2/102 [00:03<02:18,  1.38s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:03<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.31it/s]  7%|▋         | 7/102 [00:04<00:35,  2.65it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:05<00:29,  3.16it/s] 10%|▉         | 10/102 [00:05<00:27,  3.35it/s] 11%|█         | 11/102 [00:05<00:25,  3.53it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.67it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.72it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.75it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.74it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.77it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.82it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.83it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.83it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.83it/s] 21%|██        | 21/102 [00:08<00:21,  3.79it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.83it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.87it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.85it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.84it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.88it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.87it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.85it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.86it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.86it/s] 30%|███       | 31/102 [00:10<00:18,  3.89it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.92it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.91it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.88it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.87it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.84it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.86it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.84it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.91it/s] 40%|████      | 41/102 [00:13<00:15,  3.88it/s] 41%|████      | 42/102 [00:13<00:15,  3.86it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.90it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.88it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.92it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.96it/s] 46%|████▌     | 47/102 [00:14<00:12,  4.33it/s] 47%|████▋     | 48/102 [00:15<00:13,  4.13it/s] 48%|████▊     | 49/102 [00:15<00:12,  4.28it/s] 49%|████▉     | 50/102 [00:15<00:12,  4.12it/s] 50%|█████     | 51/102 [00:15<00:12,  4.03it/s] 51%|█████     | 52/102 [00:16<00:12,  3.99it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.98it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.95it/s] 54%|█████▍    | 55/102 [00:16<00:11,  3.93it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.94it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.92it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.90it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.08it/s] 59%|█████▉    | 60/102 [00:18<00:10,  4.04it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.99it/s] 61%|██████    | 62/102 [00:18<00:10,  3.96it/s] 62%|██████▏   | 63/102 [00:18<00:09,  3.93it/s] 63%|██████▎   | 64/102 [00:19<00:09,  4.20it/s] 64%|██████▎   | 65/102 [00:19<00:09,  4.08it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.01it/s] 66%|██████▌   | 67/102 [00:19<00:08,  3.99it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.91it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.88it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.88it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.97it/s] 71%|███████   | 72/102 [00:21<00:07,  4.17it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.20it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.76it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.34it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.83it/s] 75%|███████▌  | 77/102 [00:21<00:04,  6.24it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.57it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.82it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.00it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.13it/s] 80%|████████  | 82/102 [00:22<00:02,  7.23it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.11it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.21it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.28it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.33it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.36it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.38it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.40it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.41it/s]100%|██████████| 102/102 [00:25<00:00,  7.42it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,206
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [13/30] batch [20/204] time 0.264 (0.298) data 0.000 (0.036) loss -0.0316 (1.3179) lr 6.5451e-03 eta 0:18:06
epoch [13/30] batch [40/204] time 0.256 (0.277) data 0.000 (0.018) loss 0.6484 (1.1664) lr 6.5451e-03 eta 0:16:47
epoch [13/30] batch [60/204] time 0.256 (0.270) data 0.000 (0.012) loss 0.4666 (1.0325) lr 6.5451e-03 eta 0:16:14
epoch [13/30] batch [80/204] time 0.265 (0.266) data 0.000 (0.009) loss 0.1393 (0.9780) lr 6.5451e-03 eta 0:15:55
epoch [13/30] batch [100/204] time 0.253 (0.264) data 0.000 (0.007) loss 1.5322 (1.0175) lr 6.5451e-03 eta 0:15:43
epoch [13/30] batch [120/204] time 0.256 (0.262) data 0.001 (0.006) loss 1.5234 (1.0721) lr 6.5451e-03 eta 0:15:32
epoch [13/30] batch [140/204] time 0.259 (0.262) data 0.000 (0.005) loss -0.0146 (1.0856) lr 6.5451e-03 eta 0:15:25
epoch [13/30] batch [160/204] time 0.259 (0.262) data 0.000 (0.005) loss 0.5752 (1.1538) lr 6.5451e-03 eta 0:15:20
epoch [13/30] batch [180/204] time 0.249 (0.261) data 0.000 (0.004) loss 0.2228 (1.1024) lr 6.5451e-03 eta 0:15:11
epoch [13/30] batch [200/204] time 0.246 (0.259) data 0.000 (0.004) loss 2.4023 (1.1111) lr 6.5451e-03 eta 0:15:00
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<03:57,  2.35s/it]  2%|▏         | 2/102 [00:02<02:05,  1.26s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:03<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.31it/s]  7%|▋         | 7/102 [00:04<00:35,  2.65it/s]  8%|▊         | 8/102 [00:04<00:31,  2.96it/s]  9%|▉         | 9/102 [00:04<00:28,  3.23it/s] 10%|▉         | 10/102 [00:05<00:26,  3.43it/s] 11%|█         | 11/102 [00:05<00:25,  3.54it/s] 12%|█▏        | 12/102 [00:05<00:23,  3.76it/s] 13%|█▎        | 13/102 [00:05<00:23,  3.85it/s] 14%|█▎        | 14/102 [00:06<00:22,  3.83it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.83it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.85it/s] 17%|█▋        | 17/102 [00:06<00:20,  4.11it/s] 18%|█▊        | 18/102 [00:07<00:20,  4.08it/s] 19%|█▊        | 19/102 [00:07<00:20,  4.07it/s] 20%|█▉        | 20/102 [00:07<00:19,  4.26it/s] 21%|██        | 21/102 [00:07<00:19,  4.10it/s] 22%|██▏       | 22/102 [00:08<00:19,  4.01it/s] 23%|██▎       | 23/102 [00:08<00:19,  4.01it/s] 24%|██▎       | 24/102 [00:08<00:17,  4.37it/s] 25%|██▍       | 25/102 [00:08<00:16,  4.78it/s] 25%|██▌       | 26/102 [00:08<00:16,  4.54it/s] 26%|██▋       | 27/102 [00:09<00:16,  4.43it/s] 27%|██▋       | 28/102 [00:09<00:16,  4.38it/s] 28%|██▊       | 29/102 [00:09<00:16,  4.37it/s] 29%|██▉       | 30/102 [00:09<00:17,  4.22it/s] 30%|███       | 31/102 [00:10<00:16,  4.29it/s] 31%|███▏      | 32/102 [00:10<00:16,  4.14it/s] 32%|███▏      | 33/102 [00:10<00:16,  4.06it/s] 33%|███▎      | 34/102 [00:10<00:17,  4.00it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.92it/s] 35%|███▌      | 36/102 [00:11<00:16,  4.09it/s] 36%|███▋      | 37/102 [00:11<00:16,  4.05it/s] 37%|███▋      | 38/102 [00:11<00:16,  3.95it/s] 38%|███▊      | 39/102 [00:12<00:15,  3.96it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.91it/s] 40%|████      | 41/102 [00:12<00:15,  3.88it/s] 41%|████      | 42/102 [00:12<00:15,  3.88it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.81it/s] 44%|████▍     | 45/102 [00:13<00:15,  3.76it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.79it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.82it/s] 47%|████▋     | 48/102 [00:14<00:14,  3.79it/s] 48%|████▊     | 49/102 [00:14<00:13,  3.86it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.88it/s] 50%|█████     | 51/102 [00:15<00:13,  3.90it/s] 51%|█████     | 52/102 [00:15<00:12,  3.92it/s] 52%|█████▏    | 53/102 [00:15<00:12,  3.87it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.86it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.91it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.88it/s] 56%|█████▌    | 57/102 [00:16<00:11,  3.82it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.83it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.85it/s] 59%|█████▉    | 60/102 [00:17<00:10,  3.88it/s] 60%|█████▉    | 61/102 [00:17<00:10,  3.82it/s] 61%|██████    | 62/102 [00:18<00:10,  3.82it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.85it/s] 63%|██████▎   | 64/102 [00:18<00:09,  3.83it/s] 64%|██████▎   | 65/102 [00:18<00:09,  3.80it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.81it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.82it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.85it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.82it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.89it/s] 71%|███████   | 72/102 [00:20<00:07,  4.00it/s] 72%|███████▏  | 73/102 [00:20<00:06,  4.49it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.09it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.63it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.07it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.43it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.70it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.91it/s] 78%|███████▊  | 80/102 [00:21<00:03,  7.06it/s] 79%|███████▉  | 81/102 [00:21<00:02,  7.16it/s] 80%|████████  | 82/102 [00:22<00:02,  7.24it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.38it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:22<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:23<00:00,  7.37it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.40it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.42it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.42it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.43it/s]100%|██████████| 102/102 [00:24<00:00,  7.42it/s]100%|██████████| 102/102 [00:24<00:00,  4.09it/s]=> result
* total: 10,200
* correct: 9,197
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%

epoch [14/30] batch [20/204] time 0.256 (0.296) data 0.000 (0.036) loss 0.5190 (0.8464) lr 6.0396e-03 eta 0:17:00
epoch [14/30] batch [40/204] time 0.261 (0.277) data 0.000 (0.018) loss 0.8491 (0.7248) lr 6.0396e-03 eta 0:15:50
epoch [14/30] batch [60/204] time 0.256 (0.272) data 0.000 (0.012) loss 0.0433 (0.8684) lr 6.0396e-03 eta 0:15:26
epoch [14/30] batch [80/204] time 0.265 (0.269) data 0.000 (0.009) loss 0.6416 (0.8047) lr 6.0396e-03 eta 0:15:09
epoch [14/30] batch [100/204] time 0.257 (0.266) data 0.000 (0.007) loss 1.4531 (0.8099) lr 6.0396e-03 eta 0:14:57
epoch [14/30] batch [120/204] time 0.253 (0.265) data 0.000 (0.006) loss -0.0291 (0.7848) lr 6.0396e-03 eta 0:14:46
epoch [14/30] batch [140/204] time 0.254 (0.264) data 0.000 (0.005) loss 1.3125 (0.8997) lr 6.0396e-03 eta 0:14:37
epoch [14/30] batch [160/204] time 0.257 (0.263) data 0.000 (0.005) loss 0.2515 (0.9434) lr 6.0396e-03 eta 0:14:28
epoch [14/30] batch [180/204] time 0.242 (0.261) data 0.000 (0.004) loss 0.1776 (0.9992) lr 6.0396e-03 eta 0:14:18
epoch [14/30] batch [200/204] time 0.243 (0.260) data 0.000 (0.004) loss 1.1289 (1.0156) lr 6.0396e-03 eta 0:14:09
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:28,  2.66s/it]  2%|▏         | 2/102 [00:03<02:23,  1.44s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:04<00:50,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.68it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:05<00:29,  3.19it/s] 10%|▉         | 10/102 [00:05<00:27,  3.34it/s] 11%|█         | 11/102 [00:05<00:26,  3.47it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.57it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.62it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.71it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.73it/s] 16%|█▌        | 16/102 [00:06<00:23,  3.74it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.78it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.80it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.82it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.80it/s] 21%|██        | 21/102 [00:08<00:21,  3.81it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.85it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.87it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.86it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.86it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.85it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.89it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.84it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.88it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.91it/s] 30%|███       | 31/102 [00:10<00:18,  3.88it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.84it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.89it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.88it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.82it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.85it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.85it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.85it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.89it/s] 40%|████      | 41/102 [00:13<00:15,  3.89it/s] 41%|████      | 42/102 [00:13<00:15,  3.89it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.84it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.82it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.85it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.83it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.83it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.84it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.84it/s] 50%|█████     | 51/102 [00:16<00:13,  3.84it/s] 51%|█████     | 52/102 [00:16<00:12,  3.86it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.87it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.83it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.83it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.83it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.81it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.84it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.82it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.91it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.90it/s] 61%|██████    | 62/102 [00:18<00:10,  3.92it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.87it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.85it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.83it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.85it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.82it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.87it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.91it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.88it/s] 71%|███████   | 72/102 [00:21<00:07,  3.93it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.43it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.05it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.59it/s] 75%|███████▍  | 76/102 [00:22<00:04,  6.05it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.41it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.71it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.82it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.99it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.13it/s] 80%|████████  | 82/102 [00:22<00:02,  7.22it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.30it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.34it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.37it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.39it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.41it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.98it/s]=> result
* total: 10,200
* correct: 9,202
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%

epoch [15/30] batch [20/204] time 0.264 (0.297) data 0.000 (0.035) loss 0.9014 (0.4994) lr 5.5226e-03 eta 0:16:02
epoch [15/30] batch [40/204] time 0.257 (0.277) data 0.000 (0.018) loss 0.5107 (0.8195) lr 5.5226e-03 eta 0:14:53
epoch [15/30] batch [60/204] time 0.255 (0.271) data 0.000 (0.012) loss 0.8340 (0.8748) lr 5.5226e-03 eta 0:14:26
epoch [15/30] batch [80/204] time 0.256 (0.268) data 0.000 (0.009) loss 2.4434 (0.9086) lr 5.5226e-03 eta 0:14:13
epoch [15/30] batch [100/204] time 0.252 (0.266) data 0.000 (0.007) loss 1.2324 (0.9479) lr 5.5226e-03 eta 0:14:02
epoch [15/30] batch [120/204] time 0.259 (0.265) data 0.000 (0.006) loss 0.0959 (0.8921) lr 5.5226e-03 eta 0:13:52
epoch [15/30] batch [140/204] time 0.252 (0.263) data 0.000 (0.005) loss 0.7349 (0.8837) lr 5.5226e-03 eta 0:13:42
epoch [15/30] batch [160/204] time 0.263 (0.263) data 0.000 (0.005) loss -0.0328 (0.9184) lr 5.5226e-03 eta 0:13:36
epoch [15/30] batch [180/204] time 0.244 (0.262) data 0.000 (0.004) loss 1.6064 (0.9600) lr 5.5226e-03 eta 0:13:27
epoch [15/30] batch [200/204] time 0.245 (0.260) data 0.000 (0.004) loss 0.4436 (0.9914) lr 5.5226e-03 eta 0:13:16
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:28,  2.66s/it]  2%|▏         | 2/102 [00:03<02:22,  1.43s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.54it/s]  5%|▍         | 5/102 [00:04<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:05<00:29,  3.15it/s] 10%|▉         | 10/102 [00:05<00:27,  3.36it/s] 11%|█         | 11/102 [00:05<00:26,  3.46it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.55it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:24,  3.65it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.73it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.79it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.76it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.76it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.78it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.81it/s] 21%|██        | 21/102 [00:08<00:21,  3.83it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.84it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.81it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.78it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.79it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.86it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.84it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.80it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.80it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.80it/s] 30%|███       | 31/102 [00:10<00:18,  3.80it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.86it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.89it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.86it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.81it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.83it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.81it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.83it/s] 40%|████      | 41/102 [00:13<00:16,  3.81it/s] 41%|████      | 42/102 [00:13<00:15,  3.81it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.81it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.83it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.83it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.81it/s] 46%|████▌     | 47/102 [00:15<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.86it/s] 48%|████▊     | 49/102 [00:15<00:12,  4.16it/s] 49%|████▉     | 50/102 [00:15<00:12,  4.04it/s] 50%|█████     | 51/102 [00:16<00:13,  3.92it/s] 51%|█████     | 52/102 [00:16<00:12,  3.93it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.91it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.92it/s] 54%|█████▍    | 55/102 [00:17<00:11,  3.95it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.92it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.89it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.84it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.84it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.83it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.88it/s] 61%|██████    | 62/102 [00:18<00:10,  3.88it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.83it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.80it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.80it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.82it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.87it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.90it/s] 71%|███████   | 72/102 [00:21<00:07,  3.93it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.58it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.18it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.71it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.15it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.50it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.77it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.96it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.10it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.20it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.44it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.39it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  3.98it/s]=> result
* total: 10,200
* correct: 9,204
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%

epoch [16/30] batch [20/204] time 0.254 (0.297) data 0.000 (0.036) loss 0.9761 (1.3279) lr 5.0000e-03 eta 0:15:01
epoch [16/30] batch [40/204] time 0.255 (0.280) data 0.000 (0.018) loss 1.2617 (1.3816) lr 5.0000e-03 eta 0:14:04
epoch [16/30] batch [60/204] time 0.255 (0.272) data 0.000 (0.012) loss 1.7754 (1.3214) lr 5.0000e-03 eta 0:13:36
epoch [16/30] batch [80/204] time 0.258 (0.268) data 0.000 (0.009) loss 1.0107 (1.2824) lr 5.0000e-03 eta 0:13:18
epoch [16/30] batch [100/204] time 0.256 (0.266) data 0.000 (0.008) loss 1.0225 (1.1996) lr 5.0000e-03 eta 0:13:07
epoch [16/30] batch [120/204] time 0.259 (0.265) data 0.000 (0.006) loss 2.7559 (1.2212) lr 5.0000e-03 eta 0:12:58
epoch [16/30] batch [140/204] time 0.262 (0.263) data 0.000 (0.005) loss 0.3906 (1.1426) lr 5.0000e-03 eta 0:12:48
epoch [16/30] batch [160/204] time 0.249 (0.263) data 0.000 (0.005) loss 0.6108 (1.1156) lr 5.0000e-03 eta 0:12:41
epoch [16/30] batch [180/204] time 0.243 (0.261) data 0.000 (0.004) loss -0.0137 (1.1218) lr 5.0000e-03 eta 0:12:32
epoch [16/30] batch [200/204] time 0.244 (0.260) data 0.000 (0.004) loss 0.8789 (1.1375) lr 5.0000e-03 eta 0:12:23
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:23,  2.61s/it]  2%|▏         | 2/102 [00:03<02:22,  1.43s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:04<00:50,  1.94it/s]  6%|▌         | 6/102 [00:04<00:40,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:31,  2.97it/s]  9%|▉         | 9/102 [00:05<00:29,  3.20it/s] 10%|▉         | 10/102 [00:05<00:27,  3.33it/s] 11%|█         | 11/102 [00:05<00:26,  3.46it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.56it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.63it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.71it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.72it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.81it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.85it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.97it/s] 19%|█▊        | 19/102 [00:07<00:19,  4.17it/s] 20%|█▉        | 20/102 [00:07<00:20,  4.02it/s] 21%|██        | 21/102 [00:08<00:20,  4.01it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.99it/s] 23%|██▎       | 23/102 [00:08<00:19,  4.05it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.99it/s] 25%|██▍       | 25/102 [00:09<00:17,  4.42it/s] 25%|██▌       | 26/102 [00:09<00:17,  4.23it/s] 26%|██▋       | 27/102 [00:09<00:17,  4.32it/s] 27%|██▋       | 28/102 [00:09<00:17,  4.19it/s] 28%|██▊       | 29/102 [00:10<00:17,  4.07it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.99it/s] 30%|███       | 31/102 [00:10<00:18,  3.93it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.90it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.93it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.90it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.85it/s] 35%|███▌      | 36/102 [00:11<00:16,  3.90it/s] 36%|███▋      | 37/102 [00:12<00:15,  4.14it/s] 37%|███▋      | 38/102 [00:12<00:14,  4.31it/s] 38%|███▊      | 39/102 [00:12<00:15,  4.16it/s] 39%|███▉      | 40/102 [00:12<00:15,  4.09it/s] 40%|████      | 41/102 [00:13<00:15,  4.03it/s] 41%|████      | 42/102 [00:13<00:15,  3.97it/s] 42%|████▏     | 43/102 [00:13<00:14,  4.11it/s] 43%|████▎     | 44/102 [00:13<00:14,  4.02it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.98it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.98it/s] 46%|████▌     | 47/102 [00:14<00:12,  4.24it/s] 47%|████▋     | 48/102 [00:14<00:13,  4.11it/s] 48%|████▊     | 49/102 [00:15<00:13,  4.04it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.98it/s] 50%|█████     | 51/102 [00:15<00:12,  3.97it/s] 51%|█████     | 52/102 [00:15<00:12,  3.92it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.94it/s] 54%|█████▍    | 55/102 [00:16<00:11,  4.15it/s] 55%|█████▍    | 56/102 [00:16<00:10,  4.19it/s] 56%|█████▌    | 57/102 [00:16<00:10,  4.15it/s] 57%|█████▋    | 58/102 [00:17<00:10,  4.08it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.03it/s] 59%|█████▉    | 60/102 [00:17<00:09,  4.30it/s] 60%|█████▉    | 61/102 [00:17<00:09,  4.17it/s] 61%|██████    | 62/102 [00:18<00:09,  4.10it/s] 62%|██████▏   | 63/102 [00:18<00:09,  4.07it/s] 63%|██████▎   | 64/102 [00:18<00:09,  4.08it/s] 64%|██████▎   | 65/102 [00:18<00:08,  4.17it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.05it/s] 66%|██████▌   | 67/102 [00:19<00:08,  4.03it/s] 67%|██████▋   | 68/102 [00:19<00:08,  4.06it/s] 68%|██████▊   | 69/102 [00:19<00:07,  4.20it/s] 69%|██████▊   | 70/102 [00:20<00:07,  4.15it/s] 70%|██████▉   | 71/102 [00:20<00:07,  4.07it/s] 71%|███████   | 72/102 [00:20<00:07,  4.10it/s] 72%|███████▏  | 73/102 [00:20<00:06,  4.49it/s] 73%|███████▎  | 74/102 [00:21<00:06,  4.31it/s] 74%|███████▎  | 75/102 [00:21<00:05,  4.94it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.49it/s] 75%|███████▌  | 77/102 [00:21<00:04,  5.97it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.35it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.64it/s] 78%|███████▊  | 80/102 [00:21<00:03,  6.86it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.03it/s] 80%|████████  | 82/102 [00:22<00:02,  7.15it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.23it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.29it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.33it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.37it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.39it/s] 86%|████████▋ | 88/102 [00:22<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.42it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.42it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.42it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.42it/s] 93%|█████████▎| 95/102 [00:23<00:00,  7.42it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.42it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.42it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.42it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.45it/s]100%|██████████| 102/102 [00:24<00:00,  7.44it/s]100%|██████████| 102/102 [00:24<00:00,  4.09it/s]=> result
* total: 10,200
* correct: 9,216
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [17/30] batch [20/204] time 0.256 (0.296) data 0.000 (0.036) loss 0.7319 (0.8234) lr 4.4774e-03 eta 0:13:59
epoch [17/30] batch [40/204] time 0.254 (0.277) data 0.000 (0.018) loss 0.0972 (0.9401) lr 4.4774e-03 eta 0:12:58
epoch [17/30] batch [60/204] time 0.254 (0.271) data 0.000 (0.012) loss 0.1125 (0.9331) lr 4.4774e-03 eta 0:12:36
epoch [17/30] batch [80/204] time 0.250 (0.267) data 0.000 (0.009) loss 2.5195 (0.9802) lr 4.4774e-03 eta 0:12:21
epoch [17/30] batch [100/204] time 0.259 (0.265) data 0.000 (0.007) loss 1.9951 (0.9169) lr 4.4774e-03 eta 0:12:09
epoch [17/30] batch [120/204] time 0.251 (0.264) data 0.000 (0.006) loss 3.3828 (0.8784) lr 4.4774e-03 eta 0:12:03
epoch [17/30] batch [140/204] time 0.272 (0.264) data 0.000 (0.005) loss 0.8052 (0.8977) lr 4.4774e-03 eta 0:11:55
epoch [17/30] batch [160/204] time 0.253 (0.263) data 0.000 (0.005) loss 0.0862 (0.9515) lr 4.4774e-03 eta 0:11:49
epoch [17/30] batch [180/204] time 0.245 (0.262) data 0.000 (0.004) loss 0.9136 (0.9099) lr 4.4774e-03 eta 0:11:40
epoch [17/30] batch [200/204] time 0.250 (0.261) data 0.000 (0.004) loss -0.0513 (0.9383) lr 4.4774e-03 eta 0:11:32
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:07,  2.45s/it]  2%|▏         | 2/102 [00:02<02:06,  1.26s/it]  3%|▎         | 3/102 [00:03<01:27,  1.13it/s]  4%|▍         | 4/102 [00:03<01:03,  1.55it/s]  5%|▍         | 5/102 [00:03<00:48,  1.98it/s]  6%|▌         | 6/102 [00:04<00:40,  2.35it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:04<00:28,  3.22it/s] 10%|▉         | 10/102 [00:05<00:26,  3.52it/s] 11%|█         | 11/102 [00:05<00:25,  3.63it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.68it/s] 13%|█▎        | 13/102 [00:05<00:23,  3.82it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.82it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.80it/s] 16%|█▌        | 16/102 [00:06<00:21,  3.97it/s] 17%|█▋        | 17/102 [00:06<00:21,  3.91it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.88it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.88it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.85it/s] 21%|██        | 21/102 [00:07<00:21,  3.81it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.80it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.81it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.82it/s] 25%|██▍       | 25/102 [00:08<00:19,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.85it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.87it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.84it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.83it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.86it/s] 30%|███       | 31/102 [00:10<00:18,  3.90it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.89it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.92it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.86it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.89it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.84it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.84it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.82it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.82it/s] 40%|████      | 41/102 [00:13<00:16,  3.81it/s] 41%|████      | 42/102 [00:13<00:15,  3.87it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.85it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.85it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.84it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.82it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.79it/s] 47%|████▋     | 48/102 [00:14<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.80it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.82it/s] 50%|█████     | 51/102 [00:15<00:13,  3.75it/s] 51%|█████     | 52/102 [00:16<00:13,  3.76it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.78it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.80it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.82it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.82it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.80it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.83it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.88it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.86it/s] 61%|██████    | 62/102 [00:18<00:10,  3.84it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.82it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.83it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.85it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.87it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.85it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.88it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.90it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.88it/s] 71%|███████   | 72/102 [00:21<00:07,  3.95it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.52it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.13it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.66it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.07it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.43it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.71it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.91it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.25it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.42it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.02it/s]=> result
* total: 10,200
* correct: 9,226
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 90.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/204] time 0.254 (0.297) data 0.000 (0.034) loss 0.3452 (0.5827) lr 3.9604e-03 eta 0:13:00
epoch [18/30] batch [40/204] time 0.253 (0.277) data 0.000 (0.017) loss 2.3750 (0.6834) lr 3.9604e-03 eta 0:12:04
epoch [18/30] batch [60/204] time 0.254 (0.271) data 0.000 (0.012) loss 0.7383 (0.7206) lr 3.9604e-03 eta 0:11:41
epoch [18/30] batch [80/204] time 0.258 (0.267) data 0.000 (0.009) loss 0.2834 (0.8480) lr 3.9604e-03 eta 0:11:26
epoch [18/30] batch [100/204] time 0.254 (0.266) data 0.000 (0.007) loss 1.2168 (0.9171) lr 3.9604e-03 eta 0:11:18
epoch [18/30] batch [120/204] time 0.257 (0.264) data 0.000 (0.006) loss 0.1070 (0.9495) lr 3.9604e-03 eta 0:11:08
epoch [18/30] batch [140/204] time 0.254 (0.262) data 0.000 (0.005) loss 0.4590 (0.9158) lr 3.9604e-03 eta 0:10:59
epoch [18/30] batch [160/204] time 0.256 (0.262) data 0.000 (0.005) loss 1.5850 (0.8605) lr 3.9604e-03 eta 0:10:53
epoch [18/30] batch [180/204] time 0.247 (0.261) data 0.000 (0.004) loss 0.4739 (0.8971) lr 3.9604e-03 eta 0:10:45
epoch [18/30] batch [200/204] time 0.245 (0.259) data 0.000 (0.004) loss 1.2402 (0.8717) lr 3.9604e-03 eta 0:10:35
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:12,  2.50s/it]  2%|▏         | 2/102 [00:03<02:17,  1.38s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.54it/s]  5%|▍         | 5/102 [00:03<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:04<00:28,  3.22it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:26,  3.50it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.58it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.71it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.74it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.78it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.80it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.81it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.86it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.82it/s] 21%|██        | 21/102 [00:08<00:20,  3.86it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.86it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.87it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.85it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.86it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.83it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.83it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.86it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.82it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.80it/s] 30%|███       | 31/102 [00:10<00:18,  3.79it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.76it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.79it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.82it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.87it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.82it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.82it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.82it/s] 40%|████      | 41/102 [00:13<00:15,  3.83it/s] 41%|████      | 42/102 [00:13<00:15,  3.82it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.88it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.90it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.83it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.82it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.83it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.81it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.87it/s] 50%|█████     | 51/102 [00:15<00:13,  3.88it/s] 51%|█████     | 52/102 [00:16<00:12,  4.03it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.90it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.92it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.91it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.91it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.92it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.99it/s] 58%|█████▊    | 59/102 [00:17<00:10,  3.91it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.88it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.88it/s] 61%|██████    | 62/102 [00:18<00:10,  3.90it/s] 62%|██████▏   | 63/102 [00:18<00:09,  3.92it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.89it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.90it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.92it/s] 66%|██████▌   | 67/102 [00:20<00:08,  3.93it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.89it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.91it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.87it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.90it/s] 71%|███████   | 72/102 [00:21<00:07,  3.99it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.55it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.15it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.68it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.12it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.47it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.93it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.20it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.46it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.47it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.47it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.46it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,227
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 90.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/204] time 0.255 (0.297) data 0.000 (0.037) loss 1.1748 (1.2322) lr 3.4549e-03 eta 0:12:02
epoch [19/30] batch [40/204] time 0.253 (0.278) data 0.000 (0.019) loss 0.0301 (1.1469) lr 3.4549e-03 eta 0:11:09
epoch [19/30] batch [60/204] time 0.265 (0.273) data 0.000 (0.013) loss 2.9297 (1.1433) lr 3.4549e-03 eta 0:10:52
epoch [19/30] batch [80/204] time 0.255 (0.270) data 0.000 (0.010) loss 0.0201 (1.1810) lr 3.4549e-03 eta 0:10:38
epoch [19/30] batch [100/204] time 0.256 (0.267) data 0.000 (0.008) loss 0.2561 (1.1333) lr 3.4549e-03 eta 0:10:27
epoch [19/30] batch [120/204] time 0.320 (0.266) data 0.000 (0.006) loss 1.2949 (1.1392) lr 3.4549e-03 eta 0:10:19
epoch [19/30] batch [140/204] time 0.260 (0.265) data 0.000 (0.006) loss -0.0123 (1.1043) lr 3.4549e-03 eta 0:10:10
epoch [19/30] batch [160/204] time 0.260 (0.264) data 0.000 (0.005) loss 0.0055 (1.0296) lr 3.4549e-03 eta 0:10:03
epoch [19/30] batch [180/204] time 0.245 (0.262) data 0.000 (0.004) loss 0.0801 (1.0240) lr 3.4549e-03 eta 0:09:54
epoch [19/30] batch [200/204] time 0.245 (0.261) data 0.000 (0.004) loss 3.5684 (1.0047) lr 3.4549e-03 eta 0:09:45
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:48,  2.85s/it]  2%|▏         | 2/102 [00:03<02:20,  1.41s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:02,  1.56it/s]  5%|▍         | 5/102 [00:04<00:49,  1.98it/s]  6%|▌         | 6/102 [00:04<00:40,  2.36it/s]  7%|▋         | 7/102 [00:04<00:34,  2.73it/s]  8%|▊         | 8/102 [00:04<00:31,  3.00it/s]  9%|▉         | 9/102 [00:05<00:28,  3.21it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:26,  3.47it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.59it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.67it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.70it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.73it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.76it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.79it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.82it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.83it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.84it/s] 21%|██        | 21/102 [00:08<00:21,  3.82it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.88it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.88it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.88it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.83it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.85it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.85it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.82it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.82it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.85it/s] 30%|███       | 31/102 [00:10<00:18,  3.88it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.80it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.84it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.83it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.87it/s] 35%|███▌      | 36/102 [00:12<00:16,  3.90it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.88it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.85it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.83it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.84it/s] 40%|████      | 41/102 [00:13<00:15,  3.82it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.88it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.89it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.89it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.92it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.89it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.83it/s] 50%|█████     | 51/102 [00:16<00:13,  3.83it/s] 51%|█████     | 52/102 [00:16<00:13,  3.82it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.82it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.82it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.83it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.81it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.81it/s] 57%|█████▋    | 58/102 [00:17<00:10,  4.30it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.18it/s] 59%|█████▉    | 60/102 [00:18<00:10,  4.08it/s] 60%|█████▉    | 61/102 [00:18<00:10,  4.03it/s] 61%|██████    | 62/102 [00:18<00:10,  3.99it/s] 62%|██████▏   | 63/102 [00:19<00:09,  3.93it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.89it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.90it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.88it/s] 66%|██████▌   | 67/102 [00:20<00:08,  3.92it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.91it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.93it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.90it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.90it/s] 71%|███████   | 72/102 [00:21<00:07,  3.94it/s] 72%|███████▏  | 73/102 [00:21<00:07,  4.13it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.77it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.35it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.84it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.26it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.58it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.82it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.00it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.13it/s] 80%|████████  | 82/102 [00:22<00:02,  7.22it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.39it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.42it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,213
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [20/30] batch [20/204] time 0.257 (0.297) data 0.000 (0.036) loss 0.3005 (0.6536) lr 2.9663e-03 eta 0:11:01
epoch [20/30] batch [40/204] time 0.263 (0.277) data 0.000 (0.018) loss 0.1769 (0.6796) lr 2.9663e-03 eta 0:10:11
epoch [20/30] batch [60/204] time 0.261 (0.272) data 0.000 (0.012) loss 3.2031 (0.8747) lr 2.9663e-03 eta 0:09:53
epoch [20/30] batch [80/204] time 0.255 (0.268) data 0.000 (0.009) loss 5.5234 (0.9984) lr 2.9663e-03 eta 0:09:40
epoch [20/30] batch [100/204] time 0.260 (0.266) data 0.000 (0.007) loss 0.3088 (1.0160) lr 2.9663e-03 eta 0:09:30
epoch [20/30] batch [120/204] time 0.253 (0.264) data 0.000 (0.006) loss 1.2090 (0.9905) lr 2.9663e-03 eta 0:09:21
epoch [20/30] batch [140/204] time 0.264 (0.263) data 0.000 (0.005) loss 2.0547 (1.0527) lr 2.9663e-03 eta 0:09:14
epoch [20/30] batch [160/204] time 0.262 (0.263) data 0.000 (0.005) loss 0.0099 (1.0011) lr 2.9663e-03 eta 0:09:07
epoch [20/30] batch [180/204] time 0.246 (0.261) data 0.000 (0.004) loss 0.1031 (0.9655) lr 2.9663e-03 eta 0:08:59
epoch [20/30] batch [200/204] time 0.247 (0.260) data 0.000 (0.004) loss 2.4180 (1.0166) lr 2.9663e-03 eta 0:08:51
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:24,  2.62s/it]  2%|▏         | 2/102 [00:03<02:21,  1.42s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:04<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.68it/s]  8%|▊         | 8/102 [00:04<00:29,  3.14it/s]  9%|▉         | 9/102 [00:05<00:27,  3.33it/s] 10%|▉         | 10/102 [00:05<00:26,  3.48it/s] 11%|█         | 11/102 [00:05<00:25,  3.58it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.65it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.76it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.74it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.80it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.78it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.78it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.83it/s] 20%|█▉        | 20/102 [00:07<00:20,  3.91it/s] 21%|██        | 21/102 [00:08<00:21,  3.84it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.89it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.89it/s] 25%|██▍       | 25/102 [00:09<00:19,  4.05it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.98it/s] 26%|██▋       | 27/102 [00:09<00:18,  3.96it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.95it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.96it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.93it/s] 30%|███       | 31/102 [00:10<00:17,  3.95it/s] 31%|███▏      | 32/102 [00:10<00:17,  4.00it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.98it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.94it/s] 34%|███▍      | 35/102 [00:11<00:16,  4.17it/s] 35%|███▌      | 36/102 [00:11<00:16,  4.12it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.98it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.92it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.91it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.86it/s] 40%|████      | 41/102 [00:13<00:15,  3.92it/s] 41%|████      | 42/102 [00:13<00:15,  3.96it/s] 42%|████▏     | 43/102 [00:13<00:14,  4.02it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.97it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.92it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.91it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.90it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.91it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.98it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.93it/s] 50%|█████     | 51/102 [00:15<00:13,  3.90it/s] 51%|█████     | 52/102 [00:15<00:12,  3.87it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.86it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.84it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.86it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.89it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.90it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.87it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.81it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.84it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.81it/s] 61%|██████    | 62/102 [00:18<00:10,  3.86it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.89it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.89it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.86it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.80it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.82it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.86it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.86it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.87it/s] 71%|███████   | 72/102 [00:21<00:07,  3.93it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.49it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.10it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.64it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.08it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.44it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.71it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.91it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.40it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.43it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.46it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.46it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.46it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.48it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.47it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,214
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/204] time 0.254 (0.294) data 0.000 (0.036) loss 4.9766 (1.1467) lr 2.5000e-03 eta 0:09:54
epoch [21/30] batch [40/204] time 0.259 (0.277) data 0.000 (0.018) loss 0.1990 (0.9435) lr 2.5000e-03 eta 0:09:13
epoch [21/30] batch [60/204] time 0.263 (0.270) data 0.000 (0.012) loss -0.0042 (0.9532) lr 2.5000e-03 eta 0:08:55
epoch [21/30] batch [80/204] time 0.256 (0.267) data 0.000 (0.009) loss 0.3840 (1.0923) lr 2.5000e-03 eta 0:08:43
epoch [21/30] batch [100/204] time 0.257 (0.266) data 0.000 (0.007) loss 0.1873 (1.0959) lr 2.5000e-03 eta 0:08:35
epoch [21/30] batch [120/204] time 0.255 (0.264) data 0.000 (0.006) loss 0.1114 (1.0136) lr 2.5000e-03 eta 0:08:26
epoch [21/30] batch [140/204] time 0.257 (0.264) data 0.000 (0.005) loss 0.0419 (0.9809) lr 2.5000e-03 eta 0:08:20
epoch [21/30] batch [160/204] time 0.258 (0.263) data 0.000 (0.005) loss -0.0019 (0.9745) lr 2.5000e-03 eta 0:08:13
epoch [21/30] batch [180/204] time 0.246 (0.261) data 0.000 (0.004) loss -0.0385 (0.9517) lr 2.5000e-03 eta 0:08:06
epoch [21/30] batch [200/204] time 0.246 (0.260) data 0.000 (0.004) loss 0.0674 (0.9699) lr 2.5000e-03 eta 0:07:58
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:23,  2.60s/it]  2%|▏         | 2/102 [00:03<02:23,  1.44s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:04<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.68it/s]  8%|▊         | 8/102 [00:04<00:31,  2.96it/s]  9%|▉         | 9/102 [00:05<00:29,  3.21it/s] 10%|▉         | 10/102 [00:05<00:27,  3.39it/s] 11%|█         | 11/102 [00:05<00:25,  3.51it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.60it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.74it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.76it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.82it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.85it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.89it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.85it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.82it/s] 21%|██        | 21/102 [00:08<00:21,  3.82it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.85it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.91it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.88it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.83it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.80it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.80it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.81it/s] 30%|███       | 31/102 [00:10<00:18,  3.78it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.75it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.79it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.78it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.81it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.84it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.85it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.83it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.85it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.84it/s] 40%|████      | 41/102 [00:13<00:15,  3.83it/s] 41%|████      | 42/102 [00:13<00:15,  3.82it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.82it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.88it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.87it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.85it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.88it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.88it/s] 50%|█████     | 51/102 [00:15<00:13,  3.87it/s] 51%|█████     | 52/102 [00:16<00:12,  3.86it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.85it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.84it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.85it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.90it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.87it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.88it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.86it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.87it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.88it/s] 61%|██████    | 62/102 [00:18<00:10,  3.85it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.88it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.86it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.90it/s] 66%|██████▌   | 67/102 [00:20<00:08,  3.92it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.94it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.90it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.89it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.95it/s] 71%|███████   | 72/102 [00:21<00:07,  3.96it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.55it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.15it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.68it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.12it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.46it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.94it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,215
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [22/30] batch [20/204] time 0.251 (0.297) data 0.000 (0.036) loss 0.9775 (1.1394) lr 2.0611e-03 eta 0:08:59
epoch [22/30] batch [40/204] time 0.259 (0.279) data 0.000 (0.018) loss 1.5137 (0.9213) lr 2.0611e-03 eta 0:08:20
epoch [22/30] batch [60/204] time 0.262 (0.272) data 0.000 (0.012) loss -0.0021 (0.8761) lr 2.0611e-03 eta 0:08:02
epoch [22/30] batch [80/204] time 0.258 (0.268) data 0.000 (0.009) loss 4.0469 (0.9533) lr 2.0611e-03 eta 0:07:50
epoch [22/30] batch [100/204] time 0.259 (0.266) data 0.000 (0.007) loss -0.0490 (0.9222) lr 2.0611e-03 eta 0:07:41
epoch [22/30] batch [120/204] time 0.250 (0.264) data 0.000 (0.006) loss 0.6812 (0.9629) lr 2.0611e-03 eta 0:07:33
epoch [22/30] batch [140/204] time 0.254 (0.264) data 0.000 (0.005) loss 2.5566 (1.0274) lr 2.0611e-03 eta 0:07:27
epoch [22/30] batch [160/204] time 0.256 (0.263) data 0.000 (0.005) loss 1.7539 (0.9977) lr 2.0611e-03 eta 0:07:20
epoch [22/30] batch [180/204] time 0.243 (0.262) data 0.000 (0.004) loss 0.3655 (0.9702) lr 2.0611e-03 eta 0:07:13
epoch [22/30] batch [200/204] time 0.244 (0.260) data 0.000 (0.004) loss 0.6846 (1.0059) lr 2.0611e-03 eta 0:07:05
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:17,  2.55s/it]  2%|▏         | 2/102 [00:03<02:20,  1.41s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:04<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.68it/s]  8%|▊         | 8/102 [00:04<00:31,  2.96it/s]  9%|▉         | 9/102 [00:05<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.34it/s] 11%|█         | 11/102 [00:05<00:26,  3.48it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.60it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.69it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.76it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.80it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.81it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.85it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.85it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.81it/s] 21%|██        | 21/102 [00:08<00:21,  3.84it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.92it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.89it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.93it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.90it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.91it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.94it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.91it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.90it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.87it/s] 30%|███       | 31/102 [00:10<00:18,  3.88it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.91it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.89it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.89it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.88it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.85it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.82it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.84it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.84it/s] 40%|████      | 41/102 [00:13<00:15,  3.86it/s] 41%|████      | 42/102 [00:13<00:15,  3.84it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.82it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.81it/s] 44%|████▍     | 45/102 [00:14<00:15,  3.79it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.82it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.87it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.90it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.90it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.89it/s] 50%|█████     | 51/102 [00:15<00:13,  3.90it/s] 51%|█████     | 52/102 [00:16<00:12,  3.87it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.87it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.85it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.82it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.83it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.83it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.85it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.88it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.90it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.88it/s] 61%|██████    | 62/102 [00:18<00:10,  3.92it/s] 62%|██████▏   | 63/102 [00:19<00:09,  3.92it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.89it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.89it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.83it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.83it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.87it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.94it/s] 71%|███████   | 72/102 [00:21<00:07,  4.02it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.46it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.08it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.61it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.07it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.43it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.70it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.91it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.06it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.25it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.39it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.41it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.42it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,213
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [23/30] batch [20/204] time 0.257 (0.295) data 0.000 (0.036) loss 1.4375 (0.9415) lr 1.6543e-03 eta 0:07:54
epoch [23/30] batch [40/204] time 0.256 (0.276) data 0.000 (0.018) loss 3.3184 (1.1053) lr 1.6543e-03 eta 0:07:19
epoch [23/30] batch [60/204] time 0.254 (0.270) data 0.000 (0.012) loss 0.1196 (1.0374) lr 1.6543e-03 eta 0:07:04
epoch [23/30] batch [80/204] time 0.261 (0.267) data 0.000 (0.009) loss 0.3809 (1.1153) lr 1.6543e-03 eta 0:06:54
epoch [23/30] batch [100/204] time 0.246 (0.265) data 0.000 (0.007) loss 0.2258 (1.0750) lr 1.6543e-03 eta 0:06:45
epoch [23/30] batch [120/204] time 0.247 (0.264) data 0.000 (0.006) loss -0.0385 (0.9582) lr 1.6543e-03 eta 0:06:39
epoch [23/30] batch [140/204] time 0.255 (0.263) data 0.000 (0.005) loss 3.8262 (1.0257) lr 1.6543e-03 eta 0:06:32
epoch [23/30] batch [160/204] time 0.263 (0.262) data 0.000 (0.005) loss 0.2063 (0.9750) lr 1.6543e-03 eta 0:06:26
epoch [23/30] batch [180/204] time 0.244 (0.261) data 0.000 (0.004) loss 0.3459 (0.9792) lr 1.6543e-03 eta 0:06:19
epoch [23/30] batch [200/204] time 0.244 (0.260) data 0.000 (0.004) loss -0.0478 (1.0079) lr 1.6543e-03 eta 0:06:12
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:18,  2.56s/it]  2%|▏         | 2/102 [00:03<02:20,  1.41s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.53it/s]  5%|▍         | 5/102 [00:03<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:40,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:05<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.34it/s] 11%|█         | 11/102 [00:05<00:26,  3.49it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.60it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.71it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.77it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.81it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.86it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.87it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.85it/s] 21%|██        | 21/102 [00:08<00:20,  3.86it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.83it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.81it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.88it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.83it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.84it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.85it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.82it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.85it/s] 29%|██▉       | 30/102 [00:10<00:16,  4.34it/s] 30%|███       | 31/102 [00:10<00:17,  4.14it/s] 31%|███▏      | 32/102 [00:10<00:17,  4.04it/s] 32%|███▏      | 33/102 [00:11<00:17,  4.02it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.91it/s] 34%|███▍      | 35/102 [00:11<00:16,  3.95it/s] 35%|███▌      | 36/102 [00:11<00:16,  4.06it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.93it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.93it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.90it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.90it/s] 40%|████      | 41/102 [00:13<00:15,  3.84it/s] 41%|████      | 42/102 [00:13<00:15,  3.81it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.82it/s] 43%|████▎     | 44/102 [00:13<00:14,  4.03it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.98it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.94it/s] 46%|████▌     | 47/102 [00:14<00:13,  3.95it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.88it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:12,  4.04it/s] 50%|█████     | 51/102 [00:15<00:12,  3.99it/s] 51%|█████     | 52/102 [00:16<00:12,  3.99it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.92it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.92it/s] 54%|█████▍    | 55/102 [00:16<00:11,  3.93it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.89it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.87it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.88it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.89it/s] 59%|█████▉    | 60/102 [00:18<00:10,  4.08it/s] 60%|█████▉    | 61/102 [00:18<00:10,  4.03it/s] 61%|██████    | 62/102 [00:18<00:10,  4.00it/s] 62%|██████▏   | 63/102 [00:18<00:09,  3.91it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.90it/s] 64%|██████▎   | 65/102 [00:19<00:09,  4.05it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.93it/s] 66%|██████▌   | 67/102 [00:19<00:08,  3.92it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.90it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.91it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.86it/s] 71%|███████   | 72/102 [00:21<00:07,  3.89it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.17it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.81it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.38it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.87it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.26it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.58it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.82it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.99it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.12it/s] 80%|████████  | 82/102 [00:22<00:02,  7.22it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.38it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.02it/s]=> result
* total: 10,200
* correct: 9,219
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 90.4%

epoch [24/30] batch [20/204] time 0.249 (0.294) data 0.000 (0.035) loss 0.6421 (1.1427) lr 1.2843e-03 eta 0:06:54
epoch [24/30] batch [40/204] time 0.257 (0.276) data 0.000 (0.017) loss 0.1179 (1.1615) lr 1.2843e-03 eta 0:06:22
epoch [24/30] batch [60/204] time 0.257 (0.270) data 0.000 (0.012) loss 0.1606 (1.1070) lr 1.2843e-03 eta 0:06:08
epoch [24/30] batch [80/204] time 0.250 (0.266) data 0.000 (0.009) loss 3.2656 (1.1399) lr 1.2843e-03 eta 0:05:58
epoch [24/30] batch [100/204] time 0.256 (0.265) data 0.000 (0.007) loss 2.4160 (1.0943) lr 1.2843e-03 eta 0:05:52
epoch [24/30] batch [120/204] time 0.256 (0.264) data 0.000 (0.006) loss 0.2917 (1.1065) lr 1.2843e-03 eta 0:05:45
epoch [24/30] batch [140/204] time 0.258 (0.263) data 0.000 (0.005) loss 2.4023 (1.0843) lr 1.2843e-03 eta 0:05:39
epoch [24/30] batch [160/204] time 0.313 (0.263) data 0.000 (0.005) loss 0.6235 (1.0478) lr 1.2843e-03 eta 0:05:33
epoch [24/30] batch [180/204] time 0.244 (0.262) data 0.000 (0.004) loss 0.4998 (1.0392) lr 1.2843e-03 eta 0:05:26
epoch [24/30] batch [200/204] time 0.246 (0.260) data 0.000 (0.004) loss 2.0254 (1.0125) lr 1.2843e-03 eta 0:05:19
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:23,  2.61s/it]  2%|▏         | 2/102 [00:03<02:21,  1.42s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.54it/s]  5%|▍         | 5/102 [00:04<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.71it/s]  8%|▊         | 8/102 [00:04<00:31,  3.02it/s]  9%|▉         | 9/102 [00:05<00:28,  3.21it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:26,  3.48it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.61it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.68it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.75it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.75it/s] 16%|█▌        | 16/102 [00:06<00:20,  4.10it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.98it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.99it/s] 19%|█▊        | 19/102 [00:07<00:20,  4.14it/s] 20%|█▉        | 20/102 [00:07<00:20,  4.04it/s] 21%|██        | 21/102 [00:08<00:20,  4.01it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.93it/s] 23%|██▎       | 23/102 [00:08<00:19,  3.97it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.94it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.91it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.90it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.90it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.92it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.89it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.83it/s] 30%|███       | 31/102 [00:10<00:18,  3.81it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.74it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.77it/s] 33%|███▎      | 34/102 [00:11<00:18,  3.77it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.79it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.87it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.84it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.81it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.83it/s] 40%|████      | 41/102 [00:13<00:15,  3.83it/s] 41%|████      | 42/102 [00:13<00:15,  3.83it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.82it/s] 44%|████▍     | 45/102 [00:14<00:15,  3.80it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.82it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.84it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.79it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.82it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.78it/s] 50%|█████     | 51/102 [00:15<00:13,  3.85it/s] 51%|█████     | 52/102 [00:16<00:12,  3.85it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.87it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.87it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.85it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.83it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.79it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.77it/s] 59%|█████▉    | 60/102 [00:18<00:11,  3.80it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.84it/s] 61%|██████    | 62/102 [00:18<00:10,  3.83it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.85it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.84it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.83it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.87it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.83it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.87it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.87it/s] 71%|███████   | 72/102 [00:21<00:07,  3.97it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.54it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.14it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.67it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.11it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.46it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.93it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.43it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.45it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.40it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.40it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.41it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,220
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 90.4%

epoch [25/30] batch [20/204] time 0.251 (0.298) data 0.000 (0.036) loss 0.3181 (0.8108) lr 9.5492e-04 eta 0:05:58
epoch [25/30] batch [40/204] time 0.258 (0.277) data 0.000 (0.018) loss 0.2407 (0.7897) lr 9.5492e-04 eta 0:05:28
epoch [25/30] batch [60/204] time 0.260 (0.273) data 0.000 (0.012) loss 0.4714 (0.7989) lr 9.5492e-04 eta 0:05:17
epoch [25/30] batch [80/204] time 0.264 (0.269) data 0.000 (0.009) loss 0.0585 (0.8834) lr 9.5492e-04 eta 0:05:08
epoch [25/30] batch [100/204] time 0.253 (0.267) data 0.000 (0.007) loss 4.5000 (0.9396) lr 9.5492e-04 eta 0:05:00
epoch [25/30] batch [120/204] time 0.255 (0.265) data 0.000 (0.006) loss 1.0459 (0.9262) lr 9.5492e-04 eta 0:04:52
epoch [25/30] batch [140/204] time 0.248 (0.264) data 0.000 (0.005) loss 0.2598 (0.9132) lr 9.5492e-04 eta 0:04:45
epoch [25/30] batch [160/204] time 0.265 (0.263) data 0.000 (0.005) loss 1.1982 (0.9105) lr 9.5492e-04 eta 0:04:39
epoch [25/30] batch [180/204] time 0.245 (0.262) data 0.000 (0.004) loss 0.0365 (0.9497) lr 9.5492e-04 eta 0:04:33
epoch [25/30] batch [200/204] time 0.246 (0.260) data 0.000 (0.004) loss 0.4663 (0.9637) lr 9.5492e-04 eta 0:04:26
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:24,  2.61s/it]  2%|▏         | 2/102 [00:03<02:22,  1.43s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:04<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:31,  2.97it/s]  9%|▉         | 9/102 [00:05<00:29,  3.18it/s] 10%|▉         | 10/102 [00:05<00:27,  3.38it/s] 11%|█         | 11/102 [00:05<00:25,  3.52it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.60it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.69it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.77it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.80it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.81it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.80it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.78it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.81it/s] 21%|██        | 21/102 [00:08<00:21,  3.77it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.78it/s] 23%|██▎       | 23/102 [00:08<00:21,  3.74it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.77it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.77it/s] 25%|██▌       | 26/102 [00:09<00:20,  3.78it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.80it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.81it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.84it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.81it/s] 30%|███       | 31/102 [00:10<00:18,  3.78it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.80it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.84it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.83it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.83it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.84it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.81it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.81it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.84it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.80it/s] 40%|████      | 41/102 [00:13<00:15,  3.86it/s] 41%|████      | 42/102 [00:13<00:15,  3.84it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.91it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.89it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.89it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.85it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.85it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.82it/s] 50%|█████     | 51/102 [00:16<00:13,  3.86it/s] 51%|█████     | 52/102 [00:16<00:13,  3.84it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.87it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.84it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.83it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.82it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.81it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.84it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.81it/s] 59%|█████▉    | 60/102 [00:18<00:11,  3.80it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.80it/s] 61%|██████    | 62/102 [00:18<00:10,  3.86it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.84it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.83it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.85it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.84it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.88it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.88it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.87it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.91it/s] 71%|███████   | 72/102 [00:21<00:07,  4.00it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.48it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.08it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.62it/s] 75%|███████▍  | 76/102 [00:22<00:04,  6.07it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.42it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.68it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.89it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.04it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.15it/s] 80%|████████  | 82/102 [00:22<00:02,  7.22it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.17it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.21it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.28it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.33it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.37it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.39it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:25<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  3.97it/s]=> result
* total: 10,200
* correct: 9,222
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 90.4%

epoch [26/30] batch [20/204] time 0.259 (0.301) data 0.000 (0.036) loss 1.6523 (1.0027) lr 6.6987e-04 eta 0:05:00
epoch [26/30] batch [40/204] time 0.265 (0.278) data 0.000 (0.018) loss 0.0818 (0.9463) lr 6.6987e-04 eta 0:04:32
epoch [26/30] batch [60/204] time 0.253 (0.271) data 0.000 (0.012) loss 0.9990 (0.9557) lr 6.6987e-04 eta 0:04:19
epoch [26/30] batch [80/204] time 0.252 (0.267) data 0.000 (0.009) loss 3.7266 (0.9291) lr 6.6987e-04 eta 0:04:11
epoch [26/30] batch [100/204] time 0.257 (0.265) data 0.000 (0.007) loss 3.6211 (0.9826) lr 6.6987e-04 eta 0:04:03
epoch [26/30] batch [120/204] time 0.263 (0.264) data 0.000 (0.006) loss 1.7754 (0.9984) lr 6.6987e-04 eta 0:03:57
epoch [26/30] batch [140/204] time 0.259 (0.264) data 0.000 (0.005) loss 1.5010 (1.0484) lr 6.6987e-04 eta 0:03:52
epoch [26/30] batch [160/204] time 0.252 (0.263) data 0.000 (0.005) loss 0.0646 (1.1045) lr 6.6987e-04 eta 0:03:45
epoch [26/30] batch [180/204] time 0.246 (0.261) data 0.000 (0.004) loss 0.4832 (1.0674) lr 6.6987e-04 eta 0:03:39
epoch [26/30] batch [200/204] time 0.245 (0.260) data 0.000 (0.004) loss 1.4531 (1.0440) lr 6.6987e-04 eta 0:03:33
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:13,  2.51s/it]  2%|▏         | 2/102 [00:03<02:17,  1.38s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:03<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:05<00:28,  3.21it/s] 10%|▉         | 10/102 [00:05<00:27,  3.40it/s] 11%|█         | 11/102 [00:05<00:25,  3.56it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.69it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.71it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.75it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.72it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.75it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.77it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.80it/s] 19%|█▊        | 19/102 [00:07<00:22,  3.77it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.82it/s] 21%|██        | 21/102 [00:08<00:21,  3.84it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.83it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.89it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.87it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.85it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.84it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.83it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.81it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.82it/s] 30%|███       | 31/102 [00:10<00:18,  3.81it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.85it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.82it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.80it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.80it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.81it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.80it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.83it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.86it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.85it/s] 40%|████      | 41/102 [00:13<00:15,  3.89it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.86it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.83it/s] 44%|████▍     | 45/102 [00:14<00:15,  3.78it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.76it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.79it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.86it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.87it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.86it/s] 50%|█████     | 51/102 [00:15<00:13,  3.81it/s] 51%|█████     | 52/102 [00:16<00:13,  3.84it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.84it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.80it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.81it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.80it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.77it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.83it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.82it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.83it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.83it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.82it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.81it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.82it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.84it/s] 66%|██████▌   | 67/102 [00:20<00:08,  4.16it/s] 67%|██████▋   | 68/102 [00:20<00:08,  4.06it/s] 68%|██████▊   | 69/102 [00:20<00:07,  4.13it/s] 69%|██████▊   | 70/102 [00:20<00:07,  4.05it/s] 70%|██████▉   | 71/102 [00:21<00:07,  4.13it/s] 71%|███████   | 72/102 [00:21<00:07,  4.09it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.50it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.12it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.65it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.11it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.47it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.96it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.11it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.23it/s] 80%|████████  | 82/102 [00:22<00:02,  7.31it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.35it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.40it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.43it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.44it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.46it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.47it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.47it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.49it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.48it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.47it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.47it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.48it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.48it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.47it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.48it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.48it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.47it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.48it/s]100%|██████████| 102/102 [00:25<00:00,  7.48it/s]100%|██████████| 102/102 [00:25<00:00,  4.01it/s]=> result
* total: 10,200
* correct: 9,213
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [27/30] batch [20/204] time 0.258 (0.300) data 0.000 (0.036) loss 0.2452 (0.8800) lr 4.3227e-04 eta 0:03:58
epoch [27/30] batch [40/204] time 0.249 (0.277) data 0.000 (0.018) loss 0.3835 (0.9891) lr 4.3227e-04 eta 0:03:35
epoch [27/30] batch [60/204] time 0.253 (0.270) data 0.000 (0.012) loss 1.4746 (1.0424) lr 4.3227e-04 eta 0:03:23
epoch [27/30] batch [80/204] time 0.255 (0.266) data 0.000 (0.009) loss 0.3323 (0.9891) lr 4.3227e-04 eta 0:03:15
epoch [27/30] batch [100/204] time 0.256 (0.264) data 0.000 (0.007) loss 2.9297 (1.1125) lr 4.3227e-04 eta 0:03:09
epoch [27/30] batch [120/204] time 0.249 (0.263) data 0.000 (0.006) loss 0.5103 (1.0618) lr 4.3227e-04 eta 0:03:02
epoch [27/30] batch [140/204] time 0.255 (0.262) data 0.000 (0.005) loss 2.6172 (1.0669) lr 4.3227e-04 eta 0:02:56
epoch [27/30] batch [160/204] time 0.258 (0.261) data 0.000 (0.005) loss 0.4617 (1.0314) lr 4.3227e-04 eta 0:02:51
epoch [27/30] batch [180/204] time 0.243 (0.260) data 0.000 (0.004) loss 2.4043 (1.0492) lr 4.3227e-04 eta 0:02:45
epoch [27/30] batch [200/204] time 0.246 (0.258) data 0.000 (0.004) loss 0.2227 (0.9986) lr 4.3227e-04 eta 0:02:38
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:01,  2.39s/it]  2%|▏         | 2/102 [00:02<02:09,  1.30s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:05,  1.51it/s]  5%|▍         | 5/102 [00:03<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.30it/s]  7%|▋         | 7/102 [00:04<00:35,  2.65it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:04<00:28,  3.23it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:25,  3.50it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.66it/s] 13%|█▎        | 13/102 [00:05<00:24,  3.68it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.78it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.81it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.84it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.86it/s] 19%|█▊        | 19/102 [00:07<00:20,  4.12it/s] 20%|█▉        | 20/102 [00:07<00:20,  4.08it/s] 21%|██        | 21/102 [00:07<00:20,  4.02it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.97it/s] 23%|██▎       | 23/102 [00:08<00:19,  4.05it/s] 24%|██▎       | 24/102 [00:08<00:19,  4.04it/s] 25%|██▍       | 25/102 [00:08<00:19,  4.03it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.99it/s] 26%|██▋       | 27/102 [00:09<00:18,  4.08it/s] 27%|██▋       | 28/102 [00:09<00:18,  4.03it/s] 28%|██▊       | 29/102 [00:09<00:18,  4.02it/s] 29%|██▉       | 30/102 [00:10<00:17,  4.12it/s] 30%|███       | 31/102 [00:10<00:17,  3.99it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.97it/s] 32%|███▏      | 33/102 [00:10<00:17,  3.93it/s] 33%|███▎      | 34/102 [00:11<00:16,  4.21it/s] 34%|███▍      | 35/102 [00:11<00:16,  4.16it/s] 35%|███▌      | 36/102 [00:11<00:16,  4.10it/s] 36%|███▋      | 37/102 [00:11<00:16,  4.00it/s] 37%|███▋      | 38/102 [00:12<00:15,  4.02it/s] 38%|███▊      | 39/102 [00:12<00:15,  3.97it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.90it/s] 40%|████      | 41/102 [00:12<00:14,  4.08it/s] 41%|████      | 42/102 [00:13<00:15,  4.00it/s] 42%|████▏     | 43/102 [00:13<00:14,  3.99it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.96it/s] 44%|████▍     | 45/102 [00:13<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.93it/s] 46%|████▌     | 47/102 [00:14<00:13,  3.99it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.95it/s] 48%|████▊     | 49/102 [00:14<00:13,  3.89it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.89it/s] 50%|█████     | 51/102 [00:15<00:13,  3.92it/s] 51%|█████     | 52/102 [00:15<00:13,  3.84it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.81it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.81it/s] 54%|█████▍    | 55/102 [00:16<00:11,  3.98it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.94it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.90it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.88it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.08it/s] 59%|█████▉    | 60/102 [00:17<00:10,  4.03it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.99it/s] 61%|██████    | 62/102 [00:18<00:10,  3.94it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:18<00:09,  3.88it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.84it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.84it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.81it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.80it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.85it/s] 71%|███████   | 72/102 [00:20<00:07,  3.92it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.58it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.18it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.72it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.14it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.49it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.76it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.95it/s] 78%|███████▊  | 80/102 [00:21<00:03,  7.11it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.22it/s] 80%|████████  | 82/102 [00:22<00:02,  7.28it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.35it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.38it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.40it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.44it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.45it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.46it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.46it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.46it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.47it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.48it/s] 93%|█████████▎| 95/102 [00:23<00:00,  7.47it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.48it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.47it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.46it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.47it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.47it/s]100%|██████████| 102/102 [00:24<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  4.07it/s]=> result
* total: 10,200
* correct: 9,209
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [28/30] batch [20/204] time 0.254 (0.300) data 0.000 (0.036) loss -0.0201 (0.7388) lr 2.4472e-04 eta 0:02:57
epoch [28/30] batch [40/204] time 0.258 (0.280) data 0.000 (0.018) loss 0.0415 (0.7190) lr 2.4472e-04 eta 0:02:39
epoch [28/30] batch [60/204] time 0.261 (0.272) data 0.000 (0.012) loss 0.0936 (0.7812) lr 2.4472e-04 eta 0:02:30
epoch [28/30] batch [80/204] time 0.259 (0.268) data 0.000 (0.009) loss -0.0379 (0.8485) lr 2.4472e-04 eta 0:02:22
epoch [28/30] batch [100/204] time 0.255 (0.266) data 0.000 (0.007) loss -0.0049 (0.8641) lr 2.4472e-04 eta 0:02:16
epoch [28/30] batch [120/204] time 0.257 (0.265) data 0.000 (0.006) loss 0.2388 (0.8132) lr 2.4472e-04 eta 0:02:10
epoch [28/30] batch [140/204] time 0.254 (0.264) data 0.000 (0.005) loss 2.6602 (0.9170) lr 2.4472e-04 eta 0:02:04
epoch [28/30] batch [160/204] time 0.254 (0.263) data 0.000 (0.005) loss 3.1211 (0.8881) lr 2.4472e-04 eta 0:01:58
epoch [28/30] batch [180/204] time 0.243 (0.261) data 0.000 (0.004) loss 0.1138 (0.8950) lr 2.4472e-04 eta 0:01:52
epoch [28/30] batch [200/204] time 0.243 (0.259) data 0.000 (0.004) loss 1.6309 (0.8873) lr 2.4472e-04 eta 0:01:46
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:03,  2.41s/it]  2%|▏         | 2/102 [00:03<02:16,  1.36s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:03<00:50,  1.92it/s]  6%|▌         | 6/102 [00:04<00:41,  2.31it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:31,  2.97it/s]  9%|▉         | 9/102 [00:04<00:28,  3.21it/s] 10%|▉         | 10/102 [00:05<00:27,  3.34it/s] 11%|█         | 11/102 [00:05<00:25,  3.52it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.61it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.72it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.78it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.80it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.80it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.78it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.79it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.80it/s] 21%|██        | 21/102 [00:08<00:20,  3.88it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.85it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.93it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.93it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.95it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.97it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.91it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.85it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.81it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.82it/s] 30%|███       | 31/102 [00:10<00:18,  3.80it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.85it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.86it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.80it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.83it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.79it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.80it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.81it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.80it/s] 40%|████      | 41/102 [00:13<00:16,  3.80it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.87it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.85it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.82it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.85it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:14,  3.77it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.81it/s] 50%|█████     | 51/102 [00:15<00:13,  3.82it/s] 51%|█████     | 52/102 [00:16<00:13,  3.84it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.85it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.85it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.82it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.86it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.89it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.89it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.82it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.84it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.87it/s] 61%|██████    | 62/102 [00:18<00:10,  3.85it/s] 62%|██████▏   | 63/102 [00:19<00:09,  3.92it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.90it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.93it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.94it/s] 66%|██████▌   | 67/102 [00:20<00:08,  3.92it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.90it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.88it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.87it/s] 71%|███████   | 72/102 [00:21<00:07,  3.94it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.46it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.08it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.62it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.08it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.44it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.72it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.94it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.20it/s] 80%|████████  | 82/102 [00:22<00:02,  7.28it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.40it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.46it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.48it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.47it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.48it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.49it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.47it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.46it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.41it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,209
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [29/30] batch [20/204] time 0.253 (0.302) data 0.000 (0.035) loss 0.2440 (0.7325) lr 1.0926e-04 eta 0:01:57
epoch [29/30] batch [40/204] time 0.257 (0.279) data 0.000 (0.017) loss -0.0382 (0.7860) lr 1.0926e-04 eta 0:01:42
epoch [29/30] batch [60/204] time 0.265 (0.273) data 0.000 (0.012) loss 4.6055 (0.9513) lr 1.0926e-04 eta 0:01:34
epoch [29/30] batch [80/204] time 0.258 (0.270) data 0.000 (0.009) loss 2.0176 (0.8973) lr 1.0926e-04 eta 0:01:28
epoch [29/30] batch [100/204] time 0.254 (0.267) data 0.000 (0.007) loss 0.0226 (0.9351) lr 1.0926e-04 eta 0:01:22
epoch [29/30] batch [120/204] time 0.257 (0.266) data 0.000 (0.006) loss -0.0391 (0.9017) lr 1.0926e-04 eta 0:01:16
epoch [29/30] batch [140/204] time 0.259 (0.264) data 0.000 (0.005) loss 0.3276 (0.9244) lr 1.0926e-04 eta 0:01:10
epoch [29/30] batch [160/204] time 0.260 (0.263) data 0.000 (0.005) loss 0.4775 (0.8911) lr 1.0926e-04 eta 0:01:05
epoch [29/30] batch [180/204] time 0.246 (0.262) data 0.000 (0.004) loss 0.1185 (0.8755) lr 1.0926e-04 eta 0:00:59
epoch [29/30] batch [200/204] time 0.244 (0.260) data 0.000 (0.004) loss 0.4006 (0.8913) lr 1.0926e-04 eta 0:00:54
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:24,  2.62s/it]  2%|▏         | 2/102 [00:03<02:25,  1.45s/it]  3%|▎         | 3/102 [00:03<01:31,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:04<00:50,  1.92it/s]  6%|▌         | 6/102 [00:04<00:41,  2.31it/s]  7%|▋         | 7/102 [00:04<00:35,  2.65it/s]  8%|▊         | 8/102 [00:04<00:31,  2.94it/s]  9%|▉         | 9/102 [00:05<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.35it/s] 11%|█         | 11/102 [00:05<00:26,  3.47it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.57it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.69it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.70it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.74it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.82it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.80it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.80it/s] 20%|█▉        | 20/102 [00:08<00:21,  3.81it/s] 21%|██        | 21/102 [00:08<00:21,  3.81it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.87it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.91it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.87it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.87it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.90it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.85it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.85it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.85it/s] 30%|███       | 31/102 [00:10<00:17,  3.96it/s] 31%|███▏      | 32/102 [00:11<00:17,  3.90it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.89it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.86it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.87it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.86it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.84it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.84it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.82it/s] 40%|████      | 41/102 [00:13<00:16,  3.80it/s] 41%|████      | 42/102 [00:13<00:15,  3.80it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.82it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.79it/s] 44%|████▍     | 45/102 [00:14<00:15,  3.79it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.82it/s] 46%|████▌     | 47/102 [00:15<00:14,  3.80it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.80it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.80it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.82it/s] 50%|█████     | 51/102 [00:16<00:13,  3.82it/s] 51%|█████     | 52/102 [00:16<00:13,  3.79it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.77it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.78it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.78it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.81it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.80it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.83it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.83it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.84it/s] 61%|██████    | 62/102 [00:18<00:10,  3.85it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.88it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.84it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.90it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.88it/s] 66%|██████▌   | 67/102 [00:20<00:08,  3.90it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.90it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.86it/s] 69%|██████▊   | 70/102 [00:21<00:08,  3.84it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.87it/s] 71%|███████   | 72/102 [00:21<00:07,  3.93it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.57it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.18it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.64it/s] 75%|███████▍  | 76/102 [00:22<00:04,  6.10it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.46it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.73it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.95it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.29it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.34it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.37it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.41it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.32it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.35it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.39it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.41it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.47it/s] 96%|█████████▌| 98/102 [00:25<00:00,  7.47it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  3.97it/s]=> result
* total: 10,200
* correct: 9,209
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [30/30] batch [20/204] time 0.263 (0.300) data 0.000 (0.034) loss 1.1289 (1.5131) lr 2.7391e-05 eta 0:00:55
epoch [30/30] batch [40/204] time 0.260 (0.278) data 0.000 (0.017) loss 2.2168 (1.3236) lr 2.7391e-05 eta 0:00:45
epoch [30/30] batch [60/204] time 0.249 (0.272) data 0.000 (0.012) loss 0.1260 (1.0964) lr 2.7391e-05 eta 0:00:39
epoch [30/30] batch [80/204] time 0.256 (0.268) data 0.000 (0.009) loss 3.0684 (1.2047) lr 2.7391e-05 eta 0:00:33
epoch [30/30] batch [100/204] time 0.258 (0.266) data 0.000 (0.007) loss 0.5923 (1.1351) lr 2.7391e-05 eta 0:00:27
epoch [30/30] batch [120/204] time 0.265 (0.265) data 0.000 (0.006) loss 0.1920 (1.0504) lr 2.7391e-05 eta 0:00:22
epoch [30/30] batch [140/204] time 0.257 (0.263) data 0.000 (0.005) loss -0.0416 (1.0168) lr 2.7391e-05 eta 0:00:16
epoch [30/30] batch [160/204] time 0.252 (0.263) data 0.000 (0.005) loss 1.3838 (0.9906) lr 2.7391e-05 eta 0:00:11
epoch [30/30] batch [180/204] time 0.246 (0.262) data 0.000 (0.004) loss 1.7656 (1.0083) lr 2.7391e-05 eta 0:00:06
epoch [30/30] batch [200/204] time 0.244 (0.260) data 0.000 (0.004) loss 3.3574 (1.0130) lr 2.7391e-05 eta 0:00:01
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:17,  2.55s/it]  2%|▏         | 2/102 [00:03<02:14,  1.34s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:03<00:50,  1.92it/s]  6%|▌         | 6/102 [00:04<00:41,  2.31it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.94it/s]  9%|▉         | 9/102 [00:05<00:29,  3.18it/s] 10%|▉         | 10/102 [00:05<00:27,  3.33it/s] 11%|█         | 11/102 [00:05<00:25,  3.50it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.62it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.72it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.76it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.78it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.80it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.82it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.89it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.87it/s] 21%|██        | 21/102 [00:08<00:20,  3.86it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.91it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.94it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.90it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.84it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.83it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.80it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.82it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.86it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.85it/s] 30%|███       | 31/102 [00:10<00:18,  3.90it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.83it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.79it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.80it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.80it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.78it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.84it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.83it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.87it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.88it/s] 40%|████      | 41/102 [00:13<00:15,  4.01it/s] 41%|████      | 42/102 [00:13<00:14,  4.01it/s] 42%|████▏     | 43/102 [00:13<00:14,  3.97it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.93it/s] 44%|████▍     | 45/102 [00:14<00:13,  4.12it/s] 45%|████▌     | 46/102 [00:14<00:12,  4.36it/s] 46%|████▌     | 47/102 [00:14<00:13,  4.20it/s] 47%|████▋     | 48/102 [00:15<00:13,  4.08it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.99it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.97it/s] 50%|█████     | 51/102 [00:15<00:12,  3.95it/s] 51%|█████     | 52/102 [00:16<00:12,  3.87it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.86it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.86it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.87it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.91it/s] 56%|█████▌    | 57/102 [00:17<00:10,  4.10it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.96it/s] 58%|█████▊    | 59/102 [00:17<00:10,  3.92it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.87it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.87it/s] 61%|██████    | 62/102 [00:18<00:10,  3.90it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.88it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.91it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.95it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.30it/s] 66%|██████▌   | 67/102 [00:19<00:08,  4.12it/s] 67%|██████▋   | 68/102 [00:20<00:08,  4.06it/s] 68%|██████▊   | 69/102 [00:20<00:08,  4.01it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.92it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.90it/s] 71%|███████   | 72/102 [00:21<00:07,  4.20it/s] 72%|███████▏  | 73/102 [00:21<00:07,  4.12it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.69it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.28it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.80it/s] 75%|███████▌  | 77/102 [00:21<00:04,  6.13it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.48it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.75it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.95it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.10it/s] 80%|████████  | 82/102 [00:22<00:02,  7.21it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.28it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.43it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]
=> result
* total: 10,200
* correct: 9,209
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 19)
Evaluate on the *test* set
  0%|          | 0/153 [00:00<?, ?it/s]  1%|          | 1/153 [00:02<06:40,  2.64s/it]  1%|▏         | 2/153 [00:03<03:32,  1.41s/it]  2%|▏         | 3/153 [00:03<02:17,  1.09it/s]  3%|▎         | 4/153 [00:03<01:38,  1.51it/s]  3%|▎         | 5/153 [00:04<01:16,  1.93it/s]  4%|▍         | 6/153 [00:04<01:03,  2.31it/s]  5%|▍         | 7/153 [00:04<00:55,  2.65it/s]  5%|▌         | 8/153 [00:04<00:49,  2.93it/s]  6%|▌         | 9/153 [00:05<00:45,  3.17it/s]  7%|▋         | 10/153 [00:05<00:41,  3.41it/s]  7%|▋         | 11/153 [00:05<00:40,  3.51it/s]  8%|▊         | 12/153 [00:05<00:38,  3.66it/s]  8%|▊         | 13/153 [00:06<00:36,  3.87it/s]  9%|▉         | 14/153 [00:06<00:36,  3.85it/s] 10%|▉         | 15/153 [00:06<00:35,  3.87it/s] 10%|█         | 16/153 [00:06<00:35,  3.84it/s] 11%|█         | 17/153 [00:07<00:35,  3.88it/s] 12%|█▏        | 18/153 [00:07<00:35,  3.84it/s] 12%|█▏        | 19/153 [00:07<00:34,  3.86it/s] 13%|█▎        | 20/153 [00:07<00:34,  3.83it/s] 14%|█▎        | 21/153 [00:08<00:34,  3.83it/s] 14%|█▍        | 22/153 [00:08<00:34,  3.85it/s] 15%|█▌        | 23/153 [00:08<00:33,  3.84it/s] 16%|█▌        | 24/153 [00:08<00:33,  3.88it/s] 16%|█▋        | 25/153 [00:09<00:32,  3.92it/s] 17%|█▋        | 26/153 [00:09<00:32,  3.91it/s] 18%|█▊        | 27/153 [00:09<00:31,  4.04it/s] 18%|█▊        | 28/153 [00:09<00:31,  3.99it/s] 19%|█▉        | 29/153 [00:10<00:31,  3.94it/s] 20%|█▉        | 30/153 [00:10<00:31,  3.90it/s] 20%|██        | 31/153 [00:10<00:31,  3.92it/s] 21%|██        | 32/153 [00:10<00:30,  3.97it/s] 22%|██▏       | 33/153 [00:11<00:30,  3.95it/s] 22%|██▏       | 34/153 [00:11<00:29,  4.00it/s] 23%|██▎       | 35/153 [00:11<00:29,  3.97it/s] 24%|██▎       | 36/153 [00:11<00:29,  3.93it/s] 24%|██▍       | 37/153 [00:12<00:28,  4.07it/s] 25%|██▍       | 38/153 [00:12<00:28,  3.98it/s] 25%|██▌       | 39/153 [00:12<00:28,  3.99it/s] 26%|██▌       | 40/153 [00:12<00:28,  3.90it/s] 27%|██▋       | 41/153 [00:13<00:29,  3.86it/s] 27%|██▋       | 42/153 [00:13<00:28,  3.84it/s] 28%|██▊       | 43/153 [00:13<00:28,  3.85it/s] 29%|██▉       | 44/153 [00:14<00:28,  3.88it/s] 29%|██▉       | 45/153 [00:14<00:27,  3.86it/s] 30%|███       | 46/153 [00:14<00:27,  3.85it/s] 31%|███       | 47/153 [00:14<00:27,  3.90it/s] 31%|███▏      | 48/153 [00:15<00:26,  3.90it/s] 32%|███▏      | 49/153 [00:15<00:26,  3.86it/s] 33%|███▎      | 50/153 [00:15<00:26,  3.83it/s] 33%|███▎      | 51/153 [00:15<00:26,  3.87it/s] 34%|███▍      | 52/153 [00:16<00:26,  3.85it/s] 35%|███▍      | 53/153 [00:16<00:26,  3.84it/s] 35%|███▌      | 54/153 [00:16<00:25,  3.86it/s] 36%|███▌      | 55/153 [00:16<00:25,  3.85it/s] 37%|███▋      | 56/153 [00:17<00:25,  3.84it/s] 37%|███▋      | 57/153 [00:17<00:24,  3.88it/s] 38%|███▊      | 58/153 [00:17<00:24,  3.86it/s] 39%|███▊      | 59/153 [00:17<00:24,  3.84it/s] 39%|███▉      | 60/153 [00:18<00:24,  3.87it/s] 40%|███▉      | 61/153 [00:18<00:23,  3.88it/s] 41%|████      | 62/153 [00:18<00:23,  3.87it/s] 41%|████      | 63/153 [00:18<00:21,  4.11it/s] 42%|████▏     | 64/153 [00:19<00:22,  4.00it/s] 42%|████▏     | 65/153 [00:19<00:22,  3.98it/s] 43%|████▎     | 66/153 [00:19<00:22,  3.95it/s] 44%|████▍     | 67/153 [00:19<00:21,  3.96it/s] 44%|████▍     | 68/153 [00:20<00:21,  3.98it/s] 45%|████▌     | 69/153 [00:20<00:20,  4.08it/s] 46%|████▌     | 70/153 [00:20<00:20,  3.98it/s] 46%|████▋     | 71/153 [00:20<00:20,  3.94it/s] 47%|████▋     | 72/153 [00:21<00:20,  3.91it/s] 48%|████▊     | 73/153 [00:21<00:20,  3.85it/s] 48%|████▊     | 74/153 [00:21<00:20,  3.83it/s] 49%|████▉     | 75/153 [00:21<00:20,  3.87it/s] 50%|████▉     | 76/153 [00:22<00:19,  3.89it/s] 50%|█████     | 77/153 [00:22<00:18,  4.03it/s] 51%|█████     | 78/153 [00:22<00:19,  3.93it/s] 52%|█████▏    | 79/153 [00:22<00:18,  3.90it/s] 52%|█████▏    | 80/153 [00:23<00:18,  3.87it/s] 53%|█████▎    | 81/153 [00:23<00:16,  4.31it/s] 54%|█████▎    | 82/153 [00:23<00:16,  4.39it/s] 54%|█████▍    | 83/153 [00:23<00:16,  4.35it/s] 55%|█████▍    | 84/153 [00:24<00:15,  4.34it/s] 56%|█████▌    | 85/153 [00:24<00:16,  4.17it/s] 56%|█████▌    | 86/153 [00:24<00:16,  4.04it/s] 57%|█████▋    | 87/153 [00:24<00:16,  4.03it/s] 58%|█████▊    | 88/153 [00:25<00:16,  3.99it/s] 58%|█████▊    | 89/153 [00:25<00:16,  3.95it/s] 59%|█████▉    | 90/153 [00:25<00:15,  4.00it/s] 59%|█████▉    | 91/153 [00:25<00:15,  4.00it/s] 60%|██████    | 92/153 [00:26<00:15,  3.99it/s] 61%|██████    | 93/153 [00:26<00:14,  4.09it/s] 61%|██████▏   | 94/153 [00:26<00:14,  4.10it/s] 62%|██████▏   | 95/153 [00:26<00:14,  4.08it/s] 63%|██████▎   | 96/153 [00:27<00:14,  3.97it/s] 63%|██████▎   | 97/153 [00:27<00:13,  4.00it/s] 64%|██████▍   | 98/153 [00:27<00:13,  3.98it/s] 65%|██████▍   | 99/153 [00:27<00:13,  3.96it/s] 65%|██████▌   | 100/153 [00:28<00:13,  3.91it/s] 66%|██████▌   | 101/153 [00:28<00:13,  3.87it/s] 67%|██████▋   | 102/153 [00:28<00:13,  3.86it/s] 67%|██████▋   | 103/153 [00:28<00:12,  3.91it/s] 68%|██████▊   | 104/153 [00:29<00:12,  3.88it/s] 69%|██████▊   | 105/153 [00:29<00:12,  3.90it/s] 69%|██████▉   | 106/153 [00:29<00:12,  3.88it/s] 70%|██████▉   | 107/153 [00:29<00:11,  4.02it/s] 71%|███████   | 108/153 [00:30<00:11,  3.95it/s] 71%|███████   | 109/153 [00:30<00:11,  3.95it/s] 72%|███████▏  | 110/153 [00:30<00:10,  3.97it/s] 73%|███████▎  | 111/153 [00:30<00:10,  3.92it/s] 73%|███████▎  | 112/153 [00:31<00:10,  3.94it/s] 74%|███████▍  | 113/153 [00:31<00:10,  3.91it/s] 75%|███████▍  | 114/153 [00:31<00:10,  3.90it/s] 75%|███████▌  | 115/153 [00:31<00:09,  3.90it/s] 76%|███████▌  | 116/153 [00:32<00:09,  3.92it/s] 76%|███████▋  | 117/153 [00:32<00:09,  3.87it/s] 77%|███████▋  | 118/153 [00:32<00:09,  3.85it/s] 78%|███████▊  | 119/153 [00:33<00:08,  3.85it/s] 78%|███████▊  | 120/153 [00:33<00:08,  3.87it/s] 79%|███████▉  | 121/153 [00:33<00:08,  3.89it/s] 80%|███████▉  | 122/153 [00:33<00:08,  3.85it/s] 80%|████████  | 123/153 [00:34<00:07,  3.87it/s] 81%|████████  | 124/153 [00:34<00:07,  3.93it/s] 82%|████████▏ | 125/153 [00:34<00:06,  4.58it/s] 82%|████████▏ | 126/153 [00:34<00:05,  5.17it/s] 83%|████████▎ | 127/153 [00:34<00:04,  5.70it/s] 84%|████████▎ | 128/153 [00:34<00:04,  6.14it/s] 84%|████████▍ | 129/153 [00:34<00:03,  6.48it/s] 85%|████████▍ | 130/153 [00:35<00:03,  6.75it/s] 86%|████████▌ | 131/153 [00:35<00:03,  6.94it/s] 86%|████████▋ | 132/153 [00:35<00:02,  7.07it/s] 87%|████████▋ | 133/153 [00:35<00:02,  7.19it/s] 88%|████████▊ | 134/153 [00:35<00:02,  7.26it/s] 88%|████████▊ | 135/153 [00:35<00:02,  7.32it/s] 89%|████████▉ | 136/153 [00:35<00:02,  7.35it/s] 90%|████████▉ | 137/153 [00:36<00:02,  7.38it/s] 90%|█████████ | 138/153 [00:36<00:02,  7.41it/s] 91%|█████████ | 139/153 [00:36<00:01,  7.41it/s] 92%|█████████▏| 140/153 [00:36<00:01,  7.40it/s] 92%|█████████▏| 141/153 [00:36<00:01,  7.42it/s] 93%|█████████▎| 142/153 [00:36<00:01,  7.42it/s] 93%|█████████▎| 143/153 [00:36<00:01,  7.45it/s] 94%|█████████▍| 144/153 [00:36<00:01,  7.45it/s] 95%|█████████▍| 145/153 [00:37<00:01,  7.44it/s] 95%|█████████▌| 146/153 [00:37<00:00,  7.45it/s] 96%|█████████▌| 147/153 [00:37<00:00,  7.44it/s] 97%|█████████▋| 148/153 [00:37<00:00,  7.43it/s] 97%|█████████▋| 149/153 [00:37<00:00,  7.44it/s] 98%|█████████▊| 150/153 [00:37<00:00,  7.46it/s] 99%|█████████▊| 151/153 [00:37<00:00,  7.45it/s] 99%|█████████▉| 152/153 [00:38<00:00,  7.45it/s]100%|██████████| 153/153 [00:38<00:00,  7.44it/s]100%|██████████| 153/153 [00:38<00:00,  3.99it/s]
=> result
* total: 15,300
* correct: 13,882
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 90.7%
Elapsed: 0:39:56
+ sh scripts/rpo_prime/base2new_test_sdl.sh food101 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
800 10000 15000
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  50
# train_x  800
# val      10,000
# test     15,000
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 19)
Evaluate on the *test* set
  0%|          | 0/150 [00:00<?, ?it/s]  1%|          | 1/150 [00:05<13:59,  5.63s/it]  1%|▏         | 2/150 [00:05<05:56,  2.41s/it]  2%|▏         | 3/150 [00:06<03:29,  1.43s/it]  3%|▎         | 4/150 [00:06<02:20,  1.04it/s]  3%|▎         | 5/150 [00:06<01:42,  1.42it/s]  4%|▍         | 6/150 [00:06<01:18,  1.84it/s]  5%|▍         | 7/150 [00:07<01:03,  2.26it/s]  5%|▌         | 8/150 [00:07<00:54,  2.60it/s]  6%|▌         | 9/150 [00:07<00:49,  2.87it/s]  7%|▋         | 10/150 [00:07<00:44,  3.12it/s]  7%|▋         | 11/150 [00:08<00:40,  3.40it/s]  8%|▊         | 12/150 [00:08<00:39,  3.52it/s]  9%|▊         | 13/150 [00:08<00:37,  3.65it/s]  9%|▉         | 14/150 [00:08<00:36,  3.69it/s] 10%|█         | 15/150 [00:09<00:36,  3.72it/s] 11%|█         | 16/150 [00:09<00:35,  3.81it/s] 11%|█▏        | 17/150 [00:09<00:34,  3.84it/s] 12%|█▏        | 18/150 [00:09<00:32,  4.11it/s] 13%|█▎        | 19/150 [00:10<00:32,  4.02it/s] 13%|█▎        | 20/150 [00:10<00:32,  3.96it/s] 14%|█▍        | 21/150 [00:10<00:32,  3.93it/s] 15%|█▍        | 22/150 [00:10<00:32,  3.90it/s] 15%|█▌        | 23/150 [00:11<00:32,  3.88it/s] 16%|█▌        | 24/150 [00:11<00:31,  4.03it/s] 17%|█▋        | 25/150 [00:11<00:30,  4.13it/s] 17%|█▋        | 26/150 [00:11<00:30,  4.04it/s] 18%|█▊        | 27/150 [00:12<00:31,  3.95it/s] 19%|█▊        | 28/150 [00:12<00:31,  3.91it/s] 19%|█▉        | 29/150 [00:12<00:31,  3.85it/s] 20%|██        | 30/150 [00:12<00:31,  3.85it/s] 21%|██        | 31/150 [00:13<00:31,  3.83it/s] 21%|██▏       | 32/150 [00:13<00:30,  3.82it/s] 22%|██▏       | 33/150 [00:13<00:29,  4.00it/s] 23%|██▎       | 34/150 [00:13<00:28,  4.10it/s] 23%|██▎       | 35/150 [00:14<00:28,  4.02it/s] 24%|██▍       | 36/150 [00:14<00:28,  3.95it/s] 25%|██▍       | 37/150 [00:14<00:28,  3.90it/s] 25%|██▌       | 38/150 [00:14<00:29,  3.85it/s] 26%|██▌       | 39/150 [00:15<00:26,  4.16it/s] 27%|██▋       | 40/150 [00:15<00:25,  4.38it/s] 27%|██▋       | 41/150 [00:15<00:26,  4.15it/s] 28%|██▊       | 42/150 [00:15<00:26,  4.11it/s] 29%|██▊       | 43/150 [00:16<00:25,  4.26it/s] 29%|██▉       | 44/150 [00:16<00:25,  4.10it/s] 30%|███       | 45/150 [00:16<00:26,  4.01it/s] 31%|███       | 46/150 [00:16<00:25,  4.06it/s] 31%|███▏      | 47/150 [00:17<00:25,  4.01it/s] 32%|███▏      | 48/150 [00:17<00:25,  3.96it/s] 33%|███▎      | 49/150 [00:17<00:26,  3.88it/s] 33%|███▎      | 50/150 [00:17<00:26,  3.81it/s] 34%|███▍      | 51/150 [00:18<00:25,  3.84it/s] 35%|███▍      | 52/150 [00:18<00:25,  3.83it/s] 35%|███▌      | 53/150 [00:18<00:25,  3.79it/s] 36%|███▌      | 54/150 [00:18<00:25,  3.83it/s] 37%|███▋      | 55/150 [00:19<00:23,  4.03it/s] 37%|███▋      | 56/150 [00:19<00:21,  4.42it/s] 38%|███▊      | 57/150 [00:19<00:21,  4.23it/s] 39%|███▊      | 58/150 [00:19<00:21,  4.28it/s] 39%|███▉      | 59/150 [00:20<00:22,  4.11it/s] 40%|████      | 60/150 [00:20<00:22,  4.01it/s] 41%|████      | 61/150 [00:20<00:21,  4.05it/s] 41%|████▏     | 62/150 [00:20<00:22,  3.99it/s] 42%|████▏     | 63/150 [00:21<00:22,  3.93it/s] 43%|████▎     | 64/150 [00:21<00:21,  3.94it/s] 43%|████▎     | 65/150 [00:21<00:21,  3.94it/s] 44%|████▍     | 66/150 [00:21<00:21,  3.90it/s] 45%|████▍     | 67/150 [00:22<00:21,  3.86it/s] 45%|████▌     | 68/150 [00:22<00:20,  4.08it/s] 46%|████▌     | 69/150 [00:22<00:18,  4.30it/s] 47%|████▋     | 70/150 [00:22<00:19,  4.14it/s] 47%|████▋     | 71/150 [00:23<00:19,  4.04it/s] 48%|████▊     | 72/150 [00:23<00:19,  3.94it/s] 49%|████▊     | 73/150 [00:23<00:19,  3.92it/s] 49%|████▉     | 74/150 [00:23<00:19,  3.87it/s] 50%|█████     | 75/150 [00:24<00:19,  3.84it/s] 51%|█████     | 76/150 [00:24<00:19,  3.87it/s] 51%|█████▏    | 77/150 [00:24<00:18,  3.88it/s] 52%|█████▏    | 78/150 [00:24<00:18,  3.99it/s] 53%|█████▎    | 79/150 [00:25<00:16,  4.21it/s] 53%|█████▎    | 80/150 [00:25<00:17,  4.09it/s] 54%|█████▍    | 81/150 [00:25<00:16,  4.07it/s] 55%|█████▍    | 82/150 [00:25<00:16,  4.03it/s] 55%|█████▌    | 83/150 [00:26<00:16,  3.97it/s] 56%|█████▌    | 84/150 [00:26<00:16,  3.96it/s] 57%|█████▋    | 85/150 [00:26<00:16,  3.90it/s] 57%|█████▋    | 86/150 [00:26<00:16,  3.90it/s] 58%|█████▊    | 87/150 [00:27<00:14,  4.23it/s] 59%|█████▊    | 88/150 [00:27<00:15,  4.11it/s] 59%|█████▉    | 89/150 [00:27<00:15,  3.96it/s] 60%|██████    | 90/150 [00:27<00:15,  3.96it/s] 61%|██████    | 91/150 [00:28<00:14,  3.97it/s] 61%|██████▏   | 92/150 [00:28<00:14,  3.91it/s] 62%|██████▏   | 93/150 [00:28<00:14,  3.87it/s] 63%|██████▎   | 94/150 [00:28<00:13,  4.19it/s] 63%|██████▎   | 95/150 [00:29<00:13,  4.11it/s] 64%|██████▍   | 96/150 [00:29<00:13,  4.03it/s] 65%|██████▍   | 97/150 [00:29<00:13,  3.98it/s] 65%|██████▌   | 98/150 [00:29<00:12,  4.08it/s] 66%|██████▌   | 99/150 [00:30<00:12,  4.01it/s] 67%|██████▋   | 100/150 [00:30<00:12,  3.99it/s] 67%|██████▋   | 101/150 [00:30<00:11,  4.14it/s] 68%|██████▊   | 102/150 [00:30<00:11,  4.04it/s] 69%|██████▊   | 103/150 [00:31<00:11,  4.15it/s] 69%|██████▉   | 104/150 [00:31<00:11,  4.04it/s] 70%|███████   | 105/150 [00:31<00:11,  3.98it/s] 71%|███████   | 106/150 [00:31<00:11,  3.97it/s] 71%|███████▏  | 107/150 [00:32<00:10,  3.95it/s] 72%|███████▏  | 108/150 [00:32<00:10,  3.96it/s] 73%|███████▎  | 109/150 [00:32<00:10,  3.90it/s] 73%|███████▎  | 110/150 [00:32<00:10,  3.91it/s] 74%|███████▍  | 111/150 [00:32<00:09,  4.27it/s] 75%|███████▍  | 112/150 [00:33<00:09,  4.11it/s] 75%|███████▌  | 113/150 [00:33<00:09,  3.99it/s] 76%|███████▌  | 114/150 [00:33<00:09,  3.93it/s] 77%|███████▋  | 115/150 [00:34<00:08,  3.92it/s] 77%|███████▋  | 116/150 [00:34<00:08,  3.91it/s] 78%|███████▊  | 117/150 [00:34<00:08,  3.89it/s] 79%|███████▊  | 118/150 [00:34<00:08,  3.90it/s] 79%|███████▉  | 119/150 [00:35<00:08,  3.87it/s] 80%|████████  | 120/150 [00:35<00:07,  3.86it/s] 81%|████████  | 121/150 [00:35<00:06,  4.17it/s] 81%|████████▏ | 122/150 [00:35<00:05,  4.79it/s] 82%|████████▏ | 123/150 [00:35<00:05,  5.35it/s] 83%|████████▎ | 124/150 [00:35<00:04,  5.83it/s] 83%|████████▎ | 125/150 [00:36<00:04,  6.22it/s] 84%|████████▍ | 126/150 [00:36<00:03,  6.53it/s] 85%|████████▍ | 127/150 [00:36<00:03,  6.75it/s] 85%|████████▌ | 128/150 [00:36<00:03,  6.93it/s] 86%|████████▌ | 129/150 [00:36<00:02,  7.05it/s] 87%|████████▋ | 130/150 [00:36<00:02,  7.13it/s] 87%|████████▋ | 131/150 [00:36<00:02,  7.19it/s] 88%|████████▊ | 132/150 [00:37<00:02,  7.24it/s] 89%|████████▊ | 133/150 [00:37<00:02,  7.27it/s] 89%|████████▉ | 134/150 [00:37<00:02,  7.30it/s] 90%|█████████ | 135/150 [00:37<00:02,  7.32it/s] 91%|█████████ | 136/150 [00:37<00:01,  7.34it/s] 91%|█████████▏| 137/150 [00:37<00:01,  7.34it/s] 92%|█████████▏| 138/150 [00:37<00:01,  7.35it/s] 93%|█████████▎| 139/150 [00:37<00:01,  7.29it/s] 93%|█████████▎| 140/150 [00:38<00:01,  7.31it/s] 94%|█████████▍| 141/150 [00:38<00:01,  7.34it/s] 95%|█████████▍| 142/150 [00:38<00:01,  7.35it/s] 95%|█████████▌| 143/150 [00:38<00:00,  7.35it/s] 96%|█████████▌| 144/150 [00:38<00:00,  7.35it/s] 97%|█████████▋| 145/150 [00:38<00:00,  7.34it/s] 97%|█████████▋| 146/150 [00:38<00:00,  7.34it/s] 98%|█████████▊| 147/150 [00:39<00:00,  7.35it/s] 99%|█████████▊| 148/150 [00:39<00:00,  7.35it/s] 99%|█████████▉| 149/150 [00:39<00:00,  7.37it/s]100%|██████████| 150/150 [00:39<00:00,  7.36it/s]100%|██████████| 150/150 [00:39<00:00,  3.79it/s]
=> result
* total: 15,000
* correct: 13,734
* accuracy: 91.6%
* error: 8.4%
* macro_f1: 91.5%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh food101 2 0 main_tmp1_0.1sdl 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
816 10200 15300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  51
# train_x  816
# val      10,200
# test     15,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/204] time 0.255 (0.376) data 0.000 (0.053) loss 0.4346 (1.6750) lr 1.0000e-02 eta 0:38:12
epoch [1/30] batch [40/204] time 0.252 (0.315) data 0.000 (0.027) loss 0.9854 (1.7266) lr 1.0000e-02 eta 0:31:55
epoch [1/30] batch [60/204] time 0.251 (0.295) data 0.000 (0.018) loss 0.9834 (1.7181) lr 1.0000e-02 eta 0:29:46
epoch [1/30] batch [80/204] time 0.251 (0.285) data 0.000 (0.013) loss 1.1123 (1.4852) lr 1.0000e-02 eta 0:28:39
epoch [1/30] batch [100/204] time 0.251 (0.280) data 0.000 (0.011) loss 5.1094 (1.4716) lr 1.0000e-02 eta 0:28:03
epoch [1/30] batch [120/204] time 0.254 (0.275) data 0.000 (0.009) loss 1.3867 (1.4113) lr 1.0000e-02 eta 0:27:31
epoch [1/30] batch [140/204] time 0.256 (0.273) data 0.000 (0.008) loss 2.1250 (1.4383) lr 1.0000e-02 eta 0:27:10
epoch [1/30] batch [160/204] time 0.250 (0.270) data 0.000 (0.007) loss 0.0549 (1.4096) lr 1.0000e-02 eta 0:26:52
epoch [1/30] batch [180/204] time 0.245 (0.268) data 0.000 (0.006) loss 5.0859 (1.3897) lr 1.0000e-02 eta 0:26:33
epoch [1/30] batch [200/204] time 0.243 (0.266) data 0.000 (0.006) loss 0.6323 (1.3926) lr 1.0000e-02 eta 0:26:16
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:29,  2.67s/it]  2%|▏         | 2/102 [00:03<02:36,  1.56s/it]  3%|▎         | 3/102 [00:03<01:43,  1.04s/it]  4%|▍         | 4/102 [00:04<01:14,  1.32it/s]  5%|▍         | 5/102 [00:04<00:56,  1.71it/s]  6%|▌         | 6/102 [00:04<00:45,  2.12it/s]  7%|▋         | 7/102 [00:04<00:37,  2.51it/s]  8%|▊         | 8/102 [00:05<00:32,  2.90it/s]  9%|▉         | 9/102 [00:05<00:29,  3.16it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:24,  3.68it/s] 12%|█▏        | 12/102 [00:06<00:23,  3.77it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.79it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.79it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.76it/s] 16%|█▌        | 16/102 [00:07<00:22,  3.84it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.87it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.89it/s] 19%|█▊        | 19/102 [00:07<00:20,  4.01it/s] 20%|█▉        | 20/102 [00:08<00:20,  4.06it/s] 21%|██        | 21/102 [00:08<00:20,  3.99it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.96it/s] 23%|██▎       | 23/102 [00:08<00:18,  4.23it/s] 24%|██▎       | 24/102 [00:09<00:17,  4.56it/s] 25%|██▍       | 25/102 [00:09<00:16,  4.71it/s] 25%|██▌       | 26/102 [00:09<00:15,  4.82it/s] 26%|██▋       | 27/102 [00:09<00:16,  4.53it/s] 27%|██▋       | 28/102 [00:10<00:17,  4.26it/s] 28%|██▊       | 29/102 [00:10<00:18,  4.04it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.93it/s] 30%|███       | 31/102 [00:10<00:18,  3.91it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.88it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.86it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.85it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.92it/s] 35%|███▌      | 36/102 [00:12<00:15,  4.18it/s] 36%|███▋      | 37/102 [00:12<00:15,  4.09it/s] 37%|███▋      | 38/102 [00:12<00:15,  4.01it/s] 38%|███▊      | 39/102 [00:12<00:15,  3.97it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.98it/s] 40%|████      | 41/102 [00:13<00:15,  3.99it/s] 41%|████      | 42/102 [00:13<00:14,  4.15it/s] 42%|████▏     | 43/102 [00:13<00:14,  4.04it/s] 43%|████▎     | 44/102 [00:14<00:14,  4.05it/s] 44%|████▍     | 45/102 [00:14<00:14,  4.01it/s] 45%|████▌     | 46/102 [00:14<00:13,  4.01it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.92it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.90it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.93it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.93it/s] 50%|█████     | 51/102 [00:15<00:13,  3.92it/s] 51%|█████     | 52/102 [00:16<00:12,  3.89it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.91it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.95it/s] 54%|█████▍    | 55/102 [00:16<00:11,  3.96it/s] 55%|█████▍    | 56/102 [00:17<00:11,  4.03it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.95it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.94it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.87it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.84it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.83it/s] 62%|██████▏   | 63/102 [00:18<00:09,  4.11it/s] 63%|██████▎   | 64/102 [00:19<00:09,  4.01it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.98it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.21it/s] 66%|██████▌   | 67/102 [00:19<00:08,  4.01it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.98it/s] 68%|██████▊   | 69/102 [00:20<00:07,  4.26it/s] 69%|██████▊   | 70/102 [00:20<00:07,  4.10it/s] 70%|██████▉   | 71/102 [00:20<00:07,  4.02it/s] 71%|███████   | 72/102 [00:21<00:07,  4.03it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.53it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.14it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.67it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.11it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.47it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.95it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.28it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.37it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.40it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.45it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.47it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.48it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,130
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 89.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/204] time 0.254 (0.292) data 0.000 (0.034) loss 1.4033 (1.2563) lr 9.9726e-03 eta 0:28:43
epoch [2/30] batch [40/204] time 0.251 (0.274) data 0.000 (0.017) loss 1.0508 (1.1424) lr 9.9726e-03 eta 0:26:49
epoch [2/30] batch [60/204] time 0.254 (0.268) data 0.000 (0.011) loss 2.6289 (1.1121) lr 9.9726e-03 eta 0:26:08
epoch [2/30] batch [80/204] time 0.259 (0.266) data 0.000 (0.009) loss 0.2900 (1.1288) lr 9.9726e-03 eta 0:25:52
epoch [2/30] batch [100/204] time 0.251 (0.264) data 0.000 (0.007) loss 0.7324 (1.1139) lr 9.9726e-03 eta 0:25:35
epoch [2/30] batch [120/204] time 0.258 (0.263) data 0.000 (0.006) loss 0.2585 (1.1589) lr 9.9726e-03 eta 0:25:21
epoch [2/30] batch [140/204] time 0.255 (0.262) data 0.000 (0.005) loss 0.0618 (1.1400) lr 9.9726e-03 eta 0:25:11
epoch [2/30] batch [160/204] time 0.254 (0.261) data 0.000 (0.004) loss 0.0201 (1.1394) lr 9.9726e-03 eta 0:25:03
epoch [2/30] batch [180/204] time 0.244 (0.260) data 0.000 (0.004) loss 0.7344 (1.1706) lr 9.9726e-03 eta 0:24:51
epoch [2/30] batch [200/204] time 0.243 (0.258) data 0.000 (0.004) loss 0.9492 (1.2144) lr 9.9726e-03 eta 0:24:36
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:19,  2.56s/it]  2%|▏         | 2/102 [00:03<02:21,  1.42s/it]  3%|▎         | 3/102 [00:03<01:32,  1.07it/s]  4%|▍         | 4/102 [00:03<01:05,  1.49it/s]  5%|▍         | 5/102 [00:04<00:50,  1.91it/s]  6%|▌         | 6/102 [00:04<00:39,  2.43it/s]  7%|▋         | 7/102 [00:04<00:34,  2.78it/s]  8%|▊         | 8/102 [00:04<00:30,  3.08it/s]  9%|▉         | 9/102 [00:04<00:26,  3.46it/s] 10%|▉         | 10/102 [00:05<00:25,  3.55it/s] 11%|█         | 11/102 [00:05<00:25,  3.62it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.68it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.68it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.79it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.79it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.78it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.86it/s] 20%|█▉        | 20/102 [00:07<00:20,  4.08it/s] 21%|██        | 21/102 [00:08<00:20,  4.01it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.97it/s] 23%|██▎       | 23/102 [00:08<00:18,  4.18it/s] 24%|██▎       | 24/102 [00:08<00:19,  4.06it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.99it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.95it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.89it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.91it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.92it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.87it/s] 30%|███       | 31/102 [00:10<00:18,  3.86it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.85it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.82it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.81it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.80it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.78it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.83it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.79it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.80it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.83it/s] 40%|████      | 41/102 [00:13<00:15,  3.86it/s] 41%|████      | 42/102 [00:13<00:15,  3.84it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.85it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.91it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.87it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.84it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.86it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.86it/s] 50%|█████     | 51/102 [00:15<00:13,  3.86it/s] 51%|█████     | 52/102 [00:16<00:12,  3.87it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.84it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.81it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.81it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.80it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.84it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.87it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.88it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.84it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.84it/s] 63%|██████▎   | 64/102 [00:19<00:10,  3.79it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.80it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.80it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.88it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.84it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.87it/s] 71%|███████   | 72/102 [00:21<00:07,  3.95it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.60it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.20it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.71it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.14it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.47it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.73it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.93it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.01it/s]=> result
* total: 10,200
* correct: 9,163
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 89.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/204] time 0.254 (0.298) data 0.000 (0.035) loss 3.1406 (1.2590) lr 9.8907e-03 eta 0:28:15
epoch [3/30] batch [40/204] time 0.253 (0.277) data 0.000 (0.018) loss 0.3027 (1.2122) lr 9.8907e-03 eta 0:26:09
epoch [3/30] batch [60/204] time 0.255 (0.269) data 0.000 (0.012) loss 0.4314 (1.1270) lr 9.8907e-03 eta 0:25:20
epoch [3/30] batch [80/204] time 0.252 (0.265) data 0.000 (0.009) loss 2.3828 (1.1297) lr 9.8907e-03 eta 0:24:54
epoch [3/30] batch [100/204] time 0.254 (0.263) data 0.000 (0.007) loss 2.2148 (1.0794) lr 9.8907e-03 eta 0:24:38
epoch [3/30] batch [120/204] time 0.260 (0.262) data 0.000 (0.006) loss -0.0496 (1.0909) lr 9.8907e-03 eta 0:24:23
epoch [3/30] batch [140/204] time 0.251 (0.261) data 0.000 (0.005) loss 0.0703 (1.1016) lr 9.8907e-03 eta 0:24:11
epoch [3/30] batch [160/204] time 0.253 (0.260) data 0.000 (0.005) loss 1.7158 (1.1462) lr 9.8907e-03 eta 0:24:01
epoch [3/30] batch [180/204] time 0.244 (0.259) data 0.000 (0.004) loss 0.0151 (1.1521) lr 9.8907e-03 eta 0:23:51
epoch [3/30] batch [200/204] time 0.243 (0.257) data 0.000 (0.004) loss 0.3433 (1.1678) lr 9.8907e-03 eta 0:23:37
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:02,  2.40s/it]  2%|▏         | 2/102 [00:02<02:11,  1.31s/it]  3%|▎         | 3/102 [00:03<01:32,  1.08it/s]  4%|▍         | 4/102 [00:03<01:05,  1.49it/s]  5%|▍         | 5/102 [00:03<00:51,  1.90it/s]  6%|▌         | 6/102 [00:04<00:42,  2.27it/s]  7%|▋         | 7/102 [00:04<00:36,  2.64it/s]  8%|▊         | 8/102 [00:04<00:32,  2.91it/s]  9%|▉         | 9/102 [00:05<00:29,  3.15it/s] 10%|▉         | 10/102 [00:05<00:27,  3.35it/s] 11%|█         | 11/102 [00:05<00:26,  3.45it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.55it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.64it/s] 14%|█▎        | 14/102 [00:06<00:24,  3.66it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.71it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.74it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.78it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.79it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.78it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.79it/s] 21%|██        | 21/102 [00:08<00:21,  3.81it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.84it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.85it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.90it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.90it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.86it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.85it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.87it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.90it/s] 30%|███       | 31/102 [00:10<00:18,  3.92it/s] 31%|███▏      | 32/102 [00:11<00:17,  3.91it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.89it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.89it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.84it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.84it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.87it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.87it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.88it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.80it/s] 40%|████      | 41/102 [00:13<00:16,  3.79it/s] 41%|████      | 42/102 [00:13<00:15,  3.82it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.88it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.87it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.82it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.83it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.80it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.83it/s] 50%|█████     | 51/102 [00:15<00:13,  3.84it/s] 51%|█████     | 52/102 [00:16<00:12,  3.87it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.83it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.80it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.81it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.82it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.83it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.85it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.87it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.87it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.89it/s] 61%|██████    | 62/102 [00:18<00:10,  3.85it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.85it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.86it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.81it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.83it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.81it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.82it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.88it/s] 71%|███████   | 72/102 [00:21<00:07,  3.92it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.39it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.00it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.54it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.00it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.38it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.66it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.83it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.00it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.12it/s] 80%|████████  | 82/102 [00:22<00:02,  7.22it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.28it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.42it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.42it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.42it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.98it/s]=> result
* total: 10,200
* correct: 9,177
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/204] time 0.256 (0.298) data 0.000 (0.036) loss 2.5625 (1.2748) lr 9.7553e-03 eta 0:27:17
epoch [4/30] batch [40/204] time 0.260 (0.277) data 0.000 (0.018) loss -0.0342 (1.2926) lr 9.7553e-03 eta 0:25:14
epoch [4/30] batch [60/204] time 0.249 (0.269) data 0.000 (0.012) loss 0.6421 (1.1619) lr 9.7553e-03 eta 0:24:28
epoch [4/30] batch [80/204] time 0.249 (0.266) data 0.000 (0.009) loss -0.0421 (1.1211) lr 9.7553e-03 eta 0:24:02
epoch [4/30] batch [100/204] time 0.252 (0.263) data 0.000 (0.007) loss 3.4141 (1.1612) lr 9.7553e-03 eta 0:23:42
epoch [4/30] batch [120/204] time 0.252 (0.261) data 0.000 (0.006) loss 2.5996 (1.1917) lr 9.7553e-03 eta 0:23:27
epoch [4/30] batch [140/204] time 0.249 (0.260) data 0.000 (0.005) loss 0.0764 (1.1984) lr 9.7553e-03 eta 0:23:14
epoch [4/30] batch [160/204] time 0.319 (0.260) data 0.000 (0.005) loss 0.0480 (1.2014) lr 9.7553e-03 eta 0:23:08
epoch [4/30] batch [180/204] time 0.242 (0.258) data 0.000 (0.004) loss 0.7319 (1.2232) lr 9.7553e-03 eta 0:22:55
epoch [4/30] batch [200/204] time 0.243 (0.257) data 0.000 (0.004) loss 0.1902 (1.2206) lr 9.7553e-03 eta 0:22:42
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:12,  2.50s/it]  2%|▏         | 2/102 [00:03<02:19,  1.40s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.53it/s]  5%|▍         | 5/102 [00:03<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:32,  2.93it/s]  9%|▉         | 9/102 [00:05<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.33it/s] 11%|█         | 11/102 [00:05<00:26,  3.49it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.57it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.64it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.71it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.71it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.75it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.79it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.84it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.84it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.85it/s] 21%|██        | 21/102 [00:08<00:20,  3.86it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.88it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.89it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.88it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.88it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.87it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.86it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.87it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.87it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.89it/s] 30%|███       | 31/102 [00:10<00:18,  3.86it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.87it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.83it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.86it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.86it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.82it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.81it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.83it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.80it/s] 40%|████      | 41/102 [00:13<00:16,  3.80it/s] 41%|████      | 42/102 [00:13<00:15,  3.81it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.81it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.87it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.89it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.87it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.90it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.87it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.89it/s] 50%|█████     | 51/102 [00:15<00:13,  3.85it/s] 51%|█████     | 52/102 [00:16<00:13,  3.81it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.85it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.81it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.84it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.81it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.84it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.86it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.88it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.87it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.83it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.82it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.80it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.78it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.78it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.79it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.79it/s] 68%|██████▊   | 69/102 [00:20<00:08,  4.01it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.95it/s] 70%|██████▉   | 71/102 [00:21<00:07,  4.03it/s] 71%|███████   | 72/102 [00:21<00:07,  3.98it/s] 72%|███████▏  | 73/102 [00:21<00:07,  4.02it/s] 73%|███████▎  | 74/102 [00:21<00:06,  4.62it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.21it/s] 75%|███████▍  | 76/102 [00:22<00:04,  5.73it/s] 75%|███████▌  | 77/102 [00:22<00:04,  6.15it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.49it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.74it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.93it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.08it/s] 80%|████████  | 82/102 [00:22<00:02,  7.18it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.25it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.30it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.33it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.36it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.38it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.39it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.41it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.42it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.42it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.42it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  3.98it/s]=> result
* total: 10,200
* correct: 9,172
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.9%

epoch [5/30] batch [20/204] time 0.259 (0.295) data 0.000 (0.035) loss -0.0020 (1.5121) lr 9.5677e-03 eta 0:25:58
epoch [5/30] batch [40/204] time 0.256 (0.275) data 0.000 (0.018) loss 0.0966 (1.5695) lr 9.5677e-03 eta 0:24:10
epoch [5/30] batch [60/204] time 0.254 (0.270) data 0.000 (0.012) loss 0.0596 (1.3783) lr 9.5677e-03 eta 0:23:35
epoch [5/30] batch [80/204] time 0.259 (0.266) data 0.000 (0.009) loss 2.7402 (1.3421) lr 9.5677e-03 eta 0:23:11
epoch [5/30] batch [100/204] time 0.253 (0.264) data 0.000 (0.007) loss 0.6094 (1.2767) lr 9.5677e-03 eta 0:22:53
epoch [5/30] batch [120/204] time 0.256 (0.262) data 0.000 (0.006) loss 5.7969 (1.2806) lr 9.5677e-03 eta 0:22:39
epoch [5/30] batch [140/204] time 0.249 (0.261) data 0.000 (0.005) loss 0.6016 (1.3002) lr 9.5677e-03 eta 0:22:27
epoch [5/30] batch [160/204] time 0.256 (0.260) data 0.001 (0.005) loss 3.8594 (1.3195) lr 9.5677e-03 eta 0:22:18
epoch [5/30] batch [180/204] time 0.240 (0.259) data 0.000 (0.004) loss 0.6743 (1.3133) lr 9.5677e-03 eta 0:22:09
epoch [5/30] batch [200/204] time 0.243 (0.258) data 0.000 (0.004) loss 4.4297 (1.3038) lr 9.5677e-03 eta 0:21:55
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:16,  2.54s/it]  2%|▏         | 2/102 [00:03<02:18,  1.39s/it]  3%|▎         | 3/102 [00:03<01:28,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.55it/s]  5%|▍         | 5/102 [00:03<00:48,  2.00it/s]  6%|▌         | 6/102 [00:04<00:40,  2.37it/s]  7%|▋         | 7/102 [00:04<00:35,  2.70it/s]  8%|▊         | 8/102 [00:04<00:31,  3.01it/s]  9%|▉         | 9/102 [00:04<00:28,  3.24it/s] 10%|▉         | 10/102 [00:05<00:26,  3.46it/s] 11%|█         | 11/102 [00:05<00:25,  3.58it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.67it/s] 13%|█▎        | 13/102 [00:05<00:23,  3.83it/s] 14%|█▎        | 14/102 [00:06<00:22,  3.85it/s] 15%|█▍        | 15/102 [00:06<00:21,  4.02it/s] 16%|█▌        | 16/102 [00:06<00:21,  4.01it/s] 17%|█▋        | 17/102 [00:06<00:21,  3.94it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.93it/s] 19%|█▊        | 19/102 [00:07<00:19,  4.31it/s] 20%|█▉        | 20/102 [00:07<00:19,  4.23it/s] 21%|██        | 21/102 [00:07<00:18,  4.46it/s] 22%|██▏       | 22/102 [00:08<00:18,  4.32it/s] 23%|██▎       | 23/102 [00:08<00:18,  4.19it/s] 24%|██▎       | 24/102 [00:08<00:19,  4.07it/s] 25%|██▍       | 25/102 [00:08<00:19,  3.97it/s] 25%|██▌       | 26/102 [00:09<00:18,  4.15it/s] 26%|██▋       | 27/102 [00:09<00:18,  4.05it/s] 27%|██▋       | 28/102 [00:09<00:18,  4.01it/s] 28%|██▊       | 29/102 [00:09<00:18,  3.95it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.89it/s] 30%|███       | 31/102 [00:10<00:18,  3.86it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.83it/s] 32%|███▏      | 33/102 [00:10<00:17,  3.86it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.86it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.87it/s] 35%|███▌      | 36/102 [00:11<00:16,  3.91it/s] 36%|███▋      | 37/102 [00:11<00:15,  4.24it/s] 37%|███▋      | 38/102 [00:12<00:15,  4.10it/s] 38%|███▊      | 39/102 [00:12<00:14,  4.23it/s] 39%|███▉      | 40/102 [00:12<00:15,  4.13it/s] 40%|████      | 41/102 [00:12<00:15,  4.04it/s] 41%|████      | 42/102 [00:13<00:14,  4.01it/s] 42%|████▏     | 43/102 [00:13<00:14,  3.98it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.99it/s] 44%|████▍     | 45/102 [00:13<00:14,  3.95it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.93it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.88it/s] 48%|████▊     | 49/102 [00:14<00:13,  3.88it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.84it/s] 50%|█████     | 51/102 [00:15<00:13,  3.85it/s] 51%|█████     | 52/102 [00:15<00:12,  3.85it/s] 52%|█████▏    | 53/102 [00:15<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.85it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.86it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.87it/s] 56%|█████▌    | 57/102 [00:16<00:11,  3.96it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.89it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.05it/s] 59%|█████▉    | 60/102 [00:17<00:10,  4.04it/s] 60%|█████▉    | 61/102 [00:17<00:09,  4.12it/s] 61%|██████    | 62/102 [00:18<00:09,  4.07it/s] 62%|██████▏   | 63/102 [00:18<00:09,  3.99it/s] 63%|██████▎   | 64/102 [00:18<00:09,  4.13it/s] 64%|██████▎   | 65/102 [00:18<00:08,  4.12it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.02it/s] 66%|██████▌   | 67/102 [00:19<00:08,  3.96it/s] 67%|██████▋   | 68/102 [00:19<00:08,  4.09it/s] 68%|██████▊   | 69/102 [00:19<00:08,  4.00it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.98it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.91it/s] 71%|███████   | 72/102 [00:20<00:07,  3.97it/s] 72%|███████▏  | 73/102 [00:20<00:06,  4.27it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.90it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.46it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.93it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.32it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.62it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.84it/s] 78%|███████▊  | 80/102 [00:21<00:03,  7.02it/s] 79%|███████▉  | 81/102 [00:21<00:02,  7.14it/s] 80%|████████  | 82/102 [00:22<00:02,  7.24it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.30it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.43it/s] 86%|████████▋ | 88/102 [00:22<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:23<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:23<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.45it/s]100%|██████████| 102/102 [00:24<00:00,  7.45it/s]100%|██████████| 102/102 [00:24<00:00,  4.09it/s]=> result
* total: 10,200
* correct: 9,172
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.9%

epoch [6/30] batch [20/204] time 0.252 (0.291) data 0.000 (0.035) loss 0.0593 (1.5233) lr 9.3301e-03 eta 0:24:40
epoch [6/30] batch [40/204] time 0.259 (0.273) data 0.000 (0.018) loss 0.8569 (1.2070) lr 9.3301e-03 eta 0:23:00
epoch [6/30] batch [60/204] time 0.258 (0.267) data 0.000 (0.012) loss -0.0328 (1.2441) lr 9.3301e-03 eta 0:22:27
epoch [6/30] batch [80/204] time 0.263 (0.266) data 0.000 (0.009) loss 2.6152 (1.2725) lr 9.3301e-03 eta 0:22:16
epoch [6/30] batch [100/204] time 0.260 (0.264) data 0.000 (0.007) loss 0.2018 (1.2758) lr 9.3301e-03 eta 0:22:00
epoch [6/30] batch [120/204] time 0.260 (0.263) data 0.000 (0.006) loss 0.0954 (1.1848) lr 9.3301e-03 eta 0:21:47
epoch [6/30] batch [140/204] time 0.254 (0.262) data 0.000 (0.005) loss 0.2379 (1.1373) lr 9.3301e-03 eta 0:21:37
epoch [6/30] batch [160/204] time 0.254 (0.261) data 0.000 (0.005) loss 0.8442 (1.1163) lr 9.3301e-03 eta 0:21:30
epoch [6/30] batch [180/204] time 0.242 (0.260) data 0.000 (0.004) loss 0.8232 (1.1194) lr 9.3301e-03 eta 0:21:16
epoch [6/30] batch [200/204] time 0.241 (0.258) data 0.000 (0.004) loss 0.7451 (1.1227) lr 9.3301e-03 eta 0:21:02
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:21,  2.59s/it]  2%|▏         | 2/102 [00:03<02:18,  1.39s/it]  3%|▎         | 3/102 [00:03<01:28,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.55it/s]  5%|▍         | 5/102 [00:03<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:05<00:29,  3.18it/s] 10%|▉         | 10/102 [00:05<00:27,  3.35it/s] 11%|█         | 11/102 [00:05<00:26,  3.46it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.56it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.63it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.67it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.75it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.81it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.84it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.87it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.90it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.87it/s] 21%|██        | 21/102 [00:08<00:21,  3.84it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.84it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.83it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.88it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.83it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.85it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.92it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.91it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.84it/s] 30%|███       | 31/102 [00:10<00:18,  3.82it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.81it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.84it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.81it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.80it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.81it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.82it/s] 40%|████      | 41/102 [00:13<00:15,  3.96it/s] 41%|████      | 42/102 [00:13<00:15,  3.90it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.84it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.81it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.81it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.81it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.90it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.85it/s] 50%|█████     | 51/102 [00:15<00:13,  3.90it/s] 51%|█████     | 52/102 [00:16<00:12,  3.88it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.85it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.81it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.82it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.82it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.87it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.87it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.80it/s] 61%|██████    | 62/102 [00:18<00:10,  3.75it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.78it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.82it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.81it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.82it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.82it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.82it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.88it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.88it/s] 71%|███████   | 72/102 [00:21<00:07,  3.89it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.37it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.98it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.54it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.00it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.36it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.65it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.87it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.03it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.98it/s]=> result
* total: 10,200
* correct: 9,184
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/204] time 0.254 (0.293) data 0.000 (0.034) loss 0.0989 (1.0152) lr 9.0451e-03 eta 0:23:50
epoch [7/30] batch [40/204] time 0.259 (0.277) data 0.000 (0.017) loss 4.8750 (1.2897) lr 9.0451e-03 eta 0:22:27
epoch [7/30] batch [60/204] time 0.258 (0.270) data 0.000 (0.012) loss 0.4666 (1.1851) lr 9.0451e-03 eta 0:21:47
epoch [7/30] batch [80/204] time 0.256 (0.267) data 0.000 (0.009) loss 1.6797 (1.1434) lr 9.0451e-03 eta 0:21:26
epoch [7/30] batch [100/204] time 0.252 (0.265) data 0.000 (0.007) loss 2.3633 (1.0422) lr 9.0451e-03 eta 0:21:09
epoch [7/30] batch [120/204] time 0.251 (0.263) data 0.000 (0.006) loss 0.0918 (1.0810) lr 9.0451e-03 eta 0:20:55
epoch [7/30] batch [140/204] time 0.256 (0.261) data 0.000 (0.005) loss 1.3184 (1.0999) lr 9.0451e-03 eta 0:20:43
epoch [7/30] batch [160/204] time 0.257 (0.260) data 0.000 (0.005) loss 0.6875 (1.1365) lr 9.0451e-03 eta 0:20:33
epoch [7/30] batch [180/204] time 0.244 (0.259) data 0.000 (0.004) loss 1.5127 (1.1580) lr 9.0451e-03 eta 0:20:23
epoch [7/30] batch [200/204] time 0.246 (0.258) data 0.000 (0.004) loss 0.8169 (1.1440) lr 9.0451e-03 eta 0:20:10
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:44,  2.82s/it]  2%|▏         | 2/102 [00:03<02:22,  1.43s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:03,  1.55it/s]  5%|▍         | 5/102 [00:04<00:49,  1.98it/s]  6%|▌         | 6/102 [00:04<00:40,  2.36it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:05<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:25,  3.51it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.61it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.72it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.84it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.86it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.90it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.87it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.85it/s] 21%|██        | 21/102 [00:08<00:21,  3.84it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.85it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.83it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.84it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.86it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.85it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.86it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.98it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.96it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.92it/s] 30%|███       | 31/102 [00:10<00:18,  3.91it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.88it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.87it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.88it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.86it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.88it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.90it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.85it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.88it/s] 40%|████      | 41/102 [00:13<00:15,  3.91it/s] 41%|████      | 42/102 [00:13<00:15,  3.89it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.86it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.90it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.94it/s] 46%|████▌     | 47/102 [00:14<00:13,  3.97it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.93it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.89it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.92it/s] 50%|█████     | 51/102 [00:15<00:13,  3.89it/s] 51%|█████     | 52/102 [00:16<00:12,  3.90it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.88it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.86it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.83it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.83it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.84it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.82it/s] 59%|█████▉    | 60/102 [00:18<00:11,  3.81it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.91it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.89it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.89it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.84it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.83it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.81it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.81it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.79it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.80it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.85it/s] 71%|███████   | 72/102 [00:21<00:07,  3.93it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.56it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.15it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.68it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.12it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.46it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.73it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.93it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.42it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,188
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/204] time 0.255 (0.297) data 0.000 (0.035) loss 1.4180 (1.5163) lr 8.7157e-03 eta 0:23:08
epoch [8/30] batch [40/204] time 0.261 (0.276) data 0.000 (0.018) loss 1.0459 (1.2321) lr 8.7157e-03 eta 0:21:23
epoch [8/30] batch [60/204] time 0.256 (0.269) data 0.000 (0.012) loss 0.5811 (1.0919) lr 8.7157e-03 eta 0:20:44
epoch [8/30] batch [80/204] time 0.256 (0.265) data 0.000 (0.009) loss 0.1910 (1.0588) lr 8.7157e-03 eta 0:20:22
epoch [8/30] batch [100/204] time 0.253 (0.263) data 0.000 (0.007) loss 0.1344 (0.9651) lr 8.7157e-03 eta 0:20:07
epoch [8/30] batch [120/204] time 0.249 (0.262) data 0.000 (0.006) loss 1.3281 (1.0659) lr 8.7157e-03 eta 0:19:56
epoch [8/30] batch [140/204] time 0.256 (0.261) data 0.000 (0.005) loss 1.0410 (1.1154) lr 8.7157e-03 eta 0:19:46
epoch [8/30] batch [160/204] time 0.250 (0.260) data 0.000 (0.005) loss 0.9966 (1.1145) lr 8.7157e-03 eta 0:19:39
epoch [8/30] batch [180/204] time 0.245 (0.259) data 0.000 (0.004) loss 0.0621 (1.1356) lr 8.7157e-03 eta 0:19:28
epoch [8/30] batch [200/204] time 0.243 (0.257) data 0.000 (0.004) loss -0.0223 (1.1451) lr 8.7157e-03 eta 0:19:16
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<03:44,  2.23s/it]  2%|▏         | 2/102 [00:02<02:11,  1.31s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:03<00:50,  1.92it/s]  6%|▌         | 6/102 [00:04<00:41,  2.29it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.94it/s]  9%|▉         | 9/102 [00:04<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.38it/s] 11%|█         | 11/102 [00:05<00:25,  3.51it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.59it/s] 13%|█▎        | 13/102 [00:05<00:24,  3.64it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.70it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.76it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.78it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.79it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.80it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.81it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.83it/s] 21%|██        | 21/102 [00:08<00:21,  3.85it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.80it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.84it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.85it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.87it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.87it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.88it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.89it/s] 30%|███       | 31/102 [00:10<00:18,  3.88it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.86it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.84it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.86it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.83it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.86it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.83it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.89it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.87it/s] 40%|████      | 41/102 [00:13<00:15,  3.83it/s] 41%|████      | 42/102 [00:13<00:15,  3.89it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.89it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.90it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.88it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.86it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.83it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.85it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.90it/s] 49%|████▉     | 50/102 [00:15<00:12,  4.26it/s] 50%|█████     | 51/102 [00:15<00:12,  4.13it/s] 51%|█████     | 52/102 [00:15<00:12,  4.05it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.97it/s] 53%|█████▎    | 54/102 [00:16<00:11,  4.21it/s] 54%|█████▍    | 55/102 [00:16<00:11,  4.13it/s] 55%|█████▍    | 56/102 [00:16<00:11,  4.04it/s] 56%|█████▌    | 57/102 [00:17<00:11,  4.04it/s] 57%|█████▋    | 58/102 [00:17<00:11,  4.00it/s] 58%|█████▊    | 59/102 [00:17<00:10,  3.98it/s] 59%|█████▉    | 60/102 [00:17<00:10,  4.00it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.95it/s] 61%|██████    | 62/102 [00:18<00:10,  3.92it/s] 62%|██████▏   | 63/102 [00:18<00:09,  4.08it/s] 63%|██████▎   | 64/102 [00:18<00:08,  4.27it/s] 64%|██████▎   | 65/102 [00:19<00:08,  4.13it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.08it/s] 66%|██████▌   | 67/102 [00:19<00:08,  3.99it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.93it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.89it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:20<00:07,  4.14it/s] 71%|███████   | 72/102 [00:20<00:07,  4.11it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.69it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.89it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.41it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.89it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.28it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.60it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.83it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.01it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.14it/s] 80%|████████  | 82/102 [00:22<00:02,  7.23it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.38it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.39it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.40it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.05it/s]=> result
* total: 10,200
* correct: 9,201
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/204] time 0.254 (0.291) data 0.000 (0.034) loss 0.5830 (1.0374) lr 8.3457e-03 eta 0:21:40
epoch [9/30] batch [40/204] time 0.263 (0.272) data 0.000 (0.017) loss 1.2158 (1.0326) lr 8.3457e-03 eta 0:20:11
epoch [9/30] batch [60/204] time 0.263 (0.268) data 0.000 (0.012) loss 0.1941 (1.0755) lr 8.3457e-03 eta 0:19:45
epoch [9/30] batch [80/204] time 0.249 (0.265) data 0.000 (0.009) loss 0.6431 (1.1191) lr 8.3457e-03 eta 0:19:26
epoch [9/30] batch [100/204] time 0.253 (0.262) data 0.000 (0.007) loss 0.1838 (1.0663) lr 8.3457e-03 eta 0:19:10
epoch [9/30] batch [120/204] time 0.254 (0.261) data 0.000 (0.006) loss 1.1914 (1.0446) lr 8.3457e-03 eta 0:18:59
epoch [9/30] batch [140/204] time 0.324 (0.260) data 0.001 (0.005) loss 0.0111 (1.0890) lr 8.3457e-03 eta 0:18:52
epoch [9/30] batch [160/204] time 0.260 (0.260) data 0.000 (0.005) loss 2.7734 (1.1105) lr 8.3457e-03 eta 0:18:44
epoch [9/30] batch [180/204] time 0.243 (0.259) data 0.000 (0.004) loss 0.4805 (1.1066) lr 8.3457e-03 eta 0:18:35
epoch [9/30] batch [200/204] time 0.244 (0.257) data 0.000 (0.004) loss 2.8965 (1.0867) lr 8.3457e-03 eta 0:18:23
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<03:59,  2.37s/it]  2%|▏         | 2/102 [00:02<02:13,  1.33s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:03<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.65it/s]  8%|▊         | 8/102 [00:04<00:31,  2.97it/s]  9%|▉         | 9/102 [00:04<00:29,  3.19it/s] 10%|▉         | 10/102 [00:05<00:26,  3.50it/s] 11%|█         | 11/102 [00:05<00:25,  3.59it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.66it/s] 13%|█▎        | 13/102 [00:05<00:24,  3.67it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.71it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.74it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.75it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.77it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.83it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.84it/s] 20%|█▉        | 20/102 [00:07<00:20,  4.00it/s] 21%|██        | 21/102 [00:08<00:20,  3.98it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.97it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.95it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.96it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.94it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.91it/s] 26%|██▋       | 27/102 [00:09<00:18,  4.09it/s] 27%|██▋       | 28/102 [00:09<00:18,  4.02it/s] 28%|██▊       | 29/102 [00:10<00:18,  4.03it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.96it/s] 30%|███       | 31/102 [00:10<00:18,  3.91it/s] 31%|███▏      | 32/102 [00:10<00:16,  4.19it/s] 32%|███▏      | 33/102 [00:11<00:16,  4.09it/s] 33%|███▎      | 34/102 [00:11<00:16,  4.06it/s] 34%|███▍      | 35/102 [00:11<00:16,  3.98it/s] 35%|███▌      | 36/102 [00:11<00:16,  3.98it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.93it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.94it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.90it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.89it/s] 40%|████      | 41/102 [00:13<00:15,  3.90it/s] 41%|████      | 42/102 [00:13<00:15,  3.88it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.88it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.85it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.88it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.94it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.89it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.88it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.86it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.81it/s] 50%|█████     | 51/102 [00:15<00:13,  3.81it/s] 51%|█████     | 52/102 [00:15<00:13,  3.80it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.78it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.81it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.83it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.86it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.89it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.89it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.82it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.82it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.80it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.82it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.80it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.82it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.84it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.85it/s] 71%|███████   | 72/102 [00:21<00:07,  3.93it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.53it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.10it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.63it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.09it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.44it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.71it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.92it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.31it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.36it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.38it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.41it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.42it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,183
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%

epoch [10/30] batch [20/204] time 0.255 (0.294) data 0.000 (0.035) loss 2.9531 (1.1940) lr 7.9389e-03 eta 0:20:53
epoch [10/30] batch [40/204] time 0.254 (0.276) data 0.001 (0.018) loss 0.0554 (0.8945) lr 7.9389e-03 eta 0:19:30
epoch [10/30] batch [60/204] time 0.256 (0.270) data 0.000 (0.012) loss 1.4590 (1.0155) lr 7.9389e-03 eta 0:19:02
epoch [10/30] batch [80/204] time 0.257 (0.266) data 0.000 (0.009) loss 1.6465 (1.0670) lr 7.9389e-03 eta 0:18:40
epoch [10/30] batch [100/204] time 0.252 (0.264) data 0.000 (0.007) loss 1.3770 (0.9824) lr 7.9389e-03 eta 0:18:24
epoch [10/30] batch [120/204] time 0.259 (0.262) data 0.000 (0.006) loss 1.9434 (1.0242) lr 7.9389e-03 eta 0:18:12
epoch [10/30] batch [140/204] time 0.256 (0.261) data 0.000 (0.005) loss 0.1483 (1.0075) lr 7.9389e-03 eta 0:18:03
epoch [10/30] batch [160/204] time 0.250 (0.260) data 0.000 (0.005) loss 2.1797 (1.0133) lr 7.9389e-03 eta 0:17:54
epoch [10/30] batch [180/204] time 0.242 (0.259) data 0.000 (0.004) loss 0.9492 (1.0038) lr 7.9389e-03 eta 0:17:43
epoch [10/30] batch [200/204] time 0.244 (0.258) data 0.000 (0.004) loss 0.4905 (1.0280) lr 7.9389e-03 eta 0:17:32
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:17,  2.55s/it]  2%|▏         | 2/102 [00:03<02:16,  1.37s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:03<00:50,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:05<00:28,  3.22it/s] 10%|▉         | 10/102 [00:05<00:27,  3.39it/s] 11%|█         | 11/102 [00:05<00:25,  3.57it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.61it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.68it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.70it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.74it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.79it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.80it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.81it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.79it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.80it/s] 21%|██        | 21/102 [00:08<00:21,  3.75it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.75it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.78it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.80it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.81it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.82it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.85it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.86it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.84it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.81it/s] 30%|███       | 31/102 [00:10<00:18,  3.82it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.84it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.80it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.78it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.81it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.89it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.92it/s] 38%|███▊      | 39/102 [00:12<00:15,  3.96it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.90it/s] 40%|████      | 41/102 [00:13<00:15,  3.88it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.85it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.88it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.87it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.87it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.83it/s] 50%|█████     | 51/102 [00:15<00:13,  3.80it/s] 51%|█████     | 52/102 [00:16<00:12,  3.86it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.86it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.86it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.81it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.82it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.84it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.86it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.80it/s] 59%|█████▉    | 60/102 [00:18<00:11,  3.80it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.83it/s] 61%|██████    | 62/102 [00:18<00:10,  3.87it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.87it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.86it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.90it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.85it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.83it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.81it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.81it/s] 71%|███████   | 72/102 [00:21<00:07,  3.89it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.51it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.12it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.65it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.10it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.45it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.72it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.91it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.06it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,184
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/204] time 0.263 (0.294) data 0.000 (0.035) loss 0.3945 (0.8256) lr 7.5000e-03 eta 0:19:54
epoch [11/30] batch [40/204] time 0.259 (0.276) data 0.001 (0.018) loss 0.8643 (0.9979) lr 7.5000e-03 eta 0:18:33
epoch [11/30] batch [60/204] time 0.262 (0.269) data 0.000 (0.012) loss 0.0548 (1.1167) lr 7.5000e-03 eta 0:18:02
epoch [11/30] batch [80/204] time 0.253 (0.266) data 0.000 (0.009) loss 0.0506 (1.0762) lr 7.5000e-03 eta 0:17:42
epoch [11/30] batch [100/204] time 0.252 (0.263) data 0.000 (0.007) loss 1.8154 (1.1185) lr 7.5000e-03 eta 0:17:26
epoch [11/30] batch [120/204] time 0.254 (0.262) data 0.001 (0.006) loss 4.2109 (1.1614) lr 7.5000e-03 eta 0:17:17
epoch [11/30] batch [140/204] time 0.248 (0.260) data 0.000 (0.005) loss 0.1406 (1.1796) lr 7.5000e-03 eta 0:17:06
epoch [11/30] batch [160/204] time 0.254 (0.260) data 0.000 (0.005) loss 0.1689 (1.1397) lr 7.5000e-03 eta 0:16:58
epoch [11/30] batch [180/204] time 0.241 (0.258) data 0.000 (0.004) loss -0.0268 (1.1330) lr 7.5000e-03 eta 0:16:47
epoch [11/30] batch [200/204] time 0.241 (0.257) data 0.000 (0.004) loss 0.2805 (1.1413) lr 7.5000e-03 eta 0:16:36
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:11,  2.49s/it]  2%|▏         | 2/102 [00:03<02:24,  1.45s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:04<00:50,  1.91it/s]  6%|▌         | 6/102 [00:04<00:41,  2.30it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.97it/s]  9%|▉         | 9/102 [00:05<00:29,  3.18it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:26,  3.49it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.67it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.74it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.79it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.80it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.88it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.88it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.87it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.88it/s] 21%|██        | 21/102 [00:08<00:21,  3.82it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.82it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.87it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.88it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.89it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.84it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.84it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.82it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.82it/s] 30%|███       | 31/102 [00:10<00:17,  4.02it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.97it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.94it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.91it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.94it/s] 35%|███▌      | 36/102 [00:12<00:16,  3.94it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.89it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.87it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.86it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.89it/s] 40%|████      | 41/102 [00:13<00:15,  3.91it/s] 41%|████      | 42/102 [00:13<00:15,  3.89it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.82it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.82it/s] 44%|████▍     | 45/102 [00:14<00:15,  3.79it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.81it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.87it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.84it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.85it/s] 50%|█████     | 51/102 [00:15<00:13,  3.89it/s] 51%|█████     | 52/102 [00:16<00:12,  3.87it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.83it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.87it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.87it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.84it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.85it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.86it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.82it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:10,  3.83it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.82it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.82it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.87it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.83it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.81it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.80it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.84it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.83it/s] 71%|███████   | 72/102 [00:21<00:07,  3.91it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.42it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.05it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.59it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.05it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.41it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.69it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.92it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,214
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/204] time 0.252 (0.297) data 0.000 (0.035) loss 0.0544 (1.1410) lr 7.0337e-03 eta 0:19:03
epoch [12/30] batch [40/204] time 0.249 (0.275) data 0.000 (0.017) loss 1.3467 (1.1281) lr 7.0337e-03 eta 0:17:36
epoch [12/30] batch [60/204] time 0.255 (0.269) data 0.000 (0.012) loss 0.6768 (1.0587) lr 7.0337e-03 eta 0:17:08
epoch [12/30] batch [80/204] time 0.251 (0.266) data 0.000 (0.009) loss 0.5142 (1.0686) lr 7.0337e-03 eta 0:16:48
epoch [12/30] batch [100/204] time 0.258 (0.264) data 0.000 (0.007) loss 0.1715 (1.1789) lr 7.0337e-03 eta 0:16:35
epoch [12/30] batch [120/204] time 0.255 (0.262) data 0.000 (0.006) loss 0.2627 (1.1492) lr 7.0337e-03 eta 0:16:24
epoch [12/30] batch [140/204] time 0.252 (0.261) data 0.000 (0.005) loss 1.4814 (1.1691) lr 7.0337e-03 eta 0:16:15
epoch [12/30] batch [160/204] time 0.254 (0.260) data 0.000 (0.005) loss 0.2595 (1.1973) lr 7.0337e-03 eta 0:16:06
epoch [12/30] batch [180/204] time 0.243 (0.259) data 0.000 (0.004) loss 1.7100 (1.2043) lr 7.0337e-03 eta 0:15:57
epoch [12/30] batch [200/204] time 0.243 (0.257) data 0.000 (0.004) loss 0.4202 (1.2080) lr 7.0337e-03 eta 0:15:46
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:18,  2.56s/it]  2%|▏         | 2/102 [00:03<02:20,  1.40s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:03,  1.55it/s]  5%|▍         | 5/102 [00:03<00:49,  1.97it/s]  6%|▌         | 6/102 [00:04<00:40,  2.36it/s]  7%|▋         | 7/102 [00:04<00:35,  2.68it/s]  8%|▊         | 8/102 [00:04<00:31,  2.99it/s]  9%|▉         | 9/102 [00:05<00:29,  3.20it/s] 10%|▉         | 10/102 [00:05<00:27,  3.36it/s] 11%|█         | 11/102 [00:05<00:25,  3.51it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.62it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.69it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.76it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.84it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.88it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.89it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.87it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.80it/s] 21%|██        | 21/102 [00:08<00:21,  3.79it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.84it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.82it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.79it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.81it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.83it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.82it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.82it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.96it/s] 30%|███       | 31/102 [00:10<00:17,  4.08it/s] 31%|███▏      | 32/102 [00:10<00:17,  4.00it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.94it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.95it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.88it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.85it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.94it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.97it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.89it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.89it/s] 40%|████      | 41/102 [00:13<00:15,  3.98it/s] 41%|████      | 42/102 [00:13<00:14,  4.27it/s] 42%|████▏     | 43/102 [00:13<00:14,  4.13it/s] 43%|████▎     | 44/102 [00:13<00:14,  4.07it/s] 44%|████▍     | 45/102 [00:14<00:14,  4.02it/s] 45%|████▌     | 46/102 [00:14<00:13,  4.00it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.90it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.92it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.94it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.90it/s] 50%|█████     | 51/102 [00:15<00:13,  3.87it/s] 51%|█████     | 52/102 [00:15<00:12,  3.91it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.92it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.89it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.88it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.86it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.87it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.85it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.83it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.82it/s] 61%|██████    | 62/102 [00:18<00:10,  3.85it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.82it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.84it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.81it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.89it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.86it/s] 68%|██████▊   | 69/102 [00:20<00:07,  4.14it/s] 69%|██████▊   | 70/102 [00:20<00:07,  4.07it/s] 70%|██████▉   | 71/102 [00:20<00:07,  4.33it/s] 71%|███████   | 72/102 [00:21<00:07,  4.23it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.62it/s] 73%|███████▎  | 74/102 [00:21<00:06,  4.56it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.16it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.68it/s] 75%|███████▌  | 77/102 [00:21<00:04,  6.13it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.49it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.75it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.97it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.12it/s] 80%|████████  | 82/102 [00:22<00:02,  7.21it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.46it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,184
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%

epoch [13/30] batch [20/204] time 0.251 (0.295) data 0.000 (0.035) loss 0.0313 (0.7230) lr 6.5451e-03 eta 0:17:55
epoch [13/30] batch [40/204] time 0.257 (0.275) data 0.000 (0.018) loss 0.1827 (0.9359) lr 6.5451e-03 eta 0:16:38
epoch [13/30] batch [60/204] time 0.257 (0.270) data 0.000 (0.012) loss 2.0449 (1.0458) lr 6.5451e-03 eta 0:16:16
epoch [13/30] batch [80/204] time 0.259 (0.266) data 0.000 (0.009) loss 0.8003 (0.9509) lr 6.5451e-03 eta 0:15:56
epoch [13/30] batch [100/204] time 0.259 (0.265) data 0.000 (0.007) loss 0.0168 (0.9813) lr 6.5451e-03 eta 0:15:45
epoch [13/30] batch [120/204] time 0.251 (0.263) data 0.000 (0.006) loss 0.0781 (1.0126) lr 6.5451e-03 eta 0:15:34
epoch [13/30] batch [140/204] time 0.261 (0.262) data 0.000 (0.005) loss 1.3184 (1.0178) lr 6.5451e-03 eta 0:15:24
epoch [13/30] batch [160/204] time 0.255 (0.262) data 0.000 (0.005) loss 0.5576 (1.0588) lr 6.5451e-03 eta 0:15:19
epoch [13/30] batch [180/204] time 0.245 (0.261) data 0.000 (0.004) loss 2.0840 (1.0400) lr 6.5451e-03 eta 0:15:10
epoch [13/30] batch [200/204] time 0.245 (0.259) data 0.000 (0.004) loss -0.0337 (1.0547) lr 6.5451e-03 eta 0:14:59
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:40,  2.78s/it]  2%|▏         | 2/102 [00:03<02:22,  1.42s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:02,  1.56it/s]  5%|▍         | 5/102 [00:04<00:49,  1.97it/s]  6%|▌         | 6/102 [00:04<00:40,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.70it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:05<00:29,  3.20it/s] 10%|▉         | 10/102 [00:05<00:27,  3.39it/s] 11%|█         | 11/102 [00:05<00:25,  3.54it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.63it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.64it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.71it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.95it/s] 16%|█▌        | 16/102 [00:06<00:20,  4.27it/s] 17%|█▋        | 17/102 [00:07<00:19,  4.34it/s] 18%|█▊        | 18/102 [00:07<00:20,  4.15it/s] 19%|█▊        | 19/102 [00:07<00:20,  4.04it/s] 20%|█▉        | 20/102 [00:07<00:19,  4.11it/s] 21%|██        | 21/102 [00:08<00:19,  4.20it/s] 22%|██▏       | 22/102 [00:08<00:19,  4.12it/s] 23%|██▎       | 23/102 [00:08<00:19,  4.03it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.94it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.89it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.88it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.89it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.91it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.98it/s] 29%|██▉       | 30/102 [00:10<00:17,  4.05it/s] 30%|███       | 31/102 [00:10<00:17,  4.02it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.94it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.88it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.93it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.89it/s] 35%|███▌      | 36/102 [00:11<00:16,  3.90it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.87it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.91it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.84it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.82it/s] 40%|████      | 41/102 [00:13<00:15,  3.84it/s] 41%|████      | 42/102 [00:13<00:15,  3.80it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.79it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.79it/s] 44%|████▍     | 45/102 [00:14<00:15,  3.79it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.80it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.82it/s] 47%|████▋     | 48/102 [00:14<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.83it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.82it/s] 50%|█████     | 51/102 [00:15<00:13,  3.83it/s] 51%|█████     | 52/102 [00:16<00:13,  3.84it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.84it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.87it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.83it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.83it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.88it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.87it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.83it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.84it/s] 61%|██████    | 62/102 [00:18<00:10,  3.86it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.89it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.86it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.88it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.87it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.83it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.85it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.90it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.92it/s] 71%|███████   | 72/102 [00:21<00:07,  3.98it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.57it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.17it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.70it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.14it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.48it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.94it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.34it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.38it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.46it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.46it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,193
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%

epoch [14/30] batch [20/204] time 0.256 (0.292) data 0.001 (0.034) loss 0.6035 (0.9051) lr 6.0396e-03 eta 0:16:45
epoch [14/30] batch [40/204] time 0.255 (0.273) data 0.000 (0.017) loss 1.8398 (0.9982) lr 6.0396e-03 eta 0:15:35
epoch [14/30] batch [60/204] time 0.259 (0.269) data 0.000 (0.012) loss 0.5688 (0.9812) lr 6.0396e-03 eta 0:15:15
epoch [14/30] batch [80/204] time 0.260 (0.265) data 0.000 (0.009) loss 0.3269 (1.0257) lr 6.0396e-03 eta 0:14:59
epoch [14/30] batch [100/204] time 0.254 (0.264) data 0.000 (0.007) loss 4.5508 (1.1117) lr 6.0396e-03 eta 0:14:47
epoch [14/30] batch [120/204] time 0.251 (0.262) data 0.000 (0.006) loss 1.9170 (1.2461) lr 6.0396e-03 eta 0:14:37
epoch [14/30] batch [140/204] time 0.249 (0.262) data 0.000 (0.005) loss -0.0350 (1.1981) lr 6.0396e-03 eta 0:14:30
epoch [14/30] batch [160/204] time 0.261 (0.261) data 0.000 (0.005) loss -0.0409 (1.1409) lr 6.0396e-03 eta 0:14:22
epoch [14/30] batch [180/204] time 0.244 (0.260) data 0.000 (0.004) loss 0.8369 (1.1110) lr 6.0396e-03 eta 0:14:14
epoch [14/30] batch [200/204] time 0.244 (0.259) data 0.000 (0.004) loss 0.5029 (1.1239) lr 6.0396e-03 eta 0:14:04
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:08,  2.46s/it]  2%|▏         | 2/102 [00:03<02:21,  1.42s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:03,  1.53it/s]  5%|▍         | 5/102 [00:03<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.68it/s]  8%|▊         | 8/102 [00:04<00:31,  2.96it/s]  9%|▉         | 9/102 [00:05<00:29,  3.20it/s] 10%|▉         | 10/102 [00:05<00:27,  3.41it/s] 11%|█         | 11/102 [00:05<00:25,  3.51it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.62it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.70it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.74it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.75it/s] 16%|█▌        | 16/102 [00:06<00:23,  3.73it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.74it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.73it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.79it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.81it/s] 21%|██        | 21/102 [00:08<00:21,  3.79it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.83it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.83it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.83it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.85it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.79it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.83it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.83it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.83it/s] 30%|███       | 31/102 [00:10<00:18,  3.87it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.83it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.81it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.81it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.82it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.83it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.80it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.86it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.85it/s] 40%|████      | 41/102 [00:13<00:15,  3.87it/s] 41%|████      | 42/102 [00:13<00:15,  3.88it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.87it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.84it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.81it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.81it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.81it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.87it/s] 50%|█████     | 51/102 [00:15<00:13,  3.89it/s] 51%|█████     | 52/102 [00:16<00:12,  3.85it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.87it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.90it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.86it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.84it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.84it/s] 58%|█████▊    | 59/102 [00:18<00:10,  3.92it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.89it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.86it/s] 61%|██████    | 62/102 [00:18<00:10,  3.89it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.88it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.88it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.85it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.89it/s] 66%|██████▌   | 67/102 [00:20<00:08,  3.90it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.86it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.87it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.90it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.90it/s] 71%|███████   | 72/102 [00:21<00:07,  4.04it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.45it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.06it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.60it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.06it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.41it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.69it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.90it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.06it/s] 79%|███████▉  | 81/102 [00:22<00:03,  6.97it/s] 80%|████████  | 82/102 [00:22<00:02,  7.11it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.21it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.28it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.33it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.36it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.38it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,218
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 90.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/204] time 0.255 (0.293) data 0.000 (0.036) loss 0.0226 (0.9231) lr 5.5226e-03 eta 0:15:50
epoch [15/30] batch [40/204] time 0.254 (0.274) data 0.000 (0.018) loss 0.1254 (0.9582) lr 5.5226e-03 eta 0:14:43
epoch [15/30] batch [60/204] time 0.248 (0.267) data 0.000 (0.012) loss 1.5918 (0.9004) lr 5.5226e-03 eta 0:14:15
epoch [15/30] batch [80/204] time 0.249 (0.265) data 0.000 (0.009) loss 1.4287 (0.8690) lr 5.5226e-03 eta 0:14:03
epoch [15/30] batch [100/204] time 0.248 (0.263) data 0.000 (0.007) loss 0.0764 (0.8221) lr 5.5226e-03 eta 0:13:52
epoch [15/30] batch [120/204] time 0.252 (0.262) data 0.000 (0.006) loss 0.2238 (0.8789) lr 5.5226e-03 eta 0:13:42
epoch [15/30] batch [140/204] time 0.255 (0.261) data 0.000 (0.005) loss -0.0149 (0.9430) lr 5.5226e-03 eta 0:13:34
epoch [15/30] batch [160/204] time 0.251 (0.260) data 0.000 (0.005) loss 2.1348 (0.9489) lr 5.5226e-03 eta 0:13:27
epoch [15/30] batch [180/204] time 0.244 (0.259) data 0.000 (0.004) loss 2.7676 (0.9595) lr 5.5226e-03 eta 0:13:18
epoch [15/30] batch [200/204] time 0.243 (0.257) data 0.000 (0.004) loss 3.4277 (0.9807) lr 5.5226e-03 eta 0:13:08
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:34,  2.72s/it]  2%|▏         | 2/102 [00:03<02:23,  1.43s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.53it/s]  5%|▍         | 5/102 [00:04<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:05<00:29,  3.16it/s] 10%|▉         | 10/102 [00:05<00:27,  3.32it/s] 11%|█         | 11/102 [00:05<00:26,  3.44it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.54it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.61it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.69it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.67it/s] 16%|█▌        | 16/102 [00:06<00:23,  3.72it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.77it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.80it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.85it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.83it/s] 21%|██        | 21/102 [00:08<00:21,  3.80it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.79it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.87it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.81it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.81it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.87it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.86it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.88it/s] 30%|███       | 31/102 [00:10<00:18,  3.85it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.88it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.85it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.85it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.88it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.88it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.87it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.85it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.87it/s] 40%|████      | 41/102 [00:13<00:15,  3.83it/s] 41%|████      | 42/102 [00:13<00:15,  3.82it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.78it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.77it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.84it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.84it/s] 46%|████▌     | 47/102 [00:15<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.84it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.83it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.83it/s] 50%|█████     | 51/102 [00:16<00:13,  3.87it/s] 51%|█████     | 52/102 [00:16<00:12,  3.91it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.84it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.83it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.84it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.87it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.84it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.83it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.85it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.89it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.96it/s] 61%|██████    | 62/102 [00:18<00:10,  3.94it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.90it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.88it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.85it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.88it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.87it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.88it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.86it/s] 71%|███████   | 72/102 [00:21<00:07,  3.90it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.40it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.01it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.56it/s] 75%|███████▍  | 76/102 [00:22<00:04,  6.02it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.39it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.67it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.88it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.04it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.15it/s] 80%|████████  | 82/102 [00:22<00:02,  7.24it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.35it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.37it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.40it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.34it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.36it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.38it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.41it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.42it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.42it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.39it/s] 96%|█████████▌| 98/102 [00:25<00:00,  7.42it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.97it/s]=> result
* total: 10,200
* correct: 9,210
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [16/30] batch [20/204] time 0.250 (0.292) data 0.000 (0.036) loss 2.8555 (0.9412) lr 5.0000e-03 eta 0:14:47
epoch [16/30] batch [40/204] time 0.253 (0.275) data 0.000 (0.018) loss 1.3633 (0.9773) lr 5.0000e-03 eta 0:13:51
epoch [16/30] batch [60/204] time 0.258 (0.269) data 0.000 (0.012) loss 3.8672 (1.0121) lr 5.0000e-03 eta 0:13:25
epoch [16/30] batch [80/204] time 0.257 (0.265) data 0.000 (0.009) loss 0.2288 (0.9022) lr 5.0000e-03 eta 0:13:09
epoch [16/30] batch [100/204] time 0.253 (0.263) data 0.000 (0.007) loss 1.0957 (0.8929) lr 5.0000e-03 eta 0:12:57
epoch [16/30] batch [120/204] time 0.252 (0.261) data 0.000 (0.006) loss 0.0272 (0.8742) lr 5.0000e-03 eta 0:12:47
epoch [16/30] batch [140/204] time 0.250 (0.260) data 0.000 (0.005) loss 0.0555 (0.9260) lr 5.0000e-03 eta 0:12:38
epoch [16/30] batch [160/204] time 0.327 (0.260) data 0.000 (0.005) loss 3.0371 (0.8920) lr 5.0000e-03 eta 0:12:33
epoch [16/30] batch [180/204] time 0.247 (0.259) data 0.000 (0.004) loss 1.7969 (0.8629) lr 5.0000e-03 eta 0:12:25
epoch [16/30] batch [200/204] time 0.242 (0.257) data 0.000 (0.004) loss 0.1919 (0.8600) lr 5.0000e-03 eta 0:12:16
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:41,  2.78s/it]  2%|▏         | 2/102 [00:03<02:21,  1.42s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:03,  1.55it/s]  5%|▍         | 5/102 [00:04<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:29,  3.14it/s]  9%|▉         | 9/102 [00:05<00:27,  3.35it/s] 10%|▉         | 10/102 [00:05<00:26,  3.53it/s] 11%|█         | 11/102 [00:05<00:25,  3.63it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.70it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.70it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.74it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.87it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.83it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.86it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.87it/s] 20%|█▉        | 20/102 [00:07<00:20,  3.98it/s] 21%|██        | 21/102 [00:08<00:20,  3.92it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.88it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.84it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.94it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.93it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.93it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.90it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.88it/s] 29%|██▉       | 30/102 [00:10<00:18,  4.00it/s] 30%|███       | 31/102 [00:10<00:17,  3.98it/s] 31%|███▏      | 32/102 [00:10<00:17,  4.02it/s] 32%|███▏      | 33/102 [00:11<00:17,  4.01it/s] 33%|███▎      | 34/102 [00:11<00:16,  4.00it/s] 34%|███▍      | 35/102 [00:11<00:16,  3.95it/s] 35%|███▌      | 36/102 [00:11<00:15,  4.31it/s] 36%|███▋      | 37/102 [00:12<00:15,  4.16it/s] 37%|███▋      | 38/102 [00:12<00:15,  4.16it/s] 38%|███▊      | 39/102 [00:12<00:15,  4.08it/s] 39%|███▉      | 40/102 [00:12<00:15,  4.03it/s] 40%|████      | 41/102 [00:13<00:15,  3.94it/s] 41%|████      | 42/102 [00:13<00:15,  3.93it/s] 42%|████▏     | 43/102 [00:13<00:14,  4.00it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.95it/s] 44%|████▍     | 45/102 [00:14<00:14,  4.03it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.95it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.88it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.88it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.92it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.94it/s] 50%|█████     | 51/102 [00:15<00:11,  4.32it/s] 51%|█████     | 52/102 [00:15<00:11,  4.24it/s] 52%|█████▏    | 53/102 [00:16<00:12,  4.05it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.97it/s] 54%|█████▍    | 55/102 [00:16<00:11,  4.05it/s] 55%|█████▍    | 56/102 [00:16<00:11,  4.02it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.99it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.94it/s] 58%|█████▊    | 59/102 [00:17<00:10,  3.97it/s] 59%|█████▉    | 60/102 [00:17<00:10,  3.90it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.94it/s] 61%|██████    | 62/102 [00:18<00:10,  3.96it/s] 62%|██████▏   | 63/102 [00:18<00:09,  3.98it/s] 63%|██████▎   | 64/102 [00:18<00:09,  3.94it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.93it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.91it/s] 66%|██████▌   | 67/102 [00:19<00:08,  3.89it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.85it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.84it/s] 69%|██████▊   | 70/102 [00:20<00:07,  4.08it/s] 70%|██████▉   | 71/102 [00:20<00:07,  4.16it/s] 71%|███████   | 72/102 [00:20<00:07,  4.14it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.67it/s] 73%|███████▎  | 74/102 [00:21<00:06,  4.51it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.07it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.61it/s] 75%|███████▌  | 77/102 [00:21<00:04,  6.06it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.42it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.69it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.90it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.06it/s] 80%|████████  | 82/102 [00:22<00:02,  7.17it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.25it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.31it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.38it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.40it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.42it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.38it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.39it/s]100%|██████████| 102/102 [00:25<00:00,  7.41it/s]100%|██████████| 102/102 [00:25<00:00,  4.05it/s]=> result
* total: 10,200
* correct: 9,198
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%

epoch [17/30] batch [20/204] time 0.261 (0.297) data 0.000 (0.035) loss 1.6895 (1.5368) lr 4.4774e-03 eta 0:14:01
epoch [17/30] batch [40/204] time 0.254 (0.278) data 0.000 (0.018) loss 0.5410 (1.0153) lr 4.4774e-03 eta 0:13:03
epoch [17/30] batch [60/204] time 0.252 (0.271) data 0.000 (0.012) loss 0.1422 (0.9353) lr 4.4774e-03 eta 0:12:36
epoch [17/30] batch [80/204] time 0.249 (0.267) data 0.000 (0.009) loss 0.2859 (0.9492) lr 4.4774e-03 eta 0:12:20
epoch [17/30] batch [100/204] time 0.256 (0.264) data 0.000 (0.007) loss 0.1487 (0.8936) lr 4.4774e-03 eta 0:12:07
epoch [17/30] batch [120/204] time 0.250 (0.262) data 0.000 (0.006) loss 3.3203 (0.8725) lr 4.4774e-03 eta 0:11:57
epoch [17/30] batch [140/204] time 0.264 (0.261) data 0.000 (0.005) loss 0.0108 (0.9160) lr 4.4774e-03 eta 0:11:50
epoch [17/30] batch [160/204] time 0.251 (0.261) data 0.000 (0.005) loss 0.2397 (0.9293) lr 4.4774e-03 eta 0:11:44
epoch [17/30] batch [180/204] time 0.244 (0.260) data 0.000 (0.004) loss 0.1821 (0.9424) lr 4.4774e-03 eta 0:11:35
epoch [17/30] batch [200/204] time 0.243 (0.258) data 0.000 (0.004) loss 0.1462 (0.9892) lr 4.4774e-03 eta 0:11:25
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:19,  2.57s/it]  2%|▏         | 2/102 [00:03<02:20,  1.40s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:04<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.65it/s]  8%|▊         | 8/102 [00:04<00:32,  2.91it/s]  9%|▉         | 9/102 [00:05<00:29,  3.13it/s] 10%|▉         | 10/102 [00:05<00:27,  3.33it/s] 11%|█         | 11/102 [00:05<00:26,  3.49it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.57it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.70it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.76it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.78it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.86it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.86it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.86it/s] 21%|██        | 21/102 [00:08<00:20,  3.88it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.86it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.87it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.87it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.85it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.82it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.89it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.86it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.81it/s] 30%|███       | 31/102 [00:10<00:18,  3.82it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.87it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.88it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.82it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.84it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.83it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.86it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.85it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.84it/s] 40%|████      | 41/102 [00:13<00:15,  3.84it/s] 41%|████      | 42/102 [00:13<00:15,  3.81it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.79it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.80it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.85it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.86it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.84it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.87it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.82it/s] 50%|█████     | 51/102 [00:15<00:13,  3.81it/s] 51%|█████     | 52/102 [00:16<00:13,  3.81it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.80it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.80it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.82it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.83it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.83it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.90it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.89it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.84it/s] 61%|██████    | 62/102 [00:18<00:10,  3.83it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.85it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.87it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.88it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.88it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.86it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.83it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.86it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.86it/s] 71%|███████   | 72/102 [00:21<00:07,  4.11it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.60it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.19it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.71it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.14it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.48it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.94it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.36it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.40it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,227
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 90.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/204] time 0.255 (0.293) data 0.000 (0.035) loss 0.1792 (0.9139) lr 3.9604e-03 eta 0:12:50
epoch [18/30] batch [40/204] time 0.256 (0.274) data 0.000 (0.017) loss 0.3484 (1.1750) lr 3.9604e-03 eta 0:11:54
epoch [18/30] batch [60/204] time 0.253 (0.269) data 0.000 (0.012) loss 0.3105 (1.2058) lr 3.9604e-03 eta 0:11:37
epoch [18/30] batch [80/204] time 0.256 (0.266) data 0.000 (0.009) loss 2.2285 (1.1319) lr 3.9604e-03 eta 0:11:23
epoch [18/30] batch [100/204] time 0.252 (0.264) data 0.000 (0.007) loss 0.2617 (1.1386) lr 3.9604e-03 eta 0:11:12
epoch [18/30] batch [120/204] time 0.251 (0.262) data 0.000 (0.006) loss 0.2563 (1.0593) lr 3.9604e-03 eta 0:11:03
epoch [18/30] batch [140/204] time 0.248 (0.261) data 0.000 (0.005) loss 0.3171 (0.9822) lr 3.9604e-03 eta 0:10:56
epoch [18/30] batch [160/204] time 0.254 (0.260) data 0.000 (0.005) loss 0.1389 (0.9665) lr 3.9604e-03 eta 0:10:48
epoch [18/30] batch [180/204] time 0.241 (0.259) data 0.000 (0.004) loss 1.2676 (0.9681) lr 3.9604e-03 eta 0:10:40
epoch [18/30] batch [200/204] time 0.246 (0.258) data 0.000 (0.004) loss 4.7930 (0.9856) lr 3.9604e-03 eta 0:10:31
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:35,  2.73s/it]  2%|▏         | 2/102 [00:03<02:22,  1.43s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.53it/s]  5%|▍         | 5/102 [00:04<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:40,  2.35it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:31,  2.97it/s]  9%|▉         | 9/102 [00:05<00:29,  3.20it/s] 10%|▉         | 10/102 [00:05<00:27,  3.36it/s] 11%|█         | 11/102 [00:05<00:26,  3.49it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.54it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.63it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.72it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.79it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.79it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.83it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.82it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.80it/s] 21%|██        | 21/102 [00:08<00:21,  3.82it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.82it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.80it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.82it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.84it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.89it/s] 27%|██▋       | 28/102 [00:10<00:18,  3.90it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.84it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.83it/s] 30%|███       | 31/102 [00:10<00:18,  3.83it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.83it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.83it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.85it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.84it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.84it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.88it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.94it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.90it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.89it/s] 40%|████      | 41/102 [00:13<00:15,  3.88it/s] 41%|████      | 42/102 [00:13<00:15,  3.90it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.87it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.82it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.83it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.85it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.87it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.85it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.87it/s] 50%|█████     | 51/102 [00:16<00:13,  3.87it/s] 51%|█████     | 52/102 [00:16<00:13,  3.83it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.84it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.84it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.88it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.90it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.89it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.85it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.89it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.88it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.87it/s] 61%|██████    | 62/102 [00:18<00:10,  3.87it/s] 62%|██████▏   | 63/102 [00:19<00:09,  3.90it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.86it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.87it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.88it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.80it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.82it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.86it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.89it/s] 71%|███████   | 72/102 [00:21<00:07,  3.98it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.49it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.09it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.63it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.07it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.42it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.69it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.90it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.05it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.16it/s] 80%|████████  | 82/102 [00:22<00:02,  7.23it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.35it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.37it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.41it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.42it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.42it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.42it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.42it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.42it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.42it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.42it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.42it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.42it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.41it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.40it/s]100%|██████████| 102/102 [00:25<00:00,  7.41it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,205
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%

epoch [19/30] batch [20/204] time 0.255 (0.294) data 0.000 (0.035) loss 0.7939 (0.8330) lr 3.4549e-03 eta 0:11:55
epoch [19/30] batch [40/204] time 0.255 (0.277) data 0.000 (0.017) loss 0.8906 (0.7759) lr 3.4549e-03 eta 0:11:05
epoch [19/30] batch [60/204] time 0.260 (0.271) data 0.000 (0.012) loss 2.3555 (0.7820) lr 3.4549e-03 eta 0:10:46
epoch [19/30] batch [80/204] time 0.255 (0.266) data 0.000 (0.009) loss 0.1360 (0.7749) lr 3.4549e-03 eta 0:10:30
epoch [19/30] batch [100/204] time 0.258 (0.264) data 0.001 (0.007) loss 2.8340 (0.8015) lr 3.4549e-03 eta 0:10:20
epoch [19/30] batch [120/204] time 0.256 (0.263) data 0.000 (0.006) loss 0.6460 (0.8557) lr 3.4549e-03 eta 0:10:12
epoch [19/30] batch [140/204] time 0.255 (0.262) data 0.000 (0.005) loss 0.1411 (0.8347) lr 3.4549e-03 eta 0:10:03
epoch [19/30] batch [160/204] time 0.252 (0.261) data 0.000 (0.005) loss 0.4143 (0.8986) lr 3.4549e-03 eta 0:09:56
epoch [19/30] batch [180/204] time 0.246 (0.260) data 0.000 (0.004) loss 0.5508 (0.9106) lr 3.4549e-03 eta 0:09:49
epoch [19/30] batch [200/204] time 0.242 (0.258) data 0.000 (0.004) loss 0.7871 (0.8945) lr 3.4549e-03 eta 0:09:40
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:02,  2.40s/it]  2%|▏         | 2/102 [00:02<02:09,  1.30s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:05,  1.49it/s]  5%|▍         | 5/102 [00:03<00:51,  1.89it/s]  6%|▌         | 6/102 [00:04<00:42,  2.26it/s]  7%|▋         | 7/102 [00:04<00:36,  2.63it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:05<00:29,  3.13it/s] 10%|▉         | 10/102 [00:05<00:27,  3.34it/s] 11%|█         | 11/102 [00:05<00:26,  3.46it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.58it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.68it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.69it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.72it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.76it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.78it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.83it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.85it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.83it/s] 21%|██        | 21/102 [00:08<00:21,  3.85it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.86it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.84it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.84it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.88it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.84it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.86it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.85it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.86it/s] 30%|███       | 31/102 [00:10<00:18,  3.85it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.88it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.88it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.87it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.86it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.88it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.87it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.90it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.91it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.86it/s] 40%|████      | 41/102 [00:13<00:15,  3.85it/s] 41%|████      | 42/102 [00:13<00:15,  3.88it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.86it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.88it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.86it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.83it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.87it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.83it/s] 50%|█████     | 51/102 [00:15<00:12,  4.24it/s] 51%|█████     | 52/102 [00:15<00:10,  4.60it/s] 52%|█████▏    | 53/102 [00:16<00:11,  4.39it/s] 53%|█████▎    | 54/102 [00:16<00:11,  4.19it/s] 54%|█████▍    | 55/102 [00:16<00:11,  4.07it/s] 55%|█████▍    | 56/102 [00:17<00:11,  4.04it/s] 56%|█████▌    | 57/102 [00:17<00:11,  4.08it/s] 57%|█████▋    | 58/102 [00:17<00:10,  4.02it/s] 58%|█████▊    | 59/102 [00:17<00:10,  3.98it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.99it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.97it/s] 61%|██████    | 62/102 [00:18<00:10,  3.92it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.87it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.89it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.88it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.85it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.82it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.83it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.90it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.86it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.90it/s] 71%|███████   | 72/102 [00:21<00:07,  4.08it/s] 72%|███████▏  | 73/102 [00:21<00:07,  4.13it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.68it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.26it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.76it/s] 75%|███████▌  | 77/102 [00:21<00:04,  6.18it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.34it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.64it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.87it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.03it/s] 80%|████████  | 82/102 [00:22<00:02,  7.14it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.22it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.28it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.32it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.35it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.38it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.40it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.41it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.42it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.42it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.02it/s]=> result
* total: 10,200
* correct: 9,211
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [20/30] batch [20/204] time 0.251 (0.298) data 0.001 (0.036) loss 0.4548 (1.0211) lr 2.9663e-03 eta 0:11:01
epoch [20/30] batch [40/204] time 0.259 (0.277) data 0.000 (0.018) loss 1.3262 (0.7306) lr 2.9663e-03 eta 0:10:10
epoch [20/30] batch [60/204] time 0.259 (0.270) data 0.000 (0.012) loss 0.1025 (0.8914) lr 2.9663e-03 eta 0:09:50
epoch [20/30] batch [80/204] time 0.260 (0.266) data 0.000 (0.009) loss 0.3401 (0.9647) lr 2.9663e-03 eta 0:09:36
epoch [20/30] batch [100/204] time 0.247 (0.264) data 0.000 (0.007) loss 0.0758 (0.9635) lr 2.9663e-03 eta 0:09:25
epoch [20/30] batch [120/204] time 0.251 (0.263) data 0.000 (0.006) loss 0.1876 (1.0193) lr 2.9663e-03 eta 0:09:18
epoch [20/30] batch [140/204] time 0.255 (0.262) data 0.000 (0.005) loss 0.2786 (1.0143) lr 2.9663e-03 eta 0:09:10
epoch [20/30] batch [160/204] time 0.254 (0.261) data 0.000 (0.005) loss -0.0336 (1.0261) lr 2.9663e-03 eta 0:09:04
epoch [20/30] batch [180/204] time 0.244 (0.260) data 0.000 (0.004) loss 0.2583 (1.0558) lr 2.9663e-03 eta 0:08:57
epoch [20/30] batch [200/204] time 0.244 (0.259) data 0.000 (0.004) loss 0.7734 (1.0591) lr 2.9663e-03 eta 0:08:48
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:10,  2.48s/it]  2%|▏         | 2/102 [00:02<02:09,  1.30s/it]  3%|▎         | 3/102 [00:03<01:32,  1.07it/s]  4%|▍         | 4/102 [00:03<01:05,  1.49it/s]  5%|▍         | 5/102 [00:03<00:50,  1.92it/s]  6%|▌         | 6/102 [00:04<00:41,  2.30it/s]  7%|▋         | 7/102 [00:04<00:35,  2.64it/s]  8%|▊         | 8/102 [00:04<00:31,  2.94it/s]  9%|▉         | 9/102 [00:05<00:29,  3.18it/s] 10%|▉         | 10/102 [00:05<00:27,  3.35it/s] 11%|█         | 11/102 [00:05<00:26,  3.50it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.59it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.69it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.74it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.80it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.83it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.80it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.86it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.87it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.87it/s] 21%|██        | 21/102 [00:08<00:20,  4.00it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.93it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.89it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.89it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.91it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.92it/s] 26%|██▋       | 27/102 [00:09<00:18,  4.12it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.99it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.94it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.88it/s] 30%|███       | 31/102 [00:10<00:18,  3.89it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.89it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.90it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.90it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.86it/s] 35%|███▌      | 36/102 [00:11<00:16,  3.93it/s] 36%|███▋      | 37/102 [00:12<00:15,  4.12it/s] 37%|███▋      | 38/102 [00:12<00:15,  4.06it/s] 38%|███▊      | 39/102 [00:12<00:15,  3.98it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.96it/s] 40%|████      | 41/102 [00:13<00:15,  3.95it/s] 41%|████      | 42/102 [00:13<00:15,  3.90it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.87it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.84it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.83it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.84it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.87it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.86it/s] 50%|█████     | 51/102 [00:15<00:13,  3.88it/s] 51%|█████     | 52/102 [00:16<00:13,  3.83it/s] 52%|█████▏    | 53/102 [00:16<00:13,  3.76it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.78it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.80it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.82it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.82it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.83it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.82it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.84it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.88it/s] 61%|██████    | 62/102 [00:18<00:10,  3.85it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.84it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.89it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.90it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.87it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.85it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.89it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.90it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.95it/s] 71%|███████   | 72/102 [00:21<00:07,  3.96it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.55it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.15it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.68it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.11it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.45it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.73it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.94it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.39it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.42it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.15it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.24it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.29it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.34it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.38it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.39it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.41it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.42it/s]100%|██████████| 102/102 [00:25<00:00,  7.42it/s]100%|██████████| 102/102 [00:25<00:00,  4.01it/s]=> result
* total: 10,200
* correct: 9,192
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/204] time 0.258 (0.292) data 0.000 (0.036) loss 0.5654 (1.3669) lr 2.5000e-03 eta 0:09:49
epoch [21/30] batch [40/204] time 0.251 (0.275) data 0.000 (0.018) loss 0.1045 (1.2884) lr 2.5000e-03 eta 0:09:09
epoch [21/30] batch [60/204] time 0.254 (0.268) data 0.000 (0.012) loss 2.0273 (1.2240) lr 2.5000e-03 eta 0:08:50
epoch [21/30] batch [80/204] time 0.255 (0.265) data 0.000 (0.009) loss 1.1777 (1.2001) lr 2.5000e-03 eta 0:08:39
epoch [21/30] batch [100/204] time 0.251 (0.263) data 0.000 (0.008) loss 1.5693 (1.1175) lr 2.5000e-03 eta 0:08:30
epoch [21/30] batch [120/204] time 0.258 (0.262) data 0.000 (0.006) loss 1.6924 (1.1008) lr 2.5000e-03 eta 0:08:23
epoch [21/30] batch [140/204] time 0.268 (0.261) data 0.000 (0.005) loss 0.0373 (1.0282) lr 2.5000e-03 eta 0:08:16
epoch [21/30] batch [160/204] time 0.255 (0.261) data 0.000 (0.005) loss -0.0335 (0.9565) lr 2.5000e-03 eta 0:08:10
epoch [21/30] batch [180/204] time 0.242 (0.259) data 0.000 (0.004) loss 0.3513 (0.9517) lr 2.5000e-03 eta 0:08:02
epoch [21/30] batch [200/204] time 0.243 (0.258) data 0.000 (0.004) loss 0.3125 (0.9512) lr 2.5000e-03 eta 0:07:54
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:08,  2.46s/it]  2%|▏         | 2/102 [00:03<02:15,  1.35s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:03<00:50,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.96it/s]  9%|▉         | 9/102 [00:05<00:29,  3.14it/s] 10%|▉         | 10/102 [00:05<00:27,  3.35it/s] 11%|█         | 11/102 [00:05<00:26,  3.49it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.56it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.63it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.71it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.74it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.77it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.79it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.82it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.81it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.80it/s] 21%|██        | 21/102 [00:08<00:21,  3.79it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.83it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.81it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.83it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.87it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.80it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.80it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.84it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.87it/s] 30%|███       | 31/102 [00:10<00:18,  3.86it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.85it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.80it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.86it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.87it/s] 35%|███▌      | 36/102 [00:12<00:16,  3.90it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.85it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.89it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.82it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.83it/s] 40%|████      | 41/102 [00:13<00:15,  3.85it/s] 41%|████      | 42/102 [00:13<00:15,  3.83it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.84it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.81it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.80it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.82it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.89it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.88it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.84it/s] 50%|█████     | 51/102 [00:15<00:13,  3.86it/s] 51%|█████     | 52/102 [00:16<00:12,  3.90it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.88it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.85it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.83it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.87it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.83it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.83it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.91it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.92it/s] 61%|██████    | 62/102 [00:18<00:10,  3.91it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.83it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.85it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.90it/s] 66%|██████▌   | 67/102 [00:20<00:08,  3.90it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.89it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.86it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.83it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.84it/s] 71%|███████   | 72/102 [00:21<00:07,  3.91it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.47it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.08it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.62it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.07it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.43it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.71it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.92it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.15it/s] 80%|████████  | 82/102 [00:22<00:02,  7.23it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.30it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.43it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.47it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.48it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.47it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.47it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.46it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,210
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [22/30] batch [20/204] time 0.249 (0.291) data 0.000 (0.035) loss 1.1436 (0.6810) lr 2.0611e-03 eta 0:08:47
epoch [22/30] batch [40/204] time 0.251 (0.272) data 0.000 (0.017) loss 0.0591 (0.8410) lr 2.0611e-03 eta 0:08:08
epoch [22/30] batch [60/204] time 0.252 (0.268) data 0.000 (0.012) loss 0.0965 (0.8387) lr 2.0611e-03 eta 0:07:55
epoch [22/30] batch [80/204] time 0.255 (0.264) data 0.000 (0.009) loss 0.9980 (0.8935) lr 2.0611e-03 eta 0:07:43
epoch [22/30] batch [100/204] time 0.253 (0.262) data 0.000 (0.007) loss 0.6343 (0.9329) lr 2.0611e-03 eta 0:07:34
epoch [22/30] batch [120/204] time 0.256 (0.260) data 0.000 (0.006) loss 3.6289 (0.9675) lr 2.0611e-03 eta 0:07:26
epoch [22/30] batch [140/204] time 0.249 (0.259) data 0.000 (0.005) loss 0.2338 (0.9561) lr 2.0611e-03 eta 0:07:19
epoch [22/30] batch [160/204] time 0.262 (0.259) data 0.000 (0.005) loss 2.1152 (0.9814) lr 2.0611e-03 eta 0:07:13
epoch [22/30] batch [180/204] time 0.246 (0.258) data 0.000 (0.004) loss 0.8369 (1.0158) lr 2.0611e-03 eta 0:07:07
epoch [22/30] batch [200/204] time 0.242 (0.257) data 0.000 (0.004) loss 0.5752 (1.0367) lr 2.0611e-03 eta 0:06:59
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:02,  2.40s/it]  2%|▏         | 2/102 [00:02<02:14,  1.34s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:03<00:50,  1.92it/s]  6%|▌         | 6/102 [00:04<00:41,  2.30it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.94it/s]  9%|▉         | 9/102 [00:04<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.38it/s] 11%|█         | 11/102 [00:05<00:26,  3.50it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.59it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.67it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.72it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.83it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.81it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.83it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.91it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.87it/s] 21%|██        | 21/102 [00:08<00:21,  3.85it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.85it/s] 23%|██▎       | 23/102 [00:08<00:19,  4.02it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.96it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.92it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.90it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.90it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.91it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.88it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.90it/s] 30%|███       | 31/102 [00:10<00:18,  3.87it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.84it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.87it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.89it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.90it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.85it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.78it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.79it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.78it/s] 40%|████      | 41/102 [00:13<00:16,  3.80it/s] 41%|████      | 42/102 [00:13<00:15,  3.78it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.82it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.84it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.85it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.81it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.77it/s] 48%|████▊     | 49/102 [00:15<00:14,  3.78it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.79it/s] 50%|█████     | 51/102 [00:15<00:13,  3.84it/s] 51%|█████     | 52/102 [00:16<00:12,  3.86it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.84it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.85it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.88it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.92it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.88it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.90it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.90it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.87it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.89it/s] 61%|██████    | 62/102 [00:18<00:10,  3.79it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.81it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.84it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.84it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.85it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.88it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.89it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.87it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.87it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.84it/s] 71%|███████   | 72/102 [00:21<00:07,  4.06it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.58it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.18it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.70it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.13it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.47it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.72it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.93it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.16it/s] 80%|████████  | 82/102 [00:22<00:02,  7.24it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.01it/s]=> result
* total: 10,200
* correct: 9,228
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 90.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [23/30] batch [20/204] time 0.251 (0.293) data 0.000 (0.037) loss 0.8643 (0.6895) lr 1.6543e-03 eta 0:07:52
epoch [23/30] batch [40/204] time 0.264 (0.277) data 0.000 (0.019) loss 4.2891 (1.0169) lr 1.6543e-03 eta 0:07:20
epoch [23/30] batch [60/204] time 0.265 (0.270) data 0.000 (0.013) loss -0.0429 (0.9978) lr 1.6543e-03 eta 0:07:04
epoch [23/30] batch [80/204] time 0.250 (0.266) data 0.000 (0.009) loss 0.0609 (0.9408) lr 1.6543e-03 eta 0:06:52
epoch [23/30] batch [100/204] time 0.259 (0.264) data 0.000 (0.008) loss 1.0996 (0.9696) lr 1.6543e-03 eta 0:06:43
epoch [23/30] batch [120/204] time 0.256 (0.262) data 0.001 (0.006) loss 4.7812 (0.9041) lr 1.6543e-03 eta 0:06:36
epoch [23/30] batch [140/204] time 0.251 (0.261) data 0.000 (0.006) loss 2.2285 (0.9721) lr 1.6543e-03 eta 0:06:29
epoch [23/30] batch [160/204] time 0.259 (0.260) data 0.000 (0.005) loss 0.6982 (0.9324) lr 1.6543e-03 eta 0:06:23
epoch [23/30] batch [180/204] time 0.242 (0.259) data 0.000 (0.004) loss 1.6299 (0.9617) lr 1.6543e-03 eta 0:06:16
epoch [23/30] batch [200/204] time 0.241 (0.258) data 0.000 (0.004) loss 0.0525 (0.9419) lr 1.6543e-03 eta 0:06:09
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:22,  2.60s/it]  2%|▏         | 2/102 [00:03<02:22,  1.43s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:04<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:31,  2.96it/s]  9%|▉         | 9/102 [00:05<00:29,  3.19it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:25,  3.51it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.58it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.68it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.72it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.74it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.78it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.80it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.84it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.83it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.86it/s] 21%|██        | 21/102 [00:08<00:20,  3.90it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.92it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.83it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.84it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.90it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.86it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.93it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.89it/s] 29%|██▉       | 30/102 [00:10<00:17,  4.03it/s] 30%|███       | 31/102 [00:10<00:16,  4.25it/s] 31%|███▏      | 32/102 [00:10<00:16,  4.16it/s] 32%|███▏      | 33/102 [00:11<00:16,  4.23it/s] 33%|███▎      | 34/102 [00:11<00:16,  4.07it/s] 34%|███▍      | 35/102 [00:11<00:15,  4.30it/s] 35%|███▌      | 36/102 [00:11<00:15,  4.26it/s] 36%|███▋      | 37/102 [00:12<00:14,  4.41it/s] 37%|███▋      | 38/102 [00:12<00:15,  4.22it/s] 38%|███▊      | 39/102 [00:12<00:15,  4.07it/s] 39%|███▉      | 40/102 [00:12<00:15,  4.02it/s] 40%|████      | 41/102 [00:13<00:14,  4.22it/s] 41%|████      | 42/102 [00:13<00:14,  4.10it/s] 42%|████▏     | 43/102 [00:13<00:14,  4.04it/s] 43%|████▎     | 44/102 [00:13<00:14,  4.01it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.95it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.97it/s] 46%|████▌     | 47/102 [00:14<00:13,  3.94it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.93it/s] 48%|████▊     | 49/102 [00:15<00:13,  4.03it/s] 49%|████▉     | 50/102 [00:15<00:13,  4.00it/s] 50%|█████     | 51/102 [00:15<00:12,  3.98it/s] 51%|█████     | 52/102 [00:15<00:12,  4.04it/s] 52%|█████▏    | 53/102 [00:16<00:11,  4.25it/s] 53%|█████▎    | 54/102 [00:16<00:11,  4.09it/s] 54%|█████▍    | 55/102 [00:16<00:11,  4.03it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.97it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.96it/s] 57%|█████▋    | 58/102 [00:17<00:10,  4.01it/s] 58%|█████▊    | 59/102 [00:17<00:10,  3.99it/s] 59%|█████▉    | 60/102 [00:17<00:10,  3.94it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.97it/s] 61%|██████    | 62/102 [00:18<00:10,  3.92it/s] 62%|██████▏   | 63/102 [00:18<00:09,  3.91it/s] 63%|██████▎   | 64/102 [00:18<00:08,  4.26it/s] 64%|██████▎   | 65/102 [00:19<00:08,  4.18it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.09it/s] 66%|██████▌   | 67/102 [00:19<00:08,  4.03it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.95it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.92it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.92it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.92it/s] 71%|███████   | 72/102 [00:20<00:06,  4.35it/s] 72%|███████▏  | 73/102 [00:20<00:06,  4.36it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.79it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.37it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.87it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.28it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.59it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.84it/s] 78%|███████▊  | 80/102 [00:21<00:03,  7.02it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.14it/s] 80%|████████  | 82/102 [00:22<00:02,  7.23it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.28it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:23<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.43it/s]100%|██████████| 102/102 [00:24<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.07it/s]=> result
* total: 10,200
* correct: 9,211
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [24/30] batch [20/204] time 0.253 (0.296) data 0.000 (0.036) loss 0.6133 (0.6807) lr 1.2843e-03 eta 0:06:56
epoch [24/30] batch [40/204] time 0.254 (0.275) data 0.000 (0.018) loss 0.4402 (0.8235) lr 1.2843e-03 eta 0:06:22
epoch [24/30] batch [60/204] time 0.353 (0.270) data 0.000 (0.012) loss 0.3091 (0.8716) lr 1.2843e-03 eta 0:06:09
epoch [24/30] batch [80/204] time 0.255 (0.266) data 0.000 (0.009) loss 0.6016 (0.8601) lr 1.2843e-03 eta 0:05:59
epoch [24/30] batch [100/204] time 0.255 (0.264) data 0.000 (0.007) loss 0.4648 (0.8340) lr 1.2843e-03 eta 0:05:50
epoch [24/30] batch [120/204] time 0.253 (0.263) data 0.000 (0.006) loss 0.0798 (0.8596) lr 1.2843e-03 eta 0:05:43
epoch [24/30] batch [140/204] time 0.241 (0.261) data 0.000 (0.005) loss 0.0894 (0.8909) lr 1.2843e-03 eta 0:05:36
epoch [24/30] batch [160/204] time 0.251 (0.260) data 0.000 (0.005) loss 1.5967 (0.9348) lr 1.2843e-03 eta 0:05:30
epoch [24/30] batch [180/204] time 0.243 (0.260) data 0.000 (0.004) loss 0.0152 (0.9515) lr 1.2843e-03 eta 0:05:23
epoch [24/30] batch [200/204] time 0.244 (0.258) data 0.000 (0.004) loss 0.4551 (0.9563) lr 1.2843e-03 eta 0:05:16
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:17,  2.55s/it]  2%|▏         | 2/102 [00:03<02:20,  1.41s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.54it/s]  5%|▍         | 5/102 [00:03<00:49,  1.96it/s]  6%|▌         | 6/102 [00:04<00:41,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:31,  3.02it/s]  9%|▉         | 9/102 [00:04<00:28,  3.29it/s] 10%|▉         | 10/102 [00:05<00:26,  3.53it/s] 11%|█         | 11/102 [00:05<00:24,  3.69it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.73it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.74it/s] 14%|█▎        | 14/102 [00:06<00:22,  3.84it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.86it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.91it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.90it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.90it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.89it/s] 20%|█▉        | 20/102 [00:07<00:20,  3.97it/s] 21%|██        | 21/102 [00:08<00:20,  3.96it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.97it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.91it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.93it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.88it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.95it/s] 26%|██▋       | 27/102 [00:09<00:18,  3.96it/s] 27%|██▋       | 28/102 [00:09<00:17,  4.32it/s] 28%|██▊       | 29/102 [00:09<00:16,  4.33it/s] 29%|██▉       | 30/102 [00:10<00:17,  4.24it/s] 30%|███       | 31/102 [00:10<00:17,  4.03it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.95it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.89it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.80it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.81it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.86it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.86it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.86it/s] 40%|████      | 41/102 [00:13<00:15,  3.83it/s] 41%|████      | 42/102 [00:13<00:15,  3.81it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.84it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.84it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.88it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.86it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.84it/s] 47%|████▋     | 48/102 [00:14<00:14,  3.85it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.82it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.82it/s] 50%|█████     | 51/102 [00:15<00:13,  3.79it/s] 51%|█████     | 52/102 [00:15<00:13,  3.83it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.82it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.87it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.85it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.80it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.84it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.85it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.89it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.86it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.90it/s] 61%|██████    | 62/102 [00:18<00:10,  3.92it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.80it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.80it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.83it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.80it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.80it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.86it/s] 71%|███████   | 72/102 [00:21<00:07,  3.92it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.48it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.09it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.63it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.08it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.43it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.72it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.95it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.21it/s] 80%|████████  | 82/102 [00:22<00:02,  7.28it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.38it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.40it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.44it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.45it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.47it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.47it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.47it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.48it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.47it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.47it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.47it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.48it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.47it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.48it/s]100%|██████████| 102/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,198
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%

epoch [25/30] batch [20/204] time 0.256 (0.293) data 0.000 (0.034) loss 0.0701 (0.5207) lr 9.5492e-04 eta 0:05:52
epoch [25/30] batch [40/204] time 0.258 (0.274) data 0.000 (0.017) loss 0.0750 (0.8312) lr 9.5492e-04 eta 0:05:23
epoch [25/30] batch [60/204] time 0.263 (0.269) data 0.000 (0.012) loss 0.6138 (0.8769) lr 9.5492e-04 eta 0:05:13
epoch [25/30] batch [80/204] time 0.257 (0.266) data 0.000 (0.009) loss -0.0054 (0.9370) lr 9.5492e-04 eta 0:05:03
epoch [25/30] batch [100/204] time 0.250 (0.264) data 0.000 (0.007) loss 1.5977 (0.9830) lr 9.5492e-04 eta 0:04:56
epoch [25/30] batch [120/204] time 0.249 (0.263) data 0.000 (0.006) loss -0.0036 (0.9486) lr 9.5492e-04 eta 0:04:50
epoch [25/30] batch [140/204] time 0.254 (0.262) data 0.000 (0.005) loss 0.0961 (1.0236) lr 9.5492e-04 eta 0:04:44
epoch [25/30] batch [160/204] time 0.259 (0.261) data 0.000 (0.004) loss 0.0854 (0.9660) lr 9.5492e-04 eta 0:04:37
epoch [25/30] batch [180/204] time 0.244 (0.260) data 0.000 (0.004) loss 1.7910 (0.9558) lr 9.5492e-04 eta 0:04:31
epoch [25/30] batch [200/204] time 0.243 (0.259) data 0.000 (0.004) loss 2.2461 (0.9755) lr 9.5492e-04 eta 0:04:24
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:22,  2.60s/it]  2%|▏         | 2/102 [00:03<02:19,  1.39s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:02,  1.56it/s]  5%|▍         | 5/102 [00:03<00:49,  1.97it/s]  6%|▌         | 6/102 [00:04<00:40,  2.36it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:05<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:26,  3.47it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.56it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.79it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.80it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.83it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.82it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.77it/s] 21%|██        | 21/102 [00:08<00:21,  3.79it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.79it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.85it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.83it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.87it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.85it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.84it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.82it/s] 30%|███       | 31/102 [00:10<00:18,  3.82it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.84it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.85it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.87it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.86it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.85it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.85it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.80it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.85it/s] 40%|████      | 41/102 [00:13<00:15,  3.88it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.84it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.85it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.85it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.89it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.88it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.87it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.85it/s] 50%|█████     | 51/102 [00:15<00:12,  3.92it/s] 51%|█████     | 52/102 [00:16<00:12,  3.90it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.87it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.88it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.87it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.88it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.91it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.88it/s] 59%|█████▉    | 60/102 [00:18<00:11,  3.81it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.91it/s] 61%|██████    | 62/102 [00:18<00:10,  3.92it/s] 62%|██████▏   | 63/102 [00:19<00:09,  3.94it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.91it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.93it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.90it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.82it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.81it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.83it/s] 71%|███████   | 72/102 [00:21<00:07,  3.88it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.47it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.09it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.63it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.08it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.45it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.72it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.91it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.20it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.34it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.38it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.48it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.47it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.48it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.47it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,208
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [26/30] batch [20/204] time 0.258 (0.294) data 0.000 (0.035) loss 2.9551 (1.0647) lr 6.6987e-04 eta 0:04:54
epoch [26/30] batch [40/204] time 0.255 (0.274) data 0.000 (0.018) loss 0.6562 (0.8728) lr 6.6987e-04 eta 0:04:28
epoch [26/30] batch [60/204] time 0.254 (0.268) data 0.000 (0.012) loss 0.8784 (1.0844) lr 6.6987e-04 eta 0:04:17
epoch [26/30] batch [80/204] time 0.251 (0.266) data 0.000 (0.009) loss 1.0029 (1.0124) lr 6.6987e-04 eta 0:04:10
epoch [26/30] batch [100/204] time 0.265 (0.264) data 0.000 (0.007) loss 0.1576 (1.0522) lr 6.6987e-04 eta 0:04:02
epoch [26/30] batch [120/204] time 0.250 (0.262) data 0.000 (0.006) loss 0.3704 (1.0761) lr 6.6987e-04 eta 0:03:55
epoch [26/30] batch [140/204] time 0.248 (0.261) data 0.000 (0.005) loss 2.7285 (1.0774) lr 6.6987e-04 eta 0:03:49
epoch [26/30] batch [160/204] time 0.254 (0.260) data 0.000 (0.005) loss 4.0586 (1.0723) lr 6.6987e-04 eta 0:03:43
epoch [26/30] batch [180/204] time 0.247 (0.259) data 0.000 (0.004) loss 0.4326 (1.0429) lr 6.6987e-04 eta 0:03:37
epoch [26/30] batch [200/204] time 0.242 (0.258) data 0.000 (0.004) loss 0.2234 (0.9995) lr 6.6987e-04 eta 0:03:31
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<03:58,  2.36s/it]  2%|▏         | 2/102 [00:02<02:13,  1.33s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:03,  1.54it/s]  5%|▍         | 5/102 [00:03<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.30it/s]  7%|▋         | 7/102 [00:04<00:36,  2.62it/s]  8%|▊         | 8/102 [00:04<00:32,  2.90it/s]  9%|▉         | 9/102 [00:04<00:29,  3.14it/s] 10%|▉         | 10/102 [00:05<00:27,  3.35it/s] 11%|█         | 11/102 [00:05<00:26,  3.49it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.57it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.63it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.67it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.76it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.75it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.76it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.76it/s] 19%|█▊        | 19/102 [00:07<00:22,  3.75it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.77it/s] 21%|██        | 21/102 [00:08<00:21,  3.82it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.79it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.79it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.81it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.83it/s] 25%|██▌       | 26/102 [00:09<00:20,  3.80it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.83it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.87it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.82it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.82it/s] 30%|███       | 31/102 [00:10<00:18,  3.80it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.80it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.87it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.87it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.85it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.84it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.84it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.83it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.83it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.84it/s] 40%|████      | 41/102 [00:13<00:15,  3.83it/s] 41%|████      | 42/102 [00:13<00:15,  3.87it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.84it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.82it/s] 44%|████▍     | 45/102 [00:14<00:15,  3.78it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.78it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.82it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.84it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.85it/s] 50%|█████     | 51/102 [00:15<00:13,  3.83it/s] 51%|█████     | 52/102 [00:16<00:13,  3.83it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.84it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.87it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.81it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.85it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.80it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.82it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.84it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.89it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.90it/s] 61%|██████    | 62/102 [00:18<00:10,  3.89it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.90it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.86it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.90it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.84it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.82it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.87it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.87it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.85it/s] 71%|███████   | 72/102 [00:21<00:07,  3.92it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.55it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.16it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.69it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.12it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.47it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.75it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.95it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.20it/s] 80%|████████  | 82/102 [00:22<00:02,  7.29it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.34it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.38it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.42it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.43it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.44it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.46it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.46it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.46it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.46it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.47it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.47it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.48it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.25it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.31it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.35it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.39it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.41it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.42it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,212
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [27/30] batch [20/204] time 0.253 (0.293) data 0.000 (0.035) loss 0.9478 (1.5275) lr 4.3227e-04 eta 0:03:53
epoch [27/30] batch [40/204] time 0.252 (0.276) data 0.000 (0.018) loss 1.6797 (1.1931) lr 4.3227e-04 eta 0:03:33
epoch [27/30] batch [60/204] time 0.253 (0.268) data 0.000 (0.012) loss 0.7529 (1.1224) lr 4.3227e-04 eta 0:03:22
epoch [27/30] batch [80/204] time 0.256 (0.265) data 0.000 (0.009) loss -0.0269 (1.0313) lr 4.3227e-04 eta 0:03:15
epoch [27/30] batch [100/204] time 0.252 (0.264) data 0.000 (0.007) loss 2.0977 (1.0269) lr 4.3227e-04 eta 0:03:08
epoch [27/30] batch [120/204] time 0.251 (0.263) data 0.000 (0.006) loss 2.4746 (1.0065) lr 4.3227e-04 eta 0:03:02
epoch [27/30] batch [140/204] time 0.257 (0.261) data 0.000 (0.005) loss 0.6963 (1.0417) lr 4.3227e-04 eta 0:02:56
epoch [27/30] batch [160/204] time 0.256 (0.261) data 0.000 (0.005) loss 1.1689 (0.9793) lr 4.3227e-04 eta 0:02:51
epoch [27/30] batch [180/204] time 0.243 (0.260) data 0.000 (0.004) loss 2.4883 (0.9800) lr 4.3227e-04 eta 0:02:45
epoch [27/30] batch [200/204] time 0.243 (0.258) data 0.000 (0.004) loss 1.5771 (0.9963) lr 4.3227e-04 eta 0:02:39
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:12,  2.50s/it]  2%|▏         | 2/102 [00:03<02:16,  1.36s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:03<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.31it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.97it/s]  9%|▉         | 9/102 [00:04<00:28,  3.24it/s] 10%|▉         | 10/102 [00:05<00:26,  3.47it/s] 11%|█         | 11/102 [00:05<00:24,  3.77it/s] 12%|█▏        | 12/102 [00:05<00:22,  3.96it/s] 13%|█▎        | 13/102 [00:05<00:22,  3.94it/s] 14%|█▎        | 14/102 [00:06<00:22,  3.88it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.88it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.90it/s] 17%|█▋        | 17/102 [00:06<00:21,  3.90it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.87it/s] 19%|█▊        | 19/102 [00:07<00:20,  4.09it/s] 20%|█▉        | 20/102 [00:07<00:20,  4.01it/s] 21%|██        | 21/102 [00:07<00:19,  4.17it/s] 22%|██▏       | 22/102 [00:08<00:19,  4.03it/s] 23%|██▎       | 23/102 [00:08<00:18,  4.30it/s] 24%|██▎       | 24/102 [00:08<00:18,  4.17it/s] 25%|██▍       | 25/102 [00:08<00:18,  4.11it/s] 25%|██▌       | 26/102 [00:09<00:18,  4.13it/s] 26%|██▋       | 27/102 [00:09<00:18,  4.11it/s] 27%|██▋       | 28/102 [00:09<00:18,  4.03it/s] 28%|██▊       | 29/102 [00:09<00:18,  3.97it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.93it/s] 30%|███       | 31/102 [00:10<00:18,  3.94it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.93it/s] 32%|███▏      | 33/102 [00:10<00:17,  3.92it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.90it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.94it/s] 35%|███▌      | 36/102 [00:11<00:16,  3.93it/s] 36%|███▋      | 37/102 [00:11<00:16,  3.89it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.96it/s] 38%|███▊      | 39/102 [00:12<00:15,  3.94it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.95it/s] 40%|████      | 41/102 [00:12<00:15,  3.93it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.89it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.92it/s] 44%|████▍     | 45/102 [00:13<00:14,  3.95it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.94it/s] 46%|████▌     | 47/102 [00:14<00:13,  4.05it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.99it/s] 48%|████▊     | 49/102 [00:14<00:13,  4.06it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.97it/s] 50%|█████     | 51/102 [00:15<00:12,  4.02it/s] 51%|█████     | 52/102 [00:15<00:12,  3.94it/s] 52%|█████▏    | 53/102 [00:15<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.88it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.83it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.86it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.89it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.89it/s] 59%|█████▉    | 60/102 [00:17<00:10,  4.01it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.97it/s] 61%|██████    | 62/102 [00:18<00:10,  3.93it/s] 62%|██████▏   | 63/102 [00:18<00:09,  3.93it/s] 63%|██████▎   | 64/102 [00:18<00:09,  4.10it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.98it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.96it/s] 66%|██████▌   | 67/102 [00:19<00:08,  3.90it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.94it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.95it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.97it/s] 70%|██████▉   | 71/102 [00:20<00:07,  4.01it/s] 71%|███████   | 72/102 [00:20<00:06,  4.42it/s] 72%|███████▏  | 73/102 [00:20<00:06,  4.31it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.76it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.34it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.84it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.25it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.57it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.81it/s] 78%|███████▊  | 80/102 [00:21<00:03,  6.99it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.12it/s] 80%|████████  | 82/102 [00:22<00:02,  7.22it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.39it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.40it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:23<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.44it/s]100%|██████████| 102/102 [00:24<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.08it/s]=> result
* total: 10,200
* correct: 9,209
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [28/30] batch [20/204] time 0.256 (0.298) data 0.000 (0.034) loss 1.8203 (1.3914) lr 2.4472e-04 eta 0:02:56
epoch [28/30] batch [40/204] time 0.251 (0.276) data 0.001 (0.017) loss 0.3145 (1.0952) lr 2.4472e-04 eta 0:02:37
epoch [28/30] batch [60/204] time 0.259 (0.269) data 0.000 (0.012) loss 0.2942 (1.1167) lr 2.4472e-04 eta 0:02:28
epoch [28/30] batch [80/204] time 0.248 (0.265) data 0.000 (0.009) loss -0.0256 (1.0864) lr 2.4472e-04 eta 0:02:21
epoch [28/30] batch [100/204] time 0.255 (0.263) data 0.000 (0.007) loss 1.4268 (1.0191) lr 2.4472e-04 eta 0:02:14
epoch [28/30] batch [120/204] time 0.254 (0.262) data 0.000 (0.006) loss 0.0833 (0.9834) lr 2.4472e-04 eta 0:02:08
epoch [28/30] batch [140/204] time 0.254 (0.261) data 0.000 (0.005) loss 1.0586 (0.9766) lr 2.4472e-04 eta 0:02:03
epoch [28/30] batch [160/204] time 0.251 (0.260) data 0.000 (0.005) loss 0.5991 (0.9717) lr 2.4472e-04 eta 0:01:57
epoch [28/30] batch [180/204] time 0.247 (0.259) data 0.000 (0.004) loss -0.0233 (0.9637) lr 2.4472e-04 eta 0:01:52
epoch [28/30] batch [200/204] time 0.242 (0.258) data 0.000 (0.004) loss 0.5967 (0.9903) lr 2.4472e-04 eta 0:01:46
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:00,  2.38s/it]  2%|▏         | 2/102 [00:02<02:08,  1.28s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:03<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:40,  2.35it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.96it/s]  9%|▉         | 9/102 [00:04<00:28,  3.21it/s] 10%|▉         | 10/102 [00:05<00:25,  3.55it/s] 11%|█         | 11/102 [00:05<00:25,  3.60it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.65it/s] 13%|█▎        | 13/102 [00:05<00:23,  3.73it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.78it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.81it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.83it/s] 17%|█▋        | 17/102 [00:06<00:22,  3.82it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.84it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.88it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.88it/s] 21%|██        | 21/102 [00:07<00:20,  3.89it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.85it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.87it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.90it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.91it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.90it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.88it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.83it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.84it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.82it/s] 30%|███       | 31/102 [00:10<00:18,  3.83it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.85it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.85it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.89it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.86it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.86it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.88it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.85it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.89it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.91it/s] 40%|████      | 41/102 [00:13<00:15,  3.92it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.88it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.89it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.84it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.86it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.84it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.88it/s] 50%|█████     | 51/102 [00:15<00:13,  3.88it/s] 51%|█████     | 52/102 [00:16<00:12,  3.91it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.87it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.86it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.92it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.89it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.82it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.84it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.79it/s] 61%|██████    | 62/102 [00:18<00:10,  3.87it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.87it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.88it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.89it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.88it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.85it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.83it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.83it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.81it/s] 71%|███████   | 72/102 [00:21<00:07,  3.86it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.51it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.11it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.65it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.09it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.45it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.72it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.92it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.37it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.40it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.43it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.45it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.46it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.47it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.46it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.48it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.21it/s]100%|██████████| 102/102 [00:25<00:00,  7.28it/s]100%|██████████| 102/102 [00:25<00:00,  4.02it/s]=> result
* total: 10,200
* correct: 9,206
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.2%

epoch [29/30] batch [20/204] time 0.253 (0.295) data 0.000 (0.035) loss 0.0534 (0.9263) lr 1.0926e-04 eta 0:01:54
epoch [29/30] batch [40/204] time 0.255 (0.275) data 0.000 (0.018) loss 0.8369 (0.9806) lr 1.0926e-04 eta 0:01:41
epoch [29/30] batch [60/204] time 0.254 (0.269) data 0.000 (0.012) loss 0.1030 (0.9452) lr 1.0926e-04 eta 0:01:33
epoch [29/30] batch [80/204] time 0.252 (0.266) data 0.000 (0.009) loss 0.7246 (0.8785) lr 1.0926e-04 eta 0:01:27
epoch [29/30] batch [100/204] time 0.252 (0.264) data 0.000 (0.007) loss 0.1533 (0.8662) lr 1.0926e-04 eta 0:01:21
epoch [29/30] batch [120/204] time 0.251 (0.262) data 0.000 (0.006) loss 0.1731 (0.8897) lr 1.0926e-04 eta 0:01:15
epoch [29/30] batch [140/204] time 0.308 (0.261) data 0.000 (0.005) loss 0.0039 (0.8930) lr 1.0926e-04 eta 0:01:10
epoch [29/30] batch [160/204] time 0.252 (0.260) data 0.000 (0.005) loss 0.5249 (0.9116) lr 1.0926e-04 eta 0:01:04
epoch [29/30] batch [180/204] time 0.241 (0.259) data 0.000 (0.004) loss 2.6289 (0.9201) lr 1.0926e-04 eta 0:00:59
epoch [29/30] batch [200/204] time 0.244 (0.257) data 0.000 (0.004) loss 0.1575 (0.8827) lr 1.0926e-04 eta 0:00:53
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:12,  2.50s/it]  2%|▏         | 2/102 [00:02<02:12,  1.32s/it]  3%|▎         | 3/102 [00:03<01:27,  1.13it/s]  4%|▍         | 4/102 [00:03<01:02,  1.56it/s]  5%|▍         | 5/102 [00:03<00:48,  1.98it/s]  6%|▌         | 6/102 [00:04<00:40,  2.35it/s]  7%|▋         | 7/102 [00:04<00:35,  2.71it/s]  8%|▊         | 8/102 [00:04<00:31,  3.01it/s]  9%|▉         | 9/102 [00:04<00:28,  3.24it/s] 10%|▉         | 10/102 [00:05<00:27,  3.40it/s] 11%|█         | 11/102 [00:05<00:25,  3.53it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.64it/s] 13%|█▎        | 13/102 [00:05<00:24,  3.71it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.75it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.75it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.75it/s] 17%|█▋        | 17/102 [00:06<00:22,  3.83it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.83it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.84it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.81it/s] 21%|██        | 21/102 [00:08<00:21,  3.82it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.86it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.88it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.88it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.93it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.86it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.92it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.90it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.83it/s] 30%|███       | 31/102 [00:10<00:18,  3.82it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.86it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.84it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.86it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.85it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.85it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.85it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.85it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.84it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.86it/s] 40%|████      | 41/102 [00:13<00:15,  3.82it/s] 41%|████      | 42/102 [00:13<00:15,  3.87it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.90it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.89it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.87it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.83it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.87it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.84it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.82it/s] 50%|█████     | 51/102 [00:15<00:13,  3.82it/s] 51%|█████     | 52/102 [00:16<00:13,  3.83it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.84it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.85it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.83it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.85it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.84it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.86it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.88it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.89it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.89it/s] 61%|██████    | 62/102 [00:18<00:10,  3.88it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.84it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.89it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.82it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.86it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.86it/s] 71%|███████   | 72/102 [00:21<00:07,  4.25it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.33it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.86it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.43it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.93it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.32it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.62it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.84it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.02it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.14it/s] 80%|████████  | 82/102 [00:22<00:02,  7.22it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  4.01it/s]=> result
* total: 10,200
* correct: 9,207
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.2%

epoch [30/30] batch [20/204] time 0.256 (0.293) data 0.000 (0.036) loss 0.0883 (0.6626) lr 2.7391e-05 eta 0:00:53
epoch [30/30] batch [40/204] time 0.255 (0.275) data 0.000 (0.018) loss 0.0767 (0.9342) lr 2.7391e-05 eta 0:00:45
epoch [30/30] batch [60/204] time 0.261 (0.270) data 0.000 (0.012) loss 0.7617 (0.8972) lr 2.7391e-05 eta 0:00:38
epoch [30/30] batch [80/204] time 0.257 (0.266) data 0.000 (0.009) loss -0.0216 (0.8837) lr 2.7391e-05 eta 0:00:33
epoch [30/30] batch [100/204] time 0.252 (0.264) data 0.000 (0.007) loss -0.0504 (0.9605) lr 2.7391e-05 eta 0:00:27
epoch [30/30] batch [120/204] time 0.259 (0.263) data 0.000 (0.006) loss 0.1787 (0.9155) lr 2.7391e-05 eta 0:00:22
epoch [30/30] batch [140/204] time 0.256 (0.262) data 0.000 (0.005) loss 0.2168 (0.9130) lr 2.7391e-05 eta 0:00:16
epoch [30/30] batch [160/204] time 0.250 (0.261) data 0.000 (0.005) loss 0.2336 (0.8560) lr 2.7391e-05 eta 0:00:11
epoch [30/30] batch [180/204] time 0.242 (0.260) data 0.000 (0.004) loss 0.3296 (0.8905) lr 2.7391e-05 eta 0:00:06
epoch [30/30] batch [200/204] time 0.242 (0.258) data 0.000 (0.004) loss 0.2166 (0.8976) lr 2.7391e-05 eta 0:00:01
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:17,  2.55s/it]  2%|▏         | 2/102 [00:03<02:22,  1.43s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:04<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:40,  2.35it/s]  7%|▋         | 7/102 [00:04<00:35,  2.71it/s]  8%|▊         | 8/102 [00:04<00:31,  3.00it/s]  9%|▉         | 9/102 [00:05<00:28,  3.21it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:25,  3.52it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.61it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.67it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.72it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.76it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.78it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.79it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.78it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.79it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.82it/s] 21%|██        | 21/102 [00:08<00:21,  3.77it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.79it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.80it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.82it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.80it/s] 25%|██▌       | 26/102 [00:09<00:20,  3.74it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.79it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.84it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.86it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.84it/s] 30%|███       | 31/102 [00:10<00:18,  3.81it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.86it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.83it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.86it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.85it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.81it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.82it/s] 40%|████      | 41/102 [00:13<00:15,  3.82it/s] 41%|████      | 42/102 [00:13<00:15,  3.83it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.82it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.88it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.85it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.88it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.85it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.81it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.81it/s] 50%|█████     | 51/102 [00:16<00:13,  3.86it/s] 51%|█████     | 52/102 [00:16<00:12,  3.88it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.86it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.88it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.87it/s] 55%|█████▍    | 56/102 [00:17<00:11,  4.16it/s] 56%|█████▌    | 57/102 [00:17<00:11,  4.05it/s] 57%|█████▋    | 58/102 [00:17<00:11,  4.00it/s] 58%|█████▊    | 59/102 [00:18<00:10,  3.96it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.93it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.92it/s] 61%|██████    | 62/102 [00:18<00:10,  3.90it/s] 62%|██████▏   | 63/102 [00:19<00:09,  3.93it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.88it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.86it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.85it/s] 66%|██████▌   | 67/102 [00:20<00:08,  3.98it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.90it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.88it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.89it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.93it/s] 71%|███████   | 72/102 [00:21<00:07,  4.04it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.62it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.84it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.42it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.87it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.28it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.59it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.84it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.02it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.14it/s] 80%|████████  | 82/102 [00:22<00:02,  7.23it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.30it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.33it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.36it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.39it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.40it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.41it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.42it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.42it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.42it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.38it/s]100%|██████████| 102/102 [00:25<00:00,  7.40it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]
=> result
* total: 10,200
* correct: 9,209
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 22)
Evaluate on the *test* set
  0%|          | 0/153 [00:00<?, ?it/s]  1%|          | 1/153 [00:02<06:38,  2.62s/it]  1%|▏         | 2/153 [00:03<03:33,  1.41s/it]  2%|▏         | 3/153 [00:03<02:14,  1.12it/s]  3%|▎         | 4/153 [00:03<01:35,  1.55it/s]  3%|▎         | 5/153 [00:03<01:15,  1.97it/s]  4%|▍         | 6/153 [00:04<01:02,  2.36it/s]  5%|▍         | 7/153 [00:04<00:53,  2.74it/s]  5%|▌         | 8/153 [00:04<00:48,  3.02it/s]  6%|▌         | 9/153 [00:04<00:42,  3.37it/s]  7%|▋         | 10/153 [00:05<00:40,  3.53it/s]  7%|▋         | 11/153 [00:05<00:36,  3.91it/s]  8%|▊         | 12/153 [00:05<00:35,  3.92it/s]  8%|▊         | 13/153 [00:05<00:35,  3.95it/s]  9%|▉         | 14/153 [00:06<00:35,  3.93it/s] 10%|▉         | 15/153 [00:06<00:35,  3.90it/s] 10%|█         | 16/153 [00:06<00:35,  3.87it/s] 11%|█         | 17/153 [00:06<00:35,  3.86it/s] 12%|█▏        | 18/153 [00:07<00:35,  3.84it/s] 12%|█▏        | 19/153 [00:07<00:35,  3.81it/s] 13%|█▎        | 20/153 [00:07<00:32,  4.06it/s] 14%|█▎        | 21/153 [00:07<00:31,  4.13it/s] 14%|█▍        | 22/153 [00:08<00:32,  4.00it/s] 15%|█▌        | 23/153 [00:08<00:33,  3.93it/s] 16%|█▌        | 24/153 [00:08<00:32,  3.94it/s] 16%|█▋        | 25/153 [00:08<00:32,  3.88it/s] 17%|█▋        | 26/153 [00:09<00:31,  3.99it/s] 18%|█▊        | 27/153 [00:09<00:31,  3.95it/s] 18%|█▊        | 28/153 [00:09<00:31,  3.95it/s] 19%|█▉        | 29/153 [00:09<00:30,  4.02it/s] 20%|█▉        | 30/153 [00:10<00:29,  4.13it/s] 20%|██        | 31/153 [00:10<00:29,  4.09it/s] 21%|██        | 32/153 [00:10<00:30,  4.01it/s] 22%|██▏       | 33/153 [00:10<00:30,  3.98it/s] 22%|██▏       | 34/153 [00:11<00:30,  3.96it/s] 23%|██▎       | 35/153 [00:11<00:30,  3.91it/s] 24%|██▎       | 36/153 [00:11<00:30,  3.85it/s] 24%|██▍       | 37/153 [00:12<00:30,  3.86it/s] 25%|██▍       | 38/153 [00:12<00:29,  3.85it/s] 25%|██▌       | 39/153 [00:12<00:29,  3.85it/s] 26%|██▌       | 40/153 [00:12<00:28,  3.90it/s] 27%|██▋       | 41/153 [00:13<00:28,  3.91it/s] 27%|██▋       | 42/153 [00:13<00:27,  4.02it/s] 28%|██▊       | 43/153 [00:13<00:27,  3.98it/s] 29%|██▉       | 44/153 [00:13<00:27,  3.95it/s] 29%|██▉       | 45/153 [00:14<00:27,  3.87it/s] 30%|███       | 46/153 [00:14<00:27,  3.85it/s] 31%|███       | 47/153 [00:14<00:27,  3.87it/s] 31%|███▏      | 48/153 [00:14<00:27,  3.83it/s] 32%|███▏      | 49/153 [00:15<00:26,  3.86it/s] 33%|███▎      | 50/153 [00:15<00:26,  3.94it/s] 33%|███▎      | 51/153 [00:15<00:26,  3.91it/s] 34%|███▍      | 52/153 [00:15<00:26,  3.87it/s] 35%|███▍      | 53/153 [00:16<00:25,  3.86it/s] 35%|███▌      | 54/153 [00:16<00:24,  3.98it/s] 36%|███▌      | 55/153 [00:16<00:23,  4.19it/s] 37%|███▋      | 56/153 [00:16<00:22,  4.28it/s] 37%|███▋      | 57/153 [00:16<00:21,  4.43it/s] 38%|███▊      | 58/153 [00:17<00:22,  4.20it/s] 39%|███▊      | 59/153 [00:17<00:23,  4.07it/s] 39%|███▉      | 60/153 [00:17<00:23,  4.01it/s] 40%|███▉      | 61/153 [00:18<00:22,  4.00it/s] 41%|████      | 62/153 [00:18<00:20,  4.38it/s] 41%|████      | 63/153 [00:18<00:21,  4.23it/s] 42%|████▏     | 64/153 [00:18<00:21,  4.11it/s] 42%|████▏     | 65/153 [00:18<00:21,  4.02it/s] 43%|████▎     | 66/153 [00:19<00:21,  4.03it/s] 44%|████▍     | 67/153 [00:19<00:21,  3.97it/s] 44%|████▍     | 68/153 [00:19<00:21,  3.90it/s] 45%|████▌     | 69/153 [00:20<00:21,  3.91it/s] 46%|████▌     | 70/153 [00:20<00:21,  3.86it/s] 46%|████▋     | 71/153 [00:20<00:21,  3.89it/s] 47%|████▋     | 72/153 [00:20<00:20,  3.87it/s] 48%|████▊     | 73/153 [00:21<00:20,  3.84it/s] 48%|████▊     | 74/153 [00:21<00:20,  3.85it/s] 49%|████▉     | 75/153 [00:21<00:19,  3.92it/s] 50%|████▉     | 76/153 [00:21<00:19,  3.88it/s] 50%|█████     | 77/153 [00:22<00:18,  4.20it/s] 51%|█████     | 78/153 [00:22<00:17,  4.17it/s] 52%|█████▏    | 79/153 [00:22<00:18,  4.04it/s] 52%|█████▏    | 80/153 [00:22<00:18,  3.94it/s] 53%|█████▎    | 81/153 [00:23<00:18,  3.91it/s] 54%|█████▎    | 82/153 [00:23<00:17,  4.01it/s] 54%|█████▍    | 83/153 [00:23<00:17,  4.00it/s] 55%|█████▍    | 84/153 [00:23<00:17,  3.93it/s] 56%|█████▌    | 85/153 [00:24<00:17,  3.94it/s] 56%|█████▌    | 86/153 [00:24<00:17,  3.94it/s] 57%|█████▋    | 87/153 [00:24<00:16,  3.93it/s] 58%|█████▊    | 88/153 [00:24<00:16,  3.89it/s] 58%|█████▊    | 89/153 [00:25<00:16,  3.86it/s] 59%|█████▉    | 90/153 [00:25<00:16,  3.90it/s] 59%|█████▉    | 91/153 [00:25<00:15,  3.89it/s] 60%|██████    | 92/153 [00:25<00:15,  3.93it/s] 61%|██████    | 93/153 [00:26<00:15,  3.91it/s] 61%|██████▏   | 94/153 [00:26<00:14,  4.00it/s] 62%|██████▏   | 95/153 [00:26<00:14,  3.94it/s] 63%|██████▎   | 96/153 [00:26<00:14,  3.90it/s] 63%|██████▎   | 97/153 [00:27<00:14,  3.93it/s] 64%|██████▍   | 98/153 [00:27<00:14,  3.87it/s] 65%|██████▍   | 99/153 [00:27<00:14,  3.81it/s] 65%|██████▌   | 100/153 [00:27<00:13,  3.89it/s] 66%|██████▌   | 101/153 [00:28<00:13,  3.88it/s] 67%|██████▋   | 102/153 [00:28<00:13,  3.87it/s] 67%|██████▋   | 103/153 [00:28<00:13,  3.84it/s] 68%|██████▊   | 104/153 [00:28<00:12,  3.87it/s] 69%|██████▊   | 105/153 [00:29<00:12,  3.91it/s] 69%|██████▉   | 106/153 [00:29<00:12,  3.86it/s] 70%|██████▉   | 107/153 [00:29<00:11,  4.13it/s] 71%|███████   | 108/153 [00:29<00:11,  4.04it/s] 71%|███████   | 109/153 [00:30<00:11,  4.00it/s] 72%|███████▏  | 110/153 [00:30<00:10,  3.91it/s] 73%|███████▎  | 111/153 [00:30<00:10,  3.90it/s] 73%|███████▎  | 112/153 [00:30<00:10,  3.88it/s] 74%|███████▍  | 113/153 [00:31<00:10,  3.85it/s] 75%|███████▍  | 114/153 [00:31<00:10,  3.87it/s] 75%|███████▌  | 115/153 [00:31<00:09,  3.87it/s] 76%|███████▌  | 116/153 [00:32<00:09,  3.84it/s] 76%|███████▋  | 117/153 [00:32<00:09,  3.88it/s] 77%|███████▋  | 118/153 [00:32<00:08,  3.94it/s] 78%|███████▊  | 119/153 [00:32<00:08,  4.06it/s] 78%|███████▊  | 120/153 [00:32<00:08,  4.06it/s] 79%|███████▉  | 121/153 [00:33<00:08,  3.93it/s] 80%|███████▉  | 122/153 [00:33<00:07,  3.91it/s] 80%|████████  | 123/153 [00:33<00:07,  4.09it/s] 81%|████████  | 124/153 [00:33<00:06,  4.62it/s] 82%|████████▏ | 125/153 [00:34<00:05,  5.22it/s] 82%|████████▏ | 126/153 [00:34<00:04,  5.73it/s] 83%|████████▎ | 127/153 [00:34<00:04,  6.15it/s] 84%|████████▎ | 128/153 [00:34<00:03,  6.48it/s] 84%|████████▍ | 129/153 [00:34<00:03,  6.74it/s] 85%|████████▍ | 130/153 [00:34<00:03,  6.93it/s] 86%|████████▌ | 131/153 [00:34<00:03,  7.07it/s] 86%|████████▋ | 132/153 [00:34<00:02,  7.17it/s] 87%|████████▋ | 133/153 [00:35<00:02,  7.24it/s] 88%|████████▊ | 134/153 [00:35<00:02,  7.30it/s] 88%|████████▊ | 135/153 [00:35<00:02,  7.33it/s] 89%|████████▉ | 136/153 [00:35<00:02,  7.36it/s] 90%|████████▉ | 137/153 [00:35<00:02,  7.38it/s] 90%|█████████ | 138/153 [00:35<00:02,  7.39it/s] 91%|█████████ | 139/153 [00:35<00:01,  7.41it/s] 92%|█████████▏| 140/153 [00:36<00:01,  7.41it/s] 92%|█████████▏| 141/153 [00:36<00:01,  7.41it/s] 93%|█████████▎| 142/153 [00:36<00:01,  7.41it/s] 93%|█████████▎| 143/153 [00:36<00:01,  7.41it/s] 94%|█████████▍| 144/153 [00:36<00:01,  7.40it/s] 95%|█████████▍| 145/153 [00:36<00:01,  7.41it/s] 95%|█████████▌| 146/153 [00:36<00:00,  7.42it/s] 96%|█████████▌| 147/153 [00:36<00:00,  7.25it/s] 97%|█████████▋| 148/153 [00:37<00:00,  7.30it/s] 97%|█████████▋| 149/153 [00:37<00:00,  7.33it/s] 98%|█████████▊| 150/153 [00:37<00:00,  7.36it/s] 99%|█████████▊| 151/153 [00:37<00:00,  7.37it/s] 99%|█████████▉| 152/153 [00:37<00:00,  7.39it/s]100%|██████████| 153/153 [00:37<00:00,  7.39it/s]100%|██████████| 153/153 [00:37<00:00,  4.03it/s]
=> result
* total: 15,300
* correct: 13,892
* accuracy: 90.8%
* error: 9.2%
* macro_f1: 90.8%
Elapsed: 0:39:43
+ sh scripts/rpo_prime/base2new_test_sdl.sh food101 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
800 10000 15000
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  50
# train_x  800
# val      10,000
# test     15,000
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 22)
Evaluate on the *test* set
  0%|          | 0/150 [00:00<?, ?it/s]  1%|          | 1/150 [00:05<13:40,  5.51s/it]  1%|▏         | 2/150 [00:05<05:48,  2.35s/it]  2%|▏         | 3/150 [00:05<03:20,  1.36s/it]  3%|▎         | 4/150 [00:06<02:14,  1.09it/s]  3%|▎         | 5/150 [00:06<01:38,  1.47it/s]  4%|▍         | 6/150 [00:06<01:17,  1.85it/s]  5%|▍         | 7/150 [00:06<01:04,  2.23it/s]  5%|▌         | 8/150 [00:07<00:55,  2.58it/s]  6%|▌         | 9/150 [00:07<00:48,  2.89it/s]  7%|▋         | 10/150 [00:07<00:44,  3.13it/s]  7%|▋         | 11/150 [00:07<00:41,  3.31it/s]  8%|▊         | 12/150 [00:08<00:39,  3.46it/s]  9%|▊         | 13/150 [00:08<00:37,  3.62it/s]  9%|▉         | 14/150 [00:08<00:36,  3.69it/s] 10%|█         | 15/150 [00:08<00:36,  3.71it/s] 11%|█         | 16/150 [00:09<00:35,  3.73it/s] 11%|█▏        | 17/150 [00:09<00:35,  3.73it/s] 12%|█▏        | 18/150 [00:09<00:32,  4.01it/s] 13%|█▎        | 19/150 [00:09<00:32,  4.02it/s] 13%|█▎        | 20/150 [00:10<00:32,  3.94it/s] 14%|█▍        | 21/150 [00:10<00:33,  3.90it/s] 15%|█▍        | 22/150 [00:10<00:32,  3.96it/s] 15%|█▌        | 23/150 [00:10<00:32,  3.89it/s] 16%|█▌        | 24/150 [00:11<00:32,  3.87it/s] 17%|█▋        | 25/150 [00:11<00:31,  3.91it/s] 17%|█▋        | 26/150 [00:11<00:31,  3.90it/s] 18%|█▊        | 27/150 [00:11<00:31,  3.88it/s] 19%|█▊        | 28/150 [00:12<00:31,  3.86it/s] 19%|█▉        | 29/150 [00:12<00:31,  3.90it/s] 20%|██        | 30/150 [00:12<00:30,  3.89it/s] 21%|██        | 31/150 [00:12<00:28,  4.16it/s] 21%|██▏       | 32/150 [00:13<00:29,  3.99it/s] 22%|██▏       | 33/150 [00:13<00:30,  3.90it/s] 23%|██▎       | 34/150 [00:13<00:29,  3.90it/s] 23%|██▎       | 35/150 [00:13<00:28,  4.01it/s] 24%|██▍       | 36/150 [00:14<00:28,  4.01it/s] 25%|██▍       | 37/150 [00:14<00:28,  3.99it/s] 25%|██▌       | 38/150 [00:14<00:28,  3.97it/s] 26%|██▌       | 39/150 [00:15<00:28,  3.93it/s] 27%|██▋       | 40/150 [00:15<00:28,  3.90it/s] 27%|██▋       | 41/150 [00:15<00:27,  3.90it/s] 28%|██▊       | 42/150 [00:15<00:25,  4.17it/s] 29%|██▊       | 43/150 [00:15<00:26,  4.06it/s] 29%|██▉       | 44/150 [00:16<00:26,  3.98it/s] 30%|███       | 45/150 [00:16<00:26,  4.01it/s] 31%|███       | 46/150 [00:16<00:26,  3.97it/s] 31%|███▏      | 47/150 [00:17<00:26,  3.90it/s] 32%|███▏      | 48/150 [00:17<00:26,  3.90it/s] 33%|███▎      | 49/150 [00:17<00:26,  3.84it/s] 33%|███▎      | 50/150 [00:17<00:24,  4.06it/s] 34%|███▍      | 51/150 [00:18<00:24,  4.01it/s] 35%|███▍      | 52/150 [00:18<00:24,  3.97it/s] 35%|███▌      | 53/150 [00:18<00:24,  3.94it/s] 36%|███▌      | 54/150 [00:18<00:24,  3.91it/s] 37%|███▋      | 55/150 [00:19<00:24,  3.93it/s] 37%|███▋      | 56/150 [00:19<00:24,  3.84it/s] 38%|███▊      | 57/150 [00:19<00:24,  3.85it/s] 39%|███▊      | 58/150 [00:19<00:21,  4.19it/s] 39%|███▉      | 59/150 [00:20<00:22,  4.12it/s] 40%|████      | 60/150 [00:20<00:22,  4.01it/s] 41%|████      | 61/150 [00:20<00:22,  3.90it/s] 41%|████▏     | 62/150 [00:20<00:21,  4.09it/s] 42%|████▏     | 63/150 [00:21<00:21,  3.99it/s] 43%|████▎     | 64/150 [00:21<00:21,  3.97it/s] 43%|████▎     | 65/150 [00:21<00:21,  3.92it/s] 44%|████▍     | 66/150 [00:21<00:21,  3.84it/s] 45%|████▍     | 67/150 [00:22<00:21,  3.84it/s] 45%|████▌     | 68/150 [00:22<00:21,  3.90it/s] 46%|████▌     | 69/150 [00:22<00:20,  3.90it/s] 47%|████▋     | 70/150 [00:22<00:20,  3.92it/s] 47%|████▋     | 71/150 [00:23<00:20,  3.90it/s] 48%|████▊     | 72/150 [00:23<00:20,  3.90it/s] 49%|████▊     | 73/150 [00:23<00:19,  3.88it/s] 49%|████▉     | 74/150 [00:23<00:19,  3.83it/s] 50%|█████     | 75/150 [00:24<00:19,  3.86it/s] 51%|█████     | 76/150 [00:24<00:18,  3.90it/s] 51%|█████▏    | 77/150 [00:24<00:18,  3.93it/s] 52%|█████▏    | 78/150 [00:24<00:18,  3.95it/s] 53%|█████▎    | 79/150 [00:25<00:17,  4.04it/s] 53%|█████▎    | 80/150 [00:25<00:17,  3.92it/s] 54%|█████▍    | 81/150 [00:25<00:17,  3.90it/s] 55%|█████▍    | 82/150 [00:25<00:17,  3.87it/s] 55%|█████▌    | 83/150 [00:26<00:17,  3.87it/s] 56%|█████▌    | 84/150 [00:26<00:16,  3.99it/s] 57%|█████▋    | 85/150 [00:26<00:16,  4.04it/s] 57%|█████▋    | 86/150 [00:26<00:16,  3.95it/s] 58%|█████▊    | 87/150 [00:27<00:16,  3.87it/s] 59%|█████▊    | 88/150 [00:27<00:15,  3.99it/s] 59%|█████▉    | 89/150 [00:27<00:15,  4.04it/s] 60%|██████    | 90/150 [00:27<00:14,  4.02it/s] 61%|██████    | 91/150 [00:28<00:14,  3.96it/s] 61%|██████▏   | 92/150 [00:28<00:14,  3.90it/s] 62%|██████▏   | 93/150 [00:28<00:14,  3.91it/s] 63%|██████▎   | 94/150 [00:28<00:13,  4.10it/s] 63%|██████▎   | 95/150 [00:29<00:13,  4.23it/s] 64%|██████▍   | 96/150 [00:29<00:13,  4.10it/s] 65%|██████▍   | 97/150 [00:29<00:13,  4.02it/s] 65%|██████▌   | 98/150 [00:29<00:13,  3.99it/s] 66%|██████▌   | 99/150 [00:30<00:12,  3.97it/s] 67%|██████▋   | 100/150 [00:30<00:12,  3.97it/s] 67%|██████▋   | 101/150 [00:30<00:12,  3.89it/s] 68%|██████▊   | 102/150 [00:30<00:12,  3.86it/s] 69%|██████▊   | 103/150 [00:31<00:12,  3.84it/s] 69%|██████▉   | 104/150 [00:31<00:11,  4.08it/s] 70%|███████   | 105/150 [00:31<00:11,  4.00it/s] 71%|███████   | 106/150 [00:31<00:11,  3.96it/s] 71%|███████▏  | 107/150 [00:32<00:10,  3.94it/s] 72%|███████▏  | 108/150 [00:32<00:10,  3.91it/s] 73%|███████▎  | 109/150 [00:32<00:10,  3.93it/s] 73%|███████▎  | 110/150 [00:32<00:10,  3.93it/s] 74%|███████▍  | 111/150 [00:33<00:09,  4.20it/s] 75%|███████▍  | 112/150 [00:33<00:09,  4.05it/s] 75%|███████▌  | 113/150 [00:33<00:09,  4.01it/s] 76%|███████▌  | 114/150 [00:33<00:08,  4.00it/s] 77%|███████▋  | 115/150 [00:34<00:08,  3.97it/s] 77%|███████▋  | 116/150 [00:34<00:08,  4.08it/s] 78%|███████▊  | 117/150 [00:34<00:08,  3.97it/s] 79%|███████▊  | 118/150 [00:34<00:08,  3.94it/s] 79%|███████▉  | 119/150 [00:35<00:07,  3.88it/s] 80%|████████  | 120/150 [00:35<00:07,  4.27it/s] 81%|████████  | 121/150 [00:35<00:06,  4.25it/s] 81%|████████▏ | 122/150 [00:35<00:05,  4.80it/s] 82%|████████▏ | 123/150 [00:35<00:05,  5.36it/s] 83%|████████▎ | 124/150 [00:36<00:04,  5.85it/s] 83%|████████▎ | 125/150 [00:36<00:04,  6.24it/s] 84%|████████▍ | 126/150 [00:36<00:03,  6.53it/s] 85%|████████▍ | 127/150 [00:36<00:03,  6.78it/s] 85%|████████▌ | 128/150 [00:36<00:03,  6.95it/s] 86%|████████▌ | 129/150 [00:36<00:02,  7.07it/s] 87%|████████▋ | 130/150 [00:36<00:02,  7.17it/s] 87%|████████▋ | 131/150 [00:36<00:02,  7.23it/s] 88%|████████▊ | 132/150 [00:37<00:02,  7.27it/s] 89%|████████▊ | 133/150 [00:37<00:02,  7.31it/s] 89%|████████▉ | 134/150 [00:37<00:02,  7.32it/s] 90%|█████████ | 135/150 [00:37<00:02,  7.23it/s] 91%|█████████ | 136/150 [00:37<00:01,  7.28it/s] 91%|█████████▏| 137/150 [00:37<00:01,  7.28it/s] 92%|█████████▏| 138/150 [00:37<00:01,  7.31it/s] 93%|█████████▎| 139/150 [00:38<00:01,  7.33it/s] 93%|█████████▎| 140/150 [00:38<00:01,  7.33it/s] 94%|█████████▍| 141/150 [00:38<00:01,  7.35it/s] 95%|█████████▍| 142/150 [00:38<00:01,  7.34it/s] 95%|█████████▌| 143/150 [00:38<00:00,  7.34it/s] 96%|█████████▌| 144/150 [00:38<00:00,  7.36it/s] 97%|█████████▋| 145/150 [00:38<00:00,  7.35it/s] 97%|█████████▋| 146/150 [00:39<00:00,  7.36it/s] 98%|█████████▊| 147/150 [00:39<00:00,  7.37it/s] 99%|█████████▊| 148/150 [00:39<00:00,  7.36it/s] 99%|█████████▉| 149/150 [00:39<00:00,  7.38it/s]100%|██████████| 150/150 [00:39<00:00,  7.38it/s]100%|██████████| 150/150 [00:39<00:00,  3.78it/s]
=> result
* total: 15,000
* correct: 13,665
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 91.1%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh food101 3 0 main_tmp1_0.1sdl 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
816 10200 15300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  51
# train_x  816
# val      10,200
# test     15,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/204] time 0.257 (0.380) data 0.000 (0.051) loss 0.3167 (1.0138) lr 1.0000e-02 eta 0:38:39
epoch [1/30] batch [40/204] time 0.251 (0.318) data 0.000 (0.025) loss 0.6079 (1.4706) lr 1.0000e-02 eta 0:32:12
epoch [1/30] batch [60/204] time 0.250 (0.297) data 0.000 (0.017) loss 0.9360 (1.4911) lr 1.0000e-02 eta 0:29:56
epoch [1/30] batch [80/204] time 0.251 (0.287) data 0.000 (0.013) loss 3.7363 (1.5056) lr 1.0000e-02 eta 0:28:55
epoch [1/30] batch [100/204] time 0.253 (0.281) data 0.000 (0.010) loss 0.1252 (1.4901) lr 1.0000e-02 eta 0:28:11
epoch [1/30] batch [120/204] time 0.253 (0.277) data 0.000 (0.009) loss 1.4961 (1.5088) lr 1.0000e-02 eta 0:27:39
epoch [1/30] batch [140/204] time 0.253 (0.274) data 0.000 (0.008) loss 0.2598 (1.4221) lr 1.0000e-02 eta 0:27:15
epoch [1/30] batch [160/204] time 0.256 (0.272) data 0.000 (0.007) loss 2.4805 (1.3946) lr 1.0000e-02 eta 0:26:59
epoch [1/30] batch [180/204] time 0.244 (0.269) data 0.000 (0.006) loss 0.3538 (1.4004) lr 1.0000e-02 eta 0:26:39
epoch [1/30] batch [200/204] time 0.245 (0.267) data 0.000 (0.005) loss 0.4561 (1.3626) lr 1.0000e-02 eta 0:26:19
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:58,  2.95s/it]  2%|▏         | 2/102 [00:03<02:35,  1.56s/it]  3%|▎         | 3/102 [00:03<01:43,  1.05s/it]  4%|▍         | 4/102 [00:04<01:19,  1.24it/s]  5%|▍         | 5/102 [00:04<00:58,  1.65it/s]  6%|▌         | 6/102 [00:04<00:46,  2.06it/s]  7%|▋         | 7/102 [00:05<00:39,  2.44it/s]  8%|▊         | 8/102 [00:05<00:34,  2.75it/s]  9%|▉         | 9/102 [00:05<00:31,  3.00it/s] 10%|▉         | 10/102 [00:05<00:28,  3.23it/s] 11%|█         | 11/102 [00:06<00:26,  3.42it/s] 12%|█▏        | 12/102 [00:06<00:25,  3.55it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.72it/s] 15%|█▍        | 15/102 [00:07<00:23,  3.74it/s] 16%|█▌        | 16/102 [00:07<00:22,  3.75it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.76it/s] 18%|█▊        | 18/102 [00:08<00:22,  3.79it/s] 19%|█▊        | 19/102 [00:08<00:21,  3.81it/s] 20%|█▉        | 20/102 [00:08<00:21,  3.87it/s] 21%|██        | 21/102 [00:08<00:20,  3.89it/s] 22%|██▏       | 22/102 [00:09<00:20,  3.88it/s] 23%|██▎       | 23/102 [00:09<00:20,  3.87it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.87it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.86it/s] 25%|██▌       | 26/102 [00:10<00:19,  3.88it/s] 26%|██▋       | 27/102 [00:10<00:19,  3.90it/s] 27%|██▋       | 28/102 [00:10<00:18,  3.91it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.88it/s] 29%|██▉       | 30/102 [00:11<00:18,  3.84it/s] 30%|███       | 31/102 [00:11<00:18,  3.83it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.82it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.81it/s] 33%|███▎      | 34/102 [00:12<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:12<00:17,  3.88it/s] 35%|███▌      | 36/102 [00:12<00:16,  3.91it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.90it/s] 37%|███▋      | 38/102 [00:13<00:16,  3.95it/s] 38%|███▊      | 39/102 [00:13<00:15,  3.98it/s] 39%|███▉      | 40/102 [00:13<00:13,  4.47it/s] 40%|████      | 41/102 [00:13<00:14,  4.35it/s] 41%|████      | 42/102 [00:14<00:13,  4.51it/s] 42%|████▏     | 43/102 [00:14<00:12,  4.56it/s] 43%|████▎     | 44/102 [00:14<00:13,  4.32it/s] 44%|████▍     | 45/102 [00:14<00:13,  4.10it/s] 45%|████▌     | 46/102 [00:15<00:14,  3.99it/s] 46%|████▌     | 47/102 [00:15<00:14,  3.89it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.88it/s] 48%|████▊     | 49/102 [00:15<00:13,  4.04it/s] 49%|████▉     | 50/102 [00:16<00:13,  3.98it/s] 50%|█████     | 51/102 [00:16<00:12,  4.00it/s] 51%|█████     | 52/102 [00:16<00:12,  3.96it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.90it/s] 53%|█████▎    | 54/102 [00:17<00:12,  3.89it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.89it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.86it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.89it/s] 57%|█████▋    | 58/102 [00:18<00:11,  3.90it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.90it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.93it/s] 60%|█████▉    | 61/102 [00:18<00:10,  4.09it/s] 61%|██████    | 62/102 [00:19<00:09,  4.01it/s] 62%|██████▏   | 63/102 [00:19<00:09,  3.95it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.93it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.90it/s] 65%|██████▍   | 66/102 [00:20<00:09,  3.91it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.88it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.87it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:21<00:08,  3.93it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.91it/s] 71%|███████   | 72/102 [00:21<00:07,  4.00it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.59it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.05it/s] 74%|███████▎  | 75/102 [00:22<00:04,  5.60it/s] 75%|███████▍  | 76/102 [00:22<00:04,  6.05it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.42it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.72it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.92it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.21it/s] 80%|████████  | 82/102 [00:23<00:02,  7.28it/s] 81%|████████▏ | 83/102 [00:23<00:02,  7.35it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.40it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.42it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.45it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.47it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.46it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.49it/s] 88%|████████▊ | 90/102 [00:24<00:01,  7.48it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.47it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.48it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.49it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.38it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.42it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:25<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:25<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  3.95it/s]=> result
* total: 10,200
* correct: 9,127
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 89.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/204] time 0.259 (0.300) data 0.000 (0.035) loss 0.0706 (0.9077) lr 9.9726e-03 eta 0:29:27
epoch [2/30] batch [40/204] time 0.258 (0.278) data 0.000 (0.018) loss 5.6445 (1.2015) lr 9.9726e-03 eta 0:27:15
epoch [2/30] batch [60/204] time 0.258 (0.272) data 0.000 (0.012) loss 0.0939 (1.1587) lr 9.9726e-03 eta 0:26:30
epoch [2/30] batch [80/204] time 0.260 (0.268) data 0.000 (0.009) loss 0.2996 (1.1716) lr 9.9726e-03 eta 0:26:04
epoch [2/30] batch [100/204] time 0.268 (0.267) data 0.000 (0.007) loss 1.2373 (1.2443) lr 9.9726e-03 eta 0:25:50
epoch [2/30] batch [120/204] time 0.259 (0.265) data 0.000 (0.006) loss 1.5830 (1.2034) lr 9.9726e-03 eta 0:25:37
epoch [2/30] batch [140/204] time 0.258 (0.264) data 0.000 (0.005) loss 0.5449 (1.2622) lr 9.9726e-03 eta 0:25:26
epoch [2/30] batch [160/204] time 0.262 (0.263) data 0.000 (0.005) loss -0.0374 (1.2518) lr 9.9726e-03 eta 0:25:15
epoch [2/30] batch [180/204] time 0.245 (0.262) data 0.000 (0.004) loss 1.9629 (1.2588) lr 9.9726e-03 eta 0:25:04
epoch [2/30] batch [200/204] time 0.244 (0.261) data 0.000 (0.004) loss 0.3362 (1.2473) lr 9.9726e-03 eta 0:24:50
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:05,  2.43s/it]  2%|▏         | 2/102 [00:02<02:10,  1.31s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:03<00:49,  1.98it/s]  6%|▌         | 6/102 [00:04<00:40,  2.35it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:04<00:28,  3.22it/s] 10%|▉         | 10/102 [00:05<00:26,  3.41it/s] 11%|█         | 11/102 [00:05<00:25,  3.56it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.64it/s] 13%|█▎        | 13/102 [00:05<00:23,  3.76it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.82it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.82it/s] 17%|█▋        | 17/102 [00:06<00:20,  4.17it/s] 18%|█▊        | 18/102 [00:07<00:20,  4.12it/s] 19%|█▊        | 19/102 [00:07<00:20,  3.98it/s] 20%|█▉        | 20/102 [00:07<00:20,  3.98it/s] 21%|██        | 21/102 [00:07<00:18,  4.49it/s] 22%|██▏       | 22/102 [00:08<00:18,  4.25it/s] 23%|██▎       | 23/102 [00:08<00:18,  4.18it/s] 24%|██▎       | 24/102 [00:08<00:19,  4.05it/s] 25%|██▍       | 25/102 [00:08<00:19,  3.99it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.98it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.90it/s] 27%|██▋       | 28/102 [00:09<00:18,  4.04it/s] 28%|██▊       | 29/102 [00:09<00:18,  3.95it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.92it/s] 30%|███       | 31/102 [00:10<00:17,  4.04it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.99it/s] 32%|███▏      | 33/102 [00:10<00:17,  3.96it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.94it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.90it/s] 35%|███▌      | 36/102 [00:11<00:16,  3.93it/s] 36%|███▋      | 37/102 [00:11<00:16,  3.91it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.90it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.86it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.83it/s] 40%|████      | 41/102 [00:12<00:15,  3.82it/s] 41%|████      | 42/102 [00:13<00:15,  3.86it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.89it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.87it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.85it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.87it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.81it/s] 47%|████▋     | 48/102 [00:14<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.84it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.87it/s] 50%|█████     | 51/102 [00:15<00:13,  3.90it/s] 51%|█████     | 52/102 [00:15<00:12,  3.89it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.93it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.93it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.91it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.87it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.86it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.85it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.83it/s] 59%|█████▉    | 60/102 [00:17<00:10,  3.82it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.83it/s] 61%|██████    | 62/102 [00:18<00:10,  3.82it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.82it/s] 63%|██████▎   | 64/102 [00:18<00:09,  3.84it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.89it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.89it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.88it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.86it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.92it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.92it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.93it/s] 71%|███████   | 72/102 [00:20<00:07,  3.99it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.59it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.19it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.72it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.15it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.49it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.94it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.10it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.20it/s] 80%|████████  | 82/102 [00:22<00:02,  7.28it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.34it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.37it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.43it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.46it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.47it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  4.06it/s]=> result
* total: 10,200
* correct: 9,164
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 89.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/204] time 0.258 (0.295) data 0.000 (0.035) loss 0.8086 (0.6422) lr 9.8907e-03 eta 0:28:01
epoch [3/30] batch [40/204] time 0.258 (0.277) data 0.000 (0.018) loss 1.5977 (0.9914) lr 9.8907e-03 eta 0:26:09
epoch [3/30] batch [60/204] time 0.259 (0.272) data 0.000 (0.012) loss 4.4258 (1.3699) lr 9.8907e-03 eta 0:25:37
epoch [3/30] batch [80/204] time 0.253 (0.268) data 0.000 (0.009) loss 2.3809 (1.3923) lr 9.8907e-03 eta 0:25:11
epoch [3/30] batch [100/204] time 0.264 (0.267) data 0.000 (0.007) loss -0.0517 (1.2864) lr 9.8907e-03 eta 0:24:55
epoch [3/30] batch [120/204] time 0.263 (0.265) data 0.000 (0.006) loss 0.1492 (1.2418) lr 9.8907e-03 eta 0:24:42
epoch [3/30] batch [140/204] time 0.260 (0.264) data 0.000 (0.005) loss 3.6875 (1.2955) lr 9.8907e-03 eta 0:24:30
epoch [3/30] batch [160/204] time 0.254 (0.263) data 0.000 (0.005) loss -0.0415 (1.2498) lr 9.8907e-03 eta 0:24:20
epoch [3/30] batch [180/204] time 0.244 (0.262) data 0.000 (0.004) loss 0.1443 (1.1822) lr 9.8907e-03 eta 0:24:08
epoch [3/30] batch [200/204] time 0.247 (0.260) data 0.000 (0.004) loss 0.3003 (1.1962) lr 9.8907e-03 eta 0:23:54
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:04,  2.42s/it]  2%|▏         | 2/102 [00:02<02:13,  1.34s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:03,  1.54it/s]  5%|▍         | 5/102 [00:03<00:50,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:04<00:29,  3.15it/s] 10%|▉         | 10/102 [00:05<00:27,  3.30it/s] 11%|█         | 11/102 [00:05<00:26,  3.44it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.55it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.63it/s] 14%|█▎        | 14/102 [00:06<00:24,  3.65it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.71it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.77it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.75it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.77it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.82it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.86it/s] 21%|██        | 21/102 [00:08<00:20,  3.86it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.87it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.82it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.81it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.83it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.86it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.85it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.86it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.86it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.85it/s] 30%|███       | 31/102 [00:10<00:18,  3.81it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.81it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.83it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.80it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.81it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.84it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.86it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.84it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.82it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.85it/s] 40%|████      | 41/102 [00:13<00:15,  3.86it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.84it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.83it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.83it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.83it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.84it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.84it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.88it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.91it/s] 50%|█████     | 51/102 [00:15<00:13,  3.86it/s] 51%|█████     | 52/102 [00:16<00:12,  3.88it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.90it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.89it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.91it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.90it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.86it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.87it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.85it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.86it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.90it/s] 61%|██████    | 62/102 [00:18<00:10,  3.89it/s] 62%|██████▏   | 63/102 [00:19<00:09,  3.91it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.89it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.87it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.86it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.86it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.82it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.84it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.83it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.91it/s] 71%|███████   | 72/102 [00:21<00:07,  4.06it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.68it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.27it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.77it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.20it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.53it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.77it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.96it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.10it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.20it/s] 80%|████████  | 82/102 [00:22<00:02,  7.28it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.37it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,161
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 89.8%

epoch [4/30] batch [20/204] time 0.258 (0.301) data 0.000 (0.036) loss 0.0515 (1.0082) lr 9.7553e-03 eta 0:27:30
epoch [4/30] batch [40/204] time 0.257 (0.279) data 0.000 (0.018) loss 3.8574 (1.4082) lr 9.7553e-03 eta 0:25:24
epoch [4/30] batch [60/204] time 0.256 (0.271) data 0.000 (0.012) loss 1.2686 (1.3109) lr 9.7553e-03 eta 0:24:36
epoch [4/30] batch [80/204] time 0.255 (0.267) data 0.000 (0.009) loss 3.8047 (1.1985) lr 9.7553e-03 eta 0:24:07
epoch [4/30] batch [100/204] time 0.259 (0.265) data 0.000 (0.007) loss 2.1191 (1.3161) lr 9.7553e-03 eta 0:23:52
epoch [4/30] batch [120/204] time 0.260 (0.264) data 0.000 (0.006) loss 0.0266 (1.2729) lr 9.7553e-03 eta 0:23:40
epoch [4/30] batch [140/204] time 0.250 (0.262) data 0.000 (0.005) loss 0.1704 (1.2270) lr 9.7553e-03 eta 0:23:28
epoch [4/30] batch [160/204] time 0.261 (0.262) data 0.001 (0.005) loss 1.8613 (1.1885) lr 9.7553e-03 eta 0:23:18
epoch [4/30] batch [180/204] time 0.246 (0.261) data 0.000 (0.004) loss 1.5303 (1.1724) lr 9.7553e-03 eta 0:23:10
epoch [4/30] batch [200/204] time 0.244 (0.259) data 0.000 (0.004) loss 2.0703 (1.1561) lr 9.7553e-03 eta 0:22:57
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<03:54,  2.33s/it]  2%|▏         | 2/102 [00:02<02:07,  1.28s/it]  3%|▎         | 3/102 [00:03<01:31,  1.08it/s]  4%|▍         | 4/102 [00:03<01:05,  1.50it/s]  5%|▍         | 5/102 [00:03<00:51,  1.90it/s]  6%|▌         | 6/102 [00:04<00:42,  2.28it/s]  7%|▋         | 7/102 [00:04<00:35,  2.65it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:04<00:29,  3.18it/s] 10%|▉         | 10/102 [00:05<00:27,  3.36it/s] 11%|█         | 11/102 [00:05<00:25,  3.50it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.59it/s] 13%|█▎        | 13/102 [00:05<00:23,  3.71it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.74it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.78it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.78it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.77it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.82it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.81it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.81it/s] 21%|██        | 21/102 [00:08<00:20,  3.87it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.89it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.92it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.86it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.85it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.86it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.89it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.88it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.88it/s] 30%|███       | 31/102 [00:10<00:18,  3.88it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.89it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.87it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.86it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.87it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.87it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.82it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.81it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.78it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.80it/s] 40%|████      | 41/102 [00:13<00:15,  3.81it/s] 41%|████      | 42/102 [00:13<00:15,  3.83it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.84it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.84it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.89it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.87it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.81it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.81it/s] 50%|█████     | 51/102 [00:15<00:13,  3.79it/s] 51%|█████     | 52/102 [00:16<00:13,  3.77it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.78it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.82it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.82it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.84it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.83it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.83it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.84it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.84it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.84it/s] 61%|██████    | 62/102 [00:18<00:10,  3.82it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.85it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.80it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.81it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.83it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.82it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.86it/s] 71%|███████   | 72/102 [00:21<00:07,  3.88it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.50it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.11it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.64it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.08it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.44it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.71it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.92it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.31it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.35it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.38it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.40it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,167
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/204] time 0.264 (0.297) data 0.000 (0.037) loss 3.2305 (1.1465) lr 9.5677e-03 eta 0:26:09
epoch [5/30] batch [40/204] time 0.256 (0.276) data 0.001 (0.019) loss 2.1777 (1.1748) lr 9.5677e-03 eta 0:24:14
epoch [5/30] batch [60/204] time 0.260 (0.270) data 0.001 (0.012) loss 0.4092 (1.0935) lr 9.5677e-03 eta 0:23:34
epoch [5/30] batch [80/204] time 0.255 (0.268) data 0.000 (0.009) loss 2.8262 (1.1340) lr 9.5677e-03 eta 0:23:18
epoch [5/30] batch [100/204] time 0.255 (0.266) data 0.000 (0.008) loss 0.0972 (1.1584) lr 9.5677e-03 eta 0:23:02
epoch [5/30] batch [120/204] time 0.253 (0.264) data 0.000 (0.006) loss 0.0947 (1.0836) lr 9.5677e-03 eta 0:22:48
epoch [5/30] batch [140/204] time 0.258 (0.263) data 0.000 (0.006) loss 2.3926 (1.0514) lr 9.5677e-03 eta 0:22:37
epoch [5/30] batch [160/204] time 0.254 (0.262) data 0.000 (0.005) loss 2.1660 (1.0700) lr 9.5677e-03 eta 0:22:28
epoch [5/30] batch [180/204] time 0.246 (0.261) data 0.000 (0.004) loss 1.7490 (1.1097) lr 9.5677e-03 eta 0:22:17
epoch [5/30] batch [200/204] time 0.247 (0.260) data 0.000 (0.004) loss 0.1417 (1.0835) lr 9.5677e-03 eta 0:22:06
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:14,  2.52s/it]  2%|▏         | 2/102 [00:03<02:18,  1.38s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:03<00:50,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.70it/s]  8%|▊         | 8/102 [00:04<00:31,  2.99it/s]  9%|▉         | 9/102 [00:05<00:28,  3.24it/s] 10%|▉         | 10/102 [00:05<00:27,  3.39it/s] 11%|█         | 11/102 [00:05<00:25,  3.53it/s] 12%|█▏        | 12/102 [00:05<00:23,  3.82it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.79it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.78it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.80it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.88it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.89it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.86it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.80it/s] 20%|█▉        | 20/102 [00:07<00:20,  3.99it/s] 21%|██        | 21/102 [00:08<00:20,  3.94it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.93it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.92it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.92it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.91it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.92it/s] 26%|██▋       | 27/102 [00:09<00:18,  3.95it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.92it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.92it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.93it/s] 30%|███       | 31/102 [00:10<00:17,  3.98it/s] 31%|███▏      | 32/102 [00:10<00:17,  4.09it/s] 32%|███▏      | 33/102 [00:11<00:17,  4.03it/s] 33%|███▎      | 34/102 [00:11<00:16,  4.00it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.91it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.88it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.88it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.92it/s] 38%|███▊      | 39/102 [00:12<00:15,  4.01it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.92it/s] 40%|████      | 41/102 [00:13<00:15,  3.96it/s] 41%|████      | 42/102 [00:13<00:15,  3.97it/s] 42%|████▏     | 43/102 [00:13<00:14,  4.02it/s] 43%|████▎     | 44/102 [00:13<00:14,  4.10it/s] 44%|████▍     | 45/102 [00:14<00:14,  4.02it/s] 45%|████▌     | 46/102 [00:14<00:13,  4.21it/s] 46%|████▌     | 47/102 [00:14<00:12,  4.29it/s] 47%|████▋     | 48/102 [00:14<00:12,  4.26it/s] 48%|████▊     | 49/102 [00:15<00:12,  4.16it/s] 49%|████▉     | 50/102 [00:15<00:12,  4.06it/s] 50%|█████     | 51/102 [00:15<00:12,  4.00it/s] 51%|█████     | 52/102 [00:15<00:12,  3.97it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.94it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.91it/s] 54%|█████▍    | 55/102 [00:16<00:11,  3.94it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.92it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.94it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.90it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.06it/s] 59%|█████▉    | 60/102 [00:17<00:10,  4.13it/s] 60%|█████▉    | 61/102 [00:18<00:09,  4.25it/s] 61%|██████    | 62/102 [00:18<00:09,  4.14it/s] 62%|██████▏   | 63/102 [00:18<00:09,  4.21it/s] 63%|██████▎   | 64/102 [00:18<00:09,  4.20it/s] 64%|██████▎   | 65/102 [00:19<00:09,  4.06it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.22it/s] 66%|██████▌   | 67/102 [00:19<00:08,  4.23it/s] 67%|██████▋   | 68/102 [00:19<00:08,  4.08it/s] 68%|██████▊   | 69/102 [00:19<00:08,  4.03it/s] 69%|██████▊   | 70/102 [00:20<00:07,  4.02it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.94it/s] 71%|███████   | 72/102 [00:20<00:07,  4.12it/s] 72%|███████▏  | 73/102 [00:20<00:07,  4.09it/s] 73%|███████▎  | 74/102 [00:21<00:06,  4.66it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.25it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.76it/s] 75%|███████▌  | 77/102 [00:21<00:04,  6.18it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.52it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.77it/s] 78%|███████▊  | 80/102 [00:21<00:03,  6.96it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.10it/s] 80%|████████  | 82/102 [00:22<00:02,  7.20it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.28it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:22<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:23<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.46it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.44it/s]100%|██████████| 102/102 [00:24<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  4.08it/s]=> result
* total: 10,200
* correct: 9,161
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 89.8%

epoch [6/30] batch [20/204] time 0.257 (0.295) data 0.000 (0.035) loss 0.0547 (0.6772) lr 9.3301e-03 eta 0:25:00
epoch [6/30] batch [40/204] time 0.258 (0.277) data 0.000 (0.018) loss 0.0325 (0.8876) lr 9.3301e-03 eta 0:23:21
epoch [6/30] batch [60/204] time 0.254 (0.270) data 0.000 (0.012) loss -0.0126 (0.8900) lr 9.3301e-03 eta 0:22:41
epoch [6/30] batch [80/204] time 0.252 (0.266) data 0.000 (0.009) loss 1.7383 (0.8692) lr 9.3301e-03 eta 0:22:17
epoch [6/30] batch [100/204] time 0.250 (0.265) data 0.000 (0.007) loss 1.4941 (0.9583) lr 9.3301e-03 eta 0:22:03
epoch [6/30] batch [120/204] time 0.254 (0.263) data 0.000 (0.006) loss 1.9238 (0.9167) lr 9.3301e-03 eta 0:21:50
epoch [6/30] batch [140/204] time 0.256 (0.263) data 0.000 (0.005) loss 0.1465 (0.9202) lr 9.3301e-03 eta 0:21:43
epoch [6/30] batch [160/204] time 0.255 (0.262) data 0.000 (0.005) loss 0.0140 (0.9020) lr 9.3301e-03 eta 0:21:35
epoch [6/30] batch [180/204] time 0.243 (0.261) data 0.000 (0.004) loss 0.4270 (0.8849) lr 9.3301e-03 eta 0:21:22
epoch [6/30] batch [200/204] time 0.247 (0.259) data 0.000 (0.004) loss 0.2397 (0.9440) lr 9.3301e-03 eta 0:21:09
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:13,  2.51s/it]  2%|▏         | 2/102 [00:03<02:21,  1.42s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:04<00:50,  1.94it/s]  6%|▌         | 6/102 [00:04<00:40,  2.35it/s]  7%|▋         | 7/102 [00:04<00:35,  2.68it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:05<00:29,  3.15it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:25,  3.52it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.60it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.69it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.72it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.74it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.79it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.77it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.82it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.84it/s] 21%|██        | 21/102 [00:08<00:20,  3.87it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.84it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.83it/s] 24%|██▎       | 24/102 [00:08<00:19,  3.91it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.86it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.84it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.86it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.86it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.84it/s] 30%|███       | 31/102 [00:10<00:18,  3.84it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.81it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.82it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.81it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.81it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.84it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.85it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.84it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.81it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.85it/s] 40%|████      | 41/102 [00:13<00:15,  3.85it/s] 41%|████      | 42/102 [00:13<00:15,  3.86it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.84it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.87it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.84it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.85it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.87it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.90it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.92it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.85it/s] 50%|█████     | 51/102 [00:15<00:13,  3.86it/s] 51%|█████     | 52/102 [00:16<00:13,  3.84it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.87it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.87it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.89it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.89it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.86it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.92it/s] 58%|█████▊    | 59/102 [00:18<00:10,  3.92it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.92it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.89it/s] 61%|██████    | 62/102 [00:18<00:10,  3.85it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.86it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.89it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.89it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.88it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.86it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.88it/s] 71%|███████   | 72/102 [00:21<00:07,  3.91it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.49it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.11it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.49it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.97it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.37it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.66it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.89it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.18it/s] 80%|████████  | 82/102 [00:22<00:02,  7.27it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.37it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.41it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.43it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.45it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.45it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.46it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.46it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.47it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.47it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.46it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.47it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,167
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.8%

epoch [7/30] batch [20/204] time 0.255 (0.299) data 0.000 (0.035) loss -0.0097 (0.5723) lr 9.0451e-03 eta 0:24:15
epoch [7/30] batch [40/204] time 0.252 (0.277) data 0.000 (0.018) loss 3.8828 (0.7959) lr 9.0451e-03 eta 0:22:26
epoch [7/30] batch [60/204] time 0.255 (0.271) data 0.000 (0.012) loss 6.0469 (0.9043) lr 9.0451e-03 eta 0:21:50
epoch [7/30] batch [80/204] time 0.254 (0.267) data 0.000 (0.009) loss 2.5918 (0.9407) lr 9.0451e-03 eta 0:21:28
epoch [7/30] batch [100/204] time 0.254 (0.266) data 0.000 (0.007) loss 0.0883 (0.8970) lr 9.0451e-03 eta 0:21:14
epoch [7/30] batch [120/204] time 0.256 (0.265) data 0.000 (0.006) loss 0.0802 (0.9650) lr 9.0451e-03 eta 0:21:06
epoch [7/30] batch [140/204] time 0.256 (0.264) data 0.000 (0.005) loss 0.6133 (0.9997) lr 9.0451e-03 eta 0:20:54
epoch [7/30] batch [160/204] time 0.256 (0.262) data 0.000 (0.005) loss 0.2585 (1.0051) lr 9.0451e-03 eta 0:20:43
epoch [7/30] batch [180/204] time 0.245 (0.261) data 0.000 (0.004) loss 2.2070 (1.0089) lr 9.0451e-03 eta 0:20:32
epoch [7/30] batch [200/204] time 0.243 (0.260) data 0.000 (0.004) loss 0.8022 (1.0262) lr 9.0451e-03 eta 0:20:18
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:38,  2.76s/it]  2%|▏         | 2/102 [00:03<02:25,  1.46s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:04<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.97it/s]  9%|▉         | 9/102 [00:05<00:29,  3.18it/s] 10%|▉         | 10/102 [00:05<00:27,  3.33it/s] 11%|█         | 11/102 [00:05<00:26,  3.43it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.52it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.59it/s] 14%|█▎        | 14/102 [00:06<00:24,  3.62it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.66it/s] 16%|█▌        | 16/102 [00:07<00:22,  3.74it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.78it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.77it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.81it/s] 20%|█▉        | 20/102 [00:08<00:21,  3.79it/s] 21%|██        | 21/102 [00:08<00:21,  3.80it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.82it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.86it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.84it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.84it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.86it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.90it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.87it/s] 30%|███       | 31/102 [00:10<00:18,  3.87it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.85it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.89it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.90it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.83it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.88it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.90it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.93it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.87it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.85it/s] 40%|████      | 41/102 [00:13<00:15,  3.82it/s] 41%|████      | 42/102 [00:13<00:15,  3.84it/s] 42%|████▏     | 43/102 [00:14<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.85it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.82it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.83it/s] 46%|████▌     | 47/102 [00:15<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.85it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.87it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.89it/s] 50%|█████     | 51/102 [00:16<00:13,  3.90it/s] 51%|█████     | 52/102 [00:16<00:12,  3.92it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.87it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.82it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.80it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.87it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.89it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.93it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.90it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.87it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.91it/s] 61%|██████    | 62/102 [00:18<00:10,  3.88it/s] 62%|██████▏   | 63/102 [00:19<00:09,  3.92it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.88it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.85it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.85it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.83it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.82it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.90it/s] 71%|███████   | 72/102 [00:21<00:07,  3.92it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.54it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.15it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.68it/s] 75%|███████▍  | 76/102 [00:22<00:04,  6.12it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.47it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.72it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.95it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.10it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.21it/s] 80%|████████  | 82/102 [00:22<00:02,  7.29it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.33it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.37it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.45it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.46it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.46it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.46it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  3.98it/s]=> result
* total: 10,200
* correct: 9,179
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 89.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/204] time 0.258 (0.297) data 0.000 (0.035) loss 1.9834 (0.7340) lr 8.7157e-03 eta 0:23:05
epoch [8/30] batch [40/204] time 0.250 (0.278) data 0.000 (0.018) loss 4.2383 (0.8503) lr 8.7157e-03 eta 0:21:32
epoch [8/30] batch [60/204] time 0.254 (0.271) data 0.000 (0.012) loss -0.0040 (1.0445) lr 8.7157e-03 eta 0:20:55
epoch [8/30] batch [80/204] time 0.263 (0.269) data 0.000 (0.009) loss 1.7588 (1.1088) lr 8.7157e-03 eta 0:20:39
epoch [8/30] batch [100/204] time 0.261 (0.266) data 0.000 (0.007) loss 1.1836 (1.0673) lr 8.7157e-03 eta 0:20:23
epoch [8/30] batch [120/204] time 0.249 (0.265) data 0.000 (0.006) loss 3.2578 (1.1024) lr 8.7157e-03 eta 0:20:10
epoch [8/30] batch [140/204] time 0.256 (0.264) data 0.000 (0.005) loss 0.0475 (1.1449) lr 8.7157e-03 eta 0:20:02
epoch [8/30] batch [160/204] time 0.258 (0.263) data 0.000 (0.005) loss 0.8672 (1.1385) lr 8.7157e-03 eta 0:19:52
epoch [8/30] batch [180/204] time 0.243 (0.262) data 0.000 (0.004) loss 0.0596 (1.1528) lr 8.7157e-03 eta 0:19:41
epoch [8/30] batch [200/204] time 0.243 (0.260) data 0.000 (0.004) loss 2.5215 (1.1368) lr 8.7157e-03 eta 0:19:28
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:14,  2.52s/it]  2%|▏         | 2/102 [00:03<02:19,  1.39s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:03,  1.55it/s]  5%|▍         | 5/102 [00:03<00:49,  1.96it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:32,  2.93it/s]  9%|▉         | 9/102 [00:05<00:29,  3.15it/s] 10%|▉         | 10/102 [00:05<00:27,  3.32it/s] 11%|█         | 11/102 [00:05<00:26,  3.47it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.59it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.64it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.76it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.81it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.86it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.88it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.87it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.85it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.86it/s] 21%|██        | 21/102 [00:08<00:20,  3.89it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.85it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.82it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.82it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.82it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.86it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.87it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.89it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.90it/s] 30%|███       | 31/102 [00:10<00:18,  3.85it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.86it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.89it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.90it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.92it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.87it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.86it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.84it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.82it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.83it/s] 40%|████      | 41/102 [00:13<00:15,  3.86it/s] 41%|████      | 42/102 [00:13<00:15,  3.87it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.89it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.92it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.89it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.89it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.88it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.83it/s] 50%|█████     | 51/102 [00:15<00:13,  3.84it/s] 51%|█████     | 52/102 [00:16<00:12,  4.13it/s] 52%|█████▏    | 53/102 [00:16<00:11,  4.30it/s] 53%|█████▎    | 54/102 [00:16<00:11,  4.18it/s] 54%|█████▍    | 55/102 [00:16<00:11,  4.05it/s] 55%|█████▍    | 56/102 [00:17<00:11,  4.09it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.98it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.96it/s] 58%|█████▊    | 59/102 [00:17<00:10,  3.92it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.89it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.88it/s] 61%|██████    | 62/102 [00:18<00:10,  3.86it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.90it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.88it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.86it/s] 66%|██████▌   | 67/102 [00:19<00:08,  4.08it/s] 67%|██████▋   | 68/102 [00:20<00:08,  4.19it/s] 68%|██████▊   | 69/102 [00:20<00:07,  4.35it/s] 69%|██████▊   | 70/102 [00:20<00:07,  4.13it/s] 70%|██████▉   | 71/102 [00:20<00:07,  4.09it/s] 71%|███████   | 72/102 [00:21<00:07,  4.09it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.32it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.94it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.50it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.96it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.34it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.63it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.86it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.02it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.14it/s] 80%|████████  | 82/102 [00:22<00:02,  7.23it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.28it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.46it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,193
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/204] time 0.253 (0.295) data 0.000 (0.035) loss 2.4902 (1.0471) lr 8.3457e-03 eta 0:21:58
epoch [9/30] batch [40/204] time 0.264 (0.276) data 0.000 (0.018) loss -0.0344 (1.1391) lr 8.3457e-03 eta 0:20:26
epoch [9/30] batch [60/204] time 0.256 (0.271) data 0.000 (0.012) loss 2.5801 (1.1819) lr 8.3457e-03 eta 0:20:01
epoch [9/30] batch [80/204] time 0.255 (0.268) data 0.000 (0.009) loss 0.0165 (1.1293) lr 8.3457e-03 eta 0:19:40
epoch [9/30] batch [100/204] time 0.250 (0.266) data 0.000 (0.007) loss 0.3018 (1.0497) lr 8.3457e-03 eta 0:19:26
epoch [9/30] batch [120/204] time 0.256 (0.265) data 0.000 (0.006) loss 0.7383 (1.0484) lr 8.3457e-03 eta 0:19:18
epoch [9/30] batch [140/204] time 0.259 (0.264) data 0.000 (0.005) loss 1.6465 (1.0840) lr 8.3457e-03 eta 0:19:08
epoch [9/30] batch [160/204] time 0.259 (0.263) data 0.000 (0.005) loss 1.8525 (1.0919) lr 8.3457e-03 eta 0:18:59
epoch [9/30] batch [180/204] time 0.245 (0.262) data 0.000 (0.004) loss 0.2961 (1.0355) lr 8.3457e-03 eta 0:18:48
epoch [9/30] batch [200/204] time 0.247 (0.260) data 0.000 (0.004) loss 0.0191 (0.9935) lr 8.3457e-03 eta 0:18:36
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:12,  2.50s/it]  2%|▏         | 2/102 [00:03<02:15,  1.35s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:03<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.99it/s]  9%|▉         | 9/102 [00:04<00:28,  3.26it/s] 10%|▉         | 10/102 [00:05<00:26,  3.42it/s] 11%|█         | 11/102 [00:05<00:25,  3.60it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.64it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.70it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.76it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.81it/s] 16%|█▌        | 16/102 [00:06<00:21,  4.06it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.97it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.95it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.90it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.89it/s] 21%|██        | 21/102 [00:08<00:20,  3.89it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.87it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.89it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.83it/s] 25%|██▍       | 25/102 [00:09<00:19,  4.04it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.98it/s] 26%|██▋       | 27/102 [00:09<00:18,  4.01it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.94it/s] 28%|██▊       | 29/102 [00:09<00:16,  4.34it/s] 29%|██▉       | 30/102 [00:10<00:17,  4.23it/s] 30%|███       | 31/102 [00:10<00:16,  4.34it/s] 31%|███▏      | 32/102 [00:10<00:15,  4.46it/s] 32%|███▏      | 33/102 [00:10<00:16,  4.28it/s] 33%|███▎      | 34/102 [00:11<00:16,  4.14it/s] 34%|███▍      | 35/102 [00:11<00:16,  4.04it/s] 35%|███▌      | 36/102 [00:11<00:16,  4.00it/s] 36%|███▋      | 37/102 [00:11<00:16,  3.95it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.94it/s] 38%|███▊      | 39/102 [00:12<00:15,  4.00it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.96it/s] 40%|████      | 41/102 [00:12<00:15,  3.89it/s] 41%|████      | 42/102 [00:13<00:15,  3.86it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.89it/s] 43%|████▎     | 44/102 [00:13<00:13,  4.20it/s] 44%|████▍     | 45/102 [00:13<00:14,  4.07it/s] 45%|████▌     | 46/102 [00:14<00:13,  4.00it/s] 46%|████▌     | 47/102 [00:14<00:13,  3.93it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.91it/s] 48%|████▊     | 49/102 [00:14<00:13,  3.99it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.94it/s] 50%|█████     | 51/102 [00:15<00:13,  3.89it/s] 51%|█████     | 52/102 [00:15<00:12,  3.87it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.82it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.81it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.83it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.86it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.86it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.85it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.81it/s] 59%|█████▉    | 60/102 [00:17<00:10,  3.87it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.90it/s] 61%|██████    | 62/102 [00:18<00:10,  3.89it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:18<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.90it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.85it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.83it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.85it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.84it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.81it/s] 71%|███████   | 72/102 [00:20<00:07,  3.95it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.51it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.12it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.66it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.10it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.46it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.94it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.20it/s] 80%|████████  | 82/102 [00:22<00:02,  7.15it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.24it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.31it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.35it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.38it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.45it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.46it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.42it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.45it/s]100%|██████████| 102/102 [00:24<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.06it/s]=> result
* total: 10,200
* correct: 9,190
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%

epoch [10/30] batch [20/204] time 0.255 (0.296) data 0.000 (0.035) loss 0.0090 (1.5248) lr 7.9389e-03 eta 0:21:03
epoch [10/30] batch [40/204] time 0.255 (0.279) data 0.000 (0.018) loss 0.7705 (1.2573) lr 7.9389e-03 eta 0:19:44
epoch [10/30] batch [60/204] time 0.255 (0.272) data 0.000 (0.012) loss 1.6758 (1.1353) lr 7.9389e-03 eta 0:19:08
epoch [10/30] batch [80/204] time 0.256 (0.269) data 0.000 (0.009) loss 4.6133 (1.2806) lr 7.9389e-03 eta 0:18:48
epoch [10/30] batch [100/204] time 0.259 (0.267) data 0.000 (0.007) loss 0.0326 (1.2485) lr 7.9389e-03 eta 0:18:35
epoch [10/30] batch [120/204] time 0.249 (0.265) data 0.000 (0.006) loss 1.9746 (1.1300) lr 7.9389e-03 eta 0:18:23
epoch [10/30] batch [140/204] time 0.257 (0.264) data 0.000 (0.005) loss 0.1913 (1.0863) lr 7.9389e-03 eta 0:18:13
epoch [10/30] batch [160/204] time 0.256 (0.263) data 0.000 (0.005) loss 0.6084 (1.0386) lr 7.9389e-03 eta 0:18:04
epoch [10/30] batch [180/204] time 0.243 (0.262) data 0.000 (0.004) loss 0.5474 (1.0797) lr 7.9389e-03 eta 0:17:55
epoch [10/30] batch [200/204] time 0.247 (0.260) data 0.000 (0.004) loss 0.0390 (1.1147) lr 7.9389e-03 eta 0:17:43
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:21,  2.58s/it]  2%|▏         | 2/102 [00:03<02:23,  1.44s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:03,  1.54it/s]  5%|▍         | 5/102 [00:04<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.66it/s]  8%|▊         | 8/102 [00:04<00:31,  2.94it/s]  9%|▉         | 9/102 [00:05<00:29,  3.19it/s] 10%|▉         | 10/102 [00:05<00:27,  3.37it/s] 11%|█         | 11/102 [00:05<00:25,  3.50it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.56it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:24,  3.66it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.70it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.74it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.76it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.82it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.86it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.87it/s] 21%|██        | 21/102 [00:08<00:21,  3.85it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.82it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.81it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.83it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.82it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.81it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.83it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.85it/s] 29%|██▉       | 30/102 [00:10<00:19,  3.78it/s] 30%|███       | 31/102 [00:10<00:18,  3.78it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.81it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.84it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.90it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.90it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.88it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.87it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.84it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.87it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.86it/s] 40%|████      | 41/102 [00:13<00:15,  3.82it/s] 41%|████      | 42/102 [00:13<00:15,  3.86it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.84it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.84it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.84it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.84it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.85it/s] 50%|█████     | 51/102 [00:16<00:13,  3.83it/s] 51%|█████     | 52/102 [00:16<00:12,  3.86it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.83it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.84it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.81it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.80it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.81it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.83it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.85it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.90it/s] 61%|██████    | 62/102 [00:18<00:10,  3.89it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.89it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.86it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.81it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.86it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.85it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.90it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.89it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.90it/s] 71%|███████   | 72/102 [00:21<00:07,  3.98it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.59it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.19it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.71it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.14it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.41it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.69it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.90it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  3.98it/s]=> result
* total: 10,200
* correct: 9,168
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/204] time 0.253 (0.297) data 0.000 (0.039) loss -0.0114 (0.7890) lr 7.5000e-03 eta 0:20:05
epoch [11/30] batch [40/204] time 0.255 (0.276) data 0.000 (0.020) loss 0.7959 (0.9001) lr 7.5000e-03 eta 0:18:35
epoch [11/30] batch [60/204] time 0.254 (0.269) data 0.000 (0.013) loss 3.9082 (1.0131) lr 7.5000e-03 eta 0:18:02
epoch [11/30] batch [80/204] time 0.252 (0.267) data 0.000 (0.010) loss -0.0367 (1.0360) lr 7.5000e-03 eta 0:17:48
epoch [11/30] batch [100/204] time 0.254 (0.264) data 0.000 (0.008) loss 0.3120 (1.0493) lr 7.5000e-03 eta 0:17:32
epoch [11/30] batch [120/204] time 0.256 (0.263) data 0.000 (0.007) loss 2.7930 (1.0946) lr 7.5000e-03 eta 0:17:21
epoch [11/30] batch [140/204] time 0.253 (0.262) data 0.000 (0.006) loss 0.9937 (1.1200) lr 7.5000e-03 eta 0:17:12
epoch [11/30] batch [160/204] time 0.260 (0.262) data 0.000 (0.005) loss 1.3252 (1.1024) lr 7.5000e-03 eta 0:17:05
epoch [11/30] batch [180/204] time 0.244 (0.261) data 0.000 (0.005) loss 0.0396 (1.0879) lr 7.5000e-03 eta 0:16:56
epoch [11/30] batch [200/204] time 0.244 (0.259) data 0.000 (0.004) loss 0.3164 (1.0557) lr 7.5000e-03 eta 0:16:44
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:20,  2.58s/it]  2%|▏         | 2/102 [00:03<02:23,  1.44s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:04<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.29it/s]  7%|▋         | 7/102 [00:04<00:35,  2.64it/s]  8%|▊         | 8/102 [00:04<00:31,  2.94it/s]  9%|▉         | 9/102 [00:05<00:28,  3.21it/s] 10%|▉         | 10/102 [00:05<00:27,  3.39it/s] 11%|█         | 11/102 [00:05<00:25,  3.53it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.63it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.71it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.76it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.76it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.77it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.81it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.81it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.84it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.90it/s] 21%|██        | 21/102 [00:08<00:20,  3.87it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.86it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.84it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.82it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.81it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.78it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.81it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.82it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.81it/s] 30%|███       | 31/102 [00:10<00:18,  3.79it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.86it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.87it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.87it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.86it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.99it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.88it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.86it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.87it/s] 40%|████      | 41/102 [00:13<00:15,  3.90it/s] 41%|████      | 42/102 [00:13<00:15,  3.88it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.86it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.87it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.89it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.88it/s] 50%|█████     | 51/102 [00:15<00:13,  3.90it/s] 51%|█████     | 52/102 [00:16<00:12,  3.90it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.87it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.85it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.84it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.84it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.85it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.83it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.83it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.84it/s] 61%|██████    | 62/102 [00:18<00:10,  3.86it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.83it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.87it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.85it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.84it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.85it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.79it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.83it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.82it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.88it/s] 71%|███████   | 72/102 [00:21<00:07,  3.95it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.54it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.14it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.67it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.12it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.46it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.94it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.42it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,168
* accuracy: 89.9%
* error: 10.1%
* macro_f1: 89.8%

epoch [12/30] batch [20/204] time 0.259 (0.302) data 0.000 (0.037) loss 2.0078 (1.0320) lr 7.0337e-03 eta 0:19:22
epoch [12/30] batch [40/204] time 0.250 (0.279) data 0.000 (0.019) loss 1.0449 (0.8670) lr 7.0337e-03 eta 0:17:49
epoch [12/30] batch [60/204] time 0.247 (0.271) data 0.000 (0.013) loss -0.0241 (0.8686) lr 7.0337e-03 eta 0:17:15
epoch [12/30] batch [80/204] time 0.264 (0.267) data 0.000 (0.009) loss 0.0003 (0.9134) lr 7.0337e-03 eta 0:16:54
epoch [12/30] batch [100/204] time 0.253 (0.265) data 0.000 (0.008) loss -0.0244 (0.9434) lr 7.0337e-03 eta 0:16:42
epoch [12/30] batch [120/204] time 0.251 (0.264) data 0.000 (0.006) loss 0.6846 (1.0655) lr 7.0337e-03 eta 0:16:29
epoch [12/30] batch [140/204] time 0.254 (0.262) data 0.000 (0.006) loss 0.5840 (1.0253) lr 7.0337e-03 eta 0:16:20
epoch [12/30] batch [160/204] time 0.255 (0.262) data 0.000 (0.005) loss 2.8145 (1.0068) lr 7.0337e-03 eta 0:16:11
epoch [12/30] batch [180/204] time 0.244 (0.261) data 0.000 (0.004) loss 2.4707 (0.9921) lr 7.0337e-03 eta 0:16:02
epoch [12/30] batch [200/204] time 0.243 (0.259) data 0.000 (0.004) loss 0.0937 (0.9928) lr 7.0337e-03 eta 0:15:51
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:08,  2.46s/it]  2%|▏         | 2/102 [00:03<02:15,  1.36s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:03<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.31it/s]  7%|▋         | 7/102 [00:04<00:35,  2.64it/s]  8%|▊         | 8/102 [00:04<00:32,  2.91it/s]  9%|▉         | 9/102 [00:05<00:29,  3.16it/s] 10%|▉         | 10/102 [00:05<00:27,  3.35it/s] 11%|█         | 11/102 [00:05<00:26,  3.48it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.59it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.68it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.81it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.80it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.82it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.84it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.84it/s] 21%|██        | 21/102 [00:08<00:21,  3.84it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.83it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.81it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.82it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.83it/s] 25%|██▌       | 26/102 [00:09<00:17,  4.34it/s] 26%|██▋       | 27/102 [00:09<00:17,  4.17it/s] 27%|██▋       | 28/102 [00:09<00:18,  4.11it/s] 28%|██▊       | 29/102 [00:10<00:18,  4.04it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.95it/s] 30%|███       | 31/102 [00:10<00:17,  4.11it/s] 31%|███▏      | 32/102 [00:10<00:17,  4.05it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.94it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.86it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.85it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.83it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.87it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.89it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.85it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.87it/s] 40%|████      | 41/102 [00:13<00:15,  3.89it/s] 41%|████      | 42/102 [00:13<00:15,  3.94it/s] 42%|████▏     | 43/102 [00:13<00:14,  3.94it/s] 43%|████▎     | 44/102 [00:13<00:14,  4.03it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.99it/s] 45%|████▌     | 46/102 [00:14<00:13,  4.21it/s] 46%|████▌     | 47/102 [00:14<00:13,  4.05it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.99it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.96it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.92it/s] 50%|█████     | 51/102 [00:15<00:13,  3.91it/s] 51%|█████     | 52/102 [00:15<00:12,  3.94it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.88it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.90it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.87it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.91it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.92it/s] 57%|█████▋    | 58/102 [00:17<00:10,  4.23it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.10it/s] 59%|█████▉    | 60/102 [00:17<00:10,  4.16it/s] 60%|█████▉    | 61/102 [00:18<00:10,  4.02it/s] 61%|██████    | 62/102 [00:18<00:09,  4.00it/s] 62%|██████▏   | 63/102 [00:18<00:09,  3.97it/s] 63%|██████▎   | 64/102 [00:18<00:09,  3.95it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.92it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.89it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.89it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.86it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.87it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.84it/s] 71%|███████   | 72/102 [00:21<00:07,  3.86it/s] 72%|███████▏  | 73/102 [00:21<00:07,  3.95it/s] 73%|███████▎  | 74/102 [00:21<00:06,  4.60it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.20it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.72it/s] 75%|███████▌  | 77/102 [00:21<00:04,  6.15it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.49it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.75it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.90it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.06it/s] 80%|████████  | 82/102 [00:22<00:02,  7.18it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.25it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.31it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.35it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.38it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.46it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.46it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.39it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,192
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%

epoch [13/30] batch [20/204] time 0.255 (0.301) data 0.000 (0.035) loss 2.9473 (1.2554) lr 6.5451e-03 eta 0:18:20
epoch [13/30] batch [40/204] time 0.259 (0.279) data 0.000 (0.018) loss -0.0006 (1.1913) lr 6.5451e-03 eta 0:16:53
epoch [13/30] batch [60/204] time 0.254 (0.272) data 0.000 (0.012) loss -0.0157 (1.2568) lr 6.5451e-03 eta 0:16:21
epoch [13/30] batch [80/204] time 0.252 (0.268) data 0.000 (0.009) loss -0.0179 (1.2134) lr 6.5451e-03 eta 0:16:04
epoch [13/30] batch [100/204] time 0.260 (0.266) data 0.000 (0.007) loss 3.2168 (1.2455) lr 6.5451e-03 eta 0:15:49
epoch [13/30] batch [120/204] time 0.259 (0.264) data 0.000 (0.006) loss 0.2734 (1.1607) lr 6.5451e-03 eta 0:15:38
epoch [13/30] batch [140/204] time 0.251 (0.263) data 0.000 (0.005) loss 1.7354 (1.1355) lr 6.5451e-03 eta 0:15:30
epoch [13/30] batch [160/204] time 0.258 (0.262) data 0.000 (0.005) loss -0.0175 (1.0772) lr 6.5451e-03 eta 0:15:21
epoch [13/30] batch [180/204] time 0.243 (0.261) data 0.000 (0.004) loss 1.6641 (1.0543) lr 6.5451e-03 eta 0:15:12
epoch [13/30] batch [200/204] time 0.246 (0.259) data 0.000 (0.004) loss 0.6343 (1.0511) lr 6.5451e-03 eta 0:15:00
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:25,  2.63s/it]  2%|▏         | 2/102 [00:03<02:19,  1.39s/it]  3%|▎         | 3/102 [00:03<01:28,  1.11it/s]  4%|▍         | 4/102 [00:03<01:03,  1.54it/s]  5%|▍         | 5/102 [00:03<00:49,  1.96it/s]  6%|▌         | 6/102 [00:04<00:40,  2.35it/s]  7%|▋         | 7/102 [00:04<00:35,  2.70it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:04<00:27,  3.39it/s] 10%|▉         | 10/102 [00:05<00:25,  3.54it/s] 11%|█         | 11/102 [00:05<00:24,  3.70it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.75it/s] 13%|█▎        | 13/102 [00:05<00:22,  3.93it/s] 14%|█▎        | 14/102 [00:06<00:22,  3.88it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.91it/s] 16%|█▌        | 16/102 [00:06<00:21,  3.95it/s] 17%|█▋        | 17/102 [00:06<00:21,  4.00it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.97it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.92it/s] 20%|█▉        | 20/102 [00:07<00:20,  3.92it/s] 21%|██        | 21/102 [00:07<00:19,  4.22it/s] 22%|██▏       | 22/102 [00:08<00:19,  4.12it/s] 23%|██▎       | 23/102 [00:08<00:19,  4.12it/s] 24%|██▎       | 24/102 [00:08<00:19,  4.01it/s] 25%|██▍       | 25/102 [00:08<00:19,  4.01it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.96it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.90it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.91it/s] 28%|██▊       | 29/102 [00:09<00:18,  3.90it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.87it/s] 30%|███       | 31/102 [00:10<00:18,  3.89it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.87it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.88it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.92it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.91it/s] 35%|███▌      | 36/102 [00:11<00:16,  3.92it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.93it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.87it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.86it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.84it/s] 40%|████      | 41/102 [00:13<00:15,  3.82it/s] 41%|████      | 42/102 [00:13<00:15,  3.83it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.88it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.84it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.82it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.81it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:14<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.85it/s] 50%|█████     | 51/102 [00:15<00:13,  3.85it/s] 51%|█████     | 52/102 [00:15<00:12,  3.89it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.84it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.81it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.85it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.88it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.82it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.81it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.77it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.82it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.83it/s] 61%|██████    | 62/102 [00:18<00:10,  3.81it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.78it/s] 63%|██████▎   | 64/102 [00:19<00:10,  3.79it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.82it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.83it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.83it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.88it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.90it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.92it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.95it/s] 71%|███████   | 72/102 [00:21<00:07,  4.02it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.48it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.09it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.62it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.06it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.42it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.70it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.90it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.06it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.25it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.35it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.39it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.40it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,179
* accuracy: 90.0%
* error: 10.0%
* macro_f1: 90.0%

epoch [14/30] batch [20/204] time 0.250 (0.298) data 0.000 (0.036) loss 2.2520 (1.0463) lr 6.0396e-03 eta 0:17:08
epoch [14/30] batch [40/204] time 0.256 (0.278) data 0.000 (0.018) loss 0.4963 (1.1274) lr 6.0396e-03 eta 0:15:51
epoch [14/30] batch [60/204] time 0.253 (0.271) data 0.000 (0.012) loss 0.1010 (1.1676) lr 6.0396e-03 eta 0:15:23
epoch [14/30] batch [80/204] time 0.259 (0.268) data 0.000 (0.009) loss 0.9185 (1.0932) lr 6.0396e-03 eta 0:15:07
epoch [14/30] batch [100/204] time 0.254 (0.266) data 0.000 (0.007) loss 0.0181 (1.0256) lr 6.0396e-03 eta 0:14:57
epoch [14/30] batch [120/204] time 0.252 (0.265) data 0.000 (0.006) loss 0.4011 (1.0433) lr 6.0396e-03 eta 0:14:46
epoch [14/30] batch [140/204] time 0.257 (0.263) data 0.000 (0.005) loss 0.3345 (0.9972) lr 6.0396e-03 eta 0:14:36
epoch [14/30] batch [160/204] time 0.256 (0.262) data 0.000 (0.005) loss 0.0210 (0.9459) lr 6.0396e-03 eta 0:14:27
epoch [14/30] batch [180/204] time 0.244 (0.261) data 0.000 (0.004) loss 0.1931 (0.9194) lr 6.0396e-03 eta 0:14:17
epoch [14/30] batch [200/204] time 0.245 (0.259) data 0.000 (0.004) loss 0.0309 (0.9326) lr 6.0396e-03 eta 0:14:07
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:10,  2.48s/it]  2%|▏         | 2/102 [00:03<02:17,  1.38s/it]  3%|▎         | 3/102 [00:03<01:28,  1.12it/s]  4%|▍         | 4/102 [00:03<01:03,  1.55it/s]  5%|▍         | 5/102 [00:03<00:49,  1.96it/s]  6%|▌         | 6/102 [00:04<00:41,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:31,  2.96it/s]  9%|▉         | 9/102 [00:04<00:28,  3.22it/s] 10%|▉         | 10/102 [00:05<00:27,  3.41it/s] 11%|█         | 11/102 [00:05<00:25,  3.56it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.61it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.67it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.75it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.79it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.88it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.86it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.84it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.84it/s] 21%|██        | 21/102 [00:08<00:21,  3.83it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.84it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.85it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.84it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.84it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.83it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.88it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.84it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.83it/s] 30%|███       | 31/102 [00:10<00:18,  3.83it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.83it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.80it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.80it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.80it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.84it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.85it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.87it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.90it/s] 40%|████      | 41/102 [00:13<00:15,  3.94it/s] 41%|████      | 42/102 [00:13<00:15,  3.96it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.90it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.86it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.87it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.92it/s] 50%|█████     | 51/102 [00:15<00:13,  3.88it/s] 51%|█████     | 52/102 [00:16<00:12,  3.85it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.83it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.84it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.86it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.83it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.85it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.83it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.83it/s] 61%|██████    | 62/102 [00:18<00:10,  3.82it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.81it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.86it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.84it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.87it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.87it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.85it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.88it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.87it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.86it/s] 71%|███████   | 72/102 [00:21<00:07,  3.88it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.54it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.14it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.55it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.01it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.38it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.66it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.88it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.04it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.16it/s] 80%|████████  | 82/102 [00:22<00:02,  7.25it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.42it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.42it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.42it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.42it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,197
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/204] time 0.255 (0.295) data 0.000 (0.035) loss 0.4282 (0.7939) lr 5.5226e-03 eta 0:15:56
epoch [15/30] batch [40/204] time 0.260 (0.278) data 0.000 (0.018) loss 0.3157 (0.8114) lr 5.5226e-03 eta 0:14:56
epoch [15/30] batch [60/204] time 0.255 (0.271) data 0.000 (0.012) loss 1.8975 (0.9446) lr 5.5226e-03 eta 0:14:29
epoch [15/30] batch [80/204] time 0.251 (0.267) data 0.000 (0.009) loss 0.1886 (0.8347) lr 5.5226e-03 eta 0:14:10
epoch [15/30] batch [100/204] time 0.256 (0.266) data 0.000 (0.007) loss 0.1265 (0.8104) lr 5.5226e-03 eta 0:14:00
epoch [15/30] batch [120/204] time 0.255 (0.265) data 0.000 (0.006) loss 2.4414 (0.8558) lr 5.5226e-03 eta 0:13:51
epoch [15/30] batch [140/204] time 0.253 (0.264) data 0.000 (0.005) loss 2.1562 (0.9363) lr 5.5226e-03 eta 0:13:43
epoch [15/30] batch [160/204] time 0.260 (0.263) data 0.000 (0.005) loss 0.1478 (0.9408) lr 5.5226e-03 eta 0:13:35
epoch [15/30] batch [180/204] time 0.249 (0.262) data 0.000 (0.004) loss 0.5229 (0.9449) lr 5.5226e-03 eta 0:13:26
epoch [15/30] batch [200/204] time 0.244 (0.260) data 0.000 (0.004) loss 1.7217 (1.0207) lr 5.5226e-03 eta 0:13:16
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:16,  2.54s/it]  2%|▏         | 2/102 [00:03<02:22,  1.43s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:04<00:50,  1.92it/s]  6%|▌         | 6/102 [00:04<00:41,  2.30it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:05<00:29,  3.16it/s] 10%|▉         | 10/102 [00:05<00:27,  3.34it/s] 11%|█         | 11/102 [00:05<00:25,  3.50it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.60it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.66it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.78it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.81it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.81it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.83it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.83it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.83it/s] 21%|██        | 21/102 [00:08<00:21,  3.84it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.84it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.88it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.84it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.83it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.82it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.83it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.81it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.84it/s] 30%|███       | 31/102 [00:10<00:18,  3.85it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.84it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.83it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.80it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.82it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.83it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.90it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.88it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.89it/s] 40%|████      | 41/102 [00:13<00:15,  3.90it/s] 41%|████      | 42/102 [00:13<00:15,  3.87it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.79it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.84it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.83it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.81it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.81it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.85it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.84it/s] 50%|█████     | 51/102 [00:15<00:13,  3.86it/s] 51%|█████     | 52/102 [00:16<00:12,  3.91it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.84it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.82it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.80it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.82it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.80it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.82it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.83it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.83it/s] 61%|██████    | 62/102 [00:18<00:10,  3.82it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.84it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.82it/s] 64%|██████▎   | 65/102 [00:19<00:09,  4.07it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.04it/s] 66%|██████▌   | 67/102 [00:20<00:08,  4.09it/s] 67%|██████▋   | 68/102 [00:20<00:08,  4.04it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.97it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.97it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.96it/s] 71%|███████   | 72/102 [00:21<00:07,  4.16it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.54it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.01it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.56it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.02it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.39it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.68it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.89it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.05it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.25it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.30it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.44it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.45it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.38it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.41it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.42it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,190
* accuracy: 90.1%
* error: 9.9%
* macro_f1: 90.1%

epoch [16/30] batch [20/204] time 0.257 (0.295) data 0.000 (0.036) loss 0.9443 (1.1313) lr 5.0000e-03 eta 0:14:56
epoch [16/30] batch [40/204] time 0.262 (0.277) data 0.000 (0.018) loss 0.7222 (0.9102) lr 5.0000e-03 eta 0:13:57
epoch [16/30] batch [60/204] time 0.259 (0.271) data 0.000 (0.012) loss 0.1838 (0.8285) lr 5.0000e-03 eta 0:13:32
epoch [16/30] batch [80/204] time 0.257 (0.267) data 0.000 (0.009) loss 0.2338 (0.7577) lr 5.0000e-03 eta 0:13:15
epoch [16/30] batch [100/204] time 0.256 (0.265) data 0.000 (0.007) loss 0.6899 (0.7949) lr 5.0000e-03 eta 0:13:03
epoch [16/30] batch [120/204] time 0.292 (0.264) data 0.000 (0.006) loss 0.1202 (0.7608) lr 5.0000e-03 eta 0:12:55
epoch [16/30] batch [140/204] time 0.258 (0.263) data 0.000 (0.005) loss 0.7061 (0.7869) lr 5.0000e-03 eta 0:12:48
epoch [16/30] batch [160/204] time 0.254 (0.262) data 0.000 (0.005) loss 1.4180 (0.7910) lr 5.0000e-03 eta 0:12:40
epoch [16/30] batch [180/204] time 0.244 (0.261) data 0.000 (0.004) loss 0.6807 (0.8108) lr 5.0000e-03 eta 0:12:31
epoch [16/30] batch [200/204] time 0.244 (0.260) data 0.000 (0.004) loss 0.7959 (0.8218) lr 5.0000e-03 eta 0:12:22
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:02,  2.41s/it]  2%|▏         | 2/102 [00:02<01:58,  1.19s/it]  3%|▎         | 3/102 [00:03<01:25,  1.16it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:03<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.31it/s]  7%|▋         | 7/102 [00:04<00:36,  2.62it/s]  8%|▊         | 8/102 [00:04<00:32,  2.89it/s]  9%|▉         | 9/102 [00:04<00:28,  3.25it/s] 10%|▉         | 10/102 [00:05<00:26,  3.41it/s] 11%|█         | 11/102 [00:05<00:25,  3.55it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.73it/s] 13%|█▎        | 13/102 [00:05<00:22,  3.90it/s] 14%|█▎        | 14/102 [00:06<00:22,  3.86it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.87it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.88it/s] 17%|█▋        | 17/102 [00:06<00:21,  3.90it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.87it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.95it/s] 20%|█▉        | 20/102 [00:07<00:20,  4.01it/s] 21%|██        | 21/102 [00:07<00:20,  3.95it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.87it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.87it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.85it/s] 25%|██▍       | 25/102 [00:08<00:20,  3.84it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.84it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.87it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.90it/s] 28%|██▊       | 29/102 [00:09<00:18,  3.90it/s] 29%|██▉       | 30/102 [00:10<00:17,  4.17it/s] 30%|███       | 31/102 [00:10<00:17,  4.05it/s] 31%|███▏      | 32/102 [00:10<00:16,  4.24it/s] 32%|███▏      | 33/102 [00:10<00:16,  4.09it/s] 33%|███▎      | 34/102 [00:11<00:17,  4.00it/s] 34%|███▍      | 35/102 [00:11<00:16,  3.96it/s] 35%|███▌      | 36/102 [00:11<00:15,  4.19it/s] 36%|███▋      | 37/102 [00:11<00:15,  4.21it/s] 37%|███▋      | 38/102 [00:12<00:14,  4.49it/s] 38%|███▊      | 39/102 [00:12<00:14,  4.44it/s] 39%|███▉      | 40/102 [00:12<00:14,  4.26it/s] 40%|████      | 41/102 [00:12<00:14,  4.16it/s] 41%|████      | 42/102 [00:13<00:14,  4.09it/s] 42%|████▏     | 43/102 [00:13<00:14,  4.02it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.99it/s] 44%|████▍     | 45/102 [00:13<00:14,  3.93it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.93it/s] 46%|████▌     | 47/102 [00:14<00:13,  4.07it/s] 47%|████▋     | 48/102 [00:14<00:13,  4.01it/s] 48%|████▊     | 49/102 [00:14<00:13,  4.06it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.97it/s] 50%|█████     | 51/102 [00:15<00:12,  3.96it/s] 51%|█████     | 52/102 [00:15<00:12,  3.89it/s] 52%|█████▏    | 53/102 [00:15<00:12,  3.88it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.86it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.82it/s] 55%|█████▍    | 56/102 [00:16<00:12,  3.81it/s] 56%|█████▌    | 57/102 [00:16<00:11,  3.81it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.86it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.88it/s] 59%|█████▉    | 60/102 [00:17<00:10,  3.86it/s] 60%|█████▉    | 61/102 [00:17<00:09,  4.13it/s] 61%|██████    | 62/102 [00:18<00:09,  4.19it/s] 62%|██████▏   | 63/102 [00:18<00:09,  4.05it/s] 63%|██████▎   | 64/102 [00:18<00:09,  4.01it/s] 64%|██████▎   | 65/102 [00:18<00:09,  3.94it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.90it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.86it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.87it/s] 68%|██████▊   | 69/102 [00:19<00:08,  3.83it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.83it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.83it/s] 71%|███████   | 72/102 [00:20<00:07,  3.93it/s] 72%|███████▏  | 73/102 [00:20<00:06,  4.58it/s] 73%|███████▎  | 74/102 [00:20<00:05,  5.18it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.70it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.14it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.48it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.74it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.94it/s] 78%|███████▊  | 80/102 [00:21<00:03,  7.09it/s] 79%|███████▉  | 81/102 [00:21<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.37it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:22<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:22<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.45it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:23<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:23<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.44it/s]100%|██████████| 102/102 [00:24<00:00,  7.44it/s]100%|██████████| 102/102 [00:24<00:00,  4.10it/s]=> result
* total: 10,200
* correct: 9,199
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [17/30] batch [20/204] time 0.253 (0.294) data 0.000 (0.035) loss 0.0829 (0.6256) lr 4.4774e-03 eta 0:13:53
epoch [17/30] batch [40/204] time 0.257 (0.275) data 0.000 (0.018) loss 4.0391 (0.7160) lr 4.4774e-03 eta 0:12:54
epoch [17/30] batch [60/204] time 0.259 (0.270) data 0.000 (0.012) loss 0.2925 (0.6675) lr 4.4774e-03 eta 0:12:34
epoch [17/30] batch [80/204] time 0.253 (0.266) data 0.001 (0.009) loss 3.0273 (0.8002) lr 4.4774e-03 eta 0:12:18
epoch [17/30] batch [100/204] time 0.266 (0.264) data 0.000 (0.007) loss -0.0274 (0.9541) lr 4.4774e-03 eta 0:12:07
epoch [17/30] batch [120/204] time 0.259 (0.263) data 0.000 (0.006) loss 2.5332 (0.9708) lr 4.4774e-03 eta 0:11:59
epoch [17/30] batch [140/204] time 0.258 (0.262) data 0.000 (0.005) loss 0.0085 (0.9797) lr 4.4774e-03 eta 0:11:51
epoch [17/30] batch [160/204] time 0.256 (0.262) data 0.000 (0.005) loss 2.6836 (0.9600) lr 4.4774e-03 eta 0:11:45
epoch [17/30] batch [180/204] time 0.246 (0.261) data 0.000 (0.004) loss 1.8145 (0.9890) lr 4.4774e-03 eta 0:11:38
epoch [17/30] batch [200/204] time 0.246 (0.260) data 0.000 (0.004) loss -0.0485 (0.9972) lr 4.4774e-03 eta 0:11:29
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:07,  2.45s/it]  2%|▏         | 2/102 [00:03<02:17,  1.38s/it]  3%|▎         | 3/102 [00:03<01:31,  1.08it/s]  4%|▍         | 4/102 [00:03<01:05,  1.50it/s]  5%|▍         | 5/102 [00:04<00:50,  1.91it/s]  6%|▌         | 6/102 [00:04<00:41,  2.29it/s]  7%|▋         | 7/102 [00:04<00:36,  2.62it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:05<00:29,  3.16it/s] 10%|▉         | 10/102 [00:05<00:27,  3.35it/s] 11%|█         | 11/102 [00:05<00:26,  3.50it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.58it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.63it/s] 14%|█▎        | 14/102 [00:06<00:24,  3.64it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.65it/s] 16%|█▌        | 16/102 [00:06<00:23,  3.72it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.82it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.84it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.81it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.80it/s] 21%|██        | 21/102 [00:08<00:21,  3.80it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.77it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.79it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.81it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.81it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.82it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.85it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.87it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.92it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.90it/s] 30%|███       | 31/102 [00:10<00:18,  3.83it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.80it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.88it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.82it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.81it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.83it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.87it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.81it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.83it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.81it/s] 40%|████      | 41/102 [00:13<00:15,  3.83it/s] 41%|████      | 42/102 [00:13<00:15,  3.83it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.84it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.84it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.82it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.81it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.87it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.87it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.85it/s] 50%|█████     | 51/102 [00:16<00:13,  3.85it/s] 51%|█████     | 52/102 [00:16<00:13,  3.84it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.86it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.86it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.87it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.84it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.84it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.86it/s] 58%|█████▊    | 59/102 [00:18<00:10,  3.95it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.90it/s] 61%|██████    | 62/102 [00:18<00:10,  3.89it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.86it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.87it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.86it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.86it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.86it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.89it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.89it/s] 71%|███████   | 72/102 [00:21<00:07,  4.02it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.43it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.05it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.58it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.04it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.40it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.68it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.90it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.06it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  3.98it/s]=> result
* total: 10,200
* correct: 9,205
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/204] time 0.256 (0.299) data 0.000 (0.038) loss 0.6431 (0.9505) lr 3.9604e-03 eta 0:13:06
epoch [18/30] batch [40/204] time 0.255 (0.278) data 0.000 (0.019) loss 1.4229 (0.7090) lr 3.9604e-03 eta 0:12:05
epoch [18/30] batch [60/204] time 0.258 (0.271) data 0.000 (0.013) loss 3.0273 (0.9730) lr 3.9604e-03 eta 0:11:41
epoch [18/30] batch [80/204] time 0.254 (0.268) data 0.000 (0.010) loss 0.4124 (0.9797) lr 3.9604e-03 eta 0:11:29
epoch [18/30] batch [100/204] time 0.262 (0.265) data 0.000 (0.008) loss 1.0156 (0.9447) lr 3.9604e-03 eta 0:11:17
epoch [18/30] batch [120/204] time 0.253 (0.264) data 0.000 (0.007) loss 0.0464 (0.9042) lr 3.9604e-03 eta 0:11:07
epoch [18/30] batch [140/204] time 0.257 (0.263) data 0.000 (0.006) loss 0.0203 (0.8706) lr 3.9604e-03 eta 0:10:59
epoch [18/30] batch [160/204] time 0.252 (0.262) data 0.000 (0.005) loss 0.2056 (0.8668) lr 3.9604e-03 eta 0:10:53
epoch [18/30] batch [180/204] time 0.244 (0.261) data 0.000 (0.005) loss -0.0337 (0.8438) lr 3.9604e-03 eta 0:10:45
epoch [18/30] batch [200/204] time 0.246 (0.260) data 0.000 (0.004) loss 1.1309 (0.8205) lr 3.9604e-03 eta 0:10:37
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:34,  2.72s/it]  2%|▏         | 2/102 [00:03<02:27,  1.47s/it]  3%|▎         | 3/102 [00:03<01:31,  1.08it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:04<00:50,  1.92it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.69it/s]  8%|▊         | 8/102 [00:04<00:31,  2.98it/s]  9%|▉         | 9/102 [00:05<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.33it/s] 11%|█         | 11/102 [00:05<00:26,  3.47it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.61it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.69it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.75it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.71it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.76it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.75it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.75it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.80it/s] 20%|█▉        | 20/102 [00:08<00:21,  3.82it/s] 21%|██        | 21/102 [00:08<00:21,  3.81it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.81it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.81it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.80it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.86it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.84it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.84it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.82it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.87it/s] 30%|███       | 31/102 [00:10<00:18,  3.86it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.86it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.83it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.82it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.83it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.86it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.85it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.84it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.99it/s] 40%|████      | 41/102 [00:13<00:15,  3.97it/s] 41%|████      | 42/102 [00:13<00:15,  3.91it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.90it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.85it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.88it/s] 46%|████▌     | 47/102 [00:15<00:14,  3.89it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.86it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.88it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.87it/s] 50%|█████     | 51/102 [00:16<00:13,  3.87it/s] 51%|█████     | 52/102 [00:16<00:12,  3.89it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.88it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.90it/s] 54%|█████▍    | 55/102 [00:17<00:11,  3.95it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.93it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.89it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.89it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.83it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.83it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.83it/s] 61%|██████    | 62/102 [00:18<00:10,  3.86it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.83it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.85it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.86it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.82it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.86it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.86it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.81it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.83it/s] 71%|███████   | 72/102 [00:21<00:07,  3.90it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.46it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.08it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.62it/s] 75%|███████▍  | 76/102 [00:22<00:04,  6.07it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.44it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.72it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.93it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.28it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.34it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.38it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.41it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.45it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.40it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.45it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.98it/s]=> result
* total: 10,200
* correct: 9,206
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/204] time 0.254 (0.297) data 0.000 (0.035) loss 1.1797 (1.0055) lr 3.4549e-03 eta 0:12:00
epoch [19/30] batch [40/204] time 0.256 (0.279) data 0.000 (0.017) loss -0.0257 (0.8768) lr 3.4549e-03 eta 0:11:11
epoch [19/30] batch [60/204] time 0.253 (0.272) data 0.000 (0.012) loss -0.0016 (0.9284) lr 3.4549e-03 eta 0:10:49
epoch [19/30] batch [80/204] time 0.254 (0.268) data 0.000 (0.009) loss 0.0191 (0.9038) lr 3.4549e-03 eta 0:10:35
epoch [19/30] batch [100/204] time 0.259 (0.266) data 0.001 (0.007) loss 0.4829 (0.9672) lr 3.4549e-03 eta 0:10:23
epoch [19/30] batch [120/204] time 0.255 (0.265) data 0.000 (0.006) loss 0.5879 (0.9803) lr 3.4549e-03 eta 0:10:16
epoch [19/30] batch [140/204] time 0.256 (0.263) data 0.000 (0.005) loss 1.4541 (0.9686) lr 3.4549e-03 eta 0:10:07
epoch [19/30] batch [160/204] time 0.249 (0.262) data 0.000 (0.005) loss 4.7188 (1.0627) lr 3.4549e-03 eta 0:10:00
epoch [19/30] batch [180/204] time 0.243 (0.261) data 0.000 (0.004) loss 0.2644 (1.0559) lr 3.4549e-03 eta 0:09:52
epoch [19/30] batch [200/204] time 0.244 (0.259) data 0.000 (0.004) loss -0.0372 (1.0216) lr 3.4549e-03 eta 0:09:43
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:05,  2.43s/it]  2%|▏         | 2/102 [00:03<02:20,  1.41s/it]  3%|▎         | 3/102 [00:03<01:31,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:03<00:50,  1.92it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.65it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:05<00:29,  3.19it/s] 10%|▉         | 10/102 [00:05<00:27,  3.36it/s] 11%|█         | 11/102 [00:05<00:26,  3.46it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.57it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.65it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.72it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.82it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.82it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.84it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.84it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.82it/s] 21%|██        | 21/102 [00:08<00:21,  3.85it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.84it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.81it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.80it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.81it/s] 25%|██▌       | 26/102 [00:09<00:20,  3.77it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.84it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.81it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.81it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.83it/s] 30%|███       | 31/102 [00:10<00:18,  3.86it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.85it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.80it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.81it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.86it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.83it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.82it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.79it/s] 38%|███▊      | 39/102 [00:12<00:15,  3.96it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.95it/s] 40%|████      | 41/102 [00:13<00:15,  3.88it/s] 41%|████      | 42/102 [00:13<00:15,  3.89it/s] 42%|████▏     | 43/102 [00:13<00:14,  3.94it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.95it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.98it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.96it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.88it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.91it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.97it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.98it/s] 50%|█████     | 51/102 [00:15<00:12,  3.95it/s] 51%|█████     | 52/102 [00:16<00:11,  4.21it/s] 52%|█████▏    | 53/102 [00:16<00:11,  4.10it/s] 53%|█████▎    | 54/102 [00:16<00:11,  4.03it/s] 54%|█████▍    | 55/102 [00:16<00:11,  4.00it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.98it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.95it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.99it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.00it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.97it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.99it/s] 61%|██████    | 62/102 [00:18<00:10,  3.95it/s] 62%|██████▏   | 63/102 [00:18<00:09,  3.93it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.90it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.91it/s] 65%|██████▍   | 66/102 [00:19<00:08,  4.06it/s] 66%|██████▌   | 67/102 [00:19<00:08,  4.36it/s] 67%|██████▋   | 68/102 [00:20<00:08,  4.22it/s] 68%|██████▊   | 69/102 [00:20<00:08,  4.08it/s] 69%|██████▊   | 70/102 [00:20<00:08,  4.00it/s] 70%|██████▉   | 71/102 [00:20<00:07,  3.98it/s] 71%|███████   | 72/102 [00:21<00:06,  4.40it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.31it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.94it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.49it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.96it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.33it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.64it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.86it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.03it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.15it/s] 80%|████████  | 82/102 [00:22<00:02,  7.23it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.30it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.29it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.33it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.37it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.38it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.39it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.40it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.42it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.42it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.03it/s]=> result
* total: 10,200
* correct: 9,202
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%

epoch [20/30] batch [20/204] time 0.352 (0.299) data 0.000 (0.035) loss -0.0091 (0.8944) lr 2.9663e-03 eta 0:11:04
epoch [20/30] batch [40/204] time 0.264 (0.278) data 0.000 (0.018) loss 1.6260 (1.0489) lr 2.9663e-03 eta 0:10:12
epoch [20/30] batch [60/204] time 0.264 (0.272) data 0.000 (0.012) loss 1.4717 (0.9252) lr 2.9663e-03 eta 0:09:53
epoch [20/30] batch [80/204] time 0.258 (0.268) data 0.000 (0.009) loss 1.5752 (0.9175) lr 2.9663e-03 eta 0:09:40
epoch [20/30] batch [100/204] time 0.255 (0.266) data 0.000 (0.007) loss 0.9473 (0.8676) lr 2.9663e-03 eta 0:09:30
epoch [20/30] batch [120/204] time 0.255 (0.265) data 0.000 (0.006) loss 0.6377 (0.8944) lr 2.9663e-03 eta 0:09:22
epoch [20/30] batch [140/204] time 0.259 (0.264) data 0.000 (0.005) loss 0.1482 (0.9171) lr 2.9663e-03 eta 0:09:15
epoch [20/30] batch [160/204] time 0.259 (0.263) data 0.000 (0.005) loss -0.0463 (0.9280) lr 2.9663e-03 eta 0:09:07
epoch [20/30] batch [180/204] time 0.243 (0.262) data 0.000 (0.004) loss 1.5771 (0.9523) lr 2.9663e-03 eta 0:09:00
epoch [20/30] batch [200/204] time 0.243 (0.260) data 0.000 (0.004) loss 0.7383 (0.9344) lr 2.9663e-03 eta 0:08:51
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:16,  2.54s/it]  2%|▏         | 2/102 [00:03<02:15,  1.35s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:03<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.34it/s]  7%|▋         | 7/102 [00:04<00:35,  2.68it/s]  8%|▊         | 8/102 [00:04<00:31,  2.99it/s]  9%|▉         | 9/102 [00:05<00:28,  3.24it/s] 10%|▉         | 10/102 [00:05<00:26,  3.41it/s] 11%|█         | 11/102 [00:05<00:24,  3.64it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.73it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.78it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.75it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.78it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.80it/s] 17%|█▋        | 17/102 [00:07<00:21,  4.03it/s] 18%|█▊        | 18/102 [00:07<00:20,  4.08it/s] 19%|█▊        | 19/102 [00:07<00:20,  4.00it/s] 20%|█▉        | 20/102 [00:07<00:20,  3.94it/s] 21%|██        | 21/102 [00:08<00:20,  3.91it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.86it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:08<00:19,  4.09it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.99it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.96it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.92it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.92it/s] 28%|██▊       | 29/102 [00:10<00:18,  4.00it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.95it/s] 30%|███       | 31/102 [00:10<00:18,  3.88it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.82it/s] 32%|███▏      | 33/102 [00:11<00:17,  4.05it/s] 33%|███▎      | 34/102 [00:11<00:15,  4.37it/s] 34%|███▍      | 35/102 [00:11<00:15,  4.25it/s] 35%|███▌      | 36/102 [00:11<00:16,  4.11it/s] 36%|███▋      | 37/102 [00:12<00:16,  4.03it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.98it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.88it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.86it/s] 40%|████      | 41/102 [00:13<00:15,  3.84it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.86it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.86it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.84it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.82it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.89it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.91it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.87it/s] 50%|█████     | 51/102 [00:15<00:13,  3.83it/s] 51%|█████     | 52/102 [00:15<00:13,  3.81it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.84it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.86it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.84it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.84it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.85it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.88it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.85it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.86it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.84it/s] 61%|██████    | 62/102 [00:18<00:10,  3.80it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.82it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.83it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.80it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.79it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.86it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.83it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.81it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.83it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.81it/s] 71%|███████   | 72/102 [00:21<00:07,  3.90it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.52it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.12it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.66it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.10it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.45it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.73it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.93it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.20it/s] 80%|████████  | 82/102 [00:22<00:02,  7.28it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.39it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.44it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.44it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.46it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.47it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.46it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.47it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.48it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.47it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.48it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.47it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.48it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.47it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.47it/s]100%|██████████| 102/102 [00:25<00:00,  7.46it/s]100%|██████████| 102/102 [00:25<00:00,  4.04it/s]=> result
* total: 10,200
* correct: 9,203
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/204] time 0.256 (0.296) data 0.000 (0.038) loss 0.2900 (0.9015) lr 2.5000e-03 eta 0:09:57
epoch [21/30] batch [40/204] time 0.258 (0.277) data 0.000 (0.019) loss 0.2222 (0.8756) lr 2.5000e-03 eta 0:09:14
epoch [21/30] batch [60/204] time 0.263 (0.273) data 0.000 (0.013) loss 0.0717 (0.8758) lr 2.5000e-03 eta 0:09:00
epoch [21/30] batch [80/204] time 0.262 (0.269) data 0.000 (0.010) loss 2.1641 (0.9481) lr 2.5000e-03 eta 0:08:47
epoch [21/30] batch [100/204] time 0.255 (0.267) data 0.000 (0.008) loss 3.6328 (0.9914) lr 2.5000e-03 eta 0:08:38
epoch [21/30] batch [120/204] time 0.257 (0.266) data 0.000 (0.007) loss 0.2729 (1.0211) lr 2.5000e-03 eta 0:08:30
epoch [21/30] batch [140/204] time 0.253 (0.264) data 0.000 (0.006) loss 1.8428 (0.9922) lr 2.5000e-03 eta 0:08:22
epoch [21/30] batch [160/204] time 0.257 (0.263) data 0.000 (0.005) loss 0.2023 (1.0414) lr 2.5000e-03 eta 0:08:14
epoch [21/30] batch [180/204] time 0.246 (0.262) data 0.000 (0.004) loss 1.3477 (0.9842) lr 2.5000e-03 eta 0:08:07
epoch [21/30] batch [200/204] time 0.245 (0.261) data 0.000 (0.004) loss 0.6074 (0.9654) lr 2.5000e-03 eta 0:07:59
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:19,  2.57s/it]  2%|▏         | 2/102 [00:03<02:24,  1.44s/it]  3%|▎         | 3/102 [00:03<01:31,  1.08it/s]  4%|▍         | 4/102 [00:03<01:05,  1.51it/s]  5%|▍         | 5/102 [00:04<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.29it/s]  7%|▋         | 7/102 [00:04<00:35,  2.64it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:05<00:29,  3.15it/s] 10%|▉         | 10/102 [00:05<00:27,  3.34it/s] 11%|█         | 11/102 [00:05<00:26,  3.46it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.58it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.66it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.72it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.76it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.77it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.78it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.85it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.86it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.83it/s] 21%|██        | 21/102 [00:08<00:21,  3.81it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.82it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:09<00:20,  3.88it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.91it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.87it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.83it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.84it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.84it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.87it/s] 30%|███       | 31/102 [00:10<00:18,  3.86it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.87it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.87it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.82it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.80it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.81it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.80it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.81it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.82it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.88it/s] 40%|████      | 41/102 [00:13<00:15,  3.86it/s] 41%|████      | 42/102 [00:13<00:15,  3.89it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.82it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.84it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.81it/s] 46%|████▌     | 47/102 [00:15<00:14,  3.81it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.82it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.86it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.84it/s] 50%|█████     | 51/102 [00:16<00:13,  3.82it/s] 51%|█████     | 52/102 [00:16<00:13,  3.84it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.90it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.83it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.82it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.80it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.79it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.78it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.77it/s] 59%|█████▉    | 60/102 [00:18<00:11,  3.79it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.80it/s] 61%|██████    | 62/102 [00:18<00:10,  3.84it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.85it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.83it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.85it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.83it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.79it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.82it/s] 69%|██████▊   | 70/102 [00:21<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.85it/s] 71%|███████   | 72/102 [00:21<00:07,  3.95it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.48it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.09it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.62it/s] 75%|███████▍  | 76/102 [00:22<00:04,  6.07it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.42it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.71it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.93it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.07it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:23<00:02,  7.31it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.35it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.42it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.38it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.40it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.41it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.41it/s] 96%|█████████▌| 98/102 [00:25<00:00,  7.41it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.45it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.96it/s]=> result
* total: 10,200
* correct: 9,202
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 90.2%

epoch [22/30] batch [20/204] time 0.253 (0.296) data 0.000 (0.036) loss 0.7354 (0.6249) lr 2.0611e-03 eta 0:08:57
epoch [22/30] batch [40/204] time 0.260 (0.277) data 0.001 (0.018) loss 0.1008 (0.6449) lr 2.0611e-03 eta 0:08:17
epoch [22/30] batch [60/204] time 0.263 (0.271) data 0.000 (0.012) loss 0.6982 (0.7097) lr 2.0611e-03 eta 0:08:01
epoch [22/30] batch [80/204] time 0.259 (0.269) data 0.000 (0.009) loss -0.0334 (0.7982) lr 2.0611e-03 eta 0:07:51
epoch [22/30] batch [100/204] time 0.258 (0.267) data 0.000 (0.007) loss -0.0163 (0.9019) lr 2.0611e-03 eta 0:07:42
epoch [22/30] batch [120/204] time 0.268 (0.265) data 0.000 (0.006) loss 1.1133 (0.9198) lr 2.0611e-03 eta 0:07:34
epoch [22/30] batch [140/204] time 0.255 (0.264) data 0.000 (0.005) loss 0.0984 (0.9175) lr 2.0611e-03 eta 0:07:27
epoch [22/30] batch [160/204] time 0.258 (0.263) data 0.000 (0.005) loss 0.0042 (0.9261) lr 2.0611e-03 eta 0:07:21
epoch [22/30] batch [180/204] time 0.246 (0.262) data 0.000 (0.004) loss 0.4287 (0.9156) lr 2.0611e-03 eta 0:07:13
epoch [22/30] batch [200/204] time 0.246 (0.261) data 0.000 (0.004) loss -0.0059 (0.8859) lr 2.0611e-03 eta 0:07:06
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:17,  2.55s/it]  2%|▏         | 2/102 [00:03<02:21,  1.41s/it]  3%|▎         | 3/102 [00:03<01:30,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:04<00:50,  1.92it/s]  6%|▌         | 6/102 [00:04<00:41,  2.30it/s]  7%|▋         | 7/102 [00:04<00:35,  2.64it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:05<00:29,  3.16it/s] 10%|▉         | 10/102 [00:05<00:27,  3.35it/s] 11%|█         | 11/102 [00:05<00:26,  3.48it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.56it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.64it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.69it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.80it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.80it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.81it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.80it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.80it/s] 21%|██        | 21/102 [00:08<00:21,  3.80it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.80it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.85it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.86it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.83it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.85it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.83it/s] 27%|██▋       | 28/102 [00:10<00:19,  3.79it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.83it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.79it/s] 30%|███       | 31/102 [00:10<00:18,  3.81it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.83it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.85it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.85it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.85it/s] 35%|███▌      | 36/102 [00:12<00:16,  3.88it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.86it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.80it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.80it/s] 40%|████      | 41/102 [00:13<00:15,  3.82it/s] 41%|████      | 42/102 [00:13<00:15,  3.80it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.85it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.84it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.83it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.86it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.84it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.84it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.82it/s] 50%|█████     | 51/102 [00:16<00:13,  3.81it/s] 51%|█████     | 52/102 [00:16<00:12,  3.86it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.86it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.84it/s] 54%|█████▍    | 55/102 [00:17<00:12,  3.84it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.83it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.84it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.84it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.82it/s] 59%|█████▉    | 60/102 [00:18<00:11,  3.80it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.79it/s] 61%|██████    | 62/102 [00:18<00:10,  3.84it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.86it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.86it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.87it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.86it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.82it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.82it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.86it/s] 71%|███████   | 72/102 [00:21<00:07,  3.97it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.38it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.00it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.49it/s] 75%|███████▍  | 76/102 [00:22<00:04,  5.95it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.34it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.63it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.86it/s] 78%|███████▊  | 80/102 [00:22<00:03,  6.98it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.10it/s] 80%|████████  | 82/102 [00:22<00:02,  7.19it/s] 81%|████████▏ | 83/102 [00:23<00:02,  7.28it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.38it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:24<00:01,  7.44it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:25<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.46it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.28it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.33it/s]100%|██████████| 102/102 [00:25<00:00,  7.36it/s]100%|██████████| 102/102 [00:25<00:00,  3.97it/s]=> result
* total: 10,200
* correct: 9,212
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [23/30] batch [20/204] time 0.255 (0.296) data 0.000 (0.036) loss 2.1504 (0.6391) lr 1.6543e-03 eta 0:07:57
epoch [23/30] batch [40/204] time 0.248 (0.276) data 0.000 (0.018) loss 0.1478 (0.6701) lr 1.6543e-03 eta 0:07:19
epoch [23/30] batch [60/204] time 0.256 (0.269) data 0.000 (0.012) loss -0.0060 (0.6942) lr 1.6543e-03 eta 0:07:02
epoch [23/30] batch [80/204] time 0.258 (0.266) data 0.000 (0.009) loss 0.1615 (0.6817) lr 1.6543e-03 eta 0:06:52
epoch [23/30] batch [100/204] time 0.259 (0.265) data 0.000 (0.007) loss 0.8257 (0.7726) lr 1.6543e-03 eta 0:06:45
epoch [23/30] batch [120/204] time 0.250 (0.264) data 0.000 (0.006) loss 1.6387 (0.7783) lr 1.6543e-03 eta 0:06:38
epoch [23/30] batch [140/204] time 0.260 (0.263) data 0.000 (0.005) loss 0.3899 (0.7513) lr 1.6543e-03 eta 0:06:32
epoch [23/30] batch [160/204] time 0.256 (0.263) data 0.000 (0.005) loss 0.8320 (0.7690) lr 1.6543e-03 eta 0:06:26
epoch [23/30] batch [180/204] time 0.244 (0.262) data 0.000 (0.004) loss 2.2676 (0.8342) lr 1.6543e-03 eta 0:06:19
epoch [23/30] batch [200/204] time 0.244 (0.260) data 0.000 (0.004) loss 1.4727 (0.8076) lr 1.6543e-03 eta 0:06:12
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:19,  2.57s/it]  2%|▏         | 2/102 [00:03<02:19,  1.39s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:04<00:50,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.30it/s]  7%|▋         | 7/102 [00:04<00:36,  2.63it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:05<00:29,  3.15it/s] 10%|▉         | 10/102 [00:05<00:26,  3.53it/s] 11%|█         | 11/102 [00:05<00:25,  3.63it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.72it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.76it/s] 14%|█▎        | 14/102 [00:06<00:22,  3.84it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.85it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.81it/s] 17%|█▋        | 17/102 [00:07<00:20,  4.07it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.99it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.95it/s] 20%|█▉        | 20/102 [00:07<00:20,  3.94it/s] 21%|██        | 21/102 [00:08<00:20,  3.97it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.94it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.92it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.83it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.99it/s] 25%|██▌       | 26/102 [00:09<00:18,  4.02it/s] 26%|██▋       | 27/102 [00:09<00:18,  3.98it/s] 27%|██▋       | 28/102 [00:09<00:18,  3.94it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.89it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.90it/s] 30%|███       | 31/102 [00:10<00:18,  3.89it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.88it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.89it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.88it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.84it/s] 35%|███▌      | 36/102 [00:11<00:15,  4.14it/s] 36%|███▋      | 37/102 [00:12<00:14,  4.45it/s] 37%|███▋      | 38/102 [00:12<00:15,  4.22it/s] 38%|███▊      | 39/102 [00:12<00:14,  4.30it/s] 39%|███▉      | 40/102 [00:12<00:14,  4.38it/s] 40%|████      | 41/102 [00:13<00:14,  4.20it/s] 41%|████      | 42/102 [00:13<00:14,  4.13it/s] 42%|████▏     | 43/102 [00:13<00:14,  4.09it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.99it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.94it/s] 45%|████▌     | 46/102 [00:14<00:13,  4.01it/s] 46%|████▌     | 47/102 [00:14<00:13,  3.94it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.93it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.89it/s] 49%|████▉     | 50/102 [00:15<00:12,  4.10it/s] 50%|█████     | 51/102 [00:15<00:12,  4.05it/s] 51%|█████     | 52/102 [00:15<00:12,  4.03it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.97it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.97it/s] 54%|█████▍    | 55/102 [00:16<00:11,  3.97it/s] 55%|█████▍    | 56/102 [00:16<00:11,  3.94it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.93it/s] 57%|█████▋    | 58/102 [00:17<00:10,  4.16it/s] 58%|█████▊    | 59/102 [00:17<00:10,  4.08it/s] 59%|█████▉    | 60/102 [00:17<00:10,  3.98it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.95it/s] 61%|██████    | 62/102 [00:18<00:10,  3.93it/s] 62%|██████▏   | 63/102 [00:18<00:09,  4.07it/s] 63%|██████▎   | 64/102 [00:18<00:09,  3.96it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.94it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.90it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.88it/s] 67%|██████▋   | 68/102 [00:19<00:08,  3.83it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.83it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.80it/s] 70%|██████▉   | 71/102 [00:20<00:08,  3.85it/s] 71%|███████   | 72/102 [00:20<00:07,  3.88it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.19it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.82it/s] 74%|███████▎  | 75/102 [00:21<00:05,  5.39it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.88it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.28it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.59it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.83it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.01it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.13it/s] 80%|████████  | 82/102 [00:22<00:02,  7.12it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.22it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.08it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.19it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.25it/s] 85%|████████▌ | 87/102 [00:22<00:02,  7.32it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.35it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.27it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.32it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.36it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.06it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.16it/s] 92%|█████████▏| 94/102 [00:23<00:01,  7.25it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.31it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.37it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.11it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.23it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.30it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.35it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.38it/s]100%|██████████| 102/102 [00:25<00:00,  7.41it/s]100%|██████████| 102/102 [00:25<00:00,  4.06it/s]=> result
* total: 10,200
* correct: 9,219
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [24/30] batch [20/204] time 0.254 (0.296) data 0.000 (0.038) loss 0.4009 (1.0803) lr 1.2843e-03 eta 0:06:57
epoch [24/30] batch [40/204] time 0.258 (0.276) data 0.000 (0.019) loss 2.1309 (0.8183) lr 1.2843e-03 eta 0:06:23
epoch [24/30] batch [60/204] time 0.260 (0.271) data 0.000 (0.013) loss 2.3086 (0.8608) lr 1.2843e-03 eta 0:06:11
epoch [24/30] batch [80/204] time 0.255 (0.268) data 0.000 (0.010) loss 1.4551 (0.9551) lr 1.2843e-03 eta 0:06:00
epoch [24/30] batch [100/204] time 0.257 (0.266) data 0.000 (0.008) loss 2.1445 (0.9834) lr 1.2843e-03 eta 0:05:52
epoch [24/30] batch [120/204] time 0.261 (0.264) data 0.000 (0.007) loss 0.0457 (0.9573) lr 1.2843e-03 eta 0:05:45
epoch [24/30] batch [140/204] time 0.260 (0.263) data 0.000 (0.006) loss -0.0291 (0.9456) lr 1.2843e-03 eta 0:05:39
epoch [24/30] batch [160/204] time 0.256 (0.263) data 0.000 (0.005) loss 0.2103 (0.9626) lr 1.2843e-03 eta 0:05:33
epoch [24/30] batch [180/204] time 0.246 (0.261) data 0.000 (0.005) loss 0.5151 (0.9393) lr 1.2843e-03 eta 0:05:26
epoch [24/30] batch [200/204] time 0.244 (0.260) data 0.000 (0.004) loss 2.1289 (0.9301) lr 1.2843e-03 eta 0:05:19
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<03:55,  2.33s/it]  2%|▏         | 2/102 [00:02<02:03,  1.24s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:06,  1.48it/s]  5%|▍         | 5/102 [00:03<00:51,  1.88it/s]  6%|▌         | 6/102 [00:04<00:42,  2.25it/s]  7%|▋         | 7/102 [00:04<00:35,  2.65it/s]  8%|▊         | 8/102 [00:04<00:30,  3.07it/s]  9%|▉         | 9/102 [00:04<00:28,  3.29it/s] 10%|▉         | 10/102 [00:05<00:26,  3.44it/s] 11%|█         | 11/102 [00:05<00:25,  3.52it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.60it/s] 13%|█▎        | 13/102 [00:05<00:24,  3.71it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.75it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.79it/s] 17%|█▋        | 17/102 [00:06<00:22,  3.80it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.82it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.88it/s] 20%|█▉        | 20/102 [00:07<00:20,  3.93it/s] 21%|██        | 21/102 [00:08<00:20,  3.89it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.89it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.89it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.87it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.87it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.91it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.87it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.84it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.85it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.84it/s] 30%|███       | 31/102 [00:10<00:18,  3.83it/s] 31%|███▏      | 32/102 [00:10<00:18,  3.88it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.80it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.84it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.85it/s] 35%|███▌      | 36/102 [00:11<00:17,  3.84it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.85it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.80it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.82it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.80it/s] 40%|████      | 41/102 [00:13<00:15,  3.87it/s] 41%|████      | 42/102 [00:13<00:15,  3.84it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.80it/s] 43%|████▎     | 44/102 [00:13<00:15,  3.83it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.85it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.85it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.87it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.88it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.91it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.85it/s] 50%|█████     | 51/102 [00:15<00:13,  3.84it/s] 51%|█████     | 52/102 [00:16<00:13,  3.83it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.81it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.79it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.80it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.81it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.81it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.83it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.84it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.85it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.86it/s] 61%|██████    | 62/102 [00:18<00:10,  3.87it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.85it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.85it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.80it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.80it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.83it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.81it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.82it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.89it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.89it/s] 71%|███████   | 72/102 [00:21<00:07,  3.93it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.36it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.98it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.53it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.99it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.37it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.66it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.88it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.04it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.16it/s] 80%|████████  | 82/102 [00:22<00:02,  7.24it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.39it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.40it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.42it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.42it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.00it/s]=> result
* total: 10,200
* correct: 9,211
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [25/30] batch [20/204] time 0.251 (0.301) data 0.000 (0.036) loss 2.9180 (0.8108) lr 9.5492e-04 eta 0:06:02
epoch [25/30] batch [40/204] time 0.259 (0.279) data 0.000 (0.018) loss 2.1465 (1.0487) lr 9.5492e-04 eta 0:05:30
epoch [25/30] batch [60/204] time 0.252 (0.271) data 0.000 (0.012) loss -0.0528 (0.9263) lr 9.5492e-04 eta 0:05:15
epoch [25/30] batch [80/204] time 0.258 (0.267) data 0.000 (0.009) loss 2.3398 (0.9111) lr 9.5492e-04 eta 0:05:05
epoch [25/30] batch [100/204] time 0.262 (0.265) data 0.000 (0.007) loss 0.1311 (0.8240) lr 9.5492e-04 eta 0:04:57
epoch [25/30] batch [120/204] time 0.255 (0.263) data 0.000 (0.006) loss 0.8945 (0.8367) lr 9.5492e-04 eta 0:04:50
epoch [25/30] batch [140/204] time 0.255 (0.262) data 0.000 (0.005) loss 2.7012 (0.8736) lr 9.5492e-04 eta 0:04:43
epoch [25/30] batch [160/204] time 0.246 (0.260) data 0.000 (0.005) loss 0.2412 (0.8536) lr 9.5492e-04 eta 0:04:37
epoch [25/30] batch [180/204] time 0.246 (0.259) data 0.000 (0.004) loss 0.0551 (0.8665) lr 9.5492e-04 eta 0:04:30
epoch [25/30] batch [200/204] time 0.244 (0.258) data 0.000 (0.004) loss 1.7061 (0.8816) lr 9.5492e-04 eta 0:04:24
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<03:57,  2.35s/it]  2%|▏         | 2/102 [00:03<02:16,  1.37s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:03<00:50,  1.91it/s]  6%|▌         | 6/102 [00:04<00:42,  2.29it/s]  7%|▋         | 7/102 [00:04<00:35,  2.64it/s]  8%|▊         | 8/102 [00:04<00:32,  2.92it/s]  9%|▉         | 9/102 [00:05<00:29,  3.14it/s] 10%|▉         | 10/102 [00:05<00:27,  3.33it/s] 11%|█         | 11/102 [00:05<00:26,  3.47it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.58it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.64it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.72it/s] 16%|█▌        | 16/102 [00:06<00:23,  3.73it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.75it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.77it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.80it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.80it/s] 21%|██        | 21/102 [00:08<00:21,  3.81it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.83it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.86it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.85it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.84it/s] 25%|██▌       | 26/102 [00:09<00:20,  3.79it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.83it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.84it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.85it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.83it/s] 30%|███       | 31/102 [00:10<00:18,  3.90it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.88it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.86it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.90it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.87it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.88it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.86it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.85it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.82it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.81it/s] 40%|████      | 41/102 [00:13<00:15,  3.83it/s] 41%|████      | 42/102 [00:13<00:15,  3.84it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.80it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.83it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.81it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.82it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:15<00:13,  3.87it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.86it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.84it/s] 50%|█████     | 51/102 [00:15<00:13,  3.91it/s] 51%|█████     | 52/102 [00:16<00:12,  3.88it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.89it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.85it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.83it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.86it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.87it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.84it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.87it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.89it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.84it/s] 61%|██████    | 62/102 [00:18<00:10,  3.83it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.84it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.83it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.83it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.86it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.89it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.91it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.89it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.85it/s] 70%|██████▉   | 71/102 [00:21<00:07,  3.88it/s] 71%|███████   | 72/102 [00:21<00:07,  3.92it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.49it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.09it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.62it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.07it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.42it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.70it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.91it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.06it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.24it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.30it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.37it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.33it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.36it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.39it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.41it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.42it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.44it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.44it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,211
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [26/30] batch [20/204] time 0.257 (0.298) data 0.000 (0.035) loss 0.7490 (0.8263) lr 6.6987e-04 eta 0:04:58
epoch [26/30] batch [40/204] time 0.251 (0.278) data 0.000 (0.017) loss 2.1309 (0.8251) lr 6.6987e-04 eta 0:04:32
epoch [26/30] batch [60/204] time 0.254 (0.273) data 0.000 (0.012) loss 0.5879 (0.7628) lr 6.6987e-04 eta 0:04:21
epoch [26/30] batch [80/204] time 0.279 (0.269) data 0.000 (0.009) loss 2.4824 (0.8364) lr 6.6987e-04 eta 0:04:12
epoch [26/30] batch [100/204] time 0.256 (0.266) data 0.000 (0.007) loss 0.9263 (0.8167) lr 6.6987e-04 eta 0:04:04
epoch [26/30] batch [120/204] time 0.255 (0.264) data 0.000 (0.006) loss 2.3867 (0.8569) lr 6.6987e-04 eta 0:03:57
epoch [26/30] batch [140/204] time 0.255 (0.263) data 0.000 (0.005) loss 1.6533 (0.8379) lr 6.6987e-04 eta 0:03:51
epoch [26/30] batch [160/204] time 0.254 (0.262) data 0.000 (0.005) loss 1.8330 (0.8791) lr 6.6987e-04 eta 0:03:45
epoch [26/30] batch [180/204] time 0.244 (0.261) data 0.000 (0.004) loss 1.9512 (0.8543) lr 6.6987e-04 eta 0:03:39
epoch [26/30] batch [200/204] time 0.242 (0.260) data 0.000 (0.004) loss 3.2012 (0.8622) lr 6.6987e-04 eta 0:03:32
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<03:58,  2.37s/it]  2%|▏         | 2/102 [00:02<02:14,  1.34s/it]  3%|▎         | 3/102 [00:03<01:32,  1.07it/s]  4%|▍         | 4/102 [00:03<01:05,  1.49it/s]  5%|▍         | 5/102 [00:03<00:51,  1.88it/s]  6%|▌         | 6/102 [00:04<00:42,  2.26it/s]  7%|▋         | 7/102 [00:04<00:36,  2.62it/s]  8%|▊         | 8/102 [00:04<00:32,  2.91it/s]  9%|▉         | 9/102 [00:05<00:29,  3.18it/s] 10%|▉         | 10/102 [00:05<00:27,  3.33it/s] 11%|█         | 11/102 [00:05<00:26,  3.47it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.59it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.64it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.69it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.70it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.75it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.78it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.80it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.81it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.84it/s] 21%|██        | 21/102 [00:08<00:21,  3.82it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.81it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.82it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.85it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.83it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.88it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.85it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.83it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.87it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.87it/s] 30%|███       | 31/102 [00:10<00:18,  3.89it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.86it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.82it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.87it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.83it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.82it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.83it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.86it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.84it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.80it/s] 40%|████      | 41/102 [00:13<00:15,  3.81it/s] 41%|████      | 42/102 [00:13<00:15,  3.83it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.87it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.85it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.86it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.86it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.85it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.83it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.87it/s] 50%|█████     | 51/102 [00:15<00:13,  3.90it/s] 51%|█████     | 52/102 [00:16<00:12,  3.91it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.93it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.90it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.88it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.88it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.88it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.96it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.87it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.87it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.85it/s] 61%|██████    | 62/102 [00:18<00:09,  4.17it/s] 62%|██████▏   | 63/102 [00:18<00:09,  4.22it/s] 63%|██████▎   | 64/102 [00:19<00:09,  4.12it/s] 64%|██████▎   | 65/102 [00:19<00:09,  4.00it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.94it/s] 66%|██████▌   | 67/102 [00:19<00:08,  3.99it/s] 67%|██████▋   | 68/102 [00:20<00:08,  4.08it/s] 68%|██████▊   | 69/102 [00:20<00:08,  4.10it/s] 69%|██████▊   | 70/102 [00:20<00:07,  4.01it/s] 70%|██████▉   | 71/102 [00:20<00:07,  4.23it/s] 71%|███████   | 72/102 [00:21<00:07,  4.13it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.29it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.92it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.47it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.94it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.32it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.62it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.85it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.01it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.13it/s] 80%|████████  | 82/102 [00:22<00:02,  7.22it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.28it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.32it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.37it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.39it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.41it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.35it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.37it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.39it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.41it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.41it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.43it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.44it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.42it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  4.01it/s]=> result
* total: 10,200
* correct: 9,208
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.2%

epoch [27/30] batch [20/204] time 0.252 (0.294) data 0.000 (0.034) loss 1.2832 (0.9538) lr 4.3227e-04 eta 0:03:54
epoch [27/30] batch [40/204] time 0.255 (0.276) data 0.000 (0.017) loss 2.6523 (0.9772) lr 4.3227e-04 eta 0:03:34
epoch [27/30] batch [60/204] time 0.255 (0.270) data 0.000 (0.012) loss 2.4863 (1.0137) lr 4.3227e-04 eta 0:03:24
epoch [27/30] batch [80/204] time 0.256 (0.267) data 0.000 (0.009) loss 0.4563 (1.0798) lr 4.3227e-04 eta 0:03:16
epoch [27/30] batch [100/204] time 0.252 (0.265) data 0.000 (0.007) loss 0.2629 (1.0311) lr 4.3227e-04 eta 0:03:09
epoch [27/30] batch [120/204] time 0.249 (0.264) data 0.000 (0.006) loss 0.2803 (0.9837) lr 4.3227e-04 eta 0:03:03
epoch [27/30] batch [140/204] time 0.252 (0.264) data 0.000 (0.005) loss 1.5576 (0.9751) lr 4.3227e-04 eta 0:02:58
epoch [27/30] batch [160/204] time 0.262 (0.263) data 0.000 (0.004) loss 0.0639 (0.9503) lr 4.3227e-04 eta 0:02:52
epoch [27/30] batch [180/204] time 0.243 (0.262) data 0.000 (0.004) loss 0.7861 (0.9474) lr 4.3227e-04 eta 0:02:46
epoch [27/30] batch [200/204] time 0.242 (0.260) data 0.000 (0.004) loss 0.8857 (0.9066) lr 4.3227e-04 eta 0:02:40
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:29,  2.67s/it]  2%|▏         | 2/102 [00:03<02:24,  1.44s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:03,  1.53it/s]  5%|▍         | 5/102 [00:04<00:49,  1.95it/s]  6%|▌         | 6/102 [00:04<00:41,  2.33it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:31,  2.97it/s]  9%|▉         | 9/102 [00:05<00:29,  3.20it/s] 10%|▉         | 10/102 [00:05<00:27,  3.34it/s] 11%|█         | 11/102 [00:05<00:25,  3.51it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.63it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.64it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.73it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.76it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.79it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.81it/s] 18%|█▊        | 18/102 [00:07<00:20,  4.18it/s] 19%|█▊        | 19/102 [00:07<00:20,  4.07it/s] 20%|█▉        | 20/102 [00:07<00:19,  4.17it/s] 21%|██        | 21/102 [00:08<00:19,  4.06it/s] 22%|██▏       | 22/102 [00:08<00:19,  4.01it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.92it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.89it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.84it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.99it/s] 26%|██▋       | 27/102 [00:09<00:18,  4.07it/s] 27%|██▋       | 28/102 [00:09<00:18,  4.01it/s] 28%|██▊       | 29/102 [00:10<00:18,  3.99it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.97it/s] 30%|███       | 31/102 [00:10<00:17,  4.04it/s] 31%|███▏      | 32/102 [00:10<00:17,  4.00it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.95it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.87it/s] 34%|███▍      | 35/102 [00:11<00:16,  4.01it/s] 35%|███▌      | 36/102 [00:11<00:16,  3.97it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.88it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.90it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.90it/s] 39%|███▉      | 40/102 [00:12<00:16,  3.87it/s] 40%|████      | 41/102 [00:13<00:15,  3.87it/s] 41%|████      | 42/102 [00:13<00:15,  3.89it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.88it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.89it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.97it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.93it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.87it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.89it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.86it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.81it/s] 50%|█████     | 51/102 [00:15<00:13,  3.83it/s] 51%|█████     | 52/102 [00:16<00:13,  3.83it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.81it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.80it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.84it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.87it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.86it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.84it/s] 58%|█████▊    | 59/102 [00:17<00:11,  3.88it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.83it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.86it/s] 61%|██████    | 62/102 [00:18<00:10,  3.85it/s] 62%|██████▏   | 63/102 [00:18<00:10,  3.80it/s] 63%|██████▎   | 64/102 [00:19<00:10,  3.78it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.81it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.85it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.83it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.83it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.81it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.80it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.83it/s] 71%|███████   | 72/102 [00:21<00:07,  4.18it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.46it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.06it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.59it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.04it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.41it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.69it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.89it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.05it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.25it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.30it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.34it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.40it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.41it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.43it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.43it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.43it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.43it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.43it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.38it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.40it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.41it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.41it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.43it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  4.01it/s]=> result
* total: 10,200
* correct: 9,212
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [28/30] batch [20/204] time 0.265 (0.300) data 0.000 (0.039) loss 3.6602 (1.2088) lr 2.4472e-04 eta 0:02:57
epoch [28/30] batch [40/204] time 0.264 (0.281) data 0.000 (0.020) loss 1.5234 (1.0887) lr 2.4472e-04 eta 0:02:40
epoch [28/30] batch [60/204] time 0.258 (0.273) data 0.000 (0.013) loss -0.0046 (1.0654) lr 2.4472e-04 eta 0:02:30
epoch [28/30] batch [80/204] time 0.260 (0.269) data 0.000 (0.010) loss 0.4570 (1.0294) lr 2.4472e-04 eta 0:02:23
epoch [28/30] batch [100/204] time 0.254 (0.267) data 0.000 (0.008) loss 4.7930 (1.0711) lr 2.4472e-04 eta 0:02:16
epoch [28/30] batch [120/204] time 0.259 (0.266) data 0.000 (0.007) loss 3.8789 (1.0862) lr 2.4472e-04 eta 0:02:10
epoch [28/30] batch [140/204] time 0.250 (0.265) data 0.000 (0.006) loss 0.2659 (1.0148) lr 2.4472e-04 eta 0:02:04
epoch [28/30] batch [160/204] time 0.257 (0.264) data 0.000 (0.005) loss 0.1145 (1.0120) lr 2.4472e-04 eta 0:01:59
epoch [28/30] batch [180/204] time 0.252 (0.263) data 0.000 (0.005) loss -0.0286 (1.0003) lr 2.4472e-04 eta 0:01:53
epoch [28/30] batch [200/204] time 0.245 (0.261) data 0.000 (0.004) loss -0.0300 (0.9721) lr 2.4472e-04 eta 0:01:47
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:16,  2.54s/it]  2%|▏         | 2/102 [00:03<02:17,  1.38s/it]  3%|▎         | 3/102 [00:03<01:29,  1.11it/s]  4%|▍         | 4/102 [00:03<01:04,  1.53it/s]  5%|▍         | 5/102 [00:03<00:49,  1.94it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.67it/s]  8%|▊         | 8/102 [00:04<00:31,  2.96it/s]  9%|▉         | 9/102 [00:05<00:29,  3.20it/s] 10%|▉         | 10/102 [00:05<00:27,  3.40it/s] 11%|█         | 11/102 [00:05<00:25,  3.50it/s] 12%|█▏        | 12/102 [00:05<00:24,  3.61it/s] 13%|█▎        | 13/102 [00:06<00:23,  3.71it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.71it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.76it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.79it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.84it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.89it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.85it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.88it/s] 21%|██        | 21/102 [00:08<00:20,  3.87it/s] 22%|██▏       | 22/102 [00:08<00:20,  3.85it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.83it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.84it/s] 25%|██▍       | 25/102 [00:09<00:19,  3.85it/s] 25%|██▌       | 26/102 [00:09<00:19,  3.86it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.82it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.82it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.82it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.80it/s] 30%|███       | 31/102 [00:10<00:18,  3.79it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.79it/s] 32%|███▏      | 33/102 [00:11<00:18,  3.83it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.81it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.85it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.83it/s] 36%|███▋      | 37/102 [00:12<00:17,  3.81it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.82it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.84it/s] 39%|███▉      | 40/102 [00:13<00:15,  3.89it/s] 40%|████      | 41/102 [00:13<00:15,  3.88it/s] 41%|████      | 42/102 [00:13<00:15,  3.83it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.83it/s] 43%|████▎     | 44/102 [00:14<00:14,  3.87it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.87it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.86it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.82it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.81it/s] 48%|████▊     | 49/102 [00:15<00:14,  3.78it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.82it/s] 50%|█████     | 51/102 [00:15<00:13,  3.81it/s] 51%|█████     | 52/102 [00:16<00:13,  3.80it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.83it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.84it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.86it/s] 55%|█████▍    | 56/102 [00:17<00:12,  3.81it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.84it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.82it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.82it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.88it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.87it/s] 61%|██████    | 62/102 [00:18<00:10,  3.89it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.88it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.90it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.87it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.86it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.85it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.86it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.84it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.83it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.87it/s] 71%|███████   | 72/102 [00:21<00:07,  3.91it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.56it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.16it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.68it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.06it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.43it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.71it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.91it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.06it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.17it/s] 80%|████████  | 82/102 [00:22<00:02,  7.25it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.30it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.36it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.28it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.33it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.37it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.39it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.41it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.34it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.37it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.40it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.42it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.43it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.43it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.42it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.43it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.43it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  7.44it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,212
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [29/30] batch [20/204] time 0.253 (0.296) data 0.000 (0.035) loss 2.3301 (0.7728) lr 1.0926e-04 eta 0:01:54
epoch [29/30] batch [40/204] time 0.255 (0.277) data 0.000 (0.018) loss 5.0781 (0.8967) lr 1.0926e-04 eta 0:01:41
epoch [29/30] batch [60/204] time 0.274 (0.272) data 0.000 (0.012) loss 1.1221 (0.8966) lr 1.0926e-04 eta 0:01:34
epoch [29/30] batch [80/204] time 0.264 (0.268) data 0.000 (0.009) loss 0.2324 (0.9037) lr 1.0926e-04 eta 0:01:28
epoch [29/30] batch [100/204] time 0.254 (0.266) data 0.000 (0.007) loss 0.4893 (0.8961) lr 1.0926e-04 eta 0:01:21
epoch [29/30] batch [120/204] time 0.262 (0.264) data 0.000 (0.006) loss 0.1926 (0.8689) lr 1.0926e-04 eta 0:01:16
epoch [29/30] batch [140/204] time 0.259 (0.263) data 0.000 (0.005) loss 0.7485 (0.8175) lr 1.0926e-04 eta 0:01:10
epoch [29/30] batch [160/204] time 0.258 (0.263) data 0.000 (0.005) loss 2.0371 (0.8817) lr 1.0926e-04 eta 0:01:05
epoch [29/30] batch [180/204] time 0.247 (0.262) data 0.000 (0.004) loss 0.5117 (0.8532) lr 1.0926e-04 eta 0:00:59
epoch [29/30] batch [200/204] time 0.243 (0.260) data 0.000 (0.004) loss 0.1401 (0.8580) lr 1.0926e-04 eta 0:00:54
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:13,  2.51s/it]  2%|▏         | 2/102 [00:03<02:18,  1.39s/it]  3%|▎         | 3/102 [00:03<01:29,  1.10it/s]  4%|▍         | 4/102 [00:03<01:04,  1.52it/s]  5%|▍         | 5/102 [00:03<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.65it/s]  8%|▊         | 8/102 [00:04<00:32,  2.93it/s]  9%|▉         | 9/102 [00:05<00:29,  3.14it/s] 10%|▉         | 10/102 [00:05<00:27,  3.36it/s] 11%|█         | 11/102 [00:05<00:26,  3.48it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.60it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.66it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.76it/s] 15%|█▍        | 15/102 [00:06<00:23,  3.77it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.86it/s] 17%|█▋        | 17/102 [00:07<00:21,  3.88it/s] 18%|█▊        | 18/102 [00:07<00:21,  3.83it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.83it/s] 20%|█▉        | 20/102 [00:07<00:21,  3.80it/s] 21%|██        | 21/102 [00:08<00:21,  3.82it/s] 22%|██▏       | 22/102 [00:08<00:21,  3.79it/s] 23%|██▎       | 23/102 [00:08<00:20,  3.80it/s] 24%|██▎       | 24/102 [00:08<00:20,  3.81it/s] 25%|██▍       | 25/102 [00:09<00:20,  3.81it/s] 25%|██▌       | 26/102 [00:09<00:20,  3.79it/s] 26%|██▋       | 27/102 [00:09<00:19,  3.81it/s] 27%|██▋       | 28/102 [00:09<00:19,  3.80it/s] 28%|██▊       | 29/102 [00:10<00:19,  3.79it/s] 29%|██▉       | 30/102 [00:10<00:18,  3.82it/s] 30%|███       | 31/102 [00:10<00:18,  3.89it/s] 31%|███▏      | 32/102 [00:11<00:18,  3.83it/s] 32%|███▏      | 33/102 [00:11<00:17,  3.85it/s] 33%|███▎      | 34/102 [00:11<00:17,  3.90it/s] 34%|███▍      | 35/102 [00:11<00:17,  3.86it/s] 35%|███▌      | 36/102 [00:12<00:17,  3.85it/s] 36%|███▋      | 37/102 [00:12<00:16,  3.90it/s] 37%|███▋      | 38/102 [00:12<00:16,  3.87it/s] 38%|███▊      | 39/102 [00:12<00:16,  3.86it/s] 39%|███▉      | 40/102 [00:13<00:16,  3.86it/s] 40%|████      | 41/102 [00:13<00:15,  3.86it/s] 41%|████      | 42/102 [00:13<00:15,  3.85it/s] 42%|████▏     | 43/102 [00:13<00:15,  3.87it/s] 43%|████▎     | 44/102 [00:14<00:15,  3.87it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.87it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.88it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.85it/s] 47%|████▋     | 48/102 [00:15<00:14,  3.83it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.87it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.86it/s] 50%|█████     | 51/102 [00:15<00:13,  3.85it/s] 51%|█████     | 52/102 [00:16<00:13,  3.84it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.83it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.87it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.83it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.84it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.82it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.85it/s] 58%|█████▊    | 59/102 [00:18<00:11,  3.83it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.87it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.86it/s] 61%|██████    | 62/102 [00:18<00:10,  3.84it/s] 62%|██████▏   | 63/102 [00:19<00:10,  3.82it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.84it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.86it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.86it/s] 66%|██████▌   | 67/102 [00:20<00:09,  3.84it/s] 67%|██████▋   | 68/102 [00:20<00:08,  3.84it/s] 68%|██████▊   | 69/102 [00:20<00:08,  3.85it/s] 69%|██████▊   | 70/102 [00:20<00:08,  3.82it/s] 70%|██████▉   | 71/102 [00:21<00:08,  3.86it/s] 71%|███████   | 72/102 [00:21<00:07,  3.92it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.54it/s] 73%|███████▎  | 74/102 [00:21<00:05,  5.14it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.69it/s] 75%|███████▍  | 76/102 [00:21<00:04,  6.13it/s] 75%|███████▌  | 77/102 [00:22<00:03,  6.46it/s] 76%|███████▋  | 78/102 [00:22<00:03,  6.75it/s] 77%|███████▋  | 79/102 [00:22<00:03,  6.94it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.08it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.19it/s] 80%|████████  | 82/102 [00:22<00:02,  7.26it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.32it/s] 82%|████████▏ | 84/102 [00:23<00:02,  7.36it/s] 83%|████████▎ | 85/102 [00:23<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:23<00:02,  7.41it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.42it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.45it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.44it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:24<00:01,  7.46it/s] 91%|█████████ | 93/102 [00:24<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.45it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.45it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.44it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.46it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.45it/s] 97%|█████████▋| 99/102 [00:25<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:25<00:00,  7.46it/s] 99%|█████████▉| 101/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  7.45it/s]100%|██████████| 102/102 [00:25<00:00,  3.99it/s]=> result
* total: 10,200
* correct: 9,211
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%

epoch [30/30] batch [20/204] time 0.252 (0.299) data 0.000 (0.034) loss 0.1261 (0.9703) lr 2.7391e-05 eta 0:00:54
epoch [30/30] batch [40/204] time 0.252 (0.277) data 0.000 (0.017) loss 0.9746 (1.0426) lr 2.7391e-05 eta 0:00:45
epoch [30/30] batch [60/204] time 0.256 (0.270) data 0.000 (0.011) loss -0.0177 (1.0393) lr 2.7391e-05 eta 0:00:38
epoch [30/30] batch [80/204] time 0.250 (0.266) data 0.000 (0.009) loss 0.8770 (1.0167) lr 2.7391e-05 eta 0:00:33
epoch [30/30] batch [100/204] time 0.255 (0.264) data 0.000 (0.007) loss -0.0383 (1.0084) lr 2.7391e-05 eta 0:00:27
epoch [30/30] batch [120/204] time 0.257 (0.263) data 0.000 (0.006) loss 1.2256 (0.9899) lr 2.7391e-05 eta 0:00:22
epoch [30/30] batch [140/204] time 0.257 (0.262) data 0.000 (0.005) loss 0.3674 (0.9775) lr 2.7391e-05 eta 0:00:16
epoch [30/30] batch [160/204] time 0.259 (0.262) data 0.000 (0.004) loss 0.1963 (0.9656) lr 2.7391e-05 eta 0:00:11
epoch [30/30] batch [180/204] time 0.243 (0.260) data 0.000 (0.004) loss 0.4175 (0.9211) lr 2.7391e-05 eta 0:00:06
epoch [30/30] batch [200/204] time 0.243 (0.259) data 0.000 (0.004) loss 0.4075 (0.9565) lr 2.7391e-05 eta 0:00:01
Evaluate on the *val* set
  0%|          | 0/102 [00:00<?, ?it/s]  1%|          | 1/102 [00:02<04:41,  2.78s/it]  2%|▏         | 2/102 [00:03<02:25,  1.46s/it]  3%|▎         | 3/102 [00:03<01:30,  1.09it/s]  4%|▍         | 4/102 [00:03<01:04,  1.51it/s]  5%|▍         | 5/102 [00:04<00:50,  1.93it/s]  6%|▌         | 6/102 [00:04<00:41,  2.32it/s]  7%|▋         | 7/102 [00:04<00:35,  2.68it/s]  8%|▊         | 8/102 [00:04<00:31,  2.95it/s]  9%|▉         | 9/102 [00:05<00:29,  3.17it/s] 10%|▉         | 10/102 [00:05<00:27,  3.36it/s] 11%|█         | 11/102 [00:05<00:26,  3.48it/s] 12%|█▏        | 12/102 [00:05<00:25,  3.58it/s] 13%|█▎        | 13/102 [00:06<00:24,  3.68it/s] 14%|█▎        | 14/102 [00:06<00:23,  3.72it/s] 15%|█▍        | 15/102 [00:06<00:22,  3.79it/s] 16%|█▌        | 16/102 [00:06<00:22,  3.81it/s] 17%|█▋        | 17/102 [00:07<00:22,  3.81it/s] 18%|█▊        | 18/102 [00:07<00:22,  3.80it/s] 19%|█▊        | 19/102 [00:07<00:21,  3.80it/s] 20%|█▉        | 20/102 [00:08<00:21,  3.78it/s] 21%|██        | 21/102 [00:08<00:21,  3.79it/s] 22%|██▏       | 22/102 [00:08<00:18,  4.23it/s] 23%|██▎       | 23/102 [00:08<00:19,  4.13it/s] 24%|██▎       | 24/102 [00:08<00:18,  4.26it/s] 25%|██▍       | 25/102 [00:09<00:18,  4.19it/s] 25%|██▌       | 26/102 [00:09<00:18,  4.16it/s] 26%|██▋       | 27/102 [00:09<00:17,  4.22it/s] 27%|██▋       | 28/102 [00:09<00:17,  4.14it/s] 28%|██▊       | 29/102 [00:10<00:17,  4.28it/s] 29%|██▉       | 30/102 [00:10<00:17,  4.10it/s] 30%|███       | 31/102 [00:10<00:17,  3.99it/s] 31%|███▏      | 32/102 [00:10<00:17,  3.99it/s] 32%|███▏      | 33/102 [00:11<00:16,  4.11it/s] 33%|███▎      | 34/102 [00:11<00:16,  4.02it/s] 34%|███▍      | 35/102 [00:11<00:16,  4.07it/s] 35%|███▌      | 36/102 [00:11<00:16,  4.10it/s] 36%|███▋      | 37/102 [00:12<00:16,  4.04it/s] 37%|███▋      | 38/102 [00:12<00:15,  4.01it/s] 38%|███▊      | 39/102 [00:12<00:15,  3.94it/s] 39%|███▉      | 40/102 [00:12<00:15,  3.94it/s] 40%|████      | 41/102 [00:13<00:15,  3.88it/s] 41%|████      | 42/102 [00:13<00:14,  4.12it/s] 42%|████▏     | 43/102 [00:13<00:14,  4.02it/s] 43%|████▎     | 44/102 [00:13<00:14,  3.96it/s] 44%|████▍     | 45/102 [00:14<00:14,  3.98it/s] 45%|████▌     | 46/102 [00:14<00:14,  3.97it/s] 46%|████▌     | 47/102 [00:14<00:14,  3.91it/s] 47%|████▋     | 48/102 [00:14<00:13,  3.92it/s] 48%|████▊     | 49/102 [00:15<00:13,  3.92it/s] 49%|████▉     | 50/102 [00:15<00:13,  3.91it/s] 50%|█████     | 51/102 [00:15<00:13,  3.86it/s] 51%|█████     | 52/102 [00:15<00:13,  3.81it/s] 52%|█████▏    | 53/102 [00:16<00:12,  3.87it/s] 53%|█████▎    | 54/102 [00:16<00:12,  3.88it/s] 54%|█████▍    | 55/102 [00:16<00:12,  3.88it/s] 55%|█████▍    | 56/102 [00:17<00:11,  3.85it/s] 56%|█████▌    | 57/102 [00:17<00:11,  3.88it/s] 57%|█████▋    | 58/102 [00:17<00:11,  3.94it/s] 58%|█████▊    | 59/102 [00:17<00:10,  3.93it/s] 59%|█████▉    | 60/102 [00:18<00:10,  3.94it/s] 60%|█████▉    | 61/102 [00:18<00:10,  3.93it/s] 61%|██████    | 62/102 [00:18<00:10,  3.95it/s] 62%|██████▏   | 63/102 [00:18<00:09,  3.93it/s] 63%|██████▎   | 64/102 [00:19<00:09,  3.90it/s] 64%|██████▎   | 65/102 [00:19<00:09,  3.90it/s] 65%|██████▍   | 66/102 [00:19<00:09,  3.88it/s] 66%|██████▌   | 67/102 [00:19<00:09,  3.86it/s] 67%|██████▋   | 68/102 [00:20<00:08,  4.09it/s] 68%|██████▊   | 69/102 [00:20<00:08,  4.03it/s] 69%|██████▊   | 70/102 [00:20<00:07,  4.01it/s] 70%|██████▉   | 71/102 [00:20<00:07,  4.29it/s] 71%|███████   | 72/102 [00:20<00:06,  4.63it/s] 72%|███████▏  | 73/102 [00:21<00:06,  4.36it/s] 73%|███████▎  | 74/102 [00:21<00:05,  4.85it/s] 74%|███████▎  | 75/102 [00:21<00:04,  5.41it/s] 75%|███████▍  | 76/102 [00:21<00:04,  5.89it/s] 75%|███████▌  | 77/102 [00:21<00:03,  6.29it/s] 76%|███████▋  | 78/102 [00:21<00:03,  6.59it/s] 77%|███████▋  | 79/102 [00:21<00:03,  6.83it/s] 78%|███████▊  | 80/102 [00:22<00:03,  7.01it/s] 79%|███████▉  | 81/102 [00:22<00:02,  7.13it/s] 80%|████████  | 82/102 [00:22<00:02,  7.21it/s] 81%|████████▏ | 83/102 [00:22<00:02,  7.29it/s] 82%|████████▏ | 84/102 [00:22<00:02,  7.33it/s] 83%|████████▎ | 85/102 [00:22<00:02,  7.38it/s] 84%|████████▍ | 86/102 [00:22<00:02,  7.42it/s] 85%|████████▌ | 87/102 [00:23<00:02,  7.42it/s] 86%|████████▋ | 88/102 [00:23<00:01,  7.43it/s] 87%|████████▋ | 89/102 [00:23<00:01,  7.43it/s] 88%|████████▊ | 90/102 [00:23<00:01,  7.41it/s] 89%|████████▉ | 91/102 [00:23<00:01,  7.45it/s] 90%|█████████ | 92/102 [00:23<00:01,  7.44it/s] 91%|█████████ | 93/102 [00:23<00:01,  7.45it/s] 92%|█████████▏| 94/102 [00:24<00:01,  7.44it/s] 93%|█████████▎| 95/102 [00:24<00:00,  7.44it/s] 94%|█████████▍| 96/102 [00:24<00:00,  7.45it/s] 95%|█████████▌| 97/102 [00:24<00:00,  7.45it/s] 96%|█████████▌| 98/102 [00:24<00:00,  7.43it/s] 97%|█████████▋| 99/102 [00:24<00:00,  7.44it/s] 98%|█████████▊| 100/102 [00:24<00:00,  7.44it/s] 99%|█████████▉| 101/102 [00:24<00:00,  7.27it/s]100%|██████████| 102/102 [00:25<00:00,  7.33it/s]100%|██████████| 102/102 [00:25<00:00,  4.04it/s]
=> result
* total: 10,200
* correct: 9,210
* accuracy: 90.3%
* error: 9.7%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 23)
Evaluate on the *test* set
  0%|          | 0/153 [00:00<?, ?it/s]  1%|          | 1/153 [00:02<06:37,  2.61s/it]  1%|▏         | 2/153 [00:03<03:30,  1.39s/it]  2%|▏         | 3/153 [00:03<02:15,  1.11it/s]  3%|▎         | 4/153 [00:03<01:36,  1.54it/s]  3%|▎         | 5/153 [00:03<01:15,  1.97it/s]  4%|▍         | 6/153 [00:04<01:02,  2.34it/s]  5%|▍         | 7/153 [00:04<00:54,  2.70it/s]  5%|▌         | 8/153 [00:04<00:48,  2.97it/s]  6%|▌         | 9/153 [00:05<00:44,  3.20it/s]  7%|▋         | 10/153 [00:05<00:41,  3.41it/s]  7%|▋         | 11/153 [00:05<00:40,  3.52it/s]  8%|▊         | 12/153 [00:05<00:38,  3.62it/s]  8%|▊         | 13/153 [00:06<00:37,  3.72it/s]  9%|▉         | 14/153 [00:06<00:37,  3.75it/s] 10%|▉         | 15/153 [00:06<00:36,  3.77it/s] 10%|█         | 16/153 [00:06<00:36,  3.76it/s] 11%|█         | 17/153 [00:07<00:35,  3.80it/s] 12%|█▏        | 18/153 [00:07<00:35,  3.83it/s] 12%|█▏        | 19/153 [00:07<00:35,  3.81it/s] 13%|█▎        | 20/153 [00:07<00:34,  3.81it/s] 14%|█▎        | 21/153 [00:08<00:34,  3.78it/s] 14%|█▍        | 22/153 [00:08<00:34,  3.80it/s] 15%|█▌        | 23/153 [00:08<00:34,  3.78it/s] 16%|█▌        | 24/153 [00:08<00:33,  3.85it/s] 16%|█▋        | 25/153 [00:09<00:33,  3.85it/s] 17%|█▋        | 26/153 [00:09<00:33,  3.83it/s] 18%|█▊        | 27/153 [00:09<00:33,  3.81it/s] 18%|█▊        | 28/153 [00:09<00:32,  3.85it/s] 19%|█▉        | 29/153 [00:10<00:31,  3.89it/s] 20%|█▉        | 30/153 [00:10<00:30,  3.98it/s] 20%|██        | 31/153 [00:10<00:30,  3.96it/s] 21%|██        | 32/153 [00:10<00:30,  3.92it/s] 22%|██▏       | 33/153 [00:11<00:30,  3.91it/s] 22%|██▏       | 34/153 [00:11<00:30,  3.92it/s] 23%|██▎       | 35/153 [00:11<00:30,  3.88it/s] 24%|██▎       | 36/153 [00:11<00:28,  4.04it/s] 24%|██▍       | 37/153 [00:12<00:29,  3.99it/s] 25%|██▍       | 38/153 [00:12<00:29,  3.95it/s] 25%|██▌       | 39/153 [00:12<00:29,  3.92it/s] 26%|██▌       | 40/153 [00:13<00:29,  3.87it/s] 27%|██▋       | 41/153 [00:13<00:28,  3.87it/s] 27%|██▋       | 42/153 [00:13<00:28,  3.88it/s] 28%|██▊       | 43/153 [00:13<00:28,  3.90it/s] 29%|██▉       | 44/153 [00:14<00:27,  3.90it/s] 29%|██▉       | 45/153 [00:14<00:25,  4.16it/s] 30%|███       | 46/153 [00:14<00:26,  4.07it/s] 31%|███       | 47/153 [00:14<00:26,  4.04it/s] 31%|███▏      | 48/153 [00:15<00:26,  3.97it/s] 32%|███▏      | 49/153 [00:15<00:26,  3.90it/s] 33%|███▎      | 50/153 [00:15<00:26,  3.91it/s] 33%|███▎      | 51/153 [00:15<00:26,  3.90it/s] 34%|███▍      | 52/153 [00:16<00:25,  3.89it/s] 35%|███▍      | 53/153 [00:16<00:25,  3.88it/s] 35%|███▌      | 54/153 [00:16<00:25,  3.87it/s] 36%|███▌      | 55/153 [00:16<00:25,  3.92it/s] 37%|███▋      | 56/153 [00:17<00:24,  3.91it/s] 37%|███▋      | 57/153 [00:17<00:23,  4.03it/s] 38%|███▊      | 58/153 [00:17<00:23,  3.98it/s] 39%|███▊      | 59/153 [00:17<00:23,  3.92it/s] 39%|███▉      | 60/153 [00:18<00:23,  3.93it/s] 40%|███▉      | 61/153 [00:18<00:23,  3.88it/s] 41%|████      | 62/153 [00:18<00:23,  3.82it/s] 41%|████      | 63/153 [00:18<00:23,  3.83it/s] 42%|████▏     | 64/153 [00:19<00:23,  3.84it/s] 42%|████▏     | 65/153 [00:19<00:22,  3.89it/s] 43%|████▎     | 66/153 [00:19<00:22,  3.86it/s] 44%|████▍     | 67/153 [00:19<00:22,  3.87it/s] 44%|████▍     | 68/153 [00:20<00:21,  3.87it/s] 45%|████▌     | 69/153 [00:20<00:21,  3.92it/s] 46%|████▌     | 70/153 [00:20<00:21,  3.87it/s] 46%|████▋     | 71/153 [00:20<00:21,  3.89it/s] 47%|████▋     | 72/153 [00:21<00:20,  3.86it/s] 48%|████▊     | 73/153 [00:21<00:20,  3.87it/s] 48%|████▊     | 74/153 [00:21<00:20,  3.89it/s] 49%|████▉     | 75/153 [00:21<00:20,  3.88it/s] 50%|████▉     | 76/153 [00:22<00:19,  3.91it/s] 50%|█████     | 77/153 [00:22<00:19,  3.90it/s] 51%|█████     | 78/153 [00:22<00:19,  3.91it/s] 52%|█████▏    | 79/153 [00:23<00:19,  3.87it/s] 52%|█████▏    | 80/153 [00:23<00:18,  3.87it/s] 53%|█████▎    | 81/153 [00:23<00:18,  3.86it/s] 54%|█████▎    | 82/153 [00:23<00:18,  3.86it/s] 54%|█████▍    | 83/153 [00:24<00:18,  3.84it/s] 55%|█████▍    | 84/153 [00:24<00:17,  4.05it/s] 56%|█████▌    | 85/153 [00:24<00:16,  4.20it/s] 56%|█████▌    | 86/153 [00:24<00:16,  4.08it/s] 57%|█████▋    | 87/153 [00:24<00:16,  4.08it/s] 58%|█████▊    | 88/153 [00:25<00:16,  4.04it/s] 58%|█████▊    | 89/153 [00:25<00:15,  4.00it/s] 59%|█████▉    | 90/153 [00:25<00:15,  3.96it/s] 59%|█████▉    | 91/153 [00:25<00:14,  4.21it/s] 60%|██████    | 92/153 [00:26<00:14,  4.09it/s] 61%|██████    | 93/153 [00:26<00:14,  4.07it/s] 61%|██████▏   | 94/153 [00:26<00:14,  3.99it/s] 62%|██████▏   | 95/153 [00:26<00:14,  4.02it/s] 63%|██████▎   | 96/153 [00:27<00:14,  3.97it/s] 63%|██████▎   | 97/153 [00:27<00:14,  3.96it/s] 64%|██████▍   | 98/153 [00:27<00:13,  4.00it/s] 65%|██████▍   | 99/153 [00:27<00:13,  3.99it/s] 65%|██████▌   | 100/153 [00:28<00:12,  4.10it/s] 66%|██████▌   | 101/153 [00:28<00:12,  4.02it/s] 67%|██████▋   | 102/153 [00:28<00:12,  3.99it/s] 67%|██████▋   | 103/153 [00:28<00:12,  3.94it/s] 68%|██████▊   | 104/153 [00:29<00:12,  3.95it/s] 69%|██████▊   | 105/153 [00:29<00:12,  3.88it/s] 69%|██████▉   | 106/153 [00:29<00:12,  3.82it/s] 70%|██████▉   | 107/153 [00:30<00:11,  3.86it/s] 71%|███████   | 108/153 [00:30<00:11,  3.86it/s] 71%|███████   | 109/153 [00:30<00:11,  3.84it/s] 72%|███████▏  | 110/153 [00:30<00:11,  3.85it/s] 73%|███████▎  | 111/153 [00:31<00:10,  3.87it/s] 73%|███████▎  | 112/153 [00:31<00:10,  3.86it/s] 74%|███████▍  | 113/153 [00:31<00:10,  3.84it/s] 75%|███████▍  | 114/153 [00:31<00:10,  3.84it/s] 75%|███████▌  | 115/153 [00:32<00:09,  3.84it/s] 76%|███████▌  | 116/153 [00:32<00:09,  3.88it/s] 76%|███████▋  | 117/153 [00:32<00:09,  3.87it/s] 77%|███████▋  | 118/153 [00:32<00:09,  3.86it/s] 78%|███████▊  | 119/153 [00:33<00:08,  3.87it/s] 78%|███████▊  | 120/153 [00:33<00:08,  3.89it/s] 79%|███████▉  | 121/153 [00:33<00:08,  3.89it/s] 80%|███████▉  | 122/153 [00:33<00:07,  3.92it/s] 80%|████████  | 123/153 [00:34<00:07,  3.92it/s] 81%|████████  | 124/153 [00:34<00:07,  4.06it/s] 82%|████████▏ | 125/153 [00:34<00:05,  4.67it/s] 82%|████████▏ | 126/153 [00:34<00:05,  5.25it/s] 83%|████████▎ | 127/153 [00:34<00:04,  5.76it/s] 84%|████████▎ | 128/153 [00:34<00:04,  6.18it/s] 84%|████████▍ | 129/153 [00:35<00:03,  6.52it/s] 85%|████████▍ | 130/153 [00:35<00:03,  6.76it/s] 86%|████████▌ | 131/153 [00:35<00:03,  6.95it/s] 86%|████████▋ | 132/153 [00:35<00:02,  7.07it/s] 87%|████████▋ | 133/153 [00:35<00:02,  7.18it/s] 88%|████████▊ | 134/153 [00:35<00:02,  7.24it/s] 88%|████████▊ | 135/153 [00:35<00:02,  7.29it/s] 89%|████████▉ | 136/153 [00:35<00:02,  7.33it/s] 90%|████████▉ | 137/153 [00:36<00:02,  7.35it/s] 90%|█████████ | 138/153 [00:36<00:02,  7.37it/s] 91%|█████████ | 139/153 [00:36<00:01,  7.39it/s] 92%|█████████▏| 140/153 [00:36<00:01,  7.39it/s] 92%|█████████▏| 141/153 [00:36<00:01,  7.40it/s] 93%|█████████▎| 142/153 [00:36<00:01,  7.40it/s] 93%|█████████▎| 143/153 [00:36<00:01,  7.40it/s] 94%|█████████▍| 144/153 [00:37<00:01,  7.41it/s] 95%|█████████▍| 145/153 [00:37<00:01,  7.41it/s] 95%|█████████▌| 146/153 [00:37<00:00,  7.40it/s] 96%|█████████▌| 147/153 [00:37<00:00,  7.41it/s] 97%|█████████▋| 148/153 [00:37<00:00,  7.41it/s] 97%|█████████▋| 149/153 [00:37<00:00,  7.42it/s] 98%|█████████▊| 150/153 [00:37<00:00,  7.41it/s] 99%|█████████▊| 151/153 [00:38<00:00,  7.40it/s] 99%|█████████▉| 152/153 [00:38<00:00,  7.41it/s]100%|██████████| 153/153 [00:38<00:00,  7.41it/s]100%|██████████| 153/153 [00:38<00:00,  3.98it/s]
=> result
* total: 15,300
* correct: 13,852
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 90.5%
Elapsed: 0:39:56
+ sh scripts/rpo_prime/base2new_test_sdl.sh food101 3 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
800 10000 15000
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  50
# train_x  800
# val      10,000
# test     15,000
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/food101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 23)
Evaluate on the *test* set
  0%|          | 0/150 [00:00<?, ?it/s]  1%|          | 1/150 [00:05<14:08,  5.70s/it]  1%|▏         | 2/150 [00:05<06:00,  2.44s/it]  2%|▏         | 3/150 [00:06<03:25,  1.40s/it]  3%|▎         | 4/150 [00:06<02:18,  1.06it/s]  3%|▎         | 5/150 [00:06<01:41,  1.43it/s]  4%|▍         | 6/150 [00:06<01:19,  1.81it/s]  5%|▍         | 7/150 [00:07<01:05,  2.19it/s]  5%|▌         | 8/150 [00:07<00:56,  2.53it/s]  6%|▌         | 9/150 [00:07<00:49,  2.83it/s]  7%|▋         | 10/150 [00:07<00:45,  3.10it/s]  7%|▋         | 11/150 [00:08<00:42,  3.30it/s]  8%|▊         | 12/150 [00:08<00:39,  3.47it/s]  9%|▊         | 13/150 [00:08<00:38,  3.54it/s]  9%|▉         | 14/150 [00:08<00:37,  3.62it/s] 10%|█         | 15/150 [00:09<00:36,  3.70it/s] 11%|█         | 16/150 [00:09<00:35,  3.77it/s] 11%|█▏        | 17/150 [00:09<00:34,  3.85it/s] 12%|█▏        | 18/150 [00:09<00:34,  3.83it/s] 13%|█▎        | 19/150 [00:10<00:34,  3.79it/s] 13%|█▎        | 20/150 [00:10<00:33,  3.84it/s] 14%|█▍        | 21/150 [00:10<00:34,  3.78it/s] 15%|█▍        | 22/150 [00:10<00:33,  3.79it/s] 15%|█▌        | 23/150 [00:11<00:33,  3.81it/s] 16%|█▌        | 24/150 [00:11<00:32,  3.82it/s] 17%|█▋        | 25/150 [00:11<00:31,  3.94it/s] 17%|█▋        | 26/150 [00:11<00:32,  3.87it/s] 18%|█▊        | 27/150 [00:12<00:31,  3.89it/s] 19%|█▊        | 28/150 [00:12<00:31,  3.89it/s] 19%|█▉        | 29/150 [00:12<00:31,  3.90it/s] 20%|██        | 30/150 [00:12<00:30,  3.94it/s] 21%|██        | 31/150 [00:13<00:30,  3.87it/s] 21%|██▏       | 32/150 [00:13<00:29,  4.04it/s] 22%|██▏       | 33/150 [00:13<00:29,  3.91it/s] 23%|██▎       | 34/150 [00:14<00:29,  3.87it/s] 23%|██▎       | 35/150 [00:14<00:29,  3.84it/s] 24%|██▍       | 36/150 [00:14<00:27,  4.21it/s] 25%|██▍       | 37/150 [00:14<00:26,  4.22it/s] 25%|██▌       | 38/150 [00:14<00:27,  4.13it/s] 26%|██▌       | 39/150 [00:15<00:27,  4.09it/s] 27%|██▋       | 40/150 [00:15<00:27,  4.04it/s] 27%|██▋       | 41/150 [00:15<00:27,  3.98it/s] 28%|██▊       | 42/150 [00:15<00:27,  3.92it/s] 29%|██▊       | 43/150 [00:16<00:27,  3.89it/s] 29%|██▉       | 44/150 [00:16<00:27,  3.89it/s] 30%|███       | 45/150 [00:16<00:24,  4.33it/s] 31%|███       | 46/150 [00:16<00:24,  4.18it/s] 31%|███▏      | 47/150 [00:17<00:25,  4.05it/s] 32%|███▏      | 48/150 [00:17<00:25,  3.96it/s] 33%|███▎      | 49/150 [00:17<00:25,  3.93it/s] 33%|███▎      | 50/150 [00:18<00:25,  3.86it/s] 34%|███▍      | 51/150 [00:18<00:25,  3.86it/s] 35%|███▍      | 52/150 [00:18<00:25,  3.83it/s] 35%|███▌      | 53/150 [00:18<00:24,  3.91it/s] 36%|███▌      | 54/150 [00:19<00:24,  3.92it/s] 37%|███▋      | 55/150 [00:19<00:24,  3.95it/s] 37%|███▋      | 56/150 [00:19<00:23,  4.03it/s] 38%|███▊      | 57/150 [00:19<00:22,  4.13it/s] 39%|███▊      | 58/150 [00:20<00:22,  4.00it/s] 39%|███▉      | 59/150 [00:20<00:22,  3.96it/s] 40%|████      | 60/150 [00:20<00:22,  3.95it/s] 41%|████      | 61/150 [00:20<00:22,  3.95it/s] 41%|████▏     | 62/150 [00:21<00:22,  3.95it/s] 42%|████▏     | 63/150 [00:21<00:20,  4.20it/s] 43%|████▎     | 64/150 [00:21<00:20,  4.10it/s] 43%|████▎     | 65/150 [00:21<00:21,  4.01it/s] 44%|████▍     | 66/150 [00:21<00:20,  4.02it/s] 45%|████▍     | 67/150 [00:22<00:19,  4.34it/s] 45%|████▌     | 68/150 [00:22<00:19,  4.30it/s] 46%|████▌     | 69/150 [00:22<00:19,  4.14it/s] 47%|████▋     | 70/150 [00:22<00:19,  4.05it/s] 47%|████▋     | 71/150 [00:23<00:19,  3.99it/s] 48%|████▊     | 72/150 [00:23<00:19,  3.94it/s] 49%|████▊     | 73/150 [00:23<00:19,  3.92it/s] 49%|████▉     | 74/150 [00:23<00:19,  3.88it/s] 50%|█████     | 75/150 [00:24<00:19,  3.85it/s] 51%|█████     | 76/150 [00:24<00:19,  3.88it/s] 51%|█████▏    | 77/150 [00:24<00:19,  3.82it/s] 52%|█████▏    | 78/150 [00:25<00:18,  3.82it/s] 53%|█████▎    | 79/150 [00:25<00:17,  4.16it/s] 53%|█████▎    | 80/150 [00:25<00:17,  4.03it/s] 54%|█████▍    | 81/150 [00:25<00:17,  3.94it/s] 55%|█████▍    | 82/150 [00:26<00:17,  3.91it/s] 55%|█████▌    | 83/150 [00:26<00:16,  3.95it/s] 56%|█████▌    | 84/150 [00:26<00:16,  3.95it/s] 57%|█████▋    | 85/150 [00:26<00:16,  3.91it/s] 57%|█████▋    | 86/150 [00:27<00:15,  4.02it/s] 58%|█████▊    | 87/150 [00:27<00:14,  4.23it/s] 59%|█████▊    | 88/150 [00:27<00:14,  4.15it/s] 59%|█████▉    | 89/150 [00:27<00:15,  4.01it/s] 60%|██████    | 90/150 [00:27<00:15,  3.99it/s] 61%|██████    | 91/150 [00:28<00:14,  3.95it/s] 61%|██████▏   | 92/150 [00:28<00:14,  4.12it/s] 62%|██████▏   | 93/150 [00:28<00:14,  4.04it/s] 63%|██████▎   | 94/150 [00:28<00:12,  4.46it/s] 63%|██████▎   | 95/150 [00:29<00:12,  4.26it/s] 64%|██████▍   | 96/150 [00:29<00:13,  4.08it/s] 65%|██████▍   | 97/150 [00:29<00:13,  3.99it/s] 65%|██████▌   | 98/150 [00:29<00:13,  3.93it/s] 66%|██████▌   | 99/150 [00:30<00:12,  3.97it/s] 67%|██████▋   | 100/150 [00:30<00:12,  3.99it/s] 67%|██████▋   | 101/150 [00:30<00:12,  3.97it/s] 68%|██████▊   | 102/150 [00:30<00:12,  3.97it/s] 69%|██████▊   | 103/150 [00:31<00:12,  3.90it/s] 69%|██████▉   | 104/150 [00:31<00:11,  3.88it/s] 70%|███████   | 105/150 [00:31<00:11,  3.86it/s] 71%|███████   | 106/150 [00:32<00:11,  3.84it/s] 71%|███████▏  | 107/150 [00:32<00:11,  3.84it/s] 72%|███████▏  | 108/150 [00:32<00:10,  4.00it/s] 73%|███████▎  | 109/150 [00:32<00:10,  4.05it/s] 73%|███████▎  | 110/150 [00:33<00:10,  3.96it/s] 74%|███████▍  | 111/150 [00:33<00:09,  3.91it/s] 75%|███████▍  | 112/150 [00:33<00:09,  3.87it/s] 75%|███████▌  | 113/150 [00:33<00:09,  3.84it/s] 76%|███████▌  | 114/150 [00:34<00:09,  3.79it/s] 77%|███████▋  | 115/150 [00:34<00:08,  3.92it/s] 77%|███████▋  | 116/150 [00:34<00:08,  3.91it/s] 78%|███████▊  | 117/150 [00:34<00:08,  3.86it/s] 79%|███████▊  | 118/150 [00:35<00:08,  3.82it/s] 79%|███████▉  | 119/150 [00:35<00:08,  3.84it/s] 80%|████████  | 120/150 [00:35<00:07,  4.08it/s] 81%|████████  | 121/150 [00:35<00:06,  4.48it/s] 81%|████████▏ | 122/150 [00:35<00:05,  4.98it/s] 82%|████████▏ | 123/150 [00:36<00:04,  5.51it/s] 83%|████████▎ | 124/150 [00:36<00:04,  5.95it/s] 83%|████████▎ | 125/150 [00:36<00:03,  6.31it/s] 84%|████████▍ | 126/150 [00:36<00:03,  6.57it/s] 85%|████████▍ | 127/150 [00:36<00:03,  6.78it/s] 85%|████████▌ | 128/150 [00:36<00:03,  6.93it/s] 86%|████████▌ | 129/150 [00:36<00:02,  7.05it/s] 87%|████████▋ | 130/150 [00:36<00:02,  7.13it/s] 87%|████████▋ | 131/150 [00:37<00:02,  7.18it/s] 88%|████████▊ | 132/150 [00:37<00:02,  7.22it/s] 89%|████████▊ | 133/150 [00:37<00:02,  7.25it/s] 89%|████████▉ | 134/150 [00:37<00:02,  7.29it/s] 90%|█████████ | 135/150 [00:37<00:02,  7.33it/s] 91%|█████████ | 136/150 [00:37<00:01,  7.33it/s] 91%|█████████▏| 137/150 [00:37<00:01,  7.32it/s] 92%|█████████▏| 138/150 [00:38<00:01,  7.32it/s] 93%|█████████▎| 139/150 [00:38<00:01,  7.32it/s] 93%|█████████▎| 140/150 [00:38<00:01,  7.33it/s] 94%|█████████▍| 141/150 [00:38<00:01,  7.28it/s] 95%|█████████▍| 142/150 [00:38<00:01,  7.28it/s] 95%|█████████▌| 143/150 [00:38<00:00,  7.29it/s] 96%|█████████▌| 144/150 [00:38<00:00,  7.29it/s] 97%|█████████▋| 145/150 [00:39<00:00,  7.32it/s] 97%|█████████▋| 146/150 [00:39<00:00,  7.33it/s] 98%|█████████▊| 147/150 [00:39<00:00,  7.33it/s] 99%|█████████▊| 148/150 [00:39<00:00,  7.33it/s] 99%|█████████▉| 149/150 [00:39<00:00,  7.33it/s]100%|██████████| 150/150 [00:39<00:00,  7.32it/s]100%|██████████| 150/150 [00:39<00:00,  3.77it/s]
=> result
* total: 15,000
* correct: 13,742
* accuracy: 91.6%
* error: 8.4%
* macro_f1: 91.6%
+ for dataset in eurosat dtd oxford_flowers stanford_cars oxford_pets food101 ucf101 caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh ucf101 1 0 main_tmp1_0.1sdl 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
816 975 1934
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  51
# train_x  816
# val      975
# test     1,934
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/204] time 0.249 (0.366) data 0.000 (0.050) loss 1.9844 (2.8082) lr 1.0000e-02 eta 0:37:15
epoch [1/30] batch [40/204] time 0.251 (0.308) data 0.000 (0.025) loss 6.6055 (2.7220) lr 1.0000e-02 eta 0:31:13
epoch [1/30] batch [60/204] time 0.249 (0.290) data 0.000 (0.017) loss 2.5215 (2.6913) lr 1.0000e-02 eta 0:29:17
epoch [1/30] batch [80/204] time 0.256 (0.280) data 0.000 (0.013) loss 4.0195 (2.6984) lr 1.0000e-02 eta 0:28:09
epoch [1/30] batch [100/204] time 0.249 (0.274) data 0.000 (0.010) loss 3.8223 (2.6817) lr 1.0000e-02 eta 0:27:26
epoch [1/30] batch [120/204] time 0.249 (0.270) data 0.000 (0.009) loss 1.4512 (2.6685) lr 1.0000e-02 eta 0:27:01
epoch [1/30] batch [140/204] time 0.247 (0.267) data 0.000 (0.007) loss 0.3093 (2.6211) lr 1.0000e-02 eta 0:26:37
epoch [1/30] batch [160/204] time 0.258 (0.265) data 0.000 (0.006) loss 2.4668 (2.5962) lr 1.0000e-02 eta 0:26:20
epoch [1/30] batch [180/204] time 0.242 (0.263) data 0.000 (0.006) loss 2.3320 (2.5621) lr 1.0000e-02 eta 0:26:03
epoch [1/30] batch [200/204] time 0.242 (0.261) data 0.000 (0.005) loss 4.2227 (2.5489) lr 1.0000e-02 eta 0:25:46
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:14,  1.58s/it] 20%|██        | 2/10 [00:01<00:05,  1.36it/s] 30%|███       | 3/10 [00:01<00:03,  2.17it/s] 40%|████      | 4/10 [00:01<00:01,  3.01it/s] 50%|█████     | 5/10 [00:02<00:01,  3.83it/s] 60%|██████    | 6/10 [00:02<00:00,  4.58it/s] 70%|███████   | 7/10 [00:02<00:00,  5.23it/s] 80%|████████  | 8/10 [00:02<00:00,  5.75it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.17it/s]100%|██████████| 10/10 [00:02<00:00,  6.87it/s]100%|██████████| 10/10 [00:02<00:00,  3.45it/s]=> result
* total: 975
* correct: 736
* accuracy: 75.5%
* error: 24.5%
* macro_f1: 72.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/204] time 0.246 (0.288) data 0.000 (0.035) loss 2.6543 (2.2788) lr 9.9726e-03 eta 0:28:17
epoch [2/30] batch [40/204] time 0.255 (0.271) data 0.000 (0.018) loss 0.8955 (2.3979) lr 9.9726e-03 eta 0:26:34
epoch [2/30] batch [60/204] time 0.246 (0.264) data 0.000 (0.012) loss 2.1406 (2.3663) lr 9.9726e-03 eta 0:25:46
epoch [2/30] batch [80/204] time 0.246 (0.260) data 0.000 (0.009) loss 1.1455 (2.3166) lr 9.9726e-03 eta 0:25:18
epoch [2/30] batch [100/204] time 0.245 (0.258) data 0.000 (0.007) loss 3.4336 (2.3135) lr 9.9726e-03 eta 0:25:02
epoch [2/30] batch [120/204] time 0.253 (0.257) data 0.000 (0.006) loss 1.7324 (2.3465) lr 9.9726e-03 eta 0:24:47
epoch [2/30] batch [140/204] time 0.249 (0.255) data 0.000 (0.005) loss 1.6055 (2.3333) lr 9.9726e-03 eta 0:24:34
epoch [2/30] batch [160/204] time 0.245 (0.254) data 0.000 (0.005) loss 1.4629 (2.3613) lr 9.9726e-03 eta 0:24:23
epoch [2/30] batch [180/204] time 0.242 (0.253) data 0.000 (0.004) loss 1.7402 (2.3347) lr 9.9726e-03 eta 0:24:12
epoch [2/30] batch [200/204] time 0.242 (0.252) data 0.000 (0.004) loss 5.7539 (2.2985) lr 9.9726e-03 eta 0:24:01
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.30s/it] 20%|██        | 2/10 [00:01<00:05,  1.59it/s] 30%|███       | 3/10 [00:01<00:02,  2.48it/s] 40%|████      | 4/10 [00:01<00:01,  3.36it/s] 50%|█████     | 5/10 [00:01<00:01,  4.18it/s] 60%|██████    | 6/10 [00:02<00:00,  4.90it/s] 70%|███████   | 7/10 [00:02<00:00,  5.51it/s] 80%|████████  | 8/10 [00:02<00:00,  5.99it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.37it/s]100%|██████████| 10/10 [00:02<00:00,  7.05it/s]100%|██████████| 10/10 [00:02<00:00,  3.82it/s]=> result
* total: 975
* correct: 761
* accuracy: 78.1%
* error: 21.9%
* macro_f1: 75.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/204] time 0.248 (0.285) data 0.000 (0.034) loss 3.2871 (2.1669) lr 9.8907e-03 eta 0:27:00
epoch [3/30] batch [40/204] time 0.249 (0.269) data 0.000 (0.017) loss 2.9434 (1.9182) lr 9.8907e-03 eta 0:25:25
epoch [3/30] batch [60/204] time 0.246 (0.262) data 0.000 (0.011) loss 3.1348 (2.1612) lr 9.8907e-03 eta 0:24:40
epoch [3/30] batch [80/204] time 0.247 (0.258) data 0.000 (0.009) loss 0.7925 (2.1482) lr 9.8907e-03 eta 0:24:15
epoch [3/30] batch [100/204] time 0.249 (0.257) data 0.000 (0.007) loss 2.5234 (2.1325) lr 9.8907e-03 eta 0:24:00
epoch [3/30] batch [120/204] time 0.246 (0.255) data 0.000 (0.006) loss 1.8525 (2.1190) lr 9.8907e-03 eta 0:23:48
epoch [3/30] batch [140/204] time 0.246 (0.255) data 0.000 (0.005) loss 1.7627 (2.0677) lr 9.8907e-03 eta 0:23:38
epoch [3/30] batch [160/204] time 0.247 (0.254) data 0.000 (0.004) loss 1.8828 (2.0548) lr 9.8907e-03 eta 0:23:29
epoch [3/30] batch [180/204] time 0.243 (0.253) data 0.000 (0.004) loss 1.9971 (2.0684) lr 9.8907e-03 eta 0:23:20
epoch [3/30] batch [200/204] time 0.245 (0.252) data 0.000 (0.004) loss 0.6699 (2.0690) lr 9.8907e-03 eta 0:23:09
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.40s/it] 20%|██        | 2/10 [00:01<00:05,  1.52it/s] 30%|███       | 3/10 [00:01<00:02,  2.38it/s] 40%|████      | 4/10 [00:01<00:01,  3.25it/s] 50%|█████     | 5/10 [00:01<00:01,  4.07it/s] 60%|██████    | 6/10 [00:02<00:00,  4.81it/s] 70%|███████   | 7/10 [00:02<00:00,  5.43it/s] 80%|████████  | 8/10 [00:02<00:00,  5.93it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.31it/s]100%|██████████| 10/10 [00:02<00:00,  6.98it/s]100%|██████████| 10/10 [00:02<00:00,  3.70it/s]=> result
* total: 975
* correct: 770
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 76.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/204] time 0.247 (0.287) data 0.000 (0.034) loss 1.0664 (2.0512) lr 9.7553e-03 eta 0:26:17
epoch [4/30] batch [40/204] time 0.243 (0.267) data 0.000 (0.017) loss 2.7402 (2.0465) lr 9.7553e-03 eta 0:24:18
epoch [4/30] batch [60/204] time 0.248 (0.260) data 0.000 (0.011) loss 1.3008 (2.0353) lr 9.7553e-03 eta 0:23:36
epoch [4/30] batch [80/204] time 0.250 (0.257) data 0.000 (0.009) loss 1.7256 (2.1362) lr 9.7553e-03 eta 0:23:15
epoch [4/30] batch [100/204] time 0.249 (0.255) data 0.000 (0.007) loss 3.4727 (2.0931) lr 9.7553e-03 eta 0:23:00
epoch [4/30] batch [120/204] time 0.249 (0.254) data 0.000 (0.006) loss 2.6699 (2.0706) lr 9.7553e-03 eta 0:22:47
epoch [4/30] batch [140/204] time 0.250 (0.254) data 0.000 (0.005) loss 2.2656 (1.9976) lr 9.7553e-03 eta 0:22:40
epoch [4/30] batch [160/204] time 0.248 (0.253) data 0.000 (0.004) loss 2.0898 (2.0174) lr 9.7553e-03 eta 0:22:30
epoch [4/30] batch [180/204] time 0.242 (0.252) data 0.000 (0.004) loss 0.0330 (2.0136) lr 9.7553e-03 eta 0:22:21
epoch [4/30] batch [200/204] time 0.246 (0.251) data 0.000 (0.004) loss 1.0908 (2.0214) lr 9.7553e-03 eta 0:22:11
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.31s/it] 20%|██        | 2/10 [00:01<00:05,  1.59it/s] 30%|███       | 3/10 [00:01<00:02,  2.48it/s] 40%|████      | 4/10 [00:01<00:01,  3.37it/s] 50%|█████     | 5/10 [00:01<00:01,  4.20it/s] 60%|██████    | 6/10 [00:02<00:00,  4.92it/s] 70%|███████   | 7/10 [00:02<00:00,  5.53it/s] 80%|████████  | 8/10 [00:02<00:00,  6.01it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.39it/s]100%|██████████| 10/10 [00:02<00:00,  7.07it/s]100%|██████████| 10/10 [00:02<00:00,  3.81it/s]=> result
* total: 975
* correct: 766
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 76.3%

epoch [5/30] batch [20/204] time 0.246 (0.292) data 0.000 (0.038) loss 2.3066 (1.9952) lr 9.5677e-03 eta 0:25:41
epoch [5/30] batch [40/204] time 0.257 (0.270) data 0.000 (0.019) loss 0.8281 (2.0051) lr 9.5677e-03 eta 0:23:41
epoch [5/30] batch [60/204] time 0.246 (0.263) data 0.000 (0.013) loss 1.3369 (1.8434) lr 9.5677e-03 eta 0:23:00
epoch [5/30] batch [80/204] time 0.246 (0.259) data 0.000 (0.010) loss 2.3965 (1.9729) lr 9.5677e-03 eta 0:22:34
epoch [5/30] batch [100/204] time 0.255 (0.258) data 0.000 (0.008) loss 1.7998 (1.9789) lr 9.5677e-03 eta 0:22:22
epoch [5/30] batch [120/204] time 0.247 (0.257) data 0.000 (0.007) loss 2.1250 (2.0480) lr 9.5677e-03 eta 0:22:10
epoch [5/30] batch [140/204] time 0.247 (0.256) data 0.000 (0.006) loss 0.4241 (1.9937) lr 9.5677e-03 eta 0:22:00
epoch [5/30] batch [160/204] time 0.252 (0.255) data 0.000 (0.005) loss 2.0469 (2.0405) lr 9.5677e-03 eta 0:21:53
epoch [5/30] batch [180/204] time 0.246 (0.255) data 0.000 (0.004) loss 2.0898 (2.0243) lr 9.5677e-03 eta 0:21:44
epoch [5/30] batch [200/204] time 0.242 (0.253) data 0.000 (0.004) loss 2.2910 (1.9763) lr 9.5677e-03 eta 0:21:33
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.28s/it] 20%|██        | 2/10 [00:01<00:05,  1.56it/s] 30%|███       | 3/10 [00:01<00:02,  2.43it/s] 40%|████      | 4/10 [00:01<00:01,  3.31it/s] 50%|█████     | 5/10 [00:01<00:01,  4.13it/s] 60%|██████    | 6/10 [00:02<00:00,  4.85it/s] 70%|███████   | 7/10 [00:02<00:00,  5.46it/s] 80%|████████  | 8/10 [00:02<00:00,  5.96it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.33it/s]100%|██████████| 10/10 [00:02<00:00,  6.94it/s]100%|██████████| 10/10 [00:02<00:00,  3.77it/s]=> result
* total: 975
* correct: 777
* accuracy: 79.7%
* error: 20.3%
* macro_f1: 78.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/204] time 0.244 (0.283) data 0.000 (0.034) loss 4.5273 (1.6851) lr 9.3301e-03 eta 0:23:58
epoch [6/30] batch [40/204] time 0.246 (0.264) data 0.000 (0.017) loss 1.5938 (1.6310) lr 9.3301e-03 eta 0:22:17
epoch [6/30] batch [60/204] time 0.244 (0.260) data 0.000 (0.012) loss 1.4355 (1.6767) lr 9.3301e-03 eta 0:21:49
epoch [6/30] batch [80/204] time 0.248 (0.256) data 0.000 (0.009) loss 0.8726 (1.8927) lr 9.3301e-03 eta 0:21:26
epoch [6/30] batch [100/204] time 0.248 (0.254) data 0.000 (0.007) loss 2.1484 (1.8534) lr 9.3301e-03 eta 0:21:11
epoch [6/30] batch [120/204] time 0.245 (0.253) data 0.000 (0.006) loss 1.8613 (1.8085) lr 9.3301e-03 eta 0:21:00
epoch [6/30] batch [140/204] time 0.251 (0.252) data 0.000 (0.005) loss 1.0225 (1.8514) lr 9.3301e-03 eta 0:20:51
epoch [6/30] batch [160/204] time 0.249 (0.252) data 0.000 (0.005) loss 1.7998 (1.8768) lr 9.3301e-03 eta 0:20:44
epoch [6/30] batch [180/204] time 0.243 (0.252) data 0.000 (0.004) loss 2.4629 (1.8351) lr 9.3301e-03 eta 0:20:41
epoch [6/30] batch [200/204] time 0.256 (0.252) data 0.000 (0.004) loss 0.0981 (1.7790) lr 9.3301e-03 eta 0:20:34
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.40s/it] 20%|██        | 2/10 [00:01<00:05,  1.51it/s] 30%|███       | 3/10 [00:01<00:02,  2.38it/s] 40%|████      | 4/10 [00:01<00:02,  2.91it/s] 50%|█████     | 5/10 [00:02<00:01,  3.72it/s] 60%|██████    | 6/10 [00:02<00:00,  4.47it/s] 70%|███████   | 7/10 [00:02<00:00,  5.10it/s] 80%|████████  | 8/10 [00:02<00:00,  5.66it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.09it/s]100%|██████████| 10/10 [00:02<00:00,  6.80it/s]100%|██████████| 10/10 [00:02<00:00,  3.55it/s]=> result
* total: 975
* correct: 792
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 79.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/204] time 0.247 (0.294) data 0.000 (0.035) loss 1.1035 (1.1568) lr 9.0451e-03 eta 0:23:55
epoch [7/30] batch [40/204] time 0.245 (0.271) data 0.000 (0.017) loss 3.5430 (1.5529) lr 9.0451e-03 eta 0:21:54
epoch [7/30] batch [60/204] time 0.247 (0.264) data 0.000 (0.012) loss 1.0156 (1.5550) lr 9.0451e-03 eta 0:21:18
epoch [7/30] batch [80/204] time 0.256 (0.261) data 0.000 (0.009) loss 2.3457 (1.6625) lr 9.0451e-03 eta 0:20:55
epoch [7/30] batch [100/204] time 0.246 (0.258) data 0.000 (0.007) loss 0.7207 (1.6634) lr 9.0451e-03 eta 0:20:39
epoch [7/30] batch [120/204] time 0.247 (0.257) data 0.000 (0.006) loss 0.7432 (1.6482) lr 9.0451e-03 eta 0:20:26
epoch [7/30] batch [140/204] time 0.248 (0.256) data 0.000 (0.005) loss 2.0156 (1.6311) lr 9.0451e-03 eta 0:20:17
epoch [7/30] batch [160/204] time 0.247 (0.255) data 0.000 (0.005) loss 1.3760 (1.6466) lr 9.0451e-03 eta 0:20:08
epoch [7/30] batch [180/204] time 0.243 (0.254) data 0.000 (0.004) loss 0.4033 (1.6607) lr 9.0451e-03 eta 0:19:58
epoch [7/30] batch [200/204] time 0.239 (0.253) data 0.000 (0.004) loss 3.5059 (1.6921) lr 9.0451e-03 eta 0:19:48
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.30s/it] 20%|██        | 2/10 [00:01<00:05,  1.58it/s] 30%|███       | 3/10 [00:01<00:02,  2.46it/s] 40%|████      | 4/10 [00:01<00:01,  3.34it/s] 50%|█████     | 5/10 [00:01<00:01,  4.16it/s] 60%|██████    | 6/10 [00:02<00:00,  4.88it/s] 70%|███████   | 7/10 [00:02<00:00,  5.48it/s] 80%|████████  | 8/10 [00:02<00:00,  5.96it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.34it/s]100%|██████████| 10/10 [00:02<00:00,  7.01it/s]100%|██████████| 10/10 [00:02<00:00,  3.78it/s]=> result
* total: 975
* correct: 796
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 79.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/204] time 0.247 (0.284) data 0.000 (0.034) loss 2.7344 (1.8012) lr 8.7157e-03 eta 0:22:07
epoch [8/30] batch [40/204] time 0.244 (0.265) data 0.000 (0.017) loss 2.2305 (1.7701) lr 8.7157e-03 eta 0:20:34
epoch [8/30] batch [60/204] time 0.256 (0.261) data 0.000 (0.012) loss 1.7891 (1.8219) lr 8.7157e-03 eta 0:20:08
epoch [8/30] batch [80/204] time 0.248 (0.257) data 0.000 (0.009) loss 1.8584 (1.8128) lr 8.7157e-03 eta 0:19:47
epoch [8/30] batch [100/204] time 0.250 (0.256) data 0.000 (0.007) loss 2.2734 (1.7750) lr 8.7157e-03 eta 0:19:35
epoch [8/30] batch [120/204] time 0.245 (0.255) data 0.000 (0.006) loss 5.5938 (1.7139) lr 8.7157e-03 eta 0:19:24
epoch [8/30] batch [140/204] time 0.246 (0.253) data 0.000 (0.005) loss 0.6870 (1.7067) lr 8.7157e-03 eta 0:19:13
epoch [8/30] batch [160/204] time 0.244 (0.252) data 0.000 (0.005) loss 1.2031 (1.6582) lr 8.7157e-03 eta 0:19:04
epoch [8/30] batch [180/204] time 0.242 (0.252) data 0.000 (0.004) loss 2.3340 (1.6628) lr 8.7157e-03 eta 0:18:55
epoch [8/30] batch [200/204] time 0.242 (0.251) data 0.000 (0.004) loss 1.7373 (1.6196) lr 8.7157e-03 eta 0:18:48
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.34s/it] 20%|██        | 2/10 [00:01<00:05,  1.57it/s] 30%|███       | 3/10 [00:01<00:02,  2.45it/s] 40%|████      | 4/10 [00:01<00:01,  3.34it/s] 50%|█████     | 5/10 [00:01<00:01,  4.17it/s] 60%|██████    | 6/10 [00:02<00:00,  4.92it/s] 70%|███████   | 7/10 [00:02<00:00,  5.54it/s] 80%|████████  | 8/10 [00:02<00:00,  6.03it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.38it/s]100%|██████████| 10/10 [00:02<00:00,  7.09it/s]100%|██████████| 10/10 [00:02<00:00,  3.80it/s]=> result
* total: 975
* correct: 809
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 81.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/204] time 0.244 (0.283) data 0.000 (0.033) loss 0.5488 (1.5422) lr 8.3457e-03 eta 0:21:05
epoch [9/30] batch [40/204] time 0.245 (0.265) data 0.000 (0.017) loss 5.5039 (1.7494) lr 8.3457e-03 eta 0:19:36
epoch [9/30] batch [60/204] time 0.246 (0.260) data 0.001 (0.011) loss 1.9922 (1.7052) lr 8.3457e-03 eta 0:19:10
epoch [9/30] batch [80/204] time 0.244 (0.257) data 0.000 (0.008) loss 0.6533 (1.6467) lr 8.3457e-03 eta 0:18:51
epoch [9/30] batch [100/204] time 0.251 (0.254) data 0.000 (0.007) loss 3.5137 (1.6470) lr 8.3457e-03 eta 0:18:36
epoch [9/30] batch [120/204] time 0.245 (0.253) data 0.000 (0.006) loss 0.2812 (1.6096) lr 8.3457e-03 eta 0:18:24
epoch [9/30] batch [140/204] time 0.244 (0.252) data 0.000 (0.005) loss 1.8066 (1.6631) lr 8.3457e-03 eta 0:18:14
epoch [9/30] batch [160/204] time 0.315 (0.251) data 0.000 (0.004) loss 0.6631 (1.6137) lr 8.3457e-03 eta 0:18:08
epoch [9/30] batch [180/204] time 0.241 (0.251) data 0.000 (0.004) loss 1.9092 (1.6580) lr 8.3457e-03 eta 0:17:59
epoch [9/30] batch [200/204] time 0.242 (0.250) data 0.000 (0.004) loss 3.6367 (1.6267) lr 8.3457e-03 eta 0:17:50
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.38s/it] 20%|██        | 2/10 [00:01<00:05,  1.55it/s] 30%|███       | 3/10 [00:01<00:02,  2.42it/s] 40%|████      | 4/10 [00:01<00:01,  3.29it/s] 50%|█████     | 5/10 [00:01<00:01,  4.11it/s] 60%|██████    | 6/10 [00:02<00:00,  4.85it/s] 70%|███████   | 7/10 [00:02<00:00,  5.48it/s] 80%|████████  | 8/10 [00:02<00:00,  5.97it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.36it/s]100%|██████████| 10/10 [00:02<00:00,  7.03it/s]100%|██████████| 10/10 [00:02<00:00,  3.72it/s]=> result
* total: 975
* correct: 809
* accuracy: 83.0%
* error: 17.0%
* macro_f1: 82.0%

epoch [10/30] batch [20/204] time 0.251 (0.285) data 0.000 (0.033) loss 3.0586 (1.6231) lr 7.9389e-03 eta 0:20:16
epoch [10/30] batch [40/204] time 0.249 (0.269) data 0.000 (0.017) loss 0.4155 (1.7269) lr 7.9389e-03 eta 0:19:02
epoch [10/30] batch [60/204] time 0.249 (0.263) data 0.000 (0.011) loss 0.1859 (1.7562) lr 7.9389e-03 eta 0:18:29
epoch [10/30] batch [80/204] time 0.247 (0.259) data 0.000 (0.008) loss 0.6328 (1.7084) lr 7.9389e-03 eta 0:18:09
epoch [10/30] batch [100/204] time 0.249 (0.257) data 0.000 (0.007) loss 3.6523 (1.6617) lr 7.9389e-03 eta 0:17:56
epoch [10/30] batch [120/204] time 0.249 (0.256) data 0.000 (0.006) loss 1.9072 (1.6633) lr 7.9389e-03 eta 0:17:45
epoch [10/30] batch [140/204] time 0.249 (0.255) data 0.000 (0.005) loss 2.0391 (1.6173) lr 7.9389e-03 eta 0:17:37
epoch [10/30] batch [160/204] time 0.247 (0.254) data 0.000 (0.004) loss 2.0312 (1.6137) lr 7.9389e-03 eta 0:17:29
epoch [10/30] batch [180/204] time 0.247 (0.254) data 0.000 (0.004) loss 1.7451 (1.6226) lr 7.9389e-03 eta 0:17:21
epoch [10/30] batch [200/204] time 0.244 (0.253) data 0.000 (0.004) loss 4.6328 (1.6387) lr 7.9389e-03 eta 0:17:12
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.34s/it] 20%|██        | 2/10 [00:01<00:05,  1.57it/s] 30%|███       | 3/10 [00:01<00:02,  2.45it/s] 40%|████      | 4/10 [00:01<00:01,  3.33it/s] 50%|█████     | 5/10 [00:01<00:01,  4.15it/s] 60%|██████    | 6/10 [00:02<00:00,  4.87it/s] 70%|███████   | 7/10 [00:02<00:00,  5.47it/s] 80%|████████  | 8/10 [00:02<00:00,  5.96it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.33it/s]100%|██████████| 10/10 [00:02<00:00,  7.01it/s]100%|██████████| 10/10 [00:02<00:00,  3.78it/s]=> result
* total: 975
* correct: 808
* accuracy: 82.9%
* error: 17.1%
* macro_f1: 81.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/204] time 0.247 (0.289) data 0.000 (0.034) loss 2.2520 (1.5880) lr 7.5000e-03 eta 0:19:33
epoch [11/30] batch [40/204] time 0.249 (0.268) data 0.000 (0.017) loss 2.4160 (1.9714) lr 7.5000e-03 eta 0:18:04
epoch [11/30] batch [60/204] time 0.246 (0.261) data 0.000 (0.012) loss 1.6572 (1.7647) lr 7.5000e-03 eta 0:17:28
epoch [11/30] batch [80/204] time 0.245 (0.257) data 0.000 (0.009) loss 1.5908 (1.6409) lr 7.5000e-03 eta 0:17:08
epoch [11/30] batch [100/204] time 0.258 (0.256) data 0.000 (0.007) loss 0.6948 (1.5954) lr 7.5000e-03 eta 0:16:59
epoch [11/30] batch [120/204] time 0.251 (0.255) data 0.000 (0.006) loss 0.3767 (1.6540) lr 7.5000e-03 eta 0:16:49
epoch [11/30] batch [140/204] time 0.245 (0.254) data 0.000 (0.005) loss 2.0645 (1.6564) lr 7.5000e-03 eta 0:16:40
epoch [11/30] batch [160/204] time 0.250 (0.253) data 0.000 (0.005) loss 1.8252 (1.6555) lr 7.5000e-03 eta 0:16:31
epoch [11/30] batch [180/204] time 0.244 (0.252) data 0.000 (0.004) loss 2.6836 (1.6443) lr 7.5000e-03 eta 0:16:22
epoch [11/30] batch [200/204] time 0.242 (0.251) data 0.000 (0.004) loss 0.5498 (1.6360) lr 7.5000e-03 eta 0:16:14
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.33s/it] 20%|██        | 2/10 [00:01<00:05,  1.53it/s] 30%|███       | 3/10 [00:01<00:02,  2.39it/s] 40%|████      | 4/10 [00:01<00:01,  3.26it/s] 50%|█████     | 5/10 [00:01<00:01,  4.07it/s] 60%|██████    | 6/10 [00:02<00:00,  4.80it/s] 70%|███████   | 7/10 [00:02<00:00,  5.42it/s] 80%|████████  | 8/10 [00:02<00:00,  5.91it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.29it/s]100%|██████████| 10/10 [00:02<00:00,  6.96it/s]100%|██████████| 10/10 [00:02<00:00,  3.69it/s]=> result
* total: 975
* correct: 819
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 82.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/204] time 0.333 (0.288) data 0.000 (0.034) loss 0.5913 (1.5702) lr 7.0337e-03 eta 0:18:29
epoch [12/30] batch [40/204] time 0.248 (0.268) data 0.000 (0.017) loss 1.0117 (1.5878) lr 7.0337e-03 eta 0:17:06
epoch [12/30] batch [60/204] time 0.247 (0.261) data 0.000 (0.011) loss 0.4751 (1.5490) lr 7.0337e-03 eta 0:16:37
epoch [12/30] batch [80/204] time 0.246 (0.259) data 0.000 (0.009) loss 0.2102 (1.5243) lr 7.0337e-03 eta 0:16:21
epoch [12/30] batch [100/204] time 0.247 (0.257) data 0.000 (0.007) loss 0.2761 (1.5283) lr 7.0337e-03 eta 0:16:09
epoch [12/30] batch [120/204] time 0.248 (0.255) data 0.000 (0.006) loss 0.3679 (1.4974) lr 7.0337e-03 eta 0:15:59
epoch [12/30] batch [140/204] time 0.247 (0.254) data 0.000 (0.005) loss 1.0322 (1.4960) lr 7.0337e-03 eta 0:15:49
epoch [12/30] batch [160/204] time 0.246 (0.254) data 0.000 (0.004) loss 1.7793 (1.5216) lr 7.0337e-03 eta 0:15:42
epoch [12/30] batch [180/204] time 0.241 (0.253) data 0.000 (0.004) loss 3.5859 (1.5135) lr 7.0337e-03 eta 0:15:35
epoch [12/30] batch [200/204] time 0.243 (0.252) data 0.000 (0.004) loss 1.3545 (1.5616) lr 7.0337e-03 eta 0:15:26
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.28s/it] 20%|██        | 2/10 [00:01<00:04,  1.65it/s] 30%|███       | 3/10 [00:01<00:02,  2.54it/s] 40%|████      | 4/10 [00:01<00:01,  3.44it/s] 50%|█████     | 5/10 [00:01<00:01,  4.27it/s] 60%|██████    | 6/10 [00:01<00:00,  4.99it/s] 70%|███████   | 7/10 [00:02<00:00,  5.59it/s] 80%|████████  | 8/10 [00:02<00:00,  6.09it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.46it/s]100%|██████████| 10/10 [00:02<00:00,  7.16it/s]100%|██████████| 10/10 [00:02<00:00,  3.90it/s]=> result
* total: 975
* correct: 823
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [13/30] batch [20/204] time 0.249 (0.285) data 0.000 (0.036) loss 0.6777 (1.5977) lr 6.5451e-03 eta 0:17:21
epoch [13/30] batch [40/204] time 0.255 (0.266) data 0.000 (0.018) loss 0.9395 (1.6994) lr 6.5451e-03 eta 0:16:06
epoch [13/30] batch [60/204] time 0.243 (0.259) data 0.000 (0.012) loss 0.5942 (1.5242) lr 6.5451e-03 eta 0:15:36
epoch [13/30] batch [80/204] time 0.245 (0.257) data 0.000 (0.009) loss 2.6094 (1.6002) lr 6.5451e-03 eta 0:15:23
epoch [13/30] batch [100/204] time 0.247 (0.255) data 0.000 (0.007) loss 0.4995 (1.5951) lr 6.5451e-03 eta 0:15:11
epoch [13/30] batch [120/204] time 0.247 (0.254) data 0.000 (0.006) loss 2.9434 (1.6254) lr 6.5451e-03 eta 0:15:02
epoch [13/30] batch [140/204] time 0.249 (0.254) data 0.000 (0.005) loss 2.2227 (1.6195) lr 6.5451e-03 eta 0:14:55
epoch [13/30] batch [160/204] time 0.246 (0.253) data 0.000 (0.005) loss 0.9438 (1.6364) lr 6.5451e-03 eta 0:14:50
epoch [13/30] batch [180/204] time 0.244 (0.253) data 0.000 (0.004) loss 5.2148 (1.6295) lr 6.5451e-03 eta 0:14:42
epoch [13/30] batch [200/204] time 0.242 (0.252) data 0.000 (0.004) loss 1.0254 (1.6118) lr 6.5451e-03 eta 0:14:34
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.34s/it] 20%|██        | 2/10 [00:01<00:05,  1.56it/s] 30%|███       | 3/10 [00:01<00:02,  2.43it/s] 40%|████      | 4/10 [00:01<00:01,  3.30it/s] 50%|█████     | 5/10 [00:01<00:01,  4.12it/s] 60%|██████    | 6/10 [00:02<00:00,  4.85it/s] 70%|███████   | 7/10 [00:02<00:00,  5.46it/s] 80%|████████  | 8/10 [00:02<00:00,  5.94it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.31it/s]100%|██████████| 10/10 [00:02<00:00,  6.98it/s]100%|██████████| 10/10 [00:02<00:00,  3.73it/s]=> result
* total: 975
* correct: 826
* accuracy: 84.7%
* error: 15.3%
* macro_f1: 83.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [14/30] batch [20/204] time 0.252 (0.286) data 0.000 (0.033) loss 1.1660 (1.1245) lr 6.0396e-03 eta 0:16:24
epoch [14/30] batch [40/204] time 0.248 (0.268) data 0.000 (0.017) loss 1.7002 (1.1748) lr 6.0396e-03 eta 0:15:18
epoch [14/30] batch [60/204] time 0.339 (0.263) data 0.000 (0.011) loss 0.1591 (1.1996) lr 6.0396e-03 eta 0:14:55
epoch [14/30] batch [80/204] time 0.246 (0.259) data 0.000 (0.008) loss 0.4424 (1.2782) lr 6.0396e-03 eta 0:14:38
epoch [14/30] batch [100/204] time 0.251 (0.257) data 0.000 (0.007) loss 0.9824 (1.2907) lr 6.0396e-03 eta 0:14:27
epoch [14/30] batch [120/204] time 0.259 (0.256) data 0.000 (0.006) loss 2.3496 (1.2692) lr 6.0396e-03 eta 0:14:17
epoch [14/30] batch [140/204] time 0.261 (0.255) data 0.000 (0.005) loss 0.1138 (1.2999) lr 6.0396e-03 eta 0:14:08
epoch [14/30] batch [160/204] time 0.254 (0.254) data 0.000 (0.004) loss 0.0740 (1.3312) lr 6.0396e-03 eta 0:14:01
epoch [14/30] batch [180/204] time 0.241 (0.253) data 0.000 (0.004) loss 3.0664 (1.3752) lr 6.0396e-03 eta 0:13:52
epoch [14/30] batch [200/204] time 0.242 (0.252) data 0.000 (0.004) loss 0.1470 (1.3836) lr 6.0396e-03 eta 0:13:43
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:13,  1.45s/it] 20%|██        | 2/10 [00:01<00:05,  1.46it/s] 30%|███       | 3/10 [00:01<00:03,  2.30it/s] 40%|████      | 4/10 [00:01<00:01,  3.17it/s] 50%|█████     | 5/10 [00:02<00:01,  3.98it/s] 60%|██████    | 6/10 [00:02<00:00,  4.72it/s] 70%|███████   | 7/10 [00:02<00:00,  5.35it/s] 80%|████████  | 8/10 [00:02<00:00,  5.86it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.25it/s]100%|██████████| 10/10 [00:02<00:00,  6.94it/s]100%|██████████| 10/10 [00:02<00:00,  3.61it/s]=> result
* total: 975
* correct: 831
* accuracy: 85.2%
* error: 14.8%
* macro_f1: 84.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/204] time 0.253 (0.289) data 0.000 (0.033) loss 0.1298 (1.1434) lr 5.5226e-03 eta 0:15:38
epoch [15/30] batch [40/204] time 0.247 (0.268) data 0.000 (0.017) loss 0.6240 (1.0397) lr 5.5226e-03 eta 0:14:24
epoch [15/30] batch [60/204] time 0.250 (0.262) data 0.000 (0.011) loss 1.3760 (1.2115) lr 5.5226e-03 eta 0:13:58
epoch [15/30] batch [80/204] time 0.244 (0.258) data 0.000 (0.009) loss 2.3438 (1.2967) lr 5.5226e-03 eta 0:13:41
epoch [15/30] batch [100/204] time 0.249 (0.256) data 0.000 (0.007) loss 0.7783 (1.3084) lr 5.5226e-03 eta 0:13:31
epoch [15/30] batch [120/204] time 0.247 (0.255) data 0.000 (0.006) loss 1.2637 (1.3443) lr 5.5226e-03 eta 0:13:22
epoch [15/30] batch [140/204] time 0.250 (0.255) data 0.000 (0.005) loss 2.0469 (1.3725) lr 5.5226e-03 eta 0:13:15
epoch [15/30] batch [160/204] time 0.251 (0.254) data 0.000 (0.004) loss 0.6348 (1.3306) lr 5.5226e-03 eta 0:13:08
epoch [15/30] batch [180/204] time 0.248 (0.254) data 0.000 (0.004) loss 0.4834 (1.3301) lr 5.5226e-03 eta 0:13:02
epoch [15/30] batch [200/204] time 0.244 (0.253) data 0.000 (0.004) loss 0.8750 (1.3461) lr 5.5226e-03 eta 0:12:54
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.41s/it] 20%|██        | 2/10 [00:01<00:05,  1.51it/s] 30%|███       | 3/10 [00:01<00:02,  2.37it/s] 40%|████      | 4/10 [00:01<00:01,  3.23it/s] 50%|█████     | 5/10 [00:01<00:01,  4.05it/s] 60%|██████    | 6/10 [00:02<00:00,  4.78it/s] 70%|███████   | 7/10 [00:02<00:00,  5.41it/s] 80%|████████  | 8/10 [00:02<00:00,  5.90it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.28it/s]100%|██████████| 10/10 [00:02<00:00,  6.96it/s]100%|██████████| 10/10 [00:02<00:00,  3.68it/s]=> result
* total: 975
* correct: 840
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 85.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [16/30] batch [20/204] time 0.245 (0.284) data 0.000 (0.034) loss 2.8320 (1.2295) lr 5.0000e-03 eta 0:14:24
epoch [16/30] batch [40/204] time 0.247 (0.266) data 0.000 (0.017) loss 3.0586 (1.5448) lr 5.0000e-03 eta 0:13:22
epoch [16/30] batch [60/204] time 0.244 (0.259) data 0.000 (0.011) loss 0.0603 (1.4611) lr 5.0000e-03 eta 0:12:58
epoch [16/30] batch [80/204] time 0.246 (0.257) data 0.000 (0.009) loss 0.6108 (1.5316) lr 5.0000e-03 eta 0:12:47
epoch [16/30] batch [100/204] time 0.249 (0.255) data 0.000 (0.007) loss 1.6504 (1.5496) lr 5.0000e-03 eta 0:12:35
epoch [16/30] batch [120/204] time 0.251 (0.254) data 0.000 (0.006) loss 5.4805 (1.5448) lr 5.0000e-03 eta 0:12:26
epoch [16/30] batch [140/204] time 0.243 (0.253) data 0.000 (0.005) loss 0.9238 (1.4887) lr 5.0000e-03 eta 0:12:17
epoch [16/30] batch [160/204] time 0.245 (0.252) data 0.000 (0.004) loss 1.0840 (1.4974) lr 5.0000e-03 eta 0:12:10
epoch [16/30] batch [180/204] time 0.241 (0.251) data 0.000 (0.004) loss 2.2461 (1.4820) lr 5.0000e-03 eta 0:12:03
epoch [16/30] batch [200/204] time 0.241 (0.251) data 0.000 (0.004) loss 0.2107 (1.4887) lr 5.0000e-03 eta 0:11:56
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.41s/it] 20%|██        | 2/10 [00:01<00:05,  1.51it/s] 30%|███       | 3/10 [00:01<00:02,  2.38it/s] 40%|████      | 4/10 [00:01<00:01,  3.25it/s] 50%|█████     | 5/10 [00:01<00:01,  4.09it/s] 60%|██████    | 6/10 [00:02<00:00,  4.84it/s] 70%|███████   | 7/10 [00:02<00:00,  5.46it/s] 80%|████████  | 8/10 [00:02<00:00,  5.97it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.37it/s]100%|██████████| 10/10 [00:02<00:00,  7.06it/s]100%|██████████| 10/10 [00:02<00:00,  3.69it/s]=> result
* total: 975
* correct: 846
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [17/30] batch [20/204] time 0.248 (0.287) data 0.000 (0.036) loss 0.4858 (1.6125) lr 4.4774e-03 eta 0:13:34
epoch [17/30] batch [40/204] time 0.246 (0.267) data 0.000 (0.018) loss 0.1710 (1.3766) lr 4.4774e-03 eta 0:12:31
epoch [17/30] batch [60/204] time 0.248 (0.260) data 0.000 (0.012) loss 0.2336 (1.2581) lr 4.4774e-03 eta 0:12:07
epoch [17/30] batch [80/204] time 0.250 (0.257) data 0.000 (0.009) loss 0.0897 (1.2812) lr 4.4774e-03 eta 0:11:53
epoch [17/30] batch [100/204] time 0.248 (0.257) data 0.000 (0.007) loss 2.0898 (1.2637) lr 4.4774e-03 eta 0:11:47
epoch [17/30] batch [120/204] time 0.246 (0.255) data 0.000 (0.006) loss 0.0389 (1.2844) lr 4.4774e-03 eta 0:11:37
epoch [17/30] batch [140/204] time 0.250 (0.254) data 0.000 (0.005) loss 0.0427 (1.2625) lr 4.4774e-03 eta 0:11:30
epoch [17/30] batch [160/204] time 0.247 (0.254) data 0.000 (0.005) loss 0.1013 (1.3024) lr 4.4774e-03 eta 0:11:24
epoch [17/30] batch [180/204] time 0.245 (0.253) data 0.000 (0.004) loss 0.1902 (1.3198) lr 4.4774e-03 eta 0:11:17
epoch [17/30] batch [200/204] time 0.243 (0.252) data 0.000 (0.004) loss 1.3125 (1.3499) lr 4.4774e-03 eta 0:11:09
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.28s/it] 20%|██        | 2/10 [00:01<00:04,  1.61it/s] 30%|███       | 3/10 [00:01<00:02,  2.50it/s] 40%|████      | 4/10 [00:01<00:01,  3.38it/s] 50%|█████     | 5/10 [00:01<00:01,  4.20it/s] 60%|██████    | 6/10 [00:01<00:00,  4.92it/s] 70%|███████   | 7/10 [00:02<00:00,  5.51it/s] 80%|████████  | 8/10 [00:02<00:00,  5.99it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.37it/s]100%|██████████| 10/10 [00:02<00:00,  7.04it/s]100%|██████████| 10/10 [00:02<00:00,  3.81it/s]=> result
* total: 975
* correct: 838
* accuracy: 85.9%
* error: 14.1%
* macro_f1: 85.0%

epoch [18/30] batch [20/204] time 0.246 (0.288) data 0.000 (0.034) loss 1.8398 (1.3498) lr 3.9604e-03 eta 0:12:37
epoch [18/30] batch [40/204] time 0.247 (0.267) data 0.000 (0.017) loss 0.6201 (1.2057) lr 3.9604e-03 eta 0:11:38
epoch [18/30] batch [60/204] time 0.247 (0.260) data 0.000 (0.012) loss 3.5137 (1.2159) lr 3.9604e-03 eta 0:11:14
epoch [18/30] batch [80/204] time 0.247 (0.258) data 0.000 (0.009) loss 0.2825 (1.2193) lr 3.9604e-03 eta 0:11:03
epoch [18/30] batch [100/204] time 0.247 (0.256) data 0.000 (0.007) loss 1.4355 (1.2924) lr 3.9604e-03 eta 0:10:52
epoch [18/30] batch [120/204] time 0.247 (0.254) data 0.000 (0.006) loss 0.6230 (1.3128) lr 3.9604e-03 eta 0:10:43
epoch [18/30] batch [140/204] time 0.252 (0.253) data 0.000 (0.005) loss 0.4819 (1.3054) lr 3.9604e-03 eta 0:10:35
epoch [18/30] batch [160/204] time 0.247 (0.253) data 0.000 (0.005) loss 0.0640 (1.2694) lr 3.9604e-03 eta 0:10:29
epoch [18/30] batch [180/204] time 0.245 (0.252) data 0.000 (0.004) loss 2.9902 (1.2572) lr 3.9604e-03 eta 0:10:23
epoch [18/30] batch [200/204] time 0.245 (0.251) data 0.000 (0.004) loss 0.2382 (1.2390) lr 3.9604e-03 eta 0:10:16
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.39s/it] 20%|██        | 2/10 [00:01<00:05,  1.53it/s] 30%|███       | 3/10 [00:01<00:02,  2.39it/s] 40%|████      | 4/10 [00:01<00:01,  3.27it/s] 50%|█████     | 5/10 [00:01<00:01,  4.08it/s] 60%|██████    | 6/10 [00:02<00:00,  4.81it/s] 70%|███████   | 7/10 [00:02<00:00,  5.43it/s] 80%|████████  | 8/10 [00:02<00:00,  5.93it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.30it/s]100%|██████████| 10/10 [00:02<00:00,  7.00it/s]100%|██████████| 10/10 [00:02<00:00,  3.72it/s]=> result
* total: 975
* correct: 848
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 85.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/204] time 0.251 (0.293) data 0.000 (0.034) loss 1.4131 (1.5339) lr 3.4549e-03 eta 0:11:50
epoch [19/30] batch [40/204] time 0.252 (0.273) data 0.000 (0.017) loss -0.0428 (1.3237) lr 3.4549e-03 eta 0:10:56
epoch [19/30] batch [60/204] time 0.254 (0.266) data 0.000 (0.012) loss 0.0263 (1.2700) lr 3.4549e-03 eta 0:10:35
epoch [19/30] batch [80/204] time 0.252 (0.263) data 0.000 (0.009) loss 0.5410 (1.4023) lr 3.4549e-03 eta 0:10:22
epoch [19/30] batch [100/204] time 0.250 (0.260) data 0.000 (0.007) loss 0.2646 (1.3655) lr 3.4549e-03 eta 0:10:11
epoch [19/30] batch [120/204] time 0.252 (0.259) data 0.000 (0.006) loss 1.2559 (1.3582) lr 3.4549e-03 eta 0:10:03
epoch [19/30] batch [140/204] time 0.256 (0.258) data 0.000 (0.005) loss 1.0264 (1.3404) lr 3.4549e-03 eta 0:09:55
epoch [19/30] batch [160/204] time 0.249 (0.257) data 0.000 (0.005) loss 0.0678 (1.3311) lr 3.4549e-03 eta 0:09:48
epoch [19/30] batch [180/204] time 0.244 (0.256) data 0.000 (0.004) loss 0.1807 (1.3208) lr 3.4549e-03 eta 0:09:40
epoch [19/30] batch [200/204] time 0.244 (0.255) data 0.000 (0.004) loss 2.3184 (1.3416) lr 3.4549e-03 eta 0:09:33
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.40s/it] 20%|██        | 2/10 [00:01<00:05,  1.52it/s] 30%|███       | 3/10 [00:01<00:02,  2.38it/s] 40%|████      | 4/10 [00:01<00:01,  3.19it/s] 50%|█████     | 5/10 [00:01<00:01,  4.03it/s] 60%|██████    | 6/10 [00:02<00:00,  4.76it/s] 70%|███████   | 7/10 [00:02<00:00,  5.41it/s] 80%|████████  | 8/10 [00:02<00:00,  5.92it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.32it/s]100%|██████████| 10/10 [00:02<00:00,  7.01it/s]100%|██████████| 10/10 [00:02<00:00,  3.68it/s]=> result
* total: 975
* correct: 843
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 85.6%

epoch [20/30] batch [20/204] time 0.248 (0.286) data 0.000 (0.034) loss 1.6504 (1.6519) lr 2.9663e-03 eta 0:10:36
epoch [20/30] batch [40/204] time 0.246 (0.268) data 0.000 (0.017) loss 0.0147 (1.2872) lr 2.9663e-03 eta 0:09:49
epoch [20/30] batch [60/204] time 0.251 (0.264) data 0.000 (0.012) loss 0.5068 (1.1453) lr 2.9663e-03 eta 0:09:35
epoch [20/30] batch [80/204] time 0.251 (0.261) data 0.000 (0.009) loss 2.5723 (1.2264) lr 2.9663e-03 eta 0:09:24
epoch [20/30] batch [100/204] time 0.254 (0.259) data 0.000 (0.007) loss 2.3887 (1.2648) lr 2.9663e-03 eta 0:09:15
epoch [20/30] batch [120/204] time 0.251 (0.259) data 0.000 (0.006) loss 0.3699 (1.2901) lr 2.9663e-03 eta 0:09:09
epoch [20/30] batch [140/204] time 0.259 (0.258) data 0.000 (0.005) loss 1.5273 (1.3512) lr 2.9663e-03 eta 0:09:02
epoch [20/30] batch [160/204] time 0.253 (0.257) data 0.000 (0.005) loss 0.5884 (1.3333) lr 2.9663e-03 eta 0:08:56
epoch [20/30] batch [180/204] time 0.246 (0.256) data 0.000 (0.004) loss 2.1465 (1.4070) lr 2.9663e-03 eta 0:08:49
epoch [20/30] batch [200/204] time 0.245 (0.255) data 0.000 (0.004) loss 0.7656 (1.3443) lr 2.9663e-03 eta 0:08:41
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.44s/it] 20%|██        | 2/10 [00:01<00:05,  1.48it/s] 30%|███       | 3/10 [00:01<00:03,  2.33it/s] 40%|████      | 4/10 [00:01<00:01,  3.19it/s] 50%|█████     | 5/10 [00:01<00:01,  4.00it/s] 60%|██████    | 6/10 [00:02<00:00,  4.74it/s] 70%|███████   | 7/10 [00:02<00:00,  5.37it/s] 80%|████████  | 8/10 [00:02<00:00,  5.88it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.27it/s]100%|██████████| 10/10 [00:02<00:00,  6.95it/s]100%|██████████| 10/10 [00:02<00:00,  3.63it/s]=> result
* total: 975
* correct: 848
* accuracy: 87.0%
* error: 13.0%
* macro_f1: 85.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/204] time 0.252 (0.294) data 0.000 (0.034) loss -0.0102 (1.3280) lr 2.5000e-03 eta 0:09:53
epoch [21/30] batch [40/204] time 0.252 (0.273) data 0.000 (0.017) loss 1.1592 (1.3677) lr 2.5000e-03 eta 0:09:05
epoch [21/30] batch [60/204] time 0.252 (0.266) data 0.000 (0.012) loss 2.3711 (1.2819) lr 2.5000e-03 eta 0:08:46
epoch [21/30] batch [80/204] time 0.254 (0.263) data 0.000 (0.009) loss 1.5938 (1.2915) lr 2.5000e-03 eta 0:08:35
epoch [21/30] batch [100/204] time 0.248 (0.260) data 0.000 (0.007) loss 0.3882 (1.2850) lr 2.5000e-03 eta 0:08:25
epoch [21/30] batch [120/204] time 0.246 (0.258) data 0.000 (0.006) loss 0.2358 (1.3147) lr 2.5000e-03 eta 0:08:15
epoch [21/30] batch [140/204] time 0.247 (0.257) data 0.000 (0.005) loss 0.3110 (1.2674) lr 2.5000e-03 eta 0:08:08
epoch [21/30] batch [160/204] time 0.246 (0.256) data 0.000 (0.004) loss 0.7593 (1.2166) lr 2.5000e-03 eta 0:08:01
epoch [21/30] batch [180/204] time 0.242 (0.255) data 0.000 (0.004) loss 4.1445 (1.2903) lr 2.5000e-03 eta 0:07:53
epoch [21/30] batch [200/204] time 0.242 (0.254) data 0.000 (0.004) loss 2.4883 (1.3210) lr 2.5000e-03 eta 0:07:46
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:13,  1.50s/it] 20%|██        | 2/10 [00:01<00:05,  1.43it/s] 30%|███       | 3/10 [00:01<00:03,  2.26it/s] 40%|████      | 4/10 [00:01<00:01,  3.10it/s] 50%|█████     | 5/10 [00:02<00:01,  3.91it/s] 60%|██████    | 6/10 [00:02<00:00,  4.66it/s] 70%|███████   | 7/10 [00:02<00:00,  5.29it/s] 80%|████████  | 8/10 [00:02<00:00,  5.81it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.22it/s]100%|██████████| 10/10 [00:02<00:00,  6.91it/s]100%|██████████| 10/10 [00:02<00:00,  3.55it/s]=> result
* total: 975
* correct: 845
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 85.5%

epoch [22/30] batch [20/204] time 0.247 (0.287) data 0.000 (0.033) loss 4.7812 (1.0001) lr 2.0611e-03 eta 0:08:40
epoch [22/30] batch [40/204] time 0.253 (0.267) data 0.000 (0.016) loss 1.8301 (0.9987) lr 2.0611e-03 eta 0:08:00
epoch [22/30] batch [60/204] time 0.248 (0.261) data 0.000 (0.011) loss 3.0117 (1.0386) lr 2.0611e-03 eta 0:07:43
epoch [22/30] batch [80/204] time 0.249 (0.258) data 0.000 (0.008) loss 1.2305 (1.1542) lr 2.0611e-03 eta 0:07:33
epoch [22/30] batch [100/204] time 0.249 (0.258) data 0.000 (0.007) loss 0.6377 (1.1850) lr 2.0611e-03 eta 0:07:27
epoch [22/30] batch [120/204] time 0.247 (0.256) data 0.000 (0.006) loss 2.4043 (1.1598) lr 2.0611e-03 eta 0:07:19
epoch [22/30] batch [140/204] time 0.252 (0.255) data 0.000 (0.005) loss 1.1289 (1.1868) lr 2.0611e-03 eta 0:07:12
epoch [22/30] batch [160/204] time 0.257 (0.255) data 0.000 (0.004) loss 0.5342 (1.1882) lr 2.0611e-03 eta 0:07:06
epoch [22/30] batch [180/204] time 0.244 (0.254) data 0.000 (0.004) loss 0.5493 (1.1967) lr 2.0611e-03 eta 0:07:01
epoch [22/30] batch [200/204] time 0.242 (0.253) data 0.000 (0.003) loss 0.5151 (1.2339) lr 2.0611e-03 eta 0:06:54
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.35s/it] 20%|██        | 2/10 [00:01<00:05,  1.56it/s] 30%|███       | 3/10 [00:01<00:02,  2.43it/s] 40%|████      | 4/10 [00:01<00:01,  3.31it/s] 50%|█████     | 5/10 [00:01<00:01,  4.11it/s] 60%|██████    | 6/10 [00:02<00:00,  4.83it/s] 70%|███████   | 7/10 [00:02<00:00,  5.44it/s] 80%|████████  | 8/10 [00:02<00:00,  5.93it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.31it/s]100%|██████████| 10/10 [00:02<00:00,  6.99it/s]100%|██████████| 10/10 [00:02<00:00,  3.73it/s]=> result
* total: 975
* correct: 865
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 87.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [23/30] batch [20/204] time 0.246 (0.286) data 0.000 (0.033) loss 1.1543 (1.3035) lr 1.6543e-03 eta 0:07:40
epoch [23/30] batch [40/204] time 0.244 (0.266) data 0.000 (0.017) loss 0.5557 (1.2409) lr 1.6543e-03 eta 0:07:04
epoch [23/30] batch [60/204] time 0.255 (0.262) data 0.000 (0.011) loss 2.3320 (1.3056) lr 1.6543e-03 eta 0:06:51
epoch [23/30] batch [80/204] time 0.249 (0.258) data 0.000 (0.008) loss 0.4229 (1.2712) lr 1.6543e-03 eta 0:06:40
epoch [23/30] batch [100/204] time 0.247 (0.256) data 0.000 (0.007) loss 3.1523 (1.2342) lr 1.6543e-03 eta 0:06:31
epoch [23/30] batch [120/204] time 0.248 (0.255) data 0.000 (0.006) loss 0.3069 (1.2788) lr 1.6543e-03 eta 0:06:24
epoch [23/30] batch [140/204] time 0.250 (0.254) data 0.000 (0.005) loss 2.1758 (1.2639) lr 1.6543e-03 eta 0:06:18
epoch [23/30] batch [160/204] time 0.246 (0.253) data 0.000 (0.004) loss 0.8003 (1.2298) lr 1.6543e-03 eta 0:06:13
epoch [23/30] batch [180/204] time 0.243 (0.253) data 0.000 (0.004) loss 1.7109 (1.2505) lr 1.6543e-03 eta 0:06:06
epoch [23/30] batch [200/204] time 0.243 (0.252) data 0.000 (0.004) loss 1.4023 (1.2586) lr 1.6543e-03 eta 0:06:00
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.30s/it] 20%|██        | 2/10 [00:01<00:04,  1.61it/s] 30%|███       | 3/10 [00:01<00:02,  2.50it/s] 40%|████      | 4/10 [00:01<00:01,  3.38it/s] 50%|█████     | 5/10 [00:01<00:01,  4.20it/s] 60%|██████    | 6/10 [00:01<00:00,  4.92it/s] 70%|███████   | 7/10 [00:02<00:00,  5.51it/s] 80%|████████  | 8/10 [00:02<00:00,  5.99it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.36it/s]100%|██████████| 10/10 [00:02<00:00,  7.04it/s]100%|██████████| 10/10 [00:02<00:00,  3.80it/s]=> result
* total: 975
* correct: 868
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 88.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [24/30] batch [20/204] time 0.247 (0.287) data 0.000 (0.036) loss 2.9551 (1.5891) lr 1.2843e-03 eta 0:06:44
epoch [24/30] batch [40/204] time 0.246 (0.267) data 0.000 (0.018) loss 0.5029 (1.5221) lr 1.2843e-03 eta 0:06:11
epoch [24/30] batch [60/204] time 0.247 (0.262) data 0.000 (0.012) loss 1.1221 (1.5632) lr 1.2843e-03 eta 0:05:59
epoch [24/30] batch [80/204] time 0.249 (0.259) data 0.001 (0.009) loss 0.0596 (1.4069) lr 1.2843e-03 eta 0:05:48
epoch [24/30] batch [100/204] time 0.247 (0.257) data 0.000 (0.007) loss 0.3965 (1.3134) lr 1.2843e-03 eta 0:05:40
epoch [24/30] batch [120/204] time 0.247 (0.255) data 0.000 (0.006) loss 3.7051 (1.3481) lr 1.2843e-03 eta 0:05:34
epoch [24/30] batch [140/204] time 0.253 (0.254) data 0.000 (0.005) loss 0.5151 (1.3402) lr 1.2843e-03 eta 0:05:27
epoch [24/30] batch [160/204] time 0.252 (0.254) data 0.000 (0.005) loss 3.1230 (1.3393) lr 1.2843e-03 eta 0:05:22
epoch [24/30] batch [180/204] time 0.242 (0.253) data 0.000 (0.004) loss 1.7773 (1.2927) lr 1.2843e-03 eta 0:05:16
epoch [24/30] batch [200/204] time 0.244 (0.252) data 0.000 (0.004) loss 0.2896 (1.2653) lr 1.2843e-03 eta 0:05:09
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.43s/it] 20%|██        | 2/10 [00:01<00:05,  1.49it/s] 30%|███       | 3/10 [00:01<00:02,  2.34it/s] 40%|████      | 4/10 [00:01<00:01,  3.21it/s] 50%|█████     | 5/10 [00:01<00:01,  4.04it/s] 60%|██████    | 6/10 [00:02<00:00,  4.79it/s] 70%|███████   | 7/10 [00:02<00:00,  5.43it/s] 80%|████████  | 8/10 [00:02<00:00,  5.94it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.36it/s]100%|██████████| 10/10 [00:02<00:00,  7.07it/s]100%|██████████| 10/10 [00:02<00:00,  3.67it/s]=> result
* total: 975
* correct: 860
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 87.5%

epoch [25/30] batch [20/204] time 0.250 (0.283) data 0.000 (0.033) loss 0.0506 (1.0171) lr 9.5492e-04 eta 0:05:41
epoch [25/30] batch [40/204] time 0.251 (0.267) data 0.000 (0.017) loss 0.2285 (1.0650) lr 9.5492e-04 eta 0:05:16
epoch [25/30] batch [60/204] time 0.245 (0.260) data 0.000 (0.011) loss 2.4453 (1.1521) lr 9.5492e-04 eta 0:05:02
epoch [25/30] batch [80/204] time 0.246 (0.257) data 0.000 (0.009) loss 2.0234 (1.1962) lr 9.5492e-04 eta 0:04:53
epoch [25/30] batch [100/204] time 0.245 (0.256) data 0.000 (0.007) loss 2.5234 (1.2738) lr 9.5492e-04 eta 0:04:47
epoch [25/30] batch [120/204] time 0.250 (0.255) data 0.000 (0.006) loss 0.4297 (1.2135) lr 9.5492e-04 eta 0:04:41
epoch [25/30] batch [140/204] time 0.250 (0.254) data 0.000 (0.005) loss 0.1331 (1.1696) lr 9.5492e-04 eta 0:04:35
epoch [25/30] batch [160/204] time 0.248 (0.254) data 0.000 (0.004) loss 0.3325 (1.1683) lr 9.5492e-04 eta 0:04:30
epoch [25/30] batch [180/204] time 0.243 (0.253) data 0.000 (0.004) loss 2.4668 (1.1542) lr 9.5492e-04 eta 0:04:24
epoch [25/30] batch [200/204] time 0.242 (0.252) data 0.000 (0.004) loss 0.4197 (1.1585) lr 9.5492e-04 eta 0:04:18
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.29s/it] 20%|██        | 2/10 [00:01<00:04,  1.63it/s] 30%|███       | 3/10 [00:01<00:02,  2.54it/s] 40%|████      | 4/10 [00:01<00:01,  3.44it/s] 50%|█████     | 5/10 [00:01<00:01,  4.25it/s] 60%|██████    | 6/10 [00:01<00:00,  4.99it/s] 70%|███████   | 7/10 [00:02<00:00,  5.59it/s] 80%|████████  | 8/10 [00:02<00:00,  6.10it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.47it/s]100%|██████████| 10/10 [00:02<00:00,  7.17it/s]100%|██████████| 10/10 [00:02<00:00,  3.90it/s]=> result
* total: 975
* correct: 863
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 87.9%

epoch [26/30] batch [20/204] time 0.248 (0.286) data 0.000 (0.033) loss 2.4512 (1.2866) lr 6.6987e-04 eta 0:04:45
epoch [26/30] batch [40/204] time 0.247 (0.267) data 0.000 (0.017) loss 0.1796 (1.0151) lr 6.6987e-04 eta 0:04:21
epoch [26/30] batch [60/204] time 0.245 (0.262) data 0.000 (0.011) loss 3.6191 (1.1755) lr 6.6987e-04 eta 0:04:11
epoch [26/30] batch [80/204] time 0.250 (0.259) data 0.000 (0.009) loss 0.3164 (1.0804) lr 6.6987e-04 eta 0:04:03
epoch [26/30] batch [100/204] time 0.249 (0.257) data 0.000 (0.007) loss 0.1715 (1.0520) lr 6.6987e-04 eta 0:03:56
epoch [26/30] batch [120/204] time 0.248 (0.256) data 0.000 (0.006) loss 4.8359 (1.1116) lr 6.6987e-04 eta 0:03:50
epoch [26/30] batch [140/204] time 0.248 (0.255) data 0.000 (0.005) loss 0.7554 (1.1539) lr 6.6987e-04 eta 0:03:44
epoch [26/30] batch [160/204] time 0.244 (0.254) data 0.000 (0.004) loss 3.4648 (1.1195) lr 6.6987e-04 eta 0:03:38
epoch [26/30] batch [180/204] time 0.240 (0.253) data 0.000 (0.004) loss 1.2412 (1.1012) lr 6.6987e-04 eta 0:03:32
epoch [26/30] batch [200/204] time 0.242 (0.252) data 0.000 (0.004) loss 0.2905 (1.0938) lr 6.6987e-04 eta 0:03:26
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.41s/it] 20%|██        | 2/10 [00:01<00:05,  1.49it/s] 30%|███       | 3/10 [00:01<00:02,  2.34it/s] 40%|████      | 4/10 [00:01<00:01,  3.20it/s] 50%|█████     | 5/10 [00:01<00:01,  4.02it/s] 60%|██████    | 6/10 [00:02<00:00,  4.75it/s] 70%|███████   | 7/10 [00:02<00:00,  5.35it/s] 80%|████████  | 8/10 [00:02<00:00,  5.72it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.15it/s]100%|██████████| 10/10 [00:02<00:00,  6.85it/s]100%|██████████| 10/10 [00:02<00:00,  3.63it/s]=> result
* total: 975
* correct: 864
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 88.0%

epoch [27/30] batch [20/204] time 0.248 (0.288) data 0.000 (0.034) loss 0.0797 (0.8339) lr 4.3227e-04 eta 0:03:49
epoch [27/30] batch [40/204] time 0.246 (0.270) data 0.000 (0.017) loss 0.8623 (0.9393) lr 4.3227e-04 eta 0:03:29
epoch [27/30] batch [60/204] time 0.254 (0.263) data 0.000 (0.011) loss 0.0784 (0.8836) lr 4.3227e-04 eta 0:03:19
epoch [27/30] batch [80/204] time 0.246 (0.260) data 0.000 (0.009) loss 0.6362 (1.0064) lr 4.3227e-04 eta 0:03:11
epoch [27/30] batch [100/204] time 0.250 (0.258) data 0.000 (0.007) loss 0.3640 (1.0747) lr 4.3227e-04 eta 0:03:04
epoch [27/30] batch [120/204] time 0.248 (0.257) data 0.000 (0.006) loss 0.3188 (1.0801) lr 4.3227e-04 eta 0:02:58
epoch [27/30] batch [140/204] time 0.248 (0.256) data 0.000 (0.005) loss 0.6826 (1.0673) lr 4.3227e-04 eta 0:02:52
epoch [27/30] batch [160/204] time 0.247 (0.255) data 0.000 (0.004) loss 0.1547 (1.1157) lr 4.3227e-04 eta 0:02:47
epoch [27/30] batch [180/204] time 0.243 (0.254) data 0.000 (0.004) loss 0.5054 (1.1114) lr 4.3227e-04 eta 0:02:41
epoch [27/30] batch [200/204] time 0.241 (0.253) data 0.000 (0.004) loss 0.9219 (1.0984) lr 4.3227e-04 eta 0:02:35
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:13,  1.45s/it] 20%|██        | 2/10 [00:01<00:05,  1.46it/s] 30%|███       | 3/10 [00:01<00:03,  2.30it/s] 40%|████      | 4/10 [00:01<00:01,  3.16it/s] 50%|█████     | 5/10 [00:02<00:01,  3.98it/s] 60%|██████    | 6/10 [00:02<00:00,  4.71it/s] 70%|███████   | 7/10 [00:02<00:00,  5.34it/s] 80%|████████  | 8/10 [00:02<00:00,  5.86it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.26it/s]100%|██████████| 10/10 [00:02<00:00,  6.95it/s]100%|██████████| 10/10 [00:02<00:00,  3.61it/s]=> result
* total: 975
* correct: 865
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 88.1%

epoch [28/30] batch [20/204] time 0.254 (0.303) data 0.000 (0.042) loss 0.2450 (0.9774) lr 2.4472e-04 eta 0:02:59
epoch [28/30] batch [40/204] time 0.250 (0.278) data 0.000 (0.021) loss 0.8677 (0.9213) lr 2.4472e-04 eta 0:02:39
epoch [28/30] batch [60/204] time 0.251 (0.270) data 0.000 (0.014) loss 0.9751 (1.0280) lr 2.4472e-04 eta 0:02:29
epoch [28/30] batch [80/204] time 0.250 (0.266) data 0.000 (0.011) loss 0.3806 (1.0723) lr 2.4472e-04 eta 0:02:21
epoch [28/30] batch [100/204] time 0.248 (0.263) data 0.000 (0.009) loss 3.7617 (1.0272) lr 2.4472e-04 eta 0:02:14
epoch [28/30] batch [120/204] time 0.249 (0.260) data 0.000 (0.007) loss 1.3750 (1.1226) lr 2.4472e-04 eta 0:02:08
epoch [28/30] batch [140/204] time 0.255 (0.259) data 0.000 (0.006) loss 0.1768 (1.1215) lr 2.4472e-04 eta 0:02:02
epoch [28/30] batch [160/204] time 0.251 (0.258) data 0.000 (0.005) loss 0.7358 (1.1468) lr 2.4472e-04 eta 0:01:56
epoch [28/30] batch [180/204] time 0.247 (0.258) data 0.000 (0.005) loss 1.3799 (1.1947) lr 2.4472e-04 eta 0:01:51
epoch [28/30] batch [200/204] time 0.246 (0.256) data 0.000 (0.004) loss 0.0024 (1.2028) lr 2.4472e-04 eta 0:01:45
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.40s/it] 20%|██        | 2/10 [00:01<00:05,  1.51it/s] 30%|███       | 3/10 [00:01<00:02,  2.37it/s] 40%|████      | 4/10 [00:01<00:01,  3.24it/s] 50%|█████     | 5/10 [00:01<00:01,  4.06it/s] 60%|██████    | 6/10 [00:02<00:00,  4.78it/s] 70%|███████   | 7/10 [00:02<00:00,  5.40it/s] 80%|████████  | 8/10 [00:02<00:00,  5.90it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.30it/s]100%|██████████| 10/10 [00:02<00:00,  6.97it/s]100%|██████████| 10/10 [00:02<00:00,  3.68it/s]=> result
* total: 975
* correct: 863
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 87.8%

epoch [29/30] batch [20/204] time 0.251 (0.291) data 0.000 (0.037) loss 0.6855 (1.0382) lr 1.0926e-04 eta 0:01:52
epoch [29/30] batch [40/204] time 0.247 (0.270) data 0.000 (0.019) loss 0.9092 (1.1630) lr 1.0926e-04 eta 0:01:39
epoch [29/30] batch [60/204] time 0.247 (0.265) data 0.000 (0.012) loss 0.5698 (1.2675) lr 1.0926e-04 eta 0:01:32
epoch [29/30] batch [80/204] time 0.250 (0.261) data 0.000 (0.009) loss 1.6387 (1.1334) lr 1.0926e-04 eta 0:01:25
epoch [29/30] batch [100/204] time 0.250 (0.259) data 0.000 (0.008) loss 1.0156 (1.1001) lr 1.0926e-04 eta 0:01:19
epoch [29/30] batch [120/204] time 0.248 (0.257) data 0.000 (0.006) loss 0.4819 (1.1062) lr 1.0926e-04 eta 0:01:14
epoch [29/30] batch [140/204] time 0.263 (0.257) data 0.000 (0.005) loss 0.2201 (1.1176) lr 1.0926e-04 eta 0:01:08
epoch [29/30] batch [160/204] time 0.249 (0.256) data 0.000 (0.005) loss 2.6035 (1.1588) lr 1.0926e-04 eta 0:01:03
epoch [29/30] batch [180/204] time 0.245 (0.255) data 0.000 (0.004) loss 0.8091 (1.1375) lr 1.0926e-04 eta 0:00:58
epoch [29/30] batch [200/204] time 0.246 (0.254) data 0.000 (0.004) loss 0.2312 (1.1398) lr 1.0926e-04 eta 0:00:52
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.32s/it] 20%|██        | 2/10 [00:01<00:05,  1.59it/s] 30%|███       | 3/10 [00:01<00:02,  2.48it/s] 40%|████      | 4/10 [00:01<00:01,  3.36it/s] 50%|█████     | 5/10 [00:01<00:01,  4.18it/s] 60%|██████    | 6/10 [00:02<00:00,  4.90it/s] 70%|███████   | 7/10 [00:02<00:00,  5.50it/s] 80%|████████  | 8/10 [00:02<00:00,  5.91it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.29it/s]100%|██████████| 10/10 [00:02<00:00,  6.97it/s]100%|██████████| 10/10 [00:02<00:00,  3.78it/s]=> result
* total: 975
* correct: 865
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 88.1%

epoch [30/30] batch [20/204] time 0.250 (0.292) data 0.000 (0.036) loss 0.6011 (1.3347) lr 2.7391e-05 eta 0:00:53
epoch [30/30] batch [40/204] time 0.245 (0.269) data 0.000 (0.018) loss 0.6631 (1.2383) lr 2.7391e-05 eta 0:00:44
epoch [30/30] batch [60/204] time 0.247 (0.262) data 0.000 (0.012) loss 2.4844 (1.1877) lr 2.7391e-05 eta 0:00:37
epoch [30/30] batch [80/204] time 0.247 (0.258) data 0.000 (0.009) loss 2.8984 (1.1373) lr 2.7391e-05 eta 0:00:31
epoch [30/30] batch [100/204] time 0.245 (0.255) data 0.000 (0.007) loss 0.0807 (1.1296) lr 2.7391e-05 eta 0:00:26
epoch [30/30] batch [120/204] time 0.248 (0.255) data 0.000 (0.006) loss 1.5996 (1.1785) lr 2.7391e-05 eta 0:00:21
epoch [30/30] batch [140/204] time 0.247 (0.254) data 0.000 (0.005) loss 2.0488 (1.1557) lr 2.7391e-05 eta 0:00:16
epoch [30/30] batch [160/204] time 0.250 (0.253) data 0.000 (0.005) loss 3.8203 (1.1871) lr 2.7391e-05 eta 0:00:11
epoch [30/30] batch [180/204] time 0.243 (0.252) data 0.000 (0.004) loss 0.2153 (1.1961) lr 2.7391e-05 eta 0:00:06
epoch [30/30] batch [200/204] time 0.244 (0.251) data 0.000 (0.004) loss 0.1956 (1.1645) lr 2.7391e-05 eta 0:00:01
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.34s/it] 20%|██        | 2/10 [00:01<00:05,  1.58it/s] 30%|███       | 3/10 [00:01<00:02,  2.45it/s] 40%|████      | 4/10 [00:01<00:01,  3.33it/s] 50%|█████     | 5/10 [00:01<00:01,  4.15it/s] 60%|██████    | 6/10 [00:02<00:00,  4.88it/s] 70%|███████   | 7/10 [00:02<00:00,  5.49it/s] 80%|████████  | 8/10 [00:02<00:00,  5.97it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.36it/s]100%|██████████| 10/10 [00:02<00:00,  7.04it/s]100%|██████████| 10/10 [00:02<00:00,  3.78it/s]
=> result
* total: 975
* correct: 865
* accuracy: 88.7%
* error: 11.3%
* macro_f1: 88.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 23)
Evaluate on the *test* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:01<00:30,  1.59s/it] 10%|█         | 2/20 [00:02<00:16,  1.11it/s] 15%|█▌        | 3/20 [00:02<00:09,  1.75it/s] 20%|██        | 4/20 [00:02<00:06,  2.51it/s] 25%|██▌       | 5/20 [00:02<00:04,  3.29it/s] 30%|███       | 6/20 [00:02<00:03,  4.05it/s] 35%|███▌      | 7/20 [00:02<00:02,  4.76it/s] 40%|████      | 8/20 [00:02<00:02,  5.36it/s] 45%|████▌     | 9/20 [00:03<00:01,  5.87it/s] 50%|█████     | 10/20 [00:03<00:01,  6.26it/s] 55%|█████▌    | 11/20 [00:03<00:01,  6.56it/s] 60%|██████    | 12/20 [00:03<00:01,  6.80it/s] 65%|██████▌   | 13/20 [00:03<00:01,  6.97it/s] 70%|███████   | 14/20 [00:03<00:00,  7.09it/s] 75%|███████▌  | 15/20 [00:03<00:00,  7.18it/s] 80%|████████  | 16/20 [00:03<00:00,  7.24it/s] 85%|████████▌ | 17/20 [00:04<00:00,  7.28it/s] 90%|█████████ | 18/20 [00:04<00:00,  7.31it/s] 95%|█████████▌| 19/20 [00:04<00:00,  7.33it/s]100%|██████████| 20/20 [00:04<00:00,  4.41it/s]
=> result
* total: 1,934
* correct: 1,599
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 81.8%
Elapsed: 0:27:16
+ sh scripts/rpo_prime/base2new_test_sdl.sh ucf101 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
800 923 1849
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  50
# train_x  800
# val      923
# test     1,849
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 23)
Evaluate on the *test* set
  0%|          | 0/19 [00:00<?, ?it/s]  5%|▌         | 1/19 [00:04<01:12,  4.02s/it] 11%|█         | 2/19 [00:04<00:29,  1.74s/it] 16%|█▌        | 3/19 [00:04<00:16,  1.00s/it] 21%|██        | 4/19 [00:04<00:09,  1.51it/s] 26%|██▋       | 5/19 [00:04<00:06,  2.12it/s] 32%|███▏      | 6/19 [00:04<00:04,  2.80it/s] 37%|███▋      | 7/19 [00:04<00:03,  3.52it/s] 42%|████▏     | 8/19 [00:04<00:02,  4.22it/s] 47%|████▋     | 9/19 [00:05<00:02,  4.86it/s] 53%|█████▎    | 10/19 [00:05<00:01,  5.44it/s] 58%|█████▊    | 11/19 [00:05<00:01,  5.92it/s] 63%|██████▎   | 12/19 [00:05<00:01,  6.29it/s] 68%|██████▊   | 13/19 [00:05<00:00,  6.57it/s] 74%|███████▎  | 14/19 [00:05<00:00,  6.80it/s] 79%|███████▉  | 15/19 [00:05<00:00,  6.96it/s] 84%|████████▍ | 16/19 [00:06<00:00,  7.08it/s] 89%|████████▉ | 17/19 [00:06<00:00,  7.16it/s] 95%|█████████▍| 18/19 [00:06<00:00,  7.25it/s]100%|██████████| 19/19 [00:06<00:00,  2.93it/s]
=> result
* total: 1,849
* correct: 1,416
* accuracy: 76.6%
* error: 23.4%
* macro_f1: 72.7%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh ucf101 2 0 main_tmp1_0.1sdl 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
816 975 1934
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  51
# train_x  816
# val      975
# test     1,934
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/204] time 0.253 (0.369) data 0.000 (0.052) loss 0.8970 (2.3650) lr 1.0000e-02 eta 0:37:30
epoch [1/30] batch [40/204] time 0.246 (0.309) data 0.000 (0.026) loss 1.9307 (2.5889) lr 1.0000e-02 eta 0:31:16
epoch [1/30] batch [60/204] time 0.248 (0.290) data 0.000 (0.018) loss 2.8691 (2.6707) lr 1.0000e-02 eta 0:29:18
epoch [1/30] batch [80/204] time 0.249 (0.280) data 0.000 (0.013) loss 1.4502 (2.4958) lr 1.0000e-02 eta 0:28:10
epoch [1/30] batch [100/204] time 0.246 (0.274) data 0.000 (0.011) loss 2.5078 (2.4513) lr 1.0000e-02 eta 0:27:26
epoch [1/30] batch [120/204] time 0.254 (0.270) data 0.000 (0.009) loss 3.4648 (2.3992) lr 1.0000e-02 eta 0:27:01
epoch [1/30] batch [140/204] time 0.250 (0.267) data 0.000 (0.008) loss 2.4043 (2.3567) lr 1.0000e-02 eta 0:26:38
epoch [1/30] batch [160/204] time 0.243 (0.265) data 0.000 (0.007) loss 1.4863 (2.4337) lr 1.0000e-02 eta 0:26:19
epoch [1/30] batch [180/204] time 0.244 (0.263) data 0.000 (0.006) loss 3.0449 (2.3737) lr 1.0000e-02 eta 0:26:02
epoch [1/30] batch [200/204] time 0.246 (0.261) data 0.000 (0.005) loss 1.7773 (2.3505) lr 1.0000e-02 eta 0:25:46
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:13,  1.49s/it] 20%|██        | 2/10 [00:01<00:05,  1.42it/s] 30%|███       | 3/10 [00:01<00:03,  2.25it/s] 40%|████      | 4/10 [00:01<00:01,  3.11it/s] 50%|█████     | 5/10 [00:02<00:01,  3.94it/s] 60%|██████    | 6/10 [00:02<00:00,  4.70it/s] 70%|███████   | 7/10 [00:02<00:00,  5.36it/s] 80%|████████  | 8/10 [00:02<00:00,  5.89it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.30it/s]100%|██████████| 10/10 [00:02<00:00,  7.03it/s]100%|██████████| 10/10 [00:02<00:00,  3.57it/s]=> result
* total: 975
* correct: 746
* accuracy: 76.5%
* error: 23.5%
* macro_f1: 74.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/204] time 0.257 (0.287) data 0.000 (0.034) loss 0.8418 (2.9755) lr 9.9726e-03 eta 0:28:11
epoch [2/30] batch [40/204] time 0.247 (0.271) data 0.000 (0.017) loss 2.0957 (2.4187) lr 9.9726e-03 eta 0:26:30
epoch [2/30] batch [60/204] time 0.247 (0.264) data 0.000 (0.011) loss 1.1514 (2.5116) lr 9.9726e-03 eta 0:25:44
epoch [2/30] batch [80/204] time 0.249 (0.260) data 0.000 (0.009) loss 3.2812 (2.4091) lr 9.9726e-03 eta 0:25:19
epoch [2/30] batch [100/204] time 0.249 (0.259) data 0.000 (0.007) loss 1.7422 (2.3295) lr 9.9726e-03 eta 0:25:07
epoch [2/30] batch [120/204] time 0.250 (0.258) data 0.000 (0.006) loss 1.3105 (2.3090) lr 9.9726e-03 eta 0:24:53
epoch [2/30] batch [140/204] time 0.248 (0.256) data 0.000 (0.005) loss 0.9844 (2.3074) lr 9.9726e-03 eta 0:24:40
epoch [2/30] batch [160/204] time 0.250 (0.255) data 0.000 (0.004) loss 1.0605 (2.2644) lr 9.9726e-03 eta 0:24:30
epoch [2/30] batch [180/204] time 0.242 (0.254) data 0.000 (0.004) loss 0.8315 (2.2627) lr 9.9726e-03 eta 0:24:19
epoch [2/30] batch [200/204] time 0.242 (0.253) data 0.000 (0.004) loss 1.2891 (2.2483) lr 9.9726e-03 eta 0:24:06
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.34s/it] 20%|██        | 2/10 [00:01<00:05,  1.56it/s] 30%|███       | 3/10 [00:01<00:02,  2.43it/s] 40%|████      | 4/10 [00:01<00:01,  3.31it/s] 50%|█████     | 5/10 [00:01<00:01,  4.13it/s] 60%|██████    | 6/10 [00:02<00:00,  4.86it/s] 70%|███████   | 7/10 [00:02<00:00,  5.44it/s] 80%|████████  | 8/10 [00:02<00:00,  5.93it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.32it/s]100%|██████████| 10/10 [00:02<00:00,  7.00it/s]100%|██████████| 10/10 [00:02<00:00,  3.74it/s]=> result
* total: 975
* correct: 772
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 77.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/204] time 0.251 (0.285) data 0.000 (0.033) loss 4.3359 (1.7336) lr 9.8907e-03 eta 0:26:59
epoch [3/30] batch [40/204] time 0.247 (0.268) data 0.000 (0.017) loss 1.2158 (1.7313) lr 9.8907e-03 eta 0:25:21
epoch [3/30] batch [60/204] time 0.250 (0.262) data 0.000 (0.011) loss 4.5586 (1.7899) lr 9.8907e-03 eta 0:24:40
epoch [3/30] batch [80/204] time 0.251 (0.259) data 0.000 (0.008) loss 0.7441 (1.8512) lr 9.8907e-03 eta 0:24:18
epoch [3/30] batch [100/204] time 0.252 (0.258) data 0.000 (0.007) loss 0.8496 (1.9525) lr 9.8907e-03 eta 0:24:06
epoch [3/30] batch [120/204] time 0.248 (0.256) data 0.000 (0.006) loss 2.3926 (2.0013) lr 9.8907e-03 eta 0:23:53
epoch [3/30] batch [140/204] time 0.254 (0.255) data 0.000 (0.005) loss 0.5176 (2.0328) lr 9.8907e-03 eta 0:23:43
epoch [3/30] batch [160/204] time 0.247 (0.255) data 0.000 (0.004) loss 3.4004 (2.0643) lr 9.8907e-03 eta 0:23:34
epoch [3/30] batch [180/204] time 0.245 (0.254) data 0.000 (0.004) loss 3.3047 (2.0721) lr 9.8907e-03 eta 0:23:23
epoch [3/30] batch [200/204] time 0.244 (0.253) data 0.000 (0.004) loss 2.0371 (2.0756) lr 9.8907e-03 eta 0:23:14
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:13,  1.51s/it] 20%|██        | 2/10 [00:01<00:05,  1.43it/s] 30%|███       | 3/10 [00:01<00:03,  2.27it/s] 40%|████      | 4/10 [00:01<00:01,  3.13it/s] 50%|█████     | 5/10 [00:02<00:01,  3.96it/s] 60%|██████    | 6/10 [00:02<00:00,  4.71it/s] 70%|███████   | 7/10 [00:02<00:00,  5.37it/s] 80%|████████  | 8/10 [00:02<00:00,  5.90it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.32it/s]100%|██████████| 10/10 [00:02<00:00,  7.03it/s]100%|██████████| 10/10 [00:02<00:00,  3.58it/s]=> result
* total: 975
* correct: 775
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 77.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/204] time 0.247 (0.287) data 0.000 (0.034) loss 3.0586 (2.2520) lr 9.7553e-03 eta 0:26:15
epoch [4/30] batch [40/204] time 0.249 (0.268) data 0.000 (0.017) loss 3.0645 (2.0468) lr 9.7553e-03 eta 0:24:27
epoch [4/30] batch [60/204] time 0.250 (0.262) data 0.000 (0.011) loss 2.1348 (2.0120) lr 9.7553e-03 eta 0:23:48
epoch [4/30] batch [80/204] time 0.248 (0.259) data 0.000 (0.009) loss 2.7324 (2.0214) lr 9.7553e-03 eta 0:23:24
epoch [4/30] batch [100/204] time 0.246 (0.258) data 0.000 (0.007) loss 1.3174 (1.9446) lr 9.7553e-03 eta 0:23:12
epoch [4/30] batch [120/204] time 0.249 (0.256) data 0.000 (0.006) loss 0.1985 (1.8915) lr 9.7553e-03 eta 0:22:59
epoch [4/30] batch [140/204] time 0.257 (0.255) data 0.000 (0.005) loss 4.3945 (1.8852) lr 9.7553e-03 eta 0:22:48
epoch [4/30] batch [160/204] time 0.251 (0.254) data 0.001 (0.004) loss 1.5850 (1.9007) lr 9.7553e-03 eta 0:22:40
epoch [4/30] batch [180/204] time 0.244 (0.254) data 0.000 (0.004) loss 2.7148 (1.8601) lr 9.7553e-03 eta 0:22:32
epoch [4/30] batch [200/204] time 0.242 (0.253) data 0.000 (0.004) loss 4.2305 (1.8773) lr 9.7553e-03 eta 0:22:21
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.40s/it] 20%|██        | 2/10 [00:01<00:05,  1.52it/s] 30%|███       | 3/10 [00:01<00:02,  2.39it/s] 40%|████      | 4/10 [00:01<00:01,  3.25it/s] 50%|█████     | 5/10 [00:01<00:01,  4.07it/s] 60%|██████    | 6/10 [00:02<00:00,  4.80it/s] 70%|███████   | 7/10 [00:02<00:00,  5.42it/s] 80%|████████  | 8/10 [00:02<00:00,  5.91it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.30it/s]100%|██████████| 10/10 [00:02<00:00,  6.97it/s]100%|██████████| 10/10 [00:02<00:00,  3.67it/s]=> result
* total: 975
* correct: 786
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 78.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/204] time 0.251 (0.289) data 0.000 (0.034) loss 2.1855 (2.6116) lr 9.5677e-03 eta 0:25:29
epoch [5/30] batch [40/204] time 0.254 (0.273) data 0.000 (0.017) loss 1.0889 (2.3072) lr 9.5677e-03 eta 0:23:55
epoch [5/30] batch [60/204] time 0.248 (0.265) data 0.000 (0.011) loss 0.3079 (2.1711) lr 9.5677e-03 eta 0:23:09
epoch [5/30] batch [80/204] time 0.248 (0.262) data 0.000 (0.009) loss 3.0625 (2.1230) lr 9.5677e-03 eta 0:22:48
epoch [5/30] batch [100/204] time 0.250 (0.260) data 0.000 (0.007) loss 1.4863 (2.1012) lr 9.5677e-03 eta 0:22:34
epoch [5/30] batch [120/204] time 0.250 (0.259) data 0.000 (0.006) loss 1.3379 (2.1037) lr 9.5677e-03 eta 0:22:20
epoch [5/30] batch [140/204] time 0.255 (0.258) data 0.000 (0.005) loss 0.3503 (2.0824) lr 9.5677e-03 eta 0:22:10
epoch [5/30] batch [160/204] time 0.252 (0.257) data 0.000 (0.004) loss 2.0801 (2.0532) lr 9.5677e-03 eta 0:22:01
epoch [5/30] batch [180/204] time 0.243 (0.256) data 0.000 (0.004) loss 0.9272 (1.9846) lr 9.5677e-03 eta 0:21:52
epoch [5/30] batch [200/204] time 0.243 (0.255) data 0.000 (0.004) loss 3.3047 (1.9905) lr 9.5677e-03 eta 0:21:41
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.37s/it] 20%|██        | 2/10 [00:01<00:05,  1.55it/s] 30%|███       | 3/10 [00:01<00:02,  2.43it/s] 40%|████      | 4/10 [00:01<00:01,  3.30it/s] 50%|█████     | 5/10 [00:01<00:01,  4.12it/s] 60%|██████    | 6/10 [00:02<00:00,  4.84it/s] 70%|███████   | 7/10 [00:02<00:00,  5.46it/s] 80%|████████  | 8/10 [00:02<00:00,  5.95it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.32it/s]100%|██████████| 10/10 [00:02<00:00,  7.00it/s]100%|██████████| 10/10 [00:02<00:00,  3.75it/s]=> result
* total: 975
* correct: 797
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 80.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/204] time 0.247 (0.287) data 0.000 (0.034) loss 0.7578 (2.0177) lr 9.3301e-03 eta 0:24:17
epoch [6/30] batch [40/204] time 0.248 (0.270) data 0.000 (0.017) loss 1.4326 (1.9039) lr 9.3301e-03 eta 0:22:45
epoch [6/30] batch [60/204] time 0.248 (0.263) data 0.000 (0.012) loss 1.2168 (2.0008) lr 9.3301e-03 eta 0:22:04
epoch [6/30] batch [80/204] time 0.249 (0.259) data 0.000 (0.009) loss 1.8398 (1.9442) lr 9.3301e-03 eta 0:21:41
epoch [6/30] batch [100/204] time 0.248 (0.257) data 0.000 (0.007) loss 1.5742 (2.0012) lr 9.3301e-03 eta 0:21:26
epoch [6/30] batch [120/204] time 0.252 (0.256) data 0.000 (0.006) loss 0.2517 (1.9746) lr 9.3301e-03 eta 0:21:15
epoch [6/30] batch [140/204] time 0.250 (0.256) data 0.000 (0.005) loss 1.2988 (1.9255) lr 9.3301e-03 eta 0:21:08
epoch [6/30] batch [160/204] time 0.247 (0.255) data 0.000 (0.005) loss 0.7207 (1.8522) lr 9.3301e-03 eta 0:20:59
epoch [6/30] batch [180/204] time 0.313 (0.255) data 0.000 (0.004) loss 0.7354 (1.8591) lr 9.3301e-03 eta 0:20:53
epoch [6/30] batch [200/204] time 0.244 (0.254) data 0.000 (0.004) loss 1.3389 (1.9027) lr 9.3301e-03 eta 0:20:43
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:13,  1.46s/it] 20%|██        | 2/10 [00:01<00:05,  1.45it/s] 30%|███       | 3/10 [00:01<00:03,  2.30it/s] 40%|████      | 4/10 [00:01<00:01,  3.15it/s] 50%|█████     | 5/10 [00:02<00:01,  3.96it/s] 60%|██████    | 6/10 [00:02<00:00,  4.70it/s] 70%|███████   | 7/10 [00:02<00:00,  5.33it/s] 80%|████████  | 8/10 [00:02<00:00,  5.84it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.24it/s]100%|██████████| 10/10 [00:02<00:00,  6.95it/s]100%|██████████| 10/10 [00:02<00:00,  3.57it/s]=> result
* total: 975
* correct: 797
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 80.4%

epoch [7/30] batch [20/204] time 0.250 (0.289) data 0.000 (0.033) loss 3.5254 (1.8615) lr 9.0451e-03 eta 0:23:28
epoch [7/30] batch [40/204] time 0.250 (0.272) data 0.000 (0.017) loss 4.0586 (1.7163) lr 9.0451e-03 eta 0:21:59
epoch [7/30] batch [60/204] time 0.249 (0.265) data 0.000 (0.011) loss 0.9395 (1.8679) lr 9.0451e-03 eta 0:21:22
epoch [7/30] batch [80/204] time 0.250 (0.262) data 0.000 (0.009) loss 2.6582 (1.8352) lr 9.0451e-03 eta 0:21:01
epoch [7/30] batch [100/204] time 0.257 (0.260) data 0.000 (0.007) loss 2.9023 (1.7803) lr 9.0451e-03 eta 0:20:48
epoch [7/30] batch [120/204] time 0.251 (0.259) data 0.000 (0.006) loss 1.3105 (1.7892) lr 9.0451e-03 eta 0:20:36
epoch [7/30] batch [140/204] time 0.254 (0.258) data 0.000 (0.005) loss 0.4695 (1.7677) lr 9.0451e-03 eta 0:20:27
epoch [7/30] batch [160/204] time 0.254 (0.258) data 0.000 (0.004) loss -0.0020 (1.7461) lr 9.0451e-03 eta 0:20:22
epoch [7/30] batch [180/204] time 0.245 (0.257) data 0.000 (0.004) loss 1.7656 (1.7467) lr 9.0451e-03 eta 0:20:13
epoch [7/30] batch [200/204] time 0.242 (0.256) data 0.000 (0.004) loss 1.3193 (1.7491) lr 9.0451e-03 eta 0:20:02
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.32s/it] 20%|██        | 2/10 [00:01<00:05,  1.53it/s] 30%|███       | 3/10 [00:01<00:02,  2.40it/s] 40%|████      | 4/10 [00:01<00:01,  3.28it/s] 50%|█████     | 5/10 [00:01<00:01,  4.10it/s] 60%|██████    | 6/10 [00:02<00:00,  4.83it/s] 70%|███████   | 7/10 [00:02<00:00,  5.45it/s] 80%|████████  | 8/10 [00:02<00:00,  5.93it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.33it/s]100%|██████████| 10/10 [00:02<00:00,  7.00it/s]100%|██████████| 10/10 [00:02<00:00,  3.73it/s]=> result
* total: 975
* correct: 811
* accuracy: 83.2%
* error: 16.8%
* macro_f1: 82.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/204] time 0.249 (0.288) data 0.000 (0.037) loss 2.8242 (2.1905) lr 8.7157e-03 eta 0:22:24
epoch [8/30] batch [40/204] time 0.247 (0.268) data 0.000 (0.019) loss 0.2756 (2.0144) lr 8.7157e-03 eta 0:20:47
epoch [8/30] batch [60/204] time 0.249 (0.264) data 0.001 (0.013) loss 1.5352 (2.0828) lr 8.7157e-03 eta 0:20:21
epoch [8/30] batch [80/204] time 0.247 (0.260) data 0.000 (0.009) loss 0.1455 (1.9696) lr 8.7157e-03 eta 0:19:59
epoch [8/30] batch [100/204] time 0.251 (0.258) data 0.000 (0.008) loss 0.1635 (1.9271) lr 8.7157e-03 eta 0:19:45
epoch [8/30] batch [120/204] time 0.249 (0.257) data 0.000 (0.006) loss 1.4043 (1.8873) lr 8.7157e-03 eta 0:19:36
epoch [8/30] batch [140/204] time 0.248 (0.256) data 0.000 (0.006) loss 1.0586 (1.8121) lr 8.7157e-03 eta 0:19:26
epoch [8/30] batch [160/204] time 0.252 (0.255) data 0.000 (0.005) loss 3.5215 (1.8327) lr 8.7157e-03 eta 0:19:17
epoch [8/30] batch [180/204] time 0.247 (0.255) data 0.000 (0.004) loss 1.9414 (1.8188) lr 8.7157e-03 eta 0:19:09
epoch [8/30] batch [200/204] time 0.243 (0.254) data 0.000 (0.004) loss 2.7148 (1.7683) lr 8.7157e-03 eta 0:19:00
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.38s/it] 20%|██        | 2/10 [00:01<00:05,  1.54it/s] 30%|███       | 3/10 [00:01<00:02,  2.42it/s] 40%|████      | 4/10 [00:01<00:01,  3.31it/s] 50%|█████     | 5/10 [00:01<00:01,  4.14it/s] 60%|██████    | 6/10 [00:02<00:00,  4.88it/s] 70%|███████   | 7/10 [00:02<00:00,  5.51it/s] 80%|████████  | 8/10 [00:02<00:00,  6.02it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.41it/s]100%|██████████| 10/10 [00:02<00:00,  7.12it/s]100%|██████████| 10/10 [00:02<00:00,  3.75it/s]=> result
* total: 975
* correct: 798
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 80.8%

epoch [9/30] batch [20/204] time 0.249 (0.287) data 0.000 (0.033) loss 3.7363 (1.4495) lr 8.3457e-03 eta 0:21:21
epoch [9/30] batch [40/204] time 0.247 (0.270) data 0.000 (0.017) loss 1.5078 (1.7648) lr 8.3457e-03 eta 0:20:00
epoch [9/30] batch [60/204] time 0.247 (0.263) data 0.000 (0.011) loss 2.9082 (1.6904) lr 8.3457e-03 eta 0:19:23
epoch [9/30] batch [80/204] time 0.250 (0.259) data 0.000 (0.008) loss 1.4658 (1.7686) lr 8.3457e-03 eta 0:19:02
epoch [9/30] batch [100/204] time 0.246 (0.257) data 0.000 (0.007) loss 2.2441 (1.7648) lr 8.3457e-03 eta 0:18:48
epoch [9/30] batch [120/204] time 0.246 (0.256) data 0.000 (0.006) loss 0.7925 (1.7202) lr 8.3457e-03 eta 0:18:36
epoch [9/30] batch [140/204] time 0.247 (0.254) data 0.000 (0.005) loss 0.8774 (1.6158) lr 8.3457e-03 eta 0:18:25
epoch [9/30] batch [160/204] time 0.247 (0.253) data 0.000 (0.004) loss 2.8047 (1.6359) lr 8.3457e-03 eta 0:18:16
epoch [9/30] batch [180/204] time 0.244 (0.253) data 0.000 (0.004) loss 0.8848 (1.6557) lr 8.3457e-03 eta 0:18:08
epoch [9/30] batch [200/204] time 0.242 (0.252) data 0.000 (0.004) loss 0.8276 (1.6319) lr 8.3457e-03 eta 0:17:59
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.35s/it] 20%|██        | 2/10 [00:01<00:05,  1.57it/s] 30%|███       | 3/10 [00:01<00:02,  2.46it/s] 40%|████      | 4/10 [00:01<00:01,  3.33it/s] 50%|█████     | 5/10 [00:01<00:01,  4.15it/s] 60%|██████    | 6/10 [00:02<00:00,  4.87it/s] 70%|███████   | 7/10 [00:02<00:00,  5.47it/s] 80%|████████  | 8/10 [00:02<00:00,  5.97it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.34it/s]100%|██████████| 10/10 [00:02<00:00,  7.01it/s]100%|██████████| 10/10 [00:02<00:00,  3.75it/s]=> result
* total: 975
* correct: 806
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 81.3%

epoch [10/30] batch [20/204] time 0.251 (0.285) data 0.000 (0.034) loss 0.8682 (1.5192) lr 7.9389e-03 eta 0:20:13
epoch [10/30] batch [40/204] time 0.247 (0.266) data 0.000 (0.017) loss 1.1182 (1.4639) lr 7.9389e-03 eta 0:18:49
epoch [10/30] batch [60/204] time 0.251 (0.261) data 0.000 (0.012) loss 2.0371 (1.5584) lr 7.9389e-03 eta 0:18:20
epoch [10/30] batch [80/204] time 0.248 (0.258) data 0.000 (0.009) loss 2.9336 (1.5386) lr 7.9389e-03 eta 0:18:03
epoch [10/30] batch [100/204] time 0.254 (0.256) data 0.000 (0.007) loss 0.1189 (1.4680) lr 7.9389e-03 eta 0:17:52
epoch [10/30] batch [120/204] time 0.252 (0.255) data 0.000 (0.006) loss 2.2266 (1.5114) lr 7.9389e-03 eta 0:17:43
epoch [10/30] batch [140/204] time 0.252 (0.255) data 0.000 (0.005) loss 1.1523 (1.5375) lr 7.9389e-03 eta 0:17:36
epoch [10/30] batch [160/204] time 0.251 (0.255) data 0.000 (0.005) loss 0.6162 (1.5473) lr 7.9389e-03 eta 0:17:31
epoch [10/30] batch [180/204] time 0.244 (0.254) data 0.000 (0.004) loss 2.4570 (1.5177) lr 7.9389e-03 eta 0:17:24
epoch [10/30] batch [200/204] time 0.246 (0.254) data 0.000 (0.004) loss 3.2070 (1.5471) lr 7.9389e-03 eta 0:17:15
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.37s/it] 20%|██        | 2/10 [00:01<00:05,  1.54it/s] 30%|███       | 3/10 [00:01<00:02,  2.41it/s] 40%|████      | 4/10 [00:01<00:01,  3.28it/s] 50%|█████     | 5/10 [00:01<00:01,  4.10it/s] 60%|██████    | 6/10 [00:02<00:00,  4.83it/s] 70%|███████   | 7/10 [00:02<00:00,  5.44it/s] 80%|████████  | 8/10 [00:02<00:00,  5.94it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.32it/s]100%|██████████| 10/10 [00:02<00:00,  7.00it/s]100%|██████████| 10/10 [00:02<00:00,  3.73it/s]=> result
* total: 975
* correct: 830
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 84.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/204] time 0.248 (0.288) data 0.000 (0.033) loss -0.0311 (1.5316) lr 7.5000e-03 eta 0:19:30
epoch [11/30] batch [40/204] time 0.252 (0.269) data 0.000 (0.017) loss 3.0508 (1.5437) lr 7.5000e-03 eta 0:18:06
epoch [11/30] batch [60/204] time 0.246 (0.262) data 0.000 (0.011) loss 1.2520 (1.6347) lr 7.5000e-03 eta 0:17:33
epoch [11/30] batch [80/204] time 0.247 (0.260) data 0.000 (0.009) loss 3.1191 (1.6956) lr 7.5000e-03 eta 0:17:18
epoch [11/30] batch [100/204] time 0.245 (0.258) data 0.000 (0.007) loss 2.8262 (1.6216) lr 7.5000e-03 eta 0:17:05
epoch [11/30] batch [120/204] time 0.247 (0.256) data 0.001 (0.006) loss 2.2012 (1.7140) lr 7.5000e-03 eta 0:16:53
epoch [11/30] batch [140/204] time 0.248 (0.255) data 0.000 (0.005) loss 3.5977 (1.7068) lr 7.5000e-03 eta 0:16:44
epoch [11/30] batch [160/204] time 0.248 (0.255) data 0.000 (0.004) loss -0.0242 (1.6525) lr 7.5000e-03 eta 0:16:37
epoch [11/30] batch [180/204] time 0.243 (0.254) data 0.000 (0.004) loss 1.8936 (1.6618) lr 7.5000e-03 eta 0:16:28
epoch [11/30] batch [200/204] time 0.243 (0.253) data 0.000 (0.004) loss 0.4556 (1.6296) lr 7.5000e-03 eta 0:16:19
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.41s/it] 20%|██        | 2/10 [00:01<00:05,  1.51it/s] 30%|███       | 3/10 [00:01<00:02,  2.37it/s] 40%|████      | 4/10 [00:01<00:01,  3.25it/s] 50%|█████     | 5/10 [00:01<00:01,  4.08it/s] 60%|██████    | 6/10 [00:02<00:00,  4.83it/s] 70%|███████   | 7/10 [00:02<00:00,  5.46it/s] 80%|████████  | 8/10 [00:02<00:00,  5.97it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.36it/s]100%|██████████| 10/10 [00:02<00:00,  7.07it/s]100%|██████████| 10/10 [00:02<00:00,  3.69it/s]=> result
* total: 975
* correct: 822
* accuracy: 84.3%
* error: 15.7%
* macro_f1: 83.2%

epoch [12/30] batch [20/204] time 0.249 (0.293) data 0.000 (0.037) loss 1.1680 (1.7251) lr 7.0337e-03 eta 0:18:51
epoch [12/30] batch [40/204] time 0.249 (0.272) data 0.000 (0.019) loss 1.3818 (1.5821) lr 7.0337e-03 eta 0:17:22
epoch [12/30] batch [60/204] time 0.253 (0.264) data 0.000 (0.012) loss 0.5869 (1.5992) lr 7.0337e-03 eta 0:16:48
epoch [12/30] batch [80/204] time 0.250 (0.262) data 0.000 (0.009) loss 3.4609 (1.4860) lr 7.0337e-03 eta 0:16:33
epoch [12/30] batch [100/204] time 0.252 (0.259) data 0.000 (0.008) loss 1.7686 (1.5233) lr 7.0337e-03 eta 0:16:19
epoch [12/30] batch [120/204] time 0.256 (0.258) data 0.000 (0.006) loss 3.2148 (1.5626) lr 7.0337e-03 eta 0:16:09
epoch [12/30] batch [140/204] time 0.247 (0.257) data 0.000 (0.005) loss 0.0843 (1.5781) lr 7.0337e-03 eta 0:16:00
epoch [12/30] batch [160/204] time 0.262 (0.256) data 0.000 (0.005) loss 4.2461 (1.5724) lr 7.0337e-03 eta 0:15:51
epoch [12/30] batch [180/204] time 0.244 (0.255) data 0.000 (0.004) loss 1.0918 (1.5637) lr 7.0337e-03 eta 0:15:43
epoch [12/30] batch [200/204] time 0.244 (0.254) data 0.000 (0.004) loss 1.9092 (1.5680) lr 7.0337e-03 eta 0:15:34
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.39s/it] 20%|██        | 2/10 [00:01<00:05,  1.49it/s] 30%|███       | 3/10 [00:01<00:02,  2.34it/s] 40%|████      | 4/10 [00:01<00:01,  3.19it/s] 50%|█████     | 5/10 [00:01<00:01,  4.01it/s] 60%|██████    | 6/10 [00:02<00:00,  4.75it/s] 70%|███████   | 7/10 [00:02<00:00,  5.36it/s] 80%|████████  | 8/10 [00:02<00:00,  5.87it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.12it/s]100%|██████████| 10/10 [00:02<00:00,  6.82it/s]100%|██████████| 10/10 [00:02<00:00,  3.62it/s]=> result
* total: 975
* correct: 823
* accuracy: 84.4%
* error: 15.6%
* macro_f1: 83.5%

epoch [13/30] batch [20/204] time 0.251 (0.293) data 0.000 (0.033) loss 0.2449 (1.0534) lr 6.5451e-03 eta 0:17:51
epoch [13/30] batch [40/204] time 0.248 (0.272) data 0.000 (0.017) loss 0.2607 (1.2902) lr 6.5451e-03 eta 0:16:26
epoch [13/30] batch [60/204] time 0.249 (0.266) data 0.000 (0.011) loss 3.7598 (1.2531) lr 6.5451e-03 eta 0:15:59
epoch [13/30] batch [80/204] time 0.249 (0.262) data 0.000 (0.009) loss 1.7061 (1.2787) lr 6.5451e-03 eta 0:15:40
epoch [13/30] batch [100/204] time 0.255 (0.260) data 0.000 (0.007) loss 1.9219 (1.3433) lr 6.5451e-03 eta 0:15:28
epoch [13/30] batch [120/204] time 0.248 (0.258) data 0.000 (0.006) loss 1.8232 (1.3992) lr 6.5451e-03 eta 0:15:16
epoch [13/30] batch [140/204] time 0.249 (0.257) data 0.000 (0.005) loss 3.1074 (1.4825) lr 6.5451e-03 eta 0:15:07
epoch [13/30] batch [160/204] time 0.253 (0.256) data 0.000 (0.004) loss 1.4639 (1.4797) lr 6.5451e-03 eta 0:14:59
epoch [13/30] batch [180/204] time 0.246 (0.255) data 0.000 (0.004) loss 1.5615 (1.5059) lr 6.5451e-03 eta 0:14:51
epoch [13/30] batch [200/204] time 0.244 (0.255) data 0.000 (0.004) loss 2.7031 (1.5438) lr 6.5451e-03 eta 0:14:44
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.39s/it] 20%|██        | 2/10 [00:01<00:05,  1.50it/s] 30%|███       | 3/10 [00:01<00:02,  2.36it/s] 40%|████      | 4/10 [00:01<00:01,  3.24it/s] 50%|█████     | 5/10 [00:01<00:01,  4.07it/s] 60%|██████    | 6/10 [00:02<00:00,  4.83it/s] 70%|███████   | 7/10 [00:02<00:00,  5.45it/s] 80%|████████  | 8/10 [00:02<00:00,  5.97it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.37it/s]100%|██████████| 10/10 [00:02<00:00,  7.09it/s]100%|██████████| 10/10 [00:02<00:00,  3.70it/s]=> result
* total: 975
* correct: 825
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 83.7%

epoch [14/30] batch [20/204] time 0.251 (0.287) data 0.000 (0.034) loss 0.6436 (1.0581) lr 6.0396e-03 eta 0:16:28
epoch [14/30] batch [40/204] time 0.252 (0.268) data 0.000 (0.017) loss 0.2629 (1.3486) lr 6.0396e-03 eta 0:15:17
epoch [14/30] batch [60/204] time 0.247 (0.261) data 0.000 (0.012) loss 1.6494 (1.3492) lr 6.0396e-03 eta 0:14:50
epoch [14/30] batch [80/204] time 0.249 (0.258) data 0.000 (0.009) loss 5.7812 (1.4112) lr 6.0396e-03 eta 0:14:34
epoch [14/30] batch [100/204] time 0.249 (0.257) data 0.000 (0.007) loss 1.0146 (1.6079) lr 6.0396e-03 eta 0:14:26
epoch [14/30] batch [120/204] time 0.249 (0.256) data 0.000 (0.006) loss 0.0507 (1.5392) lr 6.0396e-03 eta 0:14:17
epoch [14/30] batch [140/204] time 0.244 (0.255) data 0.000 (0.005) loss 0.2925 (1.5721) lr 6.0396e-03 eta 0:14:08
epoch [14/30] batch [160/204] time 0.247 (0.254) data 0.000 (0.004) loss 3.8672 (1.5437) lr 6.0396e-03 eta 0:13:59
epoch [14/30] batch [180/204] time 0.240 (0.253) data 0.000 (0.004) loss 2.2520 (1.5381) lr 6.0396e-03 eta 0:13:50
epoch [14/30] batch [200/204] time 0.241 (0.252) data 0.000 (0.004) loss 0.5239 (1.5566) lr 6.0396e-03 eta 0:13:43
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.34s/it] 20%|██        | 2/10 [00:01<00:05,  1.58it/s] 30%|███       | 3/10 [00:01<00:02,  2.46it/s] 40%|████      | 4/10 [00:01<00:01,  3.35it/s] 50%|█████     | 5/10 [00:01<00:01,  4.09it/s] 60%|██████    | 6/10 [00:02<00:00,  4.83it/s] 70%|███████   | 7/10 [00:02<00:00,  5.45it/s] 80%|████████  | 8/10 [00:02<00:00,  5.95it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.35it/s]100%|██████████| 10/10 [00:02<00:00,  7.04it/s]100%|██████████| 10/10 [00:02<00:00,  3.77it/s]=> result
* total: 975
* correct: 837
* accuracy: 85.8%
* error: 14.2%
* macro_f1: 84.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/204] time 0.253 (0.289) data 0.000 (0.035) loss 2.0293 (1.3283) lr 5.5226e-03 eta 0:15:37
epoch [15/30] batch [40/204] time 0.248 (0.271) data 0.000 (0.017) loss 0.0092 (1.5032) lr 5.5226e-03 eta 0:14:33
epoch [15/30] batch [60/204] time 0.252 (0.264) data 0.000 (0.012) loss 1.0791 (1.3721) lr 5.5226e-03 eta 0:14:04
epoch [15/30] batch [80/204] time 0.251 (0.260) data 0.000 (0.009) loss 2.0508 (1.3575) lr 5.5226e-03 eta 0:13:49
epoch [15/30] batch [100/204] time 0.248 (0.260) data 0.000 (0.007) loss 2.4941 (1.3829) lr 5.5226e-03 eta 0:13:41
epoch [15/30] batch [120/204] time 0.252 (0.258) data 0.000 (0.006) loss 0.3264 (1.3622) lr 5.5226e-03 eta 0:13:30
epoch [15/30] batch [140/204] time 0.245 (0.257) data 0.000 (0.005) loss 0.0710 (1.3043) lr 5.5226e-03 eta 0:13:21
epoch [15/30] batch [160/204] time 0.256 (0.256) data 0.000 (0.005) loss 2.4336 (1.3797) lr 5.5226e-03 eta 0:13:14
epoch [15/30] batch [180/204] time 0.245 (0.255) data 0.000 (0.004) loss 1.4883 (1.4123) lr 5.5226e-03 eta 0:13:06
epoch [15/30] batch [200/204] time 0.243 (0.254) data 0.000 (0.004) loss 1.2705 (1.4000) lr 5.5226e-03 eta 0:12:57
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:13,  1.46s/it] 20%|██        | 2/10 [00:01<00:05,  1.46it/s] 30%|███       | 3/10 [00:01<00:03,  2.30it/s] 40%|████      | 4/10 [00:01<00:01,  3.09it/s] 50%|█████     | 5/10 [00:02<00:01,  3.91it/s] 60%|██████    | 6/10 [00:02<00:00,  4.66it/s] 70%|███████   | 7/10 [00:02<00:00,  5.31it/s] 80%|████████  | 8/10 [00:02<00:00,  5.85it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.03it/s]100%|██████████| 10/10 [00:02<00:00,  6.76it/s]100%|██████████| 10/10 [00:02<00:00,  3.56it/s]=> result
* total: 975
* correct: 840
* accuracy: 86.2%
* error: 13.8%
* macro_f1: 85.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [16/30] batch [20/204] time 0.261 (0.293) data 0.000 (0.038) loss 0.6572 (1.5015) lr 5.0000e-03 eta 0:14:51
epoch [16/30] batch [40/204] time 0.254 (0.273) data 0.000 (0.019) loss 1.0889 (1.6210) lr 5.0000e-03 eta 0:13:45
epoch [16/30] batch [60/204] time 0.251 (0.267) data 0.000 (0.013) loss 1.9707 (1.6165) lr 5.0000e-03 eta 0:13:20
epoch [16/30] batch [80/204] time 0.248 (0.264) data 0.000 (0.010) loss 0.2822 (1.6137) lr 5.0000e-03 eta 0:13:07
epoch [16/30] batch [100/204] time 0.248 (0.261) data 0.000 (0.008) loss 1.5850 (1.5616) lr 5.0000e-03 eta 0:12:53
epoch [16/30] batch [120/204] time 0.251 (0.259) data 0.000 (0.007) loss 4.5391 (1.6049) lr 5.0000e-03 eta 0:12:41
epoch [16/30] batch [140/204] time 0.250 (0.258) data 0.000 (0.006) loss 2.4531 (1.5646) lr 5.0000e-03 eta 0:12:34
epoch [16/30] batch [160/204] time 0.251 (0.257) data 0.000 (0.005) loss 0.4226 (1.5254) lr 5.0000e-03 eta 0:12:26
epoch [16/30] batch [180/204] time 0.243 (0.256) data 0.000 (0.004) loss 2.3691 (1.5204) lr 5.0000e-03 eta 0:12:18
epoch [16/30] batch [200/204] time 0.242 (0.255) data 0.000 (0.004) loss 0.6875 (1.5022) lr 5.0000e-03 eta 0:12:09
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.36s/it] 20%|██        | 2/10 [00:01<00:05,  1.54it/s] 30%|███       | 3/10 [00:01<00:02,  2.42it/s] 40%|████      | 4/10 [00:01<00:01,  3.31it/s] 50%|█████     | 5/10 [00:01<00:01,  4.14it/s] 60%|██████    | 6/10 [00:02<00:00,  4.89it/s] 70%|███████   | 7/10 [00:02<00:00,  5.52it/s] 80%|████████  | 8/10 [00:02<00:00,  6.03it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.42it/s]100%|██████████| 10/10 [00:02<00:00,  7.13it/s]100%|██████████| 10/10 [00:02<00:00,  3.76it/s]=> result
* total: 975
* correct: 841
* accuracy: 86.3%
* error: 13.7%
* macro_f1: 85.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [17/30] batch [20/204] time 0.256 (0.286) data 0.000 (0.033) loss 0.2930 (1.5487) lr 4.4774e-03 eta 0:13:29
epoch [17/30] batch [40/204] time 0.249 (0.270) data 0.000 (0.017) loss 1.4023 (1.4679) lr 4.4774e-03 eta 0:12:39
epoch [17/30] batch [60/204] time 0.249 (0.263) data 0.000 (0.011) loss 0.4819 (1.3620) lr 4.4774e-03 eta 0:12:14
epoch [17/30] batch [80/204] time 0.249 (0.259) data 0.000 (0.009) loss 0.2126 (1.2940) lr 4.4774e-03 eta 0:12:00
epoch [17/30] batch [100/204] time 0.250 (0.258) data 0.000 (0.007) loss 2.8965 (1.3270) lr 4.4774e-03 eta 0:11:49
epoch [17/30] batch [120/204] time 0.248 (0.256) data 0.000 (0.006) loss 1.4941 (1.3262) lr 4.4774e-03 eta 0:11:41
epoch [17/30] batch [140/204] time 0.246 (0.255) data 0.000 (0.005) loss 4.1875 (1.3412) lr 4.4774e-03 eta 0:11:33
epoch [17/30] batch [160/204] time 0.249 (0.255) data 0.000 (0.004) loss 2.6367 (1.3574) lr 4.4774e-03 eta 0:11:26
epoch [17/30] batch [180/204] time 0.245 (0.254) data 0.000 (0.004) loss 1.1367 (1.3268) lr 4.4774e-03 eta 0:11:20
epoch [17/30] batch [200/204] time 0.243 (0.253) data 0.000 (0.004) loss 0.7690 (1.3710) lr 4.4774e-03 eta 0:11:12
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.33s/it] 20%|██        | 2/10 [00:01<00:05,  1.59it/s] 30%|███       | 3/10 [00:01<00:02,  2.48it/s] 40%|████      | 4/10 [00:01<00:01,  3.38it/s] 50%|█████     | 5/10 [00:01<00:01,  4.21it/s] 60%|██████    | 6/10 [00:02<00:00,  4.96it/s] 70%|███████   | 7/10 [00:02<00:00,  5.57it/s] 80%|████████  | 8/10 [00:02<00:00,  6.08it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.46it/s]100%|██████████| 10/10 [00:02<00:00,  7.16it/s]100%|██████████| 10/10 [00:02<00:00,  3.82it/s]=> result
* total: 975
* correct: 846
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 86.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/204] time 0.247 (0.285) data 0.000 (0.033) loss 2.0254 (1.3316) lr 3.9604e-03 eta 0:12:29
epoch [18/30] batch [40/204] time 0.247 (0.267) data 0.000 (0.017) loss 2.2266 (1.3345) lr 3.9604e-03 eta 0:11:36
epoch [18/30] batch [60/204] time 0.250 (0.260) data 0.000 (0.011) loss 0.1290 (1.2712) lr 3.9604e-03 eta 0:11:15
epoch [18/30] batch [80/204] time 0.245 (0.258) data 0.000 (0.008) loss 0.8994 (1.2237) lr 3.9604e-03 eta 0:11:03
epoch [18/30] batch [100/204] time 0.245 (0.256) data 0.000 (0.007) loss 1.6279 (1.2025) lr 3.9604e-03 eta 0:10:53
epoch [18/30] batch [120/204] time 0.246 (0.255) data 0.000 (0.006) loss 3.6172 (1.3350) lr 3.9604e-03 eta 0:10:44
epoch [18/30] batch [140/204] time 0.245 (0.254) data 0.000 (0.005) loss 0.0083 (1.3099) lr 3.9604e-03 eta 0:10:37
epoch [18/30] batch [160/204] time 0.249 (0.253) data 0.000 (0.004) loss 1.7822 (1.2881) lr 3.9604e-03 eta 0:10:31
epoch [18/30] batch [180/204] time 0.244 (0.253) data 0.000 (0.004) loss 0.6377 (1.2544) lr 3.9604e-03 eta 0:10:24
epoch [18/30] batch [200/204] time 0.244 (0.252) data 0.000 (0.003) loss 4.2148 (1.2876) lr 3.9604e-03 eta 0:10:17
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:13,  1.48s/it] 20%|██        | 2/10 [00:01<00:05,  1.45it/s] 30%|███       | 3/10 [00:01<00:03,  2.29it/s] 40%|████      | 4/10 [00:01<00:01,  3.15it/s] 50%|█████     | 5/10 [00:02<00:01,  3.99it/s] 60%|██████    | 6/10 [00:02<00:00,  4.75it/s] 70%|███████   | 7/10 [00:02<00:00,  5.40it/s] 80%|████████  | 8/10 [00:02<00:00,  5.93it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.34it/s]100%|██████████| 10/10 [00:02<00:00,  7.06it/s]100%|██████████| 10/10 [00:02<00:00,  3.62it/s]=> result
* total: 975
* correct: 847
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/204] time 0.249 (0.287) data 0.000 (0.034) loss 0.1154 (1.1134) lr 3.4549e-03 eta 0:11:37
epoch [19/30] batch [40/204] time 0.247 (0.268) data 0.000 (0.017) loss 1.0371 (1.2650) lr 3.4549e-03 eta 0:10:46
epoch [19/30] batch [60/204] time 0.253 (0.264) data 0.000 (0.012) loss 1.6924 (1.3486) lr 3.4549e-03 eta 0:10:29
epoch [19/30] batch [80/204] time 0.250 (0.260) data 0.000 (0.009) loss 2.2383 (1.3723) lr 3.4549e-03 eta 0:10:16
epoch [19/30] batch [100/204] time 0.249 (0.258) data 0.000 (0.007) loss 0.7334 (1.3237) lr 3.4549e-03 eta 0:10:06
epoch [19/30] batch [120/204] time 0.254 (0.257) data 0.000 (0.006) loss 3.4395 (1.3399) lr 3.4549e-03 eta 0:09:58
epoch [19/30] batch [140/204] time 0.247 (0.256) data 0.000 (0.005) loss 2.7656 (1.2930) lr 3.4549e-03 eta 0:09:50
epoch [19/30] batch [160/204] time 0.248 (0.255) data 0.000 (0.004) loss 1.1094 (1.3200) lr 3.4549e-03 eta 0:09:42
epoch [19/30] batch [180/204] time 0.242 (0.254) data 0.000 (0.004) loss 0.0880 (1.2771) lr 3.4549e-03 eta 0:09:35
epoch [19/30] batch [200/204] time 0.243 (0.253) data 0.000 (0.004) loss 2.1230 (1.2819) lr 3.4549e-03 eta 0:09:28
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.29s/it] 20%|██        | 2/10 [00:01<00:04,  1.61it/s] 30%|███       | 3/10 [00:01<00:02,  2.52it/s] 40%|████      | 4/10 [00:01<00:01,  3.41it/s] 50%|█████     | 5/10 [00:01<00:01,  4.25it/s] 60%|██████    | 6/10 [00:01<00:00,  4.99it/s] 70%|███████   | 7/10 [00:02<00:00,  5.61it/s] 80%|████████  | 8/10 [00:02<00:00,  6.10it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.47it/s]100%|██████████| 10/10 [00:02<00:00,  7.17it/s]100%|██████████| 10/10 [00:02<00:00,  3.87it/s]=> result
* total: 975
* correct: 845
* accuracy: 86.7%
* error: 13.3%
* macro_f1: 86.1%

epoch [20/30] batch [20/204] time 0.251 (0.292) data 0.000 (0.034) loss 0.8325 (0.9587) lr 2.9663e-03 eta 0:10:48
epoch [20/30] batch [40/204] time 0.252 (0.270) data 0.000 (0.017) loss 3.5898 (1.2943) lr 2.9663e-03 eta 0:09:55
epoch [20/30] batch [60/204] time 0.247 (0.263) data 0.000 (0.012) loss 1.0576 (1.2106) lr 2.9663e-03 eta 0:09:34
epoch [20/30] batch [80/204] time 0.249 (0.260) data 0.000 (0.009) loss 2.5391 (1.3203) lr 2.9663e-03 eta 0:09:22
epoch [20/30] batch [100/204] time 0.260 (0.258) data 0.000 (0.007) loss 0.3296 (1.1984) lr 2.9663e-03 eta 0:09:12
epoch [20/30] batch [120/204] time 0.248 (0.257) data 0.000 (0.006) loss 0.2705 (1.2057) lr 2.9663e-03 eta 0:09:04
epoch [20/30] batch [140/204] time 0.253 (0.256) data 0.000 (0.005) loss 1.8652 (1.2084) lr 2.9663e-03 eta 0:08:58
epoch [20/30] batch [160/204] time 0.248 (0.255) data 0.000 (0.005) loss 2.1055 (1.2214) lr 2.9663e-03 eta 0:08:51
epoch [20/30] batch [180/204] time 0.243 (0.254) data 0.000 (0.004) loss 0.2698 (1.2172) lr 2.9663e-03 eta 0:08:45
epoch [20/30] batch [200/204] time 0.243 (0.253) data 0.000 (0.004) loss 2.1426 (1.2392) lr 2.9663e-03 eta 0:08:38
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.40s/it] 20%|██        | 2/10 [00:01<00:05,  1.52it/s] 30%|███       | 3/10 [00:01<00:02,  2.39it/s] 40%|████      | 4/10 [00:01<00:01,  3.27it/s] 50%|█████     | 5/10 [00:01<00:01,  4.11it/s] 60%|██████    | 6/10 [00:02<00:00,  4.85it/s] 70%|███████   | 7/10 [00:02<00:00,  5.49it/s] 80%|████████  | 8/10 [00:02<00:00,  6.01it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.41it/s]100%|██████████| 10/10 [00:02<00:00,  7.12it/s]100%|██████████| 10/10 [00:02<00:00,  3.71it/s]=> result
* total: 975
* correct: 853
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 87.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/204] time 0.249 (0.288) data 0.000 (0.034) loss 0.0842 (1.0678) lr 2.5000e-03 eta 0:09:40
epoch [21/30] batch [40/204] time 0.252 (0.269) data 0.000 (0.017) loss 0.6885 (1.0265) lr 2.5000e-03 eta 0:08:58
epoch [21/30] batch [60/204] time 0.248 (0.263) data 0.000 (0.011) loss 1.9492 (1.1833) lr 2.5000e-03 eta 0:08:41
epoch [21/30] batch [80/204] time 0.252 (0.260) data 0.000 (0.009) loss 0.2087 (1.1434) lr 2.5000e-03 eta 0:08:29
epoch [21/30] batch [100/204] time 0.335 (0.259) data 0.000 (0.007) loss 0.4297 (1.1192) lr 2.5000e-03 eta 0:08:22
epoch [21/30] batch [120/204] time 0.247 (0.257) data 0.000 (0.006) loss 0.7466 (1.1869) lr 2.5000e-03 eta 0:08:13
epoch [21/30] batch [140/204] time 0.249 (0.256) data 0.000 (0.005) loss 0.5337 (1.1722) lr 2.5000e-03 eta 0:08:05
epoch [21/30] batch [160/204] time 0.246 (0.255) data 0.000 (0.004) loss 2.1055 (1.2059) lr 2.5000e-03 eta 0:07:58
epoch [21/30] batch [180/204] time 0.241 (0.253) data 0.000 (0.004) loss 4.5195 (1.2107) lr 2.5000e-03 eta 0:07:51
epoch [21/30] batch [200/204] time 0.240 (0.252) data 0.000 (0.004) loss 0.4858 (1.2304) lr 2.5000e-03 eta 0:07:43
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.40s/it] 20%|██        | 2/10 [00:01<00:05,  1.52it/s] 30%|███       | 3/10 [00:01<00:02,  2.39it/s] 40%|████      | 4/10 [00:01<00:01,  3.27it/s] 50%|█████     | 5/10 [00:01<00:01,  4.11it/s] 60%|██████    | 6/10 [00:02<00:00,  4.86it/s] 70%|███████   | 7/10 [00:02<00:00,  5.49it/s] 80%|████████  | 8/10 [00:02<00:00,  6.00it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.41it/s]100%|██████████| 10/10 [00:02<00:00,  7.12it/s]100%|██████████| 10/10 [00:02<00:00,  3.70it/s]=> result
* total: 975
* correct: 847
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 86.2%

epoch [22/30] batch [20/204] time 0.250 (0.296) data 0.000 (0.041) loss 0.6597 (1.1641) lr 2.0611e-03 eta 0:08:57
epoch [22/30] batch [40/204] time 0.250 (0.273) data 0.000 (0.021) loss 1.0068 (1.2566) lr 2.0611e-03 eta 0:08:09
epoch [22/30] batch [60/204] time 0.251 (0.265) data 0.000 (0.014) loss 1.3027 (1.3585) lr 2.0611e-03 eta 0:07:50
epoch [22/30] batch [80/204] time 0.249 (0.261) data 0.000 (0.011) loss 0.1132 (1.2535) lr 2.0611e-03 eta 0:07:38
epoch [22/30] batch [100/204] time 0.258 (0.259) data 0.000 (0.008) loss 1.7051 (1.2145) lr 2.0611e-03 eta 0:07:29
epoch [22/30] batch [120/204] time 0.247 (0.258) data 0.000 (0.007) loss 1.7129 (1.2615) lr 2.0611e-03 eta 0:07:21
epoch [22/30] batch [140/204] time 0.252 (0.256) data 0.000 (0.006) loss -0.0219 (1.2156) lr 2.0611e-03 eta 0:07:14
epoch [22/30] batch [160/204] time 0.315 (0.256) data 0.000 (0.005) loss 0.5552 (1.2356) lr 2.0611e-03 eta 0:07:08
epoch [22/30] batch [180/204] time 0.246 (0.255) data 0.000 (0.005) loss 0.2090 (1.2663) lr 2.0611e-03 eta 0:07:02
epoch [22/30] batch [200/204] time 0.248 (0.254) data 0.000 (0.004) loss 1.9385 (1.2650) lr 2.0611e-03 eta 0:06:55
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.32s/it] 20%|██        | 2/10 [00:01<00:05,  1.59it/s] 30%|███       | 3/10 [00:01<00:02,  2.48it/s] 40%|████      | 4/10 [00:01<00:01,  3.37it/s] 50%|█████     | 5/10 [00:01<00:01,  4.21it/s] 60%|██████    | 6/10 [00:01<00:00,  4.95it/s] 70%|███████   | 7/10 [00:02<00:00,  5.58it/s] 80%|████████  | 8/10 [00:02<00:00,  6.08it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.47it/s]100%|██████████| 10/10 [00:02<00:00,  7.17it/s]100%|██████████| 10/10 [00:02<00:00,  3.81it/s]=> result
* total: 975
* correct: 857
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 87.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [23/30] batch [20/204] time 0.253 (0.287) data 0.000 (0.033) loss 0.0237 (1.0134) lr 1.6543e-03 eta 0:07:43
epoch [23/30] batch [40/204] time 0.249 (0.269) data 0.000 (0.017) loss 3.0020 (1.0943) lr 1.6543e-03 eta 0:07:08
epoch [23/30] batch [60/204] time 0.247 (0.263) data 0.000 (0.011) loss 1.4902 (1.0713) lr 1.6543e-03 eta 0:06:52
epoch [23/30] batch [80/204] time 0.246 (0.260) data 0.000 (0.009) loss 1.0283 (1.0300) lr 1.6543e-03 eta 0:06:43
epoch [23/30] batch [100/204] time 0.250 (0.257) data 0.000 (0.007) loss 0.2437 (1.0677) lr 1.6543e-03 eta 0:06:34
epoch [23/30] batch [120/204] time 0.247 (0.256) data 0.000 (0.006) loss 0.5684 (1.0540) lr 1.6543e-03 eta 0:06:27
epoch [23/30] batch [140/204] time 0.245 (0.255) data 0.000 (0.005) loss 1.0215 (1.0850) lr 1.6543e-03 eta 0:06:20
epoch [23/30] batch [160/204] time 0.247 (0.254) data 0.000 (0.004) loss 0.6377 (1.0965) lr 1.6543e-03 eta 0:06:13
epoch [23/30] batch [180/204] time 0.243 (0.253) data 0.000 (0.004) loss 6.0664 (1.1666) lr 1.6543e-03 eta 0:06:08
epoch [23/30] batch [200/204] time 0.244 (0.252) data 0.000 (0.004) loss 3.1797 (1.2063) lr 1.6543e-03 eta 0:06:01
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.35s/it] 20%|██        | 2/10 [00:01<00:05,  1.57it/s] 30%|███       | 3/10 [00:01<00:02,  2.47it/s] 40%|████      | 4/10 [00:01<00:01,  3.35it/s] 50%|█████     | 5/10 [00:01<00:01,  4.19it/s] 60%|██████    | 6/10 [00:02<00:00,  4.94it/s] 70%|███████   | 7/10 [00:02<00:00,  5.56it/s] 80%|████████  | 8/10 [00:02<00:00,  6.06it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.45it/s]100%|██████████| 10/10 [00:02<00:00,  7.15it/s]100%|██████████| 10/10 [00:02<00:00,  3.79it/s]=> result
* total: 975
* correct: 859
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 87.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [24/30] batch [20/204] time 0.249 (0.289) data 0.000 (0.036) loss 4.3867 (1.6289) lr 1.2843e-03 eta 0:06:47
epoch [24/30] batch [40/204] time 0.248 (0.269) data 0.000 (0.018) loss 0.3030 (1.4202) lr 1.2843e-03 eta 0:06:13
epoch [24/30] batch [60/204] time 0.258 (0.264) data 0.000 (0.012) loss 2.2930 (1.4544) lr 1.2843e-03 eta 0:06:01
epoch [24/30] batch [80/204] time 0.248 (0.260) data 0.000 (0.009) loss 0.2722 (1.3813) lr 1.2843e-03 eta 0:05:51
epoch [24/30] batch [100/204] time 0.248 (0.258) data 0.000 (0.007) loss 0.3047 (1.2880) lr 1.2843e-03 eta 0:05:42
epoch [24/30] batch [120/204] time 0.253 (0.257) data 0.000 (0.006) loss 0.4346 (1.2328) lr 1.2843e-03 eta 0:05:36
epoch [24/30] batch [140/204] time 0.251 (0.257) data 0.000 (0.005) loss 1.1650 (1.2203) lr 1.2843e-03 eta 0:05:30
epoch [24/30] batch [160/204] time 0.252 (0.256) data 0.000 (0.005) loss 1.4854 (1.2361) lr 1.2843e-03 eta 0:05:24
epoch [24/30] batch [180/204] time 0.246 (0.255) data 0.000 (0.004) loss 0.5713 (1.2585) lr 1.2843e-03 eta 0:05:18
epoch [24/30] batch [200/204] time 0.242 (0.254) data 0.000 (0.004) loss 4.6250 (1.2733) lr 1.2843e-03 eta 0:05:12
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.35s/it] 20%|██        | 2/10 [00:01<00:05,  1.57it/s] 30%|███       | 3/10 [00:01<00:02,  2.46it/s] 40%|████      | 4/10 [00:01<00:01,  3.35it/s] 50%|█████     | 5/10 [00:01<00:01,  4.19it/s] 60%|██████    | 6/10 [00:02<00:00,  4.93it/s] 70%|███████   | 7/10 [00:02<00:00,  5.56it/s] 80%|████████  | 8/10 [00:02<00:00,  6.05it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.44it/s]100%|██████████| 10/10 [00:02<00:00,  7.14it/s]100%|██████████| 10/10 [00:02<00:00,  3.81it/s]=> result
* total: 975
* correct: 857
* accuracy: 87.9%
* error: 12.1%
* macro_f1: 87.3%

epoch [25/30] batch [20/204] time 0.244 (0.284) data 0.000 (0.034) loss 1.1084 (1.1082) lr 9.5492e-04 eta 0:05:41
epoch [25/30] batch [40/204] time 0.245 (0.265) data 0.000 (0.017) loss 0.7075 (1.0056) lr 9.5492e-04 eta 0:05:14
epoch [25/30] batch [60/204] time 0.247 (0.261) data 0.000 (0.011) loss 1.2656 (1.1183) lr 9.5492e-04 eta 0:05:03
epoch [25/30] batch [80/204] time 0.246 (0.258) data 0.000 (0.009) loss 0.0634 (1.2587) lr 9.5492e-04 eta 0:04:54
epoch [25/30] batch [100/204] time 0.244 (0.256) data 0.000 (0.007) loss 0.8154 (1.2368) lr 9.5492e-04 eta 0:04:47
epoch [25/30] batch [120/204] time 0.248 (0.254) data 0.000 (0.006) loss 1.3740 (1.1964) lr 9.5492e-04 eta 0:04:40
epoch [25/30] batch [140/204] time 0.262 (0.254) data 0.000 (0.005) loss 0.4175 (1.1540) lr 9.5492e-04 eta 0:04:34
epoch [25/30] batch [160/204] time 0.252 (0.253) data 0.000 (0.004) loss 1.1738 (1.1096) lr 9.5492e-04 eta 0:04:29
epoch [25/30] batch [180/204] time 0.244 (0.253) data 0.000 (0.004) loss 0.0108 (1.1183) lr 9.5492e-04 eta 0:04:24
epoch [25/30] batch [200/204] time 0.243 (0.252) data 0.000 (0.004) loss 4.0234 (1.1476) lr 9.5492e-04 eta 0:04:18
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.31s/it] 20%|██        | 2/10 [00:01<00:04,  1.62it/s] 30%|███       | 3/10 [00:01<00:02,  2.52it/s] 40%|████      | 4/10 [00:01<00:01,  3.41it/s] 50%|█████     | 5/10 [00:01<00:01,  4.25it/s] 60%|██████    | 6/10 [00:01<00:00,  4.99it/s] 70%|███████   | 7/10 [00:02<00:00,  5.60it/s] 80%|████████  | 8/10 [00:02<00:00,  6.09it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.48it/s]100%|██████████| 10/10 [00:02<00:00,  7.17it/s]100%|██████████| 10/10 [00:02<00:00,  3.85it/s]=> result
* total: 975
* correct: 862
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 87.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [26/30] batch [20/204] time 0.248 (0.285) data 0.000 (0.032) loss 2.4062 (1.1961) lr 6.6987e-04 eta 0:04:44
epoch [26/30] batch [40/204] time 0.251 (0.267) data 0.000 (0.016) loss 0.4551 (1.2516) lr 6.6987e-04 eta 0:04:21
epoch [26/30] batch [60/204] time 0.248 (0.263) data 0.000 (0.011) loss 1.7705 (1.2754) lr 6.6987e-04 eta 0:04:12
epoch [26/30] batch [80/204] time 0.250 (0.259) data 0.000 (0.008) loss 1.9639 (1.2402) lr 6.6987e-04 eta 0:04:03
epoch [26/30] batch [100/204] time 0.250 (0.258) data 0.000 (0.007) loss 0.3191 (1.2319) lr 6.6987e-04 eta 0:03:56
epoch [26/30] batch [120/204] time 0.246 (0.257) data 0.000 (0.006) loss 1.3701 (1.2330) lr 6.6987e-04 eta 0:03:50
epoch [26/30] batch [140/204] time 0.248 (0.255) data 0.000 (0.005) loss 2.6309 (1.1944) lr 6.6987e-04 eta 0:03:44
epoch [26/30] batch [160/204] time 0.246 (0.254) data 0.000 (0.004) loss 0.6021 (1.1732) lr 6.6987e-04 eta 0:03:38
epoch [26/30] batch [180/204] time 0.242 (0.254) data 0.000 (0.004) loss 1.0977 (1.1847) lr 6.6987e-04 eta 0:03:33
epoch [26/30] batch [200/204] time 0.242 (0.253) data 0.000 (0.003) loss 1.3799 (1.2117) lr 6.6987e-04 eta 0:03:27
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.41s/it] 20%|██        | 2/10 [00:01<00:05,  1.52it/s] 30%|███       | 3/10 [00:01<00:02,  2.36it/s] 40%|████      | 4/10 [00:01<00:01,  3.23it/s] 50%|█████     | 5/10 [00:01<00:01,  4.07it/s] 60%|██████    | 6/10 [00:02<00:00,  4.79it/s] 70%|███████   | 7/10 [00:02<00:00,  5.43it/s] 80%|████████  | 8/10 [00:02<00:00,  5.96it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.37it/s]100%|██████████| 10/10 [00:02<00:00,  7.08it/s]100%|██████████| 10/10 [00:02<00:00,  3.71it/s]=> result
* total: 975
* correct: 856
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 87.2%

epoch [27/30] batch [20/204] time 0.247 (0.283) data 0.000 (0.033) loss 0.3325 (1.7031) lr 4.3227e-04 eta 0:03:45
epoch [27/30] batch [40/204] time 0.251 (0.266) data 0.000 (0.017) loss 1.4707 (1.4078) lr 4.3227e-04 eta 0:03:26
epoch [27/30] batch [60/204] time 0.249 (0.261) data 0.000 (0.011) loss 0.0594 (1.2254) lr 4.3227e-04 eta 0:03:17
epoch [27/30] batch [80/204] time 0.248 (0.258) data 0.000 (0.008) loss 0.6436 (1.2238) lr 4.3227e-04 eta 0:03:09
epoch [27/30] batch [100/204] time 0.248 (0.256) data 0.000 (0.007) loss 1.4668 (1.1082) lr 4.3227e-04 eta 0:03:03
epoch [27/30] batch [120/204] time 0.247 (0.255) data 0.000 (0.006) loss 1.5801 (1.0546) lr 4.3227e-04 eta 0:02:57
epoch [27/30] batch [140/204] time 0.249 (0.254) data 0.000 (0.005) loss 0.5132 (1.0912) lr 4.3227e-04 eta 0:02:51
epoch [27/30] batch [160/204] time 0.254 (0.254) data 0.000 (0.004) loss 1.8926 (1.1233) lr 4.3227e-04 eta 0:02:46
epoch [27/30] batch [180/204] time 0.245 (0.253) data 0.000 (0.004) loss 1.0947 (1.1338) lr 4.3227e-04 eta 0:02:40
epoch [27/30] batch [200/204] time 0.244 (0.252) data 0.000 (0.004) loss 3.0449 (1.1294) lr 4.3227e-04 eta 0:02:35
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.34s/it] 20%|██        | 2/10 [00:01<00:05,  1.59it/s] 30%|███       | 3/10 [00:01<00:02,  2.48it/s] 40%|████      | 4/10 [00:01<00:01,  3.37it/s] 50%|█████     | 5/10 [00:01<00:01,  4.21it/s] 60%|██████    | 6/10 [00:02<00:00,  4.96it/s] 70%|███████   | 7/10 [00:02<00:00,  5.58it/s] 80%|████████  | 8/10 [00:02<00:00,  6.08it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.46it/s]100%|██████████| 10/10 [00:02<00:00,  7.17it/s]100%|██████████| 10/10 [00:02<00:00,  3.83it/s]=> result
* total: 975
* correct: 859
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 87.6%

epoch [28/30] batch [20/204] time 0.249 (0.291) data 0.000 (0.034) loss 0.6958 (0.7376) lr 2.4472e-04 eta 0:02:52
epoch [28/30] batch [40/204] time 0.247 (0.270) data 0.000 (0.017) loss 1.0830 (1.0537) lr 2.4472e-04 eta 0:02:34
epoch [28/30] batch [60/204] time 0.247 (0.263) data 0.000 (0.011) loss 1.7480 (1.0791) lr 2.4472e-04 eta 0:02:25
epoch [28/30] batch [80/204] time 0.247 (0.259) data 0.000 (0.009) loss 2.7852 (1.0914) lr 2.4472e-04 eta 0:02:17
epoch [28/30] batch [100/204] time 0.245 (0.257) data 0.000 (0.007) loss 1.3311 (1.0641) lr 2.4472e-04 eta 0:02:11
epoch [28/30] batch [120/204] time 0.245 (0.255) data 0.000 (0.006) loss 1.7158 (1.1131) lr 2.4472e-04 eta 0:02:05
epoch [28/30] batch [140/204] time 0.246 (0.254) data 0.000 (0.005) loss 0.0458 (1.0984) lr 2.4472e-04 eta 0:01:59
epoch [28/30] batch [160/204] time 0.251 (0.253) data 0.000 (0.004) loss 0.2649 (1.0925) lr 2.4472e-04 eta 0:01:54
epoch [28/30] batch [180/204] time 0.308 (0.252) data 0.000 (0.004) loss 0.6250 (1.0754) lr 2.4472e-04 eta 0:01:49
epoch [28/30] batch [200/204] time 0.240 (0.251) data 0.000 (0.004) loss 0.4536 (1.0679) lr 2.4472e-04 eta 0:01:43
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.26s/it] 20%|██        | 2/10 [00:01<00:04,  1.62it/s] 30%|███       | 3/10 [00:01<00:02,  2.52it/s] 40%|████      | 4/10 [00:01<00:01,  3.42it/s] 50%|█████     | 5/10 [00:01<00:01,  4.25it/s] 60%|██████    | 6/10 [00:01<00:00,  5.00it/s] 70%|███████   | 7/10 [00:02<00:00,  5.60it/s] 80%|████████  | 8/10 [00:02<00:00,  6.10it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.48it/s]100%|██████████| 10/10 [00:02<00:00,  7.18it/s]100%|██████████| 10/10 [00:02<00:00,  3.88it/s]=> result
* total: 975
* correct: 858
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 87.5%

epoch [29/30] batch [20/204] time 0.251 (0.286) data 0.000 (0.034) loss 2.1582 (1.2784) lr 1.0926e-04 eta 0:01:51
epoch [29/30] batch [40/204] time 0.247 (0.268) data 0.000 (0.017) loss -0.0153 (1.1318) lr 1.0926e-04 eta 0:01:38
epoch [29/30] batch [60/204] time 0.249 (0.262) data 0.000 (0.012) loss 3.0625 (1.0715) lr 1.0926e-04 eta 0:01:31
epoch [29/30] batch [80/204] time 0.249 (0.260) data 0.000 (0.009) loss 2.1191 (1.1240) lr 1.0926e-04 eta 0:01:25
epoch [29/30] batch [100/204] time 0.252 (0.258) data 0.000 (0.007) loss 1.2578 (1.0711) lr 1.0926e-04 eta 0:01:19
epoch [29/30] batch [120/204] time 0.248 (0.256) data 0.000 (0.006) loss 1.3799 (1.0901) lr 1.0926e-04 eta 0:01:13
epoch [29/30] batch [140/204] time 0.246 (0.255) data 0.000 (0.005) loss 1.0156 (1.0943) lr 1.0926e-04 eta 0:01:08
epoch [29/30] batch [160/204] time 0.249 (0.254) data 0.000 (0.004) loss 1.3291 (1.0862) lr 1.0926e-04 eta 0:01:03
epoch [29/30] batch [180/204] time 0.311 (0.254) data 0.000 (0.004) loss 2.1211 (1.0786) lr 1.0926e-04 eta 0:00:57
epoch [29/30] batch [200/204] time 0.245 (0.253) data 0.000 (0.004) loss 0.1406 (1.0827) lr 1.0926e-04 eta 0:00:52
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.30s/it] 20%|██        | 2/10 [00:01<00:04,  1.62it/s] 30%|███       | 3/10 [00:01<00:02,  2.51it/s] 40%|████      | 4/10 [00:01<00:01,  3.41it/s] 50%|█████     | 5/10 [00:01<00:01,  4.24it/s] 60%|██████    | 6/10 [00:01<00:00,  4.98it/s] 70%|███████   | 7/10 [00:02<00:00,  5.61it/s] 80%|████████  | 8/10 [00:02<00:00,  6.09it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.47it/s]100%|██████████| 10/10 [00:02<00:00,  7.16it/s]100%|██████████| 10/10 [00:02<00:00,  3.86it/s]=> result
* total: 975
* correct: 858
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 87.5%

epoch [30/30] batch [20/204] time 0.249 (0.285) data 0.000 (0.033) loss 0.6147 (1.0092) lr 2.7391e-05 eta 0:00:52
epoch [30/30] batch [40/204] time 0.248 (0.266) data 0.000 (0.017) loss 0.3232 (0.9957) lr 2.7391e-05 eta 0:00:43
epoch [30/30] batch [60/204] time 0.248 (0.261) data 0.000 (0.011) loss 1.3604 (0.9934) lr 2.7391e-05 eta 0:00:37
epoch [30/30] batch [80/204] time 0.249 (0.259) data 0.000 (0.009) loss 1.8730 (1.0253) lr 2.7391e-05 eta 0:00:32
epoch [30/30] batch [100/204] time 0.252 (0.257) data 0.000 (0.007) loss 0.8892 (0.9608) lr 2.7391e-05 eta 0:00:26
epoch [30/30] batch [120/204] time 0.252 (0.256) data 0.000 (0.006) loss 1.9443 (1.0088) lr 2.7391e-05 eta 0:00:21
epoch [30/30] batch [140/204] time 0.247 (0.255) data 0.000 (0.005) loss 0.0407 (1.0610) lr 2.7391e-05 eta 0:00:16
epoch [30/30] batch [160/204] time 0.247 (0.254) data 0.000 (0.004) loss 0.3704 (0.9982) lr 2.7391e-05 eta 0:00:11
epoch [30/30] batch [180/204] time 0.242 (0.253) data 0.000 (0.004) loss 3.0176 (0.9965) lr 2.7391e-05 eta 0:00:06
epoch [30/30] batch [200/204] time 0.242 (0.253) data 0.000 (0.004) loss 0.0889 (1.0095) lr 2.7391e-05 eta 0:00:01
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.29s/it] 20%|██        | 2/10 [00:01<00:04,  1.61it/s] 30%|███       | 3/10 [00:01<00:02,  2.52it/s] 40%|████      | 4/10 [00:01<00:01,  3.41it/s] 50%|█████     | 5/10 [00:01<00:01,  4.25it/s] 60%|██████    | 6/10 [00:01<00:00,  4.98it/s] 70%|███████   | 7/10 [00:02<00:00,  5.60it/s] 80%|████████  | 8/10 [00:02<00:00,  6.11it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.50it/s]100%|██████████| 10/10 [00:02<00:00,  7.20it/s]100%|██████████| 10/10 [00:02<00:00,  3.89it/s]
=> result
* total: 975
* correct: 858
* accuracy: 88.0%
* error: 12.0%
* macro_f1: 87.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:01<00:31,  1.67s/it] 10%|█         | 2/20 [00:01<00:14,  1.22it/s] 15%|█▌        | 3/20 [00:02<00:08,  1.97it/s] 20%|██        | 4/20 [00:02<00:05,  2.78it/s] 25%|██▌       | 5/20 [00:02<00:04,  3.60it/s] 30%|███       | 6/20 [00:02<00:03,  4.38it/s] 35%|███▌      | 7/20 [00:02<00:02,  5.07it/s] 40%|████      | 8/20 [00:02<00:02,  5.66it/s] 45%|████▌     | 9/20 [00:02<00:01,  6.14it/s] 50%|█████     | 10/20 [00:02<00:01,  6.51it/s] 55%|█████▌    | 11/20 [00:03<00:01,  6.80it/s] 60%|██████    | 12/20 [00:03<00:01,  6.99it/s] 65%|██████▌   | 13/20 [00:03<00:00,  7.14it/s] 70%|███████   | 14/20 [00:03<00:00,  7.25it/s] 75%|███████▌  | 15/20 [00:03<00:00,  7.34it/s] 80%|████████  | 16/20 [00:03<00:00,  7.39it/s] 85%|████████▌ | 17/20 [00:03<00:00,  7.43it/s] 90%|█████████ | 18/20 [00:04<00:00,  7.46it/s] 95%|█████████▌| 19/20 [00:04<00:00,  7.49it/s]100%|██████████| 20/20 [00:04<00:00,  4.61it/s]
=> result
* total: 1,934
* correct: 1,641
* accuracy: 84.9%
* error: 15.1%
* macro_f1: 83.8%
Elapsed: 0:27:20
+ sh scripts/rpo_prime/base2new_test_sdl.sh ucf101 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
800 923 1849
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  50
# train_x  800
# val      923
# test     1,849
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/19 [00:00<?, ?it/s]  5%|▌         | 1/19 [00:03<01:05,  3.64s/it] 11%|█         | 2/19 [00:03<00:26,  1.58s/it] 16%|█▌        | 3/19 [00:03<00:14,  1.09it/s] 21%|██        | 4/19 [00:04<00:09,  1.65it/s] 26%|██▋       | 5/19 [00:04<00:06,  2.29it/s] 32%|███▏      | 6/19 [00:04<00:04,  3.01it/s] 37%|███▋      | 7/19 [00:04<00:03,  3.75it/s] 42%|████▏     | 8/19 [00:04<00:02,  4.46it/s] 47%|████▋     | 9/19 [00:04<00:01,  5.12it/s] 53%|█████▎    | 10/19 [00:04<00:01,  5.69it/s] 58%|█████▊    | 11/19 [00:04<00:01,  6.16it/s] 63%|██████▎   | 12/19 [00:05<00:01,  6.53it/s] 68%|██████▊   | 13/19 [00:05<00:00,  6.82it/s] 74%|███████▎  | 14/19 [00:05<00:00,  7.03it/s] 79%|███████▉  | 15/19 [00:05<00:00,  7.19it/s] 84%|████████▍ | 16/19 [00:05<00:00,  7.30it/s] 89%|████████▉ | 17/19 [00:05<00:00,  7.38it/s] 95%|█████████▍| 18/19 [00:05<00:00,  7.42it/s]100%|██████████| 19/19 [00:06<00:00,  3.13it/s]
=> result
* total: 1,849
* correct: 1,426
* accuracy: 77.1%
* error: 22.9%
* macro_f1: 73.8%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh ucf101 3 0 main_tmp1_0.1sdl 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
816 975 1934
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  51
# train_x  816
# val      975
# test     1,934
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/204] time 0.250 (0.371) data 0.000 (0.049) loss 2.0391 (2.7381) lr 1.0000e-02 eta 0:37:41
epoch [1/30] batch [40/204] time 0.247 (0.309) data 0.000 (0.025) loss 3.3984 (3.0176) lr 1.0000e-02 eta 0:31:20
epoch [1/30] batch [60/204] time 0.245 (0.291) data 0.000 (0.016) loss 2.7695 (2.8900) lr 1.0000e-02 eta 0:29:21
epoch [1/30] batch [80/204] time 0.247 (0.280) data 0.000 (0.012) loss 3.2051 (2.8217) lr 1.0000e-02 eta 0:28:08
epoch [1/30] batch [100/204] time 0.246 (0.273) data 0.000 (0.010) loss 4.2578 (2.8299) lr 1.0000e-02 eta 0:27:25
epoch [1/30] batch [120/204] time 0.249 (0.270) data 0.000 (0.008) loss 5.1289 (2.7249) lr 1.0000e-02 eta 0:26:59
epoch [1/30] batch [140/204] time 0.246 (0.267) data 0.000 (0.007) loss 2.2773 (2.6492) lr 1.0000e-02 eta 0:26:35
epoch [1/30] batch [160/204] time 0.246 (0.264) data 0.000 (0.006) loss 1.0732 (2.6134) lr 1.0000e-02 eta 0:26:15
epoch [1/30] batch [180/204] time 0.241 (0.262) data 0.000 (0.006) loss 0.5200 (2.5890) lr 1.0000e-02 eta 0:25:57
epoch [1/30] batch [200/204] time 0.243 (0.260) data 0.000 (0.005) loss 1.6104 (2.5474) lr 1.0000e-02 eta 0:25:41
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:13,  1.46s/it] 20%|██        | 2/10 [00:01<00:05,  1.47it/s] 30%|███       | 3/10 [00:01<00:03,  2.32it/s] 40%|████      | 4/10 [00:01<00:01,  3.19it/s] 50%|█████     | 5/10 [00:01<00:01,  4.03it/s] 60%|██████    | 6/10 [00:02<00:00,  4.78it/s] 70%|███████   | 7/10 [00:02<00:00,  5.43it/s] 80%|████████  | 8/10 [00:02<00:00,  5.96it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.38it/s]100%|██████████| 10/10 [00:02<00:00,  7.10it/s]100%|██████████| 10/10 [00:02<00:00,  3.63it/s]=> result
* total: 975
* correct: 744
* accuracy: 76.3%
* error: 23.7%
* macro_f1: 74.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/204] time 0.250 (0.292) data 0.000 (0.034) loss 0.9146 (2.0271) lr 9.9726e-03 eta 0:28:40
epoch [2/30] batch [40/204] time 0.248 (0.270) data 0.000 (0.017) loss 0.6343 (1.9691) lr 9.9726e-03 eta 0:26:29
epoch [2/30] batch [60/204] time 0.252 (0.263) data 0.000 (0.011) loss 0.6909 (2.1497) lr 9.9726e-03 eta 0:25:42
epoch [2/30] batch [80/204] time 0.250 (0.260) data 0.000 (0.009) loss 2.6797 (2.1769) lr 9.9726e-03 eta 0:25:16
epoch [2/30] batch [100/204] time 0.248 (0.258) data 0.000 (0.007) loss 2.1016 (2.1349) lr 9.9726e-03 eta 0:24:58
epoch [2/30] batch [120/204] time 0.251 (0.256) data 0.000 (0.006) loss 1.9219 (2.1539) lr 9.9726e-03 eta 0:24:45
epoch [2/30] batch [140/204] time 0.247 (0.255) data 0.000 (0.005) loss 1.1240 (2.2159) lr 9.9726e-03 eta 0:24:34
epoch [2/30] batch [160/204] time 0.248 (0.255) data 0.000 (0.004) loss 4.5078 (2.2605) lr 9.9726e-03 eta 0:24:27
epoch [2/30] batch [180/204] time 0.243 (0.254) data 0.000 (0.004) loss 1.2666 (2.2088) lr 9.9726e-03 eta 0:24:16
epoch [2/30] batch [200/204] time 0.241 (0.253) data 0.000 (0.004) loss 0.4973 (2.2499) lr 9.9726e-03 eta 0:24:04
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.30s/it] 20%|██        | 2/10 [00:01<00:04,  1.63it/s] 30%|███       | 3/10 [00:01<00:02,  2.53it/s] 40%|████      | 4/10 [00:01<00:01,  3.43it/s] 50%|█████     | 5/10 [00:01<00:01,  4.28it/s] 60%|██████    | 6/10 [00:01<00:00,  5.01it/s] 70%|███████   | 7/10 [00:02<00:00,  5.62it/s] 80%|████████  | 8/10 [00:02<00:00,  6.12it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.50it/s]100%|██████████| 10/10 [00:02<00:00,  7.20it/s]100%|██████████| 10/10 [00:02<00:00,  3.87it/s]=> result
* total: 975
* correct: 757
* accuracy: 77.6%
* error: 22.4%
* macro_f1: 75.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/204] time 0.247 (0.288) data 0.000 (0.034) loss 5.2852 (2.2273) lr 9.8907e-03 eta 0:27:18
epoch [3/30] batch [40/204] time 0.247 (0.268) data 0.000 (0.017) loss 0.8691 (2.2690) lr 9.8907e-03 eta 0:25:20
epoch [3/30] batch [60/204] time 0.249 (0.261) data 0.000 (0.011) loss 1.5391 (2.2646) lr 9.8907e-03 eta 0:24:36
epoch [3/30] batch [80/204] time 0.246 (0.259) data 0.000 (0.009) loss 2.9551 (2.1969) lr 9.8907e-03 eta 0:24:17
epoch [3/30] batch [100/204] time 0.249 (0.257) data 0.000 (0.007) loss 2.7949 (2.1551) lr 9.8907e-03 eta 0:24:02
epoch [3/30] batch [120/204] time 0.247 (0.255) data 0.000 (0.006) loss 1.8008 (2.2309) lr 9.8907e-03 eta 0:23:48
epoch [3/30] batch [140/204] time 0.248 (0.255) data 0.000 (0.005) loss 0.2615 (2.1796) lr 9.8907e-03 eta 0:23:38
epoch [3/30] batch [160/204] time 0.250 (0.254) data 0.000 (0.004) loss 2.1523 (2.1906) lr 9.8907e-03 eta 0:23:30
epoch [3/30] batch [180/204] time 0.241 (0.254) data 0.000 (0.004) loss 1.3184 (2.1241) lr 9.8907e-03 eta 0:23:22
epoch [3/30] batch [200/204] time 0.244 (0.252) data 0.000 (0.004) loss 0.8623 (2.1037) lr 9.8907e-03 eta 0:23:11
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.36s/it] 20%|██        | 2/10 [00:01<00:05,  1.56it/s] 30%|███       | 3/10 [00:01<00:02,  2.45it/s] 40%|████      | 4/10 [00:01<00:01,  3.34it/s] 50%|█████     | 5/10 [00:01<00:01,  4.18it/s] 60%|██████    | 6/10 [00:02<00:00,  4.92it/s] 70%|███████   | 7/10 [00:02<00:00,  5.55it/s] 80%|████████  | 8/10 [00:02<00:00,  6.06it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.45it/s]100%|██████████| 10/10 [00:02<00:00,  7.16it/s]100%|██████████| 10/10 [00:02<00:00,  3.76it/s]=> result
* total: 975
* correct: 768
* accuracy: 78.8%
* error: 21.2%
* macro_f1: 76.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/204] time 0.245 (0.283) data 0.000 (0.033) loss 1.2207 (2.3515) lr 9.7553e-03 eta 0:25:53
epoch [4/30] batch [40/204] time 0.245 (0.264) data 0.000 (0.017) loss 3.0020 (2.3903) lr 9.7553e-03 eta 0:24:05
epoch [4/30] batch [60/204] time 0.259 (0.260) data 0.000 (0.011) loss 2.4277 (2.3395) lr 9.7553e-03 eta 0:23:34
epoch [4/30] batch [80/204] time 0.257 (0.258) data 0.000 (0.009) loss 2.8125 (2.2087) lr 9.7553e-03 eta 0:23:21
epoch [4/30] batch [100/204] time 0.249 (0.257) data 0.000 (0.007) loss 2.7656 (2.1797) lr 9.7553e-03 eta 0:23:08
epoch [4/30] batch [120/204] time 0.251 (0.256) data 0.000 (0.006) loss 2.3555 (2.1382) lr 9.7553e-03 eta 0:22:56
epoch [4/30] batch [140/204] time 0.252 (0.255) data 0.000 (0.005) loss 1.4609 (2.1066) lr 9.7553e-03 eta 0:22:49
epoch [4/30] batch [160/204] time 0.246 (0.254) data 0.000 (0.004) loss 2.7520 (2.0414) lr 9.7553e-03 eta 0:22:40
epoch [4/30] batch [180/204] time 0.244 (0.254) data 0.000 (0.004) loss 1.4531 (2.0191) lr 9.7553e-03 eta 0:22:31
epoch [4/30] batch [200/204] time 0.243 (0.253) data 0.000 (0.004) loss 5.8398 (2.0266) lr 9.7553e-03 eta 0:22:22
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.40s/it] 20%|██        | 2/10 [00:01<00:05,  1.53it/s] 30%|███       | 3/10 [00:01<00:02,  2.40it/s] 40%|████      | 4/10 [00:01<00:01,  3.29it/s] 50%|█████     | 5/10 [00:01<00:01,  4.13it/s] 60%|██████    | 6/10 [00:02<00:00,  4.88it/s] 70%|███████   | 7/10 [00:02<00:00,  5.51it/s] 80%|████████  | 8/10 [00:02<00:00,  6.03it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.44it/s]100%|██████████| 10/10 [00:02<00:00,  7.15it/s]100%|██████████| 10/10 [00:02<00:00,  3.73it/s]=> result
* total: 975
* correct: 791
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 79.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/204] time 0.248 (0.288) data 0.000 (0.036) loss 2.2559 (2.0209) lr 9.5677e-03 eta 0:25:24
epoch [5/30] batch [40/204] time 0.245 (0.268) data 0.000 (0.018) loss 0.3257 (1.7409) lr 9.5677e-03 eta 0:23:30
epoch [5/30] batch [60/204] time 0.249 (0.263) data 0.000 (0.012) loss 4.5898 (1.7363) lr 9.5677e-03 eta 0:22:56
epoch [5/30] batch [80/204] time 0.248 (0.259) data 0.000 (0.009) loss 1.5977 (1.7643) lr 9.5677e-03 eta 0:22:33
epoch [5/30] batch [100/204] time 0.254 (0.257) data 0.000 (0.007) loss 1.2949 (1.8539) lr 9.5677e-03 eta 0:22:18
epoch [5/30] batch [120/204] time 0.245 (0.256) data 0.000 (0.006) loss 1.1045 (1.7859) lr 9.5677e-03 eta 0:22:07
epoch [5/30] batch [140/204] time 0.248 (0.255) data 0.000 (0.005) loss 3.7910 (1.7746) lr 9.5677e-03 eta 0:21:55
epoch [5/30] batch [160/204] time 0.245 (0.254) data 0.000 (0.005) loss 3.4121 (1.7820) lr 9.5677e-03 eta 0:21:46
epoch [5/30] batch [180/204] time 0.310 (0.253) data 0.000 (0.004) loss 4.3789 (1.8203) lr 9.5677e-03 eta 0:21:38
epoch [5/30] batch [200/204] time 0.249 (0.253) data 0.000 (0.004) loss 1.3027 (1.8355) lr 9.5677e-03 eta 0:21:28
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.28s/it] 20%|██        | 2/10 [00:01<00:04,  1.64it/s] 30%|███       | 3/10 [00:01<00:02,  2.55it/s] 40%|████      | 4/10 [00:01<00:01,  3.46it/s] 50%|█████     | 5/10 [00:01<00:01,  4.29it/s] 60%|██████    | 6/10 [00:01<00:00,  5.03it/s] 70%|███████   | 7/10 [00:02<00:00,  5.65it/s] 80%|████████  | 8/10 [00:02<00:00,  6.13it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.51it/s]100%|██████████| 10/10 [00:02<00:00,  7.21it/s]100%|██████████| 10/10 [00:02<00:00,  3.88it/s]=> result
* total: 975
* correct: 790
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 79.4%

epoch [6/30] batch [20/204] time 0.252 (0.284) data 0.000 (0.034) loss 3.7227 (2.0807) lr 9.3301e-03 eta 0:24:04
epoch [6/30] batch [40/204] time 0.247 (0.266) data 0.000 (0.017) loss 1.8057 (1.9757) lr 9.3301e-03 eta 0:22:26
epoch [6/30] batch [60/204] time 0.248 (0.260) data 0.000 (0.011) loss 0.8999 (1.7817) lr 9.3301e-03 eta 0:21:51
epoch [6/30] batch [80/204] time 0.248 (0.259) data 0.000 (0.009) loss 3.5547 (1.7856) lr 9.3301e-03 eta 0:21:38
epoch [6/30] batch [100/204] time 0.250 (0.256) data 0.000 (0.007) loss 1.2891 (1.8531) lr 9.3301e-03 eta 0:21:21
epoch [6/30] batch [120/204] time 0.252 (0.255) data 0.000 (0.006) loss 1.0156 (1.7941) lr 9.3301e-03 eta 0:21:10
epoch [6/30] batch [140/204] time 0.250 (0.254) data 0.000 (0.005) loss 1.5469 (1.6932) lr 9.3301e-03 eta 0:21:01
epoch [6/30] batch [160/204] time 0.253 (0.254) data 0.000 (0.004) loss 0.3979 (1.6634) lr 9.3301e-03 eta 0:20:56
epoch [6/30] batch [180/204] time 0.243 (0.253) data 0.000 (0.004) loss 0.5659 (1.6326) lr 9.3301e-03 eta 0:20:46
epoch [6/30] batch [200/204] time 0.243 (0.253) data 0.000 (0.004) loss 2.0684 (1.6082) lr 9.3301e-03 eta 0:20:37
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.29s/it] 20%|██        | 2/10 [00:01<00:04,  1.61it/s] 30%|███       | 3/10 [00:01<00:02,  2.51it/s] 40%|████      | 4/10 [00:01<00:01,  3.41it/s] 50%|█████     | 5/10 [00:01<00:01,  4.25it/s] 60%|██████    | 6/10 [00:01<00:00,  4.97it/s] 70%|███████   | 7/10 [00:02<00:00,  5.59it/s] 80%|████████  | 8/10 [00:02<00:00,  6.07it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.46it/s]100%|██████████| 10/10 [00:02<00:00,  7.16it/s]100%|██████████| 10/10 [00:02<00:00,  3.84it/s]=> result
* total: 975
* correct: 795
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 80.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/204] time 0.249 (0.289) data 0.000 (0.034) loss 3.8496 (1.1771) lr 9.0451e-03 eta 0:23:27
epoch [7/30] batch [40/204] time 0.251 (0.269) data 0.000 (0.017) loss 0.6470 (1.4777) lr 9.0451e-03 eta 0:21:45
epoch [7/30] batch [60/204] time 0.253 (0.262) data 0.000 (0.011) loss 2.0801 (1.7007) lr 9.0451e-03 eta 0:21:06
epoch [7/30] batch [80/204] time 0.246 (0.259) data 0.000 (0.009) loss 0.7534 (1.8714) lr 9.0451e-03 eta 0:20:49
epoch [7/30] batch [100/204] time 0.251 (0.257) data 0.000 (0.007) loss 4.6211 (1.8982) lr 9.0451e-03 eta 0:20:34
epoch [7/30] batch [120/204] time 0.248 (0.256) data 0.000 (0.006) loss 0.7280 (1.8265) lr 9.0451e-03 eta 0:20:23
epoch [7/30] batch [140/204] time 0.249 (0.255) data 0.000 (0.005) loss 1.3096 (1.8052) lr 9.0451e-03 eta 0:20:12
epoch [7/30] batch [160/204] time 0.248 (0.254) data 0.000 (0.004) loss 0.9443 (1.8225) lr 9.0451e-03 eta 0:20:03
epoch [7/30] batch [180/204] time 0.243 (0.253) data 0.000 (0.004) loss 0.1394 (1.8239) lr 9.0451e-03 eta 0:19:55
epoch [7/30] batch [200/204] time 0.244 (0.253) data 0.000 (0.004) loss 1.9736 (1.8050) lr 9.0451e-03 eta 0:19:46
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.30s/it] 20%|██        | 2/10 [00:01<00:04,  1.60it/s] 30%|███       | 3/10 [00:01<00:02,  2.50it/s] 40%|████      | 4/10 [00:01<00:01,  3.40it/s] 50%|█████     | 5/10 [00:01<00:01,  4.24it/s] 60%|██████    | 6/10 [00:01<00:00,  4.98it/s] 70%|███████   | 7/10 [00:02<00:00,  5.58it/s] 80%|████████  | 8/10 [00:02<00:00,  6.08it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.47it/s]100%|██████████| 10/10 [00:02<00:00,  7.17it/s]100%|██████████| 10/10 [00:02<00:00,  3.84it/s]=> result
* total: 975
* correct: 797
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 80.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/204] time 0.249 (0.294) data 0.000 (0.035) loss 1.4463 (1.7655) lr 8.7157e-03 eta 0:22:51
epoch [8/30] batch [40/204] time 0.248 (0.272) data 0.000 (0.018) loss 1.1338 (1.7009) lr 8.7157e-03 eta 0:21:04
epoch [8/30] batch [60/204] time 0.252 (0.264) data 0.000 (0.012) loss 2.2656 (1.9124) lr 8.7157e-03 eta 0:20:25
epoch [8/30] batch [80/204] time 0.250 (0.261) data 0.000 (0.009) loss 1.6777 (1.9571) lr 8.7157e-03 eta 0:20:03
epoch [8/30] batch [100/204] time 0.248 (0.259) data 0.000 (0.007) loss 1.9922 (1.9308) lr 8.7157e-03 eta 0:19:48
epoch [8/30] batch [120/204] time 0.254 (0.258) data 0.000 (0.006) loss 0.6440 (1.8961) lr 8.7157e-03 eta 0:19:38
epoch [8/30] batch [140/204] time 0.247 (0.257) data 0.000 (0.005) loss 4.3672 (1.8759) lr 8.7157e-03 eta 0:19:28
epoch [8/30] batch [160/204] time 0.244 (0.255) data 0.000 (0.005) loss 2.8125 (1.9006) lr 8.7157e-03 eta 0:19:17
epoch [8/30] batch [180/204] time 0.242 (0.254) data 0.000 (0.004) loss 0.7368 (1.8536) lr 8.7157e-03 eta 0:19:07
epoch [8/30] batch [200/204] time 0.244 (0.254) data 0.000 (0.004) loss 2.9395 (1.8117) lr 8.7157e-03 eta 0:18:59
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.37s/it] 20%|██        | 2/10 [00:01<00:05,  1.54it/s] 30%|███       | 3/10 [00:01<00:02,  2.42it/s] 40%|████      | 4/10 [00:01<00:01,  3.30it/s] 50%|█████     | 5/10 [00:01<00:01,  4.14it/s] 60%|██████    | 6/10 [00:02<00:00,  4.89it/s] 70%|███████   | 7/10 [00:02<00:00,  5.49it/s] 80%|████████  | 8/10 [00:02<00:00,  6.01it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.42it/s]100%|██████████| 10/10 [00:02<00:00,  7.13it/s]100%|██████████| 10/10 [00:02<00:00,  3.75it/s]=> result
* total: 975
* correct: 814
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/204] time 0.248 (0.289) data 0.000 (0.037) loss 2.5391 (2.0464) lr 8.3457e-03 eta 0:21:29
epoch [9/30] batch [40/204] time 0.247 (0.270) data 0.000 (0.019) loss 2.1309 (1.8467) lr 8.3457e-03 eta 0:20:00
epoch [9/30] batch [60/204] time 0.251 (0.265) data 0.000 (0.013) loss 0.3037 (1.6560) lr 8.3457e-03 eta 0:19:34
epoch [9/30] batch [80/204] time 0.247 (0.261) data 0.000 (0.009) loss 1.4355 (1.6987) lr 8.3457e-03 eta 0:19:11
epoch [9/30] batch [100/204] time 0.248 (0.259) data 0.000 (0.008) loss 3.2383 (1.6993) lr 8.3457e-03 eta 0:18:57
epoch [9/30] batch [120/204] time 0.250 (0.258) data 0.000 (0.006) loss 0.0812 (1.6532) lr 8.3457e-03 eta 0:18:48
epoch [9/30] batch [140/204] time 0.251 (0.257) data 0.000 (0.006) loss 2.0410 (1.6729) lr 8.3457e-03 eta 0:18:37
epoch [9/30] batch [160/204] time 0.249 (0.256) data 0.000 (0.005) loss 1.3760 (1.6234) lr 8.3457e-03 eta 0:18:28
epoch [9/30] batch [180/204] time 0.240 (0.255) data 0.000 (0.004) loss 1.3857 (1.6038) lr 8.3457e-03 eta 0:18:19
epoch [9/30] batch [200/204] time 0.240 (0.254) data 0.000 (0.004) loss 1.4707 (1.5928) lr 8.3457e-03 eta 0:18:07
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.38s/it] 20%|██        | 2/10 [00:01<00:05,  1.54it/s] 30%|███       | 3/10 [00:01<00:02,  2.42it/s] 40%|████      | 4/10 [00:01<00:01,  3.31it/s] 50%|█████     | 5/10 [00:01<00:01,  4.15it/s] 60%|██████    | 6/10 [00:02<00:00,  4.89it/s] 70%|███████   | 7/10 [00:02<00:00,  5.53it/s] 80%|████████  | 8/10 [00:02<00:00,  6.04it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.44it/s]100%|██████████| 10/10 [00:02<00:00,  7.15it/s]100%|██████████| 10/10 [00:02<00:00,  3.75it/s]=> result
* total: 975
* correct: 806
* accuracy: 82.7%
* error: 17.3%
* macro_f1: 82.1%

epoch [10/30] batch [20/204] time 0.248 (0.285) data 0.000 (0.035) loss 2.1055 (1.6809) lr 7.9389e-03 eta 0:20:16
epoch [10/30] batch [40/204] time 0.249 (0.270) data 0.000 (0.017) loss 0.5830 (1.4749) lr 7.9389e-03 eta 0:19:04
epoch [10/30] batch [60/204] time 0.247 (0.263) data 0.000 (0.012) loss 3.1426 (1.5079) lr 7.9389e-03 eta 0:18:30
epoch [10/30] batch [80/204] time 0.247 (0.259) data 0.000 (0.009) loss 0.7637 (1.4479) lr 7.9389e-03 eta 0:18:10
epoch [10/30] batch [100/204] time 0.251 (0.257) data 0.000 (0.007) loss 0.8838 (1.4944) lr 7.9389e-03 eta 0:17:57
epoch [10/30] batch [120/204] time 0.249 (0.256) data 0.000 (0.006) loss 1.0850 (1.5865) lr 7.9389e-03 eta 0:17:47
epoch [10/30] batch [140/204] time 0.248 (0.255) data 0.000 (0.005) loss 0.0895 (1.5673) lr 7.9389e-03 eta 0:17:38
epoch [10/30] batch [160/204] time 0.249 (0.255) data 0.000 (0.005) loss 1.4277 (1.5667) lr 7.9389e-03 eta 0:17:30
epoch [10/30] batch [180/204] time 0.242 (0.254) data 0.000 (0.004) loss 0.1672 (1.5373) lr 7.9389e-03 eta 0:17:22
epoch [10/30] batch [200/204] time 0.244 (0.253) data 0.000 (0.004) loss 0.7246 (1.5458) lr 7.9389e-03 eta 0:17:12
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.32s/it] 20%|██        | 2/10 [00:01<00:05,  1.60it/s] 30%|███       | 3/10 [00:01<00:02,  2.50it/s] 40%|████      | 4/10 [00:01<00:01,  3.39it/s] 50%|█████     | 5/10 [00:01<00:01,  4.23it/s] 60%|██████    | 6/10 [00:01<00:00,  4.97it/s] 70%|███████   | 7/10 [00:02<00:00,  5.60it/s] 80%|████████  | 8/10 [00:02<00:00,  6.10it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.49it/s]100%|██████████| 10/10 [00:02<00:00,  7.19it/s]100%|██████████| 10/10 [00:02<00:00,  3.84it/s]=> result
* total: 975
* correct: 817
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/204] time 0.246 (0.288) data 0.000 (0.035) loss 0.7236 (1.4206) lr 7.5000e-03 eta 0:19:30
epoch [11/30] batch [40/204] time 0.248 (0.268) data 0.000 (0.018) loss 4.8281 (1.6183) lr 7.5000e-03 eta 0:18:01
epoch [11/30] batch [60/204] time 0.248 (0.261) data 0.000 (0.012) loss 0.8608 (1.7561) lr 7.5000e-03 eta 0:17:29
epoch [11/30] batch [80/204] time 0.250 (0.258) data 0.000 (0.009) loss 2.3516 (1.6556) lr 7.5000e-03 eta 0:17:11
epoch [11/30] batch [100/204] time 0.246 (0.256) data 0.000 (0.007) loss 2.7617 (1.6494) lr 7.5000e-03 eta 0:16:58
epoch [11/30] batch [120/204] time 0.249 (0.255) data 0.000 (0.006) loss 1.5254 (1.7471) lr 7.5000e-03 eta 0:16:48
epoch [11/30] batch [140/204] time 0.247 (0.254) data 0.000 (0.005) loss 0.6675 (1.7599) lr 7.5000e-03 eta 0:16:39
epoch [11/30] batch [160/204] time 0.248 (0.253) data 0.000 (0.005) loss 0.3174 (1.7472) lr 7.5000e-03 eta 0:16:33
epoch [11/30] batch [180/204] time 0.243 (0.253) data 0.000 (0.004) loss 3.4727 (1.6716) lr 7.5000e-03 eta 0:16:25
epoch [11/30] batch [200/204] time 0.243 (0.252) data 0.000 (0.004) loss 3.0742 (1.6460) lr 7.5000e-03 eta 0:16:16
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.27s/it] 20%|██        | 2/10 [00:01<00:04,  1.65it/s] 30%|███       | 3/10 [00:01<00:02,  2.57it/s] 40%|████      | 4/10 [00:01<00:01,  3.47it/s] 50%|█████     | 5/10 [00:01<00:01,  4.31it/s] 60%|██████    | 6/10 [00:01<00:00,  5.04it/s] 70%|███████   | 7/10 [00:02<00:00,  5.66it/s] 80%|████████  | 8/10 [00:02<00:00,  6.15it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.53it/s]100%|██████████| 10/10 [00:02<00:00,  7.23it/s]100%|██████████| 10/10 [00:02<00:00,  3.89it/s]=> result
* total: 975
* correct: 820
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/204] time 0.249 (0.288) data 0.000 (0.034) loss 1.4492 (1.4617) lr 7.0337e-03 eta 0:18:31
epoch [12/30] batch [40/204] time 0.248 (0.268) data 0.000 (0.017) loss 1.0322 (1.2844) lr 7.0337e-03 eta 0:17:06
epoch [12/30] batch [60/204] time 0.249 (0.262) data 0.000 (0.011) loss 5.8008 (1.5379) lr 7.0337e-03 eta 0:16:40
epoch [12/30] batch [80/204] time 0.247 (0.258) data 0.000 (0.009) loss 1.4834 (1.4633) lr 7.0337e-03 eta 0:16:20
epoch [12/30] batch [100/204] time 0.248 (0.256) data 0.000 (0.007) loss 4.1484 (1.4188) lr 7.0337e-03 eta 0:16:08
epoch [12/30] batch [120/204] time 0.252 (0.255) data 0.000 (0.006) loss 0.6870 (1.4625) lr 7.0337e-03 eta 0:15:59
epoch [12/30] batch [140/204] time 0.250 (0.255) data 0.000 (0.005) loss 0.4768 (1.4710) lr 7.0337e-03 eta 0:15:53
epoch [12/30] batch [160/204] time 0.253 (0.255) data 0.000 (0.004) loss 1.5107 (1.4589) lr 7.0337e-03 eta 0:15:46
epoch [12/30] batch [180/204] time 0.244 (0.254) data 0.000 (0.004) loss 0.0037 (1.4389) lr 7.0337e-03 eta 0:15:38
epoch [12/30] batch [200/204] time 0.247 (0.253) data 0.000 (0.004) loss 1.8984 (1.4614) lr 7.0337e-03 eta 0:15:31
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.30s/it] 20%|██        | 2/10 [00:01<00:04,  1.63it/s] 30%|███       | 3/10 [00:01<00:02,  2.54it/s] 40%|████      | 4/10 [00:01<00:01,  3.44it/s] 50%|█████     | 5/10 [00:01<00:01,  4.28it/s] 60%|██████    | 6/10 [00:01<00:00,  5.02it/s] 70%|███████   | 7/10 [00:02<00:00,  5.63it/s] 80%|████████  | 8/10 [00:02<00:00,  6.13it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.51it/s]100%|██████████| 10/10 [00:02<00:00,  7.22it/s]100%|██████████| 10/10 [00:02<00:00,  3.87it/s]=> result
* total: 975
* correct: 819
* accuracy: 84.0%
* error: 16.0%
* macro_f1: 83.1%

epoch [13/30] batch [20/204] time 0.253 (0.290) data 0.000 (0.034) loss 0.4009 (1.7951) lr 6.5451e-03 eta 0:17:39
epoch [13/30] batch [40/204] time 0.248 (0.270) data 0.000 (0.017) loss 0.4258 (1.4915) lr 6.5451e-03 eta 0:16:19
epoch [13/30] batch [60/204] time 0.252 (0.263) data 0.001 (0.011) loss 1.7246 (1.4448) lr 6.5451e-03 eta 0:15:49
epoch [13/30] batch [80/204] time 0.247 (0.260) data 0.000 (0.009) loss 2.0332 (1.5055) lr 6.5451e-03 eta 0:15:34
epoch [13/30] batch [100/204] time 0.248 (0.258) data 0.000 (0.007) loss 0.1899 (1.5196) lr 6.5451e-03 eta 0:15:20
epoch [13/30] batch [120/204] time 0.248 (0.256) data 0.000 (0.006) loss 1.4893 (1.4951) lr 6.5451e-03 eta 0:15:10
epoch [13/30] batch [140/204] time 0.250 (0.255) data 0.000 (0.005) loss 0.8252 (1.5046) lr 6.5451e-03 eta 0:15:01
epoch [13/30] batch [160/204] time 0.247 (0.254) data 0.000 (0.004) loss 1.9404 (1.4896) lr 6.5451e-03 eta 0:14:53
epoch [13/30] batch [180/204] time 0.243 (0.254) data 0.000 (0.004) loss 1.4385 (1.4816) lr 6.5451e-03 eta 0:14:46
epoch [13/30] batch [200/204] time 0.243 (0.253) data 0.000 (0.004) loss 2.2227 (1.4736) lr 6.5451e-03 eta 0:14:37
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.30s/it] 20%|██        | 2/10 [00:01<00:04,  1.62it/s] 30%|███       | 3/10 [00:01<00:02,  2.53it/s] 40%|████      | 4/10 [00:01<00:01,  3.42it/s] 50%|█████     | 5/10 [00:01<00:01,  4.26it/s] 60%|██████    | 6/10 [00:01<00:00,  5.00it/s] 70%|███████   | 7/10 [00:02<00:00,  5.61it/s] 80%|████████  | 8/10 [00:02<00:00,  6.10it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.49it/s]100%|██████████| 10/10 [00:02<00:00,  7.18it/s]100%|██████████| 10/10 [00:02<00:00,  3.85it/s]=> result
* total: 975
* correct: 818
* accuracy: 83.9%
* error: 16.1%
* macro_f1: 82.6%

epoch [14/30] batch [20/204] time 0.248 (0.287) data 0.000 (0.035) loss 2.0938 (1.0521) lr 6.0396e-03 eta 0:16:28
epoch [14/30] batch [40/204] time 0.252 (0.270) data 0.000 (0.018) loss 0.1138 (1.0540) lr 6.0396e-03 eta 0:15:25
epoch [14/30] batch [60/204] time 0.248 (0.263) data 0.000 (0.012) loss 0.9951 (1.3639) lr 6.0396e-03 eta 0:14:56
epoch [14/30] batch [80/204] time 0.250 (0.260) data 0.000 (0.009) loss 1.5703 (1.3425) lr 6.0396e-03 eta 0:14:39
epoch [14/30] batch [100/204] time 0.253 (0.258) data 0.000 (0.007) loss 0.9692 (1.3745) lr 6.0396e-03 eta 0:14:28
epoch [14/30] batch [120/204] time 0.249 (0.256) data 0.000 (0.006) loss 0.4917 (1.3731) lr 6.0396e-03 eta 0:14:18
epoch [14/30] batch [140/204] time 0.244 (0.256) data 0.000 (0.005) loss 0.6621 (1.4158) lr 6.0396e-03 eta 0:14:10
epoch [14/30] batch [160/204] time 0.248 (0.255) data 0.000 (0.005) loss 0.4165 (1.3626) lr 6.0396e-03 eta 0:14:02
epoch [14/30] batch [180/204] time 0.251 (0.254) data 0.000 (0.004) loss 0.5864 (1.4043) lr 6.0396e-03 eta 0:13:55
epoch [14/30] batch [200/204] time 0.244 (0.253) data 0.000 (0.004) loss 3.6270 (1.3912) lr 6.0396e-03 eta 0:13:46
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.32s/it] 20%|██        | 2/10 [00:01<00:05,  1.59it/s] 30%|███       | 3/10 [00:01<00:02,  2.48it/s] 40%|████      | 4/10 [00:01<00:01,  3.37it/s] 50%|█████     | 5/10 [00:01<00:01,  4.21it/s] 60%|██████    | 6/10 [00:01<00:00,  4.95it/s] 70%|███████   | 7/10 [00:02<00:00,  5.57it/s] 80%|████████  | 8/10 [00:02<00:00,  6.08it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.46it/s]100%|██████████| 10/10 [00:02<00:00,  7.17it/s]100%|██████████| 10/10 [00:02<00:00,  3.81it/s]=> result
* total: 975
* correct: 842
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/204] time 0.248 (0.291) data 0.000 (0.034) loss 2.4551 (1.4868) lr 5.5226e-03 eta 0:15:44
epoch [15/30] batch [40/204] time 0.247 (0.271) data 0.000 (0.017) loss 1.0801 (1.2977) lr 5.5226e-03 eta 0:14:33
epoch [15/30] batch [60/204] time 0.250 (0.264) data 0.000 (0.012) loss 0.7241 (1.4204) lr 5.5226e-03 eta 0:14:06
epoch [15/30] batch [80/204] time 0.256 (0.262) data 0.000 (0.009) loss 1.2783 (1.5091) lr 5.5226e-03 eta 0:13:53
epoch [15/30] batch [100/204] time 0.248 (0.260) data 0.000 (0.007) loss 2.1445 (1.4642) lr 5.5226e-03 eta 0:13:41
epoch [15/30] batch [120/204] time 0.250 (0.258) data 0.000 (0.006) loss 1.3691 (1.4865) lr 5.5226e-03 eta 0:13:31
epoch [15/30] batch [140/204] time 0.250 (0.258) data 0.000 (0.005) loss 3.1465 (1.4548) lr 5.5226e-03 eta 0:13:24
epoch [15/30] batch [160/204] time 0.249 (0.257) data 0.000 (0.005) loss 0.6362 (1.3838) lr 5.5226e-03 eta 0:13:16
epoch [15/30] batch [180/204] time 0.242 (0.255) data 0.000 (0.004) loss 0.3252 (1.3444) lr 5.5226e-03 eta 0:13:07
epoch [15/30] batch [200/204] time 0.243 (0.254) data 0.000 (0.004) loss 3.0195 (1.3170) lr 5.5226e-03 eta 0:12:58
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.38s/it] 20%|██        | 2/10 [00:01<00:05,  1.54it/s] 30%|███       | 3/10 [00:01<00:02,  2.42it/s] 40%|████      | 4/10 [00:01<00:01,  3.31it/s] 50%|█████     | 5/10 [00:01<00:01,  4.15it/s] 60%|██████    | 6/10 [00:02<00:00,  4.89it/s] 70%|███████   | 7/10 [00:02<00:00,  5.53it/s] 80%|████████  | 8/10 [00:02<00:00,  6.04it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.44it/s]100%|██████████| 10/10 [00:02<00:00,  7.15it/s]100%|██████████| 10/10 [00:02<00:00,  3.74it/s]=> result
* total: 975
* correct: 842
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 85.1%

epoch [16/30] batch [20/204] time 0.248 (0.286) data 0.000 (0.034) loss 0.9014 (1.2234) lr 5.0000e-03 eta 0:14:29
epoch [16/30] batch [40/204] time 0.249 (0.270) data 0.000 (0.017) loss 0.7427 (1.2089) lr 5.0000e-03 eta 0:13:34
epoch [16/30] batch [60/204] time 0.250 (0.263) data 0.000 (0.012) loss 0.8652 (1.1599) lr 5.0000e-03 eta 0:13:10
epoch [16/30] batch [80/204] time 0.251 (0.260) data 0.000 (0.009) loss 4.3867 (1.3838) lr 5.0000e-03 eta 0:12:55
epoch [16/30] batch [100/204] time 0.247 (0.258) data 0.000 (0.007) loss 4.9141 (1.3653) lr 5.0000e-03 eta 0:12:43
epoch [16/30] batch [120/204] time 0.250 (0.257) data 0.000 (0.006) loss 1.9102 (1.3724) lr 5.0000e-03 eta 0:12:34
epoch [16/30] batch [140/204] time 0.249 (0.256) data 0.000 (0.005) loss 0.9453 (1.3656) lr 5.0000e-03 eta 0:12:26
epoch [16/30] batch [160/204] time 0.248 (0.255) data 0.000 (0.004) loss 0.6182 (1.4045) lr 5.0000e-03 eta 0:12:19
epoch [16/30] batch [180/204] time 0.242 (0.254) data 0.000 (0.004) loss 2.0781 (1.3777) lr 5.0000e-03 eta 0:12:11
epoch [16/30] batch [200/204] time 0.241 (0.253) data 0.000 (0.004) loss 0.4033 (1.3530) lr 5.0000e-03 eta 0:12:03
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.32s/it] 20%|██        | 2/10 [00:01<00:04,  1.60it/s] 30%|███       | 3/10 [00:01<00:02,  2.50it/s] 40%|████      | 4/10 [00:01<00:01,  3.40it/s] 50%|█████     | 5/10 [00:01<00:01,  4.23it/s] 60%|██████    | 6/10 [00:01<00:00,  4.97it/s] 70%|███████   | 7/10 [00:02<00:00,  5.59it/s] 80%|████████  | 8/10 [00:02<00:00,  6.06it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.45it/s]100%|██████████| 10/10 [00:02<00:00,  7.15it/s]100%|██████████| 10/10 [00:02<00:00,  3.82it/s]=> result
* total: 975
* correct: 835
* accuracy: 85.6%
* error: 14.4%
* macro_f1: 84.7%

epoch [17/30] batch [20/204] time 0.247 (0.292) data 0.000 (0.034) loss 0.5400 (1.1665) lr 4.4774e-03 eta 0:13:47
epoch [17/30] batch [40/204] time 0.251 (0.271) data 0.000 (0.017) loss 0.2654 (1.1648) lr 4.4774e-03 eta 0:12:42
epoch [17/30] batch [60/204] time 0.250 (0.264) data 0.000 (0.012) loss 2.0586 (1.2375) lr 4.4774e-03 eta 0:12:19
epoch [17/30] batch [80/204] time 0.248 (0.261) data 0.000 (0.009) loss 1.5332 (1.2291) lr 4.4774e-03 eta 0:12:03
epoch [17/30] batch [100/204] time 0.250 (0.259) data 0.000 (0.007) loss 1.4941 (1.3488) lr 4.4774e-03 eta 0:11:52
epoch [17/30] batch [120/204] time 0.252 (0.257) data 0.000 (0.006) loss 1.1826 (1.3498) lr 4.4774e-03 eta 0:11:43
epoch [17/30] batch [140/204] time 0.250 (0.257) data 0.000 (0.005) loss 0.0698 (1.2902) lr 4.4774e-03 eta 0:11:36
epoch [17/30] batch [160/204] time 0.251 (0.256) data 0.000 (0.005) loss 0.0748 (1.2836) lr 4.4774e-03 eta 0:11:30
epoch [17/30] batch [180/204] time 0.243 (0.255) data 0.000 (0.004) loss 3.3672 (1.2767) lr 4.4774e-03 eta 0:11:23
epoch [17/30] batch [200/204] time 0.242 (0.254) data 0.000 (0.004) loss 1.8545 (1.2907) lr 4.4774e-03 eta 0:11:14
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.34s/it] 20%|██        | 2/10 [00:01<00:05,  1.58it/s] 30%|███       | 3/10 [00:01<00:02,  2.48it/s] 40%|████      | 4/10 [00:01<00:01,  3.37it/s] 50%|█████     | 5/10 [00:01<00:01,  4.21it/s] 60%|██████    | 6/10 [00:02<00:00,  4.95it/s] 70%|███████   | 7/10 [00:02<00:00,  5.58it/s] 80%|████████  | 8/10 [00:02<00:00,  6.08it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.44it/s]100%|██████████| 10/10 [00:02<00:00,  7.15it/s]100%|██████████| 10/10 [00:02<00:00,  3.80it/s]=> result
* total: 975
* correct: 846
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 85.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/204] time 0.248 (0.288) data 0.000 (0.035) loss 1.2246 (1.1612) lr 3.9604e-03 eta 0:12:37
epoch [18/30] batch [40/204] time 0.248 (0.271) data 0.000 (0.018) loss 0.7710 (1.0992) lr 3.9604e-03 eta 0:11:47
epoch [18/30] batch [60/204] time 0.249 (0.263) data 0.000 (0.012) loss 1.4658 (1.1762) lr 3.9604e-03 eta 0:11:22
epoch [18/30] batch [80/204] time 0.249 (0.260) data 0.000 (0.009) loss 1.9912 (1.2492) lr 3.9604e-03 eta 0:11:09
epoch [18/30] batch [100/204] time 0.248 (0.258) data 0.000 (0.007) loss 1.1953 (1.2593) lr 3.9604e-03 eta 0:10:59
epoch [18/30] batch [120/204] time 0.248 (0.257) data 0.000 (0.006) loss 2.4355 (1.2589) lr 3.9604e-03 eta 0:10:49
epoch [18/30] batch [140/204] time 0.249 (0.256) data 0.000 (0.005) loss 0.4712 (1.2630) lr 3.9604e-03 eta 0:10:42
epoch [18/30] batch [160/204] time 0.257 (0.255) data 0.000 (0.005) loss 0.6646 (1.2343) lr 3.9604e-03 eta 0:10:36
epoch [18/30] batch [180/204] time 0.244 (0.255) data 0.000 (0.004) loss 0.5791 (1.2248) lr 3.9604e-03 eta 0:10:29
epoch [18/30] batch [200/204] time 0.244 (0.254) data 0.000 (0.004) loss 0.3672 (1.2417) lr 3.9604e-03 eta 0:10:21
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.37s/it] 20%|██        | 2/10 [00:01<00:05,  1.54it/s] 30%|███       | 3/10 [00:01<00:02,  2.41it/s] 40%|████      | 4/10 [00:01<00:01,  3.30it/s] 50%|█████     | 5/10 [00:01<00:01,  4.14it/s] 60%|██████    | 6/10 [00:02<00:00,  4.89it/s] 70%|███████   | 7/10 [00:02<00:00,  5.52it/s] 80%|████████  | 8/10 [00:02<00:00,  6.03it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.43it/s]100%|██████████| 10/10 [00:02<00:00,  7.15it/s]100%|██████████| 10/10 [00:02<00:00,  3.74it/s]=> result
* total: 975
* correct: 847
* accuracy: 86.9%
* error: 13.1%
* macro_f1: 85.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/204] time 0.252 (0.293) data 0.000 (0.035) loss 2.4492 (1.1420) lr 3.4549e-03 eta 0:11:50
epoch [19/30] batch [40/204] time 0.253 (0.271) data 0.001 (0.018) loss 0.7432 (1.1545) lr 3.4549e-03 eta 0:10:53
epoch [19/30] batch [60/204] time 0.248 (0.264) data 0.000 (0.012) loss 1.1641 (1.2495) lr 3.4549e-03 eta 0:10:30
epoch [19/30] batch [80/204] time 0.248 (0.260) data 0.000 (0.009) loss 0.8242 (1.2234) lr 3.4549e-03 eta 0:10:15
epoch [19/30] batch [100/204] time 0.254 (0.259) data 0.000 (0.007) loss 0.2419 (1.1687) lr 3.4549e-03 eta 0:10:07
epoch [19/30] batch [120/204] time 0.256 (0.257) data 0.000 (0.006) loss 0.8125 (1.1645) lr 3.4549e-03 eta 0:09:59
epoch [19/30] batch [140/204] time 0.247 (0.256) data 0.000 (0.005) loss 0.4028 (1.1933) lr 3.4549e-03 eta 0:09:51
epoch [19/30] batch [160/204] time 0.249 (0.255) data 0.000 (0.005) loss 1.4932 (1.2300) lr 3.4549e-03 eta 0:09:43
epoch [19/30] batch [180/204] time 0.242 (0.254) data 0.000 (0.004) loss 1.3164 (1.2497) lr 3.4549e-03 eta 0:09:36
epoch [19/30] batch [200/204] time 0.242 (0.253) data 0.000 (0.004) loss 3.6484 (1.2580) lr 3.4549e-03 eta 0:09:29
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.43s/it] 20%|██        | 2/10 [00:01<00:05,  1.49it/s] 30%|███       | 3/10 [00:01<00:02,  2.36it/s] 40%|████      | 4/10 [00:01<00:01,  3.23it/s] 50%|█████     | 5/10 [00:01<00:01,  4.07it/s] 60%|██████    | 6/10 [00:02<00:00,  4.83it/s] 70%|███████   | 7/10 [00:02<00:00,  5.47it/s] 80%|████████  | 8/10 [00:02<00:00,  5.99it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.41it/s]100%|██████████| 10/10 [00:02<00:00,  7.12it/s]100%|██████████| 10/10 [00:02<00:00,  3.68it/s]=> result
* total: 975
* correct: 850
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 86.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [20/30] batch [20/204] time 0.248 (0.288) data 0.000 (0.035) loss 0.9761 (1.1900) lr 2.9663e-03 eta 0:10:41
epoch [20/30] batch [40/204] time 0.248 (0.271) data 0.000 (0.018) loss 0.2168 (1.2244) lr 2.9663e-03 eta 0:09:56
epoch [20/30] batch [60/204] time 0.251 (0.264) data 0.000 (0.012) loss 0.8208 (1.0737) lr 2.9663e-03 eta 0:09:36
epoch [20/30] batch [80/204] time 0.245 (0.260) data 0.000 (0.009) loss 0.5933 (1.1555) lr 2.9663e-03 eta 0:09:23
epoch [20/30] batch [100/204] time 0.245 (0.257) data 0.000 (0.007) loss 1.2510 (1.1825) lr 2.9663e-03 eta 0:09:11
epoch [20/30] batch [120/204] time 0.250 (0.256) data 0.000 (0.006) loss 0.0647 (1.1838) lr 2.9663e-03 eta 0:09:03
epoch [20/30] batch [140/204] time 0.247 (0.255) data 0.000 (0.005) loss 0.9976 (1.2231) lr 2.9663e-03 eta 0:08:57
epoch [20/30] batch [160/204] time 0.250 (0.254) data 0.000 (0.005) loss 0.0336 (1.2241) lr 2.9663e-03 eta 0:08:50
epoch [20/30] batch [180/204] time 0.241 (0.253) data 0.000 (0.004) loss 3.0273 (1.2605) lr 2.9663e-03 eta 0:08:43
epoch [20/30] batch [200/204] time 0.312 (0.253) data 0.000 (0.004) loss 0.6816 (1.2730) lr 2.9663e-03 eta 0:08:36
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.38s/it] 20%|██        | 2/10 [00:01<00:05,  1.54it/s] 30%|███       | 3/10 [00:01<00:02,  2.42it/s] 40%|████      | 4/10 [00:01<00:01,  3.29it/s] 50%|█████     | 5/10 [00:01<00:01,  4.13it/s] 60%|██████    | 6/10 [00:02<00:00,  4.88it/s] 70%|███████   | 7/10 [00:02<00:00,  5.51it/s] 80%|████████  | 8/10 [00:02<00:00,  6.02it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.42it/s]100%|██████████| 10/10 [00:02<00:00,  7.13it/s]100%|██████████| 10/10 [00:02<00:00,  3.71it/s]=> result
* total: 975
* correct: 853
* accuracy: 87.5%
* error: 12.5%
* macro_f1: 86.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/204] time 0.246 (0.285) data 0.000 (0.035) loss 4.8906 (1.2297) lr 2.5000e-03 eta 0:09:35
epoch [21/30] batch [40/204] time 0.247 (0.266) data 0.000 (0.018) loss 1.4248 (1.2624) lr 2.5000e-03 eta 0:08:51
epoch [21/30] batch [60/204] time 0.256 (0.261) data 0.000 (0.012) loss 0.3853 (1.2388) lr 2.5000e-03 eta 0:08:37
epoch [21/30] batch [80/204] time 0.250 (0.258) data 0.000 (0.009) loss 2.5664 (1.2152) lr 2.5000e-03 eta 0:08:25
epoch [21/30] batch [100/204] time 0.248 (0.256) data 0.000 (0.007) loss 0.2014 (1.1796) lr 2.5000e-03 eta 0:08:16
epoch [21/30] batch [120/204] time 0.250 (0.255) data 0.000 (0.006) loss 0.1036 (1.1434) lr 2.5000e-03 eta 0:08:10
epoch [21/30] batch [140/204] time 0.246 (0.254) data 0.000 (0.005) loss 2.6270 (1.2054) lr 2.5000e-03 eta 0:08:02
epoch [21/30] batch [160/204] time 0.249 (0.253) data 0.000 (0.005) loss 1.1514 (1.2354) lr 2.5000e-03 eta 0:07:56
epoch [21/30] batch [180/204] time 0.244 (0.252) data 0.000 (0.004) loss 0.7539 (1.1993) lr 2.5000e-03 eta 0:07:49
epoch [21/30] batch [200/204] time 0.244 (0.252) data 0.000 (0.004) loss 0.8623 (1.2248) lr 2.5000e-03 eta 0:07:42
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.41s/it] 20%|██        | 2/10 [00:01<00:05,  1.50it/s] 30%|███       | 3/10 [00:01<00:02,  2.37it/s] 40%|████      | 4/10 [00:01<00:01,  3.25it/s] 50%|█████     | 5/10 [00:01<00:01,  4.09it/s] 60%|██████    | 6/10 [00:02<00:00,  4.84it/s] 70%|███████   | 7/10 [00:02<00:00,  5.48it/s] 80%|████████  | 8/10 [00:02<00:00,  5.99it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.40it/s]100%|██████████| 10/10 [00:02<00:00,  7.11it/s]100%|██████████| 10/10 [00:02<00:00,  3.69it/s]=> result
* total: 975
* correct: 861
* accuracy: 88.3%
* error: 11.7%
* macro_f1: 87.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [22/30] batch [20/204] time 0.249 (0.291) data 0.000 (0.035) loss 2.9180 (1.1330) lr 2.0611e-03 eta 0:08:49
epoch [22/30] batch [40/204] time 0.258 (0.270) data 0.000 (0.017) loss 0.5459 (1.2492) lr 2.0611e-03 eta 0:08:05
epoch [22/30] batch [60/204] time 0.247 (0.263) data 0.000 (0.012) loss 0.3403 (1.2895) lr 2.0611e-03 eta 0:07:47
epoch [22/30] batch [80/204] time 0.251 (0.260) data 0.000 (0.009) loss 2.5117 (1.2585) lr 2.0611e-03 eta 0:07:35
epoch [22/30] batch [100/204] time 0.247 (0.257) data 0.000 (0.007) loss 4.0430 (1.2418) lr 2.0611e-03 eta 0:07:26
epoch [22/30] batch [120/204] time 0.247 (0.256) data 0.000 (0.006) loss 0.1426 (1.2209) lr 2.0611e-03 eta 0:07:19
epoch [22/30] batch [140/204] time 0.249 (0.255) data 0.000 (0.005) loss 0.4187 (1.1924) lr 2.0611e-03 eta 0:07:12
epoch [22/30] batch [160/204] time 0.251 (0.254) data 0.000 (0.005) loss 1.7100 (1.2224) lr 2.0611e-03 eta 0:07:05
epoch [22/30] batch [180/204] time 0.244 (0.253) data 0.000 (0.004) loss 0.6899 (1.2122) lr 2.0611e-03 eta 0:06:58
epoch [22/30] batch [200/204] time 0.244 (0.252) data 0.000 (0.004) loss 2.2500 (1.1922) lr 2.0611e-03 eta 0:06:52
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.31s/it] 20%|██        | 2/10 [00:01<00:04,  1.62it/s] 30%|███       | 3/10 [00:01<00:02,  2.52it/s] 40%|████      | 4/10 [00:01<00:01,  3.42it/s] 50%|█████     | 5/10 [00:01<00:01,  4.26it/s] 60%|██████    | 6/10 [00:01<00:00,  5.00it/s] 70%|███████   | 7/10 [00:02<00:00,  5.62it/s] 80%|████████  | 8/10 [00:02<00:00,  6.11it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.48it/s]100%|██████████| 10/10 [00:02<00:00,  7.18it/s]100%|██████████| 10/10 [00:02<00:00,  3.83it/s]=> result
* total: 975
* correct: 859
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 87.1%

epoch [23/30] batch [20/204] time 0.249 (0.288) data 0.000 (0.038) loss 1.7139 (1.5251) lr 1.6543e-03 eta 0:07:44
epoch [23/30] batch [40/204] time 0.252 (0.269) data 0.000 (0.019) loss 0.2324 (1.2199) lr 1.6543e-03 eta 0:07:07
epoch [23/30] batch [60/204] time 0.248 (0.262) data 0.000 (0.013) loss -0.0214 (1.2427) lr 1.6543e-03 eta 0:06:52
epoch [23/30] batch [80/204] time 0.248 (0.259) data 0.000 (0.010) loss 0.1103 (1.2312) lr 1.6543e-03 eta 0:06:41
epoch [23/30] batch [100/204] time 0.246 (0.257) data 0.000 (0.008) loss 4.9531 (1.2374) lr 1.6543e-03 eta 0:06:34
epoch [23/30] batch [120/204] time 0.258 (0.256) data 0.000 (0.007) loss 0.9336 (1.2327) lr 1.6543e-03 eta 0:06:26
epoch [23/30] batch [140/204] time 0.246 (0.255) data 0.000 (0.006) loss 0.5562 (1.2258) lr 1.6543e-03 eta 0:06:20
epoch [23/30] batch [160/204] time 0.248 (0.254) data 0.000 (0.005) loss 0.6719 (1.2339) lr 1.6543e-03 eta 0:06:14
epoch [23/30] batch [180/204] time 0.242 (0.253) data 0.000 (0.004) loss 0.4585 (1.2084) lr 1.6543e-03 eta 0:06:08
epoch [23/30] batch [200/204] time 0.243 (0.253) data 0.000 (0.004) loss 2.6152 (1.1817) lr 1.6543e-03 eta 0:06:01
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.36s/it] 20%|██        | 2/10 [00:01<00:05,  1.56it/s] 30%|███       | 3/10 [00:01<00:02,  2.43it/s] 40%|████      | 4/10 [00:01<00:01,  3.31it/s] 50%|█████     | 5/10 [00:01<00:01,  4.15it/s] 60%|██████    | 6/10 [00:02<00:00,  4.87it/s] 70%|███████   | 7/10 [00:02<00:00,  5.51it/s] 80%|████████  | 8/10 [00:02<00:00,  6.02it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.42it/s]100%|██████████| 10/10 [00:02<00:00,  7.13it/s]100%|██████████| 10/10 [00:02<00:00,  3.76it/s]=> result
* total: 975
* correct: 862
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 87.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [24/30] batch [20/204] time 0.249 (0.287) data 0.000 (0.034) loss 0.5386 (1.3352) lr 1.2843e-03 eta 0:06:43
epoch [24/30] batch [40/204] time 0.256 (0.269) data 0.000 (0.017) loss 2.4609 (1.2453) lr 1.2843e-03 eta 0:06:12
epoch [24/30] batch [60/204] time 0.248 (0.262) data 0.000 (0.012) loss 0.6953 (1.1512) lr 1.2843e-03 eta 0:05:58
epoch [24/30] batch [80/204] time 0.247 (0.259) data 0.000 (0.009) loss 0.9248 (1.1726) lr 1.2843e-03 eta 0:05:48
epoch [24/30] batch [100/204] time 0.249 (0.258) data 0.000 (0.007) loss 0.1848 (1.1851) lr 1.2843e-03 eta 0:05:42
epoch [24/30] batch [120/204] time 0.248 (0.256) data 0.000 (0.006) loss 0.6890 (1.1466) lr 1.2843e-03 eta 0:05:35
epoch [24/30] batch [140/204] time 0.247 (0.255) data 0.000 (0.005) loss 0.5142 (1.1573) lr 1.2843e-03 eta 0:05:28
epoch [24/30] batch [160/204] time 0.246 (0.255) data 0.000 (0.005) loss 3.8008 (1.1894) lr 1.2843e-03 eta 0:05:23
epoch [24/30] batch [180/204] time 0.245 (0.254) data 0.000 (0.004) loss 1.2158 (1.1684) lr 1.2843e-03 eta 0:05:17
epoch [24/30] batch [200/204] time 0.242 (0.253) data 0.000 (0.004) loss 1.1924 (1.1826) lr 1.2843e-03 eta 0:05:10
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.32s/it] 20%|██        | 2/10 [00:01<00:04,  1.61it/s] 30%|███       | 3/10 [00:01<00:02,  2.51it/s] 40%|████      | 4/10 [00:01<00:01,  3.41it/s] 50%|█████     | 5/10 [00:01<00:01,  4.25it/s] 60%|██████    | 6/10 [00:01<00:00,  4.99it/s] 70%|███████   | 7/10 [00:02<00:00,  5.60it/s] 80%|████████  | 8/10 [00:02<00:00,  6.10it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.48it/s]100%|██████████| 10/10 [00:02<00:00,  7.18it/s]100%|██████████| 10/10 [00:02<00:00,  3.81it/s]=> result
* total: 975
* correct: 864
* accuracy: 88.6%
* error: 11.4%
* macro_f1: 88.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [25/30] batch [20/204] time 0.248 (0.286) data 0.000 (0.036) loss 0.9385 (1.2689) lr 9.5492e-04 eta 0:05:44
epoch [25/30] batch [40/204] time 0.249 (0.267) data 0.000 (0.018) loss 0.6973 (1.1284) lr 9.5492e-04 eta 0:05:16
epoch [25/30] batch [60/204] time 0.251 (0.263) data 0.000 (0.012) loss 2.2949 (1.1232) lr 9.5492e-04 eta 0:05:05
epoch [25/30] batch [80/204] time 0.249 (0.260) data 0.000 (0.009) loss 2.3711 (1.1146) lr 9.5492e-04 eta 0:04:57
epoch [25/30] batch [100/204] time 0.251 (0.258) data 0.000 (0.007) loss 0.0371 (1.1268) lr 9.5492e-04 eta 0:04:49
epoch [25/30] batch [120/204] time 0.253 (0.257) data 0.000 (0.006) loss 1.6289 (1.0942) lr 9.5492e-04 eta 0:04:43
epoch [25/30] batch [140/204] time 0.250 (0.256) data 0.000 (0.005) loss 2.6230 (1.1130) lr 9.5492e-04 eta 0:04:37
epoch [25/30] batch [160/204] time 0.248 (0.255) data 0.000 (0.005) loss 0.0657 (1.1137) lr 9.5492e-04 eta 0:04:31
epoch [25/30] batch [180/204] time 0.244 (0.254) data 0.000 (0.004) loss 1.5625 (1.1545) lr 9.5492e-04 eta 0:04:25
epoch [25/30] batch [200/204] time 0.242 (0.254) data 0.000 (0.004) loss 0.3628 (1.1638) lr 9.5492e-04 eta 0:04:19
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.40s/it] 20%|██        | 2/10 [00:01<00:05,  1.53it/s] 30%|███       | 3/10 [00:01<00:02,  2.41it/s] 40%|████      | 4/10 [00:01<00:01,  3.29it/s] 50%|█████     | 5/10 [00:01<00:01,  4.13it/s] 60%|██████    | 6/10 [00:02<00:00,  4.89it/s] 70%|███████   | 7/10 [00:02<00:00,  5.52it/s] 80%|████████  | 8/10 [00:02<00:00,  6.04it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.44it/s]100%|██████████| 10/10 [00:02<00:00,  7.15it/s]100%|██████████| 10/10 [00:02<00:00,  3.71it/s]=> result
* total: 975
* correct: 863
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 87.6%

epoch [26/30] batch [20/204] time 0.248 (0.286) data 0.000 (0.035) loss 3.3359 (0.9966) lr 6.6987e-04 eta 0:04:46
epoch [26/30] batch [40/204] time 0.247 (0.267) data 0.000 (0.017) loss 1.0576 (1.0660) lr 6.6987e-04 eta 0:04:21
epoch [26/30] batch [60/204] time 0.249 (0.262) data 0.000 (0.012) loss 0.1050 (1.0442) lr 6.6987e-04 eta 0:04:11
epoch [26/30] batch [80/204] time 0.249 (0.259) data 0.000 (0.009) loss 0.7549 (0.9827) lr 6.6987e-04 eta 0:04:03
epoch [26/30] batch [100/204] time 0.251 (0.257) data 0.000 (0.007) loss 1.4092 (0.9516) lr 6.6987e-04 eta 0:03:56
epoch [26/30] batch [120/204] time 0.249 (0.256) data 0.000 (0.006) loss 0.1506 (1.0111) lr 6.6987e-04 eta 0:03:50
epoch [26/30] batch [140/204] time 0.250 (0.255) data 0.000 (0.005) loss 0.3660 (0.9876) lr 6.6987e-04 eta 0:03:44
epoch [26/30] batch [160/204] time 0.256 (0.255) data 0.000 (0.005) loss 0.9883 (1.0641) lr 6.6987e-04 eta 0:03:39
epoch [26/30] batch [180/204] time 0.249 (0.254) data 0.000 (0.004) loss 3.1836 (1.1236) lr 6.6987e-04 eta 0:03:33
epoch [26/30] batch [200/204] time 0.243 (0.253) data 0.000 (0.004) loss 1.9531 (1.1175) lr 6.6987e-04 eta 0:03:27
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.30s/it] 20%|██        | 2/10 [00:01<00:04,  1.61it/s] 30%|███       | 3/10 [00:01<00:02,  2.51it/s] 40%|████      | 4/10 [00:01<00:01,  3.41it/s] 50%|█████     | 5/10 [00:01<00:01,  4.25it/s] 60%|██████    | 6/10 [00:01<00:00,  4.99it/s] 70%|███████   | 7/10 [00:02<00:00,  5.61it/s] 80%|████████  | 8/10 [00:02<00:00,  6.10it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.49it/s]100%|██████████| 10/10 [00:02<00:00,  7.19it/s]100%|██████████| 10/10 [00:02<00:00,  3.85it/s]=> result
* total: 975
* correct: 867
* accuracy: 88.9%
* error: 11.1%
* macro_f1: 88.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [27/30] batch [20/204] time 0.243 (0.285) data 0.000 (0.035) loss 0.6392 (0.9663) lr 4.3227e-04 eta 0:03:46
epoch [27/30] batch [40/204] time 0.244 (0.266) data 0.000 (0.018) loss 0.0768 (1.0694) lr 4.3227e-04 eta 0:03:26
epoch [27/30] batch [60/204] time 0.247 (0.262) data 0.000 (0.012) loss 1.0488 (1.0906) lr 4.3227e-04 eta 0:03:17
epoch [27/30] batch [80/204] time 0.244 (0.258) data 0.000 (0.009) loss 0.1512 (1.0844) lr 4.3227e-04 eta 0:03:10
epoch [27/30] batch [100/204] time 0.244 (0.256) data 0.000 (0.007) loss 1.2686 (1.0955) lr 4.3227e-04 eta 0:03:03
epoch [27/30] batch [120/204] time 0.247 (0.255) data 0.000 (0.006) loss 0.8066 (1.1312) lr 4.3227e-04 eta 0:02:57
epoch [27/30] batch [140/204] time 0.246 (0.254) data 0.000 (0.005) loss 3.1719 (1.1148) lr 4.3227e-04 eta 0:02:51
epoch [27/30] batch [160/204] time 0.250 (0.253) data 0.000 (0.005) loss 1.3252 (1.1425) lr 4.3227e-04 eta 0:02:46
epoch [27/30] batch [180/204] time 0.242 (0.253) data 0.000 (0.004) loss 0.5918 (1.1782) lr 4.3227e-04 eta 0:02:40
epoch [27/30] batch [200/204] time 0.242 (0.252) data 0.000 (0.004) loss 1.3848 (1.2018) lr 4.3227e-04 eta 0:02:35
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:12,  1.41s/it] 20%|██        | 2/10 [00:01<00:05,  1.52it/s] 30%|███       | 3/10 [00:01<00:02,  2.38it/s] 40%|████      | 4/10 [00:01<00:01,  3.27it/s] 50%|█████     | 5/10 [00:01<00:01,  4.10it/s] 60%|██████    | 6/10 [00:02<00:00,  4.86it/s] 70%|███████   | 7/10 [00:02<00:00,  5.49it/s] 80%|████████  | 8/10 [00:02<00:00,  6.01it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.41it/s]100%|██████████| 10/10 [00:02<00:00,  7.12it/s]100%|██████████| 10/10 [00:02<00:00,  3.70it/s]=> result
* total: 975
* correct: 866
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 87.9%

epoch [28/30] batch [20/204] time 0.248 (0.290) data 0.000 (0.035) loss 2.4941 (0.9612) lr 2.4472e-04 eta 0:02:51
epoch [28/30] batch [40/204] time 0.248 (0.269) data 0.000 (0.017) loss 0.6382 (1.0630) lr 2.4472e-04 eta 0:02:33
epoch [28/30] batch [60/204] time 0.249 (0.263) data 0.000 (0.012) loss 0.3142 (0.9415) lr 2.4472e-04 eta 0:02:24
epoch [28/30] batch [80/204] time 0.251 (0.259) data 0.000 (0.009) loss 0.5098 (0.9793) lr 2.4472e-04 eta 0:02:18
epoch [28/30] batch [100/204] time 0.256 (0.258) data 0.000 (0.007) loss 0.1807 (0.9694) lr 2.4472e-04 eta 0:02:11
epoch [28/30] batch [120/204] time 0.247 (0.256) data 0.000 (0.006) loss 0.6626 (0.9886) lr 2.4472e-04 eta 0:02:05
epoch [28/30] batch [140/204] time 0.251 (0.255) data 0.000 (0.005) loss 0.0271 (0.9824) lr 2.4472e-04 eta 0:02:00
epoch [28/30] batch [160/204] time 0.251 (0.254) data 0.000 (0.005) loss 3.2012 (1.0084) lr 2.4472e-04 eta 0:01:54
epoch [28/30] batch [180/204] time 0.244 (0.254) data 0.000 (0.004) loss 0.4397 (1.0349) lr 2.4472e-04 eta 0:01:49
epoch [28/30] batch [200/204] time 0.243 (0.253) data 0.000 (0.004) loss 0.6318 (1.0967) lr 2.4472e-04 eta 0:01:44
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.32s/it] 20%|██        | 2/10 [00:01<00:05,  1.59it/s] 30%|███       | 3/10 [00:01<00:02,  2.49it/s] 40%|████      | 4/10 [00:01<00:01,  3.38it/s] 50%|█████     | 5/10 [00:01<00:01,  4.20it/s] 60%|██████    | 6/10 [00:01<00:00,  4.95it/s] 70%|███████   | 7/10 [00:02<00:00,  5.57it/s] 80%|████████  | 8/10 [00:02<00:00,  6.09it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.47it/s]100%|██████████| 10/10 [00:02<00:00,  7.18it/s]100%|██████████| 10/10 [00:02<00:00,  3.83it/s]=> result
* total: 975
* correct: 868
* accuracy: 89.0%
* error: 11.0%
* macro_f1: 88.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [29/30] batch [20/204] time 0.259 (0.289) data 0.000 (0.037) loss 0.2314 (1.4269) lr 1.0926e-04 eta 0:01:52
epoch [29/30] batch [40/204] time 0.248 (0.271) data 0.000 (0.019) loss 1.3750 (1.2264) lr 1.0926e-04 eta 0:01:39
epoch [29/30] batch [60/204] time 0.249 (0.264) data 0.000 (0.012) loss 2.8516 (1.2298) lr 1.0926e-04 eta 0:01:31
epoch [29/30] batch [80/204] time 0.246 (0.260) data 0.000 (0.009) loss -0.0251 (1.2022) lr 1.0926e-04 eta 0:01:25
epoch [29/30] batch [100/204] time 0.249 (0.258) data 0.000 (0.008) loss 1.0869 (1.1708) lr 1.0926e-04 eta 0:01:19
epoch [29/30] batch [120/204] time 0.250 (0.256) data 0.000 (0.006) loss 1.1104 (1.1736) lr 1.0926e-04 eta 0:01:13
epoch [29/30] batch [140/204] time 0.248 (0.255) data 0.000 (0.005) loss 1.0020 (1.1460) lr 1.0926e-04 eta 0:01:08
epoch [29/30] batch [160/204] time 0.244 (0.254) data 0.000 (0.005) loss 0.0953 (1.1097) lr 1.0926e-04 eta 0:01:03
epoch [29/30] batch [180/204] time 0.241 (0.253) data 0.000 (0.004) loss 0.2664 (1.1392) lr 1.0926e-04 eta 0:00:57
epoch [29/30] batch [200/204] time 0.243 (0.252) data 0.000 (0.004) loss 0.6587 (1.1569) lr 1.0926e-04 eta 0:00:52
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.28s/it] 20%|██        | 2/10 [00:01<00:04,  1.65it/s] 30%|███       | 3/10 [00:01<00:02,  2.56it/s] 40%|████      | 4/10 [00:01<00:01,  3.46it/s] 50%|█████     | 5/10 [00:01<00:01,  4.30it/s] 60%|██████    | 6/10 [00:01<00:00,  5.03it/s] 70%|███████   | 7/10 [00:02<00:00,  5.64it/s] 80%|████████  | 8/10 [00:02<00:00,  6.13it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.51it/s]100%|██████████| 10/10 [00:02<00:00,  7.20it/s]100%|██████████| 10/10 [00:02<00:00,  3.89it/s]=> result
* total: 975
* correct: 870
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 88.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [30/30] batch [20/204] time 0.248 (0.288) data 0.000 (0.034) loss 2.1621 (0.8216) lr 2.7391e-05 eta 0:00:52
epoch [30/30] batch [40/204] time 0.262 (0.270) data 0.000 (0.017) loss 1.6377 (0.9092) lr 2.7391e-05 eta 0:00:44
epoch [30/30] batch [60/204] time 0.253 (0.265) data 0.000 (0.011) loss 0.0397 (0.9545) lr 2.7391e-05 eta 0:00:38
epoch [30/30] batch [80/204] time 0.250 (0.261) data 0.000 (0.009) loss 1.2920 (0.9770) lr 2.7391e-05 eta 0:00:32
epoch [30/30] batch [100/204] time 0.248 (0.259) data 0.000 (0.007) loss 0.3491 (1.0642) lr 2.7391e-05 eta 0:00:26
epoch [30/30] batch [120/204] time 0.254 (0.257) data 0.000 (0.006) loss 0.1539 (1.0115) lr 2.7391e-05 eta 0:00:21
epoch [30/30] batch [140/204] time 0.253 (0.256) data 0.000 (0.005) loss 1.7607 (1.0367) lr 2.7391e-05 eta 0:00:16
epoch [30/30] batch [160/204] time 0.319 (0.255) data 0.000 (0.004) loss 0.2800 (1.0343) lr 2.7391e-05 eta 0:00:11
epoch [30/30] batch [180/204] time 0.245 (0.255) data 0.000 (0.004) loss 0.4392 (1.0117) lr 2.7391e-05 eta 0:00:06
epoch [30/30] batch [200/204] time 0.241 (0.253) data 0.000 (0.004) loss 0.9497 (1.0555) lr 2.7391e-05 eta 0:00:01
Evaluate on the *val* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:11,  1.33s/it] 20%|██        | 2/10 [00:01<00:05,  1.60it/s] 30%|███       | 3/10 [00:01<00:02,  2.49it/s] 40%|████      | 4/10 [00:01<00:01,  3.39it/s] 50%|█████     | 5/10 [00:01<00:01,  4.23it/s] 60%|██████    | 6/10 [00:01<00:00,  4.97it/s] 70%|███████   | 7/10 [00:02<00:00,  5.59it/s] 80%|████████  | 8/10 [00:02<00:00,  6.09it/s] 90%|█████████ | 9/10 [00:02<00:00,  6.48it/s]100%|██████████| 10/10 [00:02<00:00,  7.18it/s]100%|██████████| 10/10 [00:02<00:00,  3.82it/s]
=> result
* total: 975
* correct: 870
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 88.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 29)
Evaluate on the *test* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:01<00:32,  1.73s/it] 10%|█         | 2/20 [00:01<00:14,  1.26it/s] 15%|█▌        | 3/20 [00:01<00:08,  2.04it/s] 20%|██        | 4/20 [00:02<00:05,  2.86it/s] 25%|██▌       | 5/20 [00:02<00:04,  3.69it/s] 30%|███       | 6/20 [00:02<00:03,  4.46it/s] 35%|███▌      | 7/20 [00:02<00:02,  5.15it/s] 40%|████      | 8/20 [00:02<00:02,  5.73it/s] 45%|████▌     | 9/20 [00:02<00:01,  6.19it/s] 50%|█████     | 10/20 [00:02<00:01,  6.56it/s] 55%|█████▌    | 11/20 [00:03<00:01,  6.83it/s] 60%|██████    | 12/20 [00:03<00:01,  7.03it/s] 65%|██████▌   | 13/20 [00:03<00:00,  7.18it/s] 70%|███████   | 14/20 [00:03<00:00,  7.29it/s] 75%|███████▌  | 15/20 [00:03<00:00,  7.36it/s] 80%|████████  | 16/20 [00:03<00:00,  7.42it/s] 85%|████████▌ | 17/20 [00:03<00:00,  7.46it/s] 90%|█████████ | 18/20 [00:03<00:00,  7.49it/s] 95%|█████████▌| 19/20 [00:04<00:00,  7.51it/s]100%|██████████| 20/20 [00:04<00:00,  4.65it/s]
=> result
* total: 1,934
* correct: 1,626
* accuracy: 84.1%
* error: 15.9%
* macro_f1: 83.1%
Elapsed: 0:27:17
+ sh scripts/rpo_prime/base2new_test_sdl.sh ucf101 3 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
800 923 1849
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  50
# train_x  800
# val      923
# test     1,849
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/ucf101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 29)
Evaluate on the *test* set
  0%|          | 0/19 [00:00<?, ?it/s]  5%|▌         | 1/19 [00:03<01:04,  3.61s/it] 11%|█         | 2/19 [00:03<00:26,  1.56s/it] 16%|█▌        | 3/19 [00:03<00:14,  1.10it/s] 21%|██        | 4/19 [00:04<00:09,  1.65it/s] 26%|██▋       | 5/19 [00:04<00:06,  2.30it/s] 32%|███▏      | 6/19 [00:04<00:04,  3.02it/s] 37%|███▋      | 7/19 [00:04<00:03,  3.75it/s] 42%|████▏     | 8/19 [00:04<00:02,  4.47it/s] 47%|████▋     | 9/19 [00:04<00:01,  5.12it/s] 53%|█████▎    | 10/19 [00:04<00:01,  5.69it/s] 58%|█████▊    | 11/19 [00:04<00:01,  6.15it/s] 63%|██████▎   | 12/19 [00:05<00:01,  6.52it/s] 68%|██████▊   | 13/19 [00:05<00:00,  6.80it/s] 74%|███████▎  | 14/19 [00:05<00:00,  7.01it/s] 79%|███████▉  | 15/19 [00:05<00:00,  7.17it/s] 84%|████████▍ | 16/19 [00:05<00:00,  7.28it/s] 89%|████████▉ | 17/19 [00:05<00:00,  7.36it/s] 95%|█████████▍| 18/19 [00:05<00:00,  7.42it/s]100%|██████████| 19/19 [00:06<00:00,  3.14it/s]
=> result
* total: 1,849
* correct: 1,431
* accuracy: 77.4%
* error: 22.6%
* macro_f1: 74.3%
+ for dataset in eurosat dtd oxford_flowers stanford_cars oxford_pets food101 ucf101 caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh caltech101 1 0 main_tmp1_0.1sdl 16
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
800 1036 1549
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      1,036
# test     1,549
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Found checkpoint at output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1 (will resume training)
Loading checkpoint from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30"
Loaded model weights
Loaded optimizer
Loaded scheduler
Previous epoch: 30
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 18)
Evaluate on the *test* set
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:03<00:51,  3.43s/it] 12%|█▎        | 2/16 [00:03<00:20,  1.49s/it] 19%|█▉        | 3/16 [00:03<00:11,  1.15it/s] 25%|██▌       | 4/16 [00:03<00:06,  1.73it/s] 31%|███▏      | 5/16 [00:03<00:04,  2.39it/s] 38%|███▊      | 6/16 [00:04<00:03,  3.12it/s] 44%|████▍     | 7/16 [00:04<00:02,  3.86it/s] 50%|█████     | 8/16 [00:04<00:01,  4.57it/s] 56%|█████▋    | 9/16 [00:04<00:01,  5.22it/s] 62%|██████▎   | 10/16 [00:04<00:01,  5.78it/s] 69%|██████▉   | 11/16 [00:04<00:00,  6.23it/s] 75%|███████▌  | 12/16 [00:04<00:00,  6.59it/s] 81%|████████▏ | 13/16 [00:05<00:00,  6.86it/s] 88%|████████▊ | 14/16 [00:05<00:00,  7.06it/s] 94%|█████████▍| 15/16 [00:05<00:00,  7.21it/s]100%|██████████| 16/16 [00:05<00:00,  2.93it/s]
=> result
* total: 1,549
* correct: 1,525
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 97.0%
Elapsed: 0:00:05
+ sh scripts/rpo_prime/base2new_test_sdl.sh caltech101 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
800 613 916
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      613
# test     916
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 18)
Evaluate on the *test* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:03<00:27,  3.01s/it] 20%|██        | 2/10 [00:03<00:10,  1.32s/it] 30%|███       | 3/10 [00:03<00:05,  1.29it/s] 40%|████      | 4/10 [00:03<00:03,  1.91it/s] 50%|█████     | 5/10 [00:03<00:01,  2.62it/s] 60%|██████    | 6/10 [00:03<00:01,  3.37it/s] 70%|███████   | 7/10 [00:03<00:00,  4.12it/s] 80%|████████  | 8/10 [00:03<00:00,  4.82it/s] 90%|█████████ | 9/10 [00:04<00:00,  5.44it/s]100%|██████████| 10/10 [00:04<00:00,  2.37it/s]
=> result
* total: 916
* correct: 855
* accuracy: 93.3%
* error: 6.7%
* macro_f1: 93.8%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh caltech101 2 0 main_tmp1_0.1sdl 16
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
800 1036 1549
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      1,036
# test     1,549
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Found checkpoint at output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2 (will resume training)
Loading checkpoint from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30"
Loaded model weights
Loaded optimizer
Loaded scheduler
Previous epoch: 30
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 2)
Evaluate on the *test* set
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:03<00:52,  3.47s/it] 12%|█▎        | 2/16 [00:03<00:21,  1.51s/it] 19%|█▉        | 3/16 [00:03<00:11,  1.14it/s] 25%|██▌       | 4/16 [00:03<00:07,  1.71it/s] 31%|███▏      | 5/16 [00:03<00:04,  2.37it/s] 38%|███▊      | 6/16 [00:04<00:03,  3.10it/s] 44%|████▍     | 7/16 [00:04<00:02,  3.84it/s] 50%|█████     | 8/16 [00:04<00:01,  4.55it/s] 56%|█████▋    | 9/16 [00:04<00:01,  5.21it/s] 62%|██████▎   | 10/16 [00:04<00:01,  5.76it/s] 69%|██████▉   | 11/16 [00:04<00:00,  6.22it/s] 75%|███████▌  | 12/16 [00:04<00:00,  6.58it/s] 81%|████████▏ | 13/16 [00:05<00:00,  6.85it/s] 88%|████████▊ | 14/16 [00:05<00:00,  7.05it/s] 94%|█████████▍| 15/16 [00:05<00:00,  7.20it/s]100%|██████████| 16/16 [00:05<00:00,  2.91it/s]
=> result
* total: 1,549
* correct: 1,520
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.3%
Elapsed: 0:00:05
+ sh scripts/rpo_prime/base2new_test_sdl.sh caltech101 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
800 613 916
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      613
# test     916
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 2)
Evaluate on the *test* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:03<00:28,  3.12s/it] 20%|██        | 2/10 [00:03<00:10,  1.36s/it] 30%|███       | 3/10 [00:03<00:05,  1.25it/s] 40%|████      | 4/10 [00:03<00:03,  1.87it/s] 50%|█████     | 5/10 [00:03<00:01,  2.56it/s] 60%|██████    | 6/10 [00:03<00:01,  3.31it/s] 70%|███████   | 7/10 [00:03<00:00,  4.06it/s] 80%|████████  | 8/10 [00:04<00:00,  4.74it/s] 90%|█████████ | 9/10 [00:04<00:00,  5.37it/s]100%|██████████| 10/10 [00:04<00:00,  2.33it/s]
=> result
* total: 916
* correct: 861
* accuracy: 94.0%
* error: 6.0%
* macro_f1: 94.2%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh caltech101 3 0 main_tmp1_0.1sdl 16
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
800 1036 1549
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      1,036
# test     1,549
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Found checkpoint at output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3 (will resume training)
Loading checkpoint from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-30"
Loaded model weights
Loaded optimizer
Loaded scheduler
Previous epoch: 30
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 9)
Evaluate on the *test* set
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:03<00:51,  3.45s/it] 12%|█▎        | 2/16 [00:03<00:21,  1.50s/it] 19%|█▉        | 3/16 [00:03<00:11,  1.14it/s] 25%|██▌       | 4/16 [00:03<00:06,  1.72it/s] 31%|███▏      | 5/16 [00:03<00:04,  2.38it/s] 38%|███▊      | 6/16 [00:04<00:03,  3.10it/s] 44%|████▍     | 7/16 [00:04<00:02,  3.85it/s] 50%|█████     | 8/16 [00:04<00:01,  4.56it/s] 56%|█████▋    | 9/16 [00:04<00:01,  5.21it/s] 62%|██████▎   | 10/16 [00:04<00:01,  5.76it/s] 69%|██████▉   | 11/16 [00:04<00:00,  6.22it/s] 75%|███████▌  | 12/16 [00:04<00:00,  6.58it/s] 81%|████████▏ | 13/16 [00:05<00:00,  6.85it/s] 88%|████████▊ | 14/16 [00:05<00:00,  7.06it/s] 94%|█████████▍| 15/16 [00:05<00:00,  7.20it/s]100%|██████████| 16/16 [00:05<00:00,  2.92it/s]
=> result
* total: 1,549
* correct: 1,523
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.7%
Elapsed: 0:00:05
+ sh scripts/rpo_prime/base2new_test_sdl.sh caltech101 3 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
800 613 916
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      613
# test     916
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 9)
Evaluate on the *test* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:03<00:27,  3.07s/it] 20%|██        | 2/10 [00:03<00:10,  1.34s/it] 30%|███       | 3/10 [00:03<00:05,  1.27it/s] 40%|████      | 4/10 [00:03<00:03,  1.89it/s] 50%|█████     | 5/10 [00:03<00:01,  2.59it/s] 60%|██████    | 6/10 [00:03<00:01,  3.34it/s] 70%|███████   | 7/10 [00:03<00:00,  4.08it/s] 80%|████████  | 8/10 [00:03<00:00,  4.79it/s] 90%|█████████ | 9/10 [00:04<00:00,  5.41it/s]100%|██████████| 10/10 [00:04<00:00,  2.35it/s]
=> result
* total: 916
* correct: 863
* accuracy: 94.2%
* error: 5.8%
* macro_f1: 94.4%
+ for dataset in eurosat dtd oxford_flowers stanford_cars oxford_pets food101 ucf101 caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh sun397 1 0 main_tmp1_0.1sdl 16
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
3184 1990 9950
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  199
# train_x  3,184
# val      1,990
# test     9,950
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Found checkpoint at output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1 (will resume training)
Loading checkpoint from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30"
Loaded model weights
Loaded optimizer
Loaded scheduler
Previous epoch: 30
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 29)
Evaluate on the *test* set
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:08<13:26,  8.15s/it]  2%|▏         | 2/100 [00:08<06:07,  3.75s/it]  3%|▎         | 3/100 [00:09<03:45,  2.32s/it]  4%|▍         | 4/100 [00:10<02:36,  1.63s/it]  5%|▌         | 5/100 [00:10<01:54,  1.21s/it]  6%|▌         | 6/100 [00:10<01:30,  1.04it/s]  7%|▋         | 7/100 [00:11<01:13,  1.26it/s]  8%|▊         | 8/100 [00:11<01:02,  1.47it/s]  9%|▉         | 9/100 [00:12<00:56,  1.60it/s] 10%|█         | 10/100 [00:12<00:51,  1.76it/s] 11%|█         | 11/100 [00:13<00:45,  1.95it/s] 12%|█▏        | 12/100 [00:13<00:44,  1.96it/s] 13%|█▎        | 13/100 [00:14<00:41,  2.10it/s] 14%|█▍        | 14/100 [00:14<00:39,  2.18it/s] 15%|█▌        | 15/100 [00:14<00:38,  2.21it/s] 16%|█▌        | 16/100 [00:15<00:36,  2.31it/s] 17%|█▋        | 17/100 [00:15<00:36,  2.30it/s] 18%|█▊        | 18/100 [00:16<00:36,  2.28it/s] 19%|█▉        | 19/100 [00:16<00:34,  2.36it/s] 20%|██        | 20/100 [00:17<00:34,  2.35it/s] 21%|██        | 21/100 [00:17<00:33,  2.33it/s] 22%|██▏       | 22/100 [00:17<00:32,  2.37it/s] 23%|██▎       | 23/100 [00:18<00:31,  2.41it/s] 24%|██▍       | 24/100 [00:18<00:30,  2.47it/s] 25%|██▌       | 25/100 [00:19<00:30,  2.42it/s] 26%|██▌       | 26/100 [00:19<00:30,  2.46it/s] 27%|██▋       | 27/100 [00:19<00:30,  2.40it/s] 28%|██▊       | 28/100 [00:20<00:30,  2.34it/s] 29%|██▉       | 29/100 [00:20<00:31,  2.26it/s] 30%|███       | 30/100 [00:21<00:32,  2.18it/s] 31%|███       | 31/100 [00:21<00:31,  2.17it/s] 32%|███▏      | 32/100 [00:22<00:31,  2.15it/s] 33%|███▎      | 33/100 [00:22<00:31,  2.15it/s] 34%|███▍      | 34/100 [00:23<00:30,  2.14it/s] 35%|███▌      | 35/100 [00:23<00:30,  2.13it/s] 36%|███▌      | 36/100 [00:24<00:29,  2.16it/s] 37%|███▋      | 37/100 [00:24<00:28,  2.21it/s] 38%|███▊      | 38/100 [00:25<00:27,  2.22it/s] 39%|███▉      | 39/100 [00:25<00:27,  2.24it/s] 40%|████      | 40/100 [00:25<00:25,  2.32it/s] 41%|████      | 41/100 [00:26<00:25,  2.28it/s] 42%|████▏     | 42/100 [00:26<00:25,  2.25it/s] 43%|████▎     | 43/100 [00:27<00:25,  2.26it/s] 44%|████▍     | 44/100 [00:27<00:23,  2.40it/s] 45%|████▌     | 45/100 [00:27<00:22,  2.43it/s] 46%|████▌     | 46/100 [00:28<00:21,  2.54it/s] 47%|████▋     | 47/100 [00:28<00:21,  2.48it/s] 48%|████▊     | 48/100 [00:29<00:20,  2.53it/s] 49%|████▉     | 49/100 [00:29<00:20,  2.48it/s] 50%|█████     | 50/100 [00:29<00:20,  2.44it/s] 51%|█████     | 51/100 [00:30<00:20,  2.34it/s] 52%|█████▏    | 52/100 [00:30<00:20,  2.36it/s] 53%|█████▎    | 53/100 [00:31<00:19,  2.43it/s] 54%|█████▍    | 54/100 [00:31<00:18,  2.50it/s] 55%|█████▌    | 55/100 [00:31<00:17,  2.55it/s] 56%|█████▌    | 56/100 [00:32<00:18,  2.44it/s] 57%|█████▋    | 57/100 [00:32<00:18,  2.32it/s] 58%|█████▊    | 58/100 [00:33<00:18,  2.28it/s] 59%|█████▉    | 59/100 [00:33<00:17,  2.36it/s] 60%|██████    | 60/100 [00:34<00:16,  2.42it/s] 61%|██████    | 61/100 [00:34<00:16,  2.43it/s] 62%|██████▏   | 62/100 [00:34<00:15,  2.40it/s] 63%|██████▎   | 63/100 [00:35<00:15,  2.34it/s] 64%|██████▍   | 64/100 [00:35<00:15,  2.28it/s] 65%|██████▌   | 65/100 [00:36<00:15,  2.29it/s] 66%|██████▌   | 66/100 [00:36<00:14,  2.33it/s] 67%|██████▋   | 67/100 [00:37<00:14,  2.30it/s] 68%|██████▊   | 68/100 [00:37<00:14,  2.25it/s] 69%|██████▉   | 69/100 [00:38<00:12,  2.39it/s] 70%|███████   | 70/100 [00:38<00:11,  2.54it/s] 71%|███████   | 71/100 [00:38<00:11,  2.60it/s] 72%|███████▏  | 72/100 [00:39<00:10,  2.71it/s] 73%|███████▎  | 73/100 [00:39<00:09,  2.78it/s] 74%|███████▍  | 74/100 [00:39<00:09,  2.87it/s] 75%|███████▌  | 75/100 [00:40<00:08,  2.92it/s] 76%|███████▌  | 76/100 [00:40<00:08,  2.98it/s] 77%|███████▋  | 77/100 [00:40<00:07,  3.01it/s] 78%|███████▊  | 78/100 [00:40<00:07,  3.07it/s] 79%|███████▉  | 79/100 [00:41<00:06,  3.16it/s] 80%|████████  | 80/100 [00:41<00:06,  3.25it/s] 81%|████████  | 81/100 [00:41<00:05,  3.37it/s] 82%|████████▏ | 82/100 [00:42<00:04,  3.66it/s] 83%|████████▎ | 83/100 [00:42<00:04,  4.07it/s] 84%|████████▍ | 84/100 [00:42<00:03,  4.41it/s] 85%|████████▌ | 85/100 [00:42<00:03,  4.68it/s] 86%|████████▌ | 86/100 [00:42<00:02,  4.90it/s] 87%|████████▋ | 87/100 [00:42<00:02,  5.06it/s] 88%|████████▊ | 88/100 [00:43<00:02,  5.18it/s] 89%|████████▉ | 89/100 [00:43<00:02,  5.25it/s] 90%|█████████ | 90/100 [00:43<00:01,  5.31it/s] 91%|█████████ | 91/100 [00:43<00:01,  5.35it/s] 92%|█████████▏| 92/100 [00:43<00:01,  5.38it/s] 93%|█████████▎| 93/100 [00:44<00:01,  5.41it/s] 94%|█████████▍| 94/100 [00:44<00:01,  5.43it/s] 95%|█████████▌| 95/100 [00:44<00:00,  5.44it/s] 96%|█████████▌| 96/100 [00:44<00:00,  5.45it/s] 97%|█████████▋| 97/100 [00:44<00:00,  5.46it/s] 98%|█████████▊| 98/100 [00:44<00:00,  5.45it/s] 99%|█████████▉| 99/100 [00:45<00:00,  5.46it/s]100%|██████████| 100/100 [00:45<00:00,  5.99it/s]100%|██████████| 100/100 [00:45<00:00,  2.20it/s]
=> result
* total: 9,950
* correct: 8,131
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 81.5%
Elapsed: 0:00:45
+ sh scripts/rpo_prime/base2new_test_sdl.sh sun397 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
3168 1980 9900
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  198
# train_x  3,168
# val      1,980
# test     9,900
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 29)
Evaluate on the *test* set
  0%|          | 0/99 [00:00<?, ?it/s]  1%|          | 1/99 [00:09<16:09,  9.90s/it]  2%|▏         | 2/99 [00:10<07:01,  4.34s/it]  3%|▎         | 3/99 [00:10<04:02,  2.53s/it]  4%|▍         | 4/99 [00:11<02:37,  1.66s/it]  5%|▌         | 5/99 [00:11<01:50,  1.18s/it]  6%|▌         | 6/99 [00:11<01:23,  1.11it/s]  7%|▋         | 7/99 [00:12<01:05,  1.40it/s]  8%|▊         | 8/99 [00:12<00:53,  1.70it/s]  9%|▉         | 9/99 [00:12<00:45,  1.96it/s] 10%|█         | 10/99 [00:13<00:40,  2.19it/s] 11%|█         | 11/99 [00:13<00:37,  2.36it/s] 12%|█▏        | 12/99 [00:13<00:35,  2.42it/s] 13%|█▎        | 13/99 [00:14<00:33,  2.55it/s] 14%|█▍        | 14/99 [00:14<00:34,  2.48it/s] 15%|█▌        | 15/99 [00:14<00:34,  2.45it/s] 16%|█▌        | 16/99 [00:15<00:34,  2.39it/s] 17%|█▋        | 17/99 [00:15<00:34,  2.35it/s] 18%|█▊        | 18/99 [00:16<00:36,  2.24it/s] 19%|█▉        | 19/99 [00:16<00:36,  2.18it/s] 20%|██        | 20/99 [00:17<00:37,  2.11it/s] 21%|██        | 21/99 [00:17<00:36,  2.15it/s] 22%|██▏       | 22/99 [00:18<00:35,  2.16it/s] 23%|██▎       | 23/99 [00:18<00:35,  2.14it/s] 24%|██▍       | 24/99 [00:19<00:34,  2.20it/s] 25%|██▌       | 25/99 [00:19<00:33,  2.22it/s] 26%|██▋       | 26/99 [00:20<00:32,  2.28it/s] 27%|██▋       | 27/99 [00:20<00:29,  2.43it/s] 28%|██▊       | 28/99 [00:20<00:27,  2.54it/s] 29%|██▉       | 29/99 [00:21<00:26,  2.66it/s] 30%|███       | 30/99 [00:21<00:25,  2.74it/s] 31%|███▏      | 31/99 [00:21<00:24,  2.74it/s] 32%|███▏      | 32/99 [00:22<00:24,  2.69it/s] 33%|███▎      | 33/99 [00:22<00:24,  2.65it/s] 34%|███▍      | 34/99 [00:22<00:25,  2.52it/s] 35%|███▌      | 35/99 [00:23<00:27,  2.34it/s] 36%|███▋      | 36/99 [00:23<00:28,  2.24it/s] 37%|███▋      | 37/99 [00:24<00:27,  2.22it/s] 38%|███▊      | 38/99 [00:24<00:27,  2.23it/s] 39%|███▉      | 39/99 [00:25<00:26,  2.23it/s] 40%|████      | 40/99 [00:25<00:25,  2.35it/s] 41%|████▏     | 41/99 [00:26<00:24,  2.35it/s] 42%|████▏     | 42/99 [00:26<00:23,  2.38it/s] 43%|████▎     | 43/99 [00:26<00:22,  2.51it/s] 44%|████▍     | 44/99 [00:27<00:20,  2.64it/s] 45%|████▌     | 45/99 [00:27<00:20,  2.66it/s] 46%|████▋     | 46/99 [00:28<00:20,  2.52it/s] 47%|████▋     | 47/99 [00:28<00:21,  2.43it/s] 48%|████▊     | 48/99 [00:28<00:21,  2.35it/s] 49%|████▉     | 49/99 [00:29<00:20,  2.44it/s] 51%|█████     | 50/99 [00:29<00:20,  2.40it/s] 52%|█████▏    | 51/99 [00:30<00:20,  2.38it/s] 53%|█████▎    | 52/99 [00:30<00:19,  2.35it/s] 54%|█████▎    | 53/99 [00:31<00:19,  2.33it/s] 55%|█████▍    | 54/99 [00:31<00:19,  2.32it/s] 56%|█████▌    | 55/99 [00:31<00:19,  2.24it/s] 57%|█████▋    | 56/99 [00:32<00:18,  2.32it/s] 58%|█████▊    | 57/99 [00:32<00:17,  2.46it/s] 59%|█████▊    | 58/99 [00:33<00:16,  2.50it/s] 60%|█████▉    | 59/99 [00:33<00:15,  2.59it/s] 61%|██████    | 60/99 [00:33<00:15,  2.47it/s] 62%|██████▏   | 61/99 [00:34<00:16,  2.33it/s] 63%|██████▎   | 62/99 [00:34<00:16,  2.27it/s] 64%|██████▎   | 63/99 [00:35<00:16,  2.19it/s] 65%|██████▍   | 64/99 [00:35<00:15,  2.25it/s] 66%|██████▌   | 65/99 [00:36<00:14,  2.30it/s] 67%|██████▋   | 66/99 [00:36<00:13,  2.39it/s] 68%|██████▊   | 67/99 [00:36<00:13,  2.37it/s] 69%|██████▊   | 68/99 [00:37<00:13,  2.36it/s] 70%|██████▉   | 69/99 [00:37<00:12,  2.44it/s] 71%|███████   | 70/99 [00:38<00:11,  2.64it/s] 72%|███████▏  | 71/99 [00:38<00:10,  2.78it/s] 73%|███████▎  | 72/99 [00:38<00:09,  2.88it/s] 74%|███████▎  | 73/99 [00:39<00:08,  3.03it/s] 75%|███████▍  | 74/99 [00:39<00:07,  3.15it/s] 76%|███████▌  | 75/99 [00:39<00:07,  3.26it/s] 77%|███████▋  | 76/99 [00:39<00:07,  3.26it/s] 78%|███████▊  | 77/99 [00:40<00:06,  3.33it/s] 79%|███████▉  | 78/99 [00:40<00:06,  3.41it/s] 80%|███████▉  | 79/99 [00:40<00:05,  3.49it/s] 81%|████████  | 80/99 [00:40<00:05,  3.72it/s] 82%|████████▏ | 81/99 [00:41<00:04,  3.91it/s] 83%|████████▎ | 82/99 [00:41<00:04,  4.24it/s] 84%|████████▍ | 83/99 [00:41<00:03,  4.53it/s] 85%|████████▍ | 84/99 [00:41<00:03,  4.76it/s] 86%|████████▌ | 85/99 [00:41<00:02,  4.92it/s] 87%|████████▋ | 86/99 [00:42<00:02,  5.04it/s] 88%|████████▊ | 87/99 [00:42<00:02,  5.12it/s] 89%|████████▉ | 88/99 [00:42<00:02,  5.19it/s] 90%|████████▉ | 89/99 [00:42<00:01,  5.24it/s] 91%|█████████ | 90/99 [00:42<00:01,  5.28it/s] 92%|█████████▏| 91/99 [00:43<00:01,  5.31it/s] 93%|█████████▎| 92/99 [00:43<00:01,  5.33it/s] 94%|█████████▍| 93/99 [00:43<00:01,  5.35it/s] 95%|█████████▍| 94/99 [00:43<00:00,  5.36it/s] 96%|█████████▌| 95/99 [00:43<00:00,  5.35it/s] 97%|█████████▋| 96/99 [00:43<00:00,  5.34it/s] 98%|█████████▊| 97/99 [00:44<00:00,  5.36it/s] 99%|█████████▉| 98/99 [00:44<00:00,  5.38it/s]100%|██████████| 99/99 [00:44<00:00,  5.38it/s]100%|██████████| 99/99 [00:44<00:00,  2.22it/s]
=> result
* total: 9,900
* correct: 7,752
* accuracy: 78.3%
* error: 21.7%
* macro_f1: 77.4%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh sun397 2 0 main_tmp1_0.1sdl 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
3184 1990 9950
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  199
# train_x  3,184
# val      1,990
# test     9,950
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Found checkpoint at output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2 (will resume training)
Loading checkpoint from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar"
Loaded model weights
Loaded optimizer
Loaded scheduler
Previous epoch: 15
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [16/30] batch [20/796] time 0.382 (0.518) data 0.000 (0.069) loss 0.2991 (1.4708) lr 5.0000e-03 eta 1:42:50
epoch [16/30] batch [40/796] time 0.401 (0.447) data 0.000 (0.034) loss 0.5625 (1.2425) lr 5.0000e-03 eta 1:28:39
epoch [16/30] batch [60/796] time 0.371 (0.427) data 0.000 (0.023) loss 0.5718 (1.4135) lr 5.0000e-03 eta 1:24:28
epoch [16/30] batch [80/796] time 0.359 (0.416) data 0.000 (0.017) loss 0.1152 (1.4722) lr 5.0000e-03 eta 1:22:14
epoch [16/30] batch [100/796] time 0.359 (0.407) data 0.000 (0.014) loss 4.4180 (1.5719) lr 5.0000e-03 eta 1:20:22
epoch [16/30] batch [120/796] time 0.418 (0.403) data 0.000 (0.012) loss 1.2051 (1.5633) lr 5.0000e-03 eta 1:19:17
epoch [16/30] batch [140/796] time 0.403 (0.400) data 0.000 (0.010) loss 1.8770 (1.5705) lr 5.0000e-03 eta 1:18:41
epoch [16/30] batch [160/796] time 0.428 (0.399) data 0.000 (0.009) loss 0.4438 (1.5703) lr 5.0000e-03 eta 1:18:19
epoch [16/30] batch [180/796] time 0.392 (0.396) data 0.000 (0.008) loss 1.5693 (1.5679) lr 5.0000e-03 eta 1:17:41
epoch [16/30] batch [200/796] time 0.392 (0.395) data 0.000 (0.007) loss 0.0898 (1.5658) lr 5.0000e-03 eta 1:17:18
epoch [16/30] batch [220/796] time 0.400 (0.394) data 0.000 (0.006) loss 1.0127 (1.5798) lr 5.0000e-03 eta 1:17:02
epoch [16/30] batch [240/796] time 0.421 (0.394) data 0.000 (0.006) loss 3.8203 (1.5887) lr 5.0000e-03 eta 1:16:48
epoch [16/30] batch [260/796] time 0.362 (0.393) data 0.000 (0.006) loss 0.7593 (1.6074) lr 5.0000e-03 eta 1:16:25
epoch [16/30] batch [280/796] time 0.402 (0.392) data 0.000 (0.005) loss 1.5059 (1.5820) lr 5.0000e-03 eta 1:16:07
epoch [16/30] batch [300/796] time 0.395 (0.391) data 0.000 (0.005) loss 0.4861 (1.6178) lr 5.0000e-03 eta 1:15:56
epoch [16/30] batch [320/796] time 0.370 (0.391) data 0.000 (0.005) loss 1.5098 (1.6013) lr 5.0000e-03 eta 1:15:46
epoch [16/30] batch [340/796] time 0.368 (0.391) data 0.000 (0.004) loss 1.5098 (1.6004) lr 5.0000e-03 eta 1:15:34
epoch [16/30] batch [360/796] time 0.401 (0.391) data 0.000 (0.004) loss 0.0659 (1.6259) lr 5.0000e-03 eta 1:15:25
epoch [16/30] batch [380/796] time 0.390 (0.390) data 0.000 (0.004) loss 1.3037 (1.6519) lr 5.0000e-03 eta 1:15:09
epoch [16/30] batch [400/796] time 0.396 (0.390) data 0.000 (0.004) loss 1.2686 (1.6411) lr 5.0000e-03 eta 1:15:00
epoch [16/30] batch [420/796] time 0.364 (0.390) data 0.000 (0.004) loss 4.3320 (1.6464) lr 5.0000e-03 eta 1:14:48
epoch [16/30] batch [440/796] time 0.372 (0.390) data 0.000 (0.003) loss 6.2266 (1.6456) lr 5.0000e-03 eta 1:14:39
epoch [16/30] batch [460/796] time 0.371 (0.389) data 0.000 (0.003) loss 0.2297 (1.6382) lr 5.0000e-03 eta 1:14:30
epoch [16/30] batch [480/796] time 0.360 (0.389) data 0.000 (0.003) loss 1.2217 (1.6228) lr 5.0000e-03 eta 1:14:22
epoch [16/30] batch [500/796] time 0.382 (0.389) data 0.000 (0.003) loss 3.3809 (1.6274) lr 5.0000e-03 eta 1:14:15
epoch [16/30] batch [520/796] time 0.367 (0.389) data 0.000 (0.003) loss 0.4131 (1.6121) lr 5.0000e-03 eta 1:14:02
epoch [16/30] batch [540/796] time 0.368 (0.389) data 0.000 (0.003) loss 0.0678 (1.6115) lr 5.0000e-03 eta 1:13:53
epoch [16/30] batch [560/796] time 0.355 (0.389) data 0.000 (0.003) loss 1.2344 (1.6197) lr 5.0000e-03 eta 1:13:42
epoch [16/30] batch [580/796] time 0.394 (0.388) data 0.000 (0.003) loss 3.4043 (1.6286) lr 5.0000e-03 eta 1:13:31
epoch [16/30] batch [600/796] time 0.397 (0.388) data 0.000 (0.003) loss 3.9941 (1.6316) lr 5.0000e-03 eta 1:13:22
epoch [16/30] batch [620/796] time 0.417 (0.388) data 0.000 (0.002) loss 0.2107 (1.6355) lr 5.0000e-03 eta 1:13:13
epoch [16/30] batch [640/796] time 0.363 (0.388) data 0.000 (0.002) loss 1.7988 (1.6378) lr 5.0000e-03 eta 1:13:03
epoch [16/30] batch [660/796] time 0.384 (0.388) data 0.000 (0.002) loss 0.7344 (1.6358) lr 5.0000e-03 eta 1:12:54
epoch [16/30] batch [680/796] time 0.359 (0.388) data 0.000 (0.002) loss 1.3760 (1.6264) lr 5.0000e-03 eta 1:12:44
epoch [16/30] batch [700/796] time 0.403 (0.388) data 0.000 (0.002) loss 1.0889 (1.6257) lr 5.0000e-03 eta 1:12:37
epoch [16/30] batch [720/796] time 0.357 (0.387) data 0.000 (0.002) loss 2.3945 (1.6247) lr 5.0000e-03 eta 1:12:26
epoch [16/30] batch [740/796] time 0.400 (0.387) data 0.000 (0.002) loss 1.9873 (1.6262) lr 5.0000e-03 eta 1:12:16
epoch [16/30] batch [760/796] time 0.373 (0.387) data 0.000 (0.002) loss 0.6279 (1.6315) lr 5.0000e-03 eta 1:12:06
epoch [16/30] batch [780/796] time 0.347 (0.386) data 0.000 (0.002) loss 2.5684 (1.6400) lr 5.0000e-03 eta 1:11:52
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:50,  5.80s/it] 10%|█         | 2/20 [00:06<00:49,  2.76s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.64s/it] 20%|██        | 4/20 [00:07<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.24it/s] 30%|███       | 6/20 [00:07<00:08,  1.59it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.93it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.51it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.90it/s] 60%|██████    | 12/20 [00:09<00:02,  3.12it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.32it/s] 70%|███████   | 14/20 [00:09<00:01,  3.66it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.93it/s] 80%|████████  | 16/20 [00:10<00:00,  4.20it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.04it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.01it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.37it/s]100%|██████████| 20/20 [00:11<00:00,  4.73it/s]100%|██████████| 20/20 [00:11<00:00,  1.79it/s]=> result
* total: 1,990
* correct: 1,601
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 80.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [17/30] batch [20/796] time 0.354 (0.432) data 0.000 (0.042) loss 0.2795 (1.3322) lr 4.4774e-03 eta 1:20:07
epoch [17/30] batch [40/796] time 0.387 (0.405) data 0.000 (0.021) loss 0.3489 (1.5553) lr 4.4774e-03 eta 1:15:00
epoch [17/30] batch [60/796] time 0.376 (0.398) data 0.000 (0.014) loss 0.8672 (1.5192) lr 4.4774e-03 eta 1:13:35
epoch [17/30] batch [80/796] time 0.383 (0.395) data 0.000 (0.011) loss 0.3230 (1.5312) lr 4.4774e-03 eta 1:12:49
epoch [17/30] batch [100/796] time 0.400 (0.392) data 0.000 (0.009) loss 2.4355 (1.5994) lr 4.4774e-03 eta 1:12:10
epoch [17/30] batch [120/796] time 0.398 (0.392) data 0.000 (0.007) loss 2.0742 (1.6025) lr 4.4774e-03 eta 1:12:02
epoch [17/30] batch [140/796] time 0.405 (0.392) data 0.000 (0.006) loss 0.0927 (1.5722) lr 4.4774e-03 eta 1:11:50
epoch [17/30] batch [160/796] time 0.384 (0.390) data 0.000 (0.005) loss 1.0186 (1.5627) lr 4.4774e-03 eta 1:11:26
epoch [17/30] batch [180/796] time 0.386 (0.389) data 0.000 (0.005) loss 2.3672 (1.5291) lr 4.4774e-03 eta 1:11:03
epoch [17/30] batch [200/796] time 0.381 (0.388) data 0.000 (0.004) loss 0.4343 (1.5390) lr 4.4774e-03 eta 1:10:44
epoch [17/30] batch [220/796] time 0.366 (0.388) data 0.000 (0.004) loss 1.5547 (1.5294) lr 4.4774e-03 eta 1:10:33
epoch [17/30] batch [240/796] time 0.382 (0.387) data 0.000 (0.004) loss 1.4795 (1.5527) lr 4.4774e-03 eta 1:10:20
epoch [17/30] batch [260/796] time 0.394 (0.387) data 0.000 (0.003) loss 2.4355 (1.5546) lr 4.4774e-03 eta 1:10:12
epoch [17/30] batch [280/796] time 0.366 (0.387) data 0.000 (0.003) loss 2.0273 (1.5255) lr 4.4774e-03 eta 1:10:05
epoch [17/30] batch [300/796] time 0.363 (0.387) data 0.000 (0.003) loss 0.3066 (1.5207) lr 4.4774e-03 eta 1:09:55
epoch [17/30] batch [320/796] time 0.370 (0.387) data 0.000 (0.003) loss 1.1436 (1.5113) lr 4.4774e-03 eta 1:09:47
epoch [17/30] batch [340/796] time 0.400 (0.387) data 0.000 (0.003) loss 1.9961 (1.4713) lr 4.4774e-03 eta 1:09:38
epoch [17/30] batch [360/796] time 0.371 (0.386) data 0.000 (0.003) loss 1.1943 (1.5121) lr 4.4774e-03 eta 1:09:25
epoch [17/30] batch [380/796] time 0.358 (0.386) data 0.000 (0.002) loss 0.0924 (1.5512) lr 4.4774e-03 eta 1:09:20
epoch [17/30] batch [400/796] time 0.411 (0.387) data 0.000 (0.002) loss 1.6455 (1.5462) lr 4.4774e-03 eta 1:09:13
epoch [17/30] batch [420/796] time 0.399 (0.386) data 0.000 (0.002) loss 1.6064 (1.5390) lr 4.4774e-03 eta 1:09:03
epoch [17/30] batch [440/796] time 0.362 (0.386) data 0.000 (0.002) loss 1.4053 (1.5198) lr 4.4774e-03 eta 1:08:53
epoch [17/30] batch [460/796] time 0.367 (0.386) data 0.000 (0.002) loss 2.0176 (1.5401) lr 4.4774e-03 eta 1:08:41
epoch [17/30] batch [480/796] time 0.456 (0.386) data 0.000 (0.002) loss 0.8770 (1.5300) lr 4.4774e-03 eta 1:08:34
epoch [17/30] batch [500/796] time 0.391 (0.386) data 0.000 (0.002) loss 1.5195 (1.5325) lr 4.4774e-03 eta 1:08:25
epoch [17/30] batch [520/796] time 0.426 (0.386) data 0.000 (0.002) loss 1.7725 (1.5533) lr 4.4774e-03 eta 1:08:17
epoch [17/30] batch [540/796] time 0.357 (0.386) data 0.000 (0.002) loss 0.5537 (1.5627) lr 4.4774e-03 eta 1:08:10
epoch [17/30] batch [560/796] time 0.413 (0.386) data 0.000 (0.002) loss 2.1172 (1.5545) lr 4.4774e-03 eta 1:08:04
epoch [17/30] batch [580/796] time 0.412 (0.386) data 0.000 (0.002) loss 0.7246 (1.5582) lr 4.4774e-03 eta 1:07:57
epoch [17/30] batch [600/796] time 0.375 (0.386) data 0.000 (0.002) loss 2.5254 (1.5682) lr 4.4774e-03 eta 1:07:47
epoch [17/30] batch [620/796] time 0.404 (0.386) data 0.000 (0.002) loss 4.2852 (1.5628) lr 4.4774e-03 eta 1:07:39
epoch [17/30] batch [640/796] time 0.362 (0.386) data 0.000 (0.002) loss 1.6016 (1.5707) lr 4.4774e-03 eta 1:07:30
epoch [17/30] batch [660/796] time 0.372 (0.386) data 0.000 (0.002) loss 1.2939 (1.5796) lr 4.4774e-03 eta 1:07:25
epoch [17/30] batch [680/796] time 0.379 (0.386) data 0.000 (0.001) loss 1.8115 (1.5839) lr 4.4774e-03 eta 1:07:15
epoch [17/30] batch [700/796] time 0.364 (0.385) data 0.000 (0.001) loss 1.1074 (1.5800) lr 4.4774e-03 eta 1:07:05
epoch [17/30] batch [720/796] time 0.387 (0.385) data 0.000 (0.001) loss 1.5879 (1.5826) lr 4.4774e-03 eta 1:06:58
epoch [17/30] batch [740/796] time 0.376 (0.385) data 0.000 (0.001) loss 1.8262 (1.5733) lr 4.4774e-03 eta 1:06:48
epoch [17/30] batch [760/796] time 0.371 (0.385) data 0.000 (0.001) loss 1.2832 (1.5720) lr 4.4774e-03 eta 1:06:41
epoch [17/30] batch [780/796] time 0.348 (0.385) data 0.000 (0.001) loss 3.5098 (1.5816) lr 4.4774e-03 eta 1:06:25
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:52,  5.91s/it] 10%|█         | 2/20 [00:06<00:51,  2.85s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.91it/s] 60%|██████    | 12/20 [00:09<00:02,  3.11it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.49it/s] 70%|███████   | 14/20 [00:09<00:01,  3.63it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.90it/s] 80%|████████  | 16/20 [00:10<00:00,  4.06it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.97it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.60it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.02it/s]100%|██████████| 20/20 [00:11<00:00,  4.43it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,602
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 80.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/796] time 0.407 (0.437) data 0.000 (0.042) loss 1.0918 (1.5200) lr 3.9604e-03 eta 1:15:13
epoch [18/30] batch [40/796] time 0.368 (0.411) data 0.000 (0.021) loss 0.6431 (1.5649) lr 3.9604e-03 eta 1:10:38
epoch [18/30] batch [60/796] time 0.388 (0.403) data 0.000 (0.014) loss 0.6401 (1.5157) lr 3.9604e-03 eta 1:09:10
epoch [18/30] batch [80/796] time 0.374 (0.398) data 0.000 (0.011) loss 1.5986 (1.4362) lr 3.9604e-03 eta 1:08:09
epoch [18/30] batch [100/796] time 0.363 (0.394) data 0.000 (0.009) loss 1.5039 (1.3713) lr 3.9604e-03 eta 1:07:13
epoch [18/30] batch [120/796] time 0.357 (0.391) data 0.000 (0.007) loss 0.5752 (1.3506) lr 3.9604e-03 eta 1:06:41
epoch [18/30] batch [140/796] time 0.387 (0.390) data 0.000 (0.006) loss 2.9414 (1.3440) lr 3.9604e-03 eta 1:06:25
epoch [18/30] batch [160/796] time 0.398 (0.389) data 0.000 (0.005) loss 3.6211 (1.3742) lr 3.9604e-03 eta 1:06:01
epoch [18/30] batch [180/796] time 0.389 (0.388) data 0.000 (0.005) loss 0.4272 (1.4018) lr 3.9604e-03 eta 1:05:42
epoch [18/30] batch [200/796] time 0.364 (0.388) data 0.000 (0.004) loss 0.1660 (1.4168) lr 3.9604e-03 eta 1:05:34
epoch [18/30] batch [220/796] time 0.359 (0.387) data 0.000 (0.004) loss 0.5962 (1.4427) lr 3.9604e-03 eta 1:05:21
epoch [18/30] batch [240/796] time 0.366 (0.387) data 0.000 (0.004) loss 1.3330 (1.4852) lr 3.9604e-03 eta 1:05:10
epoch [18/30] batch [260/796] time 0.385 (0.387) data 0.000 (0.003) loss 0.4773 (1.4885) lr 3.9604e-03 eta 1:04:59
epoch [18/30] batch [280/796] time 0.399 (0.386) data 0.001 (0.003) loss 1.5029 (1.4814) lr 3.9604e-03 eta 1:04:46
epoch [18/30] batch [300/796] time 0.404 (0.386) data 0.000 (0.003) loss 1.0244 (1.5116) lr 3.9604e-03 eta 1:04:37
epoch [18/30] batch [320/796] time 0.358 (0.386) data 0.000 (0.003) loss 3.2402 (1.5234) lr 3.9604e-03 eta 1:04:28
epoch [18/30] batch [340/796] time 0.363 (0.386) data 0.000 (0.003) loss 0.5303 (1.5727) lr 3.9604e-03 eta 1:04:21
epoch [18/30] batch [360/796] time 0.358 (0.386) data 0.000 (0.003) loss 2.3086 (1.5740) lr 3.9604e-03 eta 1:04:13
epoch [18/30] batch [380/796] time 0.426 (0.386) data 0.000 (0.002) loss 1.9453 (1.5882) lr 3.9604e-03 eta 1:04:06
epoch [18/30] batch [400/796] time 0.360 (0.386) data 0.000 (0.002) loss 0.4216 (1.5864) lr 3.9604e-03 eta 1:03:57
epoch [18/30] batch [420/796] time 0.410 (0.386) data 0.000 (0.002) loss 0.3633 (1.5905) lr 3.9604e-03 eta 1:03:50
epoch [18/30] batch [440/796] time 0.355 (0.386) data 0.000 (0.002) loss 0.5356 (1.5967) lr 3.9604e-03 eta 1:03:41
epoch [18/30] batch [460/796] time 0.376 (0.386) data 0.000 (0.002) loss 0.9062 (1.5790) lr 3.9604e-03 eta 1:03:34
epoch [18/30] batch [480/796] time 0.361 (0.386) data 0.000 (0.002) loss 0.2360 (1.5994) lr 3.9604e-03 eta 1:03:28
epoch [18/30] batch [500/796] time 0.417 (0.386) data 0.000 (0.002) loss 0.3909 (1.5841) lr 3.9604e-03 eta 1:03:20
epoch [18/30] batch [520/796] time 0.412 (0.386) data 0.000 (0.002) loss 2.7051 (1.5813) lr 3.9604e-03 eta 1:03:13
epoch [18/30] batch [540/796] time 0.356 (0.386) data 0.000 (0.002) loss 3.2578 (1.6003) lr 3.9604e-03 eta 1:03:07
epoch [18/30] batch [560/796] time 0.394 (0.386) data 0.000 (0.002) loss 3.1816 (1.6205) lr 3.9604e-03 eta 1:02:56
epoch [18/30] batch [580/796] time 0.368 (0.386) data 0.000 (0.002) loss 2.6270 (1.6229) lr 3.9604e-03 eta 1:02:45
epoch [18/30] batch [600/796] time 0.384 (0.386) data 0.000 (0.002) loss 0.9609 (1.6221) lr 3.9604e-03 eta 1:02:38
epoch [18/30] batch [620/796] time 0.381 (0.386) data 0.000 (0.002) loss 0.1421 (1.6111) lr 3.9604e-03 eta 1:02:32
epoch [18/30] batch [640/796] time 0.361 (0.386) data 0.000 (0.002) loss 2.2363 (1.6015) lr 3.9604e-03 eta 1:02:24
epoch [18/30] batch [660/796] time 0.418 (0.386) data 0.000 (0.002) loss 0.2352 (1.6089) lr 3.9604e-03 eta 1:02:16
epoch [18/30] batch [680/796] time 0.397 (0.386) data 0.000 (0.001) loss 1.4014 (1.6050) lr 3.9604e-03 eta 1:02:08
epoch [18/30] batch [700/796] time 0.401 (0.386) data 0.000 (0.001) loss 0.0182 (1.5955) lr 3.9604e-03 eta 1:02:01
epoch [18/30] batch [720/796] time 0.388 (0.386) data 0.000 (0.001) loss 2.8926 (1.5842) lr 3.9604e-03 eta 1:01:53
epoch [18/30] batch [740/796] time 0.368 (0.385) data 0.000 (0.001) loss 0.6895 (1.5835) lr 3.9604e-03 eta 1:01:43
epoch [18/30] batch [760/796] time 0.364 (0.386) data 0.000 (0.001) loss 0.9766 (1.5709) lr 3.9604e-03 eta 1:01:37
epoch [18/30] batch [780/796] time 0.347 (0.385) data 0.000 (0.001) loss 2.7891 (1.5736) lr 3.9604e-03 eta 1:01:22
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:48,  5.70s/it] 10%|█         | 2/20 [00:06<00:52,  2.89s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.71s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.87it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.47it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.92it/s] 60%|██████    | 12/20 [00:09<00:02,  3.22it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.50it/s] 70%|███████   | 14/20 [00:09<00:01,  3.63it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.84it/s] 80%|████████  | 16/20 [00:10<00:00,  4.05it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.28it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.10it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.57it/s]100%|██████████| 20/20 [00:11<00:00,  4.04it/s]100%|██████████| 20/20 [00:11<00:00,  1.72it/s]=> result
* total: 1,990
* correct: 1,601
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 79.8%

epoch [19/30] batch [20/796] time 0.376 (0.433) data 0.000 (0.039) loss 1.0068 (1.6373) lr 3.4549e-03 eta 1:08:51
epoch [19/30] batch [40/796] time 0.377 (0.407) data 0.000 (0.020) loss 0.2147 (1.4126) lr 3.4549e-03 eta 1:04:31
epoch [19/30] batch [60/796] time 0.399 (0.400) data 0.000 (0.013) loss 0.7520 (1.6489) lr 3.4549e-03 eta 1:03:15
epoch [19/30] batch [80/796] time 0.380 (0.397) data 0.000 (0.010) loss 0.5098 (1.6255) lr 3.4549e-03 eta 1:02:39
epoch [19/30] batch [100/796] time 0.420 (0.395) data 0.000 (0.008) loss 1.4014 (1.7200) lr 3.4549e-03 eta 1:02:11
epoch [19/30] batch [120/796] time 0.376 (0.393) data 0.000 (0.007) loss 1.8887 (1.6961) lr 3.4549e-03 eta 1:01:48
epoch [19/30] batch [140/796] time 0.408 (0.392) data 0.000 (0.006) loss 1.0225 (1.6669) lr 3.4549e-03 eta 1:01:26
epoch [19/30] batch [160/796] time 0.395 (0.391) data 0.000 (0.005) loss 0.6606 (1.6443) lr 3.4549e-03 eta 1:01:09
epoch [19/30] batch [180/796] time 0.401 (0.390) data 0.000 (0.005) loss 1.4600 (1.6430) lr 3.4549e-03 eta 1:00:53
epoch [19/30] batch [200/796] time 0.361 (0.389) data 0.000 (0.004) loss 4.3242 (1.6334) lr 3.4549e-03 eta 1:00:41
epoch [19/30] batch [220/796] time 0.351 (0.389) data 0.000 (0.004) loss 0.5078 (1.5907) lr 3.4549e-03 eta 1:00:34
epoch [19/30] batch [240/796] time 0.406 (0.389) data 0.000 (0.004) loss 4.1875 (1.5520) lr 3.4549e-03 eta 1:00:20
epoch [19/30] batch [260/796] time 0.387 (0.389) data 0.000 (0.003) loss 0.1664 (1.5563) lr 3.4549e-03 eta 1:00:11
epoch [19/30] batch [280/796] time 0.363 (0.388) data 0.000 (0.003) loss 2.7734 (1.5608) lr 3.4549e-03 eta 1:00:00
epoch [19/30] batch [300/796] time 0.365 (0.388) data 0.000 (0.003) loss 0.9756 (1.5567) lr 3.4549e-03 eta 0:59:50
epoch [19/30] batch [320/796] time 0.411 (0.388) data 0.000 (0.003) loss 1.2266 (1.5396) lr 3.4549e-03 eta 0:59:39
epoch [19/30] batch [340/796] time 0.377 (0.387) data 0.000 (0.003) loss 0.1042 (1.5102) lr 3.4549e-03 eta 0:59:24
epoch [19/30] batch [360/796] time 0.391 (0.387) data 0.000 (0.002) loss 3.5293 (1.5108) lr 3.4549e-03 eta 0:59:13
epoch [19/30] batch [380/796] time 0.387 (0.386) data 0.000 (0.002) loss 1.9570 (1.5060) lr 3.4549e-03 eta 0:58:59
epoch [19/30] batch [400/796] time 0.383 (0.386) data 0.000 (0.002) loss 1.3555 (1.5008) lr 3.4549e-03 eta 0:58:51
epoch [19/30] batch [420/796] time 0.373 (0.386) data 0.000 (0.002) loss 1.3809 (1.5199) lr 3.4549e-03 eta 0:58:42
epoch [19/30] batch [440/796] time 0.384 (0.386) data 0.000 (0.002) loss 4.6055 (1.5184) lr 3.4549e-03 eta 0:58:35
epoch [19/30] batch [460/796] time 0.404 (0.386) data 0.000 (0.002) loss 0.9292 (1.5068) lr 3.4549e-03 eta 0:58:28
epoch [19/30] batch [480/796] time 0.371 (0.386) data 0.000 (0.002) loss 1.7178 (1.5034) lr 3.4549e-03 eta 0:58:22
epoch [19/30] batch [500/796] time 0.370 (0.386) data 0.000 (0.002) loss 1.4355 (1.5115) lr 3.4549e-03 eta 0:58:14
epoch [19/30] batch [520/796] time 0.399 (0.386) data 0.000 (0.002) loss 2.8691 (1.5169) lr 3.4549e-03 eta 0:58:06
epoch [19/30] batch [540/796] time 0.381 (0.386) data 0.000 (0.002) loss 1.8447 (1.5249) lr 3.4549e-03 eta 0:57:56
epoch [19/30] batch [560/796] time 0.400 (0.386) data 0.000 (0.002) loss 3.0742 (1.5244) lr 3.4549e-03 eta 0:57:48
epoch [19/30] batch [580/796] time 0.423 (0.386) data 0.000 (0.002) loss 1.1084 (1.5300) lr 3.4549e-03 eta 0:57:41
epoch [19/30] batch [600/796] time 0.360 (0.386) data 0.000 (0.002) loss 0.3147 (1.5349) lr 3.4549e-03 eta 0:57:32
epoch [19/30] batch [620/796] time 0.371 (0.386) data 0.000 (0.002) loss 4.3750 (1.5449) lr 3.4549e-03 eta 0:57:23
epoch [19/30] batch [640/796] time 0.398 (0.385) data 0.000 (0.001) loss 0.4954 (1.5418) lr 3.4549e-03 eta 0:57:15
epoch [19/30] batch [660/796] time 0.391 (0.385) data 0.000 (0.001) loss 4.0625 (1.5425) lr 3.4549e-03 eta 0:57:05
epoch [19/30] batch [680/796] time 0.380 (0.385) data 0.000 (0.001) loss 3.1309 (1.5498) lr 3.4549e-03 eta 0:56:59
epoch [19/30] batch [700/796] time 0.412 (0.386) data 0.000 (0.001) loss 4.3906 (1.5774) lr 3.4549e-03 eta 0:56:52
epoch [19/30] batch [720/796] time 0.393 (0.386) data 0.000 (0.001) loss 3.3906 (1.5847) lr 3.4549e-03 eta 0:56:45
epoch [19/30] batch [740/796] time 0.412 (0.385) data 0.000 (0.001) loss 0.7065 (1.5924) lr 3.4549e-03 eta 0:56:36
epoch [19/30] batch [760/796] time 0.379 (0.385) data 0.000 (0.001) loss 3.3438 (1.5995) lr 3.4549e-03 eta 0:56:28
epoch [19/30] batch [780/796] time 0.351 (0.385) data 0.000 (0.001) loss 1.1982 (1.5903) lr 3.4549e-03 eta 0:56:14
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.66s/it] 10%|█         | 2/20 [00:06<00:50,  2.80s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.66s/it] 20%|██        | 4/20 [00:07<00:17,  1.12s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:08,  1.56it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.86it/s] 60%|██████    | 12/20 [00:09<00:02,  3.14it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.48it/s] 70%|███████   | 14/20 [00:09<00:01,  3.63it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.97it/s] 80%|████████  | 16/20 [00:10<00:00,  4.17it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.07it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.68it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.08it/s]100%|██████████| 20/20 [00:11<00:00,  4.49it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,602
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 80.3%

epoch [20/30] batch [20/796] time 0.368 (0.433) data 0.000 (0.036) loss 1.7744 (1.6363) lr 2.9663e-03 eta 1:03:06
epoch [20/30] batch [40/796] time 0.390 (0.410) data 0.000 (0.018) loss 0.3013 (1.7322) lr 2.9663e-03 eta 0:59:31
epoch [20/30] batch [60/796] time 0.390 (0.403) data 0.000 (0.012) loss 1.1279 (1.7490) lr 2.9663e-03 eta 0:58:20
epoch [20/30] batch [80/796] time 0.399 (0.398) data 0.000 (0.009) loss 0.6099 (1.7008) lr 2.9663e-03 eta 0:57:33
epoch [20/30] batch [100/796] time 0.403 (0.396) data 0.000 (0.008) loss 0.4092 (1.6447) lr 2.9663e-03 eta 0:57:10
epoch [20/30] batch [120/796] time 0.386 (0.394) data 0.000 (0.006) loss 1.7393 (1.6861) lr 2.9663e-03 eta 0:56:42
epoch [20/30] batch [140/796] time 0.355 (0.392) data 0.000 (0.005) loss 1.5508 (1.6662) lr 2.9663e-03 eta 0:56:19
epoch [20/30] batch [160/796] time 0.351 (0.391) data 0.000 (0.005) loss 0.7705 (1.6554) lr 2.9663e-03 eta 0:55:59
epoch [20/30] batch [180/796] time 0.409 (0.390) data 0.000 (0.004) loss 2.1895 (1.5986) lr 2.9663e-03 eta 0:55:46
epoch [20/30] batch [200/796] time 0.384 (0.390) data 0.000 (0.004) loss 1.3457 (1.5947) lr 2.9663e-03 eta 0:55:34
epoch [20/30] batch [220/796] time 0.404 (0.388) data 0.000 (0.004) loss 0.7246 (1.6087) lr 2.9663e-03 eta 0:55:14
epoch [20/30] batch [240/796] time 0.357 (0.388) data 0.000 (0.003) loss 1.3311 (1.6120) lr 2.9663e-03 eta 0:55:01
epoch [20/30] batch [260/796] time 0.385 (0.387) data 0.000 (0.003) loss 0.7163 (1.5969) lr 2.9663e-03 eta 0:54:50
epoch [20/30] batch [280/796] time 0.384 (0.387) data 0.000 (0.003) loss 4.4258 (1.5742) lr 2.9663e-03 eta 0:54:40
epoch [20/30] batch [300/796] time 0.374 (0.387) data 0.000 (0.003) loss 3.4863 (1.5685) lr 2.9663e-03 eta 0:54:29
epoch [20/30] batch [320/796] time 0.357 (0.387) data 0.000 (0.003) loss 2.3281 (1.5677) lr 2.9663e-03 eta 0:54:21
epoch [20/30] batch [340/796] time 0.379 (0.386) data 0.000 (0.002) loss 1.8115 (1.5729) lr 2.9663e-03 eta 0:54:10
epoch [20/30] batch [360/796] time 0.365 (0.386) data 0.000 (0.002) loss 0.0783 (1.5752) lr 2.9663e-03 eta 0:54:01
epoch [20/30] batch [380/796] time 0.383 (0.386) data 0.000 (0.002) loss 0.1168 (1.5596) lr 2.9663e-03 eta 0:53:50
epoch [20/30] batch [400/796] time 0.369 (0.385) data 0.000 (0.002) loss 1.1953 (1.5382) lr 2.9663e-03 eta 0:53:41
epoch [20/30] batch [420/796] time 0.354 (0.386) data 0.000 (0.002) loss 5.6289 (1.5645) lr 2.9663e-03 eta 0:53:34
epoch [20/30] batch [440/796] time 0.398 (0.386) data 0.000 (0.002) loss 1.6992 (1.5849) lr 2.9663e-03 eta 0:53:27
epoch [20/30] batch [460/796] time 0.397 (0.386) data 0.000 (0.002) loss 2.5078 (1.6048) lr 2.9663e-03 eta 0:53:21
epoch [20/30] batch [480/796] time 0.405 (0.386) data 0.000 (0.002) loss 3.0957 (1.6320) lr 2.9663e-03 eta 0:53:14
epoch [20/30] batch [500/796] time 0.379 (0.386) data 0.001 (0.002) loss 1.0068 (1.6285) lr 2.9663e-03 eta 0:53:06
epoch [20/30] batch [520/796] time 0.408 (0.386) data 0.000 (0.002) loss 0.3440 (1.6348) lr 2.9663e-03 eta 0:52:59
epoch [20/30] batch [540/796] time 0.370 (0.386) data 0.000 (0.002) loss 0.5068 (1.6263) lr 2.9663e-03 eta 0:52:50
epoch [20/30] batch [560/796] time 0.372 (0.386) data 0.000 (0.002) loss 2.4902 (1.6326) lr 2.9663e-03 eta 0:52:41
epoch [20/30] batch [580/796] time 0.393 (0.386) data 0.000 (0.002) loss 4.3164 (1.6382) lr 2.9663e-03 eta 0:52:33
epoch [20/30] batch [600/796] time 0.377 (0.386) data 0.000 (0.001) loss 1.1094 (1.6209) lr 2.9663e-03 eta 0:52:26
epoch [20/30] batch [620/796] time 0.385 (0.386) data 0.000 (0.001) loss 2.0586 (1.6244) lr 2.9663e-03 eta 0:52:21
epoch [20/30] batch [640/796] time 0.357 (0.386) data 0.000 (0.001) loss 1.8955 (1.6294) lr 2.9663e-03 eta 0:52:14
epoch [20/30] batch [660/796] time 0.393 (0.386) data 0.000 (0.001) loss 3.5078 (1.6241) lr 2.9663e-03 eta 0:52:05
epoch [20/30] batch [680/796] time 0.394 (0.386) data 0.000 (0.001) loss 0.8198 (1.6185) lr 2.9663e-03 eta 0:51:57
epoch [20/30] batch [700/796] time 0.361 (0.386) data 0.000 (0.001) loss 0.6167 (1.6183) lr 2.9663e-03 eta 0:51:49
epoch [20/30] batch [720/796] time 0.410 (0.386) data 0.000 (0.001) loss 1.4326 (1.6140) lr 2.9663e-03 eta 0:51:41
epoch [20/30] batch [740/796] time 0.381 (0.386) data 0.000 (0.001) loss 2.1738 (1.6201) lr 2.9663e-03 eta 0:51:33
epoch [20/30] batch [760/796] time 0.399 (0.386) data 0.000 (0.001) loss 1.4551 (1.6281) lr 2.9663e-03 eta 0:51:23
epoch [20/30] batch [780/796] time 0.347 (0.385) data 0.000 (0.001) loss 0.5527 (1.6185) lr 2.9663e-03 eta 0:51:10
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:42,  5.42s/it] 10%|█         | 2/20 [00:06<00:52,  2.92s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.72s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.84it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.47it/s] 50%|█████     | 10/20 [00:08<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.99it/s] 60%|██████    | 12/20 [00:09<00:02,  3.29it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.49it/s] 70%|███████   | 14/20 [00:09<00:01,  3.61it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.90it/s] 80%|████████  | 16/20 [00:10<00:00,  4.16it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.40it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.50it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.93it/s]100%|██████████| 20/20 [00:11<00:00,  4.36it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,624
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 81.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/796] time 0.358 (0.427) data 0.000 (0.046) loss 0.6060 (1.3048) lr 2.5000e-03 eta 0:56:28
epoch [21/30] batch [40/796] time 0.358 (0.404) data 0.000 (0.023) loss 0.9639 (1.1930) lr 2.5000e-03 eta 0:53:19
epoch [21/30] batch [60/796] time 0.388 (0.401) data 0.000 (0.015) loss 1.3486 (1.4770) lr 2.5000e-03 eta 0:52:45
epoch [21/30] batch [80/796] time 0.375 (0.397) data 0.000 (0.012) loss 0.3892 (1.4252) lr 2.5000e-03 eta 0:52:08
epoch [21/30] batch [100/796] time 0.393 (0.396) data 0.000 (0.009) loss 0.2649 (1.4718) lr 2.5000e-03 eta 0:51:50
epoch [21/30] batch [120/796] time 0.477 (0.394) data 0.000 (0.008) loss 0.4385 (1.4737) lr 2.5000e-03 eta 0:51:31
epoch [21/30] batch [140/796] time 0.401 (0.393) data 0.000 (0.007) loss 2.5156 (1.5648) lr 2.5000e-03 eta 0:51:16
epoch [21/30] batch [160/796] time 0.393 (0.392) data 0.000 (0.006) loss 3.2676 (1.6308) lr 2.5000e-03 eta 0:50:59
epoch [21/30] batch [180/796] time 0.365 (0.392) data 0.000 (0.005) loss 0.7090 (1.5875) lr 2.5000e-03 eta 0:50:46
epoch [21/30] batch [200/796] time 0.400 (0.391) data 0.000 (0.005) loss 1.1387 (1.5699) lr 2.5000e-03 eta 0:50:36
epoch [21/30] batch [220/796] time 0.399 (0.391) data 0.000 (0.004) loss 0.2793 (1.5012) lr 2.5000e-03 eta 0:50:24
epoch [21/30] batch [240/796] time 0.393 (0.390) data 0.000 (0.004) loss 0.7388 (1.4830) lr 2.5000e-03 eta 0:50:11
epoch [21/30] batch [260/796] time 0.372 (0.389) data 0.000 (0.004) loss 0.6943 (1.4812) lr 2.5000e-03 eta 0:49:55
epoch [21/30] batch [280/796] time 0.389 (0.389) data 0.000 (0.003) loss 0.2766 (1.4656) lr 2.5000e-03 eta 0:49:43
epoch [21/30] batch [300/796] time 0.378 (0.388) data 0.000 (0.003) loss 1.5674 (1.4456) lr 2.5000e-03 eta 0:49:34
epoch [21/30] batch [320/796] time 0.366 (0.388) data 0.000 (0.003) loss 1.5273 (1.4605) lr 2.5000e-03 eta 0:49:24
epoch [21/30] batch [340/796] time 0.410 (0.388) data 0.000 (0.003) loss 0.5527 (1.4625) lr 2.5000e-03 eta 0:49:14
epoch [21/30] batch [360/796] time 0.410 (0.387) data 0.000 (0.003) loss 1.7207 (1.4808) lr 2.5000e-03 eta 0:49:03
epoch [21/30] batch [380/796] time 0.370 (0.387) data 0.000 (0.003) loss 0.6260 (1.4708) lr 2.5000e-03 eta 0:48:52
epoch [21/30] batch [400/796] time 0.355 (0.387) data 0.000 (0.003) loss 2.3809 (1.5200) lr 2.5000e-03 eta 0:48:45
epoch [21/30] batch [420/796] time 0.360 (0.387) data 0.000 (0.002) loss 0.0970 (1.5143) lr 2.5000e-03 eta 0:48:39
epoch [21/30] batch [440/796] time 0.368 (0.387) data 0.000 (0.002) loss 2.4785 (1.5313) lr 2.5000e-03 eta 0:48:30
epoch [21/30] batch [460/796] time 0.379 (0.387) data 0.000 (0.002) loss 0.8965 (1.5256) lr 2.5000e-03 eta 0:48:19
epoch [21/30] batch [480/796] time 0.364 (0.387) data 0.000 (0.002) loss 4.6289 (1.5343) lr 2.5000e-03 eta 0:48:11
epoch [21/30] batch [500/796] time 0.391 (0.387) data 0.000 (0.002) loss 0.1637 (1.5220) lr 2.5000e-03 eta 0:48:03
epoch [21/30] batch [520/796] time 0.414 (0.386) data 0.000 (0.002) loss 1.1768 (1.5063) lr 2.5000e-03 eta 0:47:54
epoch [21/30] batch [540/796] time 0.394 (0.386) data 0.000 (0.002) loss 1.5908 (1.4979) lr 2.5000e-03 eta 0:47:46
epoch [21/30] batch [560/796] time 0.380 (0.386) data 0.000 (0.002) loss 0.6035 (1.5074) lr 2.5000e-03 eta 0:47:37
epoch [21/30] batch [580/796] time 0.399 (0.386) data 0.000 (0.002) loss 1.2002 (1.5053) lr 2.5000e-03 eta 0:47:30
epoch [21/30] batch [600/796] time 0.411 (0.386) data 0.000 (0.002) loss 1.4170 (1.4966) lr 2.5000e-03 eta 0:47:21
epoch [21/30] batch [620/796] time 0.378 (0.386) data 0.000 (0.002) loss 1.0605 (1.5040) lr 2.5000e-03 eta 0:47:13
epoch [21/30] batch [640/796] time 0.420 (0.386) data 0.000 (0.002) loss 2.8887 (1.5086) lr 2.5000e-03 eta 0:47:05
epoch [21/30] batch [660/796] time 0.413 (0.386) data 0.000 (0.002) loss 0.9121 (1.5261) lr 2.5000e-03 eta 0:46:57
epoch [21/30] batch [680/796] time 0.398 (0.386) data 0.000 (0.002) loss 1.5508 (1.5240) lr 2.5000e-03 eta 0:46:49
epoch [21/30] batch [700/796] time 0.352 (0.386) data 0.000 (0.002) loss 5.0859 (1.5275) lr 2.5000e-03 eta 0:46:41
epoch [21/30] batch [720/796] time 0.363 (0.386) data 0.000 (0.002) loss 4.4414 (1.5333) lr 2.5000e-03 eta 0:46:31
epoch [21/30] batch [740/796] time 0.413 (0.386) data 0.000 (0.002) loss 3.6328 (1.5321) lr 2.5000e-03 eta 0:46:24
epoch [21/30] batch [760/796] time 0.388 (0.385) data 0.000 (0.001) loss 1.1816 (1.5337) lr 2.5000e-03 eta 0:46:14
epoch [21/30] batch [780/796] time 0.346 (0.385) data 0.000 (0.001) loss 3.3477 (1.5593) lr 2.5000e-03 eta 0:46:01
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.61s/it] 10%|█         | 2/20 [00:06<00:51,  2.85s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.69s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.98it/s] 60%|██████    | 12/20 [00:09<00:02,  3.25it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.63it/s] 70%|███████   | 14/20 [00:09<00:01,  3.71it/s] 75%|███████▌  | 15/20 [00:10<00:01,  4.04it/s] 80%|████████  | 16/20 [00:10<00:00,  4.05it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.06it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.43it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.87it/s]100%|██████████| 20/20 [00:11<00:00,  4.30it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,600
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 79.9%

epoch [22/30] batch [20/796] time 0.408 (0.433) data 0.000 (0.037) loss 3.4414 (1.5489) lr 2.0611e-03 eta 0:51:30
epoch [22/30] batch [40/796] time 0.373 (0.406) data 0.000 (0.019) loss 0.1794 (1.4756) lr 2.0611e-03 eta 0:48:15
epoch [22/30] batch [60/796] time 0.357 (0.398) data 0.000 (0.012) loss 0.5884 (1.4903) lr 2.0611e-03 eta 0:47:08
epoch [22/30] batch [80/796] time 0.353 (0.394) data 0.000 (0.009) loss 1.5801 (1.4575) lr 2.0611e-03 eta 0:46:31
epoch [22/30] batch [100/796] time 0.388 (0.391) data 0.000 (0.008) loss 3.7852 (1.4646) lr 2.0611e-03 eta 0:45:59
epoch [22/30] batch [120/796] time 0.396 (0.389) data 0.000 (0.006) loss 1.0430 (1.4313) lr 2.0611e-03 eta 0:45:39
epoch [22/30] batch [140/796] time 0.387 (0.388) data 0.000 (0.005) loss 2.3398 (1.4569) lr 2.0611e-03 eta 0:45:28
epoch [22/30] batch [160/796] time 0.391 (0.387) data 0.000 (0.005) loss 1.4736 (1.4683) lr 2.0611e-03 eta 0:45:11
epoch [22/30] batch [180/796] time 0.407 (0.388) data 0.000 (0.004) loss 1.3379 (1.4558) lr 2.0611e-03 eta 0:45:08
epoch [22/30] batch [200/796] time 0.400 (0.388) data 0.000 (0.004) loss 0.2544 (1.4915) lr 2.0611e-03 eta 0:45:02
epoch [22/30] batch [220/796] time 0.400 (0.388) data 0.000 (0.004) loss 2.4277 (1.5031) lr 2.0611e-03 eta 0:44:54
epoch [22/30] batch [240/796] time 0.358 (0.388) data 0.000 (0.003) loss 0.8516 (1.5395) lr 2.0611e-03 eta 0:44:43
epoch [22/30] batch [260/796] time 0.356 (0.387) data 0.000 (0.003) loss 3.2617 (1.5403) lr 2.0611e-03 eta 0:44:33
epoch [22/30] batch [280/796] time 0.352 (0.388) data 0.000 (0.003) loss 0.6128 (1.5120) lr 2.0611e-03 eta 0:44:28
epoch [22/30] batch [300/796] time 0.401 (0.388) data 0.000 (0.003) loss 0.1652 (1.5338) lr 2.0611e-03 eta 0:44:19
epoch [22/30] batch [320/796] time 0.415 (0.387) data 0.000 (0.003) loss 1.6025 (1.5446) lr 2.0611e-03 eta 0:44:11
epoch [22/30] batch [340/796] time 0.397 (0.387) data 0.000 (0.002) loss 0.7822 (1.5111) lr 2.0611e-03 eta 0:43:59
epoch [22/30] batch [360/796] time 0.359 (0.387) data 0.000 (0.002) loss 2.3672 (1.5132) lr 2.0611e-03 eta 0:43:51
epoch [22/30] batch [380/796] time 0.362 (0.387) data 0.000 (0.002) loss 0.7236 (1.5305) lr 2.0611e-03 eta 0:43:43
epoch [22/30] batch [400/796] time 0.360 (0.386) data 0.000 (0.002) loss 0.2793 (1.5144) lr 2.0611e-03 eta 0:43:32
epoch [22/30] batch [420/796] time 0.351 (0.386) data 0.000 (0.002) loss 1.6377 (1.5155) lr 2.0611e-03 eta 0:43:23
epoch [22/30] batch [440/796] time 0.355 (0.386) data 0.000 (0.002) loss 1.6211 (1.5121) lr 2.0611e-03 eta 0:43:14
epoch [22/30] batch [460/796] time 0.404 (0.386) data 0.000 (0.002) loss 0.9434 (1.4953) lr 2.0611e-03 eta 0:43:05
epoch [22/30] batch [480/796] time 0.362 (0.385) data 0.000 (0.002) loss 2.9824 (1.4797) lr 2.0611e-03 eta 0:42:56
epoch [22/30] batch [500/796] time 0.413 (0.386) data 0.000 (0.002) loss 1.5195 (1.4757) lr 2.0611e-03 eta 0:42:49
epoch [22/30] batch [520/796] time 0.411 (0.386) data 0.000 (0.002) loss 2.5469 (1.4674) lr 2.0611e-03 eta 0:42:43
epoch [22/30] batch [540/796] time 0.352 (0.386) data 0.000 (0.002) loss 1.0605 (1.4779) lr 2.0611e-03 eta 0:42:36
epoch [22/30] batch [560/796] time 0.384 (0.386) data 0.000 (0.002) loss 2.7285 (1.4778) lr 2.0611e-03 eta 0:42:28
epoch [22/30] batch [580/796] time 0.387 (0.386) data 0.000 (0.002) loss 0.8945 (1.4787) lr 2.0611e-03 eta 0:42:21
epoch [22/30] batch [600/796] time 0.391 (0.386) data 0.000 (0.001) loss 1.3643 (1.4930) lr 2.0611e-03 eta 0:42:12
epoch [22/30] batch [620/796] time 0.378 (0.386) data 0.000 (0.001) loss 0.5898 (1.4957) lr 2.0611e-03 eta 0:42:04
epoch [22/30] batch [640/796] time 0.405 (0.386) data 0.000 (0.001) loss 1.0908 (1.5028) lr 2.0611e-03 eta 0:41:56
epoch [22/30] batch [660/796] time 0.367 (0.386) data 0.000 (0.001) loss 1.7100 (1.5021) lr 2.0611e-03 eta 0:41:47
epoch [22/30] batch [680/796] time 0.413 (0.386) data 0.000 (0.001) loss 0.3066 (1.5057) lr 2.0611e-03 eta 0:41:39
epoch [22/30] batch [700/796] time 0.388 (0.385) data 0.000 (0.001) loss 0.8354 (1.5018) lr 2.0611e-03 eta 0:41:30
epoch [22/30] batch [720/796] time 0.386 (0.385) data 0.000 (0.001) loss 3.2031 (1.5059) lr 2.0611e-03 eta 0:41:22
epoch [22/30] batch [740/796] time 0.358 (0.385) data 0.000 (0.001) loss 0.0276 (1.4932) lr 2.0611e-03 eta 0:41:14
epoch [22/30] batch [760/796] time 0.396 (0.385) data 0.000 (0.001) loss 1.4883 (1.4970) lr 2.0611e-03 eta 0:41:06
epoch [22/30] batch [780/796] time 0.346 (0.384) data 0.000 (0.001) loss 3.3672 (1.4998) lr 2.0611e-03 eta 0:40:53
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.60s/it] 10%|█         | 2/20 [00:06<00:50,  2.83s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.67s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.67it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.25it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.57it/s] 70%|███████   | 14/20 [00:09<00:01,  3.69it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.99it/s] 80%|████████  | 16/20 [00:10<00:00,  4.31it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.37it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.62it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.04it/s]100%|██████████| 20/20 [00:11<00:00,  4.45it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,619
* accuracy: 81.4%
* error: 18.6%
* macro_f1: 80.9%

epoch [23/30] batch [20/796] time 0.416 (0.431) data 0.000 (0.042) loss 0.3149 (1.6927) lr 1.6543e-03 eta 0:45:38
epoch [23/30] batch [40/796] time 0.373 (0.405) data 0.000 (0.021) loss 4.3008 (1.5214) lr 1.6543e-03 eta 0:42:44
epoch [23/30] batch [60/796] time 0.391 (0.398) data 0.000 (0.014) loss 2.2617 (1.5516) lr 1.6543e-03 eta 0:41:50
epoch [23/30] batch [80/796] time 0.389 (0.397) data 0.000 (0.011) loss 2.7207 (1.5344) lr 1.6543e-03 eta 0:41:36
epoch [23/30] batch [100/796] time 0.368 (0.394) data 0.000 (0.009) loss 2.8027 (1.6051) lr 1.6543e-03 eta 0:41:10
epoch [23/30] batch [120/796] time 0.375 (0.392) data 0.000 (0.007) loss 0.4314 (1.5382) lr 1.6543e-03 eta 0:40:51
epoch [23/30] batch [140/796] time 0.376 (0.391) data 0.000 (0.006) loss 5.0898 (1.5309) lr 1.6543e-03 eta 0:40:35
epoch [23/30] batch [160/796] time 0.400 (0.391) data 0.000 (0.005) loss 3.3711 (1.5215) lr 1.6543e-03 eta 0:40:26
epoch [23/30] batch [180/796] time 0.363 (0.390) data 0.000 (0.005) loss 0.2445 (1.5165) lr 1.6543e-03 eta 0:40:14
epoch [23/30] batch [200/796] time 0.390 (0.390) data 0.000 (0.004) loss 1.3594 (1.4879) lr 1.6543e-03 eta 0:40:06
epoch [23/30] batch [220/796] time 0.402 (0.390) data 0.000 (0.004) loss 1.6875 (1.5065) lr 1.6543e-03 eta 0:39:54
epoch [23/30] batch [240/796] time 0.356 (0.389) data 0.000 (0.004) loss 0.3689 (1.4970) lr 1.6543e-03 eta 0:39:45
epoch [23/30] batch [260/796] time 0.382 (0.389) data 0.000 (0.003) loss 1.4502 (1.4903) lr 1.6543e-03 eta 0:39:35
epoch [23/30] batch [280/796] time 0.379 (0.388) data 0.000 (0.003) loss 0.5879 (1.5211) lr 1.6543e-03 eta 0:39:24
epoch [23/30] batch [300/796] time 0.401 (0.389) data 0.000 (0.003) loss 1.9424 (1.5319) lr 1.6543e-03 eta 0:39:19
epoch [23/30] batch [320/796] time 0.385 (0.388) data 0.000 (0.003) loss 3.9219 (1.5286) lr 1.6543e-03 eta 0:39:07
epoch [23/30] batch [340/796] time 0.371 (0.388) data 0.000 (0.003) loss 2.7266 (1.5296) lr 1.6543e-03 eta 0:38:58
epoch [23/30] batch [360/796] time 0.363 (0.388) data 0.000 (0.003) loss 5.1250 (1.5484) lr 1.6543e-03 eta 0:38:48
epoch [23/30] batch [380/796] time 0.404 (0.387) data 0.000 (0.002) loss 1.7021 (1.5485) lr 1.6543e-03 eta 0:38:38
epoch [23/30] batch [400/796] time 0.395 (0.387) data 0.000 (0.002) loss 1.3369 (1.5445) lr 1.6543e-03 eta 0:38:29
epoch [23/30] batch [420/796] time 0.379 (0.387) data 0.000 (0.002) loss 4.4414 (1.5440) lr 1.6543e-03 eta 0:38:23
epoch [23/30] batch [440/796] time 0.351 (0.387) data 0.000 (0.002) loss 2.4023 (1.5266) lr 1.6543e-03 eta 0:38:12
epoch [23/30] batch [460/796] time 0.349 (0.387) data 0.000 (0.002) loss 0.3982 (1.5275) lr 1.6543e-03 eta 0:38:04
epoch [23/30] batch [480/796] time 0.394 (0.387) data 0.000 (0.002) loss 0.3821 (1.5370) lr 1.6543e-03 eta 0:37:56
epoch [23/30] batch [500/796] time 0.371 (0.387) data 0.000 (0.002) loss 1.4951 (1.5227) lr 1.6543e-03 eta 0:37:48
epoch [23/30] batch [520/796] time 0.352 (0.386) data 0.000 (0.002) loss 5.1094 (1.5236) lr 1.6543e-03 eta 0:37:38
epoch [23/30] batch [540/796] time 0.369 (0.386) data 0.000 (0.002) loss 1.2627 (1.5239) lr 1.6543e-03 eta 0:37:29
epoch [23/30] batch [560/796] time 0.354 (0.386) data 0.000 (0.002) loss 0.3887 (1.5084) lr 1.6543e-03 eta 0:37:21
epoch [23/30] batch [580/796] time 0.385 (0.386) data 0.000 (0.002) loss 4.8008 (1.5116) lr 1.6543e-03 eta 0:37:14
epoch [23/30] batch [600/796] time 0.364 (0.386) data 0.000 (0.002) loss 0.2520 (1.5120) lr 1.6543e-03 eta 0:37:06
epoch [23/30] batch [620/796] time 0.362 (0.386) data 0.000 (0.002) loss 1.9932 (1.5002) lr 1.6543e-03 eta 0:36:57
epoch [23/30] batch [640/796] time 0.381 (0.386) data 0.000 (0.002) loss 1.4375 (1.5001) lr 1.6543e-03 eta 0:36:49
epoch [23/30] batch [660/796] time 0.396 (0.386) data 0.000 (0.002) loss 0.1204 (1.4999) lr 1.6543e-03 eta 0:36:41
epoch [23/30] batch [680/796] time 0.392 (0.386) data 0.000 (0.001) loss 1.4121 (1.4960) lr 1.6543e-03 eta 0:36:33
epoch [23/30] batch [700/796] time 0.404 (0.386) data 0.000 (0.001) loss 2.2207 (1.4961) lr 1.6543e-03 eta 0:36:26
epoch [23/30] batch [720/796] time 0.393 (0.386) data 0.000 (0.001) loss 1.8936 (1.4828) lr 1.6543e-03 eta 0:36:17
epoch [23/30] batch [740/796] time 0.371 (0.386) data 0.000 (0.001) loss 1.4473 (1.4764) lr 1.6543e-03 eta 0:36:09
epoch [23/30] batch [760/796] time 0.391 (0.385) data 0.000 (0.001) loss 4.4492 (1.4839) lr 1.6543e-03 eta 0:36:01
epoch [23/30] batch [780/796] time 0.343 (0.385) data 0.000 (0.001) loss 1.1191 (1.4975) lr 1.6543e-03 eta 0:35:48
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:48,  5.73s/it] 10%|█         | 2/20 [00:06<00:52,  2.92s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.72s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.42it/s] 50%|█████     | 10/20 [00:09<00:03,  2.67it/s] 55%|█████▌    | 11/20 [00:09<00:03,  3.00it/s] 60%|██████    | 12/20 [00:09<00:02,  3.26it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.60it/s] 70%|███████   | 14/20 [00:09<00:01,  3.70it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.76it/s] 80%|████████  | 16/20 [00:10<00:01,  3.75it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.81it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.95it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.32it/s]100%|██████████| 20/20 [00:11<00:00,  4.69it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,612
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 80.5%

epoch [24/30] batch [20/796] time 0.359 (0.443) data 0.000 (0.056) loss 2.7598 (1.5298) lr 1.2843e-03 eta 0:40:57
epoch [24/30] batch [40/796] time 0.407 (0.415) data 0.000 (0.028) loss 2.2070 (1.5304) lr 1.2843e-03 eta 0:38:16
epoch [24/30] batch [60/796] time 0.370 (0.403) data 0.000 (0.019) loss 0.2656 (1.4713) lr 1.2843e-03 eta 0:37:01
epoch [24/30] batch [80/796] time 0.356 (0.397) data 0.000 (0.014) loss 0.4382 (1.3976) lr 1.2843e-03 eta 0:36:22
epoch [24/30] batch [100/796] time 0.392 (0.395) data 0.000 (0.011) loss 2.1172 (1.3384) lr 1.2843e-03 eta 0:36:02
epoch [24/30] batch [120/796] time 0.387 (0.394) data 0.000 (0.009) loss 0.7515 (1.3203) lr 1.2843e-03 eta 0:35:47
epoch [24/30] batch [140/796] time 0.402 (0.393) data 0.000 (0.008) loss 0.9678 (1.3211) lr 1.2843e-03 eta 0:35:36
epoch [24/30] batch [160/796] time 0.369 (0.392) data 0.000 (0.007) loss 0.1569 (1.3455) lr 1.2843e-03 eta 0:35:19
epoch [24/30] batch [180/796] time 0.410 (0.391) data 0.000 (0.006) loss 1.3633 (1.3800) lr 1.2843e-03 eta 0:35:10
epoch [24/30] batch [200/796] time 0.386 (0.391) data 0.000 (0.006) loss 1.4834 (1.4182) lr 1.2843e-03 eta 0:34:59
epoch [24/30] batch [220/796] time 0.397 (0.390) data 0.000 (0.005) loss 2.0020 (1.4367) lr 1.2843e-03 eta 0:34:45
epoch [24/30] batch [240/796] time 0.375 (0.390) data 0.000 (0.005) loss 0.3206 (1.4285) lr 1.2843e-03 eta 0:34:37
epoch [24/30] batch [260/796] time 0.352 (0.389) data 0.000 (0.005) loss 0.2529 (1.3993) lr 1.2843e-03 eta 0:34:26
epoch [24/30] batch [280/796] time 0.394 (0.389) data 0.000 (0.004) loss 1.8887 (1.4206) lr 1.2843e-03 eta 0:34:20
epoch [24/30] batch [300/796] time 0.402 (0.389) data 0.000 (0.004) loss 3.5000 (1.4320) lr 1.2843e-03 eta 0:34:11
epoch [24/30] batch [320/796] time 0.410 (0.389) data 0.000 (0.004) loss 2.8105 (1.4033) lr 1.2843e-03 eta 0:34:02
epoch [24/30] batch [340/796] time 0.374 (0.388) data 0.000 (0.004) loss 2.6074 (1.4038) lr 1.2843e-03 eta 0:33:51
epoch [24/30] batch [360/796] time 0.354 (0.388) data 0.000 (0.003) loss 2.2461 (1.4123) lr 1.2843e-03 eta 0:33:41
epoch [24/30] batch [380/796] time 0.408 (0.388) data 0.000 (0.003) loss 0.9409 (1.4241) lr 1.2843e-03 eta 0:33:34
epoch [24/30] batch [400/796] time 0.373 (0.388) data 0.000 (0.003) loss 0.5044 (1.4223) lr 1.2843e-03 eta 0:33:25
epoch [24/30] batch [420/796] time 0.366 (0.388) data 0.000 (0.003) loss 0.7539 (1.4353) lr 1.2843e-03 eta 0:33:17
epoch [24/30] batch [440/796] time 0.364 (0.387) data 0.000 (0.003) loss 1.2549 (1.4268) lr 1.2843e-03 eta 0:33:07
epoch [24/30] batch [460/796] time 0.387 (0.387) data 0.001 (0.003) loss 0.9287 (1.4261) lr 1.2843e-03 eta 0:32:59
epoch [24/30] batch [480/796] time 0.398 (0.387) data 0.001 (0.003) loss 1.1650 (1.4163) lr 1.2843e-03 eta 0:32:49
epoch [24/30] batch [500/796] time 0.364 (0.387) data 0.000 (0.002) loss 1.3291 (1.4307) lr 1.2843e-03 eta 0:32:40
epoch [24/30] batch [520/796] time 0.392 (0.386) data 0.000 (0.002) loss 3.5820 (1.4436) lr 1.2843e-03 eta 0:32:31
epoch [24/30] batch [540/796] time 0.373 (0.386) data 0.000 (0.002) loss 0.8921 (1.4412) lr 1.2843e-03 eta 0:32:23
epoch [24/30] batch [560/796] time 0.361 (0.386) data 0.000 (0.002) loss 0.3071 (1.4340) lr 1.2843e-03 eta 0:32:16
epoch [24/30] batch [580/796] time 0.369 (0.386) data 0.000 (0.002) loss 1.1680 (1.4490) lr 1.2843e-03 eta 0:32:08
epoch [24/30] batch [600/796] time 0.398 (0.386) data 0.000 (0.002) loss 1.1992 (1.4377) lr 1.2843e-03 eta 0:32:00
epoch [24/30] batch [620/796] time 0.368 (0.386) data 0.000 (0.002) loss 2.3848 (1.4384) lr 1.2843e-03 eta 0:31:53
epoch [24/30] batch [640/796] time 0.396 (0.386) data 0.000 (0.002) loss 0.7847 (1.4382) lr 1.2843e-03 eta 0:31:44
epoch [24/30] batch [660/796] time 0.395 (0.386) data 0.000 (0.002) loss 3.0195 (1.4645) lr 1.2843e-03 eta 0:31:37
epoch [24/30] batch [680/796] time 0.358 (0.386) data 0.000 (0.002) loss 2.4355 (1.4733) lr 1.2843e-03 eta 0:31:28
epoch [24/30] batch [700/796] time 0.386 (0.386) data 0.000 (0.002) loss 1.1436 (1.4721) lr 1.2843e-03 eta 0:31:20
epoch [24/30] batch [720/796] time 0.393 (0.386) data 0.000 (0.002) loss 2.9551 (1.4790) lr 1.2843e-03 eta 0:31:11
epoch [24/30] batch [740/796] time 0.358 (0.386) data 0.000 (0.002) loss 0.2815 (1.4879) lr 1.2843e-03 eta 0:31:03
epoch [24/30] batch [760/796] time 0.385 (0.386) data 0.000 (0.002) loss 0.5615 (1.4799) lr 1.2843e-03 eta 0:30:57
epoch [24/30] batch [780/796] time 0.351 (0.385) data 0.000 (0.002) loss 0.8936 (1.4714) lr 1.2843e-03 eta 0:30:45
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.60s/it] 10%|█         | 2/20 [00:06<00:52,  2.91s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.72s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.87it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.01it/s] 60%|██████    | 12/20 [00:09<00:02,  3.30it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.61it/s] 70%|███████   | 14/20 [00:09<00:01,  3.80it/s] 75%|███████▌  | 15/20 [00:10<00:01,  4.03it/s] 80%|████████  | 16/20 [00:10<00:00,  4.16it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.29it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.40it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.84it/s]100%|██████████| 20/20 [00:11<00:00,  4.28it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,619
* accuracy: 81.4%
* error: 18.6%
* macro_f1: 81.0%

epoch [25/30] batch [20/796] time 0.370 (0.435) data 0.000 (0.037) loss 0.0553 (1.6602) lr 9.5492e-04 eta 0:34:27
epoch [25/30] batch [40/796] time 0.347 (0.410) data 0.000 (0.019) loss 0.2625 (1.4688) lr 9.5492e-04 eta 0:32:23
epoch [25/30] batch [60/796] time 0.375 (0.399) data 0.000 (0.013) loss 1.1172 (1.3822) lr 9.5492e-04 eta 0:31:21
epoch [25/30] batch [80/796] time 0.396 (0.397) data 0.000 (0.010) loss 0.8608 (1.3469) lr 9.5492e-04 eta 0:31:02
epoch [25/30] batch [100/796] time 0.403 (0.394) data 0.000 (0.008) loss 5.4727 (1.2775) lr 9.5492e-04 eta 0:30:40
epoch [25/30] batch [120/796] time 0.361 (0.391) data 0.000 (0.006) loss 1.0029 (1.3397) lr 9.5492e-04 eta 0:30:21
epoch [25/30] batch [140/796] time 0.386 (0.389) data 0.000 (0.006) loss 1.4854 (1.4302) lr 9.5492e-04 eta 0:30:05
epoch [25/30] batch [160/796] time 0.380 (0.389) data 0.000 (0.005) loss 1.5479 (1.4059) lr 9.5492e-04 eta 0:29:55
epoch [25/30] batch [180/796] time 0.373 (0.390) data 0.000 (0.004) loss 0.1516 (1.4194) lr 9.5492e-04 eta 0:29:50
epoch [25/30] batch [200/796] time 0.404 (0.390) data 0.000 (0.004) loss 0.4746 (1.4496) lr 9.5492e-04 eta 0:29:42
epoch [25/30] batch [220/796] time 0.366 (0.389) data 0.000 (0.004) loss 1.9395 (1.4603) lr 9.5492e-04 eta 0:29:33
epoch [25/30] batch [240/796] time 0.385 (0.389) data 0.000 (0.003) loss 2.8164 (1.4398) lr 9.5492e-04 eta 0:29:26
epoch [25/30] batch [260/796] time 0.368 (0.389) data 0.000 (0.003) loss 0.3369 (1.4698) lr 9.5492e-04 eta 0:29:15
epoch [25/30] batch [280/796] time 0.397 (0.389) data 0.000 (0.003) loss 0.5425 (1.4304) lr 9.5492e-04 eta 0:29:09
epoch [25/30] batch [300/796] time 0.361 (0.389) data 0.000 (0.003) loss 0.5474 (1.4258) lr 9.5492e-04 eta 0:28:59
epoch [25/30] batch [320/796] time 0.387 (0.388) data 0.000 (0.003) loss 0.2805 (1.4220) lr 9.5492e-04 eta 0:28:47
epoch [25/30] batch [340/796] time 0.399 (0.388) data 0.000 (0.002) loss 1.6123 (1.4532) lr 9.5492e-04 eta 0:28:40
epoch [25/30] batch [360/796] time 0.361 (0.388) data 0.000 (0.002) loss 1.9043 (1.4494) lr 9.5492e-04 eta 0:28:31
epoch [25/30] batch [380/796] time 0.407 (0.387) data 0.000 (0.002) loss 2.6484 (1.4603) lr 9.5492e-04 eta 0:28:23
epoch [25/30] batch [400/796] time 0.355 (0.387) data 0.000 (0.002) loss 0.6650 (1.4446) lr 9.5492e-04 eta 0:28:13
epoch [25/30] batch [420/796] time 0.360 (0.387) data 0.000 (0.002) loss 0.5039 (1.4531) lr 9.5492e-04 eta 0:28:04
epoch [25/30] batch [440/796] time 0.391 (0.386) data 0.000 (0.002) loss 2.7227 (1.4422) lr 9.5492e-04 eta 0:27:55
epoch [25/30] batch [460/796] time 0.402 (0.386) data 0.000 (0.002) loss 0.3408 (1.4557) lr 9.5492e-04 eta 0:27:47
epoch [25/30] batch [480/796] time 0.360 (0.386) data 0.000 (0.002) loss 0.8477 (1.4522) lr 9.5492e-04 eta 0:27:39
epoch [25/30] batch [500/796] time 0.361 (0.386) data 0.000 (0.002) loss 2.4121 (1.4448) lr 9.5492e-04 eta 0:27:32
epoch [25/30] batch [520/796] time 0.383 (0.386) data 0.000 (0.002) loss 1.0586 (1.4409) lr 9.5492e-04 eta 0:27:24
epoch [25/30] batch [540/796] time 0.413 (0.386) data 0.000 (0.002) loss 2.9668 (1.4346) lr 9.5492e-04 eta 0:27:16
epoch [25/30] batch [560/796] time 0.363 (0.386) data 0.000 (0.002) loss 2.4121 (1.4446) lr 9.5492e-04 eta 0:27:07
epoch [25/30] batch [580/796] time 0.359 (0.386) data 0.000 (0.002) loss 0.2488 (1.4517) lr 9.5492e-04 eta 0:27:00
epoch [25/30] batch [600/796] time 0.373 (0.386) data 0.000 (0.002) loss 0.8330 (1.4584) lr 9.5492e-04 eta 0:26:52
epoch [25/30] batch [620/796] time 0.414 (0.386) data 0.000 (0.001) loss 0.7739 (1.4740) lr 9.5492e-04 eta 0:26:44
epoch [25/30] batch [640/796] time 0.379 (0.386) data 0.000 (0.001) loss 2.1621 (1.4800) lr 9.5492e-04 eta 0:26:36
epoch [25/30] batch [660/796] time 0.353 (0.386) data 0.000 (0.001) loss 1.4268 (1.4789) lr 9.5492e-04 eta 0:26:28
epoch [25/30] batch [680/796] time 0.374 (0.386) data 0.000 (0.001) loss 2.0020 (1.4778) lr 9.5492e-04 eta 0:26:20
epoch [25/30] batch [700/796] time 0.355 (0.386) data 0.000 (0.001) loss 2.5469 (1.4969) lr 9.5492e-04 eta 0:26:12
epoch [25/30] batch [720/796] time 0.376 (0.386) data 0.000 (0.001) loss 0.3738 (1.4944) lr 9.5492e-04 eta 0:26:04
epoch [25/30] batch [740/796] time 0.399 (0.386) data 0.000 (0.001) loss 1.0225 (1.4953) lr 9.5492e-04 eta 0:25:57
epoch [25/30] batch [760/796] time 0.359 (0.386) data 0.000 (0.001) loss 0.6680 (1.4844) lr 9.5492e-04 eta 0:25:50
epoch [25/30] batch [780/796] time 0.350 (0.385) data 0.000 (0.001) loss 1.6445 (1.4947) lr 9.5492e-04 eta 0:25:39
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.61s/it] 10%|█         | 2/20 [00:06<00:49,  2.76s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.63s/it] 20%|██        | 4/20 [00:06<00:17,  1.10s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.23it/s] 30%|███       | 6/20 [00:07<00:08,  1.58it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.91it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.50it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.87it/s] 60%|██████    | 12/20 [00:09<00:02,  3.10it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.30it/s] 70%|███████   | 14/20 [00:09<00:01,  3.55it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.58it/s] 80%|████████  | 16/20 [00:10<00:01,  3.86it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.96it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.21it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.53it/s]100%|██████████| 20/20 [00:11<00:00,  4.86it/s]100%|██████████| 20/20 [00:11<00:00,  1.79it/s]=> result
* total: 1,990
* correct: 1,615
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 80.8%

epoch [26/30] batch [20/796] time 0.380 (0.429) data 0.000 (0.043) loss 1.7285 (2.1583) lr 6.6987e-04 eta 0:28:20
epoch [26/30] batch [40/796] time 0.386 (0.411) data 0.000 (0.021) loss 2.9121 (1.9747) lr 6.6987e-04 eta 0:26:58
epoch [26/30] batch [60/796] time 0.390 (0.401) data 0.000 (0.014) loss 0.8574 (1.7896) lr 6.6987e-04 eta 0:26:12
epoch [26/30] batch [80/796] time 0.366 (0.396) data 0.000 (0.011) loss 1.4883 (1.6518) lr 6.6987e-04 eta 0:25:45
epoch [26/30] batch [100/796] time 0.401 (0.392) data 0.000 (0.009) loss 2.1562 (1.6808) lr 6.6987e-04 eta 0:25:22
epoch [26/30] batch [120/796] time 0.388 (0.391) data 0.000 (0.007) loss 2.3418 (1.6509) lr 6.6987e-04 eta 0:25:09
epoch [26/30] batch [140/796] time 0.390 (0.390) data 0.000 (0.006) loss 0.1433 (1.6147) lr 6.6987e-04 eta 0:24:56
epoch [26/30] batch [160/796] time 0.403 (0.389) data 0.000 (0.006) loss 0.8291 (1.5739) lr 6.6987e-04 eta 0:24:44
epoch [26/30] batch [180/796] time 0.389 (0.389) data 0.000 (0.005) loss 1.8369 (1.5805) lr 6.6987e-04 eta 0:24:36
epoch [26/30] batch [200/796] time 0.411 (0.389) data 0.000 (0.004) loss 0.0596 (1.5860) lr 6.6987e-04 eta 0:24:30
epoch [26/30] batch [220/796] time 0.386 (0.388) data 0.000 (0.004) loss 1.5430 (1.5601) lr 6.6987e-04 eta 0:24:20
epoch [26/30] batch [240/796] time 0.362 (0.388) data 0.000 (0.004) loss 1.1016 (1.5524) lr 6.6987e-04 eta 0:24:12
epoch [26/30] batch [260/796] time 0.408 (0.388) data 0.000 (0.004) loss 0.1305 (1.5399) lr 6.6987e-04 eta 0:24:01
epoch [26/30] batch [280/796] time 0.376 (0.388) data 0.000 (0.003) loss 0.4019 (1.5699) lr 6.6987e-04 eta 0:23:54
epoch [26/30] batch [300/796] time 0.391 (0.388) data 0.000 (0.003) loss 1.1289 (1.5800) lr 6.6987e-04 eta 0:23:46
epoch [26/30] batch [320/796] time 0.389 (0.388) data 0.000 (0.003) loss 0.8882 (1.5665) lr 6.6987e-04 eta 0:23:38
epoch [26/30] batch [340/796] time 0.380 (0.388) data 0.000 (0.003) loss 1.2061 (1.5536) lr 6.6987e-04 eta 0:23:30
epoch [26/30] batch [360/796] time 0.370 (0.387) data 0.000 (0.003) loss 6.7461 (1.5594) lr 6.6987e-04 eta 0:23:22
epoch [26/30] batch [380/796] time 0.360 (0.387) data 0.000 (0.002) loss 1.1768 (1.5615) lr 6.6987e-04 eta 0:23:13
epoch [26/30] batch [400/796] time 0.373 (0.387) data 0.000 (0.002) loss 1.1328 (1.5406) lr 6.6987e-04 eta 0:23:05
epoch [26/30] batch [420/796] time 0.376 (0.387) data 0.000 (0.002) loss 0.7354 (1.5182) lr 6.6987e-04 eta 0:22:56
epoch [26/30] batch [440/796] time 0.404 (0.387) data 0.000 (0.002) loss 0.6890 (1.5163) lr 6.6987e-04 eta 0:22:48
epoch [26/30] batch [460/796] time 0.372 (0.387) data 0.000 (0.002) loss 2.5859 (1.5166) lr 6.6987e-04 eta 0:22:41
epoch [26/30] batch [480/796] time 0.371 (0.386) data 0.000 (0.002) loss 1.0400 (1.4997) lr 6.6987e-04 eta 0:22:32
epoch [26/30] batch [500/796] time 0.377 (0.386) data 0.000 (0.002) loss 0.2468 (1.5015) lr 6.6987e-04 eta 0:22:24
epoch [26/30] batch [520/796] time 0.352 (0.386) data 0.000 (0.002) loss 0.7939 (1.4860) lr 6.6987e-04 eta 0:22:15
epoch [26/30] batch [540/796] time 0.405 (0.386) data 0.000 (0.002) loss 0.3945 (1.4866) lr 6.6987e-04 eta 0:22:08
epoch [26/30] batch [560/796] time 0.353 (0.386) data 0.000 (0.002) loss 1.0615 (1.4824) lr 6.6987e-04 eta 0:22:00
epoch [26/30] batch [580/796] time 0.361 (0.386) data 0.000 (0.002) loss 0.2622 (1.4829) lr 6.6987e-04 eta 0:21:52
epoch [26/30] batch [600/796] time 0.416 (0.386) data 0.000 (0.002) loss 1.3809 (1.4873) lr 6.6987e-04 eta 0:21:45
epoch [26/30] batch [620/796] time 0.371 (0.386) data 0.000 (0.002) loss 0.1152 (1.4811) lr 6.6987e-04 eta 0:21:36
epoch [26/30] batch [640/796] time 0.365 (0.386) data 0.000 (0.002) loss 0.6201 (1.4793) lr 6.6987e-04 eta 0:21:28
epoch [26/30] batch [660/796] time 0.370 (0.386) data 0.000 (0.002) loss 2.7422 (1.4809) lr 6.6987e-04 eta 0:21:20
epoch [26/30] batch [680/796] time 0.384 (0.386) data 0.000 (0.002) loss 1.2090 (1.4803) lr 6.6987e-04 eta 0:21:12
epoch [26/30] batch [700/796] time 0.354 (0.385) data 0.000 (0.001) loss 1.8555 (1.4729) lr 6.6987e-04 eta 0:21:04
epoch [26/30] batch [720/796] time 0.408 (0.386) data 0.000 (0.001) loss 0.9385 (1.4840) lr 6.6987e-04 eta 0:20:56
epoch [26/30] batch [740/796] time 0.376 (0.385) data 0.000 (0.001) loss 0.9375 (1.4864) lr 6.6987e-04 eta 0:20:48
epoch [26/30] batch [760/796] time 0.400 (0.385) data 0.000 (0.001) loss 3.8926 (1.4885) lr 6.6987e-04 eta 0:20:41
epoch [26/30] batch [780/796] time 0.347 (0.385) data 0.000 (0.001) loss 3.3027 (1.4967) lr 6.6987e-04 eta 0:20:30
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.48s/it] 10%|█         | 2/20 [00:06<00:52,  2.89s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.74it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.96it/s] 60%|██████    | 12/20 [00:09<00:02,  3.15it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.32it/s] 70%|███████   | 14/20 [00:09<00:01,  3.44it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.78it/s] 80%|████████  | 16/20 [00:10<00:00,  4.07it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.97it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.65it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.06it/s]100%|██████████| 20/20 [00:11<00:00,  4.47it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,615
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 80.8%

epoch [27/30] batch [20/796] time 0.412 (0.444) data 0.000 (0.051) loss 0.9688 (1.6750) lr 4.3227e-04 eta 0:23:26
epoch [27/30] batch [40/796] time 0.361 (0.418) data 0.000 (0.025) loss 0.2070 (1.5370) lr 4.3227e-04 eta 0:21:54
epoch [27/30] batch [60/796] time 0.384 (0.408) data 0.001 (0.017) loss 5.2305 (1.6511) lr 4.3227e-04 eta 0:21:14
epoch [27/30] batch [80/796] time 0.396 (0.402) data 0.000 (0.013) loss 2.9941 (1.5719) lr 4.3227e-04 eta 0:20:48
epoch [27/30] batch [100/796] time 0.360 (0.396) data 0.000 (0.010) loss 1.9062 (1.5161) lr 4.3227e-04 eta 0:20:21
epoch [27/30] batch [120/796] time 0.388 (0.395) data 0.000 (0.009) loss 1.8506 (1.5040) lr 4.3227e-04 eta 0:20:09
epoch [27/30] batch [140/796] time 0.406 (0.393) data 0.000 (0.007) loss 1.9785 (1.4977) lr 4.3227e-04 eta 0:19:57
epoch [27/30] batch [160/796] time 0.374 (0.392) data 0.000 (0.007) loss 3.4512 (1.5316) lr 4.3227e-04 eta 0:19:44
epoch [27/30] batch [180/796] time 0.382 (0.391) data 0.000 (0.006) loss 2.6055 (1.4949) lr 4.3227e-04 eta 0:19:33
epoch [27/30] batch [200/796] time 0.400 (0.390) data 0.000 (0.005) loss 1.7637 (1.5266) lr 4.3227e-04 eta 0:19:24
epoch [27/30] batch [220/796] time 0.393 (0.391) data 0.000 (0.005) loss 1.0918 (1.5215) lr 4.3227e-04 eta 0:19:18
epoch [27/30] batch [240/796] time 0.389 (0.390) data 0.000 (0.004) loss 0.2079 (1.5254) lr 4.3227e-04 eta 0:19:08
epoch [27/30] batch [260/796] time 0.396 (0.390) data 0.000 (0.004) loss 2.8223 (1.5303) lr 4.3227e-04 eta 0:19:00
epoch [27/30] batch [280/796] time 0.356 (0.389) data 0.000 (0.004) loss 2.3555 (1.4981) lr 4.3227e-04 eta 0:18:50
epoch [27/30] batch [300/796] time 0.366 (0.389) data 0.000 (0.004) loss 0.1669 (1.4996) lr 4.3227e-04 eta 0:18:43
epoch [27/30] batch [320/796] time 0.357 (0.389) data 0.000 (0.003) loss 3.3945 (1.5141) lr 4.3227e-04 eta 0:18:34
epoch [27/30] batch [340/796] time 0.367 (0.389) data 0.000 (0.003) loss 7.7930 (1.5152) lr 4.3227e-04 eta 0:18:26
epoch [27/30] batch [360/796] time 0.355 (0.389) data 0.000 (0.003) loss 0.2759 (1.5006) lr 4.3227e-04 eta 0:18:17
epoch [27/30] batch [380/796] time 0.373 (0.389) data 0.000 (0.003) loss 3.4082 (1.5168) lr 4.3227e-04 eta 0:18:09
epoch [27/30] batch [400/796] time 0.400 (0.388) data 0.000 (0.003) loss 1.1729 (1.5355) lr 4.3227e-04 eta 0:18:01
epoch [27/30] batch [420/796] time 0.388 (0.388) data 0.000 (0.003) loss 0.6182 (1.5062) lr 4.3227e-04 eta 0:17:53
epoch [27/30] batch [440/796] time 0.353 (0.388) data 0.000 (0.003) loss 1.5674 (1.4926) lr 4.3227e-04 eta 0:17:43
epoch [27/30] batch [460/796] time 0.359 (0.387) data 0.000 (0.002) loss 0.9292 (1.4910) lr 4.3227e-04 eta 0:17:35
epoch [27/30] batch [480/796] time 0.362 (0.387) data 0.000 (0.002) loss 2.2441 (1.4837) lr 4.3227e-04 eta 0:17:27
epoch [27/30] batch [500/796] time 0.380 (0.387) data 0.000 (0.002) loss 0.6045 (1.4723) lr 4.3227e-04 eta 0:17:18
epoch [27/30] batch [520/796] time 0.392 (0.387) data 0.000 (0.002) loss 1.1055 (1.4730) lr 4.3227e-04 eta 0:17:11
epoch [27/30] batch [540/796] time 0.386 (0.387) data 0.000 (0.002) loss 1.7178 (1.4856) lr 4.3227e-04 eta 0:17:02
epoch [27/30] batch [560/796] time 0.390 (0.387) data 0.000 (0.002) loss 0.8701 (1.4704) lr 4.3227e-04 eta 0:16:54
epoch [27/30] batch [580/796] time 0.388 (0.387) data 0.000 (0.002) loss 1.3018 (1.4674) lr 4.3227e-04 eta 0:16:46
epoch [27/30] batch [600/796] time 0.353 (0.386) data 0.000 (0.002) loss 2.3047 (1.4545) lr 4.3227e-04 eta 0:16:38
epoch [27/30] batch [620/796] time 0.404 (0.386) data 0.000 (0.002) loss 2.5840 (1.4433) lr 4.3227e-04 eta 0:16:30
epoch [27/30] batch [640/796] time 0.360 (0.386) data 0.000 (0.002) loss 1.5342 (1.4364) lr 4.3227e-04 eta 0:16:22
epoch [27/30] batch [660/796] time 0.361 (0.386) data 0.000 (0.002) loss 4.3438 (1.4477) lr 4.3227e-04 eta 0:16:14
epoch [27/30] batch [680/796] time 0.366 (0.386) data 0.000 (0.002) loss 0.3491 (1.4540) lr 4.3227e-04 eta 0:16:06
epoch [27/30] batch [700/796] time 0.404 (0.386) data 0.000 (0.002) loss 3.3086 (1.4644) lr 4.3227e-04 eta 0:15:58
epoch [27/30] batch [720/796] time 0.421 (0.386) data 0.000 (0.002) loss 1.7891 (1.4645) lr 4.3227e-04 eta 0:15:51
epoch [27/30] batch [740/796] time 0.366 (0.386) data 0.000 (0.002) loss 1.0576 (1.4589) lr 4.3227e-04 eta 0:15:43
epoch [27/30] batch [760/796] time 0.365 (0.386) data 0.000 (0.002) loss 0.2664 (1.4481) lr 4.3227e-04 eta 0:15:35
epoch [27/30] batch [780/796] time 0.350 (0.385) data 0.000 (0.002) loss 2.2207 (1.4419) lr 4.3227e-04 eta 0:15:26
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:50,  5.79s/it] 10%|█         | 2/20 [00:06<00:53,  2.96s/it] 15%|█▌        | 3/20 [00:07<00:29,  1.75s/it] 20%|██        | 4/20 [00:07<00:18,  1.18s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.84it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:09<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.98it/s] 60%|██████    | 12/20 [00:09<00:02,  3.20it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.57it/s] 70%|███████   | 14/20 [00:10<00:01,  3.74it/s] 75%|███████▌  | 15/20 [00:10<00:01,  4.03it/s] 80%|████████  | 16/20 [00:10<00:01,  4.00it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.85it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.54it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.96it/s]100%|██████████| 20/20 [00:11<00:00,  4.39it/s]100%|██████████| 20/20 [00:11<00:00,  1.72it/s]=> result
* total: 1,990
* correct: 1,615
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 80.7%

epoch [28/30] batch [20/796] time 0.412 (0.434) data 0.000 (0.038) loss 0.1030 (1.5021) lr 2.4472e-04 eta 0:17:08
epoch [28/30] batch [40/796] time 0.370 (0.407) data 0.000 (0.019) loss 1.3535 (1.3541) lr 2.4472e-04 eta 0:15:56
epoch [28/30] batch [60/796] time 0.388 (0.399) data 0.000 (0.013) loss 2.4180 (1.3985) lr 2.4472e-04 eta 0:15:28
epoch [28/30] batch [80/796] time 0.436 (0.395) data 0.000 (0.010) loss 0.5503 (1.3235) lr 2.4472e-04 eta 0:15:11
epoch [28/30] batch [100/796] time 0.386 (0.393) data 0.000 (0.008) loss 1.2637 (1.2734) lr 2.4472e-04 eta 0:14:59
epoch [28/30] batch [120/796] time 0.358 (0.392) data 0.000 (0.006) loss 3.5879 (1.3301) lr 2.4472e-04 eta 0:14:48
epoch [28/30] batch [140/796] time 0.382 (0.391) data 0.000 (0.006) loss 0.1641 (1.3401) lr 2.4472e-04 eta 0:14:39
epoch [28/30] batch [160/796] time 0.384 (0.390) data 0.000 (0.005) loss 2.1836 (1.3524) lr 2.4472e-04 eta 0:14:29
epoch [28/30] batch [180/796] time 0.377 (0.390) data 0.000 (0.004) loss 0.3455 (1.3325) lr 2.4472e-04 eta 0:14:20
epoch [28/30] batch [200/796] time 0.382 (0.389) data 0.000 (0.004) loss 2.1680 (1.3624) lr 2.4472e-04 eta 0:14:11
epoch [28/30] batch [220/796] time 0.410 (0.389) data 0.000 (0.004) loss 1.1465 (1.3375) lr 2.4472e-04 eta 0:14:02
epoch [28/30] batch [240/796] time 0.399 (0.388) data 0.000 (0.003) loss 3.1133 (1.3357) lr 2.4472e-04 eta 0:13:54
epoch [28/30] batch [260/796] time 0.408 (0.388) data 0.000 (0.003) loss 0.9580 (1.3642) lr 2.4472e-04 eta 0:13:46
epoch [28/30] batch [280/796] time 0.367 (0.388) data 0.000 (0.003) loss 0.8081 (1.3719) lr 2.4472e-04 eta 0:13:37
epoch [28/30] batch [300/796] time 0.354 (0.388) data 0.000 (0.003) loss 0.1782 (1.3565) lr 2.4472e-04 eta 0:13:29
epoch [28/30] batch [320/796] time 0.373 (0.388) data 0.000 (0.003) loss 1.1406 (1.3494) lr 2.4472e-04 eta 0:13:21
epoch [28/30] batch [340/796] time 0.415 (0.387) data 0.000 (0.002) loss 2.5059 (1.3391) lr 2.4472e-04 eta 0:13:13
epoch [28/30] batch [360/796] time 0.388 (0.387) data 0.000 (0.002) loss 1.0957 (1.3562) lr 2.4472e-04 eta 0:13:05
epoch [28/30] batch [380/796] time 0.362 (0.387) data 0.000 (0.002) loss 0.9751 (1.3656) lr 2.4472e-04 eta 0:12:57
epoch [28/30] batch [400/796] time 0.389 (0.387) data 0.000 (0.002) loss 0.6860 (1.3620) lr 2.4472e-04 eta 0:12:48
epoch [28/30] batch [420/796] time 0.366 (0.386) data 0.000 (0.002) loss 1.1797 (1.3504) lr 2.4472e-04 eta 0:12:40
epoch [28/30] batch [440/796] time 0.381 (0.386) data 0.000 (0.002) loss 1.8066 (1.3514) lr 2.4472e-04 eta 0:12:32
epoch [28/30] batch [460/796] time 0.412 (0.386) data 0.000 (0.002) loss 0.2517 (1.3380) lr 2.4472e-04 eta 0:12:25
epoch [28/30] batch [480/796] time 0.375 (0.386) data 0.000 (0.002) loss 0.2839 (1.3235) lr 2.4472e-04 eta 0:12:17
epoch [28/30] batch [500/796] time 0.400 (0.386) data 0.000 (0.002) loss 1.1816 (1.3311) lr 2.4472e-04 eta 0:12:08
epoch [28/30] batch [520/796] time 0.354 (0.386) data 0.000 (0.002) loss 0.2849 (1.3359) lr 2.4472e-04 eta 0:12:00
epoch [28/30] batch [540/796] time 0.378 (0.385) data 0.000 (0.002) loss 0.5728 (1.3377) lr 2.4472e-04 eta 0:11:52
epoch [28/30] batch [560/796] time 0.406 (0.385) data 0.000 (0.002) loss 1.8574 (1.3376) lr 2.4472e-04 eta 0:11:44
epoch [28/30] batch [580/796] time 0.388 (0.385) data 0.000 (0.002) loss 1.0146 (1.3569) lr 2.4472e-04 eta 0:11:36
epoch [28/30] batch [600/796] time 0.354 (0.385) data 0.000 (0.002) loss 1.9482 (1.3554) lr 2.4472e-04 eta 0:11:28
epoch [28/30] batch [620/796] time 0.364 (0.385) data 0.000 (0.001) loss 0.7700 (1.3503) lr 2.4472e-04 eta 0:11:20
epoch [28/30] batch [640/796] time 0.360 (0.385) data 0.000 (0.001) loss 1.8008 (1.3447) lr 2.4472e-04 eta 0:11:12
epoch [28/30] batch [660/796] time 0.354 (0.385) data 0.000 (0.001) loss 0.1918 (1.3454) lr 2.4472e-04 eta 0:11:04
epoch [28/30] batch [680/796] time 0.365 (0.385) data 0.000 (0.001) loss 0.5586 (1.3400) lr 2.4472e-04 eta 0:10:56
epoch [28/30] batch [700/796] time 0.411 (0.385) data 0.000 (0.001) loss 0.4785 (1.3516) lr 2.4472e-04 eta 0:10:49
epoch [28/30] batch [720/796] time 0.370 (0.385) data 0.000 (0.001) loss 0.6631 (1.3433) lr 2.4472e-04 eta 0:10:41
epoch [28/30] batch [740/796] time 0.350 (0.384) data 0.000 (0.001) loss 1.5205 (1.3434) lr 2.4472e-04 eta 0:10:33
epoch [28/30] batch [760/796] time 0.417 (0.385) data 0.000 (0.001) loss 2.2090 (1.3359) lr 2.4472e-04 eta 0:10:25
epoch [28/30] batch [780/796] time 0.345 (0.384) data 0.000 (0.001) loss 3.2793 (1.3407) lr 2.4472e-04 eta 0:10:17
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:49,  5.77s/it] 10%|█         | 2/20 [00:06<00:53,  2.95s/it] 15%|█▌        | 3/20 [00:07<00:29,  1.74s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:09<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.92it/s] 60%|██████    | 12/20 [00:09<00:02,  3.21it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.44it/s] 70%|███████   | 14/20 [00:10<00:01,  3.60it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.79it/s] 80%|████████  | 16/20 [00:10<00:00,  4.04it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.15it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.09it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.56it/s]100%|██████████| 20/20 [00:11<00:00,  4.04it/s]100%|██████████| 20/20 [00:11<00:00,  1.70it/s]=> result
* total: 1,990
* correct: 1,615
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 80.8%

epoch [29/30] batch [20/796] time 0.370 (0.431) data 0.000 (0.038) loss 0.3389 (1.1550) lr 1.0926e-04 eta 0:11:18
epoch [29/30] batch [40/796] time 0.399 (0.412) data 0.000 (0.019) loss 0.4851 (1.3797) lr 1.0926e-04 eta 0:10:39
epoch [29/30] batch [60/796] time 0.383 (0.400) data 0.000 (0.013) loss 1.7227 (1.4207) lr 1.0926e-04 eta 0:10:12
epoch [29/30] batch [80/796] time 0.371 (0.393) data 0.000 (0.010) loss 2.0000 (1.4436) lr 1.0926e-04 eta 0:09:54
epoch [29/30] batch [100/796] time 0.373 (0.393) data 0.000 (0.008) loss 3.3477 (1.5634) lr 1.0926e-04 eta 0:09:46
epoch [29/30] batch [120/796] time 0.360 (0.392) data 0.000 (0.007) loss 6.1758 (1.5798) lr 1.0926e-04 eta 0:09:36
epoch [29/30] batch [140/796] time 0.410 (0.390) data 0.000 (0.006) loss 0.5474 (1.4560) lr 1.0926e-04 eta 0:09:26
epoch [29/30] batch [160/796] time 0.355 (0.390) data 0.000 (0.005) loss 2.5801 (1.4381) lr 1.0926e-04 eta 0:09:17
epoch [29/30] batch [180/796] time 0.381 (0.389) data 0.000 (0.005) loss 0.4795 (1.4466) lr 1.0926e-04 eta 0:09:09
epoch [29/30] batch [200/796] time 0.415 (0.389) data 0.000 (0.004) loss 0.7441 (1.4571) lr 1.0926e-04 eta 0:09:01
epoch [29/30] batch [220/796] time 0.360 (0.388) data 0.000 (0.004) loss 0.6904 (1.4487) lr 1.0926e-04 eta 0:08:52
epoch [29/30] batch [240/796] time 0.370 (0.388) data 0.000 (0.003) loss 0.1281 (1.4270) lr 1.0926e-04 eta 0:08:44
epoch [29/30] batch [260/796] time 0.388 (0.388) data 0.000 (0.003) loss 3.7734 (1.4175) lr 1.0926e-04 eta 0:08:36
epoch [29/30] batch [280/796] time 0.395 (0.387) data 0.000 (0.003) loss 0.6895 (1.4438) lr 1.0926e-04 eta 0:08:27
epoch [29/30] batch [300/796] time 0.368 (0.387) data 0.000 (0.003) loss 0.6890 (1.4493) lr 1.0926e-04 eta 0:08:19
epoch [29/30] batch [320/796] time 0.359 (0.386) data 0.000 (0.003) loss 2.2715 (1.4296) lr 1.0926e-04 eta 0:08:11
epoch [29/30] batch [340/796] time 0.358 (0.386) data 0.000 (0.002) loss 4.0312 (1.4463) lr 1.0926e-04 eta 0:08:03
epoch [29/30] batch [360/796] time 0.454 (0.386) data 0.000 (0.002) loss 1.3975 (1.4384) lr 1.0926e-04 eta 0:07:55
epoch [29/30] batch [380/796] time 0.371 (0.386) data 0.000 (0.002) loss 0.9849 (1.4135) lr 1.0926e-04 eta 0:07:48
epoch [29/30] batch [400/796] time 0.378 (0.386) data 0.000 (0.002) loss 0.7368 (1.3999) lr 1.0926e-04 eta 0:07:39
epoch [29/30] batch [420/796] time 0.397 (0.386) data 0.000 (0.002) loss 2.4336 (1.3941) lr 1.0926e-04 eta 0:07:32
epoch [29/30] batch [440/796] time 0.365 (0.386) data 0.000 (0.002) loss 2.5078 (1.4183) lr 1.0926e-04 eta 0:07:24
epoch [29/30] batch [460/796] time 0.403 (0.386) data 0.000 (0.002) loss 1.9121 (1.4033) lr 1.0926e-04 eta 0:07:16
epoch [29/30] batch [480/796] time 0.412 (0.386) data 0.000 (0.002) loss 0.4299 (1.4131) lr 1.0926e-04 eta 0:07:09
epoch [29/30] batch [500/796] time 0.397 (0.386) data 0.000 (0.002) loss 2.3262 (1.4170) lr 1.0926e-04 eta 0:07:01
epoch [29/30] batch [520/796] time 0.401 (0.386) data 0.000 (0.002) loss 0.8711 (1.4194) lr 1.0926e-04 eta 0:06:53
epoch [29/30] batch [540/796] time 0.422 (0.386) data 0.000 (0.002) loss 1.9795 (1.4183) lr 1.0926e-04 eta 0:06:45
epoch [29/30] batch [560/796] time 0.391 (0.385) data 0.000 (0.002) loss 0.3362 (1.4084) lr 1.0926e-04 eta 0:06:37
epoch [29/30] batch [580/796] time 0.392 (0.386) data 0.000 (0.002) loss 0.8970 (1.3850) lr 1.0926e-04 eta 0:06:30
epoch [29/30] batch [600/796] time 0.370 (0.386) data 0.000 (0.002) loss 0.7798 (1.3886) lr 1.0926e-04 eta 0:06:22
epoch [29/30] batch [620/796] time 0.396 (0.385) data 0.000 (0.001) loss 0.8618 (1.3931) lr 1.0926e-04 eta 0:06:14
epoch [29/30] batch [640/796] time 0.391 (0.385) data 0.000 (0.001) loss 2.0078 (1.4005) lr 1.0926e-04 eta 0:06:06
epoch [29/30] batch [660/796] time 0.377 (0.385) data 0.000 (0.001) loss 1.5010 (1.4028) lr 1.0926e-04 eta 0:05:59
epoch [29/30] batch [680/796] time 0.393 (0.385) data 0.000 (0.001) loss 0.7114 (1.3966) lr 1.0926e-04 eta 0:05:51
epoch [29/30] batch [700/796] time 0.403 (0.385) data 0.000 (0.001) loss 0.4275 (1.3908) lr 1.0926e-04 eta 0:05:43
epoch [29/30] batch [720/796] time 0.383 (0.385) data 0.000 (0.001) loss 0.6689 (1.3779) lr 1.0926e-04 eta 0:05:35
epoch [29/30] batch [740/796] time 0.369 (0.385) data 0.000 (0.001) loss 2.4609 (1.3910) lr 1.0926e-04 eta 0:05:28
epoch [29/30] batch [760/796] time 0.390 (0.385) data 0.000 (0.001) loss 1.0566 (1.3868) lr 1.0926e-04 eta 0:05:20
epoch [29/30] batch [780/796] time 0.346 (0.384) data 0.000 (0.001) loss 1.7383 (1.3955) lr 1.0926e-04 eta 0:05:11
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:50,  5.80s/it] 10%|█         | 2/20 [00:06<00:50,  2.83s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.67s/it] 20%|██        | 4/20 [00:07<00:17,  1.12s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:08,  1.56it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.24it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.51it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.89it/s] 60%|██████    | 12/20 [00:09<00:02,  3.19it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.49it/s] 70%|███████   | 14/20 [00:09<00:01,  3.66it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.99it/s] 80%|████████  | 16/20 [00:10<00:00,  4.08it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.14it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.40it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.84it/s]100%|██████████| 20/20 [00:11<00:00,  4.28it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,614
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 80.7%

epoch [30/30] batch [20/796] time 0.395 (0.437) data 0.000 (0.040) loss 0.7603 (1.3568) lr 2.7391e-05 eta 0:05:39
epoch [30/30] batch [40/796] time 0.355 (0.411) data 0.000 (0.020) loss 0.5063 (1.2958) lr 2.7391e-05 eta 0:05:10
epoch [30/30] batch [60/796] time 0.385 (0.401) data 0.000 (0.014) loss 1.1172 (1.3316) lr 2.7391e-05 eta 0:04:55
epoch [30/30] batch [80/796] time 0.359 (0.396) data 0.000 (0.010) loss 0.7329 (1.3597) lr 2.7391e-05 eta 0:04:43
epoch [30/30] batch [100/796] time 0.352 (0.393) data 0.000 (0.008) loss 3.5605 (1.4292) lr 2.7391e-05 eta 0:04:33
epoch [30/30] batch [120/796] time 0.363 (0.391) data 0.000 (0.007) loss 0.3816 (1.3908) lr 2.7391e-05 eta 0:04:24
epoch [30/30] batch [140/796] time 0.398 (0.390) data 0.000 (0.006) loss 0.8560 (1.4092) lr 2.7391e-05 eta 0:04:15
epoch [30/30] batch [160/796] time 0.355 (0.390) data 0.000 (0.005) loss 1.9727 (1.4080) lr 2.7391e-05 eta 0:04:07
epoch [30/30] batch [180/796] time 0.433 (0.389) data 0.000 (0.005) loss 1.3887 (1.4052) lr 2.7391e-05 eta 0:03:59
epoch [30/30] batch [200/796] time 0.399 (0.389) data 0.000 (0.004) loss 2.4180 (1.3769) lr 2.7391e-05 eta 0:03:51
epoch [30/30] batch [220/796] time 0.410 (0.390) data 0.000 (0.004) loss 0.3088 (1.3568) lr 2.7391e-05 eta 0:03:44
epoch [30/30] batch [240/796] time 0.364 (0.390) data 0.000 (0.004) loss 0.9370 (1.3450) lr 2.7391e-05 eta 0:03:36
epoch [30/30] batch [260/796] time 0.373 (0.389) data 0.000 (0.003) loss 2.6738 (1.3462) lr 2.7391e-05 eta 0:03:28
epoch [30/30] batch [280/796] time 0.412 (0.389) data 0.000 (0.003) loss 1.3789 (1.3424) lr 2.7391e-05 eta 0:03:20
epoch [30/30] batch [300/796] time 0.412 (0.388) data 0.000 (0.003) loss 0.7183 (1.3279) lr 2.7391e-05 eta 0:03:12
epoch [30/30] batch [320/796] time 0.369 (0.388) data 0.000 (0.003) loss 1.4580 (1.3281) lr 2.7391e-05 eta 0:03:04
epoch [30/30] batch [340/796] time 0.384 (0.388) data 0.000 (0.003) loss 1.2695 (1.3341) lr 2.7391e-05 eta 0:02:56
epoch [30/30] batch [360/796] time 0.400 (0.388) data 0.000 (0.002) loss 0.9478 (1.3354) lr 2.7391e-05 eta 0:02:49
epoch [30/30] batch [380/796] time 0.397 (0.388) data 0.000 (0.002) loss 2.9629 (1.3724) lr 2.7391e-05 eta 0:02:41
epoch [30/30] batch [400/796] time 0.362 (0.387) data 0.000 (0.002) loss 0.6245 (1.3555) lr 2.7391e-05 eta 0:02:33
epoch [30/30] batch [420/796] time 0.403 (0.387) data 0.000 (0.002) loss 0.7417 (1.3350) lr 2.7391e-05 eta 0:02:25
epoch [30/30] batch [440/796] time 0.411 (0.387) data 0.000 (0.002) loss 0.2791 (1.3143) lr 2.7391e-05 eta 0:02:17
epoch [30/30] batch [460/796] time 0.360 (0.387) data 0.000 (0.002) loss 1.0020 (1.3219) lr 2.7391e-05 eta 0:02:10
epoch [30/30] batch [480/796] time 0.395 (0.387) data 0.000 (0.002) loss 1.5020 (1.3367) lr 2.7391e-05 eta 0:02:02
epoch [30/30] batch [500/796] time 0.368 (0.387) data 0.000 (0.002) loss 1.1035 (1.3409) lr 2.7391e-05 eta 0:01:54
epoch [30/30] batch [520/796] time 0.398 (0.387) data 0.000 (0.002) loss 1.0205 (1.3508) lr 2.7391e-05 eta 0:01:46
epoch [30/30] batch [540/796] time 0.371 (0.387) data 0.000 (0.002) loss 0.6802 (1.3484) lr 2.7391e-05 eta 0:01:39
epoch [30/30] batch [560/796] time 0.361 (0.387) data 0.000 (0.002) loss 0.7437 (1.3566) lr 2.7391e-05 eta 0:01:31
epoch [30/30] batch [580/796] time 0.361 (0.387) data 0.000 (0.002) loss 1.1455 (1.3519) lr 2.7391e-05 eta 0:01:23
epoch [30/30] batch [600/796] time 0.413 (0.386) data 0.000 (0.002) loss 0.9443 (1.3652) lr 2.7391e-05 eta 0:01:15
epoch [30/30] batch [620/796] time 0.398 (0.386) data 0.000 (0.002) loss 1.1885 (1.3585) lr 2.7391e-05 eta 0:01:08
epoch [30/30] batch [640/796] time 0.382 (0.386) data 0.000 (0.002) loss 0.6631 (1.3677) lr 2.7391e-05 eta 0:01:00
epoch [30/30] batch [660/796] time 0.393 (0.386) data 0.000 (0.001) loss 1.9902 (1.3574) lr 2.7391e-05 eta 0:00:52
epoch [30/30] batch [680/796] time 0.397 (0.386) data 0.000 (0.001) loss 1.6797 (1.3528) lr 2.7391e-05 eta 0:00:44
epoch [30/30] batch [700/796] time 0.389 (0.386) data 0.000 (0.001) loss 0.6323 (1.3510) lr 2.7391e-05 eta 0:00:37
epoch [30/30] batch [720/796] time 0.361 (0.386) data 0.000 (0.001) loss 2.2500 (1.3562) lr 2.7391e-05 eta 0:00:29
epoch [30/30] batch [740/796] time 0.365 (0.386) data 0.000 (0.001) loss 0.2749 (1.3641) lr 2.7391e-05 eta 0:00:21
epoch [30/30] batch [760/796] time 0.393 (0.386) data 0.000 (0.001) loss 1.3672 (1.3633) lr 2.7391e-05 eta 0:00:13
epoch [30/30] batch [780/796] time 0.346 (0.385) data 0.000 (0.001) loss 0.9238 (1.3533) lr 2.7391e-05 eta 0:00:06
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:50,  5.81s/it] 10%|█         | 2/20 [00:06<00:51,  2.84s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.67it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.91it/s] 60%|██████    | 12/20 [00:09<00:02,  3.16it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.39it/s] 70%|███████   | 14/20 [00:09<00:01,  3.69it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.77it/s] 80%|████████  | 16/20 [00:10<00:01,  3.83it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.04it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.24it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.55it/s]100%|██████████| 20/20 [00:11<00:00,  4.87it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]
=> result
* total: 1,990
* correct: 1,614
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 80.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 26)
Evaluate on the *test* set
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:05<09:21,  5.67s/it]  2%|▏         | 2/100 [00:06<04:15,  2.61s/it]  3%|▎         | 3/100 [00:07<03:23,  2.10s/it]  4%|▍         | 4/100 [00:08<02:22,  1.48s/it]  5%|▌         | 5/100 [00:08<01:47,  1.13s/it]  6%|▌         | 6/100 [00:09<01:26,  1.08it/s]  7%|▋         | 7/100 [00:09<01:13,  1.27it/s]  8%|▊         | 8/100 [00:10<01:03,  1.45it/s]  9%|▉         | 9/100 [00:10<00:57,  1.59it/s] 10%|█         | 10/100 [00:11<00:52,  1.71it/s] 11%|█         | 11/100 [00:11<00:47,  1.89it/s] 12%|█▏        | 12/100 [00:11<00:43,  2.01it/s] 13%|█▎        | 13/100 [00:12<00:43,  2.02it/s] 14%|█▍        | 14/100 [00:12<00:41,  2.06it/s] 15%|█▌        | 15/100 [00:13<00:42,  2.02it/s] 16%|█▌        | 16/100 [00:13<00:41,  2.02it/s] 17%|█▋        | 17/100 [00:14<00:43,  1.89it/s] 18%|█▊        | 18/100 [00:15<00:42,  1.95it/s] 19%|█▉        | 19/100 [00:15<00:40,  1.99it/s] 20%|██        | 20/100 [00:16<00:40,  1.99it/s] 21%|██        | 21/100 [00:16<00:38,  2.06it/s] 22%|██▏       | 22/100 [00:16<00:35,  2.18it/s] 23%|██▎       | 23/100 [00:17<00:34,  2.25it/s] 24%|██▍       | 24/100 [00:17<00:32,  2.33it/s] 25%|██▌       | 25/100 [00:18<00:31,  2.37it/s] 26%|██▌       | 26/100 [00:18<00:31,  2.37it/s] 27%|██▋       | 27/100 [00:18<00:30,  2.38it/s] 28%|██▊       | 28/100 [00:19<00:30,  2.34it/s] 29%|██▉       | 29/100 [00:19<00:30,  2.32it/s] 30%|███       | 30/100 [00:20<00:30,  2.27it/s] 31%|███       | 31/100 [00:20<00:31,  2.19it/s] 32%|███▏      | 32/100 [00:21<00:31,  2.18it/s] 33%|███▎      | 33/100 [00:21<00:31,  2.11it/s] 34%|███▍      | 34/100 [00:22<00:31,  2.11it/s] 35%|███▌      | 35/100 [00:22<00:30,  2.12it/s] 36%|███▌      | 36/100 [00:23<00:31,  2.03it/s] 37%|███▋      | 37/100 [00:23<00:31,  2.01it/s] 38%|███▊      | 38/100 [00:24<00:28,  2.20it/s] 39%|███▉      | 39/100 [00:24<00:26,  2.31it/s] 40%|████      | 40/100 [00:24<00:25,  2.32it/s] 41%|████      | 41/100 [00:25<00:24,  2.43it/s] 42%|████▏     | 42/100 [00:25<00:22,  2.53it/s] 43%|████▎     | 43/100 [00:25<00:22,  2.55it/s] 44%|████▍     | 44/100 [00:26<00:22,  2.54it/s] 45%|████▌     | 45/100 [00:26<00:20,  2.64it/s] 46%|████▌     | 46/100 [00:27<00:20,  2.61it/s] 47%|████▋     | 47/100 [00:27<00:19,  2.69it/s] 48%|████▊     | 48/100 [00:27<00:19,  2.63it/s] 49%|████▉     | 49/100 [00:28<00:20,  2.53it/s] 50%|█████     | 50/100 [00:28<00:20,  2.41it/s] 51%|█████     | 51/100 [00:29<00:20,  2.38it/s] 52%|█████▏    | 52/100 [00:29<00:19,  2.49it/s] 53%|█████▎    | 53/100 [00:29<00:18,  2.56it/s] 54%|█████▍    | 54/100 [00:30<00:17,  2.58it/s] 55%|█████▌    | 55/100 [00:30<00:17,  2.53it/s] 56%|█████▌    | 56/100 [00:31<00:17,  2.50it/s] 57%|█████▋    | 57/100 [00:31<00:16,  2.53it/s] 58%|█████▊    | 58/100 [00:31<00:17,  2.47it/s] 59%|█████▉    | 59/100 [00:32<00:16,  2.51it/s] 60%|██████    | 60/100 [00:32<00:15,  2.50it/s] 61%|██████    | 61/100 [00:33<00:15,  2.48it/s] 62%|██████▏   | 62/100 [00:33<00:16,  2.37it/s] 63%|██████▎   | 63/100 [00:33<00:15,  2.41it/s] 64%|██████▍   | 64/100 [00:34<00:14,  2.46it/s] 65%|██████▌   | 65/100 [00:34<00:14,  2.40it/s] 66%|██████▌   | 66/100 [00:35<00:14,  2.34it/s] 67%|██████▋   | 67/100 [00:35<00:14,  2.27it/s] 68%|██████▊   | 68/100 [00:36<00:14,  2.24it/s] 69%|██████▉   | 69/100 [00:36<00:13,  2.29it/s] 70%|███████   | 70/100 [00:36<00:12,  2.41it/s] 71%|███████   | 71/100 [00:37<00:11,  2.51it/s] 72%|███████▏  | 72/100 [00:37<00:10,  2.61it/s] 73%|███████▎  | 73/100 [00:38<00:10,  2.69it/s] 74%|███████▍  | 74/100 [00:38<00:09,  2.82it/s] 75%|███████▌  | 75/100 [00:38<00:08,  2.92it/s] 76%|███████▌  | 76/100 [00:38<00:07,  3.04it/s] 77%|███████▋  | 77/100 [00:39<00:07,  3.07it/s] 78%|███████▊  | 78/100 [00:39<00:06,  3.20it/s] 79%|███████▉  | 79/100 [00:39<00:06,  3.22it/s] 80%|████████  | 80/100 [00:40<00:06,  3.32it/s] 81%|████████  | 81/100 [00:40<00:05,  3.68it/s] 82%|████████▏ | 82/100 [00:40<00:04,  4.09it/s] 83%|████████▎ | 83/100 [00:40<00:03,  4.43it/s] 84%|████████▍ | 84/100 [00:40<00:03,  4.70it/s] 85%|████████▌ | 85/100 [00:41<00:03,  4.92it/s] 86%|████████▌ | 86/100 [00:41<00:02,  5.08it/s] 87%|████████▋ | 87/100 [00:41<00:02,  5.20it/s] 88%|████████▊ | 88/100 [00:41<00:02,  5.29it/s] 89%|████████▉ | 89/100 [00:41<00:02,  5.35it/s] 90%|█████████ | 90/100 [00:41<00:01,  5.39it/s] 91%|█████████ | 91/100 [00:42<00:01,  5.43it/s] 92%|█████████▏| 92/100 [00:42<00:01,  5.45it/s] 93%|█████████▎| 93/100 [00:42<00:01,  5.47it/s] 94%|█████████▍| 94/100 [00:42<00:01,  5.48it/s] 95%|█████████▌| 95/100 [00:42<00:00,  5.49it/s] 96%|█████████▌| 96/100 [00:43<00:00,  5.49it/s] 97%|█████████▋| 97/100 [00:43<00:00,  5.49it/s] 98%|█████████▊| 98/100 [00:43<00:00,  5.50it/s] 99%|█████████▉| 99/100 [00:43<00:00,  5.50it/s]100%|██████████| 100/100 [00:43<00:00,  6.05it/s]100%|██████████| 100/100 [00:43<00:00,  2.28it/s]
=> result
* total: 9,950
* correct: 8,106
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 81.2%
Elapsed: 1:20:06
+ sh scripts/rpo_prime/base2new_test_sdl.sh sun397 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
3168 1980 9900
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  198
# train_x  3,168
# val      1,980
# test     9,900
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 26)
Evaluate on the *test* set
  0%|          | 0/99 [00:00<?, ?it/s]  1%|          | 1/99 [00:10<16:24, 10.04s/it]  2%|▏         | 2/99 [00:10<07:01,  4.35s/it]  3%|▎         | 3/99 [00:10<04:02,  2.52s/it]  4%|▍         | 4/99 [00:11<02:36,  1.65s/it]  5%|▌         | 5/99 [00:11<01:50,  1.17s/it]  6%|▌         | 6/99 [00:11<01:22,  1.13it/s]  7%|▋         | 7/99 [00:12<01:04,  1.43it/s]  8%|▊         | 8/99 [00:12<00:52,  1.72it/s]  9%|▉         | 9/99 [00:12<00:45,  1.99it/s] 10%|█         | 10/99 [00:13<00:40,  2.22it/s] 11%|█         | 11/99 [00:13<00:37,  2.35it/s] 12%|█▏        | 12/99 [00:13<00:35,  2.47it/s] 13%|█▎        | 13/99 [00:14<00:34,  2.52it/s] 14%|█▍        | 14/99 [00:14<00:34,  2.43it/s] 15%|█▌        | 15/99 [00:15<00:35,  2.36it/s] 16%|█▌        | 16/99 [00:15<00:36,  2.25it/s] 17%|█▋        | 17/99 [00:15<00:36,  2.24it/s] 18%|█▊        | 18/99 [00:16<00:36,  2.19it/s] 19%|█▉        | 19/99 [00:16<00:37,  2.16it/s] 20%|██        | 20/99 [00:17<00:38,  2.04it/s] 21%|██        | 21/99 [00:17<00:37,  2.08it/s] 22%|██▏       | 22/99 [00:18<00:38,  2.03it/s] 23%|██▎       | 23/99 [00:18<00:38,  1.98it/s] 24%|██▍       | 24/99 [00:19<00:36,  2.07it/s] 25%|██▌       | 25/99 [00:19<00:33,  2.18it/s] 26%|██▋       | 26/99 [00:20<00:31,  2.35it/s] 27%|██▋       | 27/99 [00:20<00:28,  2.48it/s] 28%|██▊       | 28/99 [00:20<00:27,  2.61it/s] 29%|██▉       | 29/99 [00:21<00:25,  2.70it/s] 30%|███       | 30/99 [00:21<00:24,  2.76it/s] 31%|███▏      | 31/99 [00:21<00:24,  2.77it/s] 32%|███▏      | 32/99 [00:22<00:23,  2.79it/s] 33%|███▎      | 33/99 [00:22<00:24,  2.69it/s] 34%|███▍      | 34/99 [00:23<00:24,  2.62it/s] 35%|███▌      | 35/99 [00:23<00:25,  2.48it/s] 36%|███▋      | 36/99 [00:23<00:26,  2.37it/s] 37%|███▋      | 37/99 [00:24<00:26,  2.34it/s] 38%|███▊      | 38/99 [00:24<00:26,  2.29it/s] 39%|███▉      | 39/99 [00:25<00:26,  2.29it/s] 40%|████      | 40/99 [00:25<00:24,  2.38it/s] 41%|████▏     | 41/99 [00:26<00:24,  2.38it/s] 42%|████▏     | 42/99 [00:26<00:23,  2.44it/s] 43%|████▎     | 43/99 [00:26<00:22,  2.54it/s] 44%|████▍     | 44/99 [00:27<00:20,  2.63it/s] 45%|████▌     | 45/99 [00:27<00:20,  2.64it/s] 46%|████▋     | 46/99 [00:27<00:20,  2.64it/s] 47%|████▋     | 47/99 [00:28<00:20,  2.56it/s] 48%|████▊     | 48/99 [00:28<00:20,  2.51it/s] 49%|████▉     | 49/99 [00:29<00:20,  2.39it/s] 51%|█████     | 50/99 [00:29<00:20,  2.34it/s] 52%|█████▏    | 51/99 [00:30<00:21,  2.26it/s] 53%|█████▎    | 52/99 [00:30<00:20,  2.25it/s] 54%|█████▎    | 53/99 [00:31<00:20,  2.25it/s] 55%|█████▍    | 54/99 [00:31<00:20,  2.21it/s] 56%|█████▌    | 55/99 [00:31<00:19,  2.24it/s] 57%|█████▋    | 56/99 [00:32<00:18,  2.32it/s] 58%|█████▊    | 57/99 [00:32<00:17,  2.43it/s] 59%|█████▊    | 58/99 [00:33<00:16,  2.50it/s] 60%|█████▉    | 59/99 [00:33<00:15,  2.50it/s] 61%|██████    | 60/99 [00:33<00:16,  2.37it/s] 62%|██████▏   | 61/99 [00:34<00:16,  2.28it/s] 63%|██████▎   | 62/99 [00:34<00:16,  2.29it/s] 64%|██████▎   | 63/99 [00:35<00:15,  2.28it/s] 65%|██████▍   | 64/99 [00:35<00:15,  2.30it/s] 66%|██████▌   | 65/99 [00:36<00:14,  2.30it/s] 67%|██████▋   | 66/99 [00:36<00:13,  2.42it/s] 68%|██████▊   | 67/99 [00:36<00:12,  2.49it/s] 69%|██████▊   | 68/99 [00:37<00:11,  2.62it/s] 70%|██████▉   | 69/99 [00:37<00:11,  2.71it/s] 71%|███████   | 70/99 [00:37<00:10,  2.81it/s] 72%|███████▏  | 71/99 [00:38<00:09,  2.90it/s] 73%|███████▎  | 72/99 [00:38<00:09,  2.96it/s] 74%|███████▎  | 73/99 [00:38<00:08,  3.02it/s] 75%|███████▍  | 74/99 [00:39<00:08,  3.10it/s] 76%|███████▌  | 75/99 [00:39<00:07,  3.20it/s] 77%|███████▋  | 76/99 [00:39<00:07,  3.26it/s] 78%|███████▊  | 77/99 [00:40<00:06,  3.31it/s] 79%|███████▉  | 78/99 [00:40<00:06,  3.33it/s] 80%|███████▉  | 79/99 [00:40<00:05,  3.41it/s] 81%|████████  | 80/99 [00:40<00:05,  3.69it/s] 82%|████████▏ | 81/99 [00:41<00:04,  3.83it/s] 83%|████████▎ | 82/99 [00:41<00:04,  3.93it/s] 84%|████████▍ | 83/99 [00:41<00:03,  4.28it/s] 85%|████████▍ | 84/99 [00:41<00:03,  4.56it/s] 86%|████████▌ | 85/99 [00:41<00:02,  4.78it/s] 87%|████████▋ | 86/99 [00:42<00:02,  4.96it/s] 88%|████████▊ | 87/99 [00:42<00:02,  5.06it/s] 89%|████████▉ | 88/99 [00:42<00:02,  5.13it/s] 90%|████████▉ | 89/99 [00:42<00:01,  5.19it/s] 91%|█████████ | 90/99 [00:42<00:01,  5.25it/s] 92%|█████████▏| 91/99 [00:43<00:01,  5.27it/s] 93%|█████████▎| 92/99 [00:43<00:01,  5.31it/s] 94%|█████████▍| 93/99 [00:43<00:01,  5.32it/s] 95%|█████████▍| 94/99 [00:43<00:00,  5.34it/s] 96%|█████████▌| 95/99 [00:43<00:00,  5.36it/s] 97%|█████████▋| 96/99 [00:43<00:00,  5.38it/s] 98%|█████████▊| 97/99 [00:44<00:00,  5.39it/s] 99%|█████████▉| 98/99 [00:44<00:00,  5.38it/s]100%|██████████| 99/99 [00:44<00:00,  5.39it/s]100%|██████████| 99/99 [00:44<00:00,  2.22it/s]
=> result
* total: 9,900
* correct: 7,785
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 77.6%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh sun397 3 0 main_tmp1_0.1sdl 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
3184 1990 9950
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  199
# train_x  3,184
# val      1,990
# test     9,950
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/796] time 0.410 (0.517) data 0.000 (0.067) loss 3.3086 (2.7496) lr 1.0000e-02 eta 3:25:41
epoch [1/30] batch [40/796] time 0.379 (0.453) data 0.000 (0.034) loss 4.9219 (2.8429) lr 1.0000e-02 eta 3:00:05
epoch [1/30] batch [60/796] time 0.409 (0.428) data 0.000 (0.023) loss 3.7988 (2.7934) lr 1.0000e-02 eta 2:49:49
epoch [1/30] batch [80/796] time 0.401 (0.417) data 0.000 (0.017) loss 3.3320 (2.6980) lr 1.0000e-02 eta 2:45:17
epoch [1/30] batch [100/796] time 0.410 (0.409) data 0.000 (0.014) loss 2.0508 (2.6703) lr 1.0000e-02 eta 2:42:04
epoch [1/30] batch [120/796] time 0.421 (0.406) data 0.000 (0.011) loss 0.8896 (2.5271) lr 1.0000e-02 eta 2:40:45
epoch [1/30] batch [140/796] time 0.358 (0.402) data 0.000 (0.010) loss 5.0938 (2.5472) lr 1.0000e-02 eta 2:39:09
epoch [1/30] batch [160/796] time 0.398 (0.399) data 0.000 (0.009) loss 1.9092 (2.5334) lr 1.0000e-02 eta 2:37:50
epoch [1/30] batch [180/796] time 0.402 (0.398) data 0.000 (0.008) loss 0.5420 (2.4595) lr 1.0000e-02 eta 2:37:02
epoch [1/30] batch [200/796] time 0.401 (0.396) data 0.000 (0.007) loss 4.4922 (2.4835) lr 1.0000e-02 eta 2:36:15
epoch [1/30] batch [220/796] time 0.393 (0.394) data 0.000 (0.006) loss 1.0342 (2.4530) lr 1.0000e-02 eta 2:35:32
epoch [1/30] batch [240/796] time 0.368 (0.393) data 0.000 (0.006) loss 1.8193 (2.3933) lr 1.0000e-02 eta 2:34:56
epoch [1/30] batch [260/796] time 0.414 (0.393) data 0.000 (0.005) loss 2.2109 (2.3597) lr 1.0000e-02 eta 2:34:54
epoch [1/30] batch [280/796] time 0.373 (0.393) data 0.000 (0.005) loss 1.3311 (2.3075) lr 1.0000e-02 eta 2:34:25
epoch [1/30] batch [300/796] time 0.408 (0.392) data 0.000 (0.005) loss 4.0078 (2.2996) lr 1.0000e-02 eta 2:34:06
epoch [1/30] batch [320/796] time 0.378 (0.392) data 0.000 (0.004) loss 2.7305 (2.2701) lr 1.0000e-02 eta 2:33:45
epoch [1/30] batch [340/796] time 0.396 (0.391) data 0.000 (0.004) loss 1.6377 (2.2494) lr 1.0000e-02 eta 2:33:27
epoch [1/30] batch [360/796] time 0.369 (0.391) data 0.000 (0.004) loss 0.7036 (2.2048) lr 1.0000e-02 eta 2:33:12
epoch [1/30] batch [380/796] time 0.391 (0.391) data 0.000 (0.004) loss 0.3796 (2.2217) lr 1.0000e-02 eta 2:32:58
epoch [1/30] batch [400/796] time 0.400 (0.390) data 0.000 (0.004) loss 0.3442 (2.1954) lr 1.0000e-02 eta 2:32:45
epoch [1/30] batch [420/796] time 0.399 (0.390) data 0.001 (0.003) loss 3.9160 (2.2339) lr 1.0000e-02 eta 2:32:31
epoch [1/30] batch [440/796] time 0.372 (0.390) data 0.000 (0.003) loss 3.0234 (2.2315) lr 1.0000e-02 eta 2:32:22
epoch [1/30] batch [460/796] time 0.404 (0.390) data 0.000 (0.003) loss 1.3604 (2.2341) lr 1.0000e-02 eta 2:32:03
epoch [1/30] batch [480/796] time 0.357 (0.390) data 0.000 (0.003) loss 2.4609 (2.2510) lr 1.0000e-02 eta 2:31:55
epoch [1/30] batch [500/796] time 0.413 (0.389) data 0.000 (0.003) loss 1.2900 (2.2261) lr 1.0000e-02 eta 2:31:33
epoch [1/30] batch [520/796] time 0.384 (0.388) data 0.000 (0.003) loss 1.1426 (2.2030) lr 1.0000e-02 eta 2:31:09
epoch [1/30] batch [540/796] time 0.400 (0.388) data 0.000 (0.003) loss 3.0430 (2.2091) lr 1.0000e-02 eta 2:31:03
epoch [1/30] batch [560/796] time 0.408 (0.388) data 0.000 (0.003) loss 2.4043 (2.2072) lr 1.0000e-02 eta 2:30:53
epoch [1/30] batch [580/796] time 0.406 (0.388) data 0.000 (0.003) loss 1.6904 (2.1796) lr 1.0000e-02 eta 2:30:42
epoch [1/30] batch [600/796] time 0.394 (0.388) data 0.000 (0.003) loss 1.8203 (2.1757) lr 1.0000e-02 eta 2:30:29
epoch [1/30] batch [620/796] time 0.394 (0.388) data 0.000 (0.002) loss 2.4395 (2.1641) lr 1.0000e-02 eta 2:30:19
epoch [1/30] batch [640/796] time 0.388 (0.387) data 0.001 (0.002) loss 1.1943 (2.1489) lr 1.0000e-02 eta 2:30:03
epoch [1/30] batch [660/796] time 0.374 (0.387) data 0.000 (0.002) loss 0.7314 (2.1443) lr 1.0000e-02 eta 2:29:56
epoch [1/30] batch [680/796] time 0.360 (0.387) data 0.001 (0.002) loss 6.6836 (2.1478) lr 1.0000e-02 eta 2:29:45
epoch [1/30] batch [700/796] time 0.388 (0.387) data 0.000 (0.002) loss 3.5820 (2.1490) lr 1.0000e-02 eta 2:29:35
epoch [1/30] batch [720/796] time 0.418 (0.387) data 0.001 (0.002) loss 1.4590 (2.1545) lr 1.0000e-02 eta 2:29:31
epoch [1/30] batch [740/796] time 0.389 (0.387) data 0.000 (0.002) loss 4.5703 (2.1386) lr 1.0000e-02 eta 2:29:20
epoch [1/30] batch [760/796] time 0.379 (0.387) data 0.000 (0.002) loss 0.5361 (2.1256) lr 1.0000e-02 eta 2:29:13
epoch [1/30] batch [780/796] time 0.345 (0.386) data 0.000 (0.002) loss 7.3867 (2.1310) lr 1.0000e-02 eta 2:28:48
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:50,  5.81s/it] 10%|█         | 2/20 [00:06<00:49,  2.74s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.62s/it] 20%|██        | 4/20 [00:06<00:17,  1.10s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.23it/s] 30%|███       | 6/20 [00:07<00:08,  1.57it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.50it/s] 50%|█████     | 10/20 [00:08<00:03,  2.75it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.19it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.51it/s] 70%|███████   | 14/20 [00:09<00:01,  3.77it/s] 75%|███████▌  | 15/20 [00:09<00:01,  4.11it/s] 80%|████████  | 16/20 [00:10<00:00,  4.09it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.16it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.45it/s] 95%|█████████▌| 19/20 [00:10<00:00,  3.88it/s]100%|██████████| 20/20 [00:11<00:00,  4.32it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,512
* accuracy: 76.0%
* error: 24.0%
* macro_f1: 74.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/796] time 0.371 (0.432) data 0.000 (0.036) loss 1.4414 (2.0918) lr 9.9726e-03 eta 2:46:08
epoch [2/30] batch [40/796] time 0.402 (0.410) data 0.000 (0.018) loss 3.2363 (2.1294) lr 9.9726e-03 eta 2:37:22
epoch [2/30] batch [60/796] time 0.406 (0.402) data 0.000 (0.012) loss 0.7227 (2.1800) lr 9.9726e-03 eta 2:34:18
epoch [2/30] batch [80/796] time 0.351 (0.399) data 0.000 (0.009) loss 2.6406 (2.1657) lr 9.9726e-03 eta 2:33:05
epoch [2/30] batch [100/796] time 0.388 (0.398) data 0.000 (0.007) loss 3.9180 (2.1024) lr 9.9726e-03 eta 2:32:22
epoch [2/30] batch [120/796] time 0.402 (0.395) data 0.000 (0.006) loss 0.1562 (2.0674) lr 9.9726e-03 eta 2:31:20
epoch [2/30] batch [140/796] time 0.405 (0.393) data 0.000 (0.005) loss 0.5986 (2.0402) lr 9.9726e-03 eta 2:30:17
epoch [2/30] batch [160/796] time 0.377 (0.392) data 0.000 (0.005) loss 1.2002 (1.9817) lr 9.9726e-03 eta 2:29:51
epoch [2/30] batch [180/796] time 0.409 (0.391) data 0.000 (0.004) loss 2.4082 (2.0052) lr 9.9726e-03 eta 2:29:04
epoch [2/30] batch [200/796] time 0.384 (0.390) data 0.000 (0.004) loss 0.4053 (1.9799) lr 9.9726e-03 eta 2:28:42
epoch [2/30] batch [220/796] time 0.402 (0.388) data 0.000 (0.003) loss 0.4294 (1.9967) lr 9.9726e-03 eta 2:27:57
epoch [2/30] batch [240/796] time 0.414 (0.387) data 0.000 (0.003) loss 2.2266 (2.0080) lr 9.9726e-03 eta 2:27:26
epoch [2/30] batch [260/796] time 0.398 (0.387) data 0.000 (0.003) loss 2.0449 (2.0489) lr 9.9726e-03 eta 2:27:18
epoch [2/30] batch [280/796] time 0.406 (0.388) data 0.000 (0.003) loss 1.1807 (2.0438) lr 9.9726e-03 eta 2:27:22
epoch [2/30] batch [300/796] time 0.380 (0.387) data 0.000 (0.003) loss 1.0605 (2.0562) lr 9.9726e-03 eta 2:27:05
epoch [2/30] batch [320/796] time 0.383 (0.387) data 0.000 (0.002) loss 1.5986 (2.0605) lr 9.9726e-03 eta 2:26:44
epoch [2/30] batch [340/796] time 0.364 (0.387) data 0.000 (0.002) loss 1.2246 (2.0678) lr 9.9726e-03 eta 2:26:34
epoch [2/30] batch [360/796] time 0.387 (0.387) data 0.000 (0.002) loss 1.1572 (2.0265) lr 9.9726e-03 eta 2:26:38
epoch [2/30] batch [380/796] time 0.373 (0.387) data 0.000 (0.002) loss 0.7148 (2.0212) lr 9.9726e-03 eta 2:26:31
epoch [2/30] batch [400/796] time 0.370 (0.388) data 0.000 (0.002) loss 3.1836 (2.0144) lr 9.9726e-03 eta 2:26:30
epoch [2/30] batch [420/796] time 0.409 (0.387) data 0.000 (0.002) loss 1.8877 (2.0053) lr 9.9726e-03 eta 2:26:22
epoch [2/30] batch [440/796] time 0.370 (0.388) data 0.000 (0.002) loss 1.7480 (1.9910) lr 9.9726e-03 eta 2:26:15
epoch [2/30] batch [460/796] time 0.390 (0.387) data 0.000 (0.002) loss 0.8623 (1.9802) lr 9.9726e-03 eta 2:26:00
epoch [2/30] batch [480/796] time 0.357 (0.387) data 0.000 (0.002) loss 1.5029 (1.9657) lr 9.9726e-03 eta 2:25:42
epoch [2/30] batch [500/796] time 0.401 (0.387) data 0.000 (0.002) loss 5.0547 (1.9826) lr 9.9726e-03 eta 2:25:33
epoch [2/30] batch [520/796] time 0.384 (0.387) data 0.000 (0.002) loss 1.2305 (1.9901) lr 9.9726e-03 eta 2:25:31
epoch [2/30] batch [540/796] time 0.394 (0.387) data 0.000 (0.002) loss 0.9727 (1.9707) lr 9.9726e-03 eta 2:25:20
epoch [2/30] batch [560/796] time 0.386 (0.387) data 0.000 (0.002) loss 4.5938 (1.9832) lr 9.9726e-03 eta 2:25:06
epoch [2/30] batch [580/796] time 0.372 (0.386) data 0.000 (0.001) loss 4.0781 (1.9799) lr 9.9726e-03 eta 2:24:52
epoch [2/30] batch [600/796] time 0.404 (0.387) data 0.000 (0.001) loss 1.6855 (1.9896) lr 9.9726e-03 eta 2:24:50
epoch [2/30] batch [620/796] time 0.410 (0.386) data 0.000 (0.001) loss 0.5186 (1.9828) lr 9.9726e-03 eta 2:24:40
epoch [2/30] batch [640/796] time 0.358 (0.386) data 0.000 (0.001) loss 2.6309 (1.9798) lr 9.9726e-03 eta 2:24:31
epoch [2/30] batch [660/796] time 0.408 (0.386) data 0.000 (0.001) loss 1.1172 (1.9786) lr 9.9726e-03 eta 2:24:22
epoch [2/30] batch [680/796] time 0.403 (0.386) data 0.000 (0.001) loss 1.6377 (1.9694) lr 9.9726e-03 eta 2:24:14
epoch [2/30] batch [700/796] time 0.399 (0.386) data 0.000 (0.001) loss 1.8232 (1.9708) lr 9.9726e-03 eta 2:24:07
epoch [2/30] batch [720/796] time 0.396 (0.386) data 0.000 (0.001) loss 1.2744 (1.9653) lr 9.9726e-03 eta 2:23:56
epoch [2/30] batch [740/796] time 0.408 (0.386) data 0.000 (0.001) loss 1.0850 (1.9639) lr 9.9726e-03 eta 2:23:48
epoch [2/30] batch [760/796] time 0.384 (0.386) data 0.000 (0.001) loss 5.1836 (1.9739) lr 9.9726e-03 eta 2:23:40
epoch [2/30] batch [780/796] time 0.345 (0.385) data 0.000 (0.001) loss 0.3672 (1.9795) lr 9.9726e-03 eta 2:23:16
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.66s/it] 10%|█         | 2/20 [00:06<00:52,  2.91s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.72s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.42it/s] 50%|█████     | 10/20 [00:09<00:03,  2.66it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.99it/s] 60%|██████    | 12/20 [00:09<00:02,  3.22it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.39it/s] 70%|███████   | 14/20 [00:10<00:01,  3.44it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.60it/s] 80%|████████  | 16/20 [00:10<00:01,  3.75it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.75it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.13it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.47it/s]100%|██████████| 20/20 [00:11<00:00,  4.81it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,525
* accuracy: 76.6%
* error: 23.4%
* macro_f1: 75.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/796] time 0.359 (0.431) data 0.000 (0.037) loss 3.8438 (1.7384) lr 9.8907e-03 eta 2:40:01
epoch [3/30] batch [40/796] time 0.374 (0.407) data 0.000 (0.019) loss 1.7764 (1.8566) lr 9.8907e-03 eta 2:30:43
epoch [3/30] batch [60/796] time 0.368 (0.401) data 0.000 (0.012) loss 1.4814 (1.9642) lr 9.8907e-03 eta 2:28:40
epoch [3/30] batch [80/796] time 0.379 (0.398) data 0.002 (0.009) loss 2.1973 (1.9793) lr 9.8907e-03 eta 2:27:18
epoch [3/30] batch [100/796] time 0.358 (0.395) data 0.000 (0.008) loss 3.2305 (1.9986) lr 9.8907e-03 eta 2:25:58
epoch [3/30] batch [120/796] time 0.355 (0.393) data 0.000 (0.006) loss 0.5137 (2.0475) lr 9.8907e-03 eta 2:25:12
epoch [3/30] batch [140/796] time 0.377 (0.392) data 0.000 (0.006) loss 3.5723 (2.0163) lr 9.8907e-03 eta 2:24:38
epoch [3/30] batch [160/796] time 0.401 (0.391) data 0.000 (0.005) loss 1.0869 (2.0473) lr 9.8907e-03 eta 2:24:16
epoch [3/30] batch [180/796] time 0.356 (0.390) data 0.000 (0.004) loss 1.4326 (2.0322) lr 9.8907e-03 eta 2:23:51
epoch [3/30] batch [200/796] time 0.358 (0.391) data 0.000 (0.004) loss 1.6699 (2.0075) lr 9.8907e-03 eta 2:23:51
epoch [3/30] batch [220/796] time 0.411 (0.390) data 0.000 (0.004) loss 3.9766 (2.0332) lr 9.8907e-03 eta 2:23:27
epoch [3/30] batch [240/796] time 0.384 (0.389) data 0.000 (0.003) loss 2.0469 (2.0092) lr 9.8907e-03 eta 2:22:50
epoch [3/30] batch [260/796] time 0.355 (0.388) data 0.000 (0.003) loss 4.6797 (2.0001) lr 9.8907e-03 eta 2:22:34
epoch [3/30] batch [280/796] time 0.383 (0.388) data 0.000 (0.003) loss 1.2598 (2.0373) lr 9.8907e-03 eta 2:22:25
epoch [3/30] batch [300/796] time 0.387 (0.388) data 0.000 (0.003) loss 0.3926 (2.0230) lr 9.8907e-03 eta 2:22:13
epoch [3/30] batch [320/796] time 0.393 (0.388) data 0.000 (0.003) loss 4.1406 (2.0178) lr 9.8907e-03 eta 2:21:54
epoch [3/30] batch [340/796] time 0.395 (0.387) data 0.000 (0.002) loss 0.2986 (1.9822) lr 9.8907e-03 eta 2:21:36
epoch [3/30] batch [360/796] time 0.397 (0.387) data 0.000 (0.002) loss 2.5898 (1.9663) lr 9.8907e-03 eta 2:21:25
epoch [3/30] batch [380/796] time 0.413 (0.387) data 0.000 (0.002) loss 1.0283 (1.9483) lr 9.8907e-03 eta 2:21:21
epoch [3/30] batch [400/796] time 0.404 (0.387) data 0.000 (0.002) loss 3.4473 (1.9574) lr 9.8907e-03 eta 2:21:08
epoch [3/30] batch [420/796] time 0.390 (0.386) data 0.000 (0.002) loss 0.4753 (1.9678) lr 9.8907e-03 eta 2:20:46
epoch [3/30] batch [440/796] time 0.370 (0.386) data 0.000 (0.002) loss 0.4482 (1.9534) lr 9.8907e-03 eta 2:20:36
epoch [3/30] batch [460/796] time 0.367 (0.386) data 0.000 (0.002) loss 1.0303 (1.9548) lr 9.8907e-03 eta 2:20:31
epoch [3/30] batch [480/796] time 0.393 (0.386) data 0.000 (0.002) loss 3.3965 (1.9578) lr 9.8907e-03 eta 2:20:16
epoch [3/30] batch [500/796] time 0.351 (0.386) data 0.000 (0.002) loss 3.2168 (1.9653) lr 9.8907e-03 eta 2:20:05
epoch [3/30] batch [520/796] time 0.367 (0.386) data 0.000 (0.002) loss 1.5254 (1.9560) lr 9.8907e-03 eta 2:19:54
epoch [3/30] batch [540/796] time 0.357 (0.386) data 0.000 (0.002) loss 3.2188 (1.9546) lr 9.8907e-03 eta 2:19:44
epoch [3/30] batch [560/796] time 0.402 (0.386) data 0.000 (0.002) loss 0.6328 (1.9771) lr 9.8907e-03 eta 2:19:38
epoch [3/30] batch [580/796] time 0.395 (0.386) data 0.000 (0.002) loss 5.1016 (1.9978) lr 9.8907e-03 eta 2:19:35
epoch [3/30] batch [600/796] time 0.367 (0.386) data 0.000 (0.001) loss 3.2461 (1.9900) lr 9.8907e-03 eta 2:19:27
epoch [3/30] batch [620/796] time 0.413 (0.386) data 0.000 (0.001) loss 2.0840 (1.9992) lr 9.8907e-03 eta 2:19:21
epoch [3/30] batch [640/796] time 0.392 (0.386) data 0.000 (0.001) loss 0.7720 (2.0007) lr 9.8907e-03 eta 2:19:14
epoch [3/30] batch [660/796] time 0.390 (0.386) data 0.000 (0.001) loss 1.1807 (1.9763) lr 9.8907e-03 eta 2:19:07
epoch [3/30] batch [680/796] time 0.413 (0.386) data 0.000 (0.001) loss 3.0742 (1.9685) lr 9.8907e-03 eta 2:19:01
epoch [3/30] batch [700/796] time 0.397 (0.386) data 0.000 (0.001) loss 1.8418 (1.9766) lr 9.8907e-03 eta 2:18:54
epoch [3/30] batch [720/796] time 0.372 (0.386) data 0.000 (0.001) loss 3.4453 (1.9794) lr 9.8907e-03 eta 2:18:42
epoch [3/30] batch [740/796] time 0.407 (0.386) data 0.000 (0.001) loss 1.0859 (1.9770) lr 9.8907e-03 eta 2:18:38
epoch [3/30] batch [760/796] time 0.370 (0.386) data 0.001 (0.001) loss 1.3398 (1.9734) lr 9.8907e-03 eta 2:18:29
epoch [3/30] batch [780/796] time 0.345 (0.385) data 0.000 (0.001) loss 3.1465 (1.9879) lr 9.8907e-03 eta 2:18:03
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.55s/it] 10%|█         | 2/20 [00:06<00:53,  2.95s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.73s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.43it/s] 50%|█████     | 10/20 [00:09<00:03,  2.71it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.03it/s] 60%|██████    | 12/20 [00:09<00:02,  3.35it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.62it/s] 70%|███████   | 14/20 [00:09<00:01,  3.62it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.93it/s] 80%|████████  | 16/20 [00:10<00:01,  3.99it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.20it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.33it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.78it/s]100%|██████████| 20/20 [00:11<00:00,  4.23it/s]100%|██████████| 20/20 [00:11<00:00,  1.73it/s]=> result
* total: 1,990
* correct: 1,545
* accuracy: 77.6%
* error: 22.4%
* macro_f1: 76.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/796] time 0.388 (0.430) data 0.000 (0.040) loss 0.5771 (2.2083) lr 9.7553e-03 eta 2:33:53
epoch [4/30] batch [40/796] time 0.415 (0.407) data 0.000 (0.020) loss 1.5723 (2.2406) lr 9.7553e-03 eta 2:25:27
epoch [4/30] batch [60/796] time 0.368 (0.397) data 0.000 (0.013) loss 2.6035 (2.0434) lr 9.7553e-03 eta 2:21:58
epoch [4/30] batch [80/796] time 0.386 (0.393) data 0.000 (0.010) loss 4.8555 (2.1080) lr 9.7553e-03 eta 2:20:14
epoch [4/30] batch [100/796] time 0.355 (0.391) data 0.000 (0.008) loss 1.3672 (2.0408) lr 9.7553e-03 eta 2:19:20
epoch [4/30] batch [120/796] time 0.350 (0.388) data 0.000 (0.007) loss 3.6191 (2.0623) lr 9.7553e-03 eta 2:18:20
epoch [4/30] batch [140/796] time 0.355 (0.388) data 0.000 (0.006) loss 1.0166 (2.0212) lr 9.7553e-03 eta 2:18:03
epoch [4/30] batch [160/796] time 0.396 (0.387) data 0.000 (0.005) loss 3.6016 (1.9980) lr 9.7553e-03 eta 2:17:37
epoch [4/30] batch [180/796] time 0.362 (0.386) data 0.000 (0.005) loss 1.0234 (2.0225) lr 9.7553e-03 eta 2:17:11
epoch [4/30] batch [200/796] time 0.370 (0.387) data 0.000 (0.004) loss 1.0225 (2.0094) lr 9.7553e-03 eta 2:17:18
epoch [4/30] batch [220/796] time 0.397 (0.387) data 0.000 (0.004) loss 0.7344 (2.0281) lr 9.7553e-03 eta 2:17:09
epoch [4/30] batch [240/796] time 0.365 (0.386) data 0.000 (0.004) loss 2.6348 (2.0617) lr 9.7553e-03 eta 2:16:50
epoch [4/30] batch [260/796] time 0.382 (0.386) data 0.000 (0.003) loss 0.3162 (2.0324) lr 9.7553e-03 eta 2:16:41
epoch [4/30] batch [280/796] time 0.372 (0.385) data 0.000 (0.003) loss 1.2783 (2.0109) lr 9.7553e-03 eta 2:16:16
epoch [4/30] batch [300/796] time 0.408 (0.386) data 0.000 (0.003) loss 0.2507 (2.0019) lr 9.7553e-03 eta 2:16:12
epoch [4/30] batch [320/796] time 0.369 (0.386) data 0.000 (0.003) loss 1.1611 (2.0121) lr 9.7553e-03 eta 2:16:05
epoch [4/30] batch [340/796] time 0.381 (0.385) data 0.000 (0.003) loss 1.0859 (1.9735) lr 9.7553e-03 eta 2:15:51
epoch [4/30] batch [360/796] time 0.392 (0.386) data 0.000 (0.002) loss 4.6875 (1.9578) lr 9.7553e-03 eta 2:15:48
epoch [4/30] batch [380/796] time 0.402 (0.386) data 0.000 (0.002) loss 4.2461 (1.9981) lr 9.7553e-03 eta 2:15:41
epoch [4/30] batch [400/796] time 0.370 (0.386) data 0.000 (0.002) loss 1.5449 (1.9771) lr 9.7553e-03 eta 2:15:31
epoch [4/30] batch [420/796] time 0.367 (0.385) data 0.000 (0.002) loss 0.5098 (1.9642) lr 9.7553e-03 eta 2:15:20
epoch [4/30] batch [440/796] time 0.361 (0.386) data 0.000 (0.002) loss 1.8877 (1.9587) lr 9.7553e-03 eta 2:15:16
epoch [4/30] batch [460/796] time 0.387 (0.386) data 0.000 (0.002) loss 0.9619 (1.9661) lr 9.7553e-03 eta 2:15:10
epoch [4/30] batch [480/796] time 0.408 (0.386) data 0.000 (0.002) loss 2.9355 (1.9628) lr 9.7553e-03 eta 2:15:10
epoch [4/30] batch [500/796] time 0.388 (0.386) data 0.000 (0.002) loss 2.0801 (1.9664) lr 9.7553e-03 eta 2:14:58
epoch [4/30] batch [520/796] time 0.413 (0.386) data 0.000 (0.002) loss 0.6284 (1.9504) lr 9.7553e-03 eta 2:15:00
epoch [4/30] batch [540/796] time 0.388 (0.386) data 0.000 (0.002) loss 3.4902 (1.9463) lr 9.7553e-03 eta 2:14:53
epoch [4/30] batch [560/796] time 0.385 (0.386) data 0.000 (0.002) loss 1.4902 (1.9571) lr 9.7553e-03 eta 2:14:45
epoch [4/30] batch [580/796] time 0.375 (0.386) data 0.000 (0.002) loss 1.5869 (1.9460) lr 9.7553e-03 eta 2:14:34
epoch [4/30] batch [600/796] time 0.417 (0.386) data 0.000 (0.002) loss 2.0449 (1.9459) lr 9.7553e-03 eta 2:14:33
epoch [4/30] batch [620/796] time 0.358 (0.386) data 0.000 (0.002) loss 1.9150 (1.9427) lr 9.7553e-03 eta 2:14:23
epoch [4/30] batch [640/796] time 0.401 (0.386) data 0.001 (0.001) loss 1.5488 (1.9389) lr 9.7553e-03 eta 2:14:11
epoch [4/30] batch [660/796] time 0.357 (0.386) data 0.000 (0.001) loss 1.4619 (1.9262) lr 9.7553e-03 eta 2:14:05
epoch [4/30] batch [680/796] time 0.388 (0.386) data 0.000 (0.001) loss 3.4297 (1.9326) lr 9.7553e-03 eta 2:13:51
epoch [4/30] batch [700/796] time 0.426 (0.386) data 0.000 (0.001) loss 0.8354 (1.9191) lr 9.7553e-03 eta 2:13:45
epoch [4/30] batch [720/796] time 0.358 (0.386) data 0.000 (0.001) loss 4.2930 (1.9138) lr 9.7553e-03 eta 2:13:36
epoch [4/30] batch [740/796] time 0.390 (0.386) data 0.000 (0.001) loss 0.9038 (1.9138) lr 9.7553e-03 eta 2:13:27
epoch [4/30] batch [760/796] time 0.414 (0.386) data 0.000 (0.001) loss 0.6157 (1.8960) lr 9.7553e-03 eta 2:13:20
epoch [4/30] batch [780/796] time 0.349 (0.385) data 0.000 (0.001) loss 1.9727 (1.8977) lr 9.7553e-03 eta 2:12:56
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:51,  5.84s/it] 10%|█         | 2/20 [00:06<00:50,  2.80s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.66s/it] 20%|██        | 4/20 [00:07<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:08,  1.57it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.24it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.53it/s] 50%|█████     | 10/20 [00:08<00:03,  2.76it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.22it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.39it/s] 70%|███████   | 14/20 [00:09<00:01,  3.56it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.82it/s] 80%|████████  | 16/20 [00:10<00:00,  4.11it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.21it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.69it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.10it/s]100%|██████████| 20/20 [00:11<00:00,  4.50it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,552
* accuracy: 78.0%
* error: 22.0%
* macro_f1: 77.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/796] time 0.362 (0.432) data 0.001 (0.040) loss 1.4180 (1.9109) lr 9.5677e-03 eta 2:28:46
epoch [5/30] batch [40/796] time 0.418 (0.408) data 0.000 (0.020) loss 2.1094 (1.9611) lr 9.5677e-03 eta 2:20:31
epoch [5/30] batch [60/796] time 0.391 (0.401) data 0.000 (0.013) loss 1.8125 (2.1223) lr 9.5677e-03 eta 2:17:58
epoch [5/30] batch [80/796] time 0.376 (0.397) data 0.000 (0.010) loss 2.6289 (2.0622) lr 9.5677e-03 eta 2:16:26
epoch [5/30] batch [100/796] time 0.379 (0.395) data 0.001 (0.008) loss 2.1230 (1.9008) lr 9.5677e-03 eta 2:15:41
epoch [5/30] batch [120/796] time 0.400 (0.393) data 0.000 (0.007) loss 2.7793 (1.9053) lr 9.5677e-03 eta 2:14:36
epoch [5/30] batch [140/796] time 0.395 (0.391) data 0.000 (0.006) loss 0.3357 (1.8704) lr 9.5677e-03 eta 2:13:56
epoch [5/30] batch [160/796] time 0.395 (0.391) data 0.000 (0.005) loss 1.6592 (1.8931) lr 9.5677e-03 eta 2:13:51
epoch [5/30] batch [180/796] time 0.385 (0.390) data 0.000 (0.005) loss 1.9932 (1.8941) lr 9.5677e-03 eta 2:13:14
epoch [5/30] batch [200/796] time 0.410 (0.390) data 0.000 (0.004) loss 0.7271 (1.8898) lr 9.5677e-03 eta 2:13:03
epoch [5/30] batch [220/796] time 0.399 (0.389) data 0.000 (0.004) loss 0.5645 (1.8614) lr 9.5677e-03 eta 2:12:51
epoch [5/30] batch [240/796] time 0.377 (0.389) data 0.000 (0.004) loss 1.8652 (1.8343) lr 9.5677e-03 eta 2:12:36
epoch [5/30] batch [260/796] time 0.406 (0.388) data 0.000 (0.003) loss 2.1855 (1.8239) lr 9.5677e-03 eta 2:12:17
epoch [5/30] batch [280/796] time 0.410 (0.388) data 0.000 (0.003) loss 3.6094 (1.8505) lr 9.5677e-03 eta 2:12:05
epoch [5/30] batch [300/796] time 0.362 (0.388) data 0.000 (0.003) loss 2.7344 (1.8786) lr 9.5677e-03 eta 2:11:57
epoch [5/30] batch [320/796] time 0.408 (0.387) data 0.000 (0.003) loss 2.1309 (1.8910) lr 9.5677e-03 eta 2:11:28
epoch [5/30] batch [340/796] time 0.367 (0.387) data 0.000 (0.003) loss 0.9585 (1.9108) lr 9.5677e-03 eta 2:11:13
epoch [5/30] batch [360/796] time 0.359 (0.387) data 0.000 (0.002) loss 1.5869 (1.8829) lr 9.5677e-03 eta 2:11:02
epoch [5/30] batch [380/796] time 0.385 (0.387) data 0.000 (0.002) loss 3.3027 (1.8715) lr 9.5677e-03 eta 2:10:54
epoch [5/30] batch [400/796] time 0.415 (0.386) data 0.000 (0.002) loss 1.0010 (1.8461) lr 9.5677e-03 eta 2:10:38
epoch [5/30] batch [420/796] time 0.395 (0.386) data 0.000 (0.002) loss 2.3672 (1.8440) lr 9.5677e-03 eta 2:10:31
epoch [5/30] batch [440/796] time 0.378 (0.386) data 0.000 (0.002) loss 0.9551 (1.8379) lr 9.5677e-03 eta 2:10:25
epoch [5/30] batch [460/796] time 0.409 (0.386) data 0.000 (0.002) loss 1.6709 (1.8251) lr 9.5677e-03 eta 2:10:14
epoch [5/30] batch [480/796] time 0.363 (0.386) data 0.000 (0.002) loss 0.0188 (1.8103) lr 9.5677e-03 eta 2:10:05
epoch [5/30] batch [500/796] time 0.371 (0.386) data 0.000 (0.002) loss 3.1152 (1.8148) lr 9.5677e-03 eta 2:10:01
epoch [5/30] batch [520/796] time 0.396 (0.386) data 0.000 (0.002) loss 1.3506 (1.8348) lr 9.5677e-03 eta 2:09:54
epoch [5/30] batch [540/796] time 0.379 (0.386) data 0.000 (0.002) loss 2.9023 (1.8460) lr 9.5677e-03 eta 2:09:44
epoch [5/30] batch [560/796] time 0.401 (0.386) data 0.000 (0.002) loss 0.0522 (1.8329) lr 9.5677e-03 eta 2:09:36
epoch [5/30] batch [580/796] time 0.363 (0.386) data 0.000 (0.002) loss 1.7900 (1.8239) lr 9.5677e-03 eta 2:09:28
epoch [5/30] batch [600/796] time 0.378 (0.386) data 0.000 (0.002) loss 3.0293 (1.8319) lr 9.5677e-03 eta 2:09:25
epoch [5/30] batch [620/796] time 0.371 (0.386) data 0.000 (0.002) loss 1.5449 (1.8327) lr 9.5677e-03 eta 2:09:17
epoch [5/30] batch [640/796] time 0.420 (0.387) data 0.000 (0.002) loss 0.6177 (1.8326) lr 9.5677e-03 eta 2:09:12
epoch [5/30] batch [660/796] time 0.371 (0.386) data 0.000 (0.001) loss 1.0293 (1.8178) lr 9.5677e-03 eta 2:09:02
epoch [5/30] batch [680/796] time 0.393 (0.386) data 0.000 (0.001) loss 4.8711 (1.8118) lr 9.5677e-03 eta 2:08:53
epoch [5/30] batch [700/796] time 0.401 (0.386) data 0.000 (0.001) loss 2.7363 (1.8187) lr 9.5677e-03 eta 2:08:46
epoch [5/30] batch [720/796] time 0.357 (0.386) data 0.000 (0.001) loss 0.9946 (1.8179) lr 9.5677e-03 eta 2:08:38
epoch [5/30] batch [740/796] time 0.380 (0.386) data 0.000 (0.001) loss 1.9023 (1.8071) lr 9.5677e-03 eta 2:08:29
epoch [5/30] batch [760/796] time 0.357 (0.386) data 0.000 (0.001) loss 2.6387 (1.8122) lr 9.5677e-03 eta 2:08:23
epoch [5/30] batch [780/796] time 0.349 (0.386) data 0.000 (0.001) loss 1.0059 (1.8149) lr 9.5677e-03 eta 2:08:00
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.64s/it] 10%|█         | 2/20 [00:06<00:49,  2.73s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.62s/it] 20%|██        | 4/20 [00:06<00:17,  1.10s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.24it/s] 30%|███       | 6/20 [00:07<00:08,  1.58it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.92it/s] 40%|████      | 8/20 [00:08<00:05,  2.24it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.54it/s] 50%|█████     | 10/20 [00:08<00:03,  2.76it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.95it/s] 60%|██████    | 12/20 [00:09<00:02,  3.15it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.50it/s] 70%|███████   | 14/20 [00:09<00:01,  3.72it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.86it/s] 80%|████████  | 16/20 [00:10<00:01,  3.95it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.92it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.43it/s] 95%|█████████▌| 19/20 [00:10<00:00,  3.87it/s]100%|██████████| 20/20 [00:11<00:00,  4.31it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,552
* accuracy: 78.0%
* error: 22.0%
* macro_f1: 77.2%

epoch [6/30] batch [20/796] time 0.388 (0.431) data 0.000 (0.046) loss 5.0234 (2.1641) lr 9.3301e-03 eta 2:22:42
epoch [6/30] batch [40/796] time 0.389 (0.407) data 0.000 (0.023) loss 1.7021 (2.0078) lr 9.3301e-03 eta 2:14:35
epoch [6/30] batch [60/796] time 0.358 (0.398) data 0.000 (0.015) loss 1.3809 (1.8948) lr 9.3301e-03 eta 2:11:33
epoch [6/30] batch [80/796] time 0.383 (0.395) data 0.000 (0.012) loss 5.2227 (1.8265) lr 9.3301e-03 eta 2:10:25
epoch [6/30] batch [100/796] time 0.421 (0.393) data 0.000 (0.009) loss 1.7920 (1.8439) lr 9.3301e-03 eta 2:09:37
epoch [6/30] batch [120/796] time 0.361 (0.390) data 0.000 (0.008) loss 4.9805 (1.7566) lr 9.3301e-03 eta 2:08:42
epoch [6/30] batch [140/796] time 0.399 (0.391) data 0.000 (0.007) loss 1.3350 (1.7437) lr 9.3301e-03 eta 2:08:47
epoch [6/30] batch [160/796] time 0.393 (0.391) data 0.000 (0.006) loss 2.2148 (1.7465) lr 9.3301e-03 eta 2:08:29
epoch [6/30] batch [180/796] time 0.367 (0.390) data 0.000 (0.005) loss 0.6748 (1.7152) lr 9.3301e-03 eta 2:08:06
epoch [6/30] batch [200/796] time 0.355 (0.389) data 0.000 (0.005) loss 0.8999 (1.7023) lr 9.3301e-03 eta 2:07:52
epoch [6/30] batch [220/796] time 0.427 (0.390) data 0.000 (0.004) loss 4.6484 (1.7357) lr 9.3301e-03 eta 2:07:52
epoch [6/30] batch [240/796] time 0.380 (0.389) data 0.000 (0.004) loss 2.1426 (1.7331) lr 9.3301e-03 eta 2:07:30
epoch [6/30] batch [260/796] time 0.390 (0.389) data 0.000 (0.004) loss 0.1362 (1.7340) lr 9.3301e-03 eta 2:07:19
epoch [6/30] batch [280/796] time 0.368 (0.389) data 0.000 (0.004) loss 1.6768 (1.7183) lr 9.3301e-03 eta 2:07:02
epoch [6/30] batch [300/796] time 0.426 (0.388) data 0.000 (0.003) loss 1.1133 (1.7247) lr 9.3301e-03 eta 2:06:52
epoch [6/30] batch [320/796] time 0.406 (0.388) data 0.000 (0.003) loss 1.6738 (1.7000) lr 9.3301e-03 eta 2:06:32
epoch [6/30] batch [340/796] time 0.382 (0.388) data 0.000 (0.003) loss 0.1626 (1.7068) lr 9.3301e-03 eta 2:06:24
epoch [6/30] batch [360/796] time 0.375 (0.388) data 0.000 (0.003) loss 3.0254 (1.7162) lr 9.3301e-03 eta 2:06:16
epoch [6/30] batch [380/796] time 0.372 (0.387) data 0.000 (0.003) loss 0.9712 (1.7383) lr 9.3301e-03 eta 2:06:00
epoch [6/30] batch [400/796] time 0.377 (0.387) data 0.000 (0.003) loss 5.2656 (1.7317) lr 9.3301e-03 eta 2:05:48
epoch [6/30] batch [420/796] time 0.390 (0.387) data 0.000 (0.002) loss 2.7383 (1.7285) lr 9.3301e-03 eta 2:05:32
epoch [6/30] batch [440/796] time 0.390 (0.387) data 0.000 (0.002) loss 1.5322 (1.7395) lr 9.3301e-03 eta 2:05:25
epoch [6/30] batch [460/796] time 0.367 (0.387) data 0.000 (0.002) loss 3.2832 (1.7533) lr 9.3301e-03 eta 2:05:13
epoch [6/30] batch [480/796] time 0.411 (0.386) data 0.000 (0.002) loss 1.3535 (1.7484) lr 9.3301e-03 eta 2:05:00
epoch [6/30] batch [500/796] time 0.412 (0.386) data 0.000 (0.002) loss 1.1367 (1.7549) lr 9.3301e-03 eta 2:04:48
epoch [6/30] batch [520/796] time 0.358 (0.386) data 0.000 (0.002) loss 0.7227 (1.7626) lr 9.3301e-03 eta 2:04:48
epoch [6/30] batch [540/796] time 0.384 (0.387) data 0.000 (0.002) loss 0.2598 (1.7525) lr 9.3301e-03 eta 2:04:43
epoch [6/30] batch [560/796] time 0.408 (0.386) data 0.000 (0.002) loss 1.5879 (1.7654) lr 9.3301e-03 eta 2:04:32
epoch [6/30] batch [580/796] time 0.363 (0.386) data 0.000 (0.002) loss 0.4736 (1.7648) lr 9.3301e-03 eta 2:04:26
epoch [6/30] batch [600/796] time 0.383 (0.386) data 0.000 (0.002) loss 0.0989 (1.7608) lr 9.3301e-03 eta 2:04:14
epoch [6/30] batch [620/796] time 0.410 (0.386) data 0.000 (0.002) loss 2.6113 (1.7785) lr 9.3301e-03 eta 2:04:09
epoch [6/30] batch [640/796] time 0.357 (0.386) data 0.000 (0.002) loss 0.8555 (1.7615) lr 9.3301e-03 eta 2:04:00
epoch [6/30] batch [660/796] time 0.394 (0.386) data 0.000 (0.002) loss 1.8271 (1.7657) lr 9.3301e-03 eta 2:03:50
epoch [6/30] batch [680/796] time 0.365 (0.386) data 0.000 (0.002) loss 3.1641 (1.7681) lr 9.3301e-03 eta 2:03:38
epoch [6/30] batch [700/796] time 0.374 (0.386) data 0.000 (0.002) loss 0.3101 (1.7689) lr 9.3301e-03 eta 2:03:34
epoch [6/30] batch [720/796] time 0.378 (0.386) data 0.000 (0.002) loss 0.2798 (1.7749) lr 9.3301e-03 eta 2:03:27
epoch [6/30] batch [740/796] time 0.393 (0.386) data 0.000 (0.001) loss 1.2197 (1.7965) lr 9.3301e-03 eta 2:03:14
epoch [6/30] batch [760/796] time 0.400 (0.386) data 0.000 (0.001) loss 4.3281 (1.7964) lr 9.3301e-03 eta 2:03:03
epoch [6/30] batch [780/796] time 0.344 (0.385) data 0.000 (0.001) loss 0.5967 (1.7893) lr 9.3301e-03 eta 2:02:41
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:48,  5.72s/it] 10%|█         | 2/20 [00:06<00:52,  2.89s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.71s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.74it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.13it/s] 60%|██████    | 12/20 [00:09<00:02,  3.39it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.69it/s] 70%|███████   | 14/20 [00:09<00:01,  3.80it/s] 75%|███████▌  | 15/20 [00:10<00:01,  4.00it/s] 80%|████████  | 16/20 [00:10<00:00,  4.08it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.19it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.26it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.71it/s]100%|██████████| 20/20 [00:11<00:00,  4.16it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,566
* accuracy: 78.7%
* error: 21.3%
* macro_f1: 77.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/796] time 0.379 (0.432) data 0.000 (0.038) loss 0.9805 (1.8263) lr 9.0451e-03 eta 2:17:31
epoch [7/30] batch [40/796] time 0.360 (0.410) data 0.000 (0.019) loss 2.9961 (1.7073) lr 9.0451e-03 eta 2:10:21
epoch [7/30] batch [60/796] time 0.372 (0.403) data 0.000 (0.013) loss 2.5977 (1.7065) lr 9.0451e-03 eta 2:07:50
epoch [7/30] batch [80/796] time 0.358 (0.396) data 0.000 (0.010) loss 0.2568 (1.6815) lr 9.0451e-03 eta 2:05:42
epoch [7/30] batch [100/796] time 0.401 (0.393) data 0.000 (0.008) loss 1.8623 (1.7700) lr 9.0451e-03 eta 2:04:22
epoch [7/30] batch [120/796] time 0.357 (0.392) data 0.000 (0.007) loss 1.9023 (1.7115) lr 9.0451e-03 eta 2:03:52
epoch [7/30] batch [140/796] time 0.387 (0.391) data 0.000 (0.006) loss 1.4863 (1.7122) lr 9.0451e-03 eta 2:03:39
epoch [7/30] batch [160/796] time 0.409 (0.391) data 0.000 (0.005) loss 2.9727 (1.6936) lr 9.0451e-03 eta 2:03:33
epoch [7/30] batch [180/796] time 0.408 (0.390) data 0.000 (0.004) loss 3.1543 (1.7214) lr 9.0451e-03 eta 2:03:05
epoch [7/30] batch [200/796] time 0.359 (0.390) data 0.000 (0.004) loss 0.4255 (1.6736) lr 9.0451e-03 eta 2:02:44
epoch [7/30] batch [220/796] time 0.394 (0.389) data 0.000 (0.004) loss 4.0977 (1.7370) lr 9.0451e-03 eta 2:02:29
epoch [7/30] batch [240/796] time 0.412 (0.388) data 0.000 (0.003) loss 1.5605 (1.7148) lr 9.0451e-03 eta 2:02:08
epoch [7/30] batch [260/796] time 0.367 (0.388) data 0.000 (0.003) loss 0.5913 (1.7024) lr 9.0451e-03 eta 2:01:55
epoch [7/30] batch [280/796] time 0.399 (0.388) data 0.000 (0.003) loss 0.6899 (1.7282) lr 9.0451e-03 eta 2:01:48
epoch [7/30] batch [300/796] time 0.417 (0.388) data 0.000 (0.003) loss 1.8965 (1.7067) lr 9.0451e-03 eta 2:01:43
epoch [7/30] batch [320/796] time 0.406 (0.388) data 0.000 (0.003) loss 0.4812 (1.7535) lr 9.0451e-03 eta 2:01:25
epoch [7/30] batch [340/796] time 0.396 (0.387) data 0.000 (0.002) loss 2.7188 (1.7625) lr 9.0451e-03 eta 2:01:06
epoch [7/30] batch [360/796] time 0.412 (0.388) data 0.000 (0.002) loss 2.8535 (1.7433) lr 9.0451e-03 eta 2:01:08
epoch [7/30] batch [380/796] time 0.366 (0.388) data 0.000 (0.002) loss 2.6719 (1.7355) lr 9.0451e-03 eta 2:01:04
epoch [7/30] batch [400/796] time 0.373 (0.388) data 0.000 (0.002) loss 1.0479 (1.7455) lr 9.0451e-03 eta 2:00:57
epoch [7/30] batch [420/796] time 0.399 (0.388) data 0.000 (0.002) loss 2.9297 (1.7731) lr 9.0451e-03 eta 2:00:49
epoch [7/30] batch [440/796] time 0.352 (0.388) data 0.000 (0.002) loss 1.2998 (1.7732) lr 9.0451e-03 eta 2:00:41
epoch [7/30] batch [460/796] time 0.351 (0.388) data 0.000 (0.002) loss 1.0566 (1.7716) lr 9.0451e-03 eta 2:00:28
epoch [7/30] batch [480/796] time 0.404 (0.388) data 0.000 (0.002) loss 1.2061 (1.7663) lr 9.0451e-03 eta 2:00:19
epoch [7/30] batch [500/796] time 0.377 (0.388) data 0.000 (0.002) loss 3.8750 (1.7851) lr 9.0451e-03 eta 2:00:11
epoch [7/30] batch [520/796] time 0.383 (0.387) data 0.000 (0.002) loss 2.9590 (1.7938) lr 9.0451e-03 eta 2:00:00
epoch [7/30] batch [540/796] time 0.360 (0.387) data 0.000 (0.002) loss 0.4951 (1.7755) lr 9.0451e-03 eta 1:59:46
epoch [7/30] batch [560/796] time 0.369 (0.387) data 0.000 (0.002) loss 0.2649 (1.7809) lr 9.0451e-03 eta 1:59:32
epoch [7/30] batch [580/796] time 0.421 (0.387) data 0.000 (0.002) loss 2.3340 (1.7938) lr 9.0451e-03 eta 1:59:25
epoch [7/30] batch [600/796] time 0.393 (0.387) data 0.000 (0.002) loss 1.8682 (1.8142) lr 9.0451e-03 eta 1:59:15
epoch [7/30] batch [620/796] time 0.400 (0.387) data 0.000 (0.001) loss 1.2568 (1.8173) lr 9.0451e-03 eta 1:59:07
epoch [7/30] batch [640/796] time 0.368 (0.387) data 0.000 (0.001) loss 0.5269 (1.8157) lr 9.0451e-03 eta 1:58:57
epoch [7/30] batch [660/796] time 0.403 (0.387) data 0.000 (0.001) loss 3.5859 (1.8105) lr 9.0451e-03 eta 1:58:49
epoch [7/30] batch [680/796] time 0.400 (0.387) data 0.000 (0.001) loss 1.6621 (1.8135) lr 9.0451e-03 eta 1:58:42
epoch [7/30] batch [700/796] time 0.389 (0.386) data 0.000 (0.001) loss 0.3745 (1.8111) lr 9.0451e-03 eta 1:58:30
epoch [7/30] batch [720/796] time 0.378 (0.386) data 0.000 (0.001) loss 4.3984 (1.8120) lr 9.0451e-03 eta 1:58:20
epoch [7/30] batch [740/796] time 0.370 (0.386) data 0.000 (0.001) loss 3.2910 (1.8422) lr 9.0451e-03 eta 1:58:10
epoch [7/30] batch [760/796] time 0.363 (0.386) data 0.000 (0.001) loss 0.2834 (1.8373) lr 9.0451e-03 eta 1:58:04
epoch [7/30] batch [780/796] time 0.350 (0.385) data 0.000 (0.001) loss 0.8989 (1.8328) lr 9.0451e-03 eta 1:57:41
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.63s/it] 10%|█         | 2/20 [00:06<00:51,  2.86s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.22it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.68it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.25it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.40it/s] 70%|███████   | 14/20 [00:09<00:01,  3.60it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.95it/s] 80%|████████  | 16/20 [00:10<00:01,  3.92it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.13it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.43it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.85it/s]100%|██████████| 20/20 [00:11<00:00,  4.29it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,576
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 78.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/796] time 0.407 (0.443) data 0.000 (0.038) loss 2.8672 (1.4476) lr 8.7157e-03 eta 2:14:54
epoch [8/30] batch [40/796] time 0.368 (0.414) data 0.000 (0.019) loss 1.1162 (1.7154) lr 8.7157e-03 eta 2:06:05
epoch [8/30] batch [60/796] time 0.363 (0.408) data 0.000 (0.013) loss 3.7734 (1.8924) lr 8.7157e-03 eta 2:04:05
epoch [8/30] batch [80/796] time 0.383 (0.401) data 0.000 (0.010) loss 1.7158 (1.7881) lr 8.7157e-03 eta 2:01:50
epoch [8/30] batch [100/796] time 0.376 (0.396) data 0.000 (0.008) loss 1.6279 (1.8251) lr 8.7157e-03 eta 2:00:05
epoch [8/30] batch [120/796] time 0.388 (0.392) data 0.000 (0.007) loss 1.7344 (1.7202) lr 8.7157e-03 eta 1:58:53
epoch [8/30] batch [140/796] time 0.391 (0.392) data 0.000 (0.006) loss 4.7930 (1.7710) lr 8.7157e-03 eta 1:58:35
epoch [8/30] batch [160/796] time 0.388 (0.391) data 0.000 (0.005) loss 1.0371 (1.7749) lr 8.7157e-03 eta 1:58:16
epoch [8/30] batch [180/796] time 0.411 (0.390) data 0.000 (0.004) loss 2.0977 (1.8433) lr 8.7157e-03 eta 1:57:47
epoch [8/30] batch [200/796] time 0.376 (0.390) data 0.000 (0.004) loss 1.7842 (1.7889) lr 8.7157e-03 eta 1:57:36
epoch [8/30] batch [220/796] time 0.383 (0.389) data 0.000 (0.004) loss 0.9404 (1.8128) lr 8.7157e-03 eta 1:57:15
epoch [8/30] batch [240/796] time 0.414 (0.389) data 0.000 (0.003) loss 3.8457 (1.7997) lr 8.7157e-03 eta 1:57:03
epoch [8/30] batch [260/796] time 0.411 (0.388) data 0.000 (0.003) loss 3.6562 (1.7872) lr 8.7157e-03 eta 1:56:41
epoch [8/30] batch [280/796] time 0.358 (0.388) data 0.000 (0.003) loss 1.5000 (1.7859) lr 8.7157e-03 eta 1:56:28
epoch [8/30] batch [300/796] time 0.372 (0.387) data 0.000 (0.003) loss 0.1277 (1.7695) lr 8.7157e-03 eta 1:56:13
epoch [8/30] batch [320/796] time 0.393 (0.387) data 0.000 (0.003) loss 2.3262 (1.7867) lr 8.7157e-03 eta 1:56:02
epoch [8/30] batch [340/796] time 0.409 (0.387) data 0.000 (0.002) loss 2.4766 (1.7966) lr 8.7157e-03 eta 1:55:55
epoch [8/30] batch [360/796] time 0.409 (0.387) data 0.000 (0.002) loss 2.4590 (1.7886) lr 8.7157e-03 eta 1:55:49
epoch [8/30] batch [380/796] time 0.388 (0.387) data 0.000 (0.002) loss 2.0879 (1.7989) lr 8.7157e-03 eta 1:55:38
epoch [8/30] batch [400/796] time 0.389 (0.387) data 0.000 (0.002) loss 0.6797 (1.7774) lr 8.7157e-03 eta 1:55:23
epoch [8/30] batch [420/796] time 0.399 (0.387) data 0.000 (0.002) loss 3.4141 (1.7848) lr 8.7157e-03 eta 1:55:15
epoch [8/30] batch [440/796] time 0.403 (0.387) data 0.000 (0.002) loss 0.9609 (1.7771) lr 8.7157e-03 eta 1:55:06
epoch [8/30] batch [460/796] time 0.362 (0.387) data 0.000 (0.002) loss 4.5625 (1.8041) lr 8.7157e-03 eta 1:55:01
epoch [8/30] batch [480/796] time 0.374 (0.387) data 0.000 (0.002) loss 1.1045 (1.8122) lr 8.7157e-03 eta 1:54:52
epoch [8/30] batch [500/796] time 0.369 (0.386) data 0.000 (0.002) loss 0.1194 (1.8039) lr 8.7157e-03 eta 1:54:41
epoch [8/30] batch [520/796] time 0.369 (0.386) data 0.000 (0.002) loss 2.1465 (1.7952) lr 8.7157e-03 eta 1:54:30
epoch [8/30] batch [540/796] time 0.407 (0.386) data 0.000 (0.002) loss 2.4883 (1.8086) lr 8.7157e-03 eta 1:54:20
epoch [8/30] batch [560/796] time 0.383 (0.386) data 0.000 (0.002) loss 1.8936 (1.8207) lr 8.7157e-03 eta 1:54:08
epoch [8/30] batch [580/796] time 0.375 (0.386) data 0.000 (0.002) loss 1.8477 (1.8036) lr 8.7157e-03 eta 1:53:55
epoch [8/30] batch [600/796] time 0.403 (0.386) data 0.000 (0.002) loss 1.2266 (1.7864) lr 8.7157e-03 eta 1:53:53
epoch [8/30] batch [620/796] time 0.410 (0.386) data 0.000 (0.001) loss 0.3669 (1.7929) lr 8.7157e-03 eta 1:53:47
epoch [8/30] batch [640/796] time 0.358 (0.386) data 0.000 (0.001) loss 0.5586 (1.7822) lr 8.7157e-03 eta 1:53:40
epoch [8/30] batch [660/796] time 0.391 (0.386) data 0.000 (0.001) loss 3.7793 (1.7763) lr 8.7157e-03 eta 1:53:31
epoch [8/30] batch [680/796] time 0.407 (0.386) data 0.000 (0.001) loss 2.0430 (1.7702) lr 8.7157e-03 eta 1:53:25
epoch [8/30] batch [700/796] time 0.377 (0.386) data 0.000 (0.001) loss 0.5029 (1.7463) lr 8.7157e-03 eta 1:53:19
epoch [8/30] batch [720/796] time 0.404 (0.386) data 0.000 (0.001) loss 1.4082 (1.7454) lr 8.7157e-03 eta 1:53:10
epoch [8/30] batch [740/796] time 0.380 (0.386) data 0.000 (0.001) loss 2.3848 (1.7495) lr 8.7157e-03 eta 1:53:04
epoch [8/30] batch [760/796] time 0.363 (0.386) data 0.000 (0.001) loss 2.6641 (1.7424) lr 8.7157e-03 eta 1:52:55
epoch [8/30] batch [780/796] time 0.348 (0.385) data 0.000 (0.001) loss 1.9199 (1.7436) lr 8.7157e-03 eta 1:52:33
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.65s/it] 10%|█         | 2/20 [00:06<00:49,  2.76s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.64s/it] 20%|██        | 4/20 [00:06<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:08,  1.58it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.93it/s] 40%|████      | 8/20 [00:08<00:05,  2.25it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.52it/s] 50%|█████     | 10/20 [00:08<00:03,  2.75it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.95it/s] 60%|██████    | 12/20 [00:09<00:02,  3.18it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.34it/s] 70%|███████   | 14/20 [00:09<00:01,  3.49it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.70it/s] 80%|████████  | 16/20 [00:10<00:01,  3.98it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.91it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.29it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.59it/s]100%|██████████| 20/20 [00:11<00:00,  4.91it/s]100%|██████████| 20/20 [00:11<00:00,  1.79it/s]=> result
* total: 1,990
* correct: 1,569
* accuracy: 78.8%
* error: 21.2%
* macro_f1: 78.3%

epoch [9/30] batch [20/796] time 0.401 (0.450) data 0.000 (0.052) loss 0.8848 (1.3861) lr 8.3457e-03 eta 2:11:16
epoch [9/30] batch [40/796] time 0.410 (0.417) data 0.000 (0.026) loss 1.1162 (1.7031) lr 8.3457e-03 eta 2:01:21
epoch [9/30] batch [60/796] time 0.375 (0.406) data 0.000 (0.017) loss 0.2385 (1.6968) lr 8.3457e-03 eta 1:57:59
epoch [9/30] batch [80/796] time 0.364 (0.399) data 0.000 (0.013) loss 5.8320 (1.7653) lr 8.3457e-03 eta 1:55:53
epoch [9/30] batch [100/796] time 0.361 (0.395) data 0.000 (0.011) loss 1.3643 (1.7586) lr 8.3457e-03 eta 1:54:40
epoch [9/30] batch [120/796] time 0.403 (0.394) data 0.000 (0.009) loss 0.5068 (1.8089) lr 8.3457e-03 eta 1:54:20
epoch [9/30] batch [140/796] time 0.386 (0.393) data 0.000 (0.008) loss 2.7227 (1.8165) lr 8.3457e-03 eta 1:53:41
epoch [9/30] batch [160/796] time 0.388 (0.393) data 0.000 (0.007) loss 4.1523 (1.7970) lr 8.3457e-03 eta 1:53:41
epoch [9/30] batch [180/796] time 0.363 (0.392) data 0.001 (0.006) loss 0.3088 (1.7740) lr 8.3457e-03 eta 1:53:21
epoch [9/30] batch [200/796] time 0.395 (0.392) data 0.000 (0.005) loss 1.8555 (1.7617) lr 8.3457e-03 eta 1:53:04
epoch [9/30] batch [220/796] time 0.353 (0.391) data 0.000 (0.005) loss 0.8633 (1.7081) lr 8.3457e-03 eta 1:52:35
epoch [9/30] batch [240/796] time 0.385 (0.390) data 0.000 (0.005) loss 4.9336 (1.7846) lr 8.3457e-03 eta 1:52:18
epoch [9/30] batch [260/796] time 0.379 (0.389) data 0.000 (0.004) loss 1.4961 (1.7282) lr 8.3457e-03 eta 1:51:52
epoch [9/30] batch [280/796] time 0.362 (0.389) data 0.000 (0.004) loss 0.3320 (1.7203) lr 8.3457e-03 eta 1:51:35
epoch [9/30] batch [300/796] time 0.358 (0.388) data 0.000 (0.004) loss 1.8252 (1.7297) lr 8.3457e-03 eta 1:51:11
epoch [9/30] batch [320/796] time 0.405 (0.388) data 0.000 (0.004) loss 1.6074 (1.7299) lr 8.3457e-03 eta 1:51:02
epoch [9/30] batch [340/796] time 0.376 (0.387) data 0.000 (0.003) loss 0.1356 (1.7295) lr 8.3457e-03 eta 1:50:45
epoch [9/30] batch [360/796] time 0.400 (0.387) data 0.000 (0.003) loss 3.0312 (1.7236) lr 8.3457e-03 eta 1:50:32
epoch [9/30] batch [380/796] time 0.377 (0.386) data 0.000 (0.003) loss 0.3977 (1.7033) lr 8.3457e-03 eta 1:50:21
epoch [9/30] batch [400/796] time 0.379 (0.386) data 0.000 (0.003) loss 0.7441 (1.6959) lr 8.3457e-03 eta 1:50:13
epoch [9/30] batch [420/796] time 0.362 (0.386) data 0.000 (0.003) loss 1.5039 (1.6859) lr 8.3457e-03 eta 1:50:02
epoch [9/30] batch [440/796] time 0.363 (0.386) data 0.000 (0.003) loss 1.0586 (1.6838) lr 8.3457e-03 eta 1:49:52
epoch [9/30] batch [460/796] time 0.363 (0.386) data 0.001 (0.003) loss 1.7178 (1.6814) lr 8.3457e-03 eta 1:49:50
epoch [9/30] batch [480/796] time 0.403 (0.387) data 0.000 (0.002) loss 0.5957 (1.7057) lr 8.3457e-03 eta 1:49:44
epoch [9/30] batch [500/796] time 0.385 (0.387) data 0.000 (0.002) loss 0.5210 (1.7255) lr 8.3457e-03 eta 1:49:38
epoch [9/30] batch [520/796] time 0.390 (0.387) data 0.000 (0.002) loss 0.5566 (1.7168) lr 8.3457e-03 eta 1:49:33
epoch [9/30] batch [540/796] time 0.393 (0.387) data 0.000 (0.002) loss 1.6670 (1.7181) lr 8.3457e-03 eta 1:49:22
epoch [9/30] batch [560/796] time 0.389 (0.386) data 0.000 (0.002) loss 2.0781 (1.7207) lr 8.3457e-03 eta 1:49:10
epoch [9/30] batch [580/796] time 0.413 (0.387) data 0.000 (0.002) loss 1.6133 (1.7408) lr 8.3457e-03 eta 1:49:09
epoch [9/30] batch [600/796] time 0.397 (0.387) data 0.000 (0.002) loss 0.7422 (1.7389) lr 8.3457e-03 eta 1:48:58
epoch [9/30] batch [620/796] time 0.405 (0.387) data 0.000 (0.002) loss 1.0439 (1.7351) lr 8.3457e-03 eta 1:48:50
epoch [9/30] batch [640/796] time 0.357 (0.386) data 0.000 (0.002) loss 0.9199 (1.7455) lr 8.3457e-03 eta 1:48:40
epoch [9/30] batch [660/796] time 0.370 (0.386) data 0.000 (0.002) loss 2.5898 (1.7581) lr 8.3457e-03 eta 1:48:32
epoch [9/30] batch [680/796] time 0.364 (0.386) data 0.000 (0.002) loss 0.7300 (1.7571) lr 8.3457e-03 eta 1:48:25
epoch [9/30] batch [700/796] time 0.357 (0.386) data 0.000 (0.002) loss 1.4062 (1.7527) lr 8.3457e-03 eta 1:48:16
epoch [9/30] batch [720/796] time 0.385 (0.386) data 0.000 (0.002) loss 0.5020 (1.7559) lr 8.3457e-03 eta 1:48:04
epoch [9/30] batch [740/796] time 0.406 (0.386) data 0.000 (0.002) loss 0.5347 (1.7616) lr 8.3457e-03 eta 1:47:55
epoch [9/30] batch [760/796] time 0.366 (0.386) data 0.000 (0.002) loss 2.3574 (1.7660) lr 8.3457e-03 eta 1:47:47
epoch [9/30] batch [780/796] time 0.344 (0.385) data 0.000 (0.002) loss 1.7070 (1.7624) lr 8.3457e-03 eta 1:47:29
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.52s/it] 10%|█         | 2/20 [00:06<00:53,  2.95s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.74s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:09<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.95it/s] 60%|██████    | 12/20 [00:09<00:02,  3.18it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.38it/s] 70%|███████   | 14/20 [00:10<00:01,  3.54it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.72it/s] 80%|████████  | 16/20 [00:10<00:01,  3.99it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.13it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.48it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.91it/s]100%|██████████| 20/20 [00:11<00:00,  4.35it/s]100%|██████████| 20/20 [00:11<00:00,  1.73it/s]=> result
* total: 1,990
* correct: 1,584
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 79.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/796] time 0.418 (0.439) data 0.000 (0.044) loss 2.2266 (1.5648) lr 7.9389e-03 eta 2:02:01
epoch [10/30] batch [40/796] time 0.410 (0.412) data 0.000 (0.022) loss 1.3936 (1.6347) lr 7.9389e-03 eta 1:54:24
epoch [10/30] batch [60/796] time 0.368 (0.402) data 0.000 (0.015) loss 1.0439 (1.5955) lr 7.9389e-03 eta 1:51:40
epoch [10/30] batch [80/796] time 0.366 (0.399) data 0.000 (0.011) loss 0.6797 (1.5357) lr 7.9389e-03 eta 1:50:35
epoch [10/30] batch [100/796] time 0.414 (0.397) data 0.000 (0.009) loss 0.3987 (1.5444) lr 7.9389e-03 eta 1:49:53
epoch [10/30] batch [120/796] time 0.377 (0.395) data 0.000 (0.008) loss 3.1484 (1.5755) lr 7.9389e-03 eta 1:49:14
epoch [10/30] batch [140/796] time 0.363 (0.393) data 0.000 (0.007) loss 0.7939 (1.6167) lr 7.9389e-03 eta 1:48:36
epoch [10/30] batch [160/796] time 0.387 (0.392) data 0.000 (0.006) loss 0.6108 (1.5895) lr 7.9389e-03 eta 1:48:04
epoch [10/30] batch [180/796] time 0.371 (0.390) data 0.000 (0.005) loss 0.5093 (1.5747) lr 7.9389e-03 eta 1:47:36
epoch [10/30] batch [200/796] time 0.379 (0.390) data 0.000 (0.005) loss 3.6309 (1.6024) lr 7.9389e-03 eta 1:47:14
epoch [10/30] batch [220/796] time 0.381 (0.389) data 0.000 (0.004) loss 3.5371 (1.5899) lr 7.9389e-03 eta 1:46:56
epoch [10/30] batch [240/796] time 0.386 (0.388) data 0.000 (0.004) loss 2.0645 (1.5968) lr 7.9389e-03 eta 1:46:38
epoch [10/30] batch [260/796] time 0.404 (0.388) data 0.001 (0.004) loss 2.4551 (1.6036) lr 7.9389e-03 eta 1:46:22
epoch [10/30] batch [280/796] time 0.371 (0.388) data 0.000 (0.003) loss 0.9927 (1.5827) lr 7.9389e-03 eta 1:46:09
epoch [10/30] batch [300/796] time 0.389 (0.388) data 0.000 (0.003) loss 1.5811 (1.6020) lr 7.9389e-03 eta 1:46:02
epoch [10/30] batch [320/796] time 0.374 (0.388) data 0.000 (0.003) loss 1.1514 (1.6004) lr 7.9389e-03 eta 1:45:55
epoch [10/30] batch [340/796] time 0.408 (0.387) data 0.000 (0.003) loss 2.5234 (1.6213) lr 7.9389e-03 eta 1:45:43
epoch [10/30] batch [360/796] time 0.367 (0.387) data 0.000 (0.003) loss 1.8633 (1.6392) lr 7.9389e-03 eta 1:45:33
epoch [10/30] batch [380/796] time 0.373 (0.387) data 0.000 (0.003) loss 1.6455 (1.6366) lr 7.9389e-03 eta 1:45:22
epoch [10/30] batch [400/796] time 0.366 (0.387) data 0.000 (0.002) loss 3.8535 (1.6433) lr 7.9389e-03 eta 1:45:17
epoch [10/30] batch [420/796] time 0.401 (0.387) data 0.000 (0.002) loss 1.9150 (1.6481) lr 7.9389e-03 eta 1:45:10
epoch [10/30] batch [440/796] time 0.366 (0.387) data 0.000 (0.002) loss 0.3665 (1.6438) lr 7.9389e-03 eta 1:44:59
epoch [10/30] batch [460/796] time 0.367 (0.387) data 0.000 (0.002) loss 2.3027 (1.6533) lr 7.9389e-03 eta 1:44:48
epoch [10/30] batch [480/796] time 0.395 (0.387) data 0.000 (0.002) loss 3.4414 (1.6352) lr 7.9389e-03 eta 1:44:38
epoch [10/30] batch [500/796] time 0.394 (0.387) data 0.000 (0.002) loss 1.0117 (1.6603) lr 7.9389e-03 eta 1:44:28
epoch [10/30] batch [520/796] time 0.391 (0.386) data 0.000 (0.002) loss 1.3164 (1.6656) lr 7.9389e-03 eta 1:44:17
epoch [10/30] batch [540/796] time 0.366 (0.386) data 0.000 (0.002) loss 0.3240 (1.6673) lr 7.9389e-03 eta 1:44:10
epoch [10/30] batch [560/796] time 0.364 (0.386) data 0.000 (0.002) loss 1.5322 (1.6523) lr 7.9389e-03 eta 1:44:02
epoch [10/30] batch [580/796] time 0.350 (0.386) data 0.000 (0.002) loss 0.6621 (1.6455) lr 7.9389e-03 eta 1:43:50
epoch [10/30] batch [600/796] time 0.401 (0.386) data 0.000 (0.002) loss 1.2520 (1.6580) lr 7.9389e-03 eta 1:43:41
epoch [10/30] batch [620/796] time 0.399 (0.386) data 0.000 (0.002) loss 0.8696 (1.6354) lr 7.9389e-03 eta 1:43:29
epoch [10/30] batch [640/796] time 0.387 (0.386) data 0.000 (0.002) loss 1.0615 (1.6444) lr 7.9389e-03 eta 1:43:25
epoch [10/30] batch [660/796] time 0.392 (0.386) data 0.000 (0.002) loss 2.5449 (1.6455) lr 7.9389e-03 eta 1:43:19
epoch [10/30] batch [680/796] time 0.359 (0.386) data 0.000 (0.002) loss 1.0527 (1.6561) lr 7.9389e-03 eta 1:43:15
epoch [10/30] batch [700/796] time 0.412 (0.386) data 0.000 (0.002) loss 2.9316 (1.6806) lr 7.9389e-03 eta 1:43:06
epoch [10/30] batch [720/796] time 0.359 (0.386) data 0.000 (0.001) loss 2.2148 (1.6748) lr 7.9389e-03 eta 1:42:54
epoch [10/30] batch [740/796] time 0.361 (0.386) data 0.000 (0.001) loss 3.9180 (1.6807) lr 7.9389e-03 eta 1:42:47
epoch [10/30] batch [760/796] time 0.387 (0.386) data 0.000 (0.001) loss 4.1836 (1.6929) lr 7.9389e-03 eta 1:42:38
epoch [10/30] batch [780/796] time 0.345 (0.385) data 0.000 (0.001) loss 4.7383 (1.7057) lr 7.9389e-03 eta 1:42:17
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.64s/it] 10%|█         | 2/20 [00:06<00:52,  2.94s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.73s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.84it/s] 40%|████      | 8/20 [00:08<00:05,  2.14it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.40it/s] 50%|█████     | 10/20 [00:09<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.02it/s] 60%|██████    | 12/20 [00:09<00:02,  3.31it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.59it/s] 70%|███████   | 14/20 [00:09<00:01,  3.74it/s] 75%|███████▌  | 15/20 [00:10<00:01,  4.05it/s] 80%|████████  | 16/20 [00:10<00:00,  4.01it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.00it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.48it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.91it/s]100%|██████████| 20/20 [00:11<00:00,  4.35it/s]100%|██████████| 20/20 [00:11<00:00,  1.73it/s]=> result
* total: 1,990
* correct: 1,574
* accuracy: 79.1%
* error: 20.9%
* macro_f1: 78.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/796] time 0.356 (0.429) data 0.000 (0.036) loss 1.3936 (1.6651) lr 7.5000e-03 eta 1:53:33
epoch [11/30] batch [40/796] time 0.409 (0.404) data 0.000 (0.018) loss 0.5225 (1.5846) lr 7.5000e-03 eta 1:46:58
epoch [11/30] batch [60/796] time 0.405 (0.400) data 0.000 (0.012) loss 1.2705 (1.6199) lr 7.5000e-03 eta 1:45:48
epoch [11/30] batch [80/796] time 0.411 (0.396) data 0.000 (0.009) loss 1.5684 (1.5046) lr 7.5000e-03 eta 1:44:30
epoch [11/30] batch [100/796] time 0.405 (0.393) data 0.000 (0.008) loss 3.2227 (1.5787) lr 7.5000e-03 eta 1:43:31
epoch [11/30] batch [120/796] time 0.406 (0.391) data 0.000 (0.006) loss 0.5562 (1.5882) lr 7.5000e-03 eta 1:43:00
epoch [11/30] batch [140/796] time 0.375 (0.390) data 0.000 (0.005) loss 0.8154 (1.5659) lr 7.5000e-03 eta 1:42:37
epoch [11/30] batch [160/796] time 0.365 (0.390) data 0.000 (0.005) loss 0.7700 (1.5899) lr 7.5000e-03 eta 1:42:26
epoch [11/30] batch [180/796] time 0.411 (0.389) data 0.000 (0.004) loss 1.8574 (1.6035) lr 7.5000e-03 eta 1:42:09
epoch [11/30] batch [200/796] time 0.398 (0.389) data 0.000 (0.004) loss 4.0859 (1.6528) lr 7.5000e-03 eta 1:41:59
epoch [11/30] batch [220/796] time 0.348 (0.388) data 0.000 (0.004) loss 4.7188 (1.6595) lr 7.5000e-03 eta 1:41:30
epoch [11/30] batch [240/796] time 0.392 (0.387) data 0.000 (0.003) loss 1.2725 (1.6733) lr 7.5000e-03 eta 1:41:09
epoch [11/30] batch [260/796] time 0.363 (0.386) data 0.000 (0.003) loss 1.7871 (1.6621) lr 7.5000e-03 eta 1:40:47
epoch [11/30] batch [280/796] time 0.375 (0.386) data 0.000 (0.003) loss 4.4414 (1.6784) lr 7.5000e-03 eta 1:40:37
epoch [11/30] batch [300/796] time 0.378 (0.386) data 0.001 (0.003) loss 0.8223 (1.6780) lr 7.5000e-03 eta 1:40:26
epoch [11/30] batch [320/796] time 0.392 (0.386) data 0.000 (0.003) loss 2.5039 (1.6945) lr 7.5000e-03 eta 1:40:22
epoch [11/30] batch [340/796] time 0.350 (0.386) data 0.000 (0.002) loss 2.0352 (1.7138) lr 7.5000e-03 eta 1:40:09
epoch [11/30] batch [360/796] time 0.358 (0.386) data 0.000 (0.002) loss 1.0137 (1.6990) lr 7.5000e-03 eta 1:39:59
epoch [11/30] batch [380/796] time 0.379 (0.385) data 0.000 (0.002) loss 2.3008 (1.6979) lr 7.5000e-03 eta 1:39:46
epoch [11/30] batch [400/796] time 0.372 (0.385) data 0.000 (0.002) loss 0.8564 (1.6893) lr 7.5000e-03 eta 1:39:30
epoch [11/30] batch [420/796] time 0.395 (0.385) data 0.000 (0.002) loss 3.2188 (1.6686) lr 7.5000e-03 eta 1:39:23
epoch [11/30] batch [440/796] time 0.413 (0.385) data 0.000 (0.002) loss 0.0928 (1.6961) lr 7.5000e-03 eta 1:39:20
epoch [11/30] batch [460/796] time 0.375 (0.385) data 0.000 (0.002) loss 1.3643 (1.6691) lr 7.5000e-03 eta 1:39:10
epoch [11/30] batch [480/796] time 0.356 (0.385) data 0.000 (0.002) loss 1.4863 (1.6719) lr 7.5000e-03 eta 1:39:01
epoch [11/30] batch [500/796] time 0.357 (0.385) data 0.000 (0.002) loss 0.5190 (1.6525) lr 7.5000e-03 eta 1:38:54
epoch [11/30] batch [520/796] time 0.433 (0.385) data 0.000 (0.002) loss 1.0283 (1.6521) lr 7.5000e-03 eta 1:38:53
epoch [11/30] batch [540/796] time 0.394 (0.385) data 0.000 (0.002) loss 4.9883 (1.6431) lr 7.5000e-03 eta 1:38:46
epoch [11/30] batch [560/796] time 0.393 (0.385) data 0.000 (0.002) loss 1.6250 (1.6374) lr 7.5000e-03 eta 1:38:39
epoch [11/30] batch [580/796] time 0.380 (0.385) data 0.000 (0.002) loss 0.5972 (1.6497) lr 7.5000e-03 eta 1:38:33
epoch [11/30] batch [600/796] time 0.390 (0.385) data 0.000 (0.001) loss 2.5742 (1.6605) lr 7.5000e-03 eta 1:38:23
epoch [11/30] batch [620/796] time 0.380 (0.385) data 0.000 (0.001) loss 0.9023 (1.6691) lr 7.5000e-03 eta 1:38:17
epoch [11/30] batch [640/796] time 0.366 (0.385) data 0.000 (0.001) loss 1.2500 (1.6762) lr 7.5000e-03 eta 1:38:08
epoch [11/30] batch [660/796] time 0.368 (0.385) data 0.000 (0.001) loss 2.3730 (1.6844) lr 7.5000e-03 eta 1:38:01
epoch [11/30] batch [680/796] time 0.387 (0.385) data 0.000 (0.001) loss 0.7974 (1.6861) lr 7.5000e-03 eta 1:37:53
epoch [11/30] batch [700/796] time 0.385 (0.385) data 0.000 (0.001) loss 1.0479 (1.6924) lr 7.5000e-03 eta 1:37:43
epoch [11/30] batch [720/796] time 0.361 (0.385) data 0.000 (0.001) loss 0.7856 (1.6851) lr 7.5000e-03 eta 1:37:32
epoch [11/30] batch [740/796] time 0.388 (0.385) data 0.000 (0.001) loss 1.1211 (1.6790) lr 7.5000e-03 eta 1:37:28
epoch [11/30] batch [760/796] time 0.421 (0.385) data 0.000 (0.001) loss 2.5469 (1.6716) lr 7.5000e-03 eta 1:37:20
epoch [11/30] batch [780/796] time 0.344 (0.384) data 0.000 (0.001) loss 1.7910 (1.6779) lr 7.5000e-03 eta 1:37:00
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.61s/it] 10%|█         | 2/20 [00:06<00:50,  2.81s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.66s/it] 20%|██        | 4/20 [00:07<00:17,  1.12s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:08,  1.56it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.28it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.60it/s] 70%|███████   | 14/20 [00:09<00:01,  3.78it/s] 75%|███████▌  | 15/20 [00:09<00:01,  4.11it/s] 80%|████████  | 16/20 [00:10<00:00,  4.37it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.46it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.19it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.65it/s]100%|██████████| 20/20 [00:11<00:00,  4.11it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,579
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 78.8%

slurmstepd: error: *** JOB 395644 ON b10 CANCELLED AT 2024-02-29T08:02:20 DUE TO TIME LIMIT ***

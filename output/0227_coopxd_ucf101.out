set -e
set -x

eval "$(conda shell.bash hook)"
++ conda shell.bash hook
+ eval 'export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We're not allowing PS1 to be unbound. It must at least be set.
    # However, we're not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi
++ '[' -z x ']'

conda activate base
++ conda activate base
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate base
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate base
+++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate base
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(base) '
+++ PS1='(base) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
+++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
+++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda'
+++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda
+++ CONDA_PREFIX=/home/s2/mjoolee/anaconda
export CONDA_SHLVL='3'
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
export CONDA_DEFAULT_ENV='base'
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
export CONDA_PROMPT_MODIFIER='(base) '
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
export CONDA_PREFIX_2='/home/s2/mjoolee/anaconda/envs/dassl'
+++ export CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
+++ CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
+++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
+++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
+++ export _CE_M=
+++ _CE_M=
export _CE_CONDA=''
+++ export _CE_CONDA=
+++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
+++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
conda activate dassl
+ conda activate dassl
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate dassl
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate dassl
++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate dassl
+ ask_conda='PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
+ eval 'PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(dassl) '
++ PS1='(dassl) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda/envs/dassl'
++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
++ CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_SHLVL='4'
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
export CONDA_DEFAULT_ENV='dassl'
++ export CONDA_DEFAULT_ENV=dassl
++ CONDA_DEFAULT_ENV=dassl
export CONDA_PROMPT_MODIFIER='(dassl) '
++ export 'CONDA_PROMPT_MODIFIER=(dassl) '
++ CONDA_PROMPT_MODIFIER='(dassl) '
export CONDA_PREFIX_3='/home/s2/mjoolee/anaconda'
++ export CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
++ CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r

GPU=0
+ GPU=0
SHOT=16
+ SHOT=16
EPOCH=200
+ EPOCH=200
cfg=vit_b16_ctxv1
+ cfg=vit_b16_ctxv1
TRAINER=CoOp
+ TRAINER=CoOp


for seed in 1 2 3
 do
     #training
     sh scripts/coop/crossdataset_train.sh ucf101 ${seed} ${GPU} ${cfg} ${SHOT} ${TRAINER}
 done         
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_train.sh ucf101 1 0 vit_b16_ctxv1 16 CoOp
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_1.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/200] batch [5/50] time 0.083 (0.590) data 0.000 (0.172) loss 1.7891 (1.8207) acc 56.2500 (56.8750) lr 1.0000e-05 eta 1:38:13
epoch [1/200] batch [10/50] time 0.082 (0.336) data 0.000 (0.086) loss 1.5068 (1.7956) acc 59.3750 (54.0625) lr 1.0000e-05 eta 0:55:58
epoch [1/200] batch [15/50] time 0.083 (0.252) data 0.000 (0.057) loss 2.5176 (1.8967) acc 43.7500 (52.2917) lr 1.0000e-05 eta 0:41:53
epoch [1/200] batch [20/50] time 0.083 (0.210) data 0.000 (0.043) loss 2.3438 (1.8434) acc 40.6250 (52.9688) lr 1.0000e-05 eta 0:34:50
epoch [1/200] batch [25/50] time 0.083 (0.184) data 0.001 (0.035) loss 1.6758 (1.8328) acc 65.6250 (52.7500) lr 1.0000e-05 eta 0:30:38
epoch [1/200] batch [30/50] time 0.083 (0.167) data 0.000 (0.029) loss 1.6973 (1.8185) acc 59.3750 (52.7083) lr 1.0000e-05 eta 0:27:48
epoch [1/200] batch [35/50] time 0.083 (0.155) data 0.000 (0.025) loss 2.0566 (1.8300) acc 34.3750 (52.5893) lr 1.0000e-05 eta 0:25:47
epoch [1/200] batch [40/50] time 0.081 (0.146) data 0.000 (0.022) loss 1.4072 (1.8193) acc 56.2500 (52.7344) lr 1.0000e-05 eta 0:24:14
epoch [1/200] batch [45/50] time 0.082 (0.139) data 0.000 (0.019) loss 1.5605 (1.8153) acc 56.2500 (52.9861) lr 1.0000e-05 eta 0:23:02
epoch [1/200] batch [50/50] time 0.082 (0.133) data 0.000 (0.017) loss 1.7578 (1.8028) acc 40.6250 (52.5625) lr 2.0000e-03 eta 0:22:04
epoch [2/200] batch [5/50] time 0.083 (0.193) data 0.000 (0.109) loss 1.6357 (1.7982) acc 59.3750 (55.0000) lr 2.0000e-03 eta 0:31:57
epoch [2/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.055) loss 1.7158 (1.6317) acc 56.2500 (58.1250) lr 2.0000e-03 eta 0:22:53
epoch [2/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.037) loss 1.2969 (1.5660) acc 68.7500 (58.7500) lr 2.0000e-03 eta 0:19:51
epoch [2/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.027) loss 1.7334 (1.5124) acc 43.7500 (59.3750) lr 2.0000e-03 eta 0:18:21
epoch [2/200] batch [25/50] time 0.083 (0.105) data 0.000 (0.022) loss 1.5176 (1.5227) acc 65.6250 (59.2500) lr 2.0000e-03 eta 0:17:26
epoch [2/200] batch [30/50] time 0.083 (0.102) data 0.000 (0.018) loss 1.3623 (1.5283) acc 59.3750 (58.9583) lr 2.0000e-03 eta 0:16:49
epoch [2/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.016) loss 1.5439 (1.5211) acc 62.5000 (59.2857) lr 2.0000e-03 eta 0:16:23
epoch [2/200] batch [40/50] time 0.082 (0.097) data 0.000 (0.014) loss 1.5459 (1.5238) acc 59.3750 (58.9062) lr 2.0000e-03 eta 0:16:02
epoch [2/200] batch [45/50] time 0.082 (0.095) data 0.000 (0.012) loss 1.2803 (1.5052) acc 71.8750 (59.2361) lr 2.0000e-03 eta 0:15:45
epoch [2/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.2305 (1.5080) acc 68.7500 (59.3750) lr 1.9999e-03 eta 0:15:31
epoch [3/200] batch [5/50] time 0.083 (0.190) data 0.000 (0.104) loss 1.5615 (1.3424) acc 62.5000 (61.8750) lr 1.9999e-03 eta 0:31:16
epoch [3/200] batch [10/50] time 0.083 (0.137) data 0.000 (0.052) loss 1.4883 (1.3774) acc 53.1250 (59.6875) lr 1.9999e-03 eta 0:22:30
epoch [3/200] batch [15/50] time 0.083 (0.119) data 0.000 (0.035) loss 1.2764 (1.4116) acc 65.6250 (59.3750) lr 1.9999e-03 eta 0:19:34
epoch [3/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.5312 (1.3997) acc 56.2500 (59.3750) lr 1.9999e-03 eta 0:18:08
epoch [3/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.5176 (1.4171) acc 46.8750 (58.8750) lr 1.9999e-03 eta 0:17:15
epoch [3/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.018) loss 1.1992 (1.4018) acc 62.5000 (59.2708) lr 1.9999e-03 eta 0:16:40
epoch [3/200] batch [35/50] time 0.083 (0.099) data 0.001 (0.015) loss 1.2725 (1.4029) acc 56.2500 (59.3750) lr 1.9999e-03 eta 0:16:16
epoch [3/200] batch [40/50] time 0.082 (0.097) data 0.000 (0.013) loss 1.6943 (1.4052) acc 50.0000 (59.2188) lr 1.9999e-03 eta 0:15:55
epoch [3/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 1.4443 (1.3869) acc 56.2500 (60.2778) lr 1.9999e-03 eta 0:15:39
epoch [3/200] batch [50/50] time 0.082 (0.094) data 0.000 (0.011) loss 1.5498 (1.3911) acc 53.1250 (60.2500) lr 1.9995e-03 eta 0:15:26
epoch [4/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 0.8789 (1.0912) acc 71.8750 (66.8750) lr 1.9995e-03 eta 0:29:49
epoch [4/200] batch [10/50] time 0.083 (0.133) data 0.000 (0.049) loss 1.5156 (1.2008) acc 56.2500 (65.9375) lr 1.9995e-03 eta 0:21:45
epoch [4/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.033) loss 1.1289 (1.2593) acc 65.6250 (64.7917) lr 1.9995e-03 eta 0:19:04
epoch [4/200] batch [20/50] time 0.083 (0.108) data 0.000 (0.025) loss 1.2373 (1.2280) acc 65.6250 (66.0938) lr 1.9995e-03 eta 0:17:42
epoch [4/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.020) loss 1.1045 (1.2384) acc 68.7500 (65.2500) lr 1.9995e-03 eta 0:16:53
epoch [4/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 1.2559 (1.2474) acc 59.3750 (64.6875) lr 1.9995e-03 eta 0:16:21
epoch [4/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.2354 (1.2515) acc 68.7500 (64.6429) lr 1.9995e-03 eta 0:15:57
epoch [4/200] batch [40/50] time 0.082 (0.096) data 0.000 (0.012) loss 1.2061 (1.2786) acc 71.8750 (63.8281) lr 1.9995e-03 eta 0:15:38
epoch [4/200] batch [45/50] time 0.082 (0.094) data 0.000 (0.011) loss 1.6826 (1.2962) acc 59.3750 (63.7500) lr 1.9995e-03 eta 0:15:23
epoch [4/200] batch [50/50] time 0.082 (0.093) data 0.000 (0.010) loss 1.9639 (1.3178) acc 46.8750 (63.5625) lr 1.9989e-03 eta 0:15:10
epoch [5/200] batch [5/50] time 0.083 (0.184) data 0.000 (0.100) loss 1.3213 (1.3678) acc 68.7500 (62.5000) lr 1.9989e-03 eta 0:30:05
epoch [5/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 1.0781 (1.2740) acc 65.6250 (65.0000) lr 1.9989e-03 eta 0:21:48
epoch [5/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.034) loss 1.5967 (1.2241) acc 56.2500 (67.7083) lr 1.9989e-03 eta 0:19:04
epoch [5/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 1.4453 (1.1888) acc 65.6250 (67.1875) lr 1.9989e-03 eta 0:17:41
epoch [5/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.020) loss 1.8291 (1.1937) acc 53.1250 (66.7500) lr 1.9989e-03 eta 0:16:51
epoch [5/200] batch [30/50] time 0.082 (0.100) data 0.000 (0.017) loss 1.9531 (1.2669) acc 46.8750 (64.4792) lr 1.9989e-03 eta 0:16:17
epoch [5/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.015) loss 1.3516 (1.2582) acc 65.6250 (64.4643) lr 1.9989e-03 eta 0:15:53
epoch [5/200] batch [40/50] time 0.082 (0.096) data 0.000 (0.013) loss 1.5957 (1.2622) acc 53.1250 (64.4531) lr 1.9989e-03 eta 0:15:33
epoch [5/200] batch [45/50] time 0.082 (0.094) data 0.000 (0.011) loss 1.3984 (1.2461) acc 65.6250 (65.0000) lr 1.9989e-03 eta 0:15:18
epoch [5/200] batch [50/50] time 0.082 (0.093) data 0.000 (0.010) loss 1.0176 (1.2620) acc 56.2500 (64.1875) lr 1.9980e-03 eta 0:15:06
epoch [6/200] batch [5/50] time 0.083 (0.187) data 0.000 (0.104) loss 1.2812 (1.1295) acc 53.1250 (66.8750) lr 1.9980e-03 eta 0:30:24
epoch [6/200] batch [10/50] time 0.082 (0.135) data 0.000 (0.052) loss 1.2031 (1.2320) acc 62.5000 (65.3125) lr 1.9980e-03 eta 0:21:56
epoch [6/200] batch [15/50] time 0.082 (0.118) data 0.000 (0.035) loss 1.0947 (1.2070) acc 78.1250 (66.2500) lr 1.9980e-03 eta 0:19:06
epoch [6/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.026) loss 0.8901 (1.1717) acc 78.1250 (67.3438) lr 1.9980e-03 eta 0:17:40
epoch [6/200] batch [25/50] time 0.083 (0.104) data 0.000 (0.021) loss 1.1240 (1.1684) acc 68.7500 (67.7500) lr 1.9980e-03 eta 0:16:50
epoch [6/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.017) loss 1.2383 (1.1495) acc 59.3750 (68.0208) lr 1.9980e-03 eta 0:16:15
epoch [6/200] batch [35/50] time 0.082 (0.098) data 0.000 (0.015) loss 0.9658 (1.1303) acc 68.7500 (68.5714) lr 1.9980e-03 eta 0:15:51
epoch [6/200] batch [40/50] time 0.082 (0.096) data 0.000 (0.013) loss 0.9463 (1.1329) acc 75.0000 (68.5938) lr 1.9980e-03 eta 0:15:31
epoch [6/200] batch [45/50] time 0.082 (0.094) data 0.000 (0.012) loss 1.1758 (1.1434) acc 62.5000 (68.1944) lr 1.9980e-03 eta 0:15:16
epoch [6/200] batch [50/50] time 0.082 (0.093) data 0.000 (0.011) loss 1.0068 (1.1541) acc 75.0000 (68.4375) lr 1.9969e-03 eta 0:15:04
epoch [7/200] batch [5/50] time 0.084 (0.197) data 0.000 (0.113) loss 1.3848 (1.2406) acc 62.5000 (68.1250) lr 1.9969e-03 eta 0:31:51
epoch [7/200] batch [10/50] time 0.083 (0.140) data 0.000 (0.057) loss 1.2676 (1.1282) acc 62.5000 (68.1250) lr 1.9969e-03 eta 0:22:39
epoch [7/200] batch [15/50] time 0.083 (0.121) data 0.000 (0.038) loss 0.8516 (1.1545) acc 71.8750 (66.8750) lr 1.9969e-03 eta 0:19:35
epoch [7/200] batch [20/50] time 0.083 (0.112) data 0.000 (0.028) loss 0.7568 (1.1808) acc 81.2500 (67.0312) lr 1.9969e-03 eta 0:18:02
epoch [7/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.023) loss 0.8633 (1.1808) acc 71.8750 (66.5000) lr 1.9969e-03 eta 0:17:07
epoch [7/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.019) loss 1.1465 (1.1893) acc 71.8750 (66.1458) lr 1.9969e-03 eta 0:16:30
epoch [7/200] batch [35/50] time 0.083 (0.100) data 0.000 (0.016) loss 1.1680 (1.2039) acc 68.7500 (65.8929) lr 1.9969e-03 eta 0:16:03
epoch [7/200] batch [40/50] time 0.082 (0.098) data 0.000 (0.014) loss 1.4307 (1.2191) acc 59.3750 (65.6250) lr 1.9969e-03 eta 0:15:42
epoch [7/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.013) loss 1.1846 (1.2255) acc 68.7500 (65.3472) lr 1.9969e-03 eta 0:15:25
epoch [7/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.012) loss 1.3398 (1.2374) acc 62.5000 (65.5000) lr 1.9956e-03 eta 0:15:12
epoch [8/200] batch [5/50] time 0.083 (0.187) data 0.000 (0.103) loss 0.9297 (1.0220) acc 71.8750 (71.8750) lr 1.9956e-03 eta 0:29:59
epoch [8/200] batch [10/50] time 0.083 (0.135) data 0.000 (0.051) loss 1.6162 (1.1496) acc 50.0000 (69.6875) lr 1.9956e-03 eta 0:21:41
epoch [8/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.2080 (1.1374) acc 62.5000 (68.3333) lr 1.9956e-03 eta 0:18:54
epoch [8/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.026) loss 0.9487 (1.1220) acc 78.1250 (68.7500) lr 1.9956e-03 eta 0:17:30
epoch [8/200] batch [25/50] time 0.083 (0.104) data 0.000 (0.021) loss 0.7349 (1.1114) acc 78.1250 (69.1250) lr 1.9956e-03 eta 0:16:40
epoch [8/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.017) loss 1.2881 (1.1291) acc 75.0000 (68.4375) lr 1.9956e-03 eta 0:16:07
epoch [8/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.015) loss 0.9697 (1.1198) acc 75.0000 (68.9286) lr 1.9956e-03 eta 0:15:42
epoch [8/200] batch [40/50] time 0.082 (0.096) data 0.000 (0.013) loss 0.9609 (1.1082) acc 65.6250 (68.9062) lr 1.9956e-03 eta 0:15:23
epoch [8/200] batch [45/50] time 0.082 (0.095) data 0.000 (0.012) loss 0.9463 (1.1200) acc 78.1250 (68.7500) lr 1.9956e-03 eta 0:15:08
epoch [8/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.011) loss 0.9648 (1.1130) acc 68.7500 (69.4375) lr 1.9940e-03 eta 0:14:56
epoch [9/200] batch [5/50] time 0.084 (0.197) data 0.000 (0.113) loss 0.8481 (1.0970) acc 71.8750 (71.2500) lr 1.9940e-03 eta 0:31:29
epoch [9/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.057) loss 1.1699 (1.0384) acc 59.3750 (70.3125) lr 1.9940e-03 eta 0:22:26
epoch [9/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.038) loss 0.8618 (1.0124) acc 78.1250 (72.0833) lr 1.9940e-03 eta 0:19:25
epoch [9/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.9312 (1.0142) acc 71.8750 (71.8750) lr 1.9940e-03 eta 0:17:54
epoch [9/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.023) loss 1.0898 (1.0424) acc 68.7500 (71.1250) lr 1.9940e-03 eta 0:16:59
epoch [9/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 1.4004 (1.0430) acc 59.3750 (71.1458) lr 1.9940e-03 eta 0:16:23
epoch [9/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.1260 (1.0260) acc 68.7500 (71.3393) lr 1.9940e-03 eta 0:15:56
epoch [9/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9312 (1.0360) acc 75.0000 (71.2500) lr 1.9940e-03 eta 0:15:35
epoch [9/200] batch [45/50] time 0.082 (0.096) data 0.000 (0.013) loss 0.9873 (1.0368) acc 75.0000 (71.1806) lr 1.9940e-03 eta 0:15:18
epoch [9/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.1953 (1.0515) acc 71.8750 (71.0000) lr 1.9921e-03 eta 0:15:05
epoch [10/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 1.3877 (1.1776) acc 62.5000 (66.2500) lr 1.9921e-03 eta 0:29:42
epoch [10/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.9541 (1.1157) acc 68.7500 (68.7500) lr 1.9921e-03 eta 0:21:33
epoch [10/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.8774 (1.0644) acc 68.7500 (70.4167) lr 1.9921e-03 eta 0:18:50
epoch [10/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.9521 (1.0710) acc 65.6250 (69.8438) lr 1.9921e-03 eta 0:17:29
epoch [10/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8887 (1.0608) acc 78.1250 (69.8750) lr 1.9921e-03 eta 0:16:39
epoch [10/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 1.2793 (1.0812) acc 59.3750 (69.1667) lr 1.9921e-03 eta 0:16:06
epoch [10/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.015) loss 1.4355 (1.0973) acc 56.2500 (68.8393) lr 1.9921e-03 eta 0:15:42
epoch [10/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.3037 (1.0898) acc 59.3750 (69.1406) lr 1.9921e-03 eta 0:15:22
epoch [10/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.6787 (1.0592) acc 71.8750 (70.2083) lr 1.9921e-03 eta 0:15:07
epoch [10/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.1113 (1.0690) acc 65.6250 (70.0000) lr 1.9900e-03 eta 0:14:54
epoch [11/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 1.5029 (1.0573) acc 62.5000 (71.2500) lr 1.9900e-03 eta 0:29:33
epoch [11/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.051) loss 1.1660 (0.9935) acc 68.7500 (72.5000) lr 1.9900e-03 eta 0:21:24
epoch [11/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.1123 (1.0331) acc 71.8750 (72.0833) lr 1.9900e-03 eta 0:18:42
epoch [11/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 1.1719 (1.0530) acc 71.8750 (71.5625) lr 1.9900e-03 eta 0:17:21
epoch [11/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 1.0537 (1.0774) acc 71.8750 (70.8750) lr 1.9900e-03 eta 0:16:32
epoch [11/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.1846 (1.0809) acc 65.6250 (70.4167) lr 1.9900e-03 eta 0:16:00
epoch [11/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.3359 (1.1011) acc 68.7500 (70.3571) lr 1.9900e-03 eta 0:15:36
epoch [11/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.3789 (1.1216) acc 65.6250 (69.6875) lr 1.9900e-03 eta 0:15:17
epoch [11/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.9990 (1.0945) acc 71.8750 (70.2083) lr 1.9900e-03 eta 0:15:02
epoch [11/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0801 (1.1009) acc 68.7500 (69.7500) lr 1.9877e-03 eta 0:14:50
epoch [12/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.105) loss 0.9644 (0.9624) acc 78.1250 (73.1250) lr 1.9877e-03 eta 0:30:05
epoch [12/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.6846 (0.9436) acc 87.5000 (73.4375) lr 1.9877e-03 eta 0:21:37
epoch [12/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.9521 (1.0321) acc 71.8750 (71.8750) lr 1.9877e-03 eta 0:18:48
epoch [12/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.8857 (1.0449) acc 75.0000 (71.5625) lr 1.9877e-03 eta 0:17:24
epoch [12/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8047 (1.0418) acc 71.8750 (71.3750) lr 1.9877e-03 eta 0:16:33
epoch [12/200] batch [30/50] time 0.083 (0.102) data 0.000 (0.018) loss 1.1348 (1.0149) acc 68.7500 (72.5000) lr 1.9877e-03 eta 0:15:59
epoch [12/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.015) loss 0.6030 (1.0139) acc 84.3750 (71.7857) lr 1.9877e-03 eta 0:15:34
epoch [12/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.1719 (1.0125) acc 75.0000 (71.8750) lr 1.9877e-03 eta 0:15:14
epoch [12/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1553 (1.0007) acc 59.3750 (71.3889) lr 1.9877e-03 eta 0:14:58
epoch [12/200] batch [50/50] time 0.082 (0.094) data 0.000 (0.011) loss 0.7744 (1.0006) acc 65.6250 (70.9375) lr 1.9851e-03 eta 0:14:46
epoch [13/200] batch [5/50] time 0.085 (0.197) data 0.000 (0.112) loss 1.2148 (1.1714) acc 78.1250 (71.8750) lr 1.9851e-03 eta 0:30:47
epoch [13/200] batch [10/50] time 0.084 (0.141) data 0.000 (0.056) loss 0.9668 (1.1288) acc 62.5000 (67.8125) lr 1.9851e-03 eta 0:21:59
epoch [13/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 1.3984 (1.1511) acc 62.5000 (66.4583) lr 1.9851e-03 eta 0:19:02
epoch [13/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.9399 (1.0959) acc 71.8750 (67.9688) lr 1.9851e-03 eta 0:17:34
epoch [13/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.023) loss 0.9907 (1.0728) acc 75.0000 (68.1250) lr 1.9851e-03 eta 0:16:40
epoch [13/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.8306 (1.0930) acc 81.2500 (68.5417) lr 1.9851e-03 eta 0:16:04
epoch [13/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.0859 (1.0954) acc 68.7500 (68.8393) lr 1.9851e-03 eta 0:15:39
epoch [13/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9854 (1.0769) acc 68.7500 (69.6875) lr 1.9851e-03 eta 0:15:18
epoch [13/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.013) loss 1.4277 (1.0948) acc 62.5000 (69.5139) lr 1.9851e-03 eta 0:15:02
epoch [13/200] batch [50/50] time 0.086 (0.095) data 0.000 (0.011) loss 0.9678 (1.0846) acc 75.0000 (69.6875) lr 1.9823e-03 eta 0:14:50
epoch [14/200] batch [5/50] time 0.085 (0.196) data 0.000 (0.112) loss 0.8882 (1.0634) acc 75.0000 (75.0000) lr 1.9823e-03 eta 0:30:31
epoch [14/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.056) loss 1.2617 (1.0991) acc 65.6250 (69.6875) lr 1.9823e-03 eta 0:21:47
epoch [14/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.038) loss 1.0674 (1.0619) acc 75.0000 (70.4167) lr 1.9823e-03 eta 0:18:52
epoch [14/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.7847 (1.0395) acc 78.1250 (70.7812) lr 1.9823e-03 eta 0:17:25
epoch [14/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.023) loss 0.9165 (1.0734) acc 68.7500 (70.1250) lr 1.9823e-03 eta 0:16:32
epoch [14/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 1.5713 (1.0776) acc 68.7500 (70.5208) lr 1.9823e-03 eta 0:15:57
epoch [14/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.3203 (1.0739) acc 59.3750 (70.1786) lr 1.9823e-03 eta 0:15:32
epoch [14/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.5830 (1.0981) acc 59.3750 (69.0625) lr 1.9823e-03 eta 0:15:11
epoch [14/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.013) loss 1.0049 (1.0647) acc 75.0000 (70.2083) lr 1.9823e-03 eta 0:14:55
epoch [14/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0771 (1.0570) acc 78.1250 (70.7500) lr 1.9792e-03 eta 0:14:42
epoch [15/200] batch [5/50] time 0.086 (0.184) data 0.000 (0.098) loss 0.8027 (0.8932) acc 75.0000 (72.5000) lr 1.9792e-03 eta 0:28:28
epoch [15/200] batch [10/50] time 0.083 (0.134) data 0.000 (0.049) loss 1.1426 (0.9435) acc 71.8750 (73.1250) lr 1.9792e-03 eta 0:20:44
epoch [15/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.9717 (0.9700) acc 75.0000 (72.7083) lr 1.9792e-03 eta 0:18:09
epoch [15/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.5059 (1.0057) acc 62.5000 (71.7188) lr 1.9792e-03 eta 0:16:51
epoch [15/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 1.1680 (1.0358) acc 68.7500 (70.5000) lr 1.9792e-03 eta 0:16:06
epoch [15/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9546 (1.0576) acc 65.6250 (69.7917) lr 1.9792e-03 eta 0:15:35
epoch [15/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.7539 (1.0579) acc 78.1250 (69.8214) lr 1.9792e-03 eta 0:15:12
epoch [15/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9399 (1.0686) acc 71.8750 (69.6094) lr 1.9792e-03 eta 0:14:54
epoch [15/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7344 (1.0575) acc 75.0000 (69.9306) lr 1.9792e-03 eta 0:14:39
epoch [15/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7944 (1.0515) acc 78.1250 (70.3125) lr 1.9759e-03 eta 0:14:28
epoch [16/200] batch [5/50] time 0.083 (0.195) data 0.000 (0.110) loss 0.9355 (1.0151) acc 68.7500 (71.8750) lr 1.9759e-03 eta 0:30:00
epoch [16/200] batch [10/50] time 0.083 (0.139) data 0.000 (0.055) loss 1.0146 (0.9638) acc 62.5000 (73.1250) lr 1.9759e-03 eta 0:21:25
epoch [16/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 1.0234 (0.9360) acc 68.7500 (74.5833) lr 1.9759e-03 eta 0:18:34
epoch [16/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.028) loss 0.9224 (0.9975) acc 75.0000 (73.1250) lr 1.9759e-03 eta 0:17:07
epoch [16/200] batch [25/50] time 0.082 (0.106) data 0.000 (0.022) loss 1.4990 (1.0336) acc 56.2500 (70.6250) lr 1.9759e-03 eta 0:16:14
epoch [16/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.019) loss 1.1377 (1.0311) acc 71.8750 (70.3125) lr 1.9759e-03 eta 0:15:40
epoch [16/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.016) loss 1.0713 (1.0209) acc 75.0000 (70.8036) lr 1.9759e-03 eta 0:15:15
epoch [16/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.6177 (1.0136) acc 87.5000 (71.4844) lr 1.9759e-03 eta 0:14:56
epoch [16/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0820 (1.0091) acc 65.6250 (71.4583) lr 1.9759e-03 eta 0:14:41
epoch [16/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.2070 (1.0204) acc 62.5000 (71.3750) lr 1.9724e-03 eta 0:14:28
epoch [17/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.100) loss 1.3369 (1.1127) acc 59.3750 (66.2500) lr 1.9724e-03 eta 0:28:22
epoch [17/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.050) loss 1.1318 (1.0833) acc 68.7500 (69.6875) lr 1.9724e-03 eta 0:20:35
epoch [17/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.3193 (1.0937) acc 71.8750 (69.7917) lr 1.9724e-03 eta 0:18:00
epoch [17/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 1.0479 (1.1080) acc 62.5000 (68.7500) lr 1.9724e-03 eta 0:16:43
epoch [17/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.7622 (1.1261) acc 81.2500 (68.1250) lr 1.9724e-03 eta 0:15:57
epoch [17/200] batch [30/50] time 0.085 (0.101) data 0.001 (0.017) loss 1.0332 (1.0948) acc 71.8750 (69.2708) lr 1.9724e-03 eta 0:15:26
epoch [17/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.9253 (1.1147) acc 75.0000 (69.1964) lr 1.9724e-03 eta 0:15:04
epoch [17/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9492 (1.0992) acc 78.1250 (69.6875) lr 1.9724e-03 eta 0:14:45
epoch [17/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2988 (1.0692) acc 59.3750 (70.3472) lr 1.9724e-03 eta 0:14:31
epoch [17/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.5869 (1.0421) acc 87.5000 (71.5625) lr 1.9686e-03 eta 0:14:20
epoch [18/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.108) loss 1.4619 (1.2175) acc 65.6250 (68.7500) lr 1.9686e-03 eta 0:29:26
epoch [18/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.9248 (1.1885) acc 75.0000 (70.6250) lr 1.9686e-03 eta 0:21:05
epoch [18/200] batch [15/50] time 0.083 (0.120) data 0.000 (0.036) loss 1.0098 (1.0819) acc 71.8750 (72.5000) lr 1.9686e-03 eta 0:18:17
epoch [18/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.027) loss 1.2842 (1.0686) acc 65.6250 (72.1875) lr 1.9686e-03 eta 0:16:53
epoch [18/200] batch [25/50] time 0.083 (0.106) data 0.000 (0.022) loss 0.7168 (1.0620) acc 71.8750 (72.1250) lr 1.9686e-03 eta 0:16:02
epoch [18/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.9072 (1.0763) acc 81.2500 (71.4583) lr 1.9686e-03 eta 0:15:29
epoch [18/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.016) loss 0.9487 (1.0747) acc 75.0000 (71.3393) lr 1.9686e-03 eta 0:15:04
epoch [18/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.6650 (1.0596) acc 81.2500 (71.5625) lr 1.9686e-03 eta 0:14:45
epoch [18/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.2842 (1.0593) acc 59.3750 (71.3194) lr 1.9686e-03 eta 0:14:30
epoch [18/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.9292 (1.0420) acc 75.0000 (71.6250) lr 1.9646e-03 eta 0:14:18
epoch [19/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.108) loss 0.8447 (1.0517) acc 71.8750 (71.2500) lr 1.9646e-03 eta 0:29:18
epoch [19/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 1.0166 (0.9503) acc 65.6250 (73.7500) lr 1.9646e-03 eta 0:21:01
epoch [19/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.9980 (0.9920) acc 75.0000 (71.8750) lr 1.9646e-03 eta 0:18:16
epoch [19/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 1.0488 (0.9628) acc 75.0000 (72.8125) lr 1.9646e-03 eta 0:16:53
epoch [19/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 1.2676 (0.9932) acc 59.3750 (71.8750) lr 1.9646e-03 eta 0:16:03
epoch [19/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 1.0693 (0.9751) acc 68.7500 (72.5000) lr 1.9646e-03 eta 0:15:29
epoch [19/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.7397 (0.9686) acc 71.8750 (72.4107) lr 1.9646e-03 eta 0:15:06
epoch [19/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9121 (0.9789) acc 75.0000 (72.4219) lr 1.9646e-03 eta 0:14:46
epoch [19/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9336 (0.9800) acc 75.0000 (72.5000) lr 1.9646e-03 eta 0:14:32
epoch [19/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7412 (0.9631) acc 84.3750 (72.9375) lr 1.9603e-03 eta 0:14:19
epoch [20/200] batch [5/50] time 0.083 (0.191) data 0.000 (0.107) loss 0.6675 (0.7810) acc 81.2500 (76.8750) lr 1.9603e-03 eta 0:28:50
epoch [20/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.9746 (0.9245) acc 71.8750 (71.8750) lr 1.9603e-03 eta 0:20:45
epoch [20/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.4004 (0.9161) acc 59.3750 (73.9583) lr 1.9603e-03 eta 0:18:01
epoch [20/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.9414 (0.9236) acc 71.8750 (73.1250) lr 1.9603e-03 eta 0:16:40
epoch [20/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 1.1523 (0.8956) acc 68.7500 (73.8750) lr 1.9603e-03 eta 0:15:52
epoch [20/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.2354 (0.9279) acc 62.5000 (73.3333) lr 1.9603e-03 eta 0:15:19
epoch [20/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.016) loss 0.8232 (0.9278) acc 71.8750 (73.1250) lr 1.9603e-03 eta 0:14:55
epoch [20/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.5352 (0.9125) acc 87.5000 (73.5156) lr 1.9603e-03 eta 0:14:36
epoch [20/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0146 (0.9511) acc 68.7500 (72.3611) lr 1.9603e-03 eta 0:14:22
epoch [20/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.1338 (0.9789) acc 75.0000 (71.8750) lr 1.9558e-03 eta 0:14:10
epoch [21/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.106) loss 1.3311 (1.1762) acc 65.6250 (66.2500) lr 1.9558e-03 eta 0:28:48
epoch [21/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.8989 (1.0508) acc 75.0000 (67.5000) lr 1.9558e-03 eta 0:20:42
epoch [21/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.0205 (1.0597) acc 78.1250 (70.0000) lr 1.9558e-03 eta 0:18:01
epoch [21/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.4792 (1.0216) acc 81.2500 (70.3125) lr 1.9558e-03 eta 0:16:40
epoch [21/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 1.2500 (1.0077) acc 59.3750 (70.5000) lr 1.9558e-03 eta 0:15:51
epoch [21/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.4688 (0.9778) acc 62.5000 (71.4583) lr 1.9558e-03 eta 0:15:18
epoch [21/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 1.5811 (0.9896) acc 53.1250 (71.1607) lr 1.9558e-03 eta 0:14:54
epoch [21/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.4775 (0.9886) acc 68.7500 (71.7188) lr 1.9558e-03 eta 0:14:35
epoch [21/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0625 (1.0157) acc 62.5000 (71.1806) lr 1.9558e-03 eta 0:14:20
epoch [21/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8936 (1.0133) acc 68.7500 (71.2500) lr 1.9511e-03 eta 0:14:08
epoch [22/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 0.7515 (0.8409) acc 84.3750 (76.2500) lr 1.9511e-03 eta 0:28:45
epoch [22/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.4866 (0.8818) acc 90.6250 (76.2500) lr 1.9511e-03 eta 0:20:37
epoch [22/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.2031 (0.9258) acc 71.8750 (75.2083) lr 1.9511e-03 eta 0:17:55
epoch [22/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 1.3457 (0.9354) acc 62.5000 (74.3750) lr 1.9511e-03 eta 0:16:33
epoch [22/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 1.0820 (0.9359) acc 75.0000 (74.3750) lr 1.9511e-03 eta 0:15:45
epoch [22/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.7520 (0.9236) acc 75.0000 (74.7917) lr 1.9511e-03 eta 0:15:13
epoch [22/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.016) loss 1.0186 (0.9224) acc 71.8750 (75.0000) lr 1.9511e-03 eta 0:14:49
epoch [22/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9653 (0.9373) acc 71.8750 (74.8438) lr 1.9511e-03 eta 0:14:30
epoch [22/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9414 (0.9359) acc 68.7500 (74.7222) lr 1.9511e-03 eta 0:14:15
epoch [22/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8672 (0.9330) acc 78.1250 (75.1250) lr 1.9461e-03 eta 0:14:04
epoch [23/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 0.7725 (0.8652) acc 68.7500 (73.1250) lr 1.9461e-03 eta 0:27:58
epoch [23/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.052) loss 0.6450 (0.9723) acc 78.1250 (70.6250) lr 1.9461e-03 eta 0:20:12
epoch [23/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.5977 (0.9782) acc 90.6250 (72.0833) lr 1.9461e-03 eta 0:17:37
epoch [23/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.0146 (0.9850) acc 75.0000 (72.0312) lr 1.9461e-03 eta 0:16:19
epoch [23/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8740 (0.9802) acc 75.0000 (72.5000) lr 1.9461e-03 eta 0:15:32
epoch [23/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 1.1494 (0.9821) acc 71.8750 (72.8125) lr 1.9461e-03 eta 0:15:01
epoch [23/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.3545 (0.9690) acc 93.7500 (72.9464) lr 1.9461e-03 eta 0:14:38
epoch [23/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.9492 (1.0005) acc 56.2500 (72.7344) lr 1.9461e-03 eta 0:14:20
epoch [23/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8687 (0.9887) acc 78.1250 (73.1250) lr 1.9461e-03 eta 0:14:06
epoch [23/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.8379 (0.9870) acc 71.8750 (73.0625) lr 1.9409e-03 eta 0:13:54
epoch [24/200] batch [5/50] time 0.083 (0.184) data 0.000 (0.099) loss 0.7065 (0.8418) acc 71.8750 (75.6250) lr 1.9409e-03 eta 0:27:11
epoch [24/200] batch [10/50] time 0.085 (0.134) data 0.001 (0.050) loss 0.7881 (0.8337) acc 75.0000 (76.5625) lr 1.9409e-03 eta 0:19:48
epoch [24/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 1.1279 (0.8582) acc 68.7500 (76.2500) lr 1.9409e-03 eta 0:17:18
epoch [24/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.8911 (0.9187) acc 75.0000 (74.3750) lr 1.9409e-03 eta 0:16:03
epoch [24/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.0361 (0.9192) acc 81.2500 (74.8750) lr 1.9409e-03 eta 0:15:18
epoch [24/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.017) loss 0.8145 (0.9406) acc 81.2500 (74.7917) lr 1.9409e-03 eta 0:14:48
epoch [24/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9067 (0.9363) acc 78.1250 (74.5536) lr 1.9409e-03 eta 0:14:27
epoch [24/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9727 (0.9435) acc 71.8750 (74.0625) lr 1.9409e-03 eta 0:14:10
epoch [24/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9717 (0.9440) acc 78.1250 (73.9583) lr 1.9409e-03 eta 0:13:57
epoch [24/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9805 (0.9411) acc 75.0000 (74.1875) lr 1.9354e-03 eta 0:13:46
epoch [25/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.108) loss 0.9585 (0.9200) acc 81.2500 (78.7500) lr 1.9354e-03 eta 0:28:12
epoch [25/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 1.2568 (0.9413) acc 65.6250 (75.6250) lr 1.9354e-03 eta 0:20:16
epoch [25/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 1.2256 (0.9526) acc 75.0000 (75.0000) lr 1.9354e-03 eta 0:17:38
epoch [25/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 1.3096 (0.9510) acc 62.5000 (74.0625) lr 1.9354e-03 eta 0:16:19
epoch [25/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.7549 (0.9293) acc 81.2500 (74.2500) lr 1.9354e-03 eta 0:15:31
epoch [25/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6479 (0.9036) acc 84.3750 (75.3125) lr 1.9354e-03 eta 0:14:59
epoch [25/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5020 (0.9143) acc 87.5000 (75.3571) lr 1.9354e-03 eta 0:14:36
epoch [25/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.3848 (0.9044) acc 65.6250 (75.6250) lr 1.9354e-03 eta 0:14:17
epoch [25/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9580 (0.9202) acc 81.2500 (75.1389) lr 1.9354e-03 eta 0:14:03
epoch [25/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9961 (0.9241) acc 71.8750 (75.0000) lr 1.9298e-03 eta 0:13:51
epoch [26/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.104) loss 0.5854 (0.8027) acc 93.7500 (80.0000) lr 1.9298e-03 eta 0:27:34
epoch [26/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 1.3594 (0.8741) acc 62.5000 (77.1875) lr 1.9298e-03 eta 0:19:56
epoch [26/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 1.1338 (0.8757) acc 81.2500 (77.7083) lr 1.9298e-03 eta 0:17:22
epoch [26/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 1.0625 (0.8720) acc 75.0000 (77.1875) lr 1.9298e-03 eta 0:16:06
epoch [26/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 1.5439 (0.9062) acc 62.5000 (76.1250) lr 1.9298e-03 eta 0:15:20
epoch [26/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 1.1074 (0.8727) acc 62.5000 (76.9792) lr 1.9298e-03 eta 0:14:49
epoch [26/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 1.0498 (0.8942) acc 62.5000 (75.9821) lr 1.9298e-03 eta 0:14:26
epoch [26/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.2812 (0.9045) acc 75.0000 (76.3281) lr 1.9298e-03 eta 0:14:08
epoch [26/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.2402 (0.9188) acc 68.7500 (76.0417) lr 1.9298e-03 eta 0:13:54
epoch [26/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7666 (0.9451) acc 81.2500 (75.5000) lr 1.9239e-03 eta 0:13:42
epoch [27/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.102) loss 0.6162 (0.8949) acc 84.3750 (76.2500) lr 1.9239e-03 eta 0:27:15
epoch [27/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.4041 (0.8201) acc 84.3750 (78.1250) lr 1.9239e-03 eta 0:19:41
epoch [27/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.9966 (0.9050) acc 75.0000 (76.4583) lr 1.9239e-03 eta 0:17:11
epoch [27/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.7300 (0.9013) acc 71.8750 (76.2500) lr 1.9239e-03 eta 0:15:55
epoch [27/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.9019 (0.8761) acc 75.0000 (76.7500) lr 1.9239e-03 eta 0:15:10
epoch [27/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.9399 (0.9062) acc 78.1250 (76.3542) lr 1.9239e-03 eta 0:14:40
epoch [27/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.0020 (0.9406) acc 71.8750 (75.2679) lr 1.9239e-03 eta 0:14:18
epoch [27/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.5381 (0.9478) acc 68.7500 (75.3906) lr 1.9239e-03 eta 0:14:00
epoch [27/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8682 (0.9484) acc 78.1250 (75.2778) lr 1.9239e-03 eta 0:13:46
epoch [27/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7183 (0.9651) acc 81.2500 (74.5000) lr 1.9178e-03 eta 0:13:35
epoch [28/200] batch [5/50] time 0.085 (0.182) data 0.000 (0.096) loss 0.5762 (0.7554) acc 81.2500 (76.8750) lr 1.9178e-03 eta 0:26:13
epoch [28/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 1.1748 (0.8509) acc 71.8750 (76.8750) lr 1.9178e-03 eta 0:19:11
epoch [28/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.6411 (0.8658) acc 75.0000 (76.4583) lr 1.9178e-03 eta 0:16:53
epoch [28/200] batch [20/50] time 0.085 (0.109) data 0.001 (0.024) loss 0.9521 (0.9100) acc 68.7500 (76.0938) lr 1.9178e-03 eta 0:15:43
epoch [28/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 1.1113 (0.9912) acc 68.7500 (74.1250) lr 1.9178e-03 eta 0:15:00
epoch [28/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.3008 (1.0010) acc 93.7500 (73.5417) lr 1.9178e-03 eta 0:14:31
epoch [28/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.6978 (1.0080) acc 78.1250 (73.2143) lr 1.9178e-03 eta 0:14:10
epoch [28/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 1.3135 (1.0049) acc 68.7500 (73.4375) lr 1.9178e-03 eta 0:13:53
epoch [28/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.2197 (1.0104) acc 75.0000 (73.5417) lr 1.9178e-03 eta 0:13:40
epoch [28/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.0576 (1.0162) acc 68.7500 (73.1875) lr 1.9114e-03 eta 0:13:29
epoch [29/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.100) loss 0.7095 (0.8428) acc 81.2500 (75.6250) lr 1.9114e-03 eta 0:26:34
epoch [29/200] batch [10/50] time 0.083 (0.135) data 0.000 (0.050) loss 1.1133 (0.9175) acc 68.7500 (75.0000) lr 1.9114e-03 eta 0:19:17
epoch [29/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.0234 (0.9107) acc 68.7500 (74.1667) lr 1.9114e-03 eta 0:16:53
epoch [29/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 1.1963 (0.9102) acc 59.3750 (73.7500) lr 1.9114e-03 eta 0:15:39
epoch [29/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.9902 (0.9330) acc 68.7500 (73.0000) lr 1.9114e-03 eta 0:14:55
epoch [29/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 1.2617 (0.9541) acc 65.6250 (72.5000) lr 1.9114e-03 eta 0:14:26
epoch [29/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.7261 (0.9359) acc 81.2500 (73.0357) lr 1.9114e-03 eta 0:14:05
epoch [29/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7881 (0.9247) acc 71.8750 (72.9688) lr 1.9114e-03 eta 0:13:48
epoch [29/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9731 (0.9281) acc 68.7500 (72.8472) lr 1.9114e-03 eta 0:13:35
epoch [29/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9893 (0.9285) acc 68.7500 (73.0000) lr 1.9048e-03 eta 0:13:24
epoch [30/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.101) loss 0.4326 (0.7785) acc 84.3750 (81.2500) lr 1.9048e-03 eta 0:26:31
epoch [30/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.051) loss 1.3701 (0.9747) acc 62.5000 (74.6875) lr 1.9048e-03 eta 0:19:16
epoch [30/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.1641 (1.0086) acc 68.7500 (72.9167) lr 1.9048e-03 eta 0:16:49
epoch [30/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.7598 (0.9562) acc 84.3750 (74.2188) lr 1.9048e-03 eta 0:15:36
epoch [30/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.7593 (0.9135) acc 75.0000 (75.1250) lr 1.9048e-03 eta 0:14:53
epoch [30/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.8594 (0.9177) acc 78.1250 (75.1042) lr 1.9048e-03 eta 0:14:24
epoch [30/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 1.2451 (0.9113) acc 68.7500 (75.7143) lr 1.9048e-03 eta 0:14:03
epoch [30/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.2412 (0.9434) acc 68.7500 (74.9219) lr 1.9048e-03 eta 0:13:46
epoch [30/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.6431 (0.9410) acc 84.3750 (74.7222) lr 1.9048e-03 eta 0:13:33
epoch [30/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.2998 (0.9410) acc 65.6250 (74.8750) lr 1.8980e-03 eta 0:13:22
epoch [31/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.104) loss 1.1328 (0.9420) acc 68.7500 (72.5000) lr 1.8980e-03 eta 0:26:49
epoch [31/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 1.1289 (0.9858) acc 71.8750 (73.7500) lr 1.8980e-03 eta 0:19:25
epoch [31/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 1.4346 (1.0038) acc 65.6250 (74.7917) lr 1.8980e-03 eta 0:16:57
epoch [31/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.6235 (0.9544) acc 84.3750 (74.8438) lr 1.8980e-03 eta 0:15:43
epoch [31/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 1.2490 (1.0031) acc 65.6250 (73.0000) lr 1.8980e-03 eta 0:14:58
epoch [31/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 1.1689 (1.0132) acc 68.7500 (72.6042) lr 1.8980e-03 eta 0:14:28
epoch [31/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.9229 (1.0043) acc 71.8750 (72.6786) lr 1.8980e-03 eta 0:14:06
epoch [31/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.8042 (0.9893) acc 81.2500 (73.0469) lr 1.8980e-03 eta 0:13:48
epoch [31/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.6523 (0.9946) acc 56.2500 (72.9861) lr 1.8980e-03 eta 0:13:34
epoch [31/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1182 (0.9898) acc 71.8750 (73.0625) lr 1.8910e-03 eta 0:13:23
epoch [32/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 1.1211 (0.7850) acc 59.3750 (77.5000) lr 1.8910e-03 eta 0:27:11
epoch [32/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 1.0068 (0.9024) acc 68.7500 (74.3750) lr 1.8910e-03 eta 0:19:30
epoch [32/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.6836 (0.8627) acc 78.1250 (75.6250) lr 1.8910e-03 eta 0:16:55
epoch [32/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.7246 (0.8708) acc 78.1250 (75.3125) lr 1.8910e-03 eta 0:15:38
epoch [32/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.8047 (0.8804) acc 75.0000 (75.1250) lr 1.8910e-03 eta 0:14:53
epoch [32/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.0449 (0.9119) acc 78.1250 (74.8958) lr 1.8910e-03 eta 0:14:22
epoch [32/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7495 (0.9267) acc 75.0000 (74.5536) lr 1.8910e-03 eta 0:14:00
epoch [32/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7417 (0.9046) acc 87.5000 (75.1562) lr 1.8910e-03 eta 0:13:42
epoch [32/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4482 (0.9007) acc 87.5000 (75.0694) lr 1.8910e-03 eta 0:13:28
epoch [32/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1514 (0.8988) acc 68.7500 (75.0625) lr 1.8838e-03 eta 0:13:17
epoch [33/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.108) loss 1.1377 (0.8362) acc 68.7500 (79.3750) lr 1.8838e-03 eta 0:27:09
epoch [33/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.7993 (0.8094) acc 71.8750 (77.5000) lr 1.8838e-03 eta 0:19:29
epoch [33/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 0.8296 (0.8027) acc 81.2500 (78.1250) lr 1.8838e-03 eta 0:16:55
epoch [33/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 1.1709 (0.7903) acc 65.6250 (78.2812) lr 1.8838e-03 eta 0:15:39
epoch [33/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.9419 (0.8153) acc 68.7500 (77.0000) lr 1.8838e-03 eta 0:14:53
epoch [33/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.9624 (0.8248) acc 68.7500 (76.7708) lr 1.8838e-03 eta 0:14:22
epoch [33/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.016) loss 0.5059 (0.8341) acc 81.2500 (76.2500) lr 1.8838e-03 eta 0:13:59
epoch [33/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6509 (0.8253) acc 78.1250 (76.3281) lr 1.8838e-03 eta 0:13:41
epoch [33/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.4678 (0.8304) acc 90.6250 (76.1806) lr 1.8838e-03 eta 0:13:27
epoch [33/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8555 (0.8514) acc 68.7500 (75.6250) lr 1.8763e-03 eta 0:13:15
epoch [34/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.102) loss 1.4824 (0.9978) acc 62.5000 (73.1250) lr 1.8763e-03 eta 0:25:56
epoch [34/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 1.4785 (0.9373) acc 62.5000 (75.3125) lr 1.8763e-03 eta 0:18:50
epoch [34/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.7549 (0.9108) acc 78.1250 (75.8333) lr 1.8763e-03 eta 0:16:27
epoch [34/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 1.2178 (0.9302) acc 65.6250 (75.1562) lr 1.8763e-03 eta 0:15:16
epoch [34/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.8091 (0.9416) acc 84.3750 (75.1250) lr 1.8763e-03 eta 0:14:32
epoch [34/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9678 (0.9307) acc 71.8750 (75.4167) lr 1.8763e-03 eta 0:14:03
epoch [34/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.1582 (0.9625) acc 65.6250 (74.3750) lr 1.8763e-03 eta 0:13:43
epoch [34/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9644 (0.9712) acc 78.1250 (74.3750) lr 1.8763e-03 eta 0:13:26
epoch [34/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7568 (0.9506) acc 71.8750 (74.5139) lr 1.8763e-03 eta 0:13:13
epoch [34/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.1758 (0.9651) acc 65.6250 (74.1250) lr 1.8686e-03 eta 0:13:02
epoch [35/200] batch [5/50] time 0.085 (0.198) data 0.000 (0.113) loss 0.5557 (0.8146) acc 78.1250 (73.1250) lr 1.8686e-03 eta 0:27:20
epoch [35/200] batch [10/50] time 0.084 (0.141) data 0.000 (0.056) loss 0.6602 (0.9233) acc 81.2500 (71.2500) lr 1.8686e-03 eta 0:19:30
epoch [35/200] batch [15/50] time 0.086 (0.123) data 0.000 (0.038) loss 0.4377 (0.8152) acc 84.3750 (74.7917) lr 1.8686e-03 eta 0:16:55
epoch [35/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.028) loss 0.6729 (0.8732) acc 81.2500 (74.2188) lr 1.8686e-03 eta 0:15:35
epoch [35/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.023) loss 0.8296 (0.8718) acc 71.8750 (74.7500) lr 1.8686e-03 eta 0:14:48
epoch [35/200] batch [30/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.7114 (0.8925) acc 90.6250 (74.6875) lr 1.8686e-03 eta 0:14:16
epoch [35/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.9971 (0.9138) acc 75.0000 (74.1964) lr 1.8686e-03 eta 0:13:53
epoch [35/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.5513 (0.9037) acc 84.3750 (74.1406) lr 1.8686e-03 eta 0:13:35
epoch [35/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.1475 (0.9114) acc 68.7500 (74.0972) lr 1.8686e-03 eta 0:13:20
epoch [35/200] batch [50/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.7656 (0.9096) acc 78.1250 (74.1250) lr 1.8607e-03 eta 0:13:08
epoch [36/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.105) loss 0.7598 (0.7407) acc 71.8750 (75.0000) lr 1.8607e-03 eta 0:26:10
epoch [36/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.6030 (0.7685) acc 87.5000 (77.8125) lr 1.8607e-03 eta 0:18:53
epoch [36/200] batch [15/50] time 0.086 (0.120) data 0.000 (0.035) loss 0.9370 (0.7890) acc 78.1250 (78.5417) lr 1.8607e-03 eta 0:16:28
epoch [36/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.7495 (0.8279) acc 81.2500 (77.3438) lr 1.8607e-03 eta 0:15:14
epoch [36/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.8350 (0.8422) acc 84.3750 (77.6250) lr 1.8607e-03 eta 0:14:30
epoch [36/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.2891 (0.8479) acc 71.8750 (77.5000) lr 1.8607e-03 eta 0:14:00
epoch [36/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.8350 (0.8381) acc 78.1250 (77.6786) lr 1.8607e-03 eta 0:13:39
epoch [36/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.8647 (0.8469) acc 68.7500 (76.9531) lr 1.8607e-03 eta 0:13:22
epoch [36/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7905 (0.8456) acc 71.8750 (76.5972) lr 1.8607e-03 eta 0:13:08
epoch [36/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6870 (0.8515) acc 84.3750 (76.3125) lr 1.8526e-03 eta 0:12:58
epoch [37/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 0.6206 (0.5936) acc 81.2500 (84.3750) lr 1.8526e-03 eta 0:25:06
epoch [37/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.050) loss 1.1875 (0.7383) acc 68.7500 (80.9375) lr 1.8526e-03 eta 0:18:18
epoch [37/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.5117 (0.7209) acc 81.2500 (80.4167) lr 1.8526e-03 eta 0:16:02
epoch [37/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.4751 (0.7302) acc 87.5000 (79.8438) lr 1.8526e-03 eta 0:14:53
epoch [37/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.8491 (0.7614) acc 75.0000 (78.7500) lr 1.8526e-03 eta 0:14:12
epoch [37/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.9019 (0.7800) acc 78.1250 (77.6042) lr 1.8526e-03 eta 0:13:44
epoch [37/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.5244 (0.7943) acc 84.3750 (77.3214) lr 1.8526e-03 eta 0:13:24
epoch [37/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9004 (0.8357) acc 75.0000 (76.0938) lr 1.8526e-03 eta 0:13:08
epoch [37/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9414 (0.8741) acc 71.8750 (75.5556) lr 1.8526e-03 eta 0:12:56
epoch [37/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8906 (0.8858) acc 68.7500 (74.6875) lr 1.8443e-03 eta 0:12:46
epoch [38/200] batch [5/50] time 0.084 (0.196) data 0.000 (0.111) loss 0.8076 (0.6863) acc 78.1250 (80.6250) lr 1.8443e-03 eta 0:26:33
epoch [38/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 1.0527 (0.8285) acc 68.7500 (77.1875) lr 1.8443e-03 eta 0:18:57
epoch [38/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 1.2422 (0.8465) acc 75.0000 (76.0417) lr 1.8443e-03 eta 0:16:25
epoch [38/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 1.4824 (0.9170) acc 62.5000 (74.6875) lr 1.8443e-03 eta 0:15:09
epoch [38/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.8877 (0.8839) acc 78.1250 (75.1250) lr 1.8443e-03 eta 0:14:23
epoch [38/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.6299 (0.9030) acc 78.1250 (75.0000) lr 1.8443e-03 eta 0:13:52
epoch [38/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.016) loss 0.8384 (0.9032) acc 81.2500 (74.6429) lr 1.8443e-03 eta 0:13:30
epoch [38/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.4670 (0.8959) acc 87.5000 (75.2344) lr 1.8443e-03 eta 0:13:12
epoch [38/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9346 (0.8890) acc 71.8750 (75.3472) lr 1.8443e-03 eta 0:12:59
epoch [38/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9092 (0.8921) acc 71.8750 (75.1875) lr 1.8358e-03 eta 0:12:48
epoch [39/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.105) loss 0.9678 (0.6483) acc 71.8750 (80.6250) lr 1.8358e-03 eta 0:25:42
epoch [39/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.9482 (0.7013) acc 75.0000 (81.2500) lr 1.8358e-03 eta 0:18:33
epoch [39/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 1.1768 (0.7826) acc 62.5000 (78.3333) lr 1.8358e-03 eta 0:16:10
epoch [39/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 1.0938 (0.8804) acc 71.8750 (76.7188) lr 1.8358e-03 eta 0:14:58
epoch [39/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 1.0732 (0.8890) acc 68.7500 (76.0000) lr 1.8358e-03 eta 0:14:15
epoch [39/200] batch [30/50] time 0.086 (0.102) data 0.000 (0.018) loss 0.7334 (0.9092) acc 71.8750 (75.1042) lr 1.8358e-03 eta 0:13:46
epoch [39/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.5474 (0.9039) acc 81.2500 (75.0893) lr 1.8358e-03 eta 0:13:27
epoch [39/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.4844 (0.8683) acc 84.3750 (75.7812) lr 1.8358e-03 eta 0:13:10
epoch [39/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7690 (0.8718) acc 75.0000 (75.3472) lr 1.8358e-03 eta 0:12:56
epoch [39/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9595 (0.8640) acc 75.0000 (75.5000) lr 1.8271e-03 eta 0:12:45
epoch [40/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 1.1445 (0.7961) acc 68.7500 (78.7500) lr 1.8271e-03 eta 0:25:04
epoch [40/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.3130 (0.7904) acc 90.6250 (77.8125) lr 1.8271e-03 eta 0:18:12
epoch [40/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 1.1016 (0.8064) acc 71.8750 (76.8750) lr 1.8271e-03 eta 0:15:55
epoch [40/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.5005 (0.8046) acc 81.2500 (77.3438) lr 1.8271e-03 eta 0:14:46
epoch [40/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.9438 (0.8413) acc 78.1250 (76.5000) lr 1.8271e-03 eta 0:14:04
epoch [40/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.6777 (0.8249) acc 84.3750 (77.1875) lr 1.8271e-03 eta 0:13:36
epoch [40/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.6401 (0.8481) acc 81.2500 (76.9643) lr 1.8271e-03 eta 0:13:16
epoch [40/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8198 (0.8574) acc 78.1250 (76.7188) lr 1.8271e-03 eta 0:13:00
epoch [40/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0967 (0.8862) acc 75.0000 (76.0417) lr 1.8271e-03 eta 0:12:47
epoch [40/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.6060 (0.8774) acc 84.3750 (76.1250) lr 1.8181e-03 eta 0:12:37
epoch [41/200] batch [5/50] time 0.084 (0.195) data 0.000 (0.110) loss 1.2461 (0.9443) acc 62.5000 (73.1250) lr 1.8181e-03 eta 0:25:57
epoch [41/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.055) loss 0.8989 (0.9881) acc 75.0000 (74.3750) lr 1.8181e-03 eta 0:18:33
epoch [41/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 1.2812 (0.9693) acc 71.8750 (75.2083) lr 1.8181e-03 eta 0:16:05
epoch [41/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.4219 (0.8926) acc 87.5000 (76.4062) lr 1.8181e-03 eta 0:14:51
epoch [41/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 1.2373 (0.8950) acc 75.0000 (76.1250) lr 1.8181e-03 eta 0:14:06
epoch [41/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.019) loss 1.1387 (0.9104) acc 68.7500 (75.4167) lr 1.8181e-03 eta 0:13:36
epoch [41/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.2266 (0.9251) acc 81.2500 (75.2679) lr 1.8181e-03 eta 0:13:15
epoch [41/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5952 (0.9137) acc 78.1250 (75.5469) lr 1.8181e-03 eta 0:12:58
epoch [41/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7998 (0.9243) acc 75.0000 (75.3472) lr 1.8181e-03 eta 0:12:45
epoch [41/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.2314 (0.9368) acc 71.8750 (75.0000) lr 1.8090e-03 eta 0:12:34
epoch [42/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.103) loss 1.0664 (0.9857) acc 68.7500 (74.3750) lr 1.8090e-03 eta 0:24:51
epoch [42/200] batch [10/50] time 0.083 (0.136) data 0.000 (0.052) loss 0.9053 (0.9961) acc 75.0000 (75.6250) lr 1.8090e-03 eta 0:17:59
epoch [42/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.6323 (0.8764) acc 84.3750 (78.3333) lr 1.8090e-03 eta 0:15:40
epoch [42/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.026) loss 0.8032 (0.8761) acc 75.0000 (77.6562) lr 1.8090e-03 eta 0:14:31
epoch [42/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8525 (0.8917) acc 71.8750 (76.6250) lr 1.8090e-03 eta 0:13:50
epoch [42/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.1240 (0.8698) acc 71.8750 (77.2917) lr 1.8090e-03 eta 0:13:21
epoch [42/200] batch [35/50] time 0.083 (0.099) data 0.001 (0.015) loss 0.8916 (0.8697) acc 71.8750 (76.7857) lr 1.8090e-03 eta 0:13:01
epoch [42/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8345 (0.8698) acc 75.0000 (76.5625) lr 1.8090e-03 eta 0:12:46
epoch [42/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 1.3213 (0.8934) acc 68.7500 (76.0417) lr 1.8090e-03 eta 0:12:33
epoch [42/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.7446 (0.9082) acc 75.0000 (75.3125) lr 1.7997e-03 eta 0:12:23
epoch [43/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.104) loss 0.9375 (0.8740) acc 71.8750 (75.6250) lr 1.7997e-03 eta 0:24:55
epoch [43/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.4795 (0.7943) acc 84.3750 (78.7500) lr 1.7997e-03 eta 0:18:00
epoch [43/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.6304 (0.8313) acc 84.3750 (76.6667) lr 1.7997e-03 eta 0:15:42
epoch [43/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.9399 (0.8623) acc 71.8750 (75.7812) lr 1.7997e-03 eta 0:14:32
epoch [43/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.4097 (0.8278) acc 87.5000 (76.7500) lr 1.7997e-03 eta 0:13:50
epoch [43/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 1.2031 (0.8544) acc 62.5000 (75.9375) lr 1.7997e-03 eta 0:13:23
epoch [43/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.015) loss 0.5117 (0.8432) acc 81.2500 (76.1607) lr 1.7997e-03 eta 0:13:02
epoch [43/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.5464 (0.8274) acc 75.0000 (76.2500) lr 1.7997e-03 eta 0:12:46
epoch [43/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0186 (0.8178) acc 81.2500 (76.8056) lr 1.7997e-03 eta 0:12:33
epoch [43/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6973 (0.8326) acc 78.1250 (76.6875) lr 1.7902e-03 eta 0:12:23
epoch [44/200] batch [5/50] time 0.084 (0.197) data 0.000 (0.113) loss 1.1162 (0.8477) acc 71.8750 (78.1250) lr 1.7902e-03 eta 0:25:46
epoch [44/200] batch [10/50] time 0.084 (0.141) data 0.000 (0.056) loss 0.9390 (0.8289) acc 81.2500 (79.3750) lr 1.7902e-03 eta 0:18:22
epoch [44/200] batch [15/50] time 0.083 (0.122) data 0.000 (0.038) loss 1.0801 (0.8927) acc 68.7500 (76.8750) lr 1.7902e-03 eta 0:15:53
epoch [44/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 1.0840 (0.9174) acc 78.1250 (75.7812) lr 1.7902e-03 eta 0:14:38
epoch [44/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.023) loss 0.6426 (0.9106) acc 78.1250 (75.7500) lr 1.7902e-03 eta 0:13:53
epoch [44/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.4033 (0.8824) acc 90.6250 (76.5625) lr 1.7902e-03 eta 0:13:22
epoch [44/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5400 (0.8778) acc 87.5000 (76.5179) lr 1.7902e-03 eta 0:13:00
epoch [44/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.5034 (0.8671) acc 87.5000 (76.8750) lr 1.7902e-03 eta 0:12:44
epoch [44/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.013) loss 0.7480 (0.8611) acc 81.2500 (77.3611) lr 1.7902e-03 eta 0:12:31
epoch [44/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6914 (0.8722) acc 84.3750 (76.8750) lr 1.7804e-03 eta 0:12:20
epoch [45/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.097) loss 0.6929 (0.7546) acc 84.3750 (77.5000) lr 1.7804e-03 eta 0:23:44
epoch [45/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 0.7910 (0.7926) acc 78.1250 (78.1250) lr 1.7804e-03 eta 0:17:20
epoch [45/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.7466 (0.7998) acc 68.7500 (76.4583) lr 1.7804e-03 eta 0:15:12
epoch [45/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 1.0498 (0.8081) acc 75.0000 (77.0312) lr 1.7804e-03 eta 0:14:08
epoch [45/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 1.3535 (0.8599) acc 59.3750 (75.7500) lr 1.7804e-03 eta 0:13:29
epoch [45/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.9336 (0.8520) acc 68.7500 (76.1458) lr 1.7804e-03 eta 0:13:03
epoch [45/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.8394 (0.8329) acc 78.1250 (76.8750) lr 1.7804e-03 eta 0:12:45
epoch [45/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.7026 (0.8148) acc 78.1250 (77.1094) lr 1.7804e-03 eta 0:12:30
epoch [45/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.7920 (0.8507) acc 56.2500 (76.1111) lr 1.7804e-03 eta 0:12:18
epoch [45/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9292 (0.8579) acc 75.0000 (75.7500) lr 1.7705e-03 eta 0:12:08
epoch [46/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.101) loss 1.0742 (0.9962) acc 78.1250 (78.1250) lr 1.7705e-03 eta 0:23:57
epoch [46/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.051) loss 0.8320 (0.9419) acc 81.2500 (78.1250) lr 1.7705e-03 eta 0:17:23
epoch [46/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.2324 (0.9326) acc 68.7500 (77.0833) lr 1.7705e-03 eta 0:15:12
epoch [46/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 1.2646 (0.9130) acc 75.0000 (77.3438) lr 1.7705e-03 eta 0:14:06
epoch [46/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.3730 (0.8874) acc 90.6250 (77.6250) lr 1.7705e-03 eta 0:13:26
epoch [46/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.0391 (0.8763) acc 75.0000 (78.0208) lr 1.7705e-03 eta 0:12:59
epoch [46/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.8735 (0.8804) acc 81.2500 (77.5000) lr 1.7705e-03 eta 0:12:40
epoch [46/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6133 (0.8782) acc 84.3750 (77.2656) lr 1.7705e-03 eta 0:12:25
epoch [46/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4233 (0.8461) acc 84.3750 (77.6389) lr 1.7705e-03 eta 0:12:13
epoch [46/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.3896 (0.8363) acc 90.6250 (77.6250) lr 1.7604e-03 eta 0:12:04
epoch [47/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 0.8320 (0.9328) acc 78.1250 (76.2500) lr 1.7604e-03 eta 0:24:47
epoch [47/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 1.0928 (0.9703) acc 75.0000 (75.0000) lr 1.7604e-03 eta 0:17:47
epoch [47/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 1.5859 (0.9904) acc 62.5000 (73.7500) lr 1.7604e-03 eta 0:15:26
epoch [47/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.8208 (0.9802) acc 81.2500 (74.2188) lr 1.7604e-03 eta 0:14:16
epoch [47/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 1.0752 (0.9356) acc 75.0000 (75.6250) lr 1.7604e-03 eta 0:13:34
epoch [47/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6992 (0.9258) acc 78.1250 (75.6250) lr 1.7604e-03 eta 0:13:05
epoch [47/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.016) loss 1.1641 (0.9389) acc 68.7500 (75.2679) lr 1.7604e-03 eta 0:12:45
epoch [47/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7974 (0.9317) acc 81.2500 (75.5469) lr 1.7604e-03 eta 0:12:29
epoch [47/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7930 (0.9298) acc 78.1250 (75.4167) lr 1.7604e-03 eta 0:12:16
epoch [47/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2158 (0.9339) acc 75.0000 (75.1250) lr 1.7501e-03 eta 0:12:06
epoch [48/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.098) loss 0.8569 (0.6327) acc 75.0000 (81.2500) lr 1.7501e-03 eta 0:23:19
epoch [48/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 1.2363 (0.8817) acc 65.6250 (75.6250) lr 1.7501e-03 eta 0:16:59
epoch [48/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 1.2422 (0.8790) acc 65.6250 (75.2083) lr 1.7501e-03 eta 0:14:52
epoch [48/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.6226 (0.8672) acc 84.3750 (75.4688) lr 1.7501e-03 eta 0:13:51
epoch [48/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.3594 (0.9047) acc 59.3750 (73.8750) lr 1.7501e-03 eta 0:13:11
epoch [48/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.7495 (0.8766) acc 78.1250 (75.0000) lr 1.7501e-03 eta 0:12:47
epoch [48/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7754 (0.8878) acc 68.7500 (75.0893) lr 1.7501e-03 eta 0:12:29
epoch [48/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.8154 (0.8686) acc 78.1250 (75.3906) lr 1.7501e-03 eta 0:12:14
epoch [48/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8345 (0.8535) acc 75.0000 (76.0417) lr 1.7501e-03 eta 0:12:03
epoch [48/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5547 (0.8504) acc 90.6250 (76.3125) lr 1.7396e-03 eta 0:11:53
epoch [49/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.106) loss 0.6895 (0.9930) acc 75.0000 (71.8750) lr 1.7396e-03 eta 0:24:11
epoch [49/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.7988 (0.8187) acc 71.8750 (75.0000) lr 1.7396e-03 eta 0:17:27
epoch [49/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.7524 (0.7867) acc 78.1250 (76.0417) lr 1.7396e-03 eta 0:15:11
epoch [49/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 1.2236 (0.7700) acc 59.3750 (76.8750) lr 1.7396e-03 eta 0:14:04
epoch [49/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.5444 (0.8386) acc 93.7500 (76.2500) lr 1.7396e-03 eta 0:13:23
epoch [49/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 1.1904 (0.8560) acc 71.8750 (76.1458) lr 1.7396e-03 eta 0:12:55
epoch [49/200] batch [35/50] time 0.083 (0.100) data 0.000 (0.015) loss 0.8477 (0.8545) acc 81.2500 (76.1607) lr 1.7396e-03 eta 0:12:34
epoch [49/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 1.1016 (0.8620) acc 75.0000 (75.9375) lr 1.7396e-03 eta 0:12:18
epoch [49/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7993 (0.8443) acc 71.8750 (76.4583) lr 1.7396e-03 eta 0:12:05
epoch [49/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4556 (0.8326) acc 87.5000 (77.0000) lr 1.7290e-03 eta 0:11:55
epoch [50/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.102) loss 0.6265 (0.8830) acc 84.3750 (78.1250) lr 1.7290e-03 eta 0:23:41
epoch [50/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.051) loss 0.6685 (0.8060) acc 81.2500 (79.0625) lr 1.7290e-03 eta 0:17:10
epoch [50/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.034) loss 1.1885 (0.9143) acc 62.5000 (76.6667) lr 1.7290e-03 eta 0:15:00
epoch [50/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.5366 (0.8737) acc 90.6250 (77.6562) lr 1.7290e-03 eta 0:13:54
epoch [50/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 1.3389 (0.8753) acc 59.3750 (77.1250) lr 1.7290e-03 eta 0:13:14
epoch [50/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.5933 (0.8531) acc 81.2500 (77.2917) lr 1.7290e-03 eta 0:12:47
epoch [50/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.015) loss 0.9033 (0.8627) acc 75.0000 (76.7857) lr 1.7290e-03 eta 0:12:28
epoch [50/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.8242 (0.8536) acc 78.1250 (76.9531) lr 1.7290e-03 eta 0:12:12
epoch [50/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6094 (0.8431) acc 87.5000 (77.2222) lr 1.7290e-03 eta 0:12:00
epoch [50/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 1.0264 (0.8440) acc 68.7500 (77.3750) lr 1.7181e-03 eta 0:11:50
epoch [51/200] batch [5/50] time 0.083 (0.196) data 0.000 (0.111) loss 0.5239 (0.8636) acc 87.5000 (78.7500) lr 1.7181e-03 eta 0:24:25
epoch [51/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.056) loss 0.6421 (0.9324) acc 78.1250 (75.6250) lr 1.7181e-03 eta 0:17:26
epoch [51/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 0.8613 (0.9374) acc 81.2500 (76.2500) lr 1.7181e-03 eta 0:15:07
epoch [51/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.7427 (0.8930) acc 81.2500 (76.8750) lr 1.7181e-03 eta 0:13:56
epoch [51/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.8760 (0.8870) acc 81.2500 (76.7500) lr 1.7181e-03 eta 0:13:14
epoch [51/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.6909 (0.8826) acc 87.5000 (77.0833) lr 1.7181e-03 eta 0:12:46
epoch [51/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7368 (0.8714) acc 84.3750 (77.5000) lr 1.7181e-03 eta 0:12:26
epoch [51/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.0156 (0.8759) acc 78.1250 (77.2656) lr 1.7181e-03 eta 0:12:10
epoch [51/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.013) loss 1.2402 (0.8907) acc 65.6250 (76.8750) lr 1.7181e-03 eta 0:11:57
epoch [51/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0303 (0.8853) acc 78.1250 (76.9375) lr 1.7071e-03 eta 0:11:47
epoch [52/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.100) loss 0.7959 (0.7521) acc 75.0000 (83.7500) lr 1.7071e-03 eta 0:22:55
epoch [52/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.8042 (0.7946) acc 81.2500 (81.5625) lr 1.7071e-03 eta 0:16:38
epoch [52/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.034) loss 0.8218 (0.8507) acc 75.0000 (77.2917) lr 1.7071e-03 eta 0:14:33
epoch [52/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 1.0410 (0.8687) acc 65.6250 (76.0938) lr 1.7071e-03 eta 0:13:30
epoch [52/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.1992 (0.8461) acc 68.7500 (76.8750) lr 1.7071e-03 eta 0:12:52
epoch [52/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.3125 (0.8676) acc 68.7500 (76.3542) lr 1.7071e-03 eta 0:12:28
epoch [52/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.015) loss 0.7842 (0.8683) acc 78.1250 (76.6964) lr 1.7071e-03 eta 0:12:09
epoch [52/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0088 (0.8524) acc 78.1250 (76.8750) lr 1.7071e-03 eta 0:11:55
epoch [52/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5449 (0.8390) acc 84.3750 (77.4306) lr 1.7071e-03 eta 0:11:43
epoch [52/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9502 (0.8492) acc 81.2500 (77.3750) lr 1.6959e-03 eta 0:11:34
epoch [53/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.098) loss 0.8286 (0.8412) acc 81.2500 (77.5000) lr 1.6959e-03 eta 0:22:28
epoch [53/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.049) loss 1.1084 (0.7921) acc 68.7500 (78.4375) lr 1.6959e-03 eta 0:16:22
epoch [53/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.5942 (0.7862) acc 84.3750 (77.7083) lr 1.6959e-03 eta 0:14:21
epoch [53/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.9170 (0.8140) acc 75.0000 (77.3438) lr 1.6959e-03 eta 0:13:20
epoch [53/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.8076 (0.8126) acc 78.1250 (76.8750) lr 1.6959e-03 eta 0:12:44
epoch [53/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6562 (0.8178) acc 81.2500 (76.3542) lr 1.6959e-03 eta 0:12:20
epoch [53/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9961 (0.8097) acc 75.0000 (76.6964) lr 1.6959e-03 eta 0:12:02
epoch [53/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8325 (0.7744) acc 75.0000 (77.8906) lr 1.6959e-03 eta 0:11:48
epoch [53/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7920 (0.7873) acc 81.2500 (77.6389) lr 1.6959e-03 eta 0:11:36
epoch [53/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5464 (0.7838) acc 84.3750 (77.8750) lr 1.6845e-03 eta 0:11:28
epoch [54/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.102) loss 1.3350 (0.8200) acc 62.5000 (79.3750) lr 1.6845e-03 eta 0:22:57
epoch [54/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.5933 (0.7862) acc 75.0000 (79.0625) lr 1.6845e-03 eta 0:16:37
epoch [54/200] batch [15/50] time 0.086 (0.119) data 0.000 (0.034) loss 0.6768 (0.7455) acc 78.1250 (78.9583) lr 1.6845e-03 eta 0:14:33
epoch [54/200] batch [20/50] time 0.086 (0.110) data 0.000 (0.026) loss 1.3760 (0.7642) acc 71.8750 (78.9062) lr 1.6845e-03 eta 0:13:29
epoch [54/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.8335 (0.7871) acc 78.1250 (78.7500) lr 1.6845e-03 eta 0:12:51
epoch [54/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.4556 (0.8021) acc 84.3750 (77.8125) lr 1.6845e-03 eta 0:12:26
epoch [54/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 1.2500 (0.8193) acc 68.7500 (77.4107) lr 1.6845e-03 eta 0:12:07
epoch [54/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.6470 (0.8078) acc 75.0000 (77.9688) lr 1.6845e-03 eta 0:11:52
epoch [54/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6362 (0.8088) acc 81.2500 (77.8472) lr 1.6845e-03 eta 0:11:41
epoch [54/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.9937 (0.8141) acc 75.0000 (77.5625) lr 1.6730e-03 eta 0:11:32
epoch [55/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.109) loss 0.6309 (0.9544) acc 81.2500 (73.7500) lr 1.6730e-03 eta 0:23:33
epoch [55/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.055) loss 1.2646 (0.9301) acc 71.8750 (75.9375) lr 1.6730e-03 eta 0:16:54
epoch [55/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 0.5132 (0.8932) acc 81.2500 (75.2083) lr 1.6730e-03 eta 0:14:40
epoch [55/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.5996 (0.8884) acc 78.1250 (75.4688) lr 1.6730e-03 eta 0:13:33
epoch [55/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.8716 (0.8567) acc 78.1250 (75.8750) lr 1.6730e-03 eta 0:12:53
epoch [55/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6274 (0.8526) acc 90.6250 (76.2500) lr 1.6730e-03 eta 0:12:26
epoch [55/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6499 (0.8226) acc 84.3750 (77.4107) lr 1.6730e-03 eta 0:12:06
epoch [55/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7744 (0.8331) acc 81.2500 (77.1094) lr 1.6730e-03 eta 0:11:50
epoch [55/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7085 (0.8248) acc 81.2500 (77.6389) lr 1.6730e-03 eta 0:11:38
epoch [55/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4194 (0.8142) acc 90.6250 (77.8125) lr 1.6613e-03 eta 0:11:29
epoch [56/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 1.2314 (0.9905) acc 62.5000 (70.6250) lr 1.6613e-03 eta 0:22:35
epoch [56/200] batch [10/50] time 0.083 (0.136) data 0.000 (0.051) loss 0.3845 (0.8669) acc 84.3750 (73.4375) lr 1.6613e-03 eta 0:16:22
epoch [56/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.4082 (0.9744) acc 65.6250 (72.2917) lr 1.6613e-03 eta 0:14:17
epoch [56/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.1172 (0.9652) acc 62.5000 (73.2812) lr 1.6613e-03 eta 0:13:14
epoch [56/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8716 (0.9374) acc 75.0000 (74.5000) lr 1.6613e-03 eta 0:12:37
epoch [56/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.7964 (0.9174) acc 87.5000 (75.7292) lr 1.6613e-03 eta 0:12:11
epoch [56/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.4600 (0.9457) acc 65.6250 (75.0893) lr 1.6613e-03 eta 0:11:54
epoch [56/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.4209 (0.9536) acc 62.5000 (74.7656) lr 1.6613e-03 eta 0:11:39
epoch [56/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2168 (0.9569) acc 71.8750 (74.7917) lr 1.6613e-03 eta 0:11:27
epoch [56/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7178 (0.9542) acc 75.0000 (75.0000) lr 1.6494e-03 eta 0:11:18
epoch [57/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.108) loss 0.7173 (0.7680) acc 65.6250 (75.6250) lr 1.6494e-03 eta 0:23:04
epoch [57/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.054) loss 0.7261 (0.7580) acc 81.2500 (75.9375) lr 1.6494e-03 eta 0:16:33
epoch [57/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.8442 (0.7601) acc 71.8750 (76.0417) lr 1.6494e-03 eta 0:14:23
epoch [57/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.9272 (0.7709) acc 78.1250 (76.7188) lr 1.6494e-03 eta 0:13:18
epoch [57/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.6338 (0.7869) acc 90.6250 (76.5000) lr 1.6494e-03 eta 0:12:38
epoch [57/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6655 (0.7962) acc 78.1250 (76.8750) lr 1.6494e-03 eta 0:12:12
epoch [57/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.1338 (0.8040) acc 71.8750 (76.8750) lr 1.6494e-03 eta 0:11:53
epoch [57/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.4658 (0.8193) acc 59.3750 (76.4062) lr 1.6494e-03 eta 0:11:38
epoch [57/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4258 (0.8088) acc 87.5000 (76.7361) lr 1.6494e-03 eta 0:11:26
epoch [57/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9570 (0.8275) acc 68.7500 (76.1250) lr 1.6374e-03 eta 0:11:16
epoch [58/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.109) loss 0.8687 (0.6851) acc 71.8750 (80.0000) lr 1.6374e-03 eta 0:23:01
epoch [58/200] batch [10/50] time 0.083 (0.139) data 0.000 (0.055) loss 0.3411 (0.7307) acc 90.6250 (79.3750) lr 1.6374e-03 eta 0:16:31
epoch [58/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.037) loss 1.1777 (0.7514) acc 71.8750 (78.7500) lr 1.6374e-03 eta 0:14:19
epoch [58/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.027) loss 0.7871 (0.8202) acc 81.2500 (78.1250) lr 1.6374e-03 eta 0:13:13
epoch [58/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.7671 (0.8065) acc 75.0000 (77.7500) lr 1.6374e-03 eta 0:12:34
epoch [58/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.8970 (0.8308) acc 78.1250 (77.2917) lr 1.6374e-03 eta 0:12:07
epoch [58/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6162 (0.8183) acc 87.5000 (77.6786) lr 1.6374e-03 eta 0:11:49
epoch [58/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.6060 (0.8227) acc 81.2500 (77.8906) lr 1.6374e-03 eta 0:11:34
epoch [58/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.7568 (0.8504) acc 59.3750 (77.2917) lr 1.6374e-03 eta 0:11:22
epoch [58/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5977 (0.8500) acc 84.3750 (77.5000) lr 1.6252e-03 eta 0:11:12
epoch [59/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.098) loss 1.0430 (0.7780) acc 62.5000 (76.2500) lr 1.6252e-03 eta 0:21:41
epoch [59/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.9199 (0.7221) acc 78.1250 (79.0625) lr 1.6252e-03 eta 0:15:50
epoch [59/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.8823 (0.7194) acc 84.3750 (80.4167) lr 1.6252e-03 eta 0:13:54
epoch [59/200] batch [20/50] time 0.086 (0.110) data 0.000 (0.025) loss 1.1611 (0.7787) acc 71.8750 (78.7500) lr 1.6252e-03 eta 0:12:55
epoch [59/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.9731 (0.7907) acc 65.6250 (77.7500) lr 1.6252e-03 eta 0:12:19
epoch [59/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 1.1611 (0.7982) acc 65.6250 (77.3958) lr 1.6252e-03 eta 0:11:56
epoch [59/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.6152 (0.8366) acc 59.3750 (76.6071) lr 1.6252e-03 eta 0:11:38
epoch [59/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 1.3311 (0.8369) acc 68.7500 (76.8750) lr 1.6252e-03 eta 0:11:24
epoch [59/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5171 (0.8128) acc 81.2500 (77.7083) lr 1.6252e-03 eta 0:11:13
epoch [59/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6641 (0.8255) acc 75.0000 (77.4375) lr 1.6129e-03 eta 0:11:04
epoch [60/200] batch [5/50] time 0.084 (0.196) data 0.000 (0.111) loss 0.4575 (0.7208) acc 87.5000 (85.0000) lr 1.6129e-03 eta 0:23:01
epoch [60/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.056) loss 0.8579 (0.6877) acc 75.0000 (84.0625) lr 1.6129e-03 eta 0:16:27
epoch [60/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.037) loss 0.8647 (0.8054) acc 75.0000 (81.0417) lr 1.6129e-03 eta 0:14:16
epoch [60/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 1.0898 (0.8400) acc 71.8750 (79.5312) lr 1.6129e-03 eta 0:13:10
epoch [60/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.5181 (0.8484) acc 81.2500 (78.5000) lr 1.6129e-03 eta 0:12:30
epoch [60/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.7861 (0.8498) acc 78.1250 (78.2292) lr 1.6129e-03 eta 0:12:03
epoch [60/200] batch [35/50] time 0.089 (0.101) data 0.000 (0.016) loss 0.5264 (0.8308) acc 87.5000 (78.3929) lr 1.6129e-03 eta 0:11:45
epoch [60/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7388 (0.8140) acc 75.0000 (78.3594) lr 1.6129e-03 eta 0:11:29
epoch [60/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.4854 (0.8220) acc 59.3750 (78.0556) lr 1.6129e-03 eta 0:11:17
epoch [60/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5991 (0.8257) acc 78.1250 (78.0625) lr 1.6004e-03 eta 0:11:07
epoch [61/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 1.2295 (1.0450) acc 71.8750 (72.5000) lr 1.6004e-03 eta 0:22:09
epoch [61/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.053) loss 0.8047 (0.9157) acc 78.1250 (75.3125) lr 1.6004e-03 eta 0:15:59
epoch [61/200] batch [15/50] time 0.086 (0.120) data 0.000 (0.035) loss 0.9561 (0.8950) acc 81.2500 (76.2500) lr 1.6004e-03 eta 0:13:56
epoch [61/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.5112 (0.8391) acc 81.2500 (77.6562) lr 1.6004e-03 eta 0:12:53
epoch [61/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.8818 (0.8064) acc 71.8750 (78.5000) lr 1.6004e-03 eta 0:12:17
epoch [61/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 1.1328 (0.8191) acc 75.0000 (78.3333) lr 1.6004e-03 eta 0:11:51
epoch [61/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.8008 (0.8164) acc 78.1250 (78.6607) lr 1.6004e-03 eta 0:11:34
epoch [61/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.9639 (0.8340) acc 75.0000 (78.0469) lr 1.6004e-03 eta 0:11:19
epoch [61/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6431 (0.8388) acc 84.3750 (77.5694) lr 1.6004e-03 eta 0:11:07
epoch [61/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0605 (0.8533) acc 75.0000 (77.1875) lr 1.5878e-03 eta 0:10:58
epoch [62/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.108) loss 0.5361 (0.6213) acc 84.3750 (85.6250) lr 1.5878e-03 eta 0:22:21
epoch [62/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.6562 (0.6969) acc 84.3750 (83.4375) lr 1.5878e-03 eta 0:16:01
epoch [62/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.2070 (0.7619) acc 56.2500 (80.0000) lr 1.5878e-03 eta 0:13:55
epoch [62/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.8301 (0.7663) acc 78.1250 (79.6875) lr 1.5878e-03 eta 0:12:53
epoch [62/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.5698 (0.8030) acc 81.2500 (78.7500) lr 1.5878e-03 eta 0:12:14
epoch [62/200] batch [30/50] time 0.083 (0.102) data 0.000 (0.018) loss 0.3694 (0.7972) acc 90.6250 (78.5417) lr 1.5878e-03 eta 0:11:48
epoch [62/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8521 (0.8035) acc 75.0000 (78.1250) lr 1.5878e-03 eta 0:11:29
epoch [62/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.8311 (0.8279) acc 81.2500 (77.6562) lr 1.5878e-03 eta 0:11:15
epoch [62/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7314 (0.8283) acc 78.1250 (77.4306) lr 1.5878e-03 eta 0:11:03
epoch [62/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9995 (0.8224) acc 68.7500 (77.4375) lr 1.5750e-03 eta 0:10:54
epoch [63/200] batch [5/50] time 0.083 (0.180) data 0.000 (0.095) loss 0.6577 (0.8506) acc 87.5000 (74.3750) lr 1.5750e-03 eta 0:20:43
epoch [63/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.048) loss 1.4473 (0.8019) acc 65.6250 (77.8125) lr 1.5750e-03 eta 0:15:10
epoch [63/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 1.2402 (0.8329) acc 68.7500 (76.6667) lr 1.5750e-03 eta 0:13:20
epoch [63/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.8789 (0.8494) acc 84.3750 (77.0312) lr 1.5750e-03 eta 0:12:24
epoch [63/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.8794 (0.8721) acc 68.7500 (76.1250) lr 1.5750e-03 eta 0:11:51
epoch [63/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5161 (0.8647) acc 78.1250 (76.0417) lr 1.5750e-03 eta 0:11:28
epoch [63/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.5938 (0.8561) acc 81.2500 (76.8750) lr 1.5750e-03 eta 0:11:12
epoch [63/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4590 (0.8261) acc 87.5000 (77.9688) lr 1.5750e-03 eta 0:10:59
epoch [63/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7798 (0.8146) acc 75.0000 (77.7083) lr 1.5750e-03 eta 0:10:49
epoch [63/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7695 (0.8238) acc 81.2500 (77.5000) lr 1.5621e-03 eta 0:10:40
epoch [64/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.6948 (0.8416) acc 81.2500 (77.5000) lr 1.5621e-03 eta 0:20:41
epoch [64/200] batch [10/50] time 0.088 (0.133) data 0.000 (0.048) loss 0.3726 (0.8556) acc 81.2500 (74.3750) lr 1.5621e-03 eta 0:15:12
epoch [64/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.9507 (0.8400) acc 78.1250 (75.0000) lr 1.5621e-03 eta 0:13:20
epoch [64/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.8423 (0.7910) acc 75.0000 (76.7188) lr 1.5621e-03 eta 0:12:23
epoch [64/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7046 (0.7882) acc 75.0000 (77.5000) lr 1.5621e-03 eta 0:11:50
epoch [64/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 1.3184 (0.8236) acc 71.8750 (77.0833) lr 1.5621e-03 eta 0:11:27
epoch [64/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.8408 (0.8251) acc 75.0000 (77.3214) lr 1.5621e-03 eta 0:11:11
epoch [64/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.2729 (0.8269) acc 93.7500 (77.3438) lr 1.5621e-03 eta 0:10:58
epoch [64/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7368 (0.8346) acc 78.1250 (76.8750) lr 1.5621e-03 eta 0:10:47
epoch [64/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9004 (0.8320) acc 71.8750 (76.7500) lr 1.5490e-03 eta 0:10:39
epoch [65/200] batch [5/50] time 0.085 (0.182) data 0.000 (0.097) loss 0.4988 (0.7103) acc 90.6250 (78.7500) lr 1.5490e-03 eta 0:20:39
epoch [65/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.048) loss 0.5942 (0.8629) acc 81.2500 (76.8750) lr 1.5490e-03 eta 0:15:06
epoch [65/200] batch [15/50] time 0.084 (0.117) data 0.001 (0.032) loss 0.5469 (0.7825) acc 84.3750 (78.9583) lr 1.5490e-03 eta 0:13:15
epoch [65/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.6768 (0.8012) acc 81.2500 (78.2812) lr 1.5490e-03 eta 0:12:19
epoch [65/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.8262 (0.8162) acc 75.0000 (77.2500) lr 1.5490e-03 eta 0:11:45
epoch [65/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.8721 (0.8222) acc 78.1250 (76.9792) lr 1.5490e-03 eta 0:11:23
epoch [65/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.1582 (0.8527) acc 75.0000 (76.4286) lr 1.5490e-03 eta 0:11:06
epoch [65/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.3281 (0.8778) acc 62.5000 (75.8594) lr 1.5490e-03 eta 0:10:53
epoch [65/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.1709 (0.8711) acc 75.0000 (76.0417) lr 1.5490e-03 eta 0:10:42
epoch [65/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.2305 (0.8478) acc 71.8750 (77.0000) lr 1.5358e-03 eta 0:10:34
epoch [66/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 0.5508 (0.7856) acc 90.6250 (80.6250) lr 1.5358e-03 eta 0:21:15
epoch [66/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.6577 (0.7461) acc 90.6250 (81.2500) lr 1.5358e-03 eta 0:15:23
epoch [66/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.8066 (0.7651) acc 78.1250 (80.2083) lr 1.5358e-03 eta 0:13:23
epoch [66/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.026) loss 1.0781 (0.7855) acc 68.7500 (79.5312) lr 1.5358e-03 eta 0:12:23
epoch [66/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.8379 (0.7878) acc 75.0000 (78.7500) lr 1.5358e-03 eta 0:11:48
epoch [66/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.0410 (0.8147) acc 78.1250 (78.1250) lr 1.5358e-03 eta 0:11:23
epoch [66/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7900 (0.8075) acc 78.1250 (78.1250) lr 1.5358e-03 eta 0:11:06
epoch [66/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6768 (0.7955) acc 84.3750 (78.6719) lr 1.5358e-03 eta 0:10:52
epoch [66/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4326 (0.7712) acc 87.5000 (79.3056) lr 1.5358e-03 eta 0:10:41
epoch [66/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.8428 (0.7632) acc 71.8750 (79.3750) lr 1.5225e-03 eta 0:10:33
epoch [67/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.110) loss 0.6753 (0.8615) acc 78.1250 (76.8750) lr 1.5225e-03 eta 0:21:48
epoch [67/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.055) loss 0.6587 (0.8708) acc 84.3750 (77.5000) lr 1.5225e-03 eta 0:15:35
epoch [67/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 1.0166 (0.8383) acc 75.0000 (78.1250) lr 1.5225e-03 eta 0:13:30
epoch [67/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 1.0430 (0.8304) acc 75.0000 (78.2812) lr 1.5225e-03 eta 0:12:28
epoch [67/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 0.9712 (0.8330) acc 68.7500 (77.8750) lr 1.5225e-03 eta 0:11:51
epoch [67/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.4109 (0.8397) acc 93.7500 (78.5417) lr 1.5225e-03 eta 0:11:25
epoch [67/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6030 (0.8297) acc 84.3750 (78.4821) lr 1.5225e-03 eta 0:11:07
epoch [67/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.0859 (0.8146) acc 65.6250 (78.2812) lr 1.5225e-03 eta 0:10:53
epoch [67/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8462 (0.8272) acc 62.5000 (77.9167) lr 1.5225e-03 eta 0:10:41
epoch [67/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.3059 (0.8246) acc 90.6250 (77.6875) lr 1.5090e-03 eta 0:10:32
epoch [68/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.107) loss 1.1035 (0.7288) acc 75.0000 (80.6250) lr 1.5090e-03 eta 0:21:16
epoch [68/200] batch [10/50] time 0.086 (0.139) data 0.000 (0.053) loss 0.8804 (0.6661) acc 71.8750 (80.6250) lr 1.5090e-03 eta 0:15:20
epoch [68/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.2600 (0.6920) acc 93.7500 (81.0417) lr 1.5090e-03 eta 0:13:20
epoch [68/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.8271 (0.7445) acc 68.7500 (79.3750) lr 1.5090e-03 eta 0:12:21
epoch [68/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.5610 (0.7460) acc 87.5000 (79.6250) lr 1.5090e-03 eta 0:11:45
epoch [68/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 1.4648 (0.7983) acc 56.2500 (77.7083) lr 1.5090e-03 eta 0:11:21
epoch [68/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.8955 (0.8251) acc 65.6250 (76.8750) lr 1.5090e-03 eta 0:11:03
epoch [68/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7197 (0.8209) acc 81.2500 (77.1094) lr 1.5090e-03 eta 0:10:49
epoch [68/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.2207 (0.8247) acc 78.1250 (77.2917) lr 1.5090e-03 eta 0:10:37
epoch [68/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8516 (0.8232) acc 75.0000 (77.5000) lr 1.4955e-03 eta 0:10:29
epoch [69/200] batch [5/50] time 0.084 (0.197) data 0.000 (0.112) loss 1.1113 (0.9863) acc 78.1250 (76.2500) lr 1.4955e-03 eta 0:21:36
epoch [69/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.056) loss 0.7959 (0.8437) acc 71.8750 (79.0625) lr 1.4955e-03 eta 0:15:23
epoch [69/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.038) loss 0.6743 (0.7927) acc 81.2500 (78.9583) lr 1.4955e-03 eta 0:13:20
epoch [69/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.7114 (0.7869) acc 78.1250 (78.9062) lr 1.4955e-03 eta 0:12:18
epoch [69/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.023) loss 1.0088 (0.7932) acc 75.0000 (78.8750) lr 1.4955e-03 eta 0:11:40
epoch [69/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.5488 (0.7972) acc 84.3750 (78.7500) lr 1.4955e-03 eta 0:11:16
epoch [69/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.016) loss 0.4963 (0.8066) acc 81.2500 (78.1250) lr 1.4955e-03 eta 0:10:58
epoch [69/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8882 (0.8188) acc 65.6250 (77.1875) lr 1.4955e-03 eta 0:10:43
epoch [69/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.013) loss 1.3926 (0.8515) acc 62.5000 (76.5972) lr 1.4955e-03 eta 0:10:32
epoch [69/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1455 (0.8476) acc 71.8750 (76.9375) lr 1.4818e-03 eta 0:10:23
epoch [70/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.105) loss 0.5850 (0.8755) acc 84.3750 (75.0000) lr 1.4818e-03 eta 0:20:44
epoch [70/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.6934 (0.8572) acc 81.2500 (76.5625) lr 1.4818e-03 eta 0:14:56
epoch [70/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.8340 (0.8306) acc 78.1250 (77.0833) lr 1.4818e-03 eta 0:13:01
epoch [70/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.9009 (0.8383) acc 68.7500 (76.8750) lr 1.4818e-03 eta 0:12:03
epoch [70/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 1.3164 (0.8483) acc 68.7500 (77.0000) lr 1.4818e-03 eta 0:11:28
epoch [70/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.4922 (0.8271) acc 81.2500 (77.2917) lr 1.4818e-03 eta 0:11:05
epoch [70/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.6621 (0.8240) acc 84.3750 (77.6786) lr 1.4818e-03 eta 0:10:48
epoch [70/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.9321 (0.8320) acc 68.7500 (77.5781) lr 1.4818e-03 eta 0:10:34
epoch [70/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8105 (0.8298) acc 71.8750 (77.3611) lr 1.4818e-03 eta 0:10:24
epoch [70/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6987 (0.8350) acc 71.8750 (77.3125) lr 1.4679e-03 eta 0:10:15
epoch [71/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 0.5571 (0.7111) acc 87.5000 (80.0000) lr 1.4679e-03 eta 0:20:55
epoch [71/200] batch [10/50] time 0.083 (0.139) data 0.000 (0.054) loss 1.2764 (0.7383) acc 65.6250 (80.0000) lr 1.4679e-03 eta 0:14:59
epoch [71/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.4382 (0.7229) acc 87.5000 (80.8333) lr 1.4679e-03 eta 0:13:01
epoch [71/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.8721 (0.7557) acc 78.1250 (80.0000) lr 1.4679e-03 eta 0:12:02
epoch [71/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 1.0674 (0.7788) acc 65.6250 (79.7500) lr 1.4679e-03 eta 0:11:26
epoch [71/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.0088 (0.7801) acc 71.8750 (80.0000) lr 1.4679e-03 eta 0:11:02
epoch [71/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5859 (0.8068) acc 81.2500 (78.5714) lr 1.4679e-03 eta 0:10:45
epoch [71/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.0049 (0.8217) acc 68.7500 (77.8125) lr 1.4679e-03 eta 0:10:31
epoch [71/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9189 (0.8155) acc 87.5000 (78.3333) lr 1.4679e-03 eta 0:10:21
epoch [71/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7817 (0.8405) acc 81.2500 (77.8125) lr 1.4540e-03 eta 0:10:12
epoch [72/200] batch [5/50] time 0.084 (0.196) data 0.000 (0.111) loss 0.9155 (0.8160) acc 68.7500 (79.3750) lr 1.4540e-03 eta 0:21:01
epoch [72/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.056) loss 1.4473 (0.9022) acc 56.2500 (76.2500) lr 1.4540e-03 eta 0:14:59
epoch [72/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 0.7627 (0.9378) acc 75.0000 (73.9583) lr 1.4540e-03 eta 0:13:01
epoch [72/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.6138 (0.8892) acc 78.1250 (75.7812) lr 1.4540e-03 eta 0:12:02
epoch [72/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 0.8901 (0.8982) acc 75.0000 (75.7500) lr 1.4540e-03 eta 0:11:26
epoch [72/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 1.3770 (0.8836) acc 65.6250 (76.0417) lr 1.4540e-03 eta 0:11:02
epoch [72/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.8813 (0.8843) acc 75.0000 (75.9821) lr 1.4540e-03 eta 0:10:44
epoch [72/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4802 (0.8755) acc 90.6250 (76.4844) lr 1.4540e-03 eta 0:10:30
epoch [72/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5386 (0.8692) acc 84.3750 (76.8750) lr 1.4540e-03 eta 0:10:19
epoch [72/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4949 (0.8693) acc 81.2500 (76.6875) lr 1.4399e-03 eta 0:10:11
epoch [73/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.105) loss 0.7080 (0.7633) acc 81.2500 (80.0000) lr 1.4399e-03 eta 0:20:14
epoch [73/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.9116 (0.8215) acc 71.8750 (78.4375) lr 1.4399e-03 eta 0:14:35
epoch [73/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 1.1455 (0.7712) acc 68.7500 (79.3750) lr 1.4399e-03 eta 0:12:42
epoch [73/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.4424 (0.7494) acc 78.1250 (79.0625) lr 1.4399e-03 eta 0:11:45
epoch [73/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 1.1191 (0.7601) acc 78.1250 (78.8750) lr 1.4399e-03 eta 0:11:12
epoch [73/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.7358 (0.7858) acc 81.2500 (78.2292) lr 1.4399e-03 eta 0:10:49
epoch [73/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7783 (0.7821) acc 78.1250 (78.3036) lr 1.4399e-03 eta 0:10:32
epoch [73/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7505 (0.7781) acc 71.8750 (78.2812) lr 1.4399e-03 eta 0:10:19
epoch [73/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7803 (0.7897) acc 78.1250 (77.9861) lr 1.4399e-03 eta 0:10:09
epoch [73/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8120 (0.7916) acc 75.0000 (77.8750) lr 1.4258e-03 eta 0:10:00
epoch [74/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 0.6636 (0.7007) acc 78.1250 (80.0000) lr 1.4258e-03 eta 0:19:17
epoch [74/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.7046 (0.7452) acc 81.2500 (79.0625) lr 1.4258e-03 eta 0:14:04
epoch [74/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.8682 (0.7506) acc 78.1250 (80.2083) lr 1.4258e-03 eta 0:12:21
epoch [74/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.5303 (0.7305) acc 84.3750 (80.0000) lr 1.4258e-03 eta 0:11:28
epoch [74/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.9995 (0.7275) acc 78.1250 (80.2500) lr 1.4258e-03 eta 0:10:57
epoch [74/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.6919 (0.7407) acc 81.2500 (79.8958) lr 1.4258e-03 eta 0:10:36
epoch [74/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.0176 (0.7709) acc 75.0000 (79.3750) lr 1.4258e-03 eta 0:10:21
epoch [74/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.6470 (0.7760) acc 87.5000 (79.2188) lr 1.4258e-03 eta 0:10:09
epoch [74/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5215 (0.7716) acc 87.5000 (79.4444) lr 1.4258e-03 eta 0:09:59
epoch [74/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6367 (0.7779) acc 81.2500 (79.2500) lr 1.4115e-03 eta 0:09:51
epoch [75/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.9502 (0.8597) acc 71.8750 (78.1250) lr 1.4115e-03 eta 0:19:21
epoch [75/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.5352 (0.7690) acc 87.5000 (80.0000) lr 1.4115e-03 eta 0:14:06
epoch [75/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.7617 (0.7851) acc 81.2500 (79.3750) lr 1.4115e-03 eta 0:12:19
epoch [75/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.9121 (0.8329) acc 65.6250 (78.1250) lr 1.4115e-03 eta 0:11:27
epoch [75/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.6260 (0.8580) acc 87.5000 (77.1250) lr 1.4115e-03 eta 0:10:55
epoch [75/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.7632 (0.8341) acc 84.3750 (78.3333) lr 1.4115e-03 eta 0:10:34
epoch [75/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.7256 (0.8391) acc 81.2500 (77.9464) lr 1.4115e-03 eta 0:10:19
epoch [75/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.9609 (0.8192) acc 78.1250 (78.5156) lr 1.4115e-03 eta 0:10:06
epoch [75/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5591 (0.8362) acc 78.1250 (77.9167) lr 1.4115e-03 eta 0:09:56
epoch [75/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9209 (0.8136) acc 71.8750 (78.1875) lr 1.3971e-03 eta 0:09:48
epoch [76/200] batch [5/50] time 0.084 (0.199) data 0.000 (0.114) loss 1.1582 (0.8374) acc 75.0000 (78.1250) lr 1.3971e-03 eta 0:20:40
epoch [76/200] batch [10/50] time 0.085 (0.142) data 0.000 (0.057) loss 0.7788 (0.8368) acc 81.2500 (77.5000) lr 1.3971e-03 eta 0:14:44
epoch [76/200] batch [15/50] time 0.084 (0.123) data 0.000 (0.038) loss 0.3914 (0.7565) acc 87.5000 (78.9583) lr 1.3971e-03 eta 0:12:45
epoch [76/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.029) loss 0.6328 (0.7437) acc 81.2500 (79.8438) lr 1.3971e-03 eta 0:11:46
epoch [76/200] batch [25/50] time 0.085 (0.108) data 0.000 (0.023) loss 1.1738 (0.7455) acc 68.7500 (79.7500) lr 1.3971e-03 eta 0:11:10
epoch [76/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 1.3906 (0.7725) acc 65.6250 (79.0625) lr 1.3971e-03 eta 0:10:45
epoch [76/200] batch [35/50] time 0.085 (0.101) data 0.001 (0.017) loss 0.7524 (0.7728) acc 71.8750 (78.9286) lr 1.3971e-03 eta 0:10:28
epoch [76/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.014) loss 0.9136 (0.8169) acc 81.2500 (77.9688) lr 1.3971e-03 eta 0:10:14
epoch [76/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.4106 (0.7960) acc 84.3750 (78.2639) lr 1.3971e-03 eta 0:10:03
epoch [76/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7681 (0.8065) acc 84.3750 (78.4375) lr 1.3827e-03 eta 0:09:54
epoch [77/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.108) loss 1.2051 (0.9384) acc 65.6250 (73.7500) lr 1.3827e-03 eta 0:19:59
epoch [77/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.6187 (0.8953) acc 81.2500 (75.6250) lr 1.3827e-03 eta 0:14:20
epoch [77/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.8008 (0.8810) acc 81.2500 (76.4583) lr 1.3827e-03 eta 0:12:27
epoch [77/200] batch [20/50] time 0.083 (0.112) data 0.000 (0.027) loss 1.0059 (0.8603) acc 71.8750 (76.5625) lr 1.3827e-03 eta 0:11:30
epoch [77/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.6514 (0.8495) acc 78.1250 (76.5000) lr 1.3827e-03 eta 0:10:55
epoch [77/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6484 (0.8378) acc 81.2500 (76.5625) lr 1.3827e-03 eta 0:10:31
epoch [77/200] batch [35/50] time 0.083 (0.100) data 0.000 (0.016) loss 1.4805 (0.8619) acc 75.0000 (76.7857) lr 1.3827e-03 eta 0:10:14
epoch [77/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.2471 (0.8629) acc 65.6250 (76.7188) lr 1.3827e-03 eta 0:10:01
epoch [77/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4426 (0.8539) acc 87.5000 (76.5972) lr 1.3827e-03 eta 0:09:51
epoch [77/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6675 (0.8445) acc 78.1250 (76.4375) lr 1.3681e-03 eta 0:09:43
epoch [78/200] batch [5/50] time 0.085 (0.199) data 0.000 (0.115) loss 0.5820 (0.7390) acc 81.2500 (80.6250) lr 1.3681e-03 eta 0:20:24
epoch [78/200] batch [10/50] time 0.085 (0.142) data 0.000 (0.057) loss 0.5317 (0.8296) acc 87.5000 (78.1250) lr 1.3681e-03 eta 0:14:32
epoch [78/200] batch [15/50] time 0.085 (0.123) data 0.000 (0.038) loss 0.6772 (0.7479) acc 84.3750 (79.3750) lr 1.3681e-03 eta 0:12:35
epoch [78/200] batch [20/50] time 0.084 (0.113) data 0.000 (0.029) loss 0.8823 (0.7523) acc 75.0000 (79.6875) lr 1.3681e-03 eta 0:11:35
epoch [78/200] batch [25/50] time 0.085 (0.108) data 0.000 (0.023) loss 0.6841 (0.7472) acc 78.1250 (79.8750) lr 1.3681e-03 eta 0:10:59
epoch [78/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.6279 (0.7379) acc 75.0000 (79.5833) lr 1.3681e-03 eta 0:10:35
epoch [78/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.7710 (0.7545) acc 84.3750 (79.0179) lr 1.3681e-03 eta 0:10:18
epoch [78/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.8862 (0.7896) acc 68.7500 (78.3594) lr 1.3681e-03 eta 0:10:04
epoch [78/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8325 (0.8003) acc 75.0000 (77.7778) lr 1.3681e-03 eta 0:09:53
epoch [78/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.2334 (0.8088) acc 68.7500 (77.6875) lr 1.3535e-03 eta 0:09:44
epoch [79/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.101) loss 0.8262 (0.9903) acc 84.3750 (74.3750) lr 1.3535e-03 eta 0:18:56
epoch [79/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.051) loss 0.9663 (0.9000) acc 75.0000 (77.1875) lr 1.3535e-03 eta 0:13:44
epoch [79/200] batch [15/50] time 0.083 (0.118) data 0.000 (0.034) loss 0.6943 (0.8669) acc 81.2500 (77.7083) lr 1.3535e-03 eta 0:11:59
epoch [79/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.7769 (0.8227) acc 81.2500 (78.9062) lr 1.3535e-03 eta 0:11:06
epoch [79/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 1.1641 (0.8470) acc 62.5000 (77.8750) lr 1.3535e-03 eta 0:10:35
epoch [79/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.5928 (0.8505) acc 81.2500 (77.3958) lr 1.3535e-03 eta 0:10:14
epoch [79/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 1.4297 (0.8412) acc 65.6250 (77.7679) lr 1.3535e-03 eta 0:09:59
epoch [79/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.3088 (0.8234) acc 90.6250 (78.0469) lr 1.3535e-03 eta 0:09:46
epoch [79/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6230 (0.8154) acc 75.0000 (78.1250) lr 1.3535e-03 eta 0:09:37
epoch [79/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9556 (0.8107) acc 71.8750 (78.1875) lr 1.3387e-03 eta 0:09:29
epoch [80/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.106) loss 0.3997 (0.6893) acc 87.5000 (78.7500) lr 1.3387e-03 eta 0:19:18
epoch [80/200] batch [10/50] time 0.086 (0.138) data 0.000 (0.053) loss 0.5688 (0.6943) acc 87.5000 (80.6250) lr 1.3387e-03 eta 0:13:54
epoch [80/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.7661 (0.7338) acc 78.1250 (79.5833) lr 1.3387e-03 eta 0:12:06
epoch [80/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.9121 (0.7906) acc 75.0000 (77.8125) lr 1.3387e-03 eta 0:11:10
epoch [80/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 1.0107 (0.8002) acc 68.7500 (77.0000) lr 1.3387e-03 eta 0:10:37
epoch [80/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.7358 (0.7732) acc 78.1250 (77.6042) lr 1.3387e-03 eta 0:10:16
epoch [80/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.9863 (0.7957) acc 78.1250 (76.9643) lr 1.3387e-03 eta 0:09:59
epoch [80/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7241 (0.7871) acc 81.2500 (77.3438) lr 1.3387e-03 eta 0:09:47
epoch [80/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8374 (0.7878) acc 81.2500 (77.7778) lr 1.3387e-03 eta 0:09:37
epoch [80/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8350 (0.8057) acc 78.1250 (77.7500) lr 1.3239e-03 eta 0:09:29
epoch [81/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.097) loss 0.4607 (0.7448) acc 81.2500 (77.5000) lr 1.3239e-03 eta 0:18:16
epoch [81/200] batch [10/50] time 0.085 (0.134) data 0.001 (0.049) loss 0.8164 (0.7442) acc 75.0000 (80.3125) lr 1.3239e-03 eta 0:13:21
epoch [81/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.7690 (0.7870) acc 75.0000 (78.9583) lr 1.3239e-03 eta 0:11:42
epoch [81/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 1.1094 (0.8146) acc 71.8750 (78.1250) lr 1.3239e-03 eta 0:10:52
epoch [81/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.6748 (0.7849) acc 87.5000 (79.2500) lr 1.3239e-03 eta 0:10:22
epoch [81/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.7476 (0.7828) acc 78.1250 (79.1667) lr 1.3239e-03 eta 0:10:02
epoch [81/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.7104 (0.8010) acc 84.3750 (78.4821) lr 1.3239e-03 eta 0:09:48
epoch [81/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.3611 (0.7842) acc 87.5000 (79.0625) lr 1.3239e-03 eta 0:09:36
epoch [81/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7134 (0.7702) acc 78.1250 (79.3750) lr 1.3239e-03 eta 0:09:27
epoch [81/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7002 (0.7896) acc 87.5000 (78.8750) lr 1.3090e-03 eta 0:09:19
epoch [82/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.110) loss 0.5586 (0.7851) acc 84.3750 (80.6250) lr 1.3090e-03 eta 0:19:20
epoch [82/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.055) loss 0.5195 (0.7245) acc 84.3750 (80.9375) lr 1.3090e-03 eta 0:13:49
epoch [82/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 0.7710 (0.7295) acc 78.1250 (81.2500) lr 1.3090e-03 eta 0:11:59
epoch [82/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 1.3105 (0.8008) acc 68.7500 (79.6875) lr 1.3090e-03 eta 0:11:03
epoch [82/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.7300 (0.8029) acc 84.3750 (79.6250) lr 1.3090e-03 eta 0:10:29
epoch [82/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.5308 (0.7968) acc 90.6250 (79.6875) lr 1.3090e-03 eta 0:10:07
epoch [82/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6719 (0.7916) acc 75.0000 (79.3750) lr 1.3090e-03 eta 0:09:51
epoch [82/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.3779 (0.8123) acc 68.7500 (78.9062) lr 1.3090e-03 eta 0:09:38
epoch [82/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.013) loss 0.6626 (0.8057) acc 78.1250 (79.0278) lr 1.3090e-03 eta 0:09:28
epoch [82/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5728 (0.7969) acc 87.5000 (79.3750) lr 1.2940e-03 eta 0:09:20
epoch [83/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 0.7773 (0.8438) acc 81.2500 (76.2500) lr 1.2940e-03 eta 0:18:40
epoch [83/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.053) loss 1.3076 (1.0045) acc 65.6250 (73.1250) lr 1.2940e-03 eta 0:13:27
epoch [83/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.8154 (0.8815) acc 71.8750 (75.0000) lr 1.2940e-03 eta 0:11:44
epoch [83/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.4756 (0.8432) acc 93.7500 (76.7188) lr 1.2940e-03 eta 0:10:52
epoch [83/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.5664 (0.8304) acc 84.3750 (77.0000) lr 1.2940e-03 eta 0:10:20
epoch [83/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.1279 (0.8307) acc 68.7500 (76.5625) lr 1.2940e-03 eta 0:09:58
epoch [83/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.6992 (0.8063) acc 78.1250 (77.2321) lr 1.2940e-03 eta 0:09:42
epoch [83/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8784 (0.7851) acc 68.7500 (77.5781) lr 1.2940e-03 eta 0:09:30
epoch [83/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1836 (0.8016) acc 65.6250 (77.0139) lr 1.2940e-03 eta 0:09:20
epoch [83/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.8867 (0.7940) acc 78.1250 (77.5000) lr 1.2790e-03 eta 0:09:12
epoch [84/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.106) loss 0.7417 (0.8115) acc 78.1250 (76.8750) lr 1.2790e-03 eta 0:18:37
epoch [84/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.7656 (0.7881) acc 84.3750 (78.7500) lr 1.2790e-03 eta 0:13:24
epoch [84/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.8486 (0.8370) acc 81.2500 (77.5000) lr 1.2790e-03 eta 0:11:40
epoch [84/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.9102 (0.8468) acc 71.8750 (77.1875) lr 1.2790e-03 eta 0:10:48
epoch [84/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.9131 (0.8443) acc 71.8750 (76.8750) lr 1.2790e-03 eta 0:10:15
epoch [84/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.1387 (0.8473) acc 71.8750 (76.7708) lr 1.2790e-03 eta 0:09:54
epoch [84/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.6143 (0.8535) acc 84.3750 (76.3393) lr 1.2790e-03 eta 0:09:39
epoch [84/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.9912 (0.8576) acc 71.8750 (75.6250) lr 1.2790e-03 eta 0:09:26
epoch [84/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8003 (0.8520) acc 81.2500 (76.0417) lr 1.2790e-03 eta 0:09:17
epoch [84/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5430 (0.8497) acc 93.7500 (76.4375) lr 1.2639e-03 eta 0:09:09
epoch [85/200] batch [5/50] time 0.086 (0.183) data 0.000 (0.097) loss 0.3418 (0.5383) acc 93.7500 (88.7500) lr 1.2639e-03 eta 0:17:41
epoch [85/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 1.2812 (0.7161) acc 68.7500 (82.5000) lr 1.2639e-03 eta 0:12:57
epoch [85/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.4919 (0.7035) acc 87.5000 (80.6250) lr 1.2639e-03 eta 0:11:20
epoch [85/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.4233 (0.6588) acc 96.8750 (82.3438) lr 1.2639e-03 eta 0:10:31
epoch [85/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.8818 (0.7048) acc 81.2500 (80.8750) lr 1.2639e-03 eta 0:10:02
epoch [85/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.4038 (0.7198) acc 84.3750 (79.6875) lr 1.2639e-03 eta 0:09:42
epoch [85/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.4587 (0.7197) acc 87.5000 (79.7321) lr 1.2639e-03 eta 0:09:28
epoch [85/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0361 (0.7354) acc 71.8750 (79.6094) lr 1.2639e-03 eta 0:09:16
epoch [85/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.4014 (0.7589) acc 56.2500 (79.0972) lr 1.2639e-03 eta 0:09:07
epoch [85/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.0410 (0.7760) acc 68.7500 (78.5000) lr 1.2487e-03 eta 0:09:00
epoch [86/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.098) loss 0.8818 (0.8085) acc 78.1250 (80.6250) lr 1.2487e-03 eta 0:17:34
epoch [86/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.9556 (0.8542) acc 68.7500 (76.8750) lr 1.2487e-03 eta 0:12:48
epoch [86/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 0.7666 (0.8191) acc 75.0000 (76.2500) lr 1.2487e-03 eta 0:11:12
epoch [86/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.1348 (0.8140) acc 75.0000 (76.8750) lr 1.2487e-03 eta 0:10:24
epoch [86/200] batch [25/50] time 0.086 (0.104) data 0.000 (0.020) loss 0.4939 (0.8117) acc 90.6250 (77.3750) lr 1.2487e-03 eta 0:09:55
epoch [86/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.8799 (0.8304) acc 75.0000 (76.9792) lr 1.2487e-03 eta 0:09:36
epoch [86/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 1.0010 (0.8523) acc 68.7500 (76.5179) lr 1.2487e-03 eta 0:09:23
epoch [86/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.8501 (0.8550) acc 78.1250 (76.7188) lr 1.2487e-03 eta 0:09:12
epoch [86/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6655 (0.8667) acc 78.1250 (76.6667) lr 1.2487e-03 eta 0:09:03
epoch [86/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.4292 (0.8458) acc 87.5000 (77.2500) lr 1.2334e-03 eta 0:08:56
epoch [87/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.110) loss 0.7573 (0.6401) acc 81.2500 (81.8750) lr 1.2334e-03 eta 0:18:31
epoch [87/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.6182 (0.6729) acc 78.1250 (80.9375) lr 1.2334e-03 eta 0:13:17
epoch [87/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 1.2686 (0.7443) acc 68.7500 (80.4167) lr 1.2334e-03 eta 0:11:32
epoch [87/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.7358 (0.7661) acc 81.2500 (80.1562) lr 1.2334e-03 eta 0:10:38
epoch [87/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 1.0264 (0.7568) acc 81.2500 (79.8750) lr 1.2334e-03 eta 0:10:07
epoch [87/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.8970 (0.7918) acc 81.2500 (78.8542) lr 1.2334e-03 eta 0:09:45
epoch [87/200] batch [35/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.8872 (0.8105) acc 87.5000 (79.0179) lr 1.2334e-03 eta 0:09:30
epoch [87/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.6025 (0.8014) acc 81.2500 (78.5938) lr 1.2334e-03 eta 0:09:17
epoch [87/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.4038 (0.7986) acc 87.5000 (78.3333) lr 1.2334e-03 eta 0:09:07
epoch [87/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.011) loss 1.0225 (0.8058) acc 71.8750 (78.3750) lr 1.2181e-03 eta 0:09:00
epoch [88/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.095) loss 0.9170 (0.8131) acc 81.2500 (77.5000) lr 1.2181e-03 eta 0:17:00
epoch [88/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.6890 (0.7924) acc 84.3750 (78.7500) lr 1.2181e-03 eta 0:12:28
epoch [88/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.7842 (0.8101) acc 81.2500 (78.7500) lr 1.2181e-03 eta 0:10:56
epoch [88/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 1.4160 (0.8119) acc 65.6250 (78.7500) lr 1.2181e-03 eta 0:10:11
epoch [88/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.8535 (0.8209) acc 78.1250 (78.0000) lr 1.2181e-03 eta 0:09:43
epoch [88/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.5957 (0.8085) acc 81.2500 (78.2292) lr 1.2181e-03 eta 0:09:25
epoch [88/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7983 (0.7865) acc 78.1250 (78.7500) lr 1.2181e-03 eta 0:09:12
epoch [88/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.4226 (0.7832) acc 90.6250 (78.6719) lr 1.2181e-03 eta 0:09:01
epoch [88/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0635 (0.7996) acc 62.5000 (78.3333) lr 1.2181e-03 eta 0:08:53
epoch [88/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6812 (0.8155) acc 81.2500 (78.0625) lr 1.2028e-03 eta 0:08:46
epoch [89/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.097) loss 0.4365 (0.5986) acc 90.6250 (83.1250) lr 1.2028e-03 eta 0:17:04
epoch [89/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.048) loss 0.8481 (0.7163) acc 71.8750 (78.7500) lr 1.2028e-03 eta 0:12:29
epoch [89/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.032) loss 0.7183 (0.6938) acc 81.2500 (80.2083) lr 1.2028e-03 eta 0:10:56
epoch [89/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.6621 (0.7254) acc 68.7500 (79.0625) lr 1.2028e-03 eta 0:10:10
epoch [89/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.5278 (0.7511) acc 78.1250 (78.8750) lr 1.2028e-03 eta 0:09:42
epoch [89/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.7954 (0.7930) acc 71.8750 (77.7083) lr 1.2028e-03 eta 0:09:23
epoch [89/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 0.7661 (0.8065) acc 78.1250 (77.0536) lr 1.2028e-03 eta 0:09:09
epoch [89/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.4314 (0.8162) acc 87.5000 (76.8750) lr 1.2028e-03 eta 0:08:58
epoch [89/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6147 (0.8252) acc 87.5000 (76.5972) lr 1.2028e-03 eta 0:08:50
epoch [89/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6362 (0.8177) acc 78.1250 (77.0000) lr 1.1874e-03 eta 0:08:43
epoch [90/200] batch [5/50] time 0.083 (0.180) data 0.000 (0.095) loss 0.5049 (0.6645) acc 84.3750 (83.1250) lr 1.1874e-03 eta 0:16:36
epoch [90/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.5464 (0.7000) acc 87.5000 (81.5625) lr 1.1874e-03 eta 0:12:09
epoch [90/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.032) loss 0.6753 (0.7005) acc 78.1250 (81.4583) lr 1.1874e-03 eta 0:10:40
epoch [90/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.4299 (0.7121) acc 84.3750 (82.1875) lr 1.1874e-03 eta 0:09:56
epoch [90/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 1.1230 (0.7750) acc 68.7500 (80.2500) lr 1.1874e-03 eta 0:09:29
epoch [90/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 0.8506 (0.7659) acc 71.8750 (80.3125) lr 1.1874e-03 eta 0:09:11
epoch [90/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7725 (0.7529) acc 78.1250 (80.4464) lr 1.1874e-03 eta 0:08:58
epoch [90/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8857 (0.7687) acc 71.8750 (79.6875) lr 1.1874e-03 eta 0:08:48
epoch [90/200] batch [45/50] time 0.084 (0.094) data 0.000 (0.011) loss 0.7725 (0.7666) acc 84.3750 (79.6528) lr 1.1874e-03 eta 0:08:40
epoch [90/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.010) loss 0.9990 (0.7861) acc 75.0000 (79.1875) lr 1.1719e-03 eta 0:08:33
epoch [91/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.100) loss 1.0684 (0.8619) acc 71.8750 (74.3750) lr 1.1719e-03 eta 0:16:56
epoch [91/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.5264 (0.7356) acc 87.5000 (78.7500) lr 1.1719e-03 eta 0:12:19
epoch [91/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.1475 (0.8164) acc 68.7500 (77.0833) lr 1.1719e-03 eta 0:10:46
epoch [91/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.8545 (0.8182) acc 78.1250 (77.5000) lr 1.1719e-03 eta 0:10:00
epoch [91/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 1.0791 (0.8263) acc 71.8750 (76.8750) lr 1.1719e-03 eta 0:09:32
epoch [91/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.5020 (0.8340) acc 84.3750 (76.8750) lr 1.1719e-03 eta 0:09:13
epoch [91/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.3708 (0.8091) acc 90.6250 (77.8571) lr 1.1719e-03 eta 0:09:00
epoch [91/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.4380 (0.7834) acc 84.3750 (78.4375) lr 1.1719e-03 eta 0:08:49
epoch [91/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0449 (0.8055) acc 84.3750 (78.3333) lr 1.1719e-03 eta 0:08:40
epoch [91/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5415 (0.8135) acc 81.2500 (78.1875) lr 1.1564e-03 eta 0:08:34
epoch [92/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.8716 (0.8468) acc 75.0000 (78.1250) lr 1.1564e-03 eta 0:16:49
epoch [92/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 1.3047 (0.7485) acc 65.6250 (80.0000) lr 1.1564e-03 eta 0:12:14
epoch [92/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.8047 (0.7975) acc 78.1250 (77.9167) lr 1.1564e-03 eta 0:10:43
epoch [92/200] batch [20/50] time 0.086 (0.110) data 0.000 (0.025) loss 0.9868 (0.7727) acc 68.7500 (78.2812) lr 1.1564e-03 eta 0:09:57
epoch [92/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.9536 (0.7892) acc 68.7500 (77.6250) lr 1.1564e-03 eta 0:09:30
epoch [92/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.9224 (0.7812) acc 71.8750 (77.9167) lr 1.1564e-03 eta 0:09:11
epoch [92/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.9106 (0.8168) acc 81.2500 (77.5000) lr 1.1564e-03 eta 0:08:57
epoch [92/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8833 (0.8207) acc 75.0000 (77.2656) lr 1.1564e-03 eta 0:08:46
epoch [92/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 1.4248 (0.8080) acc 68.7500 (77.8472) lr 1.1564e-03 eta 0:08:37
epoch [92/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.6646 (0.7988) acc 81.2500 (78.1250) lr 1.1409e-03 eta 0:08:30
epoch [93/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 0.7188 (0.7532) acc 75.0000 (80.0000) lr 1.1409e-03 eta 0:16:49
epoch [93/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.3218 (0.7031) acc 93.7500 (81.8750) lr 1.1409e-03 eta 0:12:13
epoch [93/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.7490 (0.6933) acc 87.5000 (83.1250) lr 1.1409e-03 eta 0:10:40
epoch [93/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.6553 (0.7249) acc 87.5000 (82.6562) lr 1.1409e-03 eta 0:09:53
epoch [93/200] batch [25/50] time 0.086 (0.105) data 0.001 (0.021) loss 0.7124 (0.7164) acc 84.3750 (82.2500) lr 1.1409e-03 eta 0:09:26
epoch [93/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.8716 (0.7542) acc 75.0000 (80.9375) lr 1.1409e-03 eta 0:09:07
epoch [93/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.015) loss 0.5254 (0.7465) acc 87.5000 (80.8036) lr 1.1409e-03 eta 0:08:54
epoch [93/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.7188 (0.7340) acc 78.1250 (80.9375) lr 1.1409e-03 eta 0:08:42
epoch [93/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7178 (0.7371) acc 84.3750 (80.8333) lr 1.1409e-03 eta 0:08:34
epoch [93/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 1.1221 (0.7614) acc 71.8750 (80.3750) lr 1.1253e-03 eta 0:08:26
epoch [94/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 0.7266 (0.7273) acc 87.5000 (81.2500) lr 1.1253e-03 eta 0:16:23
epoch [94/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.050) loss 0.8818 (0.6907) acc 75.0000 (81.5625) lr 1.1253e-03 eta 0:11:56
epoch [94/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.8203 (0.7392) acc 78.1250 (79.1667) lr 1.1253e-03 eta 0:10:27
epoch [94/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.9385 (0.7330) acc 78.1250 (79.6875) lr 1.1253e-03 eta 0:09:42
epoch [94/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.6514 (0.7767) acc 81.2500 (78.2500) lr 1.1253e-03 eta 0:09:15
epoch [94/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.5283 (0.7787) acc 84.3750 (78.0208) lr 1.1253e-03 eta 0:08:57
epoch [94/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.014) loss 0.9800 (0.8066) acc 71.8750 (76.9643) lr 1.1253e-03 eta 0:08:43
epoch [94/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8828 (0.7772) acc 78.1250 (77.6562) lr 1.1253e-03 eta 0:08:33
epoch [94/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5518 (0.7682) acc 87.5000 (78.0556) lr 1.1253e-03 eta 0:08:25
epoch [94/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.5947 (0.7551) acc 87.5000 (78.5000) lr 1.1097e-03 eta 0:08:18
epoch [95/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 0.5376 (0.8373) acc 90.6250 (75.6250) lr 1.1097e-03 eta 0:16:12
epoch [95/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.8135 (0.7249) acc 75.0000 (80.6250) lr 1.1097e-03 eta 0:11:48
epoch [95/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 0.6880 (0.7381) acc 78.1250 (80.2083) lr 1.1097e-03 eta 0:10:19
epoch [95/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.7207 (0.7524) acc 84.3750 (79.8438) lr 1.1097e-03 eta 0:09:36
epoch [95/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.7915 (0.7760) acc 71.8750 (79.1250) lr 1.1097e-03 eta 0:09:09
epoch [95/200] batch [30/50] time 0.086 (0.101) data 0.000 (0.017) loss 0.6284 (0.7580) acc 84.3750 (79.0625) lr 1.1097e-03 eta 0:08:52
epoch [95/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.8857 (0.7691) acc 84.3750 (78.9286) lr 1.1097e-03 eta 0:08:40
epoch [95/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6309 (0.7704) acc 81.2500 (78.2812) lr 1.1097e-03 eta 0:08:29
epoch [95/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.3987 (0.7677) acc 87.5000 (78.5417) lr 1.1097e-03 eta 0:08:21
epoch [95/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5322 (0.7669) acc 84.3750 (78.5625) lr 1.0941e-03 eta 0:08:14
epoch [96/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.6938 (0.6482) acc 87.5000 (83.1250) lr 1.0941e-03 eta 0:16:08
epoch [96/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.8125 (0.8219) acc 84.3750 (79.6875) lr 1.0941e-03 eta 0:11:44
epoch [96/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.4211 (0.8344) acc 90.6250 (79.5833) lr 1.0941e-03 eta 0:10:16
epoch [96/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.6274 (0.8473) acc 81.2500 (78.2812) lr 1.0941e-03 eta 0:09:32
epoch [96/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.8154 (0.8460) acc 75.0000 (77.5000) lr 1.0941e-03 eta 0:09:06
epoch [96/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.5850 (0.8253) acc 87.5000 (78.4375) lr 1.0941e-03 eta 0:08:48
epoch [96/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.0967 (0.8390) acc 65.6250 (77.9464) lr 1.0941e-03 eta 0:08:35
epoch [96/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8867 (0.8420) acc 84.3750 (77.8906) lr 1.0941e-03 eta 0:08:25
epoch [96/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7739 (0.8280) acc 81.2500 (78.0556) lr 1.0941e-03 eta 0:08:16
epoch [96/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6812 (0.8325) acc 78.1250 (77.5000) lr 1.0785e-03 eta 0:08:10
epoch [97/200] batch [5/50] time 0.083 (0.194) data 0.000 (0.109) loss 0.8037 (0.6725) acc 78.1250 (80.0000) lr 1.0785e-03 eta 0:16:47
epoch [97/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.2502 (0.6888) acc 90.6250 (81.5625) lr 1.0785e-03 eta 0:12:04
epoch [97/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 0.8198 (0.6727) acc 68.7500 (82.0833) lr 1.0785e-03 eta 0:10:28
epoch [97/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.7432 (0.7130) acc 81.2500 (80.0000) lr 1.0785e-03 eta 0:09:40
epoch [97/200] batch [25/50] time 0.083 (0.106) data 0.000 (0.022) loss 0.8574 (0.7042) acc 78.1250 (80.5000) lr 1.0785e-03 eta 0:09:10
epoch [97/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.6348 (0.7007) acc 84.3750 (80.1042) lr 1.0785e-03 eta 0:08:50
epoch [97/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.9419 (0.7183) acc 78.1250 (79.7321) lr 1.0785e-03 eta 0:08:36
epoch [97/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7744 (0.7234) acc 78.1250 (79.4531) lr 1.0785e-03 eta 0:08:25
epoch [97/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8408 (0.7441) acc 71.8750 (79.3750) lr 1.0785e-03 eta 0:08:16
epoch [97/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7842 (0.7592) acc 78.1250 (79.0625) lr 1.0628e-03 eta 0:08:09
epoch [98/200] batch [5/50] time 0.084 (0.198) data 0.000 (0.114) loss 0.8677 (0.7700) acc 68.7500 (76.2500) lr 1.0628e-03 eta 0:17:00
epoch [98/200] batch [10/50] time 0.084 (0.142) data 0.000 (0.057) loss 0.8086 (0.7704) acc 81.2500 (78.7500) lr 1.0628e-03 eta 0:12:07
epoch [98/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.038) loss 0.6484 (0.7407) acc 78.1250 (79.1667) lr 1.0628e-03 eta 0:10:28
epoch [98/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.029) loss 0.6689 (0.7137) acc 75.0000 (79.6875) lr 1.0628e-03 eta 0:09:39
epoch [98/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.023) loss 0.6958 (0.7502) acc 81.2500 (78.8750) lr 1.0628e-03 eta 0:09:09
epoch [98/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 1.0713 (0.7568) acc 75.0000 (78.6458) lr 1.0628e-03 eta 0:08:49
epoch [98/200] batch [35/50] time 0.084 (0.101) data 0.001 (0.016) loss 0.7690 (0.7418) acc 84.3750 (80.0000) lr 1.0628e-03 eta 0:08:35
epoch [98/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.2744 (0.7456) acc 65.6250 (79.2969) lr 1.0628e-03 eta 0:08:24
epoch [98/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6396 (0.7640) acc 84.3750 (78.9583) lr 1.0628e-03 eta 0:08:15
epoch [98/200] batch [50/50] time 0.084 (0.096) data 0.001 (0.012) loss 0.4697 (0.7553) acc 84.3750 (79.3125) lr 1.0471e-03 eta 0:08:07
epoch [99/200] batch [5/50] time 0.085 (0.182) data 0.000 (0.096) loss 0.6782 (0.7341) acc 75.0000 (76.2500) lr 1.0471e-03 eta 0:15:29
epoch [99/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.9478 (0.8008) acc 75.0000 (76.5625) lr 1.0471e-03 eta 0:11:19
epoch [99/200] batch [15/50] time 0.086 (0.117) data 0.001 (0.032) loss 0.9922 (0.7721) acc 71.8750 (78.1250) lr 1.0471e-03 eta 0:09:56
epoch [99/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 1.0586 (0.7569) acc 71.8750 (78.9062) lr 1.0471e-03 eta 0:09:14
epoch [99/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.9395 (0.7832) acc 84.3750 (79.1250) lr 1.0471e-03 eta 0:08:49
epoch [99/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.9800 (0.7873) acc 78.1250 (78.7500) lr 1.0471e-03 eta 0:08:32
epoch [99/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.5815 (0.7645) acc 90.6250 (79.4643) lr 1.0471e-03 eta 0:08:20
epoch [99/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.5786 (0.7661) acc 81.2500 (79.1406) lr 1.0471e-03 eta 0:08:09
epoch [99/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5864 (0.7543) acc 84.3750 (79.4444) lr 1.0471e-03 eta 0:08:01
epoch [99/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0371 (0.7564) acc 68.7500 (79.3750) lr 1.0314e-03 eta 0:07:55
epoch [100/200] batch [5/50] time 0.086 (0.191) data 0.000 (0.106) loss 0.8862 (0.7266) acc 71.8750 (77.5000) lr 1.0314e-03 eta 0:16:05
epoch [100/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.6533 (0.7340) acc 78.1250 (78.1250) lr 1.0314e-03 eta 0:11:35
epoch [100/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.8486 (0.7398) acc 78.1250 (79.3750) lr 1.0314e-03 eta 0:10:05
epoch [100/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.7637 (0.7478) acc 78.1250 (79.8438) lr 1.0314e-03 eta 0:09:19
epoch [100/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 1.1221 (0.7648) acc 68.7500 (79.0000) lr 1.0314e-03 eta 0:08:52
epoch [100/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.9277 (0.7825) acc 81.2500 (78.8542) lr 1.0314e-03 eta 0:08:34
epoch [100/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.015) loss 0.8936 (0.7806) acc 75.0000 (79.1071) lr 1.0314e-03 eta 0:08:21
epoch [100/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.7959 (0.7831) acc 71.8750 (78.4375) lr 1.0314e-03 eta 0:08:10
epoch [100/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6309 (0.7742) acc 87.5000 (78.7500) lr 1.0314e-03 eta 0:08:01
epoch [100/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8608 (0.7746) acc 78.1250 (78.8125) lr 1.0157e-03 eta 0:07:54
epoch [101/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.108) loss 0.5972 (0.5897) acc 87.5000 (84.3750) lr 1.0157e-03 eta 0:16:05
epoch [101/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.6377 (0.6739) acc 78.1250 (81.2500) lr 1.0157e-03 eta 0:11:33
epoch [101/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.5527 (0.6606) acc 87.5000 (81.2500) lr 1.0157e-03 eta 0:10:02
epoch [101/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.4495 (0.6709) acc 90.6250 (81.0938) lr 1.0157e-03 eta 0:09:16
epoch [101/200] batch [25/50] time 0.085 (0.106) data 0.001 (0.022) loss 0.6646 (0.6866) acc 81.2500 (80.5000) lr 1.0157e-03 eta 0:08:49
epoch [101/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.6992 (0.6772) acc 84.3750 (80.8333) lr 1.0157e-03 eta 0:08:30
epoch [101/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.016) loss 0.4163 (0.6861) acc 90.6250 (80.6250) lr 1.0157e-03 eta 0:08:17
epoch [101/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6841 (0.6826) acc 84.3750 (80.6250) lr 1.0157e-03 eta 0:08:06
epoch [101/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.7832 (0.6936) acc 78.1250 (80.4167) lr 1.0157e-03 eta 0:07:58
epoch [101/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5835 (0.6882) acc 84.3750 (80.3125) lr 1.0000e-03 eta 0:07:51
epoch [102/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 0.6006 (0.7341) acc 81.2500 (81.2500) lr 1.0000e-03 eta 0:15:25
epoch [102/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.4546 (0.7559) acc 87.5000 (81.5625) lr 1.0000e-03 eta 0:11:11
epoch [102/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.8555 (0.7505) acc 68.7500 (80.6250) lr 1.0000e-03 eta 0:09:46
epoch [102/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.5918 (0.7722) acc 84.3750 (80.0000) lr 1.0000e-03 eta 0:09:03
epoch [102/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.6050 (0.7916) acc 84.3750 (80.0000) lr 1.0000e-03 eta 0:08:37
epoch [102/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.0732 (0.7862) acc 68.7500 (79.5833) lr 1.0000e-03 eta 0:08:20
epoch [102/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7114 (0.7699) acc 84.3750 (79.8214) lr 1.0000e-03 eta 0:08:07
epoch [102/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5850 (0.7483) acc 84.3750 (80.0781) lr 1.0000e-03 eta 0:07:57
epoch [102/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8286 (0.7609) acc 81.2500 (79.9306) lr 1.0000e-03 eta 0:07:49
epoch [102/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.5537 (0.7660) acc 84.3750 (79.8125) lr 9.8429e-04 eta 0:07:43
epoch [103/200] batch [5/50] time 0.083 (0.183) data 0.000 (0.098) loss 0.7168 (0.7205) acc 81.2500 (78.1250) lr 9.8429e-04 eta 0:14:56
epoch [103/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 1.0596 (0.7645) acc 71.8750 (78.1250) lr 9.8429e-04 eta 0:10:54
epoch [103/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 1.0117 (0.7846) acc 78.1250 (78.9583) lr 9.8429e-04 eta 0:09:32
epoch [103/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.4214 (0.7428) acc 87.5000 (80.1562) lr 9.8429e-04 eta 0:08:52
epoch [103/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.4358 (0.7622) acc 87.5000 (79.7500) lr 9.8429e-04 eta 0:08:27
epoch [103/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9814 (0.7649) acc 81.2500 (79.5833) lr 9.8429e-04 eta 0:08:10
epoch [103/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6978 (0.7716) acc 81.2500 (79.2857) lr 9.8429e-04 eta 0:07:58
epoch [103/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0293 (0.7815) acc 75.0000 (79.0625) lr 9.8429e-04 eta 0:07:49
epoch [103/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7573 (0.8047) acc 81.2500 (78.4722) lr 9.8429e-04 eta 0:07:41
epoch [103/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.1693 (0.7993) acc 100.0000 (78.5625) lr 9.6859e-04 eta 0:07:35
epoch [104/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.109) loss 0.6899 (0.6638) acc 84.3750 (80.6250) lr 9.6859e-04 eta 0:15:35
epoch [104/200] batch [10/50] time 0.083 (0.139) data 0.000 (0.054) loss 0.9814 (0.7612) acc 78.1250 (79.3750) lr 9.6859e-04 eta 0:11:11
epoch [104/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.6367 (0.7964) acc 87.5000 (79.7917) lr 9.6859e-04 eta 0:09:42
epoch [104/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.4915 (0.7700) acc 81.2500 (79.5312) lr 9.6859e-04 eta 0:08:57
epoch [104/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.5840 (0.7501) acc 87.5000 (79.8750) lr 9.6859e-04 eta 0:08:30
epoch [104/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.8066 (0.7636) acc 75.0000 (79.1667) lr 9.6859e-04 eta 0:08:12
epoch [104/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.3618 (0.7356) acc 87.5000 (79.9107) lr 9.6859e-04 eta 0:07:59
epoch [104/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8511 (0.7274) acc 81.2500 (80.3125) lr 9.6859e-04 eta 0:07:49
epoch [104/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8320 (0.7385) acc 71.8750 (80.0694) lr 9.6859e-04 eta 0:07:41
epoch [104/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5723 (0.7283) acc 87.5000 (80.3125) lr 9.5289e-04 eta 0:07:35
epoch [105/200] batch [5/50] time 0.085 (0.190) data 0.001 (0.105) loss 0.6943 (0.6979) acc 75.0000 (78.7500) lr 9.5289e-04 eta 0:15:13
epoch [105/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.053) loss 0.3804 (0.6963) acc 93.7500 (80.0000) lr 9.5289e-04 eta 0:10:58
epoch [105/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.5117 (0.6860) acc 84.3750 (80.8333) lr 9.5289e-04 eta 0:09:33
epoch [105/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.9736 (0.7133) acc 78.1250 (80.9375) lr 9.5289e-04 eta 0:08:51
epoch [105/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 1.1426 (0.7324) acc 68.7500 (80.7500) lr 9.5289e-04 eta 0:08:25
epoch [105/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.9604 (0.7372) acc 78.1250 (80.8333) lr 9.5289e-04 eta 0:08:07
epoch [105/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.015) loss 0.9834 (0.7382) acc 71.8750 (80.4464) lr 9.5289e-04 eta 0:07:55
epoch [105/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.5913 (0.7332) acc 78.1250 (80.3906) lr 9.5289e-04 eta 0:07:45
epoch [105/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0234 (0.7290) acc 75.0000 (80.7639) lr 9.5289e-04 eta 0:07:37
epoch [105/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4954 (0.7226) acc 87.5000 (81.1875) lr 9.3721e-04 eta 0:07:30
epoch [106/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.097) loss 0.6440 (0.5857) acc 84.3750 (83.7500) lr 9.3721e-04 eta 0:14:28
epoch [106/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.6265 (0.6686) acc 78.1250 (81.2500) lr 9.3721e-04 eta 0:10:33
epoch [106/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 1.0791 (0.7313) acc 71.8750 (78.7500) lr 9.3721e-04 eta 0:09:15
epoch [106/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 1.2412 (0.7377) acc 59.3750 (79.0625) lr 9.3721e-04 eta 0:08:36
epoch [106/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.8394 (0.7440) acc 71.8750 (79.1250) lr 9.3721e-04 eta 0:08:13
epoch [106/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.5156 (0.7273) acc 84.3750 (79.5833) lr 9.3721e-04 eta 0:07:57
epoch [106/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 1.1963 (0.7533) acc 65.6250 (79.2857) lr 9.3721e-04 eta 0:07:45
epoch [106/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.8608 (0.7625) acc 75.0000 (78.5938) lr 9.3721e-04 eta 0:07:36
epoch [106/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8101 (0.7726) acc 75.0000 (78.4028) lr 9.3721e-04 eta 0:07:28
epoch [106/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9580 (0.7726) acc 71.8750 (78.3750) lr 9.2154e-04 eta 0:07:23
epoch [107/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.103) loss 0.7656 (0.7088) acc 81.2500 (78.7500) lr 9.2154e-04 eta 0:14:44
epoch [107/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.4795 (0.7069) acc 90.6250 (81.5625) lr 9.2154e-04 eta 0:10:40
epoch [107/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.7969 (0.7063) acc 71.8750 (81.8750) lr 9.2154e-04 eta 0:09:18
epoch [107/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.3828 (0.7389) acc 68.7500 (81.2500) lr 9.2154e-04 eta 0:08:36
epoch [107/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.5488 (0.7427) acc 84.3750 (80.5000) lr 9.2154e-04 eta 0:08:12
epoch [107/200] batch [30/50] time 0.086 (0.102) data 0.000 (0.017) loss 0.9292 (0.7901) acc 75.0000 (79.1667) lr 9.2154e-04 eta 0:07:55
epoch [107/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.4973 (0.7529) acc 75.0000 (79.9107) lr 9.2154e-04 eta 0:07:43
epoch [107/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.2354 (0.7727) acc 65.6250 (78.9844) lr 9.2154e-04 eta 0:07:33
epoch [107/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.4463 (0.7962) acc 68.7500 (78.9583) lr 9.2154e-04 eta 0:07:26
epoch [107/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.3757 (0.7942) acc 87.5000 (78.8125) lr 9.0589e-04 eta 0:07:20
epoch [108/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.103) loss 0.8057 (0.7361) acc 71.8750 (78.7500) lr 9.0589e-04 eta 0:14:32
epoch [108/200] batch [10/50] time 0.083 (0.136) data 0.000 (0.052) loss 0.6870 (0.7871) acc 87.5000 (79.3750) lr 9.0589e-04 eta 0:10:31
epoch [108/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.4998 (0.7675) acc 90.6250 (79.7917) lr 9.0589e-04 eta 0:09:10
epoch [108/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.7778 (0.8313) acc 78.1250 (78.1250) lr 9.0589e-04 eta 0:08:29
epoch [108/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.1260 (0.8388) acc 62.5000 (77.3750) lr 9.0589e-04 eta 0:08:05
epoch [108/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.8203 (0.8266) acc 78.1250 (78.1250) lr 9.0589e-04 eta 0:07:49
epoch [108/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.8047 (0.8063) acc 71.8750 (78.3929) lr 9.0589e-04 eta 0:07:37
epoch [108/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.4216 (0.8024) acc 87.5000 (78.3594) lr 9.0589e-04 eta 0:07:28
epoch [108/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8696 (0.8032) acc 75.0000 (78.1250) lr 9.0589e-04 eta 0:07:20
epoch [108/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.9209 (0.8078) acc 68.7500 (78.0625) lr 8.9027e-04 eta 0:07:14
epoch [109/200] batch [5/50] time 0.083 (0.193) data 0.000 (0.108) loss 0.4788 (0.6175) acc 81.2500 (85.6250) lr 8.9027e-04 eta 0:14:45
epoch [109/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.4993 (0.6289) acc 90.6250 (83.7500) lr 8.9027e-04 eta 0:10:38
epoch [109/200] batch [15/50] time 0.083 (0.121) data 0.000 (0.036) loss 0.4297 (0.6678) acc 81.2500 (82.5000) lr 8.9027e-04 eta 0:09:12
epoch [109/200] batch [20/50] time 0.083 (0.112) data 0.000 (0.027) loss 0.8481 (0.7240) acc 71.8750 (80.7812) lr 8.9027e-04 eta 0:08:30
epoch [109/200] batch [25/50] time 0.086 (0.106) data 0.000 (0.022) loss 1.0596 (0.7374) acc 65.6250 (80.3750) lr 8.9027e-04 eta 0:08:05
epoch [109/200] batch [30/50] time 0.083 (0.102) data 0.000 (0.018) loss 0.6494 (0.7580) acc 81.2500 (79.6875) lr 8.9027e-04 eta 0:07:47
epoch [109/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.016) loss 0.6152 (0.7373) acc 84.3750 (80.7143) lr 8.9027e-04 eta 0:07:35
epoch [109/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.8452 (0.7553) acc 78.1250 (80.4688) lr 8.9027e-04 eta 0:07:25
epoch [109/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9326 (0.7655) acc 75.0000 (80.1389) lr 8.9027e-04 eta 0:07:17
epoch [109/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.3989 (0.7665) acc 90.6250 (80.3125) lr 8.7467e-04 eta 0:07:11
epoch [110/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.6992 (0.7493) acc 75.0000 (82.5000) lr 8.7467e-04 eta 0:13:59
epoch [110/200] batch [10/50] time 0.083 (0.134) data 0.000 (0.050) loss 0.4817 (0.7458) acc 87.5000 (81.8750) lr 8.7467e-04 eta 0:10:10
epoch [110/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 1.0762 (0.7725) acc 71.8750 (81.0417) lr 8.7467e-04 eta 0:08:54
epoch [110/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.7954 (0.7794) acc 78.1250 (80.6250) lr 8.7467e-04 eta 0:08:15
epoch [110/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 1.1123 (0.7870) acc 68.7500 (80.2500) lr 8.7467e-04 eta 0:07:52
epoch [110/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8506 (0.7663) acc 75.0000 (80.2083) lr 8.7467e-04 eta 0:07:37
epoch [110/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.4299 (0.7524) acc 90.6250 (80.2679) lr 8.7467e-04 eta 0:07:25
epoch [110/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0977 (0.7546) acc 62.5000 (79.9219) lr 8.7467e-04 eta 0:07:16
epoch [110/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.2275 (0.7574) acc 75.0000 (80.0000) lr 8.7467e-04 eta 0:07:09
epoch [110/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6108 (0.7571) acc 81.2500 (79.8125) lr 8.5910e-04 eta 0:07:04
epoch [111/200] batch [5/50] time 0.085 (0.197) data 0.000 (0.111) loss 0.6567 (0.6067) acc 84.3750 (83.7500) lr 8.5910e-04 eta 0:14:45
epoch [111/200] batch [10/50] time 0.086 (0.141) data 0.000 (0.056) loss 1.0088 (0.7168) acc 71.8750 (80.3125) lr 8.5910e-04 eta 0:10:34
epoch [111/200] batch [15/50] time 0.086 (0.123) data 0.001 (0.037) loss 0.9307 (0.7480) acc 75.0000 (80.8333) lr 8.5910e-04 eta 0:09:10
epoch [111/200] batch [20/50] time 0.085 (0.114) data 0.000 (0.028) loss 0.8682 (0.7584) acc 75.0000 (80.1562) lr 8.5910e-04 eta 0:08:28
epoch [111/200] batch [25/50] time 0.086 (0.108) data 0.000 (0.023) loss 0.6157 (0.7325) acc 90.6250 (80.5000) lr 8.5910e-04 eta 0:08:02
epoch [111/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 1.3447 (0.7362) acc 62.5000 (80.4167) lr 8.5910e-04 eta 0:07:45
epoch [111/200] batch [35/50] time 0.085 (0.101) data 0.001 (0.016) loss 0.4297 (0.7410) acc 87.5000 (80.4464) lr 8.5910e-04 eta 0:07:32
epoch [111/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.0039 (0.7643) acc 84.3750 (79.9219) lr 8.5910e-04 eta 0:07:22
epoch [111/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.1289 (0.7763) acc 71.8750 (79.7222) lr 8.5910e-04 eta 0:07:14
epoch [111/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.6318 (0.7744) acc 81.2500 (79.5000) lr 8.4357e-04 eta 0:07:07
epoch [112/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.098) loss 0.5234 (0.7877) acc 87.5000 (78.1250) lr 8.4357e-04 eta 0:13:38
epoch [112/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 0.7168 (0.7143) acc 75.0000 (79.6875) lr 8.4357e-04 eta 0:09:55
epoch [112/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 1.2139 (0.7230) acc 62.5000 (79.1667) lr 8.4357e-04 eta 0:08:41
epoch [112/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.7285 (0.7260) acc 87.5000 (80.0000) lr 8.4357e-04 eta 0:08:04
epoch [112/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.5640 (0.7163) acc 84.3750 (80.2500) lr 8.4357e-04 eta 0:07:42
epoch [112/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8721 (0.7579) acc 78.1250 (79.2708) lr 8.4357e-04 eta 0:07:26
epoch [112/200] batch [35/50] time 0.086 (0.099) data 0.001 (0.014) loss 0.8301 (0.7558) acc 84.3750 (79.3750) lr 8.4357e-04 eta 0:07:16
epoch [112/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.8521 (0.7536) acc 84.3750 (79.6875) lr 8.4357e-04 eta 0:07:07
epoch [112/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.1650 (0.7609) acc 68.7500 (79.5139) lr 8.4357e-04 eta 0:07:00
epoch [112/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6890 (0.7660) acc 78.1250 (79.6875) lr 8.2807e-04 eta 0:06:54
epoch [113/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.106) loss 0.6465 (0.5438) acc 87.5000 (86.2500) lr 8.2807e-04 eta 0:13:56
epoch [113/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.8506 (0.6272) acc 75.0000 (82.8125) lr 8.2807e-04 eta 0:10:05
epoch [113/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.4526 (0.6048) acc 84.3750 (83.7500) lr 8.2807e-04 eta 0:08:46
epoch [113/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.9624 (0.6326) acc 75.0000 (83.1250) lr 8.2807e-04 eta 0:08:07
epoch [113/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.7700 (0.6513) acc 81.2500 (82.2500) lr 8.2807e-04 eta 0:07:43
epoch [113/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6650 (0.6696) acc 84.3750 (81.6667) lr 8.2807e-04 eta 0:07:28
epoch [113/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.9844 (0.6706) acc 62.5000 (81.5179) lr 8.2807e-04 eta 0:07:16
epoch [113/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.4810 (0.6920) acc 90.6250 (81.2500) lr 8.2807e-04 eta 0:07:07
epoch [113/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8652 (0.6913) acc 78.1250 (81.3889) lr 8.2807e-04 eta 0:06:59
epoch [113/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.4766 (0.7059) acc 56.2500 (81.0000) lr 8.1262e-04 eta 0:06:53
epoch [114/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.100) loss 0.5049 (0.9835) acc 84.3750 (74.3750) lr 8.1262e-04 eta 0:13:25
epoch [114/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.4138 (0.8963) acc 78.1250 (77.5000) lr 8.1262e-04 eta 0:09:45
epoch [114/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.5020 (0.8381) acc 84.3750 (78.5417) lr 8.1262e-04 eta 0:08:31
epoch [114/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.025) loss 0.7495 (0.8255) acc 71.8750 (78.4375) lr 8.1262e-04 eta 0:07:54
epoch [114/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.5259 (0.8099) acc 81.2500 (78.8750) lr 8.1262e-04 eta 0:07:31
epoch [114/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.4875 (0.7828) acc 84.3750 (79.0625) lr 8.1262e-04 eta 0:07:16
epoch [114/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.014) loss 0.8574 (0.7962) acc 68.7500 (78.5714) lr 8.1262e-04 eta 0:07:05
epoch [114/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9653 (0.8094) acc 71.8750 (78.1250) lr 8.1262e-04 eta 0:06:56
epoch [114/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6128 (0.7966) acc 78.1250 (77.9861) lr 8.1262e-04 eta 0:06:49
epoch [114/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.0225 (0.8041) acc 71.8750 (77.8125) lr 7.9721e-04 eta 0:06:44
epoch [115/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.098) loss 0.7329 (0.6357) acc 78.1250 (81.2500) lr 7.9721e-04 eta 0:13:11
epoch [115/200] batch [10/50] time 0.083 (0.134) data 0.000 (0.049) loss 1.0391 (0.6247) acc 75.0000 (81.8750) lr 7.9721e-04 eta 0:09:34
epoch [115/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.2715 (0.6528) acc 96.8750 (82.2917) lr 7.9721e-04 eta 0:08:23
epoch [115/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.5757 (0.6619) acc 78.1250 (81.7188) lr 7.9721e-04 eta 0:07:47
epoch [115/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.8291 (0.6774) acc 75.0000 (81.2500) lr 7.9721e-04 eta 0:07:25
epoch [115/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.3530 (0.6935) acc 84.3750 (80.5208) lr 7.9721e-04 eta 0:07:11
epoch [115/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 1.1650 (0.7134) acc 68.7500 (79.8214) lr 7.9721e-04 eta 0:07:01
epoch [115/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5234 (0.7221) acc 84.3750 (80.0781) lr 7.9721e-04 eta 0:06:52
epoch [115/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1621 (0.7390) acc 68.7500 (79.5833) lr 7.9721e-04 eta 0:06:45
epoch [115/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8350 (0.7393) acc 78.1250 (79.6250) lr 7.8186e-04 eta 0:06:40
epoch [116/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.107) loss 0.7026 (0.7251) acc 81.2500 (82.5000) lr 7.8186e-04 eta 0:13:37
epoch [116/200] batch [10/50] time 0.086 (0.139) data 0.000 (0.054) loss 0.6313 (0.7586) acc 81.2500 (79.0625) lr 7.8186e-04 eta 0:09:48
epoch [116/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.7183 (0.7559) acc 81.2500 (78.9583) lr 7.8186e-04 eta 0:08:32
epoch [116/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.6904 (0.7851) acc 75.0000 (77.6562) lr 7.8186e-04 eta 0:07:53
epoch [116/200] batch [25/50] time 0.086 (0.107) data 0.000 (0.022) loss 0.7749 (0.7562) acc 81.2500 (78.7500) lr 7.8186e-04 eta 0:07:30
epoch [116/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 1.0527 (0.7545) acc 71.8750 (78.7500) lr 7.8186e-04 eta 0:07:14
epoch [116/200] batch [35/50] time 0.085 (0.101) data 0.001 (0.016) loss 0.5498 (0.7573) acc 90.6250 (79.3750) lr 7.8186e-04 eta 0:07:03
epoch [116/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5024 (0.7444) acc 90.6250 (79.6875) lr 7.8186e-04 eta 0:06:54
epoch [116/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0830 (0.7421) acc 68.7500 (79.5833) lr 7.8186e-04 eta 0:06:46
epoch [116/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6782 (0.7374) acc 78.1250 (79.6250) lr 7.6655e-04 eta 0:06:40
epoch [117/200] batch [5/50] time 0.086 (0.199) data 0.001 (0.114) loss 0.5376 (0.7665) acc 81.2500 (75.6250) lr 7.6655e-04 eta 0:13:53
epoch [117/200] batch [10/50] time 0.084 (0.142) data 0.000 (0.057) loss 1.0479 (0.7462) acc 71.8750 (78.1250) lr 7.6655e-04 eta 0:09:53
epoch [117/200] batch [15/50] time 0.085 (0.123) data 0.000 (0.038) loss 0.9136 (0.7112) acc 78.1250 (79.7917) lr 7.6655e-04 eta 0:08:33
epoch [117/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.029) loss 0.8174 (0.7317) acc 68.7500 (79.3750) lr 7.6655e-04 eta 0:07:53
epoch [117/200] batch [25/50] time 0.085 (0.108) data 0.000 (0.023) loss 0.9341 (0.7426) acc 71.8750 (79.1250) lr 7.6655e-04 eta 0:07:28
epoch [117/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.8882 (0.7560) acc 68.7500 (79.0625) lr 7.6655e-04 eta 0:07:12
epoch [117/200] batch [35/50] time 0.085 (0.101) data 0.001 (0.016) loss 0.2908 (0.7410) acc 96.8750 (79.9107) lr 7.6655e-04 eta 0:07:00
epoch [117/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.014) loss 0.8989 (0.7416) acc 78.1250 (80.0000) lr 7.6655e-04 eta 0:06:51
epoch [117/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.0127 (0.7536) acc 68.7500 (79.3750) lr 7.6655e-04 eta 0:06:43
epoch [117/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5864 (0.7588) acc 84.3750 (79.2500) lr 7.5131e-04 eta 0:06:37
epoch [118/200] batch [5/50] time 0.084 (0.196) data 0.000 (0.112) loss 0.5679 (0.7815) acc 84.3750 (81.8750) lr 7.5131e-04 eta 0:13:34
epoch [118/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.056) loss 0.4280 (0.7390) acc 87.5000 (82.5000) lr 7.5131e-04 eta 0:09:41
epoch [118/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 0.8198 (0.7562) acc 78.1250 (81.4583) lr 7.5131e-04 eta 0:08:22
epoch [118/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.8521 (0.7469) acc 81.2500 (81.5625) lr 7.5131e-04 eta 0:07:43
epoch [118/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.023) loss 0.8208 (0.7440) acc 81.2500 (81.1250) lr 7.5131e-04 eta 0:07:20
epoch [118/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.8457 (0.7386) acc 78.1250 (80.8333) lr 7.5131e-04 eta 0:07:04
epoch [118/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.9458 (0.7471) acc 71.8750 (80.4464) lr 7.5131e-04 eta 0:06:52
epoch [118/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9971 (0.7461) acc 68.7500 (80.2344) lr 7.5131e-04 eta 0:06:43
epoch [118/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8677 (0.7408) acc 75.0000 (80.4861) lr 7.5131e-04 eta 0:06:36
epoch [118/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8467 (0.7364) acc 78.1250 (80.7500) lr 7.3613e-04 eta 0:06:30
epoch [119/200] batch [5/50] time 0.084 (0.196) data 0.000 (0.111) loss 0.7065 (0.7707) acc 81.2500 (79.3750) lr 7.3613e-04 eta 0:13:22
epoch [119/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.056) loss 0.6602 (0.7605) acc 87.5000 (79.6875) lr 7.3613e-04 eta 0:09:34
epoch [119/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 0.7192 (0.7516) acc 84.3750 (80.0000) lr 7.3613e-04 eta 0:08:17
epoch [119/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.4141 (0.7354) acc 90.6250 (81.2500) lr 7.3613e-04 eta 0:07:38
epoch [119/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 0.8975 (0.7185) acc 78.1250 (81.7500) lr 7.3613e-04 eta 0:07:15
epoch [119/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.4844 (0.7137) acc 93.7500 (82.1875) lr 7.3613e-04 eta 0:06:59
epoch [119/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.8506 (0.7393) acc 78.1250 (81.6071) lr 7.3613e-04 eta 0:06:48
epoch [119/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.4490 (0.7037) acc 93.7500 (82.2656) lr 7.3613e-04 eta 0:06:39
epoch [119/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.5317 (0.7031) acc 90.6250 (82.1528) lr 7.3613e-04 eta 0:06:32
epoch [119/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7666 (0.7077) acc 81.2500 (82.0625) lr 7.2101e-04 eta 0:06:26
epoch [120/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.098) loss 0.7759 (0.6048) acc 81.2500 (85.0000) lr 7.2101e-04 eta 0:12:24
epoch [120/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 1.2246 (0.7271) acc 59.3750 (79.0625) lr 7.2101e-04 eta 0:09:02
epoch [120/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.5068 (0.7110) acc 84.3750 (80.0000) lr 7.2101e-04 eta 0:07:55
epoch [120/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.4832 (0.7203) acc 87.5000 (79.8438) lr 7.2101e-04 eta 0:07:21
epoch [120/200] batch [25/50] time 0.086 (0.105) data 0.000 (0.020) loss 0.8950 (0.7330) acc 84.3750 (79.7500) lr 7.2101e-04 eta 0:07:00
epoch [120/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9302 (0.7563) acc 75.0000 (78.7500) lr 7.2101e-04 eta 0:06:46
epoch [120/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.9438 (0.7561) acc 81.2500 (79.0179) lr 7.2101e-04 eta 0:06:36
epoch [120/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.8472 (0.7512) acc 78.1250 (79.3750) lr 7.2101e-04 eta 0:06:28
epoch [120/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7266 (0.7609) acc 78.1250 (78.8194) lr 7.2101e-04 eta 0:06:22
epoch [120/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7437 (0.7599) acc 84.3750 (78.8125) lr 7.0596e-04 eta 0:06:17
epoch [121/200] batch [5/50] time 0.084 (0.196) data 0.000 (0.112) loss 0.4980 (0.4394) acc 78.1250 (87.5000) lr 7.0596e-04 eta 0:13:04
epoch [121/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.056) loss 0.6074 (0.5771) acc 81.2500 (84.0625) lr 7.0596e-04 eta 0:09:19
epoch [121/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.037) loss 0.5122 (0.6237) acc 87.5000 (83.1250) lr 7.0596e-04 eta 0:08:04
epoch [121/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.9634 (0.6011) acc 81.2500 (83.9062) lr 7.0596e-04 eta 0:07:26
epoch [121/200] batch [25/50] time 0.084 (0.107) data 0.001 (0.023) loss 0.7158 (0.6491) acc 87.5000 (82.5000) lr 7.0596e-04 eta 0:07:03
epoch [121/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.6479 (0.6457) acc 84.3750 (82.6042) lr 7.0596e-04 eta 0:06:47
epoch [121/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.1504 (0.6577) acc 75.0000 (82.5893) lr 7.0596e-04 eta 0:06:36
epoch [121/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.0781 (0.6545) acc 75.0000 (82.5781) lr 7.0596e-04 eta 0:06:27
epoch [121/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.013) loss 0.5762 (0.6651) acc 87.5000 (82.2222) lr 7.0596e-04 eta 0:06:21
epoch [121/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9443 (0.6842) acc 78.1250 (81.4375) lr 6.9098e-04 eta 0:06:15
epoch [122/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.104) loss 0.8853 (0.7092) acc 75.0000 (81.8750) lr 6.9098e-04 eta 0:12:26
epoch [122/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.5210 (0.7312) acc 90.6250 (80.6250) lr 6.9098e-04 eta 0:08:58
epoch [122/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.7422 (0.7583) acc 78.1250 (79.3750) lr 6.9098e-04 eta 0:07:48
epoch [122/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.026) loss 0.5420 (0.7130) acc 87.5000 (80.9375) lr 6.9098e-04 eta 0:07:13
epoch [122/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.7661 (0.7220) acc 81.2500 (80.7500) lr 6.9098e-04 eta 0:06:51
epoch [122/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.018) loss 0.6719 (0.7145) acc 87.5000 (81.0417) lr 6.9098e-04 eta 0:06:37
epoch [122/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.5435 (0.6936) acc 75.0000 (81.1607) lr 6.9098e-04 eta 0:06:27
epoch [122/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9761 (0.7065) acc 75.0000 (80.6250) lr 6.9098e-04 eta 0:06:18
epoch [122/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.6401 (0.7163) acc 84.3750 (80.4167) lr 6.9098e-04 eta 0:06:12
epoch [122/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.1309 (0.7321) acc 68.7500 (80.0000) lr 6.7608e-04 eta 0:06:07
epoch [123/200] batch [5/50] time 0.086 (0.197) data 0.000 (0.111) loss 0.2832 (0.7718) acc 90.6250 (81.8750) lr 6.7608e-04 eta 0:12:45
epoch [123/200] batch [10/50] time 0.086 (0.141) data 0.000 (0.056) loss 0.4263 (0.7487) acc 87.5000 (81.8750) lr 6.7608e-04 eta 0:09:07
epoch [123/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.037) loss 0.5088 (0.7674) acc 84.3750 (80.2083) lr 6.7608e-04 eta 0:07:53
epoch [123/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.028) loss 0.7266 (0.7143) acc 81.2500 (81.5625) lr 6.7608e-04 eta 0:07:17
epoch [123/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 1.1240 (0.7342) acc 75.0000 (81.6250) lr 6.7608e-04 eta 0:06:55
epoch [123/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.8687 (0.7472) acc 81.2500 (81.0417) lr 6.7608e-04 eta 0:06:40
epoch [123/200] batch [35/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.7383 (0.7498) acc 84.3750 (80.8036) lr 6.7608e-04 eta 0:06:29
epoch [123/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.1406 (0.7617) acc 68.7500 (80.4688) lr 6.7608e-04 eta 0:06:21
epoch [123/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.4607 (0.7453) acc 84.3750 (80.6944) lr 6.7608e-04 eta 0:06:14
epoch [123/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.9204 (0.7434) acc 81.2500 (80.7500) lr 6.6126e-04 eta 0:06:08
epoch [124/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.099) loss 0.9746 (0.7978) acc 68.7500 (79.3750) lr 6.6126e-04 eta 0:11:47
epoch [124/200] batch [10/50] time 0.083 (0.134) data 0.000 (0.049) loss 0.5273 (0.7195) acc 87.5000 (80.9375) lr 6.6126e-04 eta 0:08:35
epoch [124/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.5928 (0.7021) acc 81.2500 (82.0833) lr 6.6126e-04 eta 0:07:31
epoch [124/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.9141 (0.6976) acc 84.3750 (81.2500) lr 6.6126e-04 eta 0:06:58
epoch [124/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.9810 (0.7220) acc 75.0000 (80.7500) lr 6.6126e-04 eta 0:06:39
epoch [124/200] batch [30/50] time 0.087 (0.101) data 0.000 (0.017) loss 1.2256 (0.7456) acc 71.8750 (80.1042) lr 6.6126e-04 eta 0:06:26
epoch [124/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.014) loss 0.6357 (0.7486) acc 84.3750 (80.0893) lr 6.6126e-04 eta 0:06:16
epoch [124/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.1055 (0.7320) acc 71.8750 (80.3906) lr 6.6126e-04 eta 0:06:08
epoch [124/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5806 (0.7508) acc 84.3750 (80.2083) lr 6.6126e-04 eta 0:06:02
epoch [124/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0068 (0.7456) acc 68.7500 (79.8750) lr 6.4653e-04 eta 0:05:57
epoch [125/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.101) loss 0.6108 (0.8205) acc 84.3750 (76.2500) lr 6.4653e-04 eta 0:11:50
epoch [125/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.051) loss 0.9570 (0.7929) acc 75.0000 (79.0625) lr 6.4653e-04 eta 0:08:37
epoch [125/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.8037 (0.7844) acc 84.3750 (79.5833) lr 6.4653e-04 eta 0:07:31
epoch [125/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.025) loss 0.8574 (0.7443) acc 68.7500 (80.1562) lr 6.4653e-04 eta 0:06:57
epoch [125/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.5142 (0.7200) acc 81.2500 (80.7500) lr 6.4653e-04 eta 0:06:37
epoch [125/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.3176 (0.6945) acc 93.7500 (81.4583) lr 6.4653e-04 eta 0:06:24
epoch [125/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.8740 (0.6816) acc 81.2500 (81.6071) lr 6.4653e-04 eta 0:06:14
epoch [125/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7158 (0.6963) acc 84.3750 (81.2500) lr 6.4653e-04 eta 0:06:06
epoch [125/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.6924 (0.7033) acc 84.3750 (81.4583) lr 6.4653e-04 eta 0:06:00
epoch [125/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 0.7725 (0.7095) acc 81.2500 (81.1250) lr 6.3188e-04 eta 0:05:54
epoch [126/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.097) loss 0.7920 (0.7402) acc 81.2500 (79.3750) lr 6.3188e-04 eta 0:11:24
epoch [126/200] batch [10/50] time 0.091 (0.134) data 0.001 (0.049) loss 0.9980 (0.7425) acc 78.1250 (81.2500) lr 6.3188e-04 eta 0:08:21
epoch [126/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 0.5176 (0.7363) acc 87.5000 (81.0417) lr 6.3188e-04 eta 0:07:17
epoch [126/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.6787 (0.7071) acc 78.1250 (81.0938) lr 6.3188e-04 eta 0:06:46
epoch [126/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.7856 (0.7424) acc 75.0000 (79.5000) lr 6.3188e-04 eta 0:06:27
epoch [126/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.6543 (0.7545) acc 78.1250 (78.6458) lr 6.3188e-04 eta 0:06:14
epoch [126/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8276 (0.7492) acc 68.7500 (78.5714) lr 6.3188e-04 eta 0:06:05
epoch [126/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.8091 (0.7468) acc 71.8750 (78.1250) lr 6.3188e-04 eta 0:05:58
epoch [126/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6572 (0.7433) acc 84.3750 (78.1944) lr 6.3188e-04 eta 0:05:52
epoch [126/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6904 (0.7442) acc 84.3750 (78.8125) lr 6.1732e-04 eta 0:05:47
epoch [127/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.109) loss 0.7534 (0.6817) acc 78.1250 (81.8750) lr 6.1732e-04 eta 0:11:58
epoch [127/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.5571 (0.6613) acc 81.2500 (82.8125) lr 6.1732e-04 eta 0:08:35
epoch [127/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 0.7412 (0.6723) acc 84.3750 (82.0833) lr 6.1732e-04 eta 0:07:27
epoch [127/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 1.0537 (0.6911) acc 78.1250 (81.8750) lr 6.1732e-04 eta 0:06:52
epoch [127/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.5464 (0.6947) acc 87.5000 (81.8750) lr 6.1732e-04 eta 0:06:32
epoch [127/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6294 (0.6837) acc 78.1250 (81.6667) lr 6.1732e-04 eta 0:06:18
epoch [127/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.7241 (0.6994) acc 84.3750 (81.6071) lr 6.1732e-04 eta 0:06:08
epoch [127/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9497 (0.7247) acc 75.0000 (81.0156) lr 6.1732e-04 eta 0:06:00
epoch [127/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.8467 (0.7368) acc 71.8750 (80.4861) lr 6.1732e-04 eta 0:05:53
epoch [127/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6572 (0.7394) acc 81.2500 (80.6250) lr 6.0285e-04 eta 0:05:48
epoch [128/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.100) loss 1.0098 (0.7113) acc 71.8750 (81.2500) lr 6.0285e-04 eta 0:11:11
epoch [128/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.050) loss 0.7681 (0.8086) acc 78.1250 (77.5000) lr 6.0285e-04 eta 0:08:08
epoch [128/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 1.1201 (0.7918) acc 75.0000 (78.1250) lr 6.0285e-04 eta 0:07:06
epoch [128/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 0.5991 (0.7705) acc 90.6250 (78.5938) lr 6.0285e-04 eta 0:06:35
epoch [128/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.5454 (0.7568) acc 78.1250 (78.8750) lr 6.0285e-04 eta 0:06:16
epoch [128/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8213 (0.7364) acc 78.1250 (79.6875) lr 6.0285e-04 eta 0:06:03
epoch [128/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.9985 (0.7494) acc 68.7500 (79.0179) lr 6.0285e-04 eta 0:05:54
epoch [128/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 0.5439 (0.7263) acc 81.2500 (79.6094) lr 6.0285e-04 eta 0:05:47
epoch [128/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6123 (0.7333) acc 81.2500 (79.9306) lr 6.0285e-04 eta 0:05:41
epoch [128/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7881 (0.7222) acc 71.8750 (80.0625) lr 5.8849e-04 eta 0:05:37
epoch [129/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 0.8325 (0.7912) acc 68.7500 (78.1250) lr 5.8849e-04 eta 0:11:20
epoch [129/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 0.4573 (0.6890) acc 87.5000 (81.2500) lr 5.8849e-04 eta 0:08:12
epoch [129/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.9629 (0.7889) acc 78.1250 (80.4167) lr 5.8849e-04 eta 0:07:09
epoch [129/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.7109 (0.7474) acc 78.1250 (80.4688) lr 5.8849e-04 eta 0:06:37
epoch [129/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.9141 (0.7187) acc 71.8750 (80.3750) lr 5.8849e-04 eta 0:06:18
epoch [129/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 1.5586 (0.7493) acc 65.6250 (79.7917) lr 5.8849e-04 eta 0:06:05
epoch [129/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.7256 (0.7449) acc 75.0000 (79.7321) lr 5.8849e-04 eta 0:05:55
epoch [129/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.5615 (0.7267) acc 87.5000 (80.3125) lr 5.8849e-04 eta 0:05:48
epoch [129/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.2952 (0.7219) acc 84.3750 (79.9306) lr 5.8849e-04 eta 0:05:42
epoch [129/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7505 (0.7200) acc 71.8750 (80.0000) lr 5.7422e-04 eta 0:05:37
epoch [130/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.106) loss 0.8857 (0.8594) acc 81.2500 (76.8750) lr 5.7422e-04 eta 0:11:17
epoch [130/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.6670 (0.7631) acc 84.3750 (78.7500) lr 5.7422e-04 eta 0:08:09
epoch [130/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.9834 (0.7240) acc 81.2500 (80.0000) lr 5.7422e-04 eta 0:07:06
epoch [130/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.5601 (0.6862) acc 78.1250 (80.9375) lr 5.7422e-04 eta 0:06:33
epoch [130/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.3684 (0.6635) acc 90.6250 (81.6250) lr 5.7422e-04 eta 0:06:14
epoch [130/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6328 (0.6734) acc 84.3750 (81.5625) lr 5.7422e-04 eta 0:06:01
epoch [130/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.016) loss 0.6899 (0.6654) acc 84.3750 (81.3393) lr 5.7422e-04 eta 0:05:52
epoch [130/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.0576 (0.7011) acc 71.8750 (80.2344) lr 5.7422e-04 eta 0:05:44
epoch [130/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8838 (0.7065) acc 75.0000 (80.1389) lr 5.7422e-04 eta 0:05:38
epoch [130/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8965 (0.7329) acc 81.2500 (79.7500) lr 5.6006e-04 eta 0:05:33
epoch [131/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 0.7622 (0.6584) acc 78.1250 (80.0000) lr 5.6006e-04 eta 0:11:01
epoch [131/200] batch [10/50] time 0.083 (0.137) data 0.000 (0.052) loss 1.2256 (0.8121) acc 75.0000 (79.3750) lr 5.6006e-04 eta 0:07:56
epoch [131/200] batch [15/50] time 0.083 (0.119) data 0.000 (0.035) loss 0.8711 (0.8301) acc 84.3750 (79.3750) lr 5.6006e-04 eta 0:06:54
epoch [131/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 1.2607 (0.7966) acc 65.6250 (79.0625) lr 5.6006e-04 eta 0:06:23
epoch [131/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.5742 (0.7679) acc 81.2500 (79.3750) lr 5.6006e-04 eta 0:06:05
epoch [131/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.3457 (0.7774) acc 87.5000 (79.0625) lr 5.6006e-04 eta 0:05:52
epoch [131/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.6719 (0.7587) acc 78.1250 (79.4643) lr 5.6006e-04 eta 0:05:43
epoch [131/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6338 (0.7460) acc 87.5000 (79.8438) lr 5.6006e-04 eta 0:05:36
epoch [131/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.4600 (0.7688) acc 65.6250 (79.8611) lr 5.6006e-04 eta 0:05:30
epoch [131/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.4409 (0.7645) acc 90.6250 (80.0625) lr 5.4601e-04 eta 0:05:25
epoch [132/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.108) loss 1.0391 (0.9056) acc 75.0000 (75.6250) lr 5.4601e-04 eta 0:11:07
epoch [132/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.7573 (0.7979) acc 78.1250 (80.6250) lr 5.4601e-04 eta 0:07:58
epoch [132/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 0.9517 (0.7460) acc 81.2500 (81.8750) lr 5.4601e-04 eta 0:06:54
epoch [132/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.4602 (0.7457) acc 87.5000 (82.1875) lr 5.4601e-04 eta 0:06:23
epoch [132/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.5518 (0.7316) acc 84.3750 (81.5000) lr 5.4601e-04 eta 0:06:04
epoch [132/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.7788 (0.7532) acc 81.2500 (80.3125) lr 5.4601e-04 eta 0:05:51
epoch [132/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.7925 (0.7364) acc 84.3750 (80.3571) lr 5.4601e-04 eta 0:05:42
epoch [132/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.2266 (0.7642) acc 68.7500 (79.5312) lr 5.4601e-04 eta 0:05:34
epoch [132/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.5010 (0.7725) acc 59.3750 (79.2361) lr 5.4601e-04 eta 0:05:28
epoch [132/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.3608 (0.7558) acc 93.7500 (79.7500) lr 5.3207e-04 eta 0:05:23
epoch [133/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.101) loss 0.6597 (0.6639) acc 81.2500 (81.8750) lr 5.3207e-04 eta 0:10:31
epoch [133/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.051) loss 1.1895 (0.7728) acc 71.8750 (79.0625) lr 5.3207e-04 eta 0:07:37
epoch [133/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.5005 (0.7278) acc 75.0000 (78.3333) lr 5.3207e-04 eta 0:06:39
epoch [133/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.6240 (0.7325) acc 87.5000 (79.3750) lr 5.3207e-04 eta 0:06:10
epoch [133/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.6982 (0.7533) acc 87.5000 (78.8750) lr 5.3207e-04 eta 0:05:53
epoch [133/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.5303 (0.7277) acc 87.5000 (80.0000) lr 5.3207e-04 eta 0:05:41
epoch [133/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 1.1133 (0.7199) acc 68.7500 (80.3571) lr 5.3207e-04 eta 0:05:32
epoch [133/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5884 (0.7465) acc 81.2500 (79.8438) lr 5.3207e-04 eta 0:05:25
epoch [133/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0439 (0.7673) acc 65.6250 (79.2361) lr 5.3207e-04 eta 0:05:20
epoch [133/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9399 (0.7759) acc 78.1250 (78.8125) lr 5.1825e-04 eta 0:05:15
epoch [134/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.102) loss 1.0557 (0.7731) acc 65.6250 (76.8750) lr 5.1825e-04 eta 0:10:26
epoch [134/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.9448 (0.8193) acc 78.1250 (77.1875) lr 5.1825e-04 eta 0:07:34
epoch [134/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.8232 (0.8531) acc 75.0000 (77.2917) lr 5.1825e-04 eta 0:06:36
epoch [134/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.026) loss 1.1396 (0.8066) acc 75.0000 (78.7500) lr 5.1825e-04 eta 0:06:06
epoch [134/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.5010 (0.7865) acc 90.6250 (79.3750) lr 5.1825e-04 eta 0:05:48
epoch [134/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.6650 (0.7577) acc 84.3750 (80.3125) lr 5.1825e-04 eta 0:05:36
epoch [134/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.015) loss 0.5962 (0.7768) acc 87.5000 (79.7321) lr 5.1825e-04 eta 0:05:28
epoch [134/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9189 (0.7955) acc 78.1250 (79.6094) lr 5.1825e-04 eta 0:05:21
epoch [134/200] batch [45/50] time 0.086 (0.096) data 0.000 (0.012) loss 0.5381 (0.7913) acc 90.6250 (79.9306) lr 5.1825e-04 eta 0:05:16
epoch [134/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.4397 (0.7716) acc 90.6250 (80.2500) lr 5.0454e-04 eta 0:05:11
epoch [135/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.108) loss 0.5967 (0.5413) acc 81.2500 (85.0000) lr 5.0454e-04 eta 0:10:39
epoch [135/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.9097 (0.6037) acc 71.8750 (82.5000) lr 5.0454e-04 eta 0:07:37
epoch [135/200] batch [15/50] time 0.083 (0.121) data 0.000 (0.036) loss 0.7866 (0.6208) acc 81.2500 (83.3333) lr 5.0454e-04 eta 0:06:36
epoch [135/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.6982 (0.6185) acc 87.5000 (83.7500) lr 5.0454e-04 eta 0:06:06
epoch [135/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.6533 (0.6726) acc 84.3750 (82.8750) lr 5.0454e-04 eta 0:05:47
epoch [135/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6714 (0.6624) acc 84.3750 (83.4375) lr 5.0454e-04 eta 0:05:35
epoch [135/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6304 (0.6765) acc 84.3750 (82.2321) lr 5.0454e-04 eta 0:05:26
epoch [135/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.6943 (0.6872) acc 81.2500 (81.9531) lr 5.0454e-04 eta 0:05:19
epoch [135/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7578 (0.6847) acc 75.0000 (81.4583) lr 5.0454e-04 eta 0:05:13
epoch [135/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7544 (0.6791) acc 71.8750 (81.6875) lr 4.9096e-04 eta 0:05:08
epoch [136/200] batch [5/50] time 0.083 (0.181) data 0.000 (0.097) loss 0.7988 (0.5746) acc 71.8750 (85.0000) lr 4.9096e-04 eta 0:09:48
epoch [136/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.049) loss 1.3711 (0.7074) acc 65.6250 (80.6250) lr 4.9096e-04 eta 0:07:10
epoch [136/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.8740 (0.7101) acc 78.1250 (80.8333) lr 4.9096e-04 eta 0:06:16
epoch [136/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 1.0068 (0.7097) acc 75.0000 (81.0938) lr 4.9096e-04 eta 0:05:50
epoch [136/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.9590 (0.7487) acc 75.0000 (80.5000) lr 4.9096e-04 eta 0:05:34
epoch [136/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8682 (0.7528) acc 81.2500 (80.9375) lr 4.9096e-04 eta 0:05:23
epoch [136/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6221 (0.7665) acc 84.3750 (80.3571) lr 4.9096e-04 eta 0:05:15
epoch [136/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9146 (0.7669) acc 75.0000 (80.3906) lr 4.9096e-04 eta 0:05:08
epoch [136/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0986 (0.7840) acc 71.8750 (79.5833) lr 4.9096e-04 eta 0:05:03
epoch [136/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7686 (0.7668) acc 78.1250 (80.0000) lr 4.7750e-04 eta 0:04:59
epoch [137/200] batch [5/50] time 0.083 (0.196) data 0.000 (0.112) loss 0.8804 (0.8759) acc 78.1250 (77.5000) lr 4.7750e-04 eta 0:10:26
epoch [137/200] batch [10/50] time 0.083 (0.140) data 0.000 (0.056) loss 1.0430 (0.8075) acc 78.1250 (78.7500) lr 4.7750e-04 eta 0:07:27
epoch [137/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.037) loss 0.5957 (0.7726) acc 87.5000 (79.7917) lr 4.7750e-04 eta 0:06:27
epoch [137/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.5601 (0.7487) acc 84.3750 (79.8438) lr 4.7750e-04 eta 0:05:57
epoch [137/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.023) loss 0.6372 (0.7382) acc 84.3750 (80.3750) lr 4.7750e-04 eta 0:05:39
epoch [137/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.9741 (0.7712) acc 71.8750 (79.3750) lr 4.7750e-04 eta 0:05:26
epoch [137/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.016) loss 0.7998 (0.7567) acc 71.8750 (79.6429) lr 4.7750e-04 eta 0:05:17
epoch [137/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.0576 (0.7619) acc 68.7500 (79.4531) lr 4.7750e-04 eta 0:05:10
epoch [137/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.3008 (0.7595) acc 71.8750 (79.8611) lr 4.7750e-04 eta 0:05:05
epoch [137/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7188 (0.7548) acc 81.2500 (80.0625) lr 4.6417e-04 eta 0:05:00
epoch [138/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.103) loss 1.2148 (0.7200) acc 59.3750 (80.0000) lr 4.6417e-04 eta 0:09:50
epoch [138/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.7095 (0.7268) acc 78.1250 (79.6875) lr 4.6417e-04 eta 0:07:07
epoch [138/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.5645 (0.7154) acc 81.2500 (79.5833) lr 4.6417e-04 eta 0:06:13
epoch [138/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.7163 (0.7234) acc 78.1250 (79.0625) lr 4.6417e-04 eta 0:05:45
epoch [138/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.9785 (0.7249) acc 71.8750 (79.0000) lr 4.6417e-04 eta 0:05:29
epoch [138/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.3408 (0.7593) acc 65.6250 (78.7500) lr 4.6417e-04 eta 0:05:17
epoch [138/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.8662 (0.7789) acc 75.0000 (78.5714) lr 4.6417e-04 eta 0:05:09
epoch [138/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6284 (0.7696) acc 84.3750 (78.9062) lr 4.6417e-04 eta 0:05:03
epoch [138/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8965 (0.7654) acc 81.2500 (79.1667) lr 4.6417e-04 eta 0:04:57
epoch [138/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.6284 (0.7590) acc 75.0000 (79.3125) lr 4.5098e-04 eta 0:04:53
epoch [139/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.102) loss 0.8120 (0.8297) acc 75.0000 (77.5000) lr 4.5098e-04 eta 0:09:39
epoch [139/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.6479 (0.7592) acc 78.1250 (78.4375) lr 4.5098e-04 eta 0:07:00
epoch [139/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.6577 (0.7173) acc 78.1250 (80.6250) lr 4.5098e-04 eta 0:06:07
epoch [139/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.5293 (0.6913) acc 78.1250 (80.9375) lr 4.5098e-04 eta 0:05:40
epoch [139/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.6509 (0.6883) acc 81.2500 (80.7500) lr 4.5098e-04 eta 0:05:23
epoch [139/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.8750 (0.7033) acc 71.8750 (80.7292) lr 4.5098e-04 eta 0:05:13
epoch [139/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.6865 (0.6955) acc 81.2500 (80.8036) lr 4.5098e-04 eta 0:05:05
epoch [139/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.5137 (0.6870) acc 81.2500 (81.0938) lr 4.5098e-04 eta 0:04:58
epoch [139/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7168 (0.6882) acc 81.2500 (81.2500) lr 4.5098e-04 eta 0:04:53
epoch [139/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.6777 (0.6833) acc 71.8750 (81.1875) lr 4.3792e-04 eta 0:04:48
epoch [140/200] batch [5/50] time 0.084 (0.195) data 0.000 (0.109) loss 0.7017 (0.7995) acc 71.8750 (76.8750) lr 4.3792e-04 eta 0:09:52
epoch [140/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.5752 (0.7724) acc 81.2500 (78.1250) lr 4.3792e-04 eta 0:07:04
epoch [140/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 0.8638 (0.7566) acc 75.0000 (79.3750) lr 4.3792e-04 eta 0:06:08
epoch [140/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.9355 (0.7460) acc 71.8750 (79.5312) lr 4.3792e-04 eta 0:05:39
epoch [140/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.4695 (0.7202) acc 87.5000 (80.2500) lr 4.3792e-04 eta 0:05:22
epoch [140/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 1.0801 (0.7192) acc 75.0000 (81.0417) lr 4.3792e-04 eta 0:05:11
epoch [140/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.9233 (0.7273) acc 81.2500 (81.2500) lr 4.3792e-04 eta 0:05:02
epoch [140/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.6973 (0.7124) acc 84.3750 (81.4844) lr 4.3792e-04 eta 0:04:55
epoch [140/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.8184 (0.7227) acc 78.1250 (80.9722) lr 4.3792e-04 eta 0:04:51
epoch [140/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.5195 (0.7188) acc 87.5000 (81.2500) lr 4.2499e-04 eta 0:04:46
epoch [141/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 0.6528 (0.5346) acc 84.3750 (86.2500) lr 4.2499e-04 eta 0:09:39
epoch [141/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.7104 (0.6596) acc 84.3750 (82.5000) lr 4.2499e-04 eta 0:06:55
epoch [141/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 0.5933 (0.6795) acc 75.0000 (81.2500) lr 4.2499e-04 eta 0:06:01
epoch [141/200] batch [20/50] time 0.085 (0.112) data 0.001 (0.027) loss 0.4824 (0.6903) acc 81.2500 (81.0938) lr 4.2499e-04 eta 0:05:34
epoch [141/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.8262 (0.6941) acc 81.2500 (81.1250) lr 4.2499e-04 eta 0:05:17
epoch [141/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.8560 (0.7126) acc 78.1250 (80.5208) lr 4.2499e-04 eta 0:05:06
epoch [141/200] batch [35/50] time 0.085 (0.101) data 0.001 (0.016) loss 0.4932 (0.7185) acc 84.3750 (80.2679) lr 4.2499e-04 eta 0:04:58
epoch [141/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.6294 (0.7192) acc 87.5000 (80.7812) lr 4.2499e-04 eta 0:04:51
epoch [141/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.6670 (0.7008) acc 84.3750 (81.4583) lr 4.2499e-04 eta 0:04:45
epoch [141/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5107 (0.6999) acc 84.3750 (81.2500) lr 4.1221e-04 eta 0:04:41
epoch [142/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.106) loss 0.9482 (0.8514) acc 68.7500 (73.7500) lr 4.1221e-04 eta 0:09:24
epoch [142/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.4417 (0.6927) acc 87.5000 (80.6250) lr 4.1221e-04 eta 0:06:46
epoch [142/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.7363 (0.7002) acc 84.3750 (80.2083) lr 4.1221e-04 eta 0:05:53
epoch [142/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.4138 (0.7412) acc 93.7500 (80.4688) lr 4.1221e-04 eta 0:05:27
epoch [142/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.3618 (0.7315) acc 93.7500 (81.3750) lr 4.1221e-04 eta 0:05:11
epoch [142/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.7046 (0.7093) acc 75.0000 (81.6667) lr 4.1221e-04 eta 0:05:00
epoch [142/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.7290 (0.7058) acc 75.0000 (81.6071) lr 4.1221e-04 eta 0:04:52
epoch [142/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9438 (0.7199) acc 75.0000 (80.7812) lr 4.1221e-04 eta 0:04:45
epoch [142/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.5688 (0.7087) acc 84.3750 (81.2500) lr 4.1221e-04 eta 0:04:40
epoch [142/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7471 (0.7079) acc 84.3750 (81.5625) lr 3.9958e-04 eta 0:04:36
epoch [143/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.100) loss 0.9556 (0.8382) acc 75.0000 (77.5000) lr 3.9958e-04 eta 0:09:00
epoch [143/200] batch [10/50] time 0.086 (0.136) data 0.000 (0.050) loss 0.6494 (0.7353) acc 78.1250 (80.0000) lr 3.9958e-04 eta 0:06:33
epoch [143/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 1.0049 (0.7507) acc 68.7500 (79.7917) lr 3.9958e-04 eta 0:05:43
epoch [143/200] batch [20/50] time 0.086 (0.111) data 0.000 (0.025) loss 0.6377 (0.7485) acc 84.3750 (79.0625) lr 3.9958e-04 eta 0:05:18
epoch [143/200] batch [25/50] time 0.086 (0.106) data 0.000 (0.020) loss 0.7554 (0.7221) acc 78.1250 (80.0000) lr 3.9958e-04 eta 0:05:03
epoch [143/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.6597 (0.7221) acc 81.2500 (80.2083) lr 3.9958e-04 eta 0:04:53
epoch [143/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.5615 (0.7051) acc 75.0000 (80.4464) lr 3.9958e-04 eta 0:04:45
epoch [143/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.4546 (0.7114) acc 96.8750 (80.4688) lr 3.9958e-04 eta 0:04:39
epoch [143/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.7075 (0.6989) acc 81.2500 (80.9722) lr 3.9958e-04 eta 0:04:34
epoch [143/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.9341 (0.6939) acc 78.1250 (81.1250) lr 3.8709e-04 eta 0:04:30
epoch [144/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.098) loss 0.8320 (0.6379) acc 78.1250 (85.0000) lr 3.8709e-04 eta 0:08:40
epoch [144/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.049) loss 0.5630 (0.6760) acc 87.5000 (84.0625) lr 3.8709e-04 eta 0:06:19
epoch [144/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.9712 (0.7007) acc 75.0000 (82.7083) lr 3.8709e-04 eta 0:05:31
epoch [144/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.8955 (0.7207) acc 78.1250 (82.0312) lr 3.8709e-04 eta 0:05:07
epoch [144/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7505 (0.7050) acc 81.2500 (82.2500) lr 3.8709e-04 eta 0:04:53
epoch [144/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.017) loss 0.2379 (0.6880) acc 90.6250 (82.3958) lr 3.8709e-04 eta 0:04:43
epoch [144/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6802 (0.6858) acc 81.2500 (82.1429) lr 3.8709e-04 eta 0:04:36
epoch [144/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8584 (0.7011) acc 75.0000 (81.4844) lr 3.8709e-04 eta 0:04:30
epoch [144/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5312 (0.6925) acc 90.6250 (81.3889) lr 3.8709e-04 eta 0:04:26
epoch [144/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5527 (0.6952) acc 93.7500 (81.5625) lr 3.7476e-04 eta 0:04:22
epoch [145/200] batch [5/50] time 0.083 (0.190) data 0.000 (0.105) loss 0.4829 (0.7338) acc 87.5000 (81.2500) lr 3.7476e-04 eta 0:08:51
epoch [145/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.053) loss 0.6797 (0.6990) acc 75.0000 (80.3125) lr 3.7476e-04 eta 0:06:23
epoch [145/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.5923 (0.7002) acc 87.5000 (81.2500) lr 3.7476e-04 eta 0:05:32
epoch [145/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.027) loss 0.4507 (0.6768) acc 90.6250 (82.0312) lr 3.7476e-04 eta 0:05:07
epoch [145/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.7280 (0.7033) acc 87.5000 (81.5000) lr 3.7476e-04 eta 0:04:52
epoch [145/200] batch [30/50] time 0.083 (0.102) data 0.000 (0.018) loss 0.7334 (0.7165) acc 78.1250 (80.9375) lr 3.7476e-04 eta 0:04:41
epoch [145/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.5518 (0.7288) acc 84.3750 (80.4464) lr 3.7476e-04 eta 0:04:34
epoch [145/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8135 (0.7296) acc 87.5000 (80.7031) lr 3.7476e-04 eta 0:04:28
epoch [145/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8105 (0.7485) acc 75.0000 (80.2778) lr 3.7476e-04 eta 0:04:23
epoch [145/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.6626 (0.7555) acc 81.2500 (79.6875) lr 3.6258e-04 eta 0:04:19
epoch [146/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.099) loss 1.1777 (0.9672) acc 68.7500 (76.2500) lr 3.6258e-04 eta 0:08:29
epoch [146/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.7788 (0.8396) acc 75.0000 (78.4375) lr 3.6258e-04 eta 0:06:10
epoch [146/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.6753 (0.8302) acc 75.0000 (77.9167) lr 3.6258e-04 eta 0:05:23
epoch [146/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.4426 (0.7876) acc 87.5000 (78.7500) lr 3.6258e-04 eta 0:05:00
epoch [146/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 1.2588 (0.7857) acc 71.8750 (78.1250) lr 3.6258e-04 eta 0:04:46
epoch [146/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.7915 (0.7584) acc 81.2500 (78.8542) lr 3.6258e-04 eta 0:04:36
epoch [146/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6582 (0.7488) acc 84.3750 (79.1964) lr 3.6258e-04 eta 0:04:29
epoch [146/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.3110 (0.7465) acc 90.6250 (79.4531) lr 3.6258e-04 eta 0:04:23
epoch [146/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.6592 (0.7545) acc 87.5000 (79.8611) lr 3.6258e-04 eta 0:04:19
epoch [146/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.6924 (0.7671) acc 84.3750 (79.3750) lr 3.5055e-04 eta 0:04:15
epoch [147/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 0.6006 (0.6042) acc 84.3750 (82.5000) lr 3.5055e-04 eta 0:08:23
epoch [147/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.9468 (0.6989) acc 75.0000 (80.9375) lr 3.5055e-04 eta 0:06:04
epoch [147/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.5581 (0.6714) acc 84.3750 (81.2500) lr 3.5055e-04 eta 0:05:17
epoch [147/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.6274 (0.6526) acc 84.3750 (82.5000) lr 3.5055e-04 eta 0:04:54
epoch [147/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.8125 (0.6333) acc 81.2500 (82.7500) lr 3.5055e-04 eta 0:04:39
epoch [147/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.5249 (0.6447) acc 84.3750 (82.3958) lr 3.5055e-04 eta 0:04:30
epoch [147/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.5771 (0.6654) acc 81.2500 (81.7857) lr 3.5055e-04 eta 0:04:23
epoch [147/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.5615 (0.6890) acc 87.5000 (81.4844) lr 3.5055e-04 eta 0:04:17
epoch [147/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.012) loss 0.8057 (0.6853) acc 81.2500 (81.7361) lr 3.5055e-04 eta 0:04:13
epoch [147/200] batch [50/50] time 0.086 (0.094) data 0.000 (0.010) loss 0.5107 (0.6719) acc 87.5000 (82.0625) lr 3.3869e-04 eta 0:04:09
epoch [148/200] batch [5/50] time 0.084 (0.204) data 0.000 (0.120) loss 1.0498 (0.8479) acc 68.7500 (76.8750) lr 3.3869e-04 eta 0:09:00
epoch [148/200] batch [10/50] time 0.084 (0.144) data 0.000 (0.060) loss 0.8276 (0.8278) acc 75.0000 (77.8125) lr 3.3869e-04 eta 0:06:20
epoch [148/200] batch [15/50] time 0.084 (0.124) data 0.000 (0.040) loss 0.6382 (0.7612) acc 84.3750 (79.7917) lr 3.3869e-04 eta 0:05:27
epoch [148/200] batch [20/50] time 0.085 (0.114) data 0.000 (0.030) loss 1.0557 (0.7988) acc 71.8750 (78.5938) lr 3.3869e-04 eta 0:05:00
epoch [148/200] batch [25/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.8057 (0.8118) acc 75.0000 (78.1250) lr 3.3869e-04 eta 0:04:44
epoch [148/200] batch [30/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7070 (0.7914) acc 75.0000 (78.5417) lr 3.3869e-04 eta 0:04:33
epoch [148/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.4771 (0.7488) acc 90.6250 (80.1786) lr 3.3869e-04 eta 0:04:25
epoch [148/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.8647 (0.7483) acc 78.1250 (80.2344) lr 3.3869e-04 eta 0:04:18
epoch [148/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.5664 (0.7393) acc 84.3750 (80.3472) lr 3.3869e-04 eta 0:04:13
epoch [148/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8970 (0.7263) acc 81.2500 (80.8125) lr 3.2699e-04 eta 0:04:09
epoch [149/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.110) loss 0.8887 (0.7575) acc 78.1250 (78.7500) lr 3.2699e-04 eta 0:08:25
epoch [149/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.055) loss 0.8618 (0.7912) acc 81.2500 (78.7500) lr 3.2699e-04 eta 0:06:01
epoch [149/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 0.3386 (0.6896) acc 87.5000 (80.8333) lr 3.2699e-04 eta 0:05:13
epoch [149/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.6606 (0.7250) acc 75.0000 (80.4688) lr 3.2699e-04 eta 0:04:49
epoch [149/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 0.6953 (0.7253) acc 71.8750 (79.8750) lr 3.2699e-04 eta 0:04:34
epoch [149/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.9512 (0.7477) acc 78.1250 (79.4792) lr 3.2699e-04 eta 0:04:24
epoch [149/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.9971 (0.7669) acc 75.0000 (78.9286) lr 3.2699e-04 eta 0:04:17
epoch [149/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7690 (0.7683) acc 81.2500 (78.9844) lr 3.2699e-04 eta 0:04:11
epoch [149/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.5488 (0.7588) acc 84.3750 (79.3056) lr 3.2699e-04 eta 0:04:06
epoch [149/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8096 (0.7740) acc 75.0000 (79.2500) lr 3.1545e-04 eta 0:04:02
epoch [150/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.100) loss 0.5972 (0.7167) acc 84.3750 (78.7500) lr 3.1545e-04 eta 0:07:52
epoch [150/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.6821 (0.7217) acc 75.0000 (79.3750) lr 3.1545e-04 eta 0:05:43
epoch [150/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.034) loss 1.2725 (0.7265) acc 68.7500 (80.2083) lr 3.1545e-04 eta 0:04:59
epoch [150/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.9575 (0.7575) acc 68.7500 (79.2188) lr 3.1545e-04 eta 0:04:37
epoch [150/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.5205 (0.7484) acc 87.5000 (80.0000) lr 3.1545e-04 eta 0:04:24
epoch [150/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9048 (0.7447) acc 71.8750 (80.7292) lr 3.1545e-04 eta 0:04:15
epoch [150/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.3262 (0.7234) acc 90.6250 (80.8929) lr 3.1545e-04 eta 0:04:08
epoch [150/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.9146 (0.7348) acc 71.8750 (80.3906) lr 3.1545e-04 eta 0:04:03
epoch [150/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.8081 (0.7391) acc 84.3750 (80.4861) lr 3.1545e-04 eta 0:03:59
epoch [150/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7852 (0.7302) acc 78.1250 (80.8125) lr 3.0409e-04 eta 0:03:56
epoch [151/200] batch [5/50] time 0.083 (0.194) data 0.000 (0.109) loss 0.6709 (0.6194) acc 81.2500 (82.5000) lr 3.0409e-04 eta 0:08:03
epoch [151/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.055) loss 0.5264 (0.5832) acc 93.7500 (83.4375) lr 3.0409e-04 eta 0:05:45
epoch [151/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 0.8696 (0.6651) acc 75.0000 (81.6667) lr 3.0409e-04 eta 0:04:59
epoch [151/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.3640 (0.6303) acc 93.7500 (83.2812) lr 3.0409e-04 eta 0:04:36
epoch [151/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.8960 (0.6964) acc 81.2500 (81.6250) lr 3.0409e-04 eta 0:04:22
epoch [151/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6553 (0.6972) acc 78.1250 (81.2500) lr 3.0409e-04 eta 0:04:13
epoch [151/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 1.1318 (0.7224) acc 68.7500 (80.1786) lr 3.0409e-04 eta 0:04:06
epoch [151/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.3613 (0.6993) acc 87.5000 (81.0938) lr 3.0409e-04 eta 0:04:01
epoch [151/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4719 (0.7013) acc 84.3750 (81.2500) lr 3.0409e-04 eta 0:03:56
epoch [151/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4927 (0.7071) acc 84.3750 (80.9375) lr 2.9289e-04 eta 0:03:52
epoch [152/200] batch [5/50] time 0.086 (0.193) data 0.000 (0.106) loss 0.9067 (0.8004) acc 71.8750 (76.8750) lr 2.9289e-04 eta 0:07:51
epoch [152/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.053) loss 0.7373 (0.8301) acc 81.2500 (75.0000) lr 2.9289e-04 eta 0:05:38
epoch [152/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.5479 (0.7934) acc 81.2500 (76.6667) lr 2.9289e-04 eta 0:04:54
epoch [152/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 1.2002 (0.8260) acc 68.7500 (76.0938) lr 2.9289e-04 eta 0:04:31
epoch [152/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 1.1260 (0.8286) acc 68.7500 (76.2500) lr 2.9289e-04 eta 0:04:18
epoch [152/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.8945 (0.8153) acc 81.2500 (76.7708) lr 2.9289e-04 eta 0:04:08
epoch [152/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.7163 (0.7845) acc 84.3750 (78.0357) lr 2.9289e-04 eta 0:04:02
epoch [152/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5405 (0.7681) acc 81.2500 (78.1250) lr 2.9289e-04 eta 0:03:56
epoch [152/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9653 (0.7581) acc 75.0000 (78.5417) lr 2.9289e-04 eta 0:03:51
epoch [152/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4978 (0.7490) acc 87.5000 (78.8125) lr 2.8187e-04 eta 0:03:48
epoch [153/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 0.7871 (0.7077) acc 78.1250 (80.0000) lr 2.8187e-04 eta 0:07:20
epoch [153/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.050) loss 0.8237 (0.6968) acc 75.0000 (80.9375) lr 2.8187e-04 eta 0:05:20
epoch [153/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 0.3440 (0.6981) acc 87.5000 (81.2500) lr 2.8187e-04 eta 0:04:39
epoch [153/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.8745 (0.6991) acc 75.0000 (80.7812) lr 2.8187e-04 eta 0:04:19
epoch [153/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.5435 (0.6723) acc 87.5000 (81.5000) lr 2.8187e-04 eta 0:04:06
epoch [153/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.017) loss 0.9692 (0.7014) acc 78.1250 (81.4583) lr 2.8187e-04 eta 0:03:58
epoch [153/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8022 (0.6874) acc 75.0000 (81.3393) lr 2.8187e-04 eta 0:03:52
epoch [153/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 1.0723 (0.6996) acc 65.6250 (80.9375) lr 2.8187e-04 eta 0:03:47
epoch [153/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6001 (0.7003) acc 90.6250 (81.1806) lr 2.8187e-04 eta 0:03:43
epoch [153/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.4692 (0.6910) acc 87.5000 (81.5000) lr 2.7103e-04 eta 0:03:40
epoch [154/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 0.6040 (0.8426) acc 78.1250 (78.1250) lr 2.7103e-04 eta 0:07:19
epoch [154/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.6147 (0.8658) acc 81.2500 (77.1875) lr 2.7103e-04 eta 0:05:17
epoch [154/200] batch [15/50] time 0.083 (0.118) data 0.000 (0.034) loss 0.3479 (0.7502) acc 93.7500 (79.5833) lr 2.7103e-04 eta 0:04:36
epoch [154/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 1.1035 (0.7491) acc 78.1250 (80.6250) lr 2.7103e-04 eta 0:04:16
epoch [154/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.0986 (0.7593) acc 75.0000 (80.0000) lr 2.7103e-04 eta 0:04:03
epoch [154/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.9697 (0.7531) acc 68.7500 (80.1042) lr 2.7103e-04 eta 0:03:55
epoch [154/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.4072 (0.7363) acc 90.6250 (80.3571) lr 2.7103e-04 eta 0:03:49
epoch [154/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5928 (0.7314) acc 87.5000 (81.0156) lr 2.7103e-04 eta 0:03:44
epoch [154/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0830 (0.7478) acc 62.5000 (80.1389) lr 2.7103e-04 eta 0:03:40
epoch [154/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6538 (0.7538) acc 84.3750 (80.0000) lr 2.6037e-04 eta 0:03:36
epoch [155/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.6919 (0.6824) acc 78.1250 (80.6250) lr 2.6037e-04 eta 0:06:55
epoch [155/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.048) loss 1.2158 (0.7458) acc 62.5000 (80.3125) lr 2.6037e-04 eta 0:05:03
epoch [155/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.032) loss 1.0029 (0.7923) acc 71.8750 (78.9583) lr 2.6037e-04 eta 0:04:26
epoch [155/200] batch [20/50] time 0.087 (0.109) data 0.000 (0.024) loss 0.5000 (0.7774) acc 84.3750 (79.0625) lr 2.6037e-04 eta 0:04:07
epoch [155/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.6948 (0.7538) acc 78.1250 (79.8750) lr 2.6037e-04 eta 0:03:55
epoch [155/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.3818 (0.7447) acc 96.8750 (80.1042) lr 2.6037e-04 eta 0:03:47
epoch [155/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.4543 (0.7393) acc 84.3750 (80.7143) lr 2.6037e-04 eta 0:03:42
epoch [155/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5664 (0.7357) acc 81.2500 (80.7031) lr 2.6037e-04 eta 0:03:37
epoch [155/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9385 (0.7373) acc 78.1250 (80.6944) lr 2.6037e-04 eta 0:03:33
epoch [155/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8477 (0.7444) acc 81.2500 (80.3750) lr 2.4989e-04 eta 0:03:30
epoch [156/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.5630 (0.8109) acc 81.2500 (77.5000) lr 2.4989e-04 eta 0:06:55
epoch [156/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.4175 (0.6795) acc 90.6250 (82.5000) lr 2.4989e-04 eta 0:05:01
epoch [156/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.8232 (0.7458) acc 75.0000 (80.0000) lr 2.4989e-04 eta 0:04:23
epoch [156/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.2537 (0.7077) acc 93.7500 (81.0938) lr 2.4989e-04 eta 0:04:04
epoch [156/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.8062 (0.7070) acc 87.5000 (81.6250) lr 2.4989e-04 eta 0:03:52
epoch [156/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.5708 (0.7527) acc 78.1250 (80.5208) lr 2.4989e-04 eta 0:03:44
epoch [156/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.014) loss 0.6255 (0.7656) acc 75.0000 (80.0000) lr 2.4989e-04 eta 0:03:38
epoch [156/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8301 (0.7537) acc 71.8750 (80.1562) lr 2.4989e-04 eta 0:03:33
epoch [156/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4504 (0.7519) acc 87.5000 (80.0694) lr 2.4989e-04 eta 0:03:30
epoch [156/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7085 (0.7377) acc 78.1250 (80.2500) lr 2.3959e-04 eta 0:03:26
epoch [157/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.106) loss 0.4009 (0.7457) acc 90.6250 (82.5000) lr 2.3959e-04 eta 0:06:59
epoch [157/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 1.1943 (0.7996) acc 68.7500 (80.0000) lr 2.3959e-04 eta 0:05:01
epoch [157/200] batch [15/50] time 0.083 (0.120) data 0.000 (0.035) loss 0.6509 (0.7972) acc 78.1250 (80.0000) lr 2.3959e-04 eta 0:04:21
epoch [157/200] batch [20/50] time 0.086 (0.111) data 0.000 (0.027) loss 0.7275 (0.7270) acc 78.1250 (81.0938) lr 2.3959e-04 eta 0:04:01
epoch [157/200] batch [25/50] time 0.083 (0.105) data 0.000 (0.021) loss 0.5693 (0.6968) acc 84.3750 (82.2500) lr 2.3959e-04 eta 0:03:49
epoch [157/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6348 (0.6927) acc 78.1250 (81.8750) lr 2.3959e-04 eta 0:03:41
epoch [157/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.7881 (0.6960) acc 84.3750 (81.4286) lr 2.3959e-04 eta 0:03:35
epoch [157/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.3857 (0.6899) acc 87.5000 (81.5625) lr 2.3959e-04 eta 0:03:30
epoch [157/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7173 (0.6954) acc 78.1250 (81.3889) lr 2.3959e-04 eta 0:03:26
epoch [157/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5610 (0.7063) acc 84.3750 (81.0000) lr 2.2949e-04 eta 0:03:23
epoch [158/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.3853 (0.6407) acc 93.7500 (80.6250) lr 2.2949e-04 eta 0:06:35
epoch [158/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.7051 (0.6769) acc 78.1250 (82.1875) lr 2.2949e-04 eta 0:04:48
epoch [158/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.9683 (0.7543) acc 75.0000 (80.4167) lr 2.2949e-04 eta 0:04:12
epoch [158/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.6499 (0.7484) acc 68.7500 (80.3125) lr 2.2949e-04 eta 0:03:53
epoch [158/200] batch [25/50] time 0.085 (0.105) data 0.001 (0.020) loss 0.7217 (0.7339) acc 78.1250 (80.5000) lr 2.2949e-04 eta 0:03:42
epoch [158/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.4905 (0.7354) acc 93.7500 (81.0417) lr 2.2949e-04 eta 0:03:35
epoch [158/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 0.3584 (0.7250) acc 93.7500 (81.0714) lr 2.2949e-04 eta 0:03:29
epoch [158/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9746 (0.7262) acc 78.1250 (81.0156) lr 2.2949e-04 eta 0:03:25
epoch [158/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.7163 (0.7375) acc 71.8750 (80.5556) lr 2.2949e-04 eta 0:03:21
epoch [158/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8042 (0.7513) acc 81.2500 (80.1250) lr 2.1957e-04 eta 0:03:18
epoch [159/200] batch [5/50] time 0.090 (0.193) data 0.000 (0.107) loss 0.5947 (0.5827) acc 87.5000 (83.7500) lr 2.1957e-04 eta 0:06:45
epoch [159/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.9512 (0.6366) acc 75.0000 (82.5000) lr 2.1957e-04 eta 0:04:50
epoch [159/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 0.5581 (0.7152) acc 87.5000 (81.2500) lr 2.1957e-04 eta 0:04:11
epoch [159/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.4678 (0.7173) acc 90.6250 (82.0312) lr 2.1957e-04 eta 0:03:52
epoch [159/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.9321 (0.7133) acc 81.2500 (82.3750) lr 2.1957e-04 eta 0:03:40
epoch [159/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.8267 (0.7397) acc 71.8750 (80.9375) lr 2.1957e-04 eta 0:03:32
epoch [159/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6943 (0.7414) acc 87.5000 (80.7143) lr 2.1957e-04 eta 0:03:26
epoch [159/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7808 (0.7314) acc 78.1250 (80.9375) lr 2.1957e-04 eta 0:03:21
epoch [159/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7114 (0.7137) acc 81.2500 (81.3889) lr 2.1957e-04 eta 0:03:17
epoch [159/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.2905 (0.6950) acc 90.6250 (81.6250) lr 2.0984e-04 eta 0:03:14
epoch [160/200] batch [5/50] time 0.086 (0.186) data 0.000 (0.100) loss 0.9722 (0.6560) acc 65.6250 (81.2500) lr 2.0984e-04 eta 0:06:20
epoch [160/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 1.0576 (0.7481) acc 65.6250 (78.4375) lr 2.0984e-04 eta 0:04:36
epoch [160/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.4036 (0.7119) acc 84.3750 (78.9583) lr 2.0984e-04 eta 0:04:00
epoch [160/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.9907 (0.7519) acc 78.1250 (78.4375) lr 2.0984e-04 eta 0:03:43
epoch [160/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.4619 (0.7656) acc 81.2500 (78.5000) lr 2.0984e-04 eta 0:03:32
epoch [160/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.4048 (0.7429) acc 90.6250 (79.2708) lr 2.0984e-04 eta 0:03:25
epoch [160/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.8252 (0.7411) acc 84.3750 (79.6429) lr 2.0984e-04 eta 0:03:19
epoch [160/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.2778 (0.7275) acc 93.7500 (80.0781) lr 2.0984e-04 eta 0:03:15
epoch [160/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.3508 (0.7154) acc 87.5000 (80.1389) lr 2.0984e-04 eta 0:03:11
epoch [160/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.0996 (0.7200) acc 75.0000 (80.1250) lr 2.0032e-04 eta 0:03:08
epoch [161/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.106) loss 0.3186 (0.6484) acc 87.5000 (85.0000) lr 2.0032e-04 eta 0:06:21
epoch [161/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.2279 (0.6887) acc 90.6250 (81.5625) lr 2.0032e-04 eta 0:04:33
epoch [161/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.7969 (0.7200) acc 81.2500 (80.4167) lr 2.0032e-04 eta 0:03:57
epoch [161/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.6670 (0.7049) acc 84.3750 (80.9375) lr 2.0032e-04 eta 0:03:39
epoch [161/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.7290 (0.7049) acc 81.2500 (81.2500) lr 2.0032e-04 eta 0:03:28
epoch [161/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 1.0283 (0.7177) acc 78.1250 (81.0417) lr 2.0032e-04 eta 0:03:21
epoch [161/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.4192 (0.7183) acc 87.5000 (80.8929) lr 2.0032e-04 eta 0:03:15
epoch [161/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.5815 (0.7197) acc 87.5000 (81.0938) lr 2.0032e-04 eta 0:03:11
epoch [161/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7383 (0.7268) acc 78.1250 (80.7639) lr 2.0032e-04 eta 0:03:07
epoch [161/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6392 (0.7270) acc 78.1250 (80.6875) lr 1.9098e-04 eta 0:03:04
epoch [162/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.100) loss 0.3877 (0.5471) acc 90.6250 (85.6250) lr 1.9098e-04 eta 0:06:02
epoch [162/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.7402 (0.6205) acc 81.2500 (83.4375) lr 1.9098e-04 eta 0:04:22
epoch [162/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.3442 (0.6716) acc 90.6250 (82.7083) lr 1.9098e-04 eta 0:03:48
epoch [162/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.4990 (0.6763) acc 87.5000 (82.1875) lr 1.9098e-04 eta 0:03:31
epoch [162/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.5967 (0.6817) acc 84.3750 (82.3750) lr 1.9098e-04 eta 0:03:21
epoch [162/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.6963 (0.6978) acc 81.2500 (81.4583) lr 1.9098e-04 eta 0:03:15
epoch [162/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7261 (0.7139) acc 84.3750 (81.2500) lr 1.9098e-04 eta 0:03:09
epoch [162/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5435 (0.7119) acc 87.5000 (81.4844) lr 1.9098e-04 eta 0:03:05
epoch [162/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.6953 (0.7067) acc 75.0000 (81.2500) lr 1.9098e-04 eta 0:03:02
epoch [162/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.8521 (0.7140) acc 84.3750 (81.2500) lr 1.8185e-04 eta 0:02:59
epoch [163/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.097) loss 0.8301 (0.6256) acc 75.0000 (82.5000) lr 1.8185e-04 eta 0:05:46
epoch [163/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 1.1680 (0.6973) acc 65.6250 (81.2500) lr 1.8185e-04 eta 0:04:12
epoch [163/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 1.1816 (0.7278) acc 71.8750 (81.0417) lr 1.8185e-04 eta 0:03:40
epoch [163/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.4836 (0.7066) acc 87.5000 (81.4062) lr 1.8185e-04 eta 0:03:25
epoch [163/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.9971 (0.7196) acc 68.7500 (80.7500) lr 1.8185e-04 eta 0:03:15
epoch [163/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.6992 (0.7328) acc 78.1250 (80.3125) lr 1.8185e-04 eta 0:03:08
epoch [163/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.6177 (0.7217) acc 81.2500 (80.8036) lr 1.8185e-04 eta 0:03:03
epoch [163/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.9844 (0.7138) acc 75.0000 (81.0938) lr 1.8185e-04 eta 0:02:59
epoch [163/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.3271 (0.7161) acc 96.8750 (81.1111) lr 1.8185e-04 eta 0:02:56
epoch [163/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6426 (0.7302) acc 75.0000 (80.3750) lr 1.7292e-04 eta 0:02:53
epoch [164/200] batch [5/50] time 0.085 (0.181) data 0.000 (0.096) loss 1.1182 (0.8093) acc 68.7500 (78.7500) lr 1.7292e-04 eta 0:05:34
epoch [164/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.5356 (0.8017) acc 81.2500 (78.1250) lr 1.7292e-04 eta 0:04:04
epoch [164/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.3357 (0.7678) acc 93.7500 (78.9583) lr 1.7292e-04 eta 0:03:34
epoch [164/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.6294 (0.7606) acc 84.3750 (79.0625) lr 1.7292e-04 eta 0:03:19
epoch [164/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.9688 (0.7703) acc 75.0000 (79.1250) lr 1.7292e-04 eta 0:03:09
epoch [164/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.9761 (0.7640) acc 75.0000 (78.8542) lr 1.7292e-04 eta 0:03:03
epoch [164/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.5532 (0.7499) acc 81.2500 (79.3750) lr 1.7292e-04 eta 0:02:58
epoch [164/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0020 (0.7644) acc 78.1250 (78.7500) lr 1.7292e-04 eta 0:02:54
epoch [164/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6719 (0.7492) acc 75.0000 (78.9583) lr 1.7292e-04 eta 0:02:51
epoch [164/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.4170 (0.7267) acc 90.6250 (79.5625) lr 1.6419e-04 eta 0:02:49
epoch [165/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.105) loss 0.8833 (0.7971) acc 81.2500 (78.1250) lr 1.6419e-04 eta 0:05:41
epoch [165/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.9517 (0.8352) acc 78.1250 (77.8125) lr 1.6419e-04 eta 0:04:05
epoch [165/200] batch [15/50] time 0.086 (0.120) data 0.001 (0.035) loss 0.9878 (0.7788) acc 81.2500 (79.3750) lr 1.6419e-04 eta 0:03:33
epoch [165/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.6621 (0.7534) acc 90.6250 (80.0000) lr 1.6419e-04 eta 0:03:17
epoch [165/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.6875 (0.7344) acc 87.5000 (80.5000) lr 1.6419e-04 eta 0:03:07
epoch [165/200] batch [30/50] time 0.087 (0.102) data 0.000 (0.018) loss 0.6621 (0.7296) acc 87.5000 (81.2500) lr 1.6419e-04 eta 0:03:01
epoch [165/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.5571 (0.7164) acc 90.6250 (81.4286) lr 1.6419e-04 eta 0:02:56
epoch [165/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.7065 (0.7159) acc 78.1250 (81.7188) lr 1.6419e-04 eta 0:02:51
epoch [165/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8984 (0.7109) acc 75.0000 (81.6667) lr 1.6419e-04 eta 0:02:48
epoch [165/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7402 (0.7238) acc 75.0000 (81.1250) lr 1.5567e-04 eta 0:02:45
epoch [166/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 0.4885 (0.6942) acc 87.5000 (81.2500) lr 1.5567e-04 eta 0:05:25
epoch [166/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.051) loss 0.7754 (0.6413) acc 78.1250 (84.0625) lr 1.5567e-04 eta 0:03:55
epoch [166/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.7988 (0.6653) acc 75.0000 (82.5000) lr 1.5567e-04 eta 0:03:25
epoch [166/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.9814 (0.7279) acc 81.2500 (82.0312) lr 1.5567e-04 eta 0:03:10
epoch [166/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.4302 (0.7301) acc 87.5000 (82.1250) lr 1.5567e-04 eta 0:03:00
epoch [166/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.4033 (0.7215) acc 87.5000 (81.9792) lr 1.5567e-04 eta 0:02:54
epoch [166/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.3145 (0.7235) acc 93.7500 (81.9643) lr 1.5567e-04 eta 0:02:49
epoch [166/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6338 (0.7225) acc 84.3750 (82.4219) lr 1.5567e-04 eta 0:02:45
epoch [166/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.012) loss 0.3821 (0.7062) acc 87.5000 (82.4306) lr 1.5567e-04 eta 0:02:42
epoch [166/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5879 (0.7020) acc 90.6250 (82.3750) lr 1.4736e-04 eta 0:02:40
epoch [167/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.106) loss 1.0723 (0.7550) acc 78.1250 (81.8750) lr 1.4736e-04 eta 0:05:24
epoch [167/200] batch [10/50] time 0.083 (0.138) data 0.000 (0.053) loss 0.6069 (0.6484) acc 84.3750 (83.7500) lr 1.4736e-04 eta 0:03:52
epoch [167/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 1.0469 (0.7510) acc 71.8750 (82.0833) lr 1.4736e-04 eta 0:03:21
epoch [167/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.9902 (0.7473) acc 71.8750 (82.3438) lr 1.4736e-04 eta 0:03:06
epoch [167/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.5557 (0.7310) acc 71.8750 (81.2500) lr 1.4736e-04 eta 0:02:56
epoch [167/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.5913 (0.7439) acc 81.2500 (80.4167) lr 1.4736e-04 eta 0:02:50
epoch [167/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.6006 (0.7245) acc 87.5000 (81.0714) lr 1.4736e-04 eta 0:02:45
epoch [167/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.5073 (0.7534) acc 87.5000 (80.6250) lr 1.4736e-04 eta 0:02:41
epoch [167/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6362 (0.7590) acc 81.2500 (80.6944) lr 1.4736e-04 eta 0:02:38
epoch [167/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6274 (0.7478) acc 84.3750 (81.0000) lr 1.3926e-04 eta 0:02:36
epoch [168/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.108) loss 0.7573 (0.4878) acc 71.8750 (83.7500) lr 1.3926e-04 eta 0:05:19
epoch [168/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.6753 (0.5561) acc 81.2500 (83.1250) lr 1.3926e-04 eta 0:03:48
epoch [168/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 0.7251 (0.5992) acc 81.2500 (82.7083) lr 1.3926e-04 eta 0:03:17
epoch [168/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.3374 (0.5985) acc 90.6250 (83.4375) lr 1.3926e-04 eta 0:03:02
epoch [168/200] batch [25/50] time 0.083 (0.106) data 0.000 (0.022) loss 0.9937 (0.5965) acc 68.7500 (83.1250) lr 1.3926e-04 eta 0:02:52
epoch [168/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.8989 (0.6284) acc 75.0000 (82.5000) lr 1.3926e-04 eta 0:02:46
epoch [168/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.0635 (0.6391) acc 68.7500 (82.4107) lr 1.3926e-04 eta 0:02:41
epoch [168/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.8560 (0.6576) acc 71.8750 (81.9531) lr 1.3926e-04 eta 0:02:37
epoch [168/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.3232 (0.6695) acc 78.1250 (81.8056) lr 1.3926e-04 eta 0:02:34
epoch [168/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8252 (0.6625) acc 81.2500 (82.0625) lr 1.3137e-04 eta 0:02:32
epoch [169/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.109) loss 0.7832 (0.6313) acc 81.2500 (80.6250) lr 1.3137e-04 eta 0:05:09
epoch [169/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.055) loss 0.9331 (0.6603) acc 78.1250 (81.8750) lr 1.3137e-04 eta 0:03:41
epoch [169/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 1.2158 (0.6713) acc 75.0000 (82.0833) lr 1.3137e-04 eta 0:03:11
epoch [169/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.7925 (0.6612) acc 81.2500 (82.1875) lr 1.3137e-04 eta 0:02:56
epoch [169/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.3269 (0.6242) acc 90.6250 (83.3750) lr 1.3137e-04 eta 0:02:47
epoch [169/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.7539 (0.6653) acc 78.1250 (82.5000) lr 1.3137e-04 eta 0:02:41
epoch [169/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5757 (0.6689) acc 75.0000 (81.8750) lr 1.3137e-04 eta 0:02:36
epoch [169/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5967 (0.6691) acc 78.1250 (81.7188) lr 1.3137e-04 eta 0:02:32
epoch [169/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.4736 (0.6688) acc 84.3750 (81.6667) lr 1.3137e-04 eta 0:02:29
epoch [169/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.3979 (0.6815) acc 84.3750 (81.2500) lr 1.2369e-04 eta 0:02:27
epoch [170/200] batch [5/50] time 0.086 (0.196) data 0.000 (0.111) loss 0.8994 (0.8638) acc 81.2500 (80.0000) lr 1.2369e-04 eta 0:05:03
epoch [170/200] batch [10/50] time 0.085 (0.141) data 0.000 (0.055) loss 0.5864 (0.7332) acc 87.5000 (82.8125) lr 1.2369e-04 eta 0:03:36
epoch [170/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 0.6851 (0.7146) acc 87.5000 (83.9583) lr 1.2369e-04 eta 0:03:07
epoch [170/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.028) loss 0.6587 (0.7286) acc 81.2500 (83.1250) lr 1.2369e-04 eta 0:02:52
epoch [170/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.6431 (0.7261) acc 84.3750 (82.2500) lr 1.2369e-04 eta 0:02:43
epoch [170/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.8120 (0.7360) acc 75.0000 (81.6667) lr 1.2369e-04 eta 0:02:37
epoch [170/200] batch [35/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.7773 (0.7615) acc 81.2500 (80.9821) lr 1.2369e-04 eta 0:02:32
epoch [170/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.014) loss 0.6235 (0.7394) acc 84.3750 (81.4844) lr 1.2369e-04 eta 0:02:29
epoch [170/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7729 (0.7436) acc 81.2500 (81.3194) lr 1.2369e-04 eta 0:02:26
epoch [170/200] batch [50/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.7422 (0.7473) acc 84.3750 (81.2500) lr 1.1623e-04 eta 0:02:23
epoch [171/200] batch [5/50] time 0.083 (0.186) data 0.000 (0.101) loss 0.6206 (0.6623) acc 78.1250 (78.1250) lr 1.1623e-04 eta 0:04:38
epoch [171/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.4810 (0.6500) acc 87.5000 (79.0625) lr 1.1623e-04 eta 0:03:22
epoch [171/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.9702 (0.6819) acc 81.2500 (80.6250) lr 1.1623e-04 eta 0:02:55
epoch [171/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.6646 (0.7127) acc 78.1250 (79.8438) lr 1.1623e-04 eta 0:02:42
epoch [171/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.8247 (0.7033) acc 75.0000 (80.3750) lr 1.1623e-04 eta 0:02:34
epoch [171/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.7041 (0.7064) acc 84.3750 (80.4167) lr 1.1623e-04 eta 0:02:28
epoch [171/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.8457 (0.7120) acc 75.0000 (80.4464) lr 1.1623e-04 eta 0:02:24
epoch [171/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5020 (0.6942) acc 84.3750 (81.0156) lr 1.1623e-04 eta 0:02:21
epoch [171/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.3477 (0.7030) acc 93.7500 (80.8333) lr 1.1623e-04 eta 0:02:18
epoch [171/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.5503 (0.7031) acc 84.3750 (80.6250) lr 1.0899e-04 eta 0:02:16
epoch [172/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.098) loss 0.4517 (0.4947) acc 90.6250 (86.2500) lr 1.0899e-04 eta 0:04:25
epoch [172/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 0.7324 (0.6145) acc 75.0000 (82.5000) lr 1.0899e-04 eta 0:03:12
epoch [172/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.2593 (0.5719) acc 87.5000 (84.1667) lr 1.0899e-04 eta 0:02:48
epoch [172/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.6489 (0.6200) acc 90.6250 (83.5938) lr 1.0899e-04 eta 0:02:36
epoch [172/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.6514 (0.6509) acc 81.2500 (82.5000) lr 1.0899e-04 eta 0:02:28
epoch [172/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.9634 (0.6716) acc 78.1250 (82.3958) lr 1.0899e-04 eta 0:02:23
epoch [172/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.4668 (0.6536) acc 87.5000 (82.5893) lr 1.0899e-04 eta 0:02:19
epoch [172/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6636 (0.6694) acc 81.2500 (82.2656) lr 1.0899e-04 eta 0:02:16
epoch [172/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.6934 (0.6922) acc 50.0000 (81.5972) lr 1.0899e-04 eta 0:02:14
epoch [172/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7725 (0.6899) acc 71.8750 (81.4375) lr 1.0197e-04 eta 0:02:11
epoch [173/200] batch [5/50] time 0.084 (0.201) data 0.000 (0.116) loss 0.8247 (0.6835) acc 78.1250 (83.7500) lr 1.0197e-04 eta 0:04:39
epoch [173/200] batch [10/50] time 0.084 (0.143) data 0.000 (0.058) loss 0.4680 (0.6074) acc 87.5000 (84.6875) lr 1.0197e-04 eta 0:03:18
epoch [173/200] batch [15/50] time 0.085 (0.123) data 0.000 (0.039) loss 1.5352 (0.6942) acc 65.6250 (82.5000) lr 1.0197e-04 eta 0:02:50
epoch [173/200] batch [20/50] time 0.084 (0.113) data 0.000 (0.029) loss 0.8179 (0.6862) acc 87.5000 (82.6562) lr 1.0197e-04 eta 0:02:36
epoch [173/200] batch [25/50] time 0.085 (0.108) data 0.001 (0.023) loss 1.0713 (0.6927) acc 75.0000 (82.3750) lr 1.0197e-04 eta 0:02:27
epoch [173/200] batch [30/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.7788 (0.7054) acc 81.2500 (81.7708) lr 1.0197e-04 eta 0:02:22
epoch [173/200] batch [35/50] time 0.085 (0.101) data 0.001 (0.017) loss 0.8418 (0.7048) acc 81.2500 (81.6964) lr 1.0197e-04 eta 0:02:17
epoch [173/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.5347 (0.7011) acc 87.5000 (81.8750) lr 1.0197e-04 eta 0:02:14
epoch [173/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5615 (0.6860) acc 87.5000 (82.2917) lr 1.0197e-04 eta 0:02:11
epoch [173/200] batch [50/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7383 (0.6954) acc 81.2500 (82.0625) lr 9.5173e-05 eta 0:02:09
epoch [174/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.106) loss 0.6367 (0.7575) acc 87.5000 (78.7500) lr 9.5173e-05 eta 0:04:16
epoch [174/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.5928 (0.6321) acc 87.5000 (83.4375) lr 9.5173e-05 eta 0:03:04
epoch [174/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.3535 (0.6895) acc 75.0000 (83.1250) lr 9.5173e-05 eta 0:02:40
epoch [174/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.9185 (0.7066) acc 84.3750 (82.6562) lr 9.5173e-05 eta 0:02:27
epoch [174/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.4019 (0.6840) acc 90.6250 (83.1250) lr 9.5173e-05 eta 0:02:20
epoch [174/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6719 (0.7088) acc 84.3750 (82.1875) lr 9.5173e-05 eta 0:02:14
epoch [174/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.015) loss 0.8477 (0.7170) acc 78.1250 (81.7857) lr 9.5173e-05 eta 0:02:11
epoch [174/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4373 (0.7108) acc 90.6250 (81.6406) lr 9.5173e-05 eta 0:02:07
epoch [174/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9111 (0.7002) acc 78.1250 (81.8750) lr 9.5173e-05 eta 0:02:05
epoch [174/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9302 (0.6998) acc 84.3750 (82.1250) lr 8.8597e-05 eta 0:02:03
epoch [175/200] batch [5/50] time 0.084 (0.201) data 0.000 (0.116) loss 0.6064 (0.6509) acc 87.5000 (84.3750) lr 8.8597e-05 eta 0:04:20
epoch [175/200] batch [10/50] time 0.086 (0.143) data 0.000 (0.058) loss 0.8955 (0.7051) acc 84.3750 (83.4375) lr 8.8597e-05 eta 0:03:04
epoch [175/200] batch [15/50] time 0.084 (0.123) data 0.000 (0.039) loss 0.3496 (0.7075) acc 90.6250 (82.9167) lr 8.8597e-05 eta 0:02:38
epoch [175/200] batch [20/50] time 0.083 (0.113) data 0.000 (0.029) loss 0.7339 (0.6926) acc 81.2500 (83.4375) lr 8.8597e-05 eta 0:02:25
epoch [175/200] batch [25/50] time 0.084 (0.108) data 0.000 (0.023) loss 0.6797 (0.6892) acc 81.2500 (83.3750) lr 8.8597e-05 eta 0:02:17
epoch [175/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.4839 (0.6833) acc 84.3750 (82.9167) lr 8.8597e-05 eta 0:02:11
epoch [175/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.7212 (0.6983) acc 78.1250 (82.0536) lr 8.8597e-05 eta 0:02:07
epoch [175/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.7539 (0.6882) acc 87.5000 (82.1094) lr 8.8597e-05 eta 0:02:04
epoch [175/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0449 (0.7004) acc 78.1250 (81.8750) lr 8.8597e-05 eta 0:02:01
epoch [175/200] batch [50/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9160 (0.7076) acc 71.8750 (81.5000) lr 8.2245e-05 eta 0:01:59
epoch [176/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.109) loss 0.7925 (0.6616) acc 81.2500 (81.8750) lr 8.2245e-05 eta 0:04:02
epoch [176/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.6533 (0.5545) acc 81.2500 (85.3125) lr 8.2245e-05 eta 0:02:53
epoch [176/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 0.5908 (0.6573) acc 78.1250 (82.2917) lr 8.2245e-05 eta 0:02:29
epoch [176/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.7822 (0.6267) acc 81.2500 (83.7500) lr 8.2245e-05 eta 0:02:17
epoch [176/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.4985 (0.6166) acc 90.6250 (84.2500) lr 8.2245e-05 eta 0:02:10
epoch [176/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.8057 (0.6279) acc 84.3750 (84.0625) lr 8.2245e-05 eta 0:02:05
epoch [176/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7437 (0.6363) acc 78.1250 (83.4821) lr 8.2245e-05 eta 0:02:01
epoch [176/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.2363 (0.6656) acc 62.5000 (82.1875) lr 8.2245e-05 eta 0:01:58
epoch [176/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5620 (0.6621) acc 87.5000 (82.1528) lr 8.2245e-05 eta 0:01:56
epoch [176/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.3972 (0.6591) acc 90.6250 (82.2500) lr 7.6120e-05 eta 0:01:54
epoch [177/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.100) loss 0.6167 (0.6449) acc 84.3750 (83.1250) lr 7.6120e-05 eta 0:03:42
epoch [177/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.4771 (0.6539) acc 90.6250 (84.0625) lr 7.6120e-05 eta 0:02:40
epoch [177/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.9785 (0.7109) acc 81.2500 (82.7083) lr 7.6120e-05 eta 0:02:20
epoch [177/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.4292 (0.6697) acc 81.2500 (83.4375) lr 7.6120e-05 eta 0:02:09
epoch [177/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.5156 (0.6748) acc 90.6250 (83.2500) lr 7.6120e-05 eta 0:02:03
epoch [177/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6899 (0.6601) acc 81.2500 (83.0208) lr 7.6120e-05 eta 0:01:58
epoch [177/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.6104 (0.6690) acc 87.5000 (82.5893) lr 7.6120e-05 eta 0:01:55
epoch [177/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8652 (0.6591) acc 75.0000 (82.8125) lr 7.6120e-05 eta 0:01:52
epoch [177/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.6074 (0.6754) acc 81.2500 (82.7083) lr 7.6120e-05 eta 0:01:50
epoch [177/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7275 (0.6726) acc 68.7500 (82.4375) lr 7.0224e-05 eta 0:01:48
epoch [178/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 0.5605 (0.6616) acc 78.1250 (81.2500) lr 7.0224e-05 eta 0:03:40
epoch [178/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.4973 (0.7332) acc 84.3750 (78.1250) lr 7.0224e-05 eta 0:02:38
epoch [178/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.7788 (0.6840) acc 78.1250 (80.0000) lr 7.0224e-05 eta 0:02:17
epoch [178/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.5215 (0.6786) acc 93.7500 (80.6250) lr 7.0224e-05 eta 0:02:06
epoch [178/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.9888 (0.7298) acc 78.1250 (79.7500) lr 7.0224e-05 eta 0:01:59
epoch [178/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.4609 (0.7388) acc 87.5000 (79.2708) lr 7.0224e-05 eta 0:01:55
epoch [178/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.016) loss 0.8257 (0.7274) acc 84.3750 (79.7321) lr 7.0224e-05 eta 0:01:51
epoch [178/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.3459 (0.7207) acc 90.6250 (79.6094) lr 7.0224e-05 eta 0:01:49
epoch [178/200] batch [45/50] time 0.085 (0.097) data 0.000 (0.012) loss 0.4180 (0.7155) acc 90.6250 (80.0694) lr 7.0224e-05 eta 0:01:46
epoch [178/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5649 (0.7123) acc 81.2500 (80.1875) lr 6.4556e-05 eta 0:01:44
epoch [179/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.105) loss 0.4624 (0.6622) acc 90.6250 (82.5000) lr 6.4556e-05 eta 0:03:28
epoch [179/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.052) loss 0.5542 (0.6124) acc 78.1250 (83.4375) lr 6.4556e-05 eta 0:02:30
epoch [179/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.5903 (0.5730) acc 87.5000 (84.1667) lr 6.4556e-05 eta 0:02:10
epoch [179/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.9922 (0.6271) acc 75.0000 (82.6562) lr 6.4556e-05 eta 0:02:00
epoch [179/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.4556 (0.6093) acc 87.5000 (83.1250) lr 6.4556e-05 eta 0:01:53
epoch [179/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.3220 (0.6272) acc 90.6250 (82.1875) lr 6.4556e-05 eta 0:01:49
epoch [179/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.7803 (0.6231) acc 71.8750 (82.4107) lr 6.4556e-05 eta 0:01:46
epoch [179/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.6382 (0.6392) acc 81.2500 (81.7188) lr 6.4556e-05 eta 0:01:43
epoch [179/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.1748 (0.6534) acc 75.0000 (81.5972) lr 6.4556e-05 eta 0:01:41
epoch [179/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8989 (0.6643) acc 81.2500 (81.6875) lr 5.9119e-05 eta 0:01:39
epoch [180/200] batch [5/50] time 0.085 (0.196) data 0.000 (0.111) loss 0.6714 (0.7515) acc 78.1250 (80.6250) lr 5.9119e-05 eta 0:03:24
epoch [180/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.6021 (0.7102) acc 81.2500 (81.8750) lr 5.9119e-05 eta 0:02:26
epoch [180/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 0.5513 (0.6877) acc 84.3750 (82.0833) lr 5.9119e-05 eta 0:02:06
epoch [180/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.028) loss 0.5371 (0.6502) acc 81.2500 (82.8125) lr 5.9119e-05 eta 0:01:56
epoch [180/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.8931 (0.6941) acc 78.1250 (81.6250) lr 5.9119e-05 eta 0:01:49
epoch [180/200] batch [30/50] time 0.086 (0.103) data 0.000 (0.019) loss 0.5537 (0.6852) acc 81.2500 (81.4583) lr 5.9119e-05 eta 0:01:45
epoch [180/200] batch [35/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.6533 (0.6865) acc 84.3750 (81.7857) lr 5.9119e-05 eta 0:01:42
epoch [180/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.7271 (0.6797) acc 81.2500 (82.0312) lr 5.9119e-05 eta 0:01:39
epoch [180/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6758 (0.6635) acc 87.5000 (82.5694) lr 5.9119e-05 eta 0:01:37
epoch [180/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.5967 (0.6627) acc 81.2500 (82.5625) lr 5.3915e-05 eta 0:01:35
epoch [181/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.098) loss 0.4893 (0.7710) acc 84.3750 (81.8750) lr 5.3915e-05 eta 0:03:02
epoch [181/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 1.1719 (0.7561) acc 68.7500 (80.3125) lr 5.3915e-05 eta 0:02:12
epoch [181/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.6206 (0.6699) acc 78.1250 (82.0833) lr 5.3915e-05 eta 0:01:55
epoch [181/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.6592 (0.7083) acc 87.5000 (81.8750) lr 5.3915e-05 eta 0:01:47
epoch [181/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.4050 (0.7245) acc 84.3750 (81.5000) lr 5.3915e-05 eta 0:01:41
epoch [181/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.017) loss 0.7520 (0.7237) acc 81.2500 (81.4583) lr 5.3915e-05 eta 0:01:37
epoch [181/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.8633 (0.7355) acc 78.1250 (80.8929) lr 5.3915e-05 eta 0:01:35
epoch [181/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.9771 (0.7350) acc 75.0000 (80.8594) lr 5.3915e-05 eta 0:01:32
epoch [181/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5479 (0.7248) acc 90.6250 (81.3194) lr 5.3915e-05 eta 0:01:30
epoch [181/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6279 (0.7149) acc 75.0000 (81.5625) lr 4.8943e-05 eta 0:01:29
epoch [182/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.106) loss 0.5586 (0.7094) acc 81.2500 (80.6250) lr 4.8943e-05 eta 0:03:00
epoch [182/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.053) loss 0.4626 (0.6420) acc 84.3750 (82.8125) lr 4.8943e-05 eta 0:02:09
epoch [182/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.7720 (0.6812) acc 78.1250 (81.2500) lr 4.8943e-05 eta 0:01:51
epoch [182/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.2686 (0.6479) acc 93.7500 (82.0312) lr 4.8943e-05 eta 0:01:42
epoch [182/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.4082 (0.6388) acc 87.5000 (82.1250) lr 4.8943e-05 eta 0:01:37
epoch [182/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.8989 (0.6733) acc 71.8750 (81.0417) lr 4.8943e-05 eta 0:01:33
epoch [182/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.5371 (0.6512) acc 84.3750 (81.6071) lr 4.8943e-05 eta 0:01:30
epoch [182/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.4221 (0.6593) acc 84.3750 (81.5625) lr 4.8943e-05 eta 0:01:28
epoch [182/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8823 (0.6691) acc 68.7500 (81.3194) lr 4.8943e-05 eta 0:01:26
epoch [182/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9995 (0.6832) acc 78.1250 (80.9375) lr 4.4207e-05 eta 0:01:25
epoch [183/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.107) loss 0.3735 (0.5952) acc 87.5000 (83.7500) lr 4.4207e-05 eta 0:02:51
epoch [183/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.6475 (0.6444) acc 81.2500 (82.1875) lr 4.4207e-05 eta 0:02:03
epoch [183/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.5039 (0.6999) acc 56.2500 (79.7917) lr 4.4207e-05 eta 0:01:46
epoch [183/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.4873 (0.6760) acc 93.7500 (80.6250) lr 4.4207e-05 eta 0:01:37
epoch [183/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.6035 (0.7331) acc 75.0000 (79.2500) lr 4.4207e-05 eta 0:01:32
epoch [183/200] batch [30/50] time 0.086 (0.103) data 0.000 (0.018) loss 0.7031 (0.7133) acc 78.1250 (79.6875) lr 4.4207e-05 eta 0:01:29
epoch [183/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.9771 (0.7096) acc 78.1250 (80.0000) lr 4.4207e-05 eta 0:01:26
epoch [183/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7217 (0.7344) acc 78.1250 (79.4531) lr 4.4207e-05 eta 0:01:24
epoch [183/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6484 (0.7225) acc 81.2500 (79.7222) lr 4.4207e-05 eta 0:01:22
epoch [183/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7695 (0.7148) acc 84.3750 (79.9375) lr 3.9706e-05 eta 0:01:20
epoch [184/200] batch [5/50] time 0.084 (0.197) data 0.000 (0.112) loss 0.7412 (0.8103) acc 81.2500 (76.8750) lr 3.9706e-05 eta 0:02:46
epoch [184/200] batch [10/50] time 0.084 (0.141) data 0.000 (0.056) loss 0.6235 (0.6834) acc 84.3750 (80.9375) lr 3.9706e-05 eta 0:01:58
epoch [184/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.038) loss 0.6006 (0.6653) acc 87.5000 (81.6667) lr 3.9706e-05 eta 0:01:41
epoch [184/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.4954 (0.7156) acc 87.5000 (80.4688) lr 3.9706e-05 eta 0:01:33
epoch [184/200] batch [25/50] time 0.086 (0.107) data 0.000 (0.023) loss 0.5894 (0.7438) acc 78.1250 (80.1250) lr 3.9706e-05 eta 0:01:28
epoch [184/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 1.0859 (0.7373) acc 62.5000 (80.0000) lr 3.9706e-05 eta 0:01:24
epoch [184/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.7969 (0.7344) acc 75.0000 (80.2679) lr 3.9706e-05 eta 0:01:21
epoch [184/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9185 (0.7485) acc 75.0000 (80.0781) lr 3.9706e-05 eta 0:01:19
epoch [184/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6528 (0.7461) acc 87.5000 (80.2778) lr 3.9706e-05 eta 0:01:17
epoch [184/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0713 (0.7392) acc 75.0000 (80.2500) lr 3.5443e-05 eta 0:01:16
epoch [185/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.108) loss 0.8286 (0.6361) acc 78.1250 (84.3750) lr 3.5443e-05 eta 0:02:33
epoch [185/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.7314 (0.6138) acc 78.1250 (83.4375) lr 3.5443e-05 eta 0:01:49
epoch [185/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.8799 (0.6957) acc 75.0000 (81.6667) lr 3.5443e-05 eta 0:01:34
epoch [185/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.2057 (0.6437) acc 96.8750 (83.1250) lr 3.5443e-05 eta 0:01:26
epoch [185/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.7305 (0.6610) acc 75.0000 (82.5000) lr 3.5443e-05 eta 0:01:22
epoch [185/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.8306 (0.6728) acc 78.1250 (82.3958) lr 3.5443e-05 eta 0:01:18
epoch [185/200] batch [35/50] time 0.083 (0.100) data 0.000 (0.016) loss 0.7163 (0.6700) acc 78.1250 (82.1429) lr 3.5443e-05 eta 0:01:16
epoch [185/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.3401 (0.6768) acc 87.5000 (82.1875) lr 3.5443e-05 eta 0:01:14
epoch [185/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6055 (0.6753) acc 84.3750 (82.2222) lr 3.5443e-05 eta 0:01:12
epoch [185/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6216 (0.6687) acc 81.2500 (82.3125) lr 3.1417e-05 eta 0:01:11
epoch [186/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.099) loss 0.9087 (0.6993) acc 75.0000 (82.5000) lr 3.1417e-05 eta 0:02:17
epoch [186/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.5181 (0.6385) acc 87.5000 (84.6875) lr 3.1417e-05 eta 0:01:39
epoch [186/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.8843 (0.7347) acc 78.1250 (81.6667) lr 3.1417e-05 eta 0:01:26
epoch [186/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.9805 (0.7159) acc 78.1250 (82.1875) lr 3.1417e-05 eta 0:01:20
epoch [186/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.3721 (0.6969) acc 90.6250 (82.0000) lr 3.1417e-05 eta 0:01:15
epoch [186/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8315 (0.6956) acc 71.8750 (81.6667) lr 3.1417e-05 eta 0:01:12
epoch [186/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 0.7124 (0.7117) acc 81.2500 (81.3393) lr 3.1417e-05 eta 0:01:10
epoch [186/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.4390 (0.6940) acc 87.5000 (81.7969) lr 3.1417e-05 eta 0:01:08
epoch [186/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6318 (0.6851) acc 84.3750 (82.2917) lr 3.1417e-05 eta 0:01:07
epoch [186/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5171 (0.6973) acc 84.3750 (82.0000) lr 2.7630e-05 eta 0:01:05
epoch [187/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.102) loss 0.6289 (0.6520) acc 81.2500 (83.1250) lr 2.7630e-05 eta 0:02:10
epoch [187/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 1.0508 (0.7047) acc 75.0000 (82.5000) lr 2.7630e-05 eta 0:01:33
epoch [187/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.6753 (0.6604) acc 71.8750 (82.5000) lr 2.7630e-05 eta 0:01:21
epoch [187/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.5864 (0.6923) acc 84.3750 (81.7188) lr 2.7630e-05 eta 0:01:14
epoch [187/200] batch [25/50] time 0.083 (0.105) data 0.000 (0.021) loss 0.4990 (0.6960) acc 87.5000 (82.0000) lr 2.7630e-05 eta 0:01:10
epoch [187/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.8164 (0.6751) acc 75.0000 (82.6042) lr 2.7630e-05 eta 0:01:07
epoch [187/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.8135 (0.6849) acc 75.0000 (82.0536) lr 2.7630e-05 eta 0:01:05
epoch [187/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0098 (0.6824) acc 75.0000 (82.3438) lr 2.7630e-05 eta 0:01:04
epoch [187/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.012) loss 0.1501 (0.6782) acc 93.7500 (81.9444) lr 2.7630e-05 eta 0:01:02
epoch [187/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7671 (0.6685) acc 75.0000 (82.0000) lr 2.4083e-05 eta 0:01:01
epoch [188/200] batch [5/50] time 0.084 (0.195) data 0.000 (0.110) loss 0.5645 (0.7540) acc 84.3750 (81.8750) lr 2.4083e-05 eta 0:02:05
epoch [188/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.055) loss 0.7354 (0.7723) acc 75.0000 (80.9375) lr 2.4083e-05 eta 0:01:29
epoch [188/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 0.6973 (0.7462) acc 81.2500 (81.4583) lr 2.4083e-05 eta 0:01:17
epoch [188/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.5786 (0.7014) acc 87.5000 (82.8125) lr 2.4083e-05 eta 0:01:10
epoch [188/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 0.4617 (0.6741) acc 84.3750 (82.7500) lr 2.4083e-05 eta 0:01:06
epoch [188/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.7290 (0.6622) acc 81.2500 (82.8125) lr 2.4083e-05 eta 0:01:03
epoch [188/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.4690 (0.6586) acc 90.6250 (82.8571) lr 2.4083e-05 eta 0:01:01
epoch [188/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7739 (0.6888) acc 81.2500 (81.9531) lr 2.4083e-05 eta 0:00:59
epoch [188/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.7188 (0.6923) acc 81.2500 (81.9444) lr 2.4083e-05 eta 0:00:58
epoch [188/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8218 (0.6952) acc 75.0000 (81.7500) lr 2.0777e-05 eta 0:00:57
epoch [189/200] batch [5/50] time 0.087 (0.192) data 0.000 (0.107) loss 0.4902 (0.5903) acc 90.6250 (83.1250) lr 2.0777e-05 eta 0:01:54
epoch [189/200] batch [10/50] time 0.083 (0.138) data 0.000 (0.054) loss 0.7920 (0.6076) acc 75.0000 (82.8125) lr 2.0777e-05 eta 0:01:21
epoch [189/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.0703 (0.6815) acc 71.8750 (80.6250) lr 2.0777e-05 eta 0:01:10
epoch [189/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.8335 (0.6633) acc 75.0000 (81.0938) lr 2.0777e-05 eta 0:01:04
epoch [189/200] batch [25/50] time 0.083 (0.105) data 0.000 (0.022) loss 0.6958 (0.6673) acc 71.8750 (80.6250) lr 2.0777e-05 eta 0:01:00
epoch [189/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6475 (0.6726) acc 81.2500 (81.0417) lr 2.0777e-05 eta 0:00:58
epoch [189/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.6270 (0.6513) acc 84.3750 (81.5179) lr 2.0777e-05 eta 0:00:56
epoch [189/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.6802 (0.6651) acc 75.0000 (81.3281) lr 2.0777e-05 eta 0:00:54
epoch [189/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6855 (0.6921) acc 84.3750 (80.6944) lr 2.0777e-05 eta 0:00:53
epoch [189/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.9136 (0.6950) acc 81.2500 (80.6250) lr 1.7713e-05 eta 0:00:51
epoch [190/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.102) loss 0.4297 (0.7115) acc 90.6250 (80.0000) lr 1.7713e-05 eta 0:01:42
epoch [190/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 1.0293 (0.7295) acc 71.8750 (80.6250) lr 1.7713e-05 eta 0:01:13
epoch [190/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.4861 (0.7217) acc 87.5000 (80.6250) lr 1.7713e-05 eta 0:01:03
epoch [190/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.2959 (0.6682) acc 90.6250 (82.0312) lr 1.7713e-05 eta 0:00:58
epoch [190/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.3953 (0.6858) acc 93.7500 (81.8750) lr 1.7713e-05 eta 0:00:55
epoch [190/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.3018 (0.7449) acc 75.0000 (80.2083) lr 1.7713e-05 eta 0:00:53
epoch [190/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.9639 (0.7495) acc 75.0000 (80.1786) lr 1.7713e-05 eta 0:00:51
epoch [190/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.6934 (0.7401) acc 84.3750 (80.0781) lr 1.7713e-05 eta 0:00:49
epoch [190/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.3403 (0.7216) acc 90.6250 (80.6250) lr 1.7713e-05 eta 0:00:48
epoch [190/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.5894 (0.6990) acc 78.1250 (80.9375) lr 1.4891e-05 eta 0:00:47
epoch [191/200] batch [5/50] time 0.086 (0.198) data 0.000 (0.112) loss 0.8408 (0.7872) acc 81.2500 (80.6250) lr 1.4891e-05 eta 0:01:37
epoch [191/200] batch [10/50] time 0.085 (0.141) data 0.000 (0.056) loss 0.2625 (0.7275) acc 96.8750 (82.8125) lr 1.4891e-05 eta 0:01:09
epoch [191/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.037) loss 1.1689 (0.6956) acc 71.8750 (82.9167) lr 1.4891e-05 eta 0:00:59
epoch [191/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.028) loss 0.3811 (0.6745) acc 90.6250 (82.9688) lr 1.4891e-05 eta 0:00:54
epoch [191/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.023) loss 0.5508 (0.6880) acc 84.3750 (82.2500) lr 1.4891e-05 eta 0:00:50
epoch [191/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.5186 (0.6911) acc 84.3750 (81.9792) lr 1.4891e-05 eta 0:00:48
epoch [191/200] batch [35/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.8281 (0.7028) acc 81.2500 (81.8750) lr 1.4891e-05 eta 0:00:46
epoch [191/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.014) loss 0.4724 (0.7114) acc 87.5000 (81.5625) lr 1.4891e-05 eta 0:00:45
epoch [191/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6250 (0.6927) acc 81.2500 (82.0139) lr 1.4891e-05 eta 0:00:44
epoch [191/200] batch [50/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.5337 (0.6939) acc 84.3750 (81.9375) lr 1.2312e-05 eta 0:00:43
epoch [192/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.100) loss 0.1145 (0.6091) acc 100.0000 (82.5000) lr 1.2312e-05 eta 0:01:22
epoch [192/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.8706 (0.6637) acc 78.1250 (82.1875) lr 1.2312e-05 eta 0:00:59
epoch [192/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.1533 (0.6856) acc 75.0000 (81.8750) lr 1.2312e-05 eta 0:00:51
epoch [192/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.8716 (0.6956) acc 84.3750 (82.1875) lr 1.2312e-05 eta 0:00:47
epoch [192/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.5547 (0.6847) acc 84.3750 (81.8750) lr 1.2312e-05 eta 0:00:44
epoch [192/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8262 (0.6823) acc 84.3750 (82.0833) lr 1.2312e-05 eta 0:00:42
epoch [192/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.9873 (0.6891) acc 75.0000 (81.7857) lr 1.2312e-05 eta 0:00:40
epoch [192/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5708 (0.6894) acc 78.1250 (81.3281) lr 1.2312e-05 eta 0:00:39
epoch [192/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9844 (0.6976) acc 78.1250 (81.1806) lr 1.2312e-05 eta 0:00:38
epoch [192/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7612 (0.7167) acc 78.1250 (80.7500) lr 9.9763e-06 eta 0:00:37
epoch [193/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 1.1846 (0.9074) acc 71.8750 (77.5000) lr 9.9763e-06 eta 0:01:11
epoch [193/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.9355 (0.8604) acc 78.1250 (77.8125) lr 9.9763e-06 eta 0:00:51
epoch [193/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.032) loss 0.5781 (0.7859) acc 78.1250 (79.1667) lr 9.9763e-06 eta 0:00:44
epoch [193/200] batch [20/50] time 0.083 (0.108) data 0.000 (0.024) loss 0.6963 (0.7352) acc 81.2500 (79.5312) lr 9.9763e-06 eta 0:00:41
epoch [193/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.3906 (0.7417) acc 87.5000 (79.2500) lr 9.9763e-06 eta 0:00:38
epoch [193/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6963 (0.7312) acc 81.2500 (79.8958) lr 9.9763e-06 eta 0:00:37
epoch [193/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.3884 (0.7113) acc 90.6250 (80.9821) lr 9.9763e-06 eta 0:00:35
epoch [193/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8306 (0.6992) acc 75.0000 (81.4062) lr 9.9763e-06 eta 0:00:34
epoch [193/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6143 (0.7179) acc 84.3750 (80.8333) lr 9.9763e-06 eta 0:00:33
epoch [193/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.010) loss 0.4746 (0.7050) acc 81.2500 (81.0000) lr 7.8853e-06 eta 0:00:32
epoch [194/200] batch [5/50] time 0.085 (0.196) data 0.000 (0.112) loss 0.5322 (0.6685) acc 87.5000 (84.3750) lr 7.8853e-06 eta 0:01:07
epoch [194/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.056) loss 0.5518 (0.6259) acc 87.5000 (84.6875) lr 7.8853e-06 eta 0:00:47
epoch [194/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 0.8892 (0.6626) acc 78.1250 (83.5417) lr 7.8853e-06 eta 0:00:40
epoch [194/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.028) loss 0.8877 (0.6864) acc 81.2500 (83.2812) lr 7.8853e-06 eta 0:00:37
epoch [194/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.023) loss 0.6133 (0.6782) acc 78.1250 (83.1250) lr 7.8853e-06 eta 0:00:34
epoch [194/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.5518 (0.6698) acc 87.5000 (83.3333) lr 7.8853e-06 eta 0:00:33
epoch [194/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.9019 (0.6687) acc 68.7500 (82.8571) lr 7.8853e-06 eta 0:00:31
epoch [194/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5000 (0.6681) acc 84.3750 (82.5000) lr 7.8853e-06 eta 0:00:30
epoch [194/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6318 (0.6748) acc 87.5000 (82.2917) lr 7.8853e-06 eta 0:00:29
epoch [194/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5303 (0.6895) acc 78.1250 (81.6250) lr 6.0390e-06 eta 0:00:28
epoch [195/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.099) loss 0.6060 (0.7489) acc 78.1250 (76.2500) lr 6.0390e-06 eta 0:00:54
epoch [195/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.050) loss 0.5645 (0.6876) acc 84.3750 (79.6875) lr 6.0390e-06 eta 0:00:39
epoch [195/200] batch [15/50] time 0.086 (0.119) data 0.000 (0.033) loss 0.6494 (0.6923) acc 78.1250 (80.6250) lr 6.0390e-06 eta 0:00:33
epoch [195/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.5596 (0.7098) acc 81.2500 (80.9375) lr 6.0390e-06 eta 0:00:30
epoch [195/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.9126 (0.7453) acc 81.2500 (80.5000) lr 6.0390e-06 eta 0:00:28
epoch [195/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.5752 (0.7200) acc 81.2500 (81.1458) lr 6.0390e-06 eta 0:00:27
epoch [195/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.5825 (0.7072) acc 81.2500 (81.4286) lr 6.0390e-06 eta 0:00:26
epoch [195/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.0391 (0.7124) acc 75.0000 (81.5625) lr 6.0390e-06 eta 0:00:25
epoch [195/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.3057 (0.6992) acc 93.7500 (81.4583) lr 6.0390e-06 eta 0:00:24
epoch [195/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.3379 (0.6875) acc 93.7500 (81.8125) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 0.5962 (0.7125) acc 84.3750 (78.7500) lr 4.4380e-06 eta 0:00:47
epoch [196/200] batch [10/50] time 0.085 (0.139) data 0.001 (0.054) loss 0.9326 (0.6774) acc 84.3750 (81.8750) lr 4.4380e-06 eta 0:00:33
epoch [196/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 0.6670 (0.7055) acc 81.2500 (81.4583) lr 4.4380e-06 eta 0:00:28
epoch [196/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.4929 (0.6889) acc 87.5000 (81.7188) lr 4.4380e-06 eta 0:00:25
epoch [196/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.9971 (0.6900) acc 75.0000 (81.6250) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 1.1055 (0.7113) acc 65.6250 (80.8333) lr 4.4380e-06 eta 0:00:22
epoch [196/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.0508 (0.7146) acc 71.8750 (80.7143) lr 4.4380e-06 eta 0:00:21
epoch [196/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.6968 (0.7152) acc 87.5000 (80.7031) lr 4.4380e-06 eta 0:00:20
epoch [196/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.8594 (0.7375) acc 75.0000 (80.0694) lr 4.4380e-06 eta 0:00:19
epoch [196/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5830 (0.7347) acc 87.5000 (80.1875) lr 3.0827e-06 eta 0:00:19
epoch [197/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.107) loss 0.8569 (0.7490) acc 75.0000 (80.0000) lr 3.0827e-06 eta 0:00:37
epoch [197/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.6899 (0.6900) acc 84.3750 (83.7500) lr 3.0827e-06 eta 0:00:26
epoch [197/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.4563 (0.6687) acc 78.1250 (82.9167) lr 3.0827e-06 eta 0:00:22
epoch [197/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.7031 (0.6605) acc 78.1250 (82.3438) lr 3.0827e-06 eta 0:00:20
epoch [197/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 1.1465 (0.6807) acc 65.6250 (81.5000) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.5000 (0.7015) acc 84.3750 (81.2500) lr 3.0827e-06 eta 0:00:17
epoch [197/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.016) loss 0.9312 (0.7040) acc 75.0000 (81.3393) lr 3.0827e-06 eta 0:00:16
epoch [197/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.8560 (0.7081) acc 78.1250 (81.1719) lr 3.0827e-06 eta 0:00:15
epoch [197/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.7515 (0.6959) acc 84.3750 (81.5972) lr 3.0827e-06 eta 0:00:14
epoch [197/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8408 (0.6898) acc 87.5000 (82.0625) lr 1.9733e-06 eta 0:00:14
epoch [198/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.108) loss 0.4878 (0.8239) acc 87.5000 (78.7500) lr 1.9733e-06 eta 0:00:28
epoch [198/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.6138 (0.7334) acc 87.5000 (80.9375) lr 1.9733e-06 eta 0:00:19
epoch [198/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.5171 (0.6974) acc 84.3750 (82.7083) lr 1.9733e-06 eta 0:00:16
epoch [198/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.9463 (0.7032) acc 68.7500 (82.0312) lr 1.9733e-06 eta 0:00:14
epoch [198/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 1.2178 (0.6974) acc 65.6250 (82.1250) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.8936 (0.7278) acc 84.3750 (81.6667) lr 1.9733e-06 eta 0:00:12
epoch [198/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.5220 (0.7210) acc 87.5000 (81.1607) lr 1.9733e-06 eta 0:00:11
epoch [198/200] batch [40/50] time 0.088 (0.098) data 0.000 (0.014) loss 0.2646 (0.7110) acc 90.6250 (81.4844) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.6489 (0.7140) acc 81.2500 (81.5972) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9551 (0.7308) acc 78.1250 (81.1875) lr 1.1101e-06 eta 0:00:09
epoch [199/200] batch [5/50] time 0.085 (0.198) data 0.000 (0.113) loss 1.0518 (0.7345) acc 68.7500 (77.5000) lr 1.1101e-06 eta 0:00:18
epoch [199/200] batch [10/50] time 0.085 (0.141) data 0.000 (0.057) loss 0.4607 (0.7718) acc 84.3750 (77.5000) lr 1.1101e-06 eta 0:00:12
epoch [199/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.038) loss 0.5176 (0.7201) acc 87.5000 (79.5833) lr 1.1101e-06 eta 0:00:10
epoch [199/200] batch [20/50] time 0.083 (0.113) data 0.000 (0.029) loss 0.7261 (0.6960) acc 84.3750 (80.6250) lr 1.1101e-06 eta 0:00:09
epoch [199/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.023) loss 0.7397 (0.6776) acc 81.2500 (81.0000) lr 1.1101e-06 eta 0:00:08
epoch [199/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.4397 (0.6938) acc 81.2500 (80.0000) lr 1.1101e-06 eta 0:00:07
epoch [199/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.5815 (0.6713) acc 81.2500 (80.7143) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.3350 (0.6492) acc 90.6250 (81.4844) lr 1.1101e-06 eta 0:00:05
epoch [199/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.4558 (0.6434) acc 87.5000 (82.0833) lr 1.1101e-06 eta 0:00:05
epoch [199/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.5977 (0.6427) acc 78.1250 (82.0000) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.109) loss 0.9521 (0.7973) acc 71.8750 (79.3750) lr 4.9344e-07 eta 0:00:08
epoch [200/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.055) loss 1.0889 (0.7608) acc 75.0000 (80.3125) lr 4.9344e-07 eta 0:00:05
epoch [200/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 1.0967 (0.7482) acc 68.7500 (80.0000) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 1.1201 (0.7784) acc 68.7500 (79.3750) lr 4.9344e-07 eta 0:00:03
epoch [200/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.5044 (0.7738) acc 84.3750 (79.7500) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.8818 (0.7553) acc 81.2500 (80.0000) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7451 (0.7337) acc 75.0000 (80.5357) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4417 (0.7169) acc 84.3750 (80.6250) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5981 (0.6974) acc 81.2500 (81.1806) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7236 (0.7024) acc 71.8750 (80.9375) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:01<00:56,  1.54s/it]  5%|▌         | 2/38 [00:01<00:25,  1.42it/s]  8%|▊         | 3/38 [00:01<00:15,  2.28it/s] 11%|█         | 4/38 [00:01<00:10,  3.19it/s] 13%|█▎        | 5/38 [00:02<00:08,  4.09it/s] 16%|█▌        | 6/38 [00:02<00:06,  4.93it/s] 18%|█▊        | 7/38 [00:02<00:05,  5.67it/s] 21%|██        | 8/38 [00:02<00:04,  6.28it/s] 24%|██▎       | 9/38 [00:02<00:04,  6.77it/s] 26%|██▋       | 10/38 [00:02<00:03,  7.15it/s] 29%|██▉       | 11/38 [00:02<00:03,  7.43it/s] 32%|███▏      | 12/38 [00:02<00:03,  7.64it/s] 34%|███▍      | 13/38 [00:03<00:03,  7.74it/s] 37%|███▋      | 14/38 [00:03<00:03,  7.88it/s] 39%|███▉      | 15/38 [00:03<00:02,  7.95it/s] 42%|████▏     | 16/38 [00:03<00:02,  8.02it/s] 45%|████▍     | 17/38 [00:03<00:02,  8.06it/s] 47%|████▋     | 18/38 [00:03<00:02,  8.10it/s] 50%|█████     | 19/38 [00:03<00:02,  8.12it/s] 53%|█████▎    | 20/38 [00:03<00:02,  8.14it/s] 55%|█████▌    | 21/38 [00:03<00:02,  8.15it/s] 58%|█████▊    | 22/38 [00:04<00:01,  8.16it/s] 61%|██████    | 23/38 [00:04<00:01,  7.69it/s] 63%|██████▎   | 24/38 [00:04<00:01,  7.85it/s] 66%|██████▌   | 25/38 [00:04<00:01,  7.95it/s] 68%|██████▊   | 26/38 [00:04<00:01,  8.03it/s] 71%|███████   | 27/38 [00:04<00:01,  8.07it/s] 74%|███████▎  | 28/38 [00:04<00:01,  8.11it/s] 76%|███████▋  | 29/38 [00:04<00:01,  8.16it/s] 79%|███████▉  | 30/38 [00:05<00:00,  8.17it/s] 82%|████████▏ | 31/38 [00:05<00:00,  8.19it/s] 84%|████████▍ | 32/38 [00:05<00:00,  8.20it/s] 87%|████████▋ | 33/38 [00:05<00:00,  8.22it/s] 89%|████████▉ | 34/38 [00:05<00:00,  8.23it/s] 92%|█████████▏| 35/38 [00:05<00:00,  8.24it/s] 95%|█████████▍| 36/38 [00:05<00:00,  8.24it/s] 97%|█████████▋| 37/38 [00:05<00:00,  8.24it/s]100%|██████████| 38/38 [00:06<00:00,  8.60it/s]100%|██████████| 38/38 [00:06<00:00,  6.15it/s]
=> result
* total: 3,783
* correct: 3,157
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.6%
Elapsed: 0:16:16
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_train.sh ucf101 2 0 vit_b16_ctxv1 16 CoOp
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_2.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/200] batch [5/50] time 0.084 (0.581) data 0.000 (0.191) loss 1.6504 (1.7311) acc 53.1250 (54.3750) lr 1.0000e-05 eta 1:36:44
epoch [1/200] batch [10/50] time 0.084 (0.332) data 0.000 (0.096) loss 1.4873 (1.8009) acc 53.1250 (54.6875) lr 1.0000e-05 eta 0:55:16
epoch [1/200] batch [15/50] time 0.084 (0.249) data 0.000 (0.064) loss 1.6982 (1.8087) acc 53.1250 (53.9583) lr 1.0000e-05 eta 0:41:28
epoch [1/200] batch [20/50] time 0.084 (0.208) data 0.000 (0.048) loss 2.1289 (1.8143) acc 37.5000 (54.0625) lr 1.0000e-05 eta 0:34:34
epoch [1/200] batch [25/50] time 0.083 (0.183) data 0.000 (0.038) loss 2.0195 (1.8239) acc 43.7500 (53.3750) lr 1.0000e-05 eta 0:30:25
epoch [1/200] batch [30/50] time 0.083 (0.166) data 0.000 (0.032) loss 1.4697 (1.8369) acc 56.2500 (53.4375) lr 1.0000e-05 eta 0:27:39
epoch [1/200] batch [35/50] time 0.084 (0.155) data 0.000 (0.028) loss 1.2256 (1.7831) acc 71.8750 (54.5536) lr 1.0000e-05 eta 0:25:40
epoch [1/200] batch [40/50] time 0.082 (0.146) data 0.000 (0.024) loss 1.7578 (1.7735) acc 46.8750 (55.0000) lr 1.0000e-05 eta 0:24:10
epoch [1/200] batch [45/50] time 0.083 (0.139) data 0.000 (0.021) loss 1.9570 (1.7977) acc 50.0000 (54.3056) lr 1.0000e-05 eta 0:22:59
epoch [1/200] batch [50/50] time 0.083 (0.133) data 0.000 (0.019) loss 1.1182 (1.7605) acc 62.5000 (54.6875) lr 2.0000e-03 eta 0:22:03
epoch [2/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.110) loss 1.0645 (1.5982) acc 71.8750 (59.3750) lr 2.0000e-03 eta 0:32:13
epoch [2/200] batch [10/50] time 0.083 (0.139) data 0.000 (0.055) loss 1.1963 (1.5056) acc 65.6250 (61.8750) lr 2.0000e-03 eta 0:23:01
epoch [2/200] batch [15/50] time 0.083 (0.121) data 0.000 (0.037) loss 1.6172 (1.5254) acc 65.6250 (59.7917) lr 2.0000e-03 eta 0:19:57
epoch [2/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.028) loss 1.5146 (1.5422) acc 65.6250 (58.2812) lr 2.0000e-03 eta 0:18:25
epoch [2/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 1.5195 (1.5240) acc 65.6250 (58.8750) lr 2.0000e-03 eta 0:17:30
epoch [2/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.6475 (1.5595) acc 50.0000 (58.0208) lr 2.0000e-03 eta 0:16:53
epoch [2/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.7412 (1.5665) acc 53.1250 (58.0357) lr 2.0000e-03 eta 0:16:27
epoch [2/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 1.3096 (1.5328) acc 62.5000 (58.6719) lr 2.0000e-03 eta 0:16:05
epoch [2/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8950 (1.5219) acc 75.0000 (58.8889) lr 2.0000e-03 eta 0:15:49
epoch [2/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.6914 (1.5045) acc 59.3750 (59.2500) lr 1.9999e-03 eta 0:15:36
epoch [3/200] batch [5/50] time 0.082 (0.186) data 0.000 (0.102) loss 1.5020 (1.3413) acc 53.1250 (61.2500) lr 1.9999e-03 eta 0:30:41
epoch [3/200] batch [10/50] time 0.083 (0.135) data 0.000 (0.051) loss 1.3896 (1.3251) acc 65.6250 (63.1250) lr 1.9999e-03 eta 0:22:12
epoch [3/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.6572 (1.4259) acc 46.8750 (60.6250) lr 1.9999e-03 eta 0:19:23
epoch [3/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.026) loss 1.8770 (1.4235) acc 46.8750 (60.4688) lr 1.9999e-03 eta 0:18:00
epoch [3/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.021) loss 1.3096 (1.3749) acc 53.1250 (61.5000) lr 1.9999e-03 eta 0:17:08
epoch [3/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.017) loss 0.8003 (1.3634) acc 75.0000 (62.1875) lr 1.9999e-03 eta 0:16:34
epoch [3/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.015) loss 1.4678 (1.3531) acc 53.1250 (63.1250) lr 1.9999e-03 eta 0:16:09
epoch [3/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 1.4023 (1.3562) acc 62.5000 (63.5156) lr 1.9999e-03 eta 0:15:50
epoch [3/200] batch [45/50] time 0.086 (0.095) data 0.000 (0.012) loss 1.8262 (1.3586) acc 46.8750 (63.0556) lr 1.9999e-03 eta 0:15:35
epoch [3/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9575 (1.3535) acc 75.0000 (63.2500) lr 1.9995e-03 eta 0:15:23
epoch [4/200] batch [5/50] time 0.083 (0.188) data 0.000 (0.103) loss 1.4375 (1.2571) acc 65.6250 (66.8750) lr 1.9995e-03 eta 0:30:49
epoch [4/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.052) loss 1.1064 (1.2299) acc 62.5000 (66.2500) lr 1.9995e-03 eta 0:22:18
epoch [4/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 1.4590 (1.2476) acc 59.3750 (65.2083) lr 1.9995e-03 eta 0:19:26
epoch [4/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.1211 (1.3342) acc 71.8750 (64.5312) lr 1.9995e-03 eta 0:18:00
epoch [4/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 2.0293 (1.3603) acc 56.2500 (63.1250) lr 1.9995e-03 eta 0:17:09
epoch [4/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.3301 (1.3373) acc 65.6250 (63.9583) lr 1.9995e-03 eta 0:16:35
epoch [4/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.2021 (1.3193) acc 62.5000 (64.1964) lr 1.9995e-03 eta 0:16:10
epoch [4/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.1660 (1.3153) acc 71.8750 (64.2188) lr 1.9995e-03 eta 0:15:50
epoch [4/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 1.3232 (1.3019) acc 62.5000 (64.5139) lr 1.9995e-03 eta 0:15:34
epoch [4/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.6865 (1.2886) acc 59.3750 (65.0625) lr 1.9989e-03 eta 0:15:22
epoch [5/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.104) loss 0.8750 (1.1855) acc 75.0000 (70.0000) lr 1.9989e-03 eta 0:30:43
epoch [5/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.052) loss 1.0186 (1.2529) acc 71.8750 (66.2500) lr 1.9989e-03 eta 0:22:11
epoch [5/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.035) loss 1.5947 (1.2809) acc 53.1250 (65.2083) lr 1.9989e-03 eta 0:19:19
epoch [5/200] batch [20/50] time 0.082 (0.110) data 0.000 (0.026) loss 1.2412 (1.2540) acc 65.6250 (65.6250) lr 1.9989e-03 eta 0:17:52
epoch [5/200] batch [25/50] time 0.083 (0.104) data 0.000 (0.021) loss 0.7300 (1.2460) acc 78.1250 (66.1250) lr 1.9989e-03 eta 0:17:00
epoch [5/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9712 (1.1977) acc 81.2500 (67.3958) lr 1.9989e-03 eta 0:16:24
epoch [5/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.015) loss 0.5273 (1.1908) acc 84.3750 (67.4107) lr 1.9989e-03 eta 0:16:00
epoch [5/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 1.5635 (1.2077) acc 53.1250 (67.1094) lr 1.9989e-03 eta 0:15:40
epoch [5/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 1.4268 (1.2082) acc 59.3750 (67.0833) lr 1.9989e-03 eta 0:15:25
epoch [5/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.2637 (1.2254) acc 65.6250 (66.5000) lr 1.9980e-03 eta 0:15:13
epoch [6/200] batch [5/50] time 0.083 (0.189) data 0.000 (0.105) loss 1.1680 (1.1185) acc 62.5000 (68.7500) lr 1.9980e-03 eta 0:30:40
epoch [6/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.052) loss 1.2773 (1.0543) acc 59.3750 (69.6875) lr 1.9980e-03 eta 0:22:06
epoch [6/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.8608 (1.0853) acc 84.3750 (70.4167) lr 1.9980e-03 eta 0:19:16
epoch [6/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.9629 (1.0978) acc 71.8750 (69.3750) lr 1.9980e-03 eta 0:17:51
epoch [6/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.7324 (1.1421) acc 53.1250 (67.7500) lr 1.9980e-03 eta 0:17:00
epoch [6/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.018) loss 1.1367 (1.1446) acc 62.5000 (67.7083) lr 1.9980e-03 eta 0:16:25
epoch [6/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.1240 (1.1650) acc 71.8750 (66.8750) lr 1.9980e-03 eta 0:16:01
epoch [6/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.3584 (1.1705) acc 59.3750 (66.7969) lr 1.9980e-03 eta 0:15:40
epoch [6/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.012) loss 0.4551 (1.1532) acc 87.5000 (67.5000) lr 1.9980e-03 eta 0:15:26
epoch [6/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.7974 (1.1481) acc 78.1250 (67.4375) lr 1.9969e-03 eta 0:15:13
epoch [7/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.097) loss 1.2139 (1.1545) acc 68.7500 (71.8750) lr 1.9969e-03 eta 0:29:30
epoch [7/200] batch [10/50] time 0.083 (0.133) data 0.000 (0.049) loss 1.5068 (1.1829) acc 59.3750 (70.3125) lr 1.9969e-03 eta 0:21:30
epoch [7/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.7490 (1.1733) acc 84.3750 (69.1667) lr 1.9969e-03 eta 0:18:49
epoch [7/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 1.3037 (1.2360) acc 65.6250 (67.3438) lr 1.9969e-03 eta 0:17:29
epoch [7/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.4844 (1.2176) acc 53.1250 (66.7500) lr 1.9969e-03 eta 0:16:41
epoch [7/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 1.4375 (1.1852) acc 68.7500 (67.6042) lr 1.9969e-03 eta 0:16:09
epoch [7/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.3008 (1.1789) acc 56.2500 (67.9464) lr 1.9969e-03 eta 0:15:46
epoch [7/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0459 (1.1492) acc 78.1250 (68.9844) lr 1.9969e-03 eta 0:15:27
epoch [7/200] batch [45/50] time 0.082 (0.095) data 0.000 (0.011) loss 1.0986 (1.1355) acc 68.7500 (68.9583) lr 1.9969e-03 eta 0:15:13
epoch [7/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.9092 (1.1254) acc 71.8750 (69.3125) lr 1.9956e-03 eta 0:15:01
epoch [8/200] batch [5/50] time 0.083 (0.178) data 0.000 (0.093) loss 1.2412 (1.1590) acc 68.7500 (70.6250) lr 1.9956e-03 eta 0:28:38
epoch [8/200] batch [10/50] time 0.084 (0.131) data 0.000 (0.047) loss 0.9419 (1.1743) acc 75.0000 (69.6875) lr 1.9956e-03 eta 0:21:00
epoch [8/200] batch [15/50] time 0.083 (0.115) data 0.000 (0.031) loss 1.2939 (1.1250) acc 59.3750 (69.3750) lr 1.9956e-03 eta 0:18:27
epoch [8/200] batch [20/50] time 0.084 (0.107) data 0.000 (0.024) loss 1.0137 (1.1362) acc 68.7500 (68.4375) lr 1.9956e-03 eta 0:17:12
epoch [8/200] batch [25/50] time 0.084 (0.102) data 0.000 (0.019) loss 1.0156 (1.1221) acc 75.0000 (68.6250) lr 1.9956e-03 eta 0:16:26
epoch [8/200] batch [30/50] time 0.083 (0.099) data 0.000 (0.016) loss 1.7256 (1.1314) acc 62.5000 (68.7500) lr 1.9956e-03 eta 0:15:56
epoch [8/200] batch [35/50] time 0.085 (0.097) data 0.000 (0.014) loss 1.2129 (1.1389) acc 59.3750 (68.3036) lr 1.9956e-03 eta 0:15:34
epoch [8/200] batch [40/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.8994 (1.1379) acc 71.8750 (68.2031) lr 1.9956e-03 eta 0:15:17
epoch [8/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.9253 (1.1382) acc 75.0000 (68.4722) lr 1.9956e-03 eta 0:15:03
epoch [8/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.7969 (1.1186) acc 75.0000 (69.1250) lr 1.9940e-03 eta 0:14:52
epoch [9/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 1.3945 (1.1879) acc 56.2500 (66.8750) lr 1.9940e-03 eta 0:30:20
epoch [9/200] batch [10/50] time 0.083 (0.137) data 0.000 (0.053) loss 0.8325 (1.1638) acc 75.0000 (68.4375) lr 1.9940e-03 eta 0:21:51
epoch [9/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.7222 (1.1381) acc 84.3750 (67.9167) lr 1.9940e-03 eta 0:19:03
epoch [9/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.5947 (1.1338) acc 56.2500 (67.9688) lr 1.9940e-03 eta 0:17:38
epoch [9/200] batch [25/50] time 0.086 (0.105) data 0.000 (0.021) loss 0.6904 (1.0887) acc 78.1250 (69.0000) lr 1.9940e-03 eta 0:16:48
epoch [9/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.5234 (1.1422) acc 56.2500 (67.9167) lr 1.9940e-03 eta 0:16:13
epoch [9/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.6436 (1.1366) acc 56.2500 (68.4821) lr 1.9940e-03 eta 0:15:49
epoch [9/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8735 (1.1201) acc 71.8750 (69.1406) lr 1.9940e-03 eta 0:15:29
epoch [9/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1729 (1.1050) acc 71.8750 (69.3750) lr 1.9940e-03 eta 0:15:14
epoch [9/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.2373 (1.1171) acc 68.7500 (69.1875) lr 1.9921e-03 eta 0:15:02
epoch [10/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 0.7749 (1.1531) acc 68.7500 (66.8750) lr 1.9921e-03 eta 0:28:58
epoch [10/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.9497 (1.0614) acc 75.0000 (69.6875) lr 1.9921e-03 eta 0:21:10
epoch [10/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 1.1807 (1.0750) acc 59.3750 (69.7917) lr 1.9921e-03 eta 0:18:34
epoch [10/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.1025 (1.0627) acc 68.7500 (69.5312) lr 1.9921e-03 eta 0:17:16
epoch [10/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.9922 (1.0737) acc 68.7500 (69.2500) lr 1.9921e-03 eta 0:16:30
epoch [10/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 1.5684 (1.0923) acc 62.5000 (69.6875) lr 1.9921e-03 eta 0:15:58
epoch [10/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 1.2656 (1.1029) acc 68.7500 (69.7321) lr 1.9921e-03 eta 0:15:36
epoch [10/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.6865 (1.1101) acc 56.2500 (69.4531) lr 1.9921e-03 eta 0:15:18
epoch [10/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0566 (1.1092) acc 65.6250 (69.5139) lr 1.9921e-03 eta 0:15:03
epoch [10/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.5137 (1.1248) acc 65.6250 (69.2500) lr 1.9900e-03 eta 0:14:51
epoch [11/200] batch [5/50] time 0.084 (0.196) data 0.000 (0.110) loss 1.5830 (1.2072) acc 62.5000 (68.1250) lr 1.9900e-03 eta 0:30:56
epoch [11/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.9233 (1.0775) acc 68.7500 (69.0625) lr 1.9900e-03 eta 0:22:08
epoch [11/200] batch [15/50] time 0.083 (0.121) data 0.000 (0.037) loss 0.8989 (1.0613) acc 75.0000 (70.4167) lr 1.9900e-03 eta 0:19:11
epoch [11/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 1.3877 (1.0806) acc 59.3750 (69.8438) lr 1.9900e-03 eta 0:17:43
epoch [11/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 1.1904 (1.0791) acc 65.6250 (70.5000) lr 1.9900e-03 eta 0:16:49
epoch [11/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.5854 (1.0690) acc 90.6250 (70.7292) lr 1.9900e-03 eta 0:16:14
epoch [11/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.016) loss 1.0059 (1.0760) acc 68.7500 (70.0893) lr 1.9900e-03 eta 0:15:49
epoch [11/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.7305 (1.0902) acc 56.2500 (70.2344) lr 1.9900e-03 eta 0:15:28
epoch [11/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.8584 (1.0866) acc 75.0000 (70.2083) lr 1.9900e-03 eta 0:15:12
epoch [11/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.2930 (1.0930) acc 62.5000 (69.9375) lr 1.9877e-03 eta 0:14:59
epoch [12/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.110) loss 0.8955 (1.2361) acc 75.0000 (67.5000) lr 1.9877e-03 eta 0:30:45
epoch [12/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.6577 (1.1798) acc 81.2500 (67.1875) lr 1.9877e-03 eta 0:22:01
epoch [12/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.037) loss 0.7402 (1.1022) acc 81.2500 (70.0000) lr 1.9877e-03 eta 0:19:06
epoch [12/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.4868 (1.0827) acc 87.5000 (70.0000) lr 1.9877e-03 eta 0:17:39
epoch [12/200] batch [25/50] time 0.087 (0.107) data 0.000 (0.022) loss 0.7949 (1.0544) acc 81.2500 (71.1250) lr 1.9877e-03 eta 0:16:46
epoch [12/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 1.4551 (1.0709) acc 56.2500 (70.5208) lr 1.9877e-03 eta 0:16:11
epoch [12/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.016) loss 1.0469 (1.0776) acc 75.0000 (70.6250) lr 1.9877e-03 eta 0:15:45
epoch [12/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.8105 (1.0689) acc 50.0000 (71.0156) lr 1.9877e-03 eta 0:15:24
epoch [12/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.6313 (1.0695) acc 81.2500 (70.8333) lr 1.9877e-03 eta 0:15:08
epoch [12/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8130 (1.0900) acc 78.1250 (70.3750) lr 1.9851e-03 eta 0:14:56
epoch [13/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.105) loss 1.3535 (1.0294) acc 59.3750 (71.2500) lr 1.9851e-03 eta 0:29:44
epoch [13/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 1.0654 (0.9459) acc 71.8750 (72.8125) lr 1.9851e-03 eta 0:21:26
epoch [13/200] batch [15/50] time 0.083 (0.119) data 0.000 (0.035) loss 0.9956 (1.0080) acc 71.8750 (71.8750) lr 1.9851e-03 eta 0:18:38
epoch [13/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.2061 (1.0452) acc 65.6250 (71.0938) lr 1.9851e-03 eta 0:17:15
epoch [13/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 1.4248 (1.0732) acc 53.1250 (70.7500) lr 1.9851e-03 eta 0:16:26
epoch [13/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 1.1904 (1.0812) acc 71.8750 (70.7292) lr 1.9851e-03 eta 0:15:53
epoch [13/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.5879 (1.0596) acc 87.5000 (71.0714) lr 1.9851e-03 eta 0:15:29
epoch [13/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9546 (1.0589) acc 78.1250 (71.2500) lr 1.9851e-03 eta 0:15:10
epoch [13/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.4492 (1.0696) acc 62.5000 (70.7639) lr 1.9851e-03 eta 0:14:55
epoch [13/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1338 (1.0756) acc 62.5000 (70.6250) lr 1.9823e-03 eta 0:14:43
epoch [14/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 1.1357 (1.0587) acc 65.6250 (70.6250) lr 1.9823e-03 eta 0:29:23
epoch [14/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 1.4736 (1.0024) acc 59.3750 (71.5625) lr 1.9823e-03 eta 0:21:16
epoch [14/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 1.1143 (1.0355) acc 78.1250 (71.0417) lr 1.9823e-03 eta 0:18:33
epoch [14/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 1.1055 (1.0980) acc 71.8750 (69.5312) lr 1.9823e-03 eta 0:17:11
epoch [14/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.7871 (1.1551) acc 50.0000 (68.1250) lr 1.9823e-03 eta 0:16:21
epoch [14/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6118 (1.1251) acc 87.5000 (68.8542) lr 1.9823e-03 eta 0:15:48
epoch [14/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.015) loss 0.9683 (1.1350) acc 75.0000 (68.5714) lr 1.9823e-03 eta 0:15:24
epoch [14/200] batch [40/50] time 0.082 (0.097) data 0.000 (0.013) loss 0.9868 (1.1028) acc 71.8750 (69.5312) lr 1.9823e-03 eta 0:15:04
epoch [14/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8120 (1.0938) acc 75.0000 (69.5833) lr 1.9823e-03 eta 0:14:49
epoch [14/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.011) loss 1.2051 (1.0814) acc 59.3750 (69.7500) lr 1.9792e-03 eta 0:14:37
epoch [15/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.100) loss 0.8369 (1.0604) acc 75.0000 (68.1250) lr 1.9792e-03 eta 0:28:46
epoch [15/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 1.4365 (1.0247) acc 56.2500 (70.3125) lr 1.9792e-03 eta 0:20:53
epoch [15/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 1.2871 (1.0305) acc 65.6250 (71.4583) lr 1.9792e-03 eta 0:18:16
epoch [15/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 1.7988 (1.0431) acc 62.5000 (71.7188) lr 1.9792e-03 eta 0:16:57
epoch [15/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.7632 (1.0057) acc 71.8750 (72.1250) lr 1.9792e-03 eta 0:16:09
epoch [15/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9556 (1.0175) acc 68.7500 (71.3542) lr 1.9792e-03 eta 0:15:38
epoch [15/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 1.3135 (1.0182) acc 68.7500 (71.2500) lr 1.9792e-03 eta 0:15:15
epoch [15/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.2852 (1.0082) acc 68.7500 (71.4844) lr 1.9792e-03 eta 0:14:56
epoch [15/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.1211 (1.0137) acc 65.6250 (71.4583) lr 1.9792e-03 eta 0:14:42
epoch [15/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0947 (1.0136) acc 75.0000 (71.6250) lr 1.9759e-03 eta 0:14:30
epoch [16/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.098) loss 1.6582 (0.9973) acc 59.3750 (72.5000) lr 1.9759e-03 eta 0:28:15
epoch [16/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 1.0049 (1.0537) acc 75.0000 (70.3125) lr 1.9759e-03 eta 0:20:36
epoch [16/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 1.0010 (1.0548) acc 75.0000 (71.4583) lr 1.9759e-03 eta 0:18:03
epoch [16/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.2285 (1.0619) acc 65.6250 (70.6250) lr 1.9759e-03 eta 0:16:45
epoch [16/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7803 (1.0255) acc 78.1250 (71.3750) lr 1.9759e-03 eta 0:16:00
epoch [16/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 1.4492 (1.0809) acc 62.5000 (70.4167) lr 1.9759e-03 eta 0:15:29
epoch [16/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.7905 (1.0490) acc 81.2500 (71.4286) lr 1.9759e-03 eta 0:15:08
epoch [16/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.7661 (1.0486) acc 78.1250 (71.7188) lr 1.9759e-03 eta 0:14:50
epoch [16/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9399 (1.0323) acc 78.1250 (71.9444) lr 1.9759e-03 eta 0:14:36
epoch [16/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9766 (1.0232) acc 68.7500 (72.0625) lr 1.9724e-03 eta 0:14:24
epoch [17/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.103) loss 0.9370 (0.9730) acc 68.7500 (70.0000) lr 1.9724e-03 eta 0:28:45
epoch [17/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.052) loss 1.2021 (0.9358) acc 68.7500 (72.1875) lr 1.9724e-03 eta 0:20:49
epoch [17/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.7695 (0.9356) acc 75.0000 (72.7083) lr 1.9724e-03 eta 0:18:14
epoch [17/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.8315 (0.9124) acc 71.8750 (73.5938) lr 1.9724e-03 eta 0:16:53
epoch [17/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.2246 (0.8993) acc 71.8750 (73.6250) lr 1.9724e-03 eta 0:16:05
epoch [17/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.1074 (0.9547) acc 78.1250 (72.9167) lr 1.9724e-03 eta 0:15:32
epoch [17/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.4216 (0.9853) acc 87.5000 (72.6786) lr 1.9724e-03 eta 0:15:10
epoch [17/200] batch [40/50] time 0.084 (0.097) data 0.001 (0.013) loss 1.6602 (1.0133) acc 59.3750 (72.1875) lr 1.9724e-03 eta 0:14:51
epoch [17/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1465 (1.0396) acc 68.7500 (71.8056) lr 1.9724e-03 eta 0:14:36
epoch [17/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9082 (1.0315) acc 71.8750 (72.1250) lr 1.9686e-03 eta 0:14:25
epoch [18/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 1.1152 (1.1311) acc 62.5000 (70.0000) lr 1.9686e-03 eta 0:27:28
epoch [18/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.047) loss 0.9136 (1.0428) acc 75.0000 (71.2500) lr 1.9686e-03 eta 0:20:06
epoch [18/200] batch [15/50] time 0.090 (0.116) data 0.000 (0.032) loss 1.0088 (1.0442) acc 78.1250 (71.2500) lr 1.9686e-03 eta 0:17:44
epoch [18/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.6963 (1.0343) acc 81.2500 (71.0938) lr 1.9686e-03 eta 0:16:29
epoch [18/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 1.5654 (1.0153) acc 59.3750 (71.6250) lr 1.9686e-03 eta 0:15:45
epoch [18/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.1592 (1.0258) acc 62.5000 (71.3542) lr 1.9686e-03 eta 0:15:15
epoch [18/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9106 (1.0227) acc 68.7500 (71.1607) lr 1.9686e-03 eta 0:14:53
epoch [18/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7876 (1.0122) acc 75.0000 (71.4844) lr 1.9686e-03 eta 0:14:36
epoch [18/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.4795 (1.0215) acc 65.6250 (71.5278) lr 1.9686e-03 eta 0:14:23
epoch [18/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.2607 (1.0173) acc 62.5000 (71.5000) lr 1.9646e-03 eta 0:14:12
epoch [19/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.107) loss 0.9707 (0.8559) acc 75.0000 (76.2500) lr 1.9646e-03 eta 0:29:02
epoch [19/200] batch [10/50] time 0.083 (0.138) data 0.000 (0.054) loss 0.4424 (0.8526) acc 87.5000 (76.8750) lr 1.9646e-03 eta 0:20:53
epoch [19/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.2070 (0.8534) acc 65.6250 (77.0833) lr 1.9646e-03 eta 0:18:09
epoch [19/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.9131 (0.8709) acc 75.0000 (77.0312) lr 1.9646e-03 eta 0:16:47
epoch [19/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.9795 (0.8967) acc 68.7500 (76.1250) lr 1.9646e-03 eta 0:15:58
epoch [19/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.2676 (0.9149) acc 59.3750 (75.4167) lr 1.9646e-03 eta 0:15:24
epoch [19/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.016) loss 1.5205 (0.9183) acc 62.5000 (74.6429) lr 1.9646e-03 eta 0:15:01
epoch [19/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.9238 (0.9496) acc 81.2500 (73.9062) lr 1.9646e-03 eta 0:14:42
epoch [19/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8213 (0.9518) acc 78.1250 (74.1667) lr 1.9646e-03 eta 0:14:27
epoch [19/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.3721 (0.9831) acc 68.7500 (73.6875) lr 1.9603e-03 eta 0:14:15
epoch [20/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 0.8076 (0.8702) acc 75.0000 (72.5000) lr 1.9603e-03 eta 0:28:30
epoch [20/200] batch [10/50] time 0.083 (0.137) data 0.000 (0.052) loss 1.0186 (0.8858) acc 59.3750 (71.2500) lr 1.9603e-03 eta 0:20:36
epoch [20/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.6958 (0.8703) acc 81.2500 (72.2917) lr 1.9603e-03 eta 0:17:57
epoch [20/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.9663 (0.8704) acc 71.8750 (73.2812) lr 1.9603e-03 eta 0:16:37
epoch [20/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.9819 (0.9338) acc 65.6250 (72.3750) lr 1.9603e-03 eta 0:15:49
epoch [20/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.3037 (0.9540) acc 62.5000 (72.6042) lr 1.9603e-03 eta 0:15:16
epoch [20/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.3921 (0.9618) acc 84.3750 (72.9464) lr 1.9603e-03 eta 0:14:53
epoch [20/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.2148 (0.9723) acc 68.7500 (72.7344) lr 1.9603e-03 eta 0:14:34
epoch [20/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8457 (0.9927) acc 75.0000 (72.2917) lr 1.9603e-03 eta 0:14:20
epoch [20/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.9844 (1.0003) acc 62.5000 (71.8750) lr 1.9558e-03 eta 0:14:08
epoch [21/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 0.7847 (0.9765) acc 81.2500 (73.7500) lr 1.9558e-03 eta 0:28:23
epoch [21/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 0.5947 (0.9894) acc 78.1250 (73.1250) lr 1.9558e-03 eta 0:20:33
epoch [21/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.7900 (0.9769) acc 81.2500 (73.5417) lr 1.9558e-03 eta 0:17:54
epoch [21/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 1.1787 (1.0284) acc 65.6250 (72.1875) lr 1.9558e-03 eta 0:16:35
epoch [21/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.7437 (0.9922) acc 81.2500 (72.7500) lr 1.9558e-03 eta 0:15:48
epoch [21/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.4438 (0.9937) acc 87.5000 (72.6042) lr 1.9558e-03 eta 0:15:16
epoch [21/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.7344 (0.9824) acc 75.0000 (72.5893) lr 1.9558e-03 eta 0:14:54
epoch [21/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.8901 (0.9921) acc 81.2500 (72.1875) lr 1.9558e-03 eta 0:14:35
epoch [21/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0791 (0.9913) acc 68.7500 (72.4306) lr 1.9558e-03 eta 0:14:22
epoch [21/200] batch [50/50] time 0.086 (0.095) data 0.000 (0.011) loss 1.2383 (0.9851) acc 62.5000 (72.6250) lr 1.9511e-03 eta 0:14:10
epoch [22/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.105) loss 1.0342 (0.7765) acc 75.0000 (80.0000) lr 1.9511e-03 eta 0:28:26
epoch [22/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.9214 (0.8519) acc 75.0000 (77.1875) lr 1.9511e-03 eta 0:20:30
epoch [22/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.9399 (0.8806) acc 75.0000 (75.0000) lr 1.9511e-03 eta 0:17:52
epoch [22/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.6816 (0.9026) acc 81.2500 (73.4375) lr 1.9511e-03 eta 0:16:32
epoch [22/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.7236 (0.8769) acc 75.0000 (74.2500) lr 1.9511e-03 eta 0:15:44
epoch [22/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.9126 (0.9046) acc 71.8750 (73.5417) lr 1.9511e-03 eta 0:15:13
epoch [22/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.7520 (0.9284) acc 81.2500 (73.1250) lr 1.9511e-03 eta 0:14:50
epoch [22/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.9683 (0.9308) acc 65.6250 (72.7344) lr 1.9511e-03 eta 0:14:31
epoch [22/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0566 (0.9312) acc 71.8750 (72.8472) lr 1.9511e-03 eta 0:14:17
epoch [22/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2012 (0.9537) acc 75.0000 (72.3750) lr 1.9461e-03 eta 0:14:05
epoch [23/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.100) loss 1.0400 (1.0598) acc 68.7500 (71.2500) lr 1.9461e-03 eta 0:27:23
epoch [23/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.8877 (1.0193) acc 78.1250 (73.1250) lr 1.9461e-03 eta 0:19:56
epoch [23/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.5601 (0.9812) acc 90.6250 (74.7917) lr 1.9461e-03 eta 0:17:27
epoch [23/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.9287 (0.9759) acc 71.8750 (73.9062) lr 1.9461e-03 eta 0:16:12
epoch [23/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.1074 (0.9645) acc 71.8750 (73.7500) lr 1.9461e-03 eta 0:15:27
epoch [23/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9072 (0.9581) acc 71.8750 (73.5417) lr 1.9461e-03 eta 0:14:57
epoch [23/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.6069 (0.9462) acc 81.2500 (73.6607) lr 1.9461e-03 eta 0:14:36
epoch [23/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0732 (0.9667) acc 68.7500 (72.8906) lr 1.9461e-03 eta 0:14:18
epoch [23/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8892 (0.9588) acc 75.0000 (73.1250) lr 1.9461e-03 eta 0:14:04
epoch [23/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7417 (0.9581) acc 71.8750 (72.7500) lr 1.9409e-03 eta 0:13:53
epoch [24/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.101) loss 1.2686 (0.8386) acc 68.7500 (76.8750) lr 1.9409e-03 eta 0:27:29
epoch [24/200] batch [10/50] time 0.086 (0.135) data 0.000 (0.051) loss 0.8716 (0.9344) acc 75.0000 (73.7500) lr 1.9409e-03 eta 0:19:57
epoch [24/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.8374 (0.8532) acc 81.2500 (76.2500) lr 1.9409e-03 eta 0:17:27
epoch [24/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 1.1455 (0.9050) acc 65.6250 (74.5312) lr 1.9409e-03 eta 0:16:13
epoch [24/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.8652 (0.8973) acc 68.7500 (74.8750) lr 1.9409e-03 eta 0:15:27
epoch [24/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.6460 (0.8894) acc 78.1250 (75.0000) lr 1.9409e-03 eta 0:14:56
epoch [24/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.6738 (0.8841) acc 75.0000 (74.7321) lr 1.9409e-03 eta 0:14:34
epoch [24/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.0342 (0.9175) acc 68.7500 (74.1406) lr 1.9409e-03 eta 0:14:16
epoch [24/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.8745 (0.9262) acc 81.2500 (74.2361) lr 1.9409e-03 eta 0:14:02
epoch [24/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7896 (0.9367) acc 78.1250 (73.8750) lr 1.9354e-03 eta 0:13:51
epoch [25/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.104) loss 0.8525 (0.8427) acc 75.0000 (76.8750) lr 1.9354e-03 eta 0:27:45
epoch [25/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 0.9321 (0.9447) acc 65.6250 (72.8125) lr 1.9354e-03 eta 0:20:02
epoch [25/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 1.1816 (0.9150) acc 75.0000 (73.7500) lr 1.9354e-03 eta 0:17:29
epoch [25/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.5981 (0.9275) acc 84.3750 (73.9062) lr 1.9354e-03 eta 0:16:12
epoch [25/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.9033 (0.9206) acc 68.7500 (73.7500) lr 1.9354e-03 eta 0:15:25
epoch [25/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.8247 (0.9035) acc 71.8750 (73.5417) lr 1.9354e-03 eta 0:14:54
epoch [25/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6411 (0.9036) acc 78.1250 (73.2143) lr 1.9354e-03 eta 0:14:31
epoch [25/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8540 (0.8964) acc 75.0000 (73.5938) lr 1.9354e-03 eta 0:14:13
epoch [25/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.2246 (0.8991) acc 65.6250 (73.4722) lr 1.9354e-03 eta 0:13:59
epoch [25/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0000 (0.9089) acc 65.6250 (73.0625) lr 1.9298e-03 eta 0:13:48
epoch [26/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.098) loss 1.0605 (0.7674) acc 68.7500 (76.2500) lr 1.9298e-03 eta 0:26:46
epoch [26/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 1.3594 (0.9313) acc 59.3750 (71.2500) lr 1.9298e-03 eta 0:19:31
epoch [26/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 1.2393 (0.9765) acc 65.6250 (68.9583) lr 1.9298e-03 eta 0:17:07
epoch [26/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 0.6172 (0.9604) acc 81.2500 (69.8438) lr 1.9298e-03 eta 0:15:52
epoch [26/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.6416 (0.9513) acc 87.5000 (71.2500) lr 1.9298e-03 eta 0:15:08
epoch [26/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 1.1465 (0.9598) acc 59.3750 (71.2500) lr 1.9298e-03 eta 0:14:38
epoch [26/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9365 (0.9509) acc 75.0000 (71.4286) lr 1.9298e-03 eta 0:14:17
epoch [26/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.1064 (0.9536) acc 71.8750 (71.8750) lr 1.9298e-03 eta 0:14:01
epoch [26/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.3125 (0.9479) acc 65.6250 (72.2917) lr 1.9298e-03 eta 0:13:47
epoch [26/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9058 (0.9433) acc 81.2500 (72.7500) lr 1.9239e-03 eta 0:13:36
epoch [27/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.102) loss 0.7393 (0.9338) acc 78.1250 (73.7500) lr 1.9239e-03 eta 0:27:19
epoch [27/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.051) loss 0.8188 (0.8909) acc 78.1250 (75.6250) lr 1.9239e-03 eta 0:19:48
epoch [27/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.034) loss 1.0918 (0.9232) acc 68.7500 (73.7500) lr 1.9239e-03 eta 0:17:18
epoch [27/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.8281 (0.8639) acc 78.1250 (75.6250) lr 1.9239e-03 eta 0:16:02
epoch [27/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 1.0039 (0.8755) acc 65.6250 (75.6250) lr 1.9239e-03 eta 0:15:16
epoch [27/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.3711 (0.8740) acc 62.5000 (75.2083) lr 1.9239e-03 eta 0:14:46
epoch [27/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.015) loss 1.1270 (0.8885) acc 68.7500 (75.1786) lr 1.9239e-03 eta 0:14:24
epoch [27/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.7974 (0.8708) acc 71.8750 (75.0000) lr 1.9239e-03 eta 0:14:06
epoch [27/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8159 (0.8754) acc 71.8750 (74.6528) lr 1.9239e-03 eta 0:13:52
epoch [27/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.7656 (0.8692) acc 71.8750 (74.5625) lr 1.9178e-03 eta 0:13:40
epoch [28/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.108) loss 0.4092 (0.6903) acc 93.7500 (81.2500) lr 1.9178e-03 eta 0:27:41
epoch [28/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.054) loss 1.2578 (0.7894) acc 62.5000 (78.1250) lr 1.9178e-03 eta 0:19:55
epoch [28/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.5381 (0.7911) acc 81.2500 (78.3333) lr 1.9178e-03 eta 0:17:19
epoch [28/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.4768 (0.8333) acc 87.5000 (77.3438) lr 1.9178e-03 eta 0:16:01
epoch [28/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.9053 (0.9009) acc 68.7500 (75.3750) lr 1.9178e-03 eta 0:15:14
epoch [28/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.5024 (0.8837) acc 84.3750 (75.2083) lr 1.9178e-03 eta 0:14:43
epoch [28/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6523 (0.8825) acc 81.2500 (75.5357) lr 1.9178e-03 eta 0:14:20
epoch [28/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.3428 (0.8964) acc 62.5000 (75.3906) lr 1.9178e-03 eta 0:14:01
epoch [28/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.3467 (0.9064) acc 71.8750 (75.2083) lr 1.9178e-03 eta 0:13:47
epoch [28/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.1123 (0.9075) acc 65.6250 (75.1250) lr 1.9114e-03 eta 0:13:36
epoch [29/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.109) loss 0.9917 (0.8370) acc 65.6250 (74.3750) lr 1.9114e-03 eta 0:27:53
epoch [29/200] batch [10/50] time 0.083 (0.139) data 0.000 (0.055) loss 0.8130 (0.8730) acc 78.1250 (75.9375) lr 1.9114e-03 eta 0:19:56
epoch [29/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 1.0400 (0.8727) acc 78.1250 (76.4583) lr 1.9114e-03 eta 0:17:18
epoch [29/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 1.3848 (0.9285) acc 62.5000 (74.5312) lr 1.9114e-03 eta 0:15:59
epoch [29/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.8228 (0.9435) acc 81.2500 (74.2500) lr 1.9114e-03 eta 0:15:11
epoch [29/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.8403 (0.9228) acc 75.0000 (74.7917) lr 1.9114e-03 eta 0:14:39
epoch [29/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8896 (0.8916) acc 75.0000 (75.5357) lr 1.9114e-03 eta 0:14:16
epoch [29/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.0850 (0.9128) acc 75.0000 (75.3906) lr 1.9114e-03 eta 0:13:58
epoch [29/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4797 (0.8936) acc 87.5000 (75.8333) lr 1.9114e-03 eta 0:13:44
epoch [29/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6206 (0.9017) acc 81.2500 (75.4375) lr 1.9048e-03 eta 0:13:32
epoch [30/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.107) loss 1.0801 (1.2246) acc 65.6250 (65.0000) lr 1.9048e-03 eta 0:27:20
epoch [30/200] batch [10/50] time 0.083 (0.138) data 0.000 (0.054) loss 1.2119 (1.0167) acc 56.2500 (68.7500) lr 1.9048e-03 eta 0:19:37
epoch [30/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.4543 (0.9068) acc 93.7500 (73.1250) lr 1.9048e-03 eta 0:17:03
epoch [30/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.6230 (0.9078) acc 81.2500 (73.7500) lr 1.9048e-03 eta 0:15:47
epoch [30/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.7070 (0.9060) acc 81.2500 (73.8750) lr 1.9048e-03 eta 0:15:01
epoch [30/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 1.5361 (0.9310) acc 59.3750 (73.2292) lr 1.9048e-03 eta 0:14:32
epoch [30/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.016) loss 0.6748 (0.9458) acc 78.1250 (73.4821) lr 1.9048e-03 eta 0:14:11
epoch [30/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.2803 (0.9469) acc 68.7500 (73.5156) lr 1.9048e-03 eta 0:13:53
epoch [30/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8809 (0.9218) acc 87.5000 (74.3750) lr 1.9048e-03 eta 0:13:39
epoch [30/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.2598 (0.9346) acc 62.5000 (73.9375) lr 1.8980e-03 eta 0:13:27
epoch [31/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.094) loss 0.6665 (0.9982) acc 84.3750 (71.2500) lr 1.8980e-03 eta 0:25:27
epoch [31/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.047) loss 1.1279 (1.0500) acc 68.7500 (70.0000) lr 1.8980e-03 eta 0:18:41
epoch [31/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 0.8647 (1.0328) acc 81.2500 (70.8333) lr 1.8980e-03 eta 0:16:26
epoch [31/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 1.1670 (1.0112) acc 75.0000 (72.1875) lr 1.8980e-03 eta 0:15:19
epoch [31/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 1.0684 (1.0063) acc 71.8750 (72.5000) lr 1.8980e-03 eta 0:14:39
epoch [31/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.8467 (0.9966) acc 75.0000 (72.5000) lr 1.8980e-03 eta 0:14:11
epoch [31/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 1.0518 (0.9886) acc 71.8750 (72.5893) lr 1.8980e-03 eta 0:13:52
epoch [31/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7568 (0.9570) acc 75.0000 (73.3594) lr 1.8980e-03 eta 0:13:36
epoch [31/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6074 (0.9479) acc 81.2500 (73.5417) lr 1.8980e-03 eta 0:13:23
epoch [31/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7280 (0.9495) acc 75.0000 (73.3750) lr 1.8910e-03 eta 0:13:13
epoch [32/200] batch [5/50] time 0.086 (0.192) data 0.000 (0.107) loss 1.0156 (0.7526) acc 68.7500 (78.1250) lr 1.8910e-03 eta 0:27:05
epoch [32/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.8354 (0.8033) acc 75.0000 (77.5000) lr 1.8910e-03 eta 0:19:26
epoch [32/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.8740 (0.8810) acc 81.2500 (77.2917) lr 1.8910e-03 eta 0:16:53
epoch [32/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.9517 (0.8748) acc 71.8750 (77.0312) lr 1.8910e-03 eta 0:15:37
epoch [32/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 1.1377 (0.9177) acc 65.6250 (74.8750) lr 1.8910e-03 eta 0:14:51
epoch [32/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6499 (0.8966) acc 81.2500 (75.1042) lr 1.8910e-03 eta 0:14:21
epoch [32/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8188 (0.8920) acc 75.0000 (75.4464) lr 1.8910e-03 eta 0:13:58
epoch [32/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.2441 (0.9106) acc 65.6250 (75.0781) lr 1.8910e-03 eta 0:13:40
epoch [32/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8164 (0.9018) acc 75.0000 (75.0694) lr 1.8910e-03 eta 0:13:27
epoch [32/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7710 (0.8969) acc 78.1250 (75.2500) lr 1.8838e-03 eta 0:13:16
epoch [33/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.094) loss 1.2080 (0.8630) acc 65.6250 (78.1250) lr 1.8838e-03 eta 0:25:06
epoch [33/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.6436 (0.8004) acc 68.7500 (78.4375) lr 1.8838e-03 eta 0:18:28
epoch [33/200] batch [15/50] time 0.087 (0.116) data 0.000 (0.032) loss 0.7734 (0.7946) acc 75.0000 (78.5417) lr 1.8838e-03 eta 0:16:16
epoch [33/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.9678 (0.8336) acc 78.1250 (77.9688) lr 1.8838e-03 eta 0:15:09
epoch [33/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 1.0840 (0.8607) acc 68.7500 (76.3750) lr 1.8838e-03 eta 0:14:28
epoch [33/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.9985 (0.8794) acc 71.8750 (75.6250) lr 1.8838e-03 eta 0:14:01
epoch [33/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 1.3535 (0.8678) acc 59.3750 (75.8036) lr 1.8838e-03 eta 0:13:42
epoch [33/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6553 (0.8586) acc 84.3750 (75.8594) lr 1.8838e-03 eta 0:13:26
epoch [33/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7070 (0.8514) acc 71.8750 (75.9722) lr 1.8838e-03 eta 0:13:13
epoch [33/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0469 (0.8441) acc 71.8750 (75.9375) lr 1.8763e-03 eta 0:13:03
epoch [34/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.105) loss 0.6680 (0.9418) acc 78.1250 (75.6250) lr 1.8763e-03 eta 0:26:35
epoch [34/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.8999 (0.9463) acc 78.1250 (75.0000) lr 1.8763e-03 eta 0:19:10
epoch [34/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 1.0664 (1.0370) acc 65.6250 (72.0833) lr 1.8763e-03 eta 0:16:43
epoch [34/200] batch [20/50] time 0.086 (0.112) data 0.000 (0.027) loss 0.9146 (1.0119) acc 78.1250 (72.9688) lr 1.8763e-03 eta 0:15:29
epoch [34/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 1.1162 (1.0050) acc 68.7500 (72.6250) lr 1.8763e-03 eta 0:14:44
epoch [34/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.8540 (0.9492) acc 81.2500 (74.4792) lr 1.8763e-03 eta 0:14:14
epoch [34/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 1.1338 (0.9333) acc 68.7500 (74.7321) lr 1.8763e-03 eta 0:13:53
epoch [34/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.9116 (0.9191) acc 75.0000 (74.9219) lr 1.8763e-03 eta 0:13:35
epoch [34/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.6689 (0.9207) acc 78.1250 (74.6528) lr 1.8763e-03 eta 0:13:21
epoch [34/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6099 (0.8988) acc 81.2500 (75.0625) lr 1.8686e-03 eta 0:13:10
epoch [35/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.109) loss 1.3164 (1.0812) acc 65.6250 (71.2500) lr 1.8686e-03 eta 0:26:43
epoch [35/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.8057 (0.9625) acc 71.8750 (72.1875) lr 1.8686e-03 eta 0:19:13
epoch [35/200] batch [15/50] time 0.086 (0.121) data 0.000 (0.036) loss 0.5952 (0.8666) acc 81.2500 (74.7917) lr 1.8686e-03 eta 0:16:43
epoch [35/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.8149 (0.8742) acc 78.1250 (75.3125) lr 1.8686e-03 eta 0:15:28
epoch [35/200] batch [25/50] time 0.086 (0.107) data 0.000 (0.022) loss 0.9321 (0.8491) acc 78.1250 (76.2500) lr 1.8686e-03 eta 0:14:42
epoch [35/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.4443 (0.8286) acc 87.5000 (77.1875) lr 1.8686e-03 eta 0:14:12
epoch [35/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.5942 (0.8258) acc 84.3750 (77.2321) lr 1.8686e-03 eta 0:13:50
epoch [35/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.2021 (0.8453) acc 71.8750 (76.4844) lr 1.8686e-03 eta 0:13:32
epoch [35/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.1777 (0.8600) acc 68.7500 (76.1111) lr 1.8686e-03 eta 0:13:18
epoch [35/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0625 (0.8667) acc 65.6250 (75.5625) lr 1.8607e-03 eta 0:13:07
epoch [36/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.109) loss 0.9297 (0.8072) acc 68.7500 (76.8750) lr 1.8607e-03 eta 0:26:35
epoch [36/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.8398 (0.9530) acc 75.0000 (71.8750) lr 1.8607e-03 eta 0:19:04
epoch [36/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 1.0479 (0.9746) acc 71.8750 (72.7083) lr 1.8607e-03 eta 0:16:33
epoch [36/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.027) loss 0.9883 (0.9731) acc 75.0000 (72.6562) lr 1.8607e-03 eta 0:15:17
epoch [36/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.7734 (0.9817) acc 78.1250 (72.0000) lr 1.8607e-03 eta 0:14:32
epoch [36/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.0645 (0.9791) acc 68.7500 (71.7708) lr 1.8607e-03 eta 0:14:01
epoch [36/200] batch [35/50] time 0.083 (0.100) data 0.000 (0.016) loss 0.8564 (0.9882) acc 75.0000 (71.3393) lr 1.8607e-03 eta 0:13:39
epoch [36/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6323 (0.9585) acc 87.5000 (72.5781) lr 1.8607e-03 eta 0:13:21
epoch [36/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7373 (0.9686) acc 81.2500 (72.6389) lr 1.8607e-03 eta 0:13:08
epoch [36/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7935 (0.9532) acc 81.2500 (73.5000) lr 1.8526e-03 eta 0:12:57
epoch [37/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.104) loss 1.1416 (0.8384) acc 62.5000 (79.3750) lr 1.8526e-03 eta 0:25:54
epoch [37/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.7964 (0.8898) acc 75.0000 (76.2500) lr 1.8526e-03 eta 0:18:41
epoch [37/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.8276 (0.8189) acc 78.1250 (78.5417) lr 1.8526e-03 eta 0:16:16
epoch [37/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.8853 (0.8722) acc 71.8750 (76.2500) lr 1.8526e-03 eta 0:15:03
epoch [37/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.6274 (0.8348) acc 84.3750 (77.3750) lr 1.8526e-03 eta 0:14:20
epoch [37/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 1.1201 (0.8579) acc 71.8750 (76.4583) lr 1.8526e-03 eta 0:13:51
epoch [37/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.5513 (0.8367) acc 78.1250 (77.1429) lr 1.8526e-03 eta 0:13:31
epoch [37/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7603 (0.8515) acc 75.0000 (76.9531) lr 1.8526e-03 eta 0:13:14
epoch [37/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6328 (0.8411) acc 81.2500 (76.8056) lr 1.8526e-03 eta 0:13:01
epoch [37/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0801 (0.8481) acc 75.0000 (76.7500) lr 1.8443e-03 eta 0:12:51
epoch [38/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.109) loss 0.8433 (0.8161) acc 71.8750 (81.2500) lr 1.8443e-03 eta 0:26:19
epoch [38/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 1.1641 (1.0080) acc 68.7500 (74.6875) lr 1.8443e-03 eta 0:18:51
epoch [38/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 0.9497 (0.9443) acc 71.8750 (75.0000) lr 1.8443e-03 eta 0:16:23
epoch [38/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.7720 (0.9420) acc 71.8750 (74.0625) lr 1.8443e-03 eta 0:15:08
epoch [38/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.7114 (0.9011) acc 78.1250 (75.5000) lr 1.8443e-03 eta 0:14:23
epoch [38/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.8818 (0.8851) acc 71.8750 (76.2500) lr 1.8443e-03 eta 0:13:53
epoch [38/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8862 (0.8963) acc 78.1250 (75.7143) lr 1.8443e-03 eta 0:13:31
epoch [38/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7998 (0.9209) acc 81.2500 (75.0000) lr 1.8443e-03 eta 0:13:14
epoch [38/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8535 (0.9373) acc 78.1250 (74.4444) lr 1.8443e-03 eta 0:13:01
epoch [38/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8296 (0.9438) acc 78.1250 (74.1250) lr 1.8358e-03 eta 0:12:50
epoch [39/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.099) loss 0.9448 (0.9064) acc 71.8750 (70.6250) lr 1.8358e-03 eta 0:25:00
epoch [39/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.9131 (0.9138) acc 68.7500 (72.1875) lr 1.8358e-03 eta 0:18:11
epoch [39/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.5117 (0.8477) acc 81.2500 (74.1667) lr 1.8358e-03 eta 0:15:52
epoch [39/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 0.4680 (0.7947) acc 87.5000 (76.4062) lr 1.8358e-03 eta 0:14:43
epoch [39/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.9097 (0.8245) acc 71.8750 (75.8750) lr 1.8358e-03 eta 0:14:01
epoch [39/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8257 (0.8396) acc 78.1250 (76.1458) lr 1.8358e-03 eta 0:13:33
epoch [39/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.9790 (0.8571) acc 71.8750 (75.8929) lr 1.8358e-03 eta 0:13:13
epoch [39/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8506 (0.8411) acc 75.0000 (76.1719) lr 1.8358e-03 eta 0:12:58
epoch [39/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0303 (0.8378) acc 68.7500 (76.1806) lr 1.8358e-03 eta 0:12:46
epoch [39/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8584 (0.8433) acc 75.0000 (76.0625) lr 1.8271e-03 eta 0:12:36
epoch [40/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.102) loss 0.9463 (0.8479) acc 71.8750 (76.2500) lr 1.8271e-03 eta 0:25:08
epoch [40/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.9229 (0.8900) acc 71.8750 (75.3125) lr 1.8271e-03 eta 0:18:11
epoch [40/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.9194 (0.8386) acc 71.8750 (76.2500) lr 1.8271e-03 eta 0:15:53
epoch [40/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.8311 (0.8537) acc 78.1250 (76.2500) lr 1.8271e-03 eta 0:14:44
epoch [40/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.6118 (0.8630) acc 81.2500 (76.3750) lr 1.8271e-03 eta 0:14:02
epoch [40/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.8638 (0.8500) acc 81.2500 (76.7708) lr 1.8271e-03 eta 0:13:34
epoch [40/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.015) loss 0.8198 (0.8338) acc 71.8750 (76.6964) lr 1.8271e-03 eta 0:13:14
epoch [40/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.4551 (0.8401) acc 84.3750 (76.5625) lr 1.8271e-03 eta 0:12:58
epoch [40/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1699 (0.8505) acc 68.7500 (76.6667) lr 1.8271e-03 eta 0:12:45
epoch [40/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.0176 (0.8653) acc 68.7500 (76.1875) lr 1.8181e-03 eta 0:12:35
epoch [41/200] batch [5/50] time 0.085 (0.198) data 0.000 (0.112) loss 0.7788 (0.8553) acc 75.0000 (73.1250) lr 1.8181e-03 eta 0:26:24
epoch [41/200] batch [10/50] time 0.086 (0.142) data 0.000 (0.056) loss 1.0586 (0.8649) acc 71.8750 (73.7500) lr 1.8181e-03 eta 0:18:51
epoch [41/200] batch [15/50] time 0.085 (0.123) data 0.000 (0.038) loss 0.8008 (0.8146) acc 81.2500 (76.4583) lr 1.8181e-03 eta 0:16:20
epoch [41/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.028) loss 0.6675 (0.7854) acc 81.2500 (77.6562) lr 1.8181e-03 eta 0:15:04
epoch [41/200] batch [25/50] time 0.085 (0.108) data 0.000 (0.023) loss 1.1328 (0.7940) acc 71.8750 (77.5000) lr 1.8181e-03 eta 0:14:18
epoch [41/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.7271 (0.8023) acc 78.1250 (77.2917) lr 1.8181e-03 eta 0:13:47
epoch [41/200] batch [35/50] time 0.083 (0.101) data 0.000 (0.016) loss 0.5742 (0.7939) acc 81.2500 (77.3214) lr 1.8181e-03 eta 0:13:24
epoch [41/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.014) loss 1.3867 (0.8252) acc 65.6250 (76.7969) lr 1.8181e-03 eta 0:13:06
epoch [41/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6631 (0.8300) acc 75.0000 (76.5278) lr 1.8181e-03 eta 0:12:52
epoch [41/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.9170 (0.8301) acc 71.8750 (76.7500) lr 1.8090e-03 eta 0:12:40
epoch [42/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.105) loss 1.0176 (0.9236) acc 71.8750 (75.6250) lr 1.8090e-03 eta 0:25:05
epoch [42/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.8784 (0.9236) acc 78.1250 (75.6250) lr 1.8090e-03 eta 0:18:07
epoch [42/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.7568 (0.8908) acc 75.0000 (76.0417) lr 1.8090e-03 eta 0:15:48
epoch [42/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 1.2949 (0.9268) acc 71.8750 (75.7812) lr 1.8090e-03 eta 0:14:39
epoch [42/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.7539 (0.9263) acc 84.3750 (75.3750) lr 1.8090e-03 eta 0:13:57
epoch [42/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.7407 (0.9031) acc 75.0000 (75.4167) lr 1.8090e-03 eta 0:13:28
epoch [42/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 1.0928 (0.9223) acc 71.8750 (75.1786) lr 1.8090e-03 eta 0:13:08
epoch [42/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.7866 (0.9053) acc 78.1250 (75.2344) lr 1.8090e-03 eta 0:12:52
epoch [42/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8540 (0.9041) acc 75.0000 (75.4861) lr 1.8090e-03 eta 0:12:39
epoch [42/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7651 (0.8938) acc 81.2500 (75.5625) lr 1.7997e-03 eta 0:12:29
epoch [43/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.100) loss 0.5806 (1.0953) acc 87.5000 (71.8750) lr 1.7997e-03 eta 0:24:16
epoch [43/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.8486 (0.9469) acc 81.2500 (74.3750) lr 1.7997e-03 eta 0:17:39
epoch [43/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.8301 (0.8627) acc 78.1250 (76.2500) lr 1.7997e-03 eta 0:15:27
epoch [43/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.0898 (0.8562) acc 65.6250 (76.2500) lr 1.7997e-03 eta 0:14:21
epoch [43/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.6484 (0.8535) acc 81.2500 (76.1250) lr 1.7997e-03 eta 0:13:42
epoch [43/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.1055 (0.8834) acc 68.7500 (75.0000) lr 1.7997e-03 eta 0:13:15
epoch [43/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.0088 (0.8814) acc 71.8750 (75.0000) lr 1.7997e-03 eta 0:12:56
epoch [43/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0254 (0.8908) acc 75.0000 (75.2344) lr 1.7997e-03 eta 0:12:41
epoch [43/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1650 (0.9007) acc 75.0000 (74.8611) lr 1.7997e-03 eta 0:12:29
epoch [43/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.1465 (0.9128) acc 65.6250 (74.7500) lr 1.7902e-03 eta 0:12:19
epoch [44/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.104) loss 0.7061 (0.8220) acc 84.3750 (78.1250) lr 1.7902e-03 eta 0:24:45
epoch [44/200] batch [10/50] time 0.083 (0.136) data 0.000 (0.052) loss 0.9238 (0.7832) acc 68.7500 (77.8125) lr 1.7902e-03 eta 0:17:50
epoch [44/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.8574 (0.7962) acc 78.1250 (77.0833) lr 1.7902e-03 eta 0:15:32
epoch [44/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.026) loss 1.0508 (0.8107) acc 71.8750 (76.5625) lr 1.7902e-03 eta 0:14:21
epoch [44/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.9180 (0.8248) acc 68.7500 (76.2500) lr 1.7902e-03 eta 0:13:40
epoch [44/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.018) loss 0.9111 (0.8285) acc 81.2500 (76.5625) lr 1.7902e-03 eta 0:13:12
epoch [44/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.9189 (0.8402) acc 78.1250 (76.2500) lr 1.7902e-03 eta 0:12:52
epoch [44/200] batch [40/50] time 0.086 (0.097) data 0.000 (0.013) loss 0.8306 (0.8616) acc 78.1250 (75.8594) lr 1.7902e-03 eta 0:12:37
epoch [44/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.012) loss 0.9546 (0.8476) acc 75.0000 (76.5278) lr 1.7902e-03 eta 0:12:25
epoch [44/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.011) loss 1.1807 (0.8535) acc 75.0000 (76.6875) lr 1.7804e-03 eta 0:12:15
epoch [45/200] batch [5/50] time 0.084 (0.179) data 0.000 (0.095) loss 0.7354 (0.8985) acc 78.1250 (75.6250) lr 1.7804e-03 eta 0:23:19
epoch [45/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.048) loss 1.1562 (0.8594) acc 71.8750 (77.8125) lr 1.7804e-03 eta 0:17:08
epoch [45/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.032) loss 0.6938 (0.8809) acc 81.2500 (76.0417) lr 1.7804e-03 eta 0:15:03
epoch [45/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.9253 (0.8661) acc 65.6250 (76.0938) lr 1.7804e-03 eta 0:14:01
epoch [45/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 1.0469 (0.8303) acc 65.6250 (77.2500) lr 1.7804e-03 eta 0:13:24
epoch [45/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.7310 (0.8601) acc 84.3750 (76.6667) lr 1.7804e-03 eta 0:12:59
epoch [45/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7280 (0.8288) acc 84.3750 (77.5893) lr 1.7804e-03 eta 0:12:41
epoch [45/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6567 (0.8492) acc 87.5000 (77.2656) lr 1.7804e-03 eta 0:12:27
epoch [45/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7246 (0.8644) acc 78.1250 (76.6667) lr 1.7804e-03 eta 0:12:15
epoch [45/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9077 (0.8690) acc 75.0000 (76.3750) lr 1.7705e-03 eta 0:12:06
epoch [46/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 1.1055 (0.8958) acc 62.5000 (73.7500) lr 1.7705e-03 eta 0:23:22
epoch [46/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.6909 (0.8365) acc 75.0000 (76.8750) lr 1.7705e-03 eta 0:17:07
epoch [46/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.5615 (0.8165) acc 84.3750 (78.1250) lr 1.7705e-03 eta 0:15:01
epoch [46/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.9023 (0.8374) acc 71.8750 (77.8125) lr 1.7705e-03 eta 0:13:58
epoch [46/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.8911 (0.8661) acc 75.0000 (77.0000) lr 1.7705e-03 eta 0:13:20
epoch [46/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5508 (0.8716) acc 84.3750 (77.0833) lr 1.7705e-03 eta 0:12:54
epoch [46/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 1.2402 (0.8917) acc 71.8750 (76.5179) lr 1.7705e-03 eta 0:12:36
epoch [46/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7734 (0.8716) acc 75.0000 (76.6406) lr 1.7705e-03 eta 0:12:21
epoch [46/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2305 (0.8927) acc 65.6250 (75.8333) lr 1.7705e-03 eta 0:12:10
epoch [46/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.2920 (0.9020) acc 62.5000 (75.3750) lr 1.7604e-03 eta 0:12:00
epoch [47/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.094) loss 0.6182 (0.7487) acc 84.3750 (81.8750) lr 1.7604e-03 eta 0:23:03
epoch [47/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 1.0576 (0.8846) acc 68.7500 (75.9375) lr 1.7604e-03 eta 0:16:53
epoch [47/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 1.1797 (0.9128) acc 68.7500 (75.4167) lr 1.7604e-03 eta 0:14:50
epoch [47/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.8970 (0.8937) acc 75.0000 (74.8438) lr 1.7604e-03 eta 0:13:49
epoch [47/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.7568 (0.8653) acc 81.2500 (75.5000) lr 1.7604e-03 eta 0:13:12
epoch [47/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.1133 (0.8620) acc 68.7500 (76.0417) lr 1.7604e-03 eta 0:12:47
epoch [47/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.0566 (0.8576) acc 71.8750 (75.6250) lr 1.7604e-03 eta 0:12:29
epoch [47/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7002 (0.8466) acc 75.0000 (75.8594) lr 1.7604e-03 eta 0:12:15
epoch [47/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7695 (0.8672) acc 84.3750 (75.4861) lr 1.7604e-03 eta 0:12:04
epoch [47/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.8652 (0.8823) acc 81.2500 (75.3750) lr 1.7501e-03 eta 0:11:55
epoch [48/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.103) loss 0.8926 (1.0342) acc 78.1250 (70.0000) lr 1.7501e-03 eta 0:23:58
epoch [48/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.9980 (0.9015) acc 71.8750 (75.3125) lr 1.7501e-03 eta 0:17:19
epoch [48/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.8911 (0.8705) acc 81.2500 (76.6667) lr 1.7501e-03 eta 0:15:07
epoch [48/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.9888 (0.8823) acc 68.7500 (75.4688) lr 1.7501e-03 eta 0:14:00
epoch [48/200] batch [25/50] time 0.083 (0.105) data 0.000 (0.021) loss 0.5864 (0.8735) acc 87.5000 (76.2500) lr 1.7501e-03 eta 0:13:20
epoch [48/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.9185 (0.8936) acc 75.0000 (75.3125) lr 1.7501e-03 eta 0:12:54
epoch [48/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.9214 (0.8851) acc 65.6250 (75.0000) lr 1.7501e-03 eta 0:12:33
epoch [48/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7666 (0.8798) acc 78.1250 (75.2344) lr 1.7501e-03 eta 0:12:18
epoch [48/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 1.0781 (0.8802) acc 75.0000 (75.4861) lr 1.7501e-03 eta 0:12:06
epoch [48/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7500 (0.8958) acc 78.1250 (75.2500) lr 1.7396e-03 eta 0:11:56
epoch [49/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.100) loss 0.5220 (0.7259) acc 84.3750 (79.3750) lr 1.7396e-03 eta 0:23:28
epoch [49/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.9351 (0.7409) acc 78.1250 (78.4375) lr 1.7396e-03 eta 0:17:02
epoch [49/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.6255 (0.7299) acc 90.6250 (80.0000) lr 1.7396e-03 eta 0:14:54
epoch [49/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 1.2988 (0.7530) acc 65.6250 (79.3750) lr 1.7396e-03 eta 0:13:51
epoch [49/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.9316 (0.7557) acc 78.1250 (79.5000) lr 1.7396e-03 eta 0:13:12
epoch [49/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.4233 (0.7407) acc 90.6250 (79.4792) lr 1.7396e-03 eta 0:12:46
epoch [49/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.9604 (0.7401) acc 68.7500 (79.0179) lr 1.7396e-03 eta 0:12:27
epoch [49/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5801 (0.7500) acc 81.2500 (78.7500) lr 1.7396e-03 eta 0:12:12
epoch [49/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6606 (0.7577) acc 84.3750 (78.8194) lr 1.7396e-03 eta 0:12:00
epoch [49/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.2041 (0.7864) acc 68.7500 (78.0000) lr 1.7290e-03 eta 0:11:51
epoch [50/200] batch [5/50] time 0.085 (0.182) data 0.000 (0.097) loss 0.6069 (0.9529) acc 84.3750 (69.3750) lr 1.7290e-03 eta 0:22:55
epoch [50/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 1.0400 (0.8539) acc 65.6250 (73.4375) lr 1.7290e-03 eta 0:16:45
epoch [50/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 1.2578 (0.8675) acc 65.6250 (74.5833) lr 1.7290e-03 eta 0:14:42
epoch [50/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.7700 (0.8550) acc 71.8750 (75.6250) lr 1.7290e-03 eta 0:13:40
epoch [50/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.9224 (0.8618) acc 78.1250 (76.1250) lr 1.7290e-03 eta 0:13:03
epoch [50/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.5601 (0.8502) acc 81.2500 (76.8750) lr 1.7290e-03 eta 0:12:38
epoch [50/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.9956 (0.8576) acc 75.0000 (76.9643) lr 1.7290e-03 eta 0:12:20
epoch [50/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.5928 (0.8489) acc 75.0000 (76.7188) lr 1.7290e-03 eta 0:12:05
epoch [50/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8975 (0.8383) acc 68.7500 (76.9444) lr 1.7290e-03 eta 0:11:53
epoch [50/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8657 (0.8403) acc 71.8750 (76.8750) lr 1.7181e-03 eta 0:11:44
epoch [51/200] batch [5/50] time 0.086 (0.185) data 0.000 (0.100) loss 1.4336 (0.8590) acc 68.7500 (80.0000) lr 1.7181e-03 eta 0:23:07
epoch [51/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 1.1016 (0.8409) acc 71.8750 (79.6875) lr 1.7181e-03 eta 0:16:51
epoch [51/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.7598 (0.7956) acc 78.1250 (79.1667) lr 1.7181e-03 eta 0:14:46
epoch [51/200] batch [20/50] time 0.085 (0.110) data 0.001 (0.025) loss 1.0020 (0.8236) acc 78.1250 (77.8125) lr 1.7181e-03 eta 0:13:42
epoch [51/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 1.2002 (0.8382) acc 65.6250 (77.3750) lr 1.7181e-03 eta 0:13:04
epoch [51/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.1709 (0.8468) acc 65.6250 (77.2917) lr 1.7181e-03 eta 0:12:39
epoch [51/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7358 (0.8623) acc 71.8750 (76.6071) lr 1.7181e-03 eta 0:12:20
epoch [51/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.0898 (0.8449) acc 71.8750 (76.9531) lr 1.7181e-03 eta 0:12:05
epoch [51/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.6924 (0.8407) acc 87.5000 (77.0833) lr 1.7181e-03 eta 0:11:53
epoch [51/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 0.8906 (0.8356) acc 75.0000 (77.3125) lr 1.7071e-03 eta 0:11:44
epoch [52/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.102) loss 0.9175 (0.9700) acc 75.0000 (74.3750) lr 1.7071e-03 eta 0:23:22
epoch [52/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.051) loss 0.7168 (0.8706) acc 81.2500 (75.0000) lr 1.7071e-03 eta 0:16:56
epoch [52/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.8574 (0.9201) acc 81.2500 (74.1667) lr 1.7071e-03 eta 0:14:48
epoch [52/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.4785 (0.9092) acc 87.5000 (75.0000) lr 1.7071e-03 eta 0:13:42
epoch [52/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.3928 (0.8861) acc 90.6250 (75.3750) lr 1.7071e-03 eta 0:13:02
epoch [52/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.0273 (0.9056) acc 68.7500 (74.5833) lr 1.7071e-03 eta 0:12:35
epoch [52/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7329 (0.9357) acc 78.1250 (73.5714) lr 1.7071e-03 eta 0:12:16
epoch [52/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8794 (0.9122) acc 75.0000 (74.0625) lr 1.7071e-03 eta 0:12:00
epoch [52/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8887 (0.9052) acc 81.2500 (74.5833) lr 1.7071e-03 eta 0:11:49
epoch [52/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 0.8750 (0.8949) acc 81.2500 (74.8750) lr 1.6959e-03 eta 0:11:39
epoch [53/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.097) loss 0.8647 (0.9293) acc 75.0000 (74.3750) lr 1.6959e-03 eta 0:22:33
epoch [53/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 1.0117 (0.8151) acc 68.7500 (76.2500) lr 1.6959e-03 eta 0:16:27
epoch [53/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.6807 (0.8263) acc 84.3750 (77.2917) lr 1.6959e-03 eta 0:14:25
epoch [53/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 1.1182 (0.8833) acc 68.7500 (76.4062) lr 1.6959e-03 eta 0:13:24
epoch [53/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7729 (0.8888) acc 84.3750 (77.2500) lr 1.6959e-03 eta 0:12:47
epoch [53/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.9609 (0.9064) acc 75.0000 (76.3542) lr 1.6959e-03 eta 0:12:22
epoch [53/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8179 (0.8956) acc 71.8750 (75.8929) lr 1.6959e-03 eta 0:12:04
epoch [53/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7095 (0.8938) acc 68.7500 (75.4688) lr 1.6959e-03 eta 0:11:50
epoch [53/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.3887 (0.8808) acc 62.5000 (76.0417) lr 1.6959e-03 eta 0:11:39
epoch [53/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7080 (0.8658) acc 84.3750 (76.1250) lr 1.6845e-03 eta 0:11:30
epoch [54/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.110) loss 0.6245 (0.7137) acc 87.5000 (78.7500) lr 1.6845e-03 eta 0:23:54
epoch [54/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.7480 (0.7848) acc 78.1250 (77.1875) lr 1.6845e-03 eta 0:17:08
epoch [54/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 1.0820 (0.8316) acc 75.0000 (76.4583) lr 1.6845e-03 eta 0:14:50
epoch [54/200] batch [20/50] time 0.083 (0.112) data 0.000 (0.028) loss 0.7153 (0.8115) acc 81.2500 (77.5000) lr 1.6845e-03 eta 0:13:41
epoch [54/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 0.7168 (0.8161) acc 78.1250 (76.8750) lr 1.6845e-03 eta 0:13:00
epoch [54/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.9712 (0.8268) acc 75.0000 (76.4583) lr 1.6845e-03 eta 0:12:33
epoch [54/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5591 (0.8494) acc 87.5000 (76.1607) lr 1.6845e-03 eta 0:12:13
epoch [54/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5166 (0.8294) acc 84.3750 (76.9531) lr 1.6845e-03 eta 0:11:57
epoch [54/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8506 (0.8418) acc 65.6250 (76.1806) lr 1.6845e-03 eta 0:11:44
epoch [54/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5703 (0.8433) acc 81.2500 (76.0000) lr 1.6730e-03 eta 0:11:34
epoch [55/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.100) loss 0.5127 (0.7901) acc 84.3750 (79.3750) lr 1.6730e-03 eta 0:22:29
epoch [55/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 1.2070 (0.8598) acc 62.5000 (76.2500) lr 1.6730e-03 eta 0:16:21
epoch [55/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.7666 (0.8740) acc 78.1250 (74.5833) lr 1.6730e-03 eta 0:14:20
epoch [55/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.7920 (0.8423) acc 71.8750 (75.3125) lr 1.6730e-03 eta 0:13:18
epoch [55/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.5337 (0.8490) acc 84.3750 (74.7500) lr 1.6730e-03 eta 0:12:41
epoch [55/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.9663 (0.8564) acc 71.8750 (75.2083) lr 1.6730e-03 eta 0:12:17
epoch [55/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.4048 (0.8327) acc 90.6250 (75.8929) lr 1.6730e-03 eta 0:11:59
epoch [55/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9512 (0.8209) acc 65.6250 (75.7812) lr 1.6730e-03 eta 0:11:44
epoch [55/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.9302 (0.8241) acc 78.1250 (75.8333) lr 1.6730e-03 eta 0:11:33
epoch [55/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9351 (0.8438) acc 75.0000 (75.6250) lr 1.6613e-03 eta 0:11:24
epoch [56/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.099) loss 0.8315 (0.8351) acc 78.1250 (75.6250) lr 1.6613e-03 eta 0:22:15
epoch [56/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.050) loss 0.9531 (0.8896) acc 78.1250 (75.6250) lr 1.6613e-03 eta 0:16:11
epoch [56/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 1.3652 (0.8217) acc 65.6250 (77.2917) lr 1.6613e-03 eta 0:14:10
epoch [56/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.4104 (0.8130) acc 87.5000 (78.1250) lr 1.6613e-03 eta 0:13:10
epoch [56/200] batch [25/50] time 0.086 (0.104) data 0.000 (0.020) loss 1.2773 (0.8250) acc 68.7500 (77.6250) lr 1.6613e-03 eta 0:12:33
epoch [56/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.8877 (0.8221) acc 65.6250 (77.7083) lr 1.6613e-03 eta 0:12:09
epoch [56/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.8169 (0.8248) acc 81.2500 (77.4107) lr 1.6613e-03 eta 0:11:51
epoch [56/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7373 (0.8091) acc 78.1250 (77.8125) lr 1.6613e-03 eta 0:11:37
epoch [56/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0459 (0.8397) acc 78.1250 (76.8750) lr 1.6613e-03 eta 0:11:26
epoch [56/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5020 (0.8227) acc 87.5000 (77.5000) lr 1.6494e-03 eta 0:11:17
epoch [57/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.094) loss 0.8003 (0.9214) acc 81.2500 (73.7500) lr 1.6494e-03 eta 0:21:27
epoch [57/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.5078 (0.7939) acc 87.5000 (77.5000) lr 1.6494e-03 eta 0:15:47
epoch [57/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.031) loss 0.4136 (0.7977) acc 93.7500 (78.3333) lr 1.6494e-03 eta 0:13:53
epoch [57/200] batch [20/50] time 0.083 (0.108) data 0.000 (0.024) loss 1.0234 (0.8264) acc 75.0000 (77.5000) lr 1.6494e-03 eta 0:12:56
epoch [57/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.6826 (0.8474) acc 81.2500 (76.5000) lr 1.6494e-03 eta 0:12:21
epoch [57/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6221 (0.8512) acc 81.2500 (76.5625) lr 1.6494e-03 eta 0:11:57
epoch [57/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 1.1230 (0.8584) acc 68.7500 (76.6071) lr 1.6494e-03 eta 0:11:41
epoch [57/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0225 (0.8587) acc 65.6250 (76.2500) lr 1.6494e-03 eta 0:11:28
epoch [57/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4407 (0.8637) acc 90.6250 (76.1806) lr 1.6494e-03 eta 0:11:17
epoch [57/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6860 (0.8629) acc 81.2500 (76.2500) lr 1.6374e-03 eta 0:11:08
epoch [58/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.106) loss 0.6001 (0.8100) acc 87.5000 (79.3750) lr 1.6374e-03 eta 0:22:38
epoch [58/200] batch [10/50] time 0.083 (0.137) data 0.000 (0.053) loss 1.3672 (0.8581) acc 71.8750 (76.8750) lr 1.6374e-03 eta 0:16:17
epoch [58/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.8901 (0.8525) acc 71.8750 (76.6667) lr 1.6374e-03 eta 0:14:11
epoch [58/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.027) loss 0.7432 (0.8419) acc 78.1250 (77.3438) lr 1.6374e-03 eta 0:13:07
epoch [58/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.4482 (0.8987) acc 59.3750 (76.2500) lr 1.6374e-03 eta 0:12:29
epoch [58/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.4941 (0.9143) acc 65.6250 (75.7292) lr 1.6374e-03 eta 0:12:04
epoch [58/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.5610 (0.9209) acc 84.3750 (75.4464) lr 1.6374e-03 eta 0:11:46
epoch [58/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8853 (0.9103) acc 78.1250 (75.9375) lr 1.6374e-03 eta 0:11:31
epoch [58/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6113 (0.9078) acc 87.5000 (76.3194) lr 1.6374e-03 eta 0:11:20
epoch [58/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8887 (0.9147) acc 68.7500 (76.1250) lr 1.6252e-03 eta 0:11:11
epoch [59/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.101) loss 1.0859 (0.9459) acc 71.8750 (76.8750) lr 1.6252e-03 eta 0:21:57
epoch [59/200] batch [10/50] time 0.083 (0.135) data 0.000 (0.051) loss 0.8477 (0.8542) acc 84.3750 (78.1250) lr 1.6252e-03 eta 0:15:56
epoch [59/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.034) loss 1.0898 (0.8730) acc 68.7500 (77.2917) lr 1.6252e-03 eta 0:13:56
epoch [59/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.5449 (0.8346) acc 90.6250 (78.7500) lr 1.6252e-03 eta 0:12:58
epoch [59/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.6523 (0.7918) acc 81.2500 (79.2500) lr 1.6252e-03 eta 0:12:21
epoch [59/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.9004 (0.8172) acc 75.0000 (78.7500) lr 1.6252e-03 eta 0:11:57
epoch [59/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6479 (0.7999) acc 81.2500 (79.0179) lr 1.6252e-03 eta 0:11:40
epoch [59/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7783 (0.7984) acc 71.8750 (78.3594) lr 1.6252e-03 eta 0:11:26
epoch [59/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.6279 (0.8048) acc 78.1250 (77.9861) lr 1.6252e-03 eta 0:11:15
epoch [59/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.1846 (0.8206) acc 62.5000 (77.6250) lr 1.6129e-03 eta 0:11:06
epoch [60/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 0.9092 (0.8946) acc 68.7500 (78.1250) lr 1.6129e-03 eta 0:21:07
epoch [60/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.6353 (0.8456) acc 81.2500 (77.8125) lr 1.6129e-03 eta 0:15:28
epoch [60/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 0.8125 (0.7948) acc 75.0000 (78.1250) lr 1.6129e-03 eta 0:13:36
epoch [60/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.8350 (0.8238) acc 71.8750 (77.3438) lr 1.6129e-03 eta 0:12:40
epoch [60/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.5254 (0.8049) acc 87.5000 (78.0000) lr 1.6129e-03 eta 0:12:06
epoch [60/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.4534 (0.8025) acc 90.6250 (77.9167) lr 1.6129e-03 eta 0:11:43
epoch [60/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.8516 (0.8140) acc 75.0000 (77.4107) lr 1.6129e-03 eta 0:11:27
epoch [60/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9937 (0.8353) acc 75.0000 (77.1094) lr 1.6129e-03 eta 0:11:14
epoch [60/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.6748 (0.8530) acc 50.0000 (76.4583) lr 1.6129e-03 eta 0:11:04
epoch [60/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9302 (0.8375) acc 71.8750 (76.6250) lr 1.6004e-03 eta 0:10:55
epoch [61/200] batch [5/50] time 0.085 (0.178) data 0.000 (0.093) loss 0.6992 (0.6692) acc 75.0000 (79.3750) lr 1.6004e-03 eta 0:20:48
epoch [61/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.7690 (0.7543) acc 71.8750 (77.8125) lr 1.6004e-03 eta 0:15:18
epoch [61/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.031) loss 0.8789 (0.7722) acc 75.0000 (77.2917) lr 1.6004e-03 eta 0:13:29
epoch [61/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.023) loss 0.9180 (0.8246) acc 75.0000 (76.8750) lr 1.6004e-03 eta 0:12:34
epoch [61/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 1.2334 (0.8021) acc 71.8750 (77.7500) lr 1.6004e-03 eta 0:12:01
epoch [61/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6299 (0.8276) acc 84.3750 (76.7708) lr 1.6004e-03 eta 0:11:39
epoch [61/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.6963 (0.8303) acc 75.0000 (76.3393) lr 1.6004e-03 eta 0:11:23
epoch [61/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6875 (0.8325) acc 84.3750 (76.5625) lr 1.6004e-03 eta 0:11:10
epoch [61/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8364 (0.8734) acc 71.8750 (75.7639) lr 1.6004e-03 eta 0:11:00
epoch [61/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.009) loss 1.0674 (0.8727) acc 68.7500 (75.7500) lr 1.5878e-03 eta 0:10:51
epoch [62/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.102) loss 0.6567 (0.6966) acc 84.3750 (79.3750) lr 1.5878e-03 eta 0:21:39
epoch [62/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 1.4238 (0.7687) acc 59.3750 (75.9375) lr 1.5878e-03 eta 0:15:43
epoch [62/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 1.0566 (0.8317) acc 78.1250 (76.2500) lr 1.5878e-03 eta 0:13:44
epoch [62/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.7368 (0.8189) acc 81.2500 (76.8750) lr 1.5878e-03 eta 0:12:44
epoch [62/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.9731 (0.8342) acc 75.0000 (76.6250) lr 1.5878e-03 eta 0:12:08
epoch [62/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.8003 (0.8152) acc 81.2500 (77.7083) lr 1.5878e-03 eta 0:11:44
epoch [62/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 1.2705 (0.8614) acc 75.0000 (76.6964) lr 1.5878e-03 eta 0:11:26
epoch [62/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.1250 (0.8630) acc 71.8750 (76.6406) lr 1.5878e-03 eta 0:11:12
epoch [62/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8257 (0.8749) acc 78.1250 (75.9722) lr 1.5878e-03 eta 0:11:01
epoch [62/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.4863 (0.8588) acc 84.3750 (76.4375) lr 1.5750e-03 eta 0:10:53
epoch [63/200] batch [5/50] time 0.085 (0.182) data 0.000 (0.096) loss 1.2402 (0.9862) acc 65.6250 (75.6250) lr 1.5750e-03 eta 0:20:55
epoch [63/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.7607 (0.9285) acc 78.1250 (75.0000) lr 1.5750e-03 eta 0:15:19
epoch [63/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.9482 (0.9018) acc 68.7500 (75.2083) lr 1.5750e-03 eta 0:13:27
epoch [63/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.4734 (0.9068) acc 87.5000 (75.4688) lr 1.5750e-03 eta 0:12:30
epoch [63/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.4441 (0.8858) acc 93.7500 (76.1250) lr 1.5750e-03 eta 0:11:55
epoch [63/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 1.0850 (0.8679) acc 68.7500 (76.4583) lr 1.5750e-03 eta 0:11:32
epoch [63/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9043 (0.8354) acc 75.0000 (77.2321) lr 1.5750e-03 eta 0:11:15
epoch [63/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0430 (0.8752) acc 71.8750 (76.4844) lr 1.5750e-03 eta 0:11:02
epoch [63/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4343 (0.8759) acc 87.5000 (76.4583) lr 1.5750e-03 eta 0:10:51
epoch [63/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8623 (0.8680) acc 75.0000 (76.5625) lr 1.5621e-03 eta 0:10:43
epoch [64/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.103) loss 0.6250 (0.7123) acc 78.1250 (81.2500) lr 1.5621e-03 eta 0:21:23
epoch [64/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.6675 (0.8288) acc 78.1250 (77.1875) lr 1.5621e-03 eta 0:15:33
epoch [64/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.7041 (0.8015) acc 78.1250 (77.0833) lr 1.5621e-03 eta 0:13:34
epoch [64/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.6299 (0.7927) acc 81.2500 (76.8750) lr 1.5621e-03 eta 0:12:35
epoch [64/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.7188 (0.7826) acc 78.1250 (77.0000) lr 1.5621e-03 eta 0:11:59
epoch [64/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.9854 (0.7891) acc 71.8750 (77.1875) lr 1.5621e-03 eta 0:11:35
epoch [64/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.9712 (0.7858) acc 71.8750 (77.5893) lr 1.5621e-03 eta 0:11:18
epoch [64/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0420 (0.8007) acc 68.7500 (77.2656) lr 1.5621e-03 eta 0:11:03
epoch [64/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1133 (0.8085) acc 68.7500 (77.5000) lr 1.5621e-03 eta 0:10:52
epoch [64/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8022 (0.8176) acc 75.0000 (77.1250) lr 1.5490e-03 eta 0:10:43
epoch [65/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 0.5405 (0.8064) acc 90.6250 (77.5000) lr 1.5490e-03 eta 0:21:22
epoch [65/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.7651 (0.8455) acc 75.0000 (75.6250) lr 1.5490e-03 eta 0:15:27
epoch [65/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.6899 (0.7841) acc 84.3750 (77.2917) lr 1.5490e-03 eta 0:13:28
epoch [65/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.0498 (0.8044) acc 65.6250 (77.1875) lr 1.5490e-03 eta 0:12:28
epoch [65/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.6021 (0.7637) acc 87.5000 (78.2500) lr 1.5490e-03 eta 0:11:53
epoch [65/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.5127 (0.7939) acc 90.6250 (77.5000) lr 1.5490e-03 eta 0:11:28
epoch [65/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 1.0088 (0.7973) acc 78.1250 (77.5893) lr 1.5490e-03 eta 0:11:11
epoch [65/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6357 (0.7941) acc 78.1250 (77.8125) lr 1.5490e-03 eta 0:10:57
epoch [65/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.9917 (0.7993) acc 71.8750 (77.5694) lr 1.5490e-03 eta 0:10:46
epoch [65/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.011) loss 0.8340 (0.8070) acc 81.2500 (77.3750) lr 1.5358e-03 eta 0:10:37
epoch [66/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.7515 (0.6679) acc 78.1250 (82.5000) lr 1.5358e-03 eta 0:20:23
epoch [66/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.4766 (0.7312) acc 87.5000 (80.9375) lr 1.5358e-03 eta 0:14:56
epoch [66/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.2583 (0.7129) acc 90.6250 (80.4167) lr 1.5358e-03 eta 0:13:06
epoch [66/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 1.3320 (0.7281) acc 62.5000 (80.1562) lr 1.5358e-03 eta 0:12:12
epoch [66/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.9365 (0.7318) acc 78.1250 (79.7500) lr 1.5358e-03 eta 0:11:39
epoch [66/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.6128 (0.7266) acc 81.2500 (79.6875) lr 1.5358e-03 eta 0:11:17
epoch [66/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 0.7144 (0.7131) acc 81.2500 (80.0893) lr 1.5358e-03 eta 0:11:01
epoch [66/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0010 (0.7160) acc 78.1250 (79.8438) lr 1.5358e-03 eta 0:10:48
epoch [66/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6216 (0.7320) acc 78.1250 (79.3056) lr 1.5358e-03 eta 0:10:38
epoch [66/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5205 (0.7422) acc 84.3750 (79.3750) lr 1.5225e-03 eta 0:10:30
epoch [67/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.097) loss 0.6201 (0.6834) acc 81.2500 (81.2500) lr 1.5225e-03 eta 0:20:33
epoch [67/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 1.2422 (0.8454) acc 78.1250 (78.1250) lr 1.5225e-03 eta 0:14:59
epoch [67/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.6304 (0.8041) acc 81.2500 (79.1667) lr 1.5225e-03 eta 0:13:07
epoch [67/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.5967 (0.8037) acc 87.5000 (79.2188) lr 1.5225e-03 eta 0:12:11
epoch [67/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.7280 (0.7737) acc 81.2500 (80.0000) lr 1.5225e-03 eta 0:11:38
epoch [67/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.9067 (0.7705) acc 75.0000 (79.3750) lr 1.5225e-03 eta 0:11:15
epoch [67/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.014) loss 0.5762 (0.7816) acc 81.2500 (79.1964) lr 1.5225e-03 eta 0:10:59
epoch [67/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.8120 (0.8025) acc 78.1250 (78.4375) lr 1.5225e-03 eta 0:10:45
epoch [67/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7446 (0.8023) acc 87.5000 (78.5417) lr 1.5225e-03 eta 0:10:35
epoch [67/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6548 (0.8063) acc 75.0000 (78.0000) lr 1.5090e-03 eta 0:10:27
epoch [68/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 0.4712 (0.8295) acc 90.6250 (78.1250) lr 1.5090e-03 eta 0:19:57
epoch [68/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.048) loss 0.5972 (0.8022) acc 81.2500 (79.0625) lr 1.5090e-03 eta 0:14:37
epoch [68/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 0.7314 (0.8009) acc 75.0000 (78.3333) lr 1.5090e-03 eta 0:12:51
epoch [68/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.6245 (0.7982) acc 87.5000 (79.0625) lr 1.5090e-03 eta 0:11:57
epoch [68/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.8755 (0.8000) acc 84.3750 (79.1250) lr 1.5090e-03 eta 0:11:25
epoch [68/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.6528 (0.8093) acc 81.2500 (79.0625) lr 1.5090e-03 eta 0:11:03
epoch [68/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.9888 (0.8325) acc 71.8750 (78.8393) lr 1.5090e-03 eta 0:10:48
epoch [68/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.9922 (0.8216) acc 75.0000 (78.9844) lr 1.5090e-03 eta 0:10:35
epoch [68/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7168 (0.8034) acc 75.0000 (78.9583) lr 1.5090e-03 eta 0:10:25
epoch [68/200] batch [50/50] time 0.085 (0.094) data 0.000 (0.010) loss 0.9438 (0.8086) acc 75.0000 (79.0625) lr 1.4955e-03 eta 0:10:18
epoch [69/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.105) loss 0.6191 (0.6010) acc 81.2500 (83.7500) lr 1.4955e-03 eta 0:20:59
epoch [69/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.7827 (0.6751) acc 81.2500 (81.5625) lr 1.4955e-03 eta 0:15:08
epoch [69/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.3879 (0.6818) acc 90.6250 (81.6667) lr 1.4955e-03 eta 0:13:11
epoch [69/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 1.0537 (0.7295) acc 62.5000 (80.4688) lr 1.4955e-03 eta 0:12:12
epoch [69/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.5723 (0.7491) acc 84.3750 (79.7500) lr 1.4955e-03 eta 0:11:36
epoch [69/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 1.0381 (0.7640) acc 68.7500 (78.9583) lr 1.4955e-03 eta 0:11:13
epoch [69/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.7861 (0.7842) acc 78.1250 (78.6607) lr 1.4955e-03 eta 0:10:56
epoch [69/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 1.0566 (0.7872) acc 75.0000 (78.2812) lr 1.4955e-03 eta 0:10:42
epoch [69/200] batch [45/50] time 0.085 (0.096) data 0.000 (0.012) loss 0.9521 (0.7769) acc 81.2500 (78.6111) lr 1.4955e-03 eta 0:10:31
epoch [69/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4871 (0.7661) acc 87.5000 (79.0000) lr 1.4818e-03 eta 0:10:22
epoch [70/200] batch [5/50] time 0.083 (0.185) data 0.000 (0.100) loss 0.9092 (0.7376) acc 81.2500 (84.3750) lr 1.4818e-03 eta 0:20:12
epoch [70/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 1.4971 (0.9251) acc 65.6250 (76.8750) lr 1.4818e-03 eta 0:14:40
epoch [70/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.034) loss 0.6992 (0.8141) acc 75.0000 (78.3333) lr 1.4818e-03 eta 0:12:50
epoch [70/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.5635 (0.7879) acc 87.5000 (79.2188) lr 1.4818e-03 eta 0:11:55
epoch [70/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.5371 (0.7484) acc 87.5000 (80.1250) lr 1.4818e-03 eta 0:11:22
epoch [70/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8608 (0.7445) acc 84.3750 (80.0000) lr 1.4818e-03 eta 0:10:59
epoch [70/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.1270 (0.7770) acc 71.8750 (79.1071) lr 1.4818e-03 eta 0:10:44
epoch [70/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8696 (0.7825) acc 71.8750 (78.8281) lr 1.4818e-03 eta 0:10:30
epoch [70/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9502 (0.7882) acc 78.1250 (78.5417) lr 1.4818e-03 eta 0:10:20
epoch [70/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6260 (0.7893) acc 84.3750 (78.5000) lr 1.4679e-03 eta 0:10:12
epoch [71/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.100) loss 0.5635 (0.5845) acc 84.3750 (84.3750) lr 1.4679e-03 eta 0:20:03
epoch [71/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.8447 (0.6564) acc 81.2500 (83.1250) lr 1.4679e-03 eta 0:14:37
epoch [71/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.6548 (0.6757) acc 81.2500 (82.5000) lr 1.4679e-03 eta 0:12:47
epoch [71/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.8345 (0.7227) acc 75.0000 (81.5625) lr 1.4679e-03 eta 0:11:52
epoch [71/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.7334 (0.7292) acc 75.0000 (81.0000) lr 1.4679e-03 eta 0:11:19
epoch [71/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.7524 (0.7200) acc 68.7500 (80.5208) lr 1.4679e-03 eta 0:10:57
epoch [71/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.8896 (0.7087) acc 78.1250 (80.8036) lr 1.4679e-03 eta 0:10:41
epoch [71/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5352 (0.7157) acc 87.5000 (80.4688) lr 1.4679e-03 eta 0:10:27
epoch [71/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.7979 (0.7290) acc 75.0000 (80.2778) lr 1.4679e-03 eta 0:10:17
epoch [71/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7339 (0.7359) acc 78.1250 (80.1875) lr 1.4540e-03 eta 0:10:09
epoch [72/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.098) loss 0.9219 (0.7733) acc 75.0000 (76.2500) lr 1.4540e-03 eta 0:19:47
epoch [72/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.5376 (0.6918) acc 87.5000 (82.5000) lr 1.4540e-03 eta 0:14:25
epoch [72/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.7617 (0.7247) acc 84.3750 (81.8750) lr 1.4540e-03 eta 0:12:38
epoch [72/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.6855 (0.7056) acc 81.2500 (81.8750) lr 1.4540e-03 eta 0:11:45
epoch [72/200] batch [25/50] time 0.086 (0.105) data 0.000 (0.020) loss 1.1475 (0.7087) acc 65.6250 (81.5000) lr 1.4540e-03 eta 0:11:12
epoch [72/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.9434 (0.7639) acc 65.6250 (79.5833) lr 1.4540e-03 eta 0:10:50
epoch [72/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.6938 (0.7694) acc 78.1250 (78.8393) lr 1.4540e-03 eta 0:10:34
epoch [72/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 1.1963 (0.8066) acc 71.8750 (78.0469) lr 1.4540e-03 eta 0:10:22
epoch [72/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.8438 (0.8123) acc 81.2500 (77.7083) lr 1.4540e-03 eta 0:10:12
epoch [72/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6567 (0.8120) acc 81.2500 (77.6875) lr 1.4399e-03 eta 0:10:04
epoch [73/200] batch [5/50] time 0.083 (0.188) data 0.000 (0.103) loss 1.3467 (0.9396) acc 59.3750 (73.7500) lr 1.4399e-03 eta 0:19:59
epoch [73/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.052) loss 0.8560 (0.8539) acc 78.1250 (75.9375) lr 1.4399e-03 eta 0:14:29
epoch [73/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.4846 (0.7784) acc 87.5000 (78.3333) lr 1.4399e-03 eta 0:12:38
epoch [73/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.9814 (0.7661) acc 75.0000 (78.9062) lr 1.4399e-03 eta 0:11:42
epoch [73/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.0635 (0.7858) acc 68.7500 (77.3750) lr 1.4399e-03 eta 0:11:09
epoch [73/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.7881 (0.7713) acc 68.7500 (77.8125) lr 1.4399e-03 eta 0:10:46
epoch [73/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.4236 (0.7665) acc 84.3750 (78.1250) lr 1.4399e-03 eta 0:10:30
epoch [73/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6982 (0.7682) acc 78.1250 (78.2031) lr 1.4399e-03 eta 0:10:17
epoch [73/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.3291 (0.7813) acc 75.0000 (77.9167) lr 1.4399e-03 eta 0:10:07
epoch [73/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7012 (0.7930) acc 78.1250 (77.5625) lr 1.4258e-03 eta 0:09:59
epoch [74/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.107) loss 0.3381 (0.7265) acc 90.6250 (80.0000) lr 1.4258e-03 eta 0:20:18
epoch [74/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.054) loss 1.4092 (0.8102) acc 59.3750 (79.0625) lr 1.4258e-03 eta 0:14:37
epoch [74/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.5938 (0.7889) acc 78.1250 (78.9583) lr 1.4258e-03 eta 0:12:43
epoch [74/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.8066 (0.7865) acc 78.1250 (78.4375) lr 1.4258e-03 eta 0:11:45
epoch [74/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 1.0986 (0.7922) acc 75.0000 (78.3750) lr 1.4258e-03 eta 0:11:11
epoch [74/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.7427 (0.8000) acc 84.3750 (77.9167) lr 1.4258e-03 eta 0:10:48
epoch [74/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.3325 (0.7945) acc 93.7500 (78.3929) lr 1.4258e-03 eta 0:10:31
epoch [74/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4136 (0.7861) acc 90.6250 (78.2031) lr 1.4258e-03 eta 0:10:18
epoch [74/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6084 (0.7738) acc 78.1250 (78.6111) lr 1.4258e-03 eta 0:10:08
epoch [74/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7539 (0.7676) acc 81.2500 (79.0000) lr 1.4115e-03 eta 0:09:59
epoch [75/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.100) loss 0.9614 (0.5580) acc 75.0000 (86.2500) lr 1.4115e-03 eta 0:19:25
epoch [75/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.8423 (0.6765) acc 78.1250 (81.2500) lr 1.4115e-03 eta 0:14:07
epoch [75/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.6621 (0.6799) acc 84.3750 (81.6667) lr 1.4115e-03 eta 0:12:21
epoch [75/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.4124 (0.6721) acc 90.6250 (82.1875) lr 1.4115e-03 eta 0:11:27
epoch [75/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.4954 (0.7028) acc 84.3750 (81.2500) lr 1.4115e-03 eta 0:10:55
epoch [75/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9058 (0.7047) acc 68.7500 (80.6250) lr 1.4115e-03 eta 0:10:33
epoch [75/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.5952 (0.7195) acc 81.2500 (80.0000) lr 1.4115e-03 eta 0:10:17
epoch [75/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6260 (0.7354) acc 78.1250 (80.0781) lr 1.4115e-03 eta 0:10:05
epoch [75/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0166 (0.7296) acc 75.0000 (80.1389) lr 1.4115e-03 eta 0:09:55
epoch [75/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9067 (0.7441) acc 71.8750 (79.6875) lr 1.3971e-03 eta 0:09:47
epoch [76/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 0.7153 (0.6467) acc 84.3750 (82.5000) lr 1.3971e-03 eta 0:18:46
epoch [76/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.048) loss 0.6675 (0.7635) acc 78.1250 (79.0625) lr 1.3971e-03 eta 0:13:44
epoch [76/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 1.1816 (0.8320) acc 68.7500 (77.2917) lr 1.3971e-03 eta 0:12:04
epoch [76/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.9902 (0.8187) acc 68.7500 (77.1875) lr 1.3971e-03 eta 0:11:15
epoch [76/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.8652 (0.7905) acc 78.1250 (77.7500) lr 1.3971e-03 eta 0:10:44
epoch [76/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 1.3301 (0.7973) acc 65.6250 (77.9167) lr 1.3971e-03 eta 0:10:24
epoch [76/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.8799 (0.7825) acc 75.0000 (78.0357) lr 1.3971e-03 eta 0:10:10
epoch [76/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0420 (0.8048) acc 71.8750 (77.1875) lr 1.3971e-03 eta 0:09:58
epoch [76/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.4238 (0.8313) acc 62.5000 (76.3889) lr 1.3971e-03 eta 0:09:49
epoch [76/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.0674 (0.8305) acc 68.7500 (76.5000) lr 1.3827e-03 eta 0:09:41
epoch [77/200] batch [5/50] time 0.084 (0.195) data 0.000 (0.110) loss 1.2656 (0.8909) acc 68.7500 (74.3750) lr 1.3827e-03 eta 0:20:07
epoch [77/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.055) loss 0.4792 (0.7988) acc 84.3750 (75.6250) lr 1.3827e-03 eta 0:14:24
epoch [77/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 1.0000 (0.8004) acc 68.7500 (76.2500) lr 1.3827e-03 eta 0:12:29
epoch [77/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.7065 (0.7691) acc 75.0000 (77.5000) lr 1.3827e-03 eta 0:11:31
epoch [77/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.7637 (0.7625) acc 68.7500 (78.2500) lr 1.3827e-03 eta 0:10:57
epoch [77/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.6641 (0.7700) acc 84.3750 (77.3958) lr 1.3827e-03 eta 0:10:34
epoch [77/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.1719 (0.7925) acc 65.6250 (76.8750) lr 1.3827e-03 eta 0:10:17
epoch [77/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.8442 (0.7906) acc 71.8750 (77.1094) lr 1.3827e-03 eta 0:10:04
epoch [77/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9897 (0.8013) acc 71.8750 (76.3889) lr 1.3827e-03 eta 0:09:53
epoch [77/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7695 (0.8164) acc 81.2500 (76.1250) lr 1.3681e-03 eta 0:09:45
epoch [78/200] batch [5/50] time 0.084 (0.178) data 0.000 (0.093) loss 0.5752 (0.7184) acc 81.2500 (78.1250) lr 1.3681e-03 eta 0:18:15
epoch [78/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.4001 (0.8278) acc 93.7500 (78.7500) lr 1.3681e-03 eta 0:13:26
epoch [78/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.031) loss 0.6729 (0.8304) acc 84.3750 (78.1250) lr 1.3681e-03 eta 0:11:49
epoch [78/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.023) loss 0.9180 (0.7929) acc 81.2500 (79.3750) lr 1.3681e-03 eta 0:11:01
epoch [78/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.6841 (0.7616) acc 81.2500 (79.7500) lr 1.3681e-03 eta 0:10:32
epoch [78/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7490 (0.7725) acc 87.5000 (79.5833) lr 1.3681e-03 eta 0:10:12
epoch [78/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.9609 (0.7645) acc 78.1250 (80.0893) lr 1.3681e-03 eta 0:09:58
epoch [78/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7358 (0.7703) acc 78.1250 (79.6094) lr 1.3681e-03 eta 0:09:47
epoch [78/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2129 (0.7998) acc 68.7500 (78.7500) lr 1.3681e-03 eta 0:09:37
epoch [78/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7837 (0.8041) acc 81.2500 (78.5000) lr 1.3535e-03 eta 0:09:30
epoch [79/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.097) loss 0.9150 (0.7332) acc 75.0000 (78.7500) lr 1.3535e-03 eta 0:18:33
epoch [79/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 1.0791 (0.7603) acc 71.8750 (79.3750) lr 1.3535e-03 eta 0:13:31
epoch [79/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 0.5122 (0.7599) acc 87.5000 (80.0000) lr 1.3535e-03 eta 0:11:50
epoch [79/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.7295 (0.7893) acc 84.3750 (79.6875) lr 1.3535e-03 eta 0:11:01
epoch [79/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.9302 (0.7707) acc 81.2500 (80.3750) lr 1.3535e-03 eta 0:10:31
epoch [79/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.7231 (0.7724) acc 68.7500 (79.8958) lr 1.3535e-03 eta 0:10:11
epoch [79/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.6704 (0.7666) acc 68.7500 (79.3750) lr 1.3535e-03 eta 0:09:57
epoch [79/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.6411 (0.7696) acc 84.3750 (79.3750) lr 1.3535e-03 eta 0:09:45
epoch [79/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5264 (0.7747) acc 81.2500 (78.8889) lr 1.3535e-03 eta 0:09:36
epoch [79/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8677 (0.7796) acc 68.7500 (78.7500) lr 1.3387e-03 eta 0:09:28
epoch [80/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.105) loss 0.5410 (0.8487) acc 84.3750 (74.3750) lr 1.3387e-03 eta 0:19:20
epoch [80/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.053) loss 0.8101 (0.8362) acc 78.1250 (75.6250) lr 1.3387e-03 eta 0:13:57
epoch [80/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.035) loss 0.7896 (0.8549) acc 68.7500 (74.3750) lr 1.3387e-03 eta 0:12:09
epoch [80/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.9194 (0.8328) acc 75.0000 (75.4688) lr 1.3387e-03 eta 0:11:15
epoch [80/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.021) loss 0.7090 (0.8188) acc 84.3750 (76.5000) lr 1.3387e-03 eta 0:10:42
epoch [80/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.8027 (0.8144) acc 78.1250 (76.8750) lr 1.3387e-03 eta 0:10:20
epoch [80/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 1.2510 (0.8164) acc 68.7500 (76.9643) lr 1.3387e-03 eta 0:10:03
epoch [80/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.9585 (0.8205) acc 81.2500 (76.8750) lr 1.3387e-03 eta 0:09:50
epoch [80/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.5190 (0.8068) acc 84.3750 (76.9444) lr 1.3387e-03 eta 0:09:40
epoch [80/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8296 (0.8039) acc 81.2500 (77.3125) lr 1.3239e-03 eta 0:09:31
epoch [81/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.106) loss 0.4304 (0.7401) acc 90.6250 (76.8750) lr 1.3239e-03 eta 0:19:03
epoch [81/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.8569 (0.8242) acc 78.1250 (75.6250) lr 1.3239e-03 eta 0:13:45
epoch [81/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 1.1006 (0.8583) acc 68.7500 (75.4167) lr 1.3239e-03 eta 0:11:58
epoch [81/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.7158 (0.8014) acc 78.1250 (77.3438) lr 1.3239e-03 eta 0:11:04
epoch [81/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.6177 (0.7670) acc 81.2500 (78.6250) lr 1.3239e-03 eta 0:10:32
epoch [81/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.5796 (0.7713) acc 84.3750 (78.9583) lr 1.3239e-03 eta 0:10:11
epoch [81/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 1.1523 (0.7667) acc 62.5000 (78.3929) lr 1.3239e-03 eta 0:09:54
epoch [81/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.3914 (0.7489) acc 93.7500 (78.7500) lr 1.3239e-03 eta 0:09:42
epoch [81/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5688 (0.7584) acc 84.3750 (78.4028) lr 1.3239e-03 eta 0:09:32
epoch [81/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4050 (0.7502) acc 96.8750 (78.9375) lr 1.3090e-03 eta 0:09:23
epoch [82/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.102) loss 0.6860 (0.7610) acc 81.2500 (78.1250) lr 1.3090e-03 eta 0:18:32
epoch [82/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.6323 (0.7219) acc 84.3750 (80.3125) lr 1.3090e-03 eta 0:13:26
epoch [82/200] batch [15/50] time 0.083 (0.118) data 0.000 (0.034) loss 0.9409 (0.7549) acc 78.1250 (80.2083) lr 1.3090e-03 eta 0:11:42
epoch [82/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.6997 (0.7361) acc 75.0000 (79.3750) lr 1.3090e-03 eta 0:10:52
epoch [82/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.5918 (0.7160) acc 84.3750 (80.3750) lr 1.3090e-03 eta 0:10:21
epoch [82/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.1943 (0.7378) acc 68.7500 (80.1042) lr 1.3090e-03 eta 0:10:01
epoch [82/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.5874 (0.7371) acc 81.2500 (80.1786) lr 1.3090e-03 eta 0:09:46
epoch [82/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7793 (0.7539) acc 75.0000 (79.1406) lr 1.3090e-03 eta 0:09:34
epoch [82/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.6479 (0.7766) acc 87.5000 (79.0278) lr 1.3090e-03 eta 0:09:24
epoch [82/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.0098 (0.7892) acc 78.1250 (78.6875) lr 1.2940e-03 eta 0:09:16
epoch [83/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 0.8184 (0.7509) acc 75.0000 (79.3750) lr 1.2940e-03 eta 0:17:54
epoch [83/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.049) loss 0.8618 (0.7892) acc 71.8750 (79.3750) lr 1.2940e-03 eta 0:13:05
epoch [83/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.8994 (0.7391) acc 75.0000 (80.0000) lr 1.2940e-03 eta 0:11:27
epoch [83/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.024) loss 0.9683 (0.7346) acc 65.6250 (79.3750) lr 1.2940e-03 eta 0:10:39
epoch [83/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 1.0283 (0.7177) acc 78.1250 (80.0000) lr 1.2940e-03 eta 0:10:09
epoch [83/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 1.4463 (0.7854) acc 71.8750 (78.4375) lr 1.2940e-03 eta 0:09:49
epoch [83/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 0.6992 (0.7666) acc 81.2500 (78.7500) lr 1.2940e-03 eta 0:09:36
epoch [83/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7891 (0.7689) acc 78.1250 (78.9062) lr 1.2940e-03 eta 0:09:24
epoch [83/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8848 (0.7652) acc 68.7500 (78.8889) lr 1.2940e-03 eta 0:09:16
epoch [83/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.3713 (0.7901) acc 93.7500 (78.0625) lr 1.2790e-03 eta 0:09:09
epoch [84/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 1.0586 (1.0315) acc 71.8750 (74.3750) lr 1.2790e-03 eta 0:17:46
epoch [84/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.048) loss 0.5186 (0.8363) acc 81.2500 (77.1875) lr 1.2790e-03 eta 0:13:00
epoch [84/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 1.0996 (0.8089) acc 71.8750 (77.9167) lr 1.2790e-03 eta 0:11:25
epoch [84/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.5234 (0.7761) acc 78.1250 (79.0625) lr 1.2790e-03 eta 0:10:37
epoch [84/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.6973 (0.7626) acc 78.1250 (79.3750) lr 1.2790e-03 eta 0:10:08
epoch [84/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.7422 (0.7695) acc 81.2500 (79.0625) lr 1.2790e-03 eta 0:09:48
epoch [84/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 1.0713 (0.7807) acc 81.2500 (79.1071) lr 1.2790e-03 eta 0:09:34
epoch [84/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.4502 (0.7739) acc 84.3750 (79.0625) lr 1.2790e-03 eta 0:09:22
epoch [84/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8628 (0.7689) acc 68.7500 (79.0278) lr 1.2790e-03 eta 0:09:13
epoch [84/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6846 (0.7708) acc 78.1250 (78.8125) lr 1.2639e-03 eta 0:09:06
epoch [85/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 0.4556 (0.7491) acc 87.5000 (78.1250) lr 1.2639e-03 eta 0:17:23
epoch [85/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.048) loss 1.0518 (0.8256) acc 68.7500 (75.3125) lr 1.2639e-03 eta 0:12:45
epoch [85/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 0.8301 (0.8445) acc 81.2500 (76.0417) lr 1.2639e-03 eta 0:11:11
epoch [85/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.9282 (0.8354) acc 81.2500 (76.5625) lr 1.2639e-03 eta 0:10:25
epoch [85/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.7808 (0.8320) acc 87.5000 (76.7500) lr 1.2639e-03 eta 0:09:56
epoch [85/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5005 (0.8057) acc 81.2500 (77.6042) lr 1.2639e-03 eta 0:09:38
epoch [85/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.4697 (0.7983) acc 87.5000 (77.9464) lr 1.2639e-03 eta 0:09:24
epoch [85/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4517 (0.7877) acc 87.5000 (78.2031) lr 1.2639e-03 eta 0:09:13
epoch [85/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9482 (0.7789) acc 68.7500 (78.3333) lr 1.2639e-03 eta 0:09:05
epoch [85/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9507 (0.7707) acc 68.7500 (78.1875) lr 1.2487e-03 eta 0:08:58
epoch [86/200] batch [5/50] time 0.085 (0.198) data 0.000 (0.113) loss 0.6318 (0.7099) acc 81.2500 (83.1250) lr 1.2487e-03 eta 0:18:55
epoch [86/200] batch [10/50] time 0.085 (0.141) data 0.000 (0.056) loss 1.3809 (0.7405) acc 65.6250 (81.8750) lr 1.2487e-03 eta 0:13:30
epoch [86/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.038) loss 0.7080 (0.7109) acc 78.1250 (81.4583) lr 1.2487e-03 eta 0:11:42
epoch [86/200] batch [20/50] time 0.086 (0.113) data 0.000 (0.028) loss 0.6060 (0.7353) acc 81.2500 (80.9375) lr 1.2487e-03 eta 0:10:47
epoch [86/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.023) loss 0.6035 (0.7605) acc 78.1250 (80.1250) lr 1.2487e-03 eta 0:10:14
epoch [86/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.3591 (0.7422) acc 84.3750 (79.8958) lr 1.2487e-03 eta 0:09:52
epoch [86/200] batch [35/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.4810 (0.7531) acc 84.3750 (79.1071) lr 1.2487e-03 eta 0:09:36
epoch [86/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.8149 (0.7518) acc 75.0000 (79.4531) lr 1.2487e-03 eta 0:09:23
epoch [86/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.0664 (0.7711) acc 68.7500 (78.9583) lr 1.2487e-03 eta 0:09:13
epoch [86/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.4531 (0.7580) acc 90.6250 (79.5625) lr 1.2334e-03 eta 0:09:05
epoch [87/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 0.6011 (0.6482) acc 84.3750 (84.3750) lr 1.2334e-03 eta 0:17:06
epoch [87/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.8179 (0.7942) acc 81.2500 (80.3125) lr 1.2334e-03 eta 0:12:33
epoch [87/200] batch [15/50] time 0.086 (0.117) data 0.000 (0.032) loss 0.3884 (0.7427) acc 87.5000 (81.0417) lr 1.2334e-03 eta 0:11:02
epoch [87/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.5894 (0.7735) acc 81.2500 (79.6875) lr 1.2334e-03 eta 0:10:17
epoch [87/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.7026 (0.7672) acc 81.2500 (79.3750) lr 1.2334e-03 eta 0:09:49
epoch [87/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.6548 (0.7822) acc 81.2500 (79.2708) lr 1.2334e-03 eta 0:09:30
epoch [87/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8198 (0.7810) acc 68.7500 (78.9286) lr 1.2334e-03 eta 0:09:17
epoch [87/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8423 (0.7924) acc 81.2500 (78.6719) lr 1.2334e-03 eta 0:09:05
epoch [87/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8364 (0.7898) acc 78.1250 (78.4028) lr 1.2334e-03 eta 0:08:57
epoch [87/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.4565 (0.8003) acc 87.5000 (78.0625) lr 1.2181e-03 eta 0:08:50
epoch [88/200] batch [5/50] time 0.084 (0.178) data 0.000 (0.093) loss 0.8062 (0.8196) acc 78.1250 (78.7500) lr 1.2181e-03 eta 0:16:46
epoch [88/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.8257 (0.7185) acc 75.0000 (79.6875) lr 1.2181e-03 eta 0:12:19
epoch [88/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.031) loss 0.9585 (0.7043) acc 78.1250 (80.2083) lr 1.2181e-03 eta 0:10:51
epoch [88/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.023) loss 0.8965 (0.7380) acc 78.1250 (79.2188) lr 1.2181e-03 eta 0:10:07
epoch [88/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 1.1289 (0.7821) acc 65.6250 (78.0000) lr 1.2181e-03 eta 0:09:40
epoch [88/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8438 (0.7602) acc 84.3750 (78.7500) lr 1.2181e-03 eta 0:09:22
epoch [88/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.5903 (0.7566) acc 81.2500 (78.8393) lr 1.2181e-03 eta 0:09:09
epoch [88/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4690 (0.7572) acc 84.3750 (78.7500) lr 1.2181e-03 eta 0:08:59
epoch [88/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5034 (0.7682) acc 90.6250 (78.5417) lr 1.2181e-03 eta 0:08:50
epoch [88/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8506 (0.7631) acc 75.0000 (78.6875) lr 1.2028e-03 eta 0:08:43
epoch [89/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 0.6455 (0.6725) acc 84.3750 (80.0000) lr 1.2028e-03 eta 0:17:41
epoch [89/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.053) loss 1.0000 (0.7266) acc 78.1250 (80.9375) lr 1.2028e-03 eta 0:12:46
epoch [89/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.8091 (0.7363) acc 75.0000 (80.4167) lr 1.2028e-03 eta 0:11:07
epoch [89/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.7563 (0.7732) acc 84.3750 (79.3750) lr 1.2028e-03 eta 0:10:17
epoch [89/200] batch [25/50] time 0.083 (0.105) data 0.000 (0.021) loss 0.5942 (0.7783) acc 84.3750 (79.3750) lr 1.2028e-03 eta 0:09:47
epoch [89/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.8643 (0.7971) acc 81.2500 (78.9583) lr 1.2028e-03 eta 0:09:27
epoch [89/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.9434 (0.8036) acc 71.8750 (78.6607) lr 1.2028e-03 eta 0:09:12
epoch [89/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7349 (0.8310) acc 75.0000 (77.6562) lr 1.2028e-03 eta 0:09:01
epoch [89/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4739 (0.8153) acc 78.1250 (77.8472) lr 1.2028e-03 eta 0:08:52
epoch [89/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6929 (0.8078) acc 75.0000 (78.0625) lr 1.1874e-03 eta 0:08:44
epoch [90/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.109) loss 0.6841 (0.6962) acc 78.1250 (81.2500) lr 1.1874e-03 eta 0:17:55
epoch [90/200] batch [10/50] time 0.083 (0.139) data 0.000 (0.055) loss 0.5698 (0.6509) acc 81.2500 (81.2500) lr 1.1874e-03 eta 0:12:50
epoch [90/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 0.7275 (0.6832) acc 78.1250 (80.2083) lr 1.1874e-03 eta 0:11:08
epoch [90/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.6772 (0.6849) acc 81.2500 (79.8438) lr 1.1874e-03 eta 0:10:16
epoch [90/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 1.3867 (0.7488) acc 68.7500 (78.8750) lr 1.1874e-03 eta 0:09:46
epoch [90/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.3936 (0.7463) acc 90.6250 (78.6458) lr 1.1874e-03 eta 0:09:25
epoch [90/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7734 (0.7684) acc 75.0000 (78.4821) lr 1.1874e-03 eta 0:09:11
epoch [90/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5811 (0.7403) acc 75.0000 (78.9844) lr 1.1874e-03 eta 0:08:59
epoch [90/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8105 (0.7470) acc 71.8750 (78.8889) lr 1.1874e-03 eta 0:08:49
epoch [90/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.1377 (0.7696) acc 62.5000 (78.3125) lr 1.1719e-03 eta 0:08:42
epoch [91/200] batch [5/50] time 0.083 (0.178) data 0.000 (0.093) loss 0.7427 (0.6735) acc 84.3750 (83.7500) lr 1.1719e-03 eta 0:16:18
epoch [91/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.8076 (0.7247) acc 78.1250 (81.5625) lr 1.1719e-03 eta 0:12:00
epoch [91/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.031) loss 0.5317 (0.6917) acc 84.3750 (82.2917) lr 1.1719e-03 eta 0:10:33
epoch [91/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.023) loss 0.5654 (0.7209) acc 81.2500 (80.4688) lr 1.1719e-03 eta 0:09:50
epoch [91/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.5293 (0.7149) acc 84.3750 (80.1250) lr 1.1719e-03 eta 0:09:24
epoch [91/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 0.6367 (0.7270) acc 78.1250 (80.0000) lr 1.1719e-03 eta 0:09:06
epoch [91/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.013) loss 1.1553 (0.7645) acc 68.7500 (78.9286) lr 1.1719e-03 eta 0:08:53
epoch [91/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5708 (0.7651) acc 84.3750 (79.0625) lr 1.1719e-03 eta 0:08:43
epoch [91/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.5557 (0.7584) acc 87.5000 (79.6528) lr 1.1719e-03 eta 0:08:35
epoch [91/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.009) loss 0.9453 (0.7648) acc 81.2500 (79.5000) lr 1.1564e-03 eta 0:08:28
epoch [92/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.8169 (0.8023) acc 87.5000 (75.0000) lr 1.1564e-03 eta 0:16:23
epoch [92/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.048) loss 0.9165 (0.8425) acc 75.0000 (75.9375) lr 1.1564e-03 eta 0:12:00
epoch [92/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 0.5938 (0.8058) acc 81.2500 (76.8750) lr 1.1564e-03 eta 0:10:31
epoch [92/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.5752 (0.7614) acc 87.5000 (78.5938) lr 1.1564e-03 eta 0:09:47
epoch [92/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 1.0820 (0.7707) acc 65.6250 (78.5000) lr 1.1564e-03 eta 0:09:20
epoch [92/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7490 (0.7626) acc 84.3750 (78.9583) lr 1.1564e-03 eta 0:09:02
epoch [92/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.2080 (0.7669) acc 71.8750 (78.7500) lr 1.1564e-03 eta 0:08:50
epoch [92/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6235 (0.7854) acc 81.2500 (78.1250) lr 1.1564e-03 eta 0:08:40
epoch [92/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.2334 (0.7910) acc 68.7500 (78.2639) lr 1.1564e-03 eta 0:08:32
epoch [92/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.4612 (0.7790) acc 87.5000 (78.5000) lr 1.1409e-03 eta 0:08:25
epoch [93/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.107) loss 0.9565 (0.7649) acc 71.8750 (79.3750) lr 1.1409e-03 eta 0:17:14
epoch [93/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.054) loss 0.7446 (0.7398) acc 81.2500 (80.6250) lr 1.1409e-03 eta 0:12:26
epoch [93/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.3149 (0.6982) acc 93.7500 (82.0833) lr 1.1409e-03 eta 0:10:49
epoch [93/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.6211 (0.6828) acc 84.3750 (81.8750) lr 1.1409e-03 eta 0:10:01
epoch [93/200] batch [25/50] time 0.086 (0.106) data 0.000 (0.022) loss 0.8472 (0.7097) acc 68.7500 (80.6250) lr 1.1409e-03 eta 0:09:32
epoch [93/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.9556 (0.7292) acc 81.2500 (80.6250) lr 1.1409e-03 eta 0:09:12
epoch [93/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.9780 (0.7263) acc 81.2500 (80.7143) lr 1.1409e-03 eta 0:08:58
epoch [93/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6909 (0.7364) acc 84.3750 (80.4688) lr 1.1409e-03 eta 0:08:46
epoch [93/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.7778 (0.7271) acc 81.2500 (80.8333) lr 1.1409e-03 eta 0:08:37
epoch [93/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5967 (0.7343) acc 84.3750 (80.3125) lr 1.1253e-03 eta 0:08:29
epoch [94/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.106) loss 0.9907 (0.7066) acc 78.1250 (76.8750) lr 1.1253e-03 eta 0:17:04
epoch [94/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.5513 (0.7059) acc 84.3750 (80.3125) lr 1.1253e-03 eta 0:12:16
epoch [94/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 1.0762 (0.7171) acc 71.8750 (79.5833) lr 1.1253e-03 eta 0:10:41
epoch [94/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.7183 (0.7120) acc 84.3750 (80.3125) lr 1.1253e-03 eta 0:09:53
epoch [94/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 1.1270 (0.7340) acc 75.0000 (80.0000) lr 1.1253e-03 eta 0:09:24
epoch [94/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.8071 (0.7328) acc 75.0000 (80.3125) lr 1.1253e-03 eta 0:09:04
epoch [94/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.7227 (0.7401) acc 78.1250 (79.7321) lr 1.1253e-03 eta 0:08:51
epoch [94/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.8257 (0.7462) acc 81.2500 (80.0781) lr 1.1253e-03 eta 0:08:39
epoch [94/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7891 (0.7638) acc 81.2500 (79.7222) lr 1.1253e-03 eta 0:08:30
epoch [94/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.3923 (0.7491) acc 87.5000 (79.7500) lr 1.1097e-03 eta 0:08:23
epoch [95/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.103) loss 0.4976 (0.6902) acc 90.6250 (80.6250) lr 1.1097e-03 eta 0:16:34
epoch [95/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.5767 (0.7009) acc 81.2500 (80.0000) lr 1.1097e-03 eta 0:12:01
epoch [95/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.8379 (0.6725) acc 75.0000 (81.4583) lr 1.1097e-03 eta 0:10:30
epoch [95/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.5991 (0.7129) acc 87.5000 (80.4688) lr 1.1097e-03 eta 0:09:43
epoch [95/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.3311 (0.7507) acc 62.5000 (79.0000) lr 1.1097e-03 eta 0:09:15
epoch [95/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.1846 (0.7735) acc 75.0000 (78.8542) lr 1.1097e-03 eta 0:08:56
epoch [95/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.5840 (0.7591) acc 87.5000 (79.1071) lr 1.1097e-03 eta 0:08:42
epoch [95/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.1074 (0.7621) acc 68.7500 (78.5938) lr 1.1097e-03 eta 0:08:31
epoch [95/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4202 (0.7633) acc 87.5000 (78.6111) lr 1.1097e-03 eta 0:08:23
epoch [95/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 1.1055 (0.7766) acc 75.0000 (78.3750) lr 1.0941e-03 eta 0:08:16
epoch [96/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.105) loss 0.9033 (0.9376) acc 75.0000 (76.8750) lr 1.0941e-03 eta 0:16:34
epoch [96/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.053) loss 0.8804 (0.8759) acc 75.0000 (77.5000) lr 1.0941e-03 eta 0:11:58
epoch [96/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.4861 (0.8308) acc 84.3750 (78.5417) lr 1.0941e-03 eta 0:10:24
epoch [96/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.4617 (0.7839) acc 93.7500 (80.1562) lr 1.0941e-03 eta 0:09:38
epoch [96/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8135 (0.7938) acc 81.2500 (79.3750) lr 1.0941e-03 eta 0:09:10
epoch [96/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.8813 (0.8024) acc 75.0000 (78.5417) lr 1.0941e-03 eta 0:08:51
epoch [96/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.015) loss 0.4858 (0.7812) acc 87.5000 (78.9286) lr 1.0941e-03 eta 0:08:38
epoch [96/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0576 (0.7727) acc 68.7500 (79.1406) lr 1.0941e-03 eta 0:08:27
epoch [96/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7505 (0.7897) acc 84.3750 (78.5417) lr 1.0941e-03 eta 0:08:18
epoch [96/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7363 (0.7766) acc 75.0000 (78.6875) lr 1.0785e-03 eta 0:08:11
epoch [97/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 0.9795 (0.7193) acc 65.6250 (79.3750) lr 1.0785e-03 eta 0:16:43
epoch [97/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 1.0928 (0.7396) acc 71.8750 (79.0625) lr 1.0785e-03 eta 0:12:01
epoch [97/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.9590 (0.7319) acc 78.1250 (79.1667) lr 1.0785e-03 eta 0:10:27
epoch [97/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.5986 (0.7300) acc 81.2500 (79.3750) lr 1.0785e-03 eta 0:09:39
epoch [97/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 1.0586 (0.7601) acc 65.6250 (78.6250) lr 1.0785e-03 eta 0:09:11
epoch [97/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 1.0967 (0.7594) acc 68.7500 (78.7500) lr 1.0785e-03 eta 0:08:51
epoch [97/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5435 (0.7389) acc 84.3750 (79.1071) lr 1.0785e-03 eta 0:08:37
epoch [97/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.3318 (0.7544) acc 90.6250 (78.5156) lr 1.0785e-03 eta 0:08:26
epoch [97/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.5391 (0.7405) acc 81.2500 (79.3750) lr 1.0785e-03 eta 0:08:17
epoch [97/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7539 (0.7481) acc 71.8750 (79.1875) lr 1.0628e-03 eta 0:08:10
epoch [98/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.109) loss 0.6108 (0.7956) acc 87.5000 (78.1250) lr 1.0628e-03 eta 0:16:37
epoch [98/200] batch [10/50] time 0.083 (0.139) data 0.000 (0.055) loss 0.9590 (0.8463) acc 75.0000 (76.2500) lr 1.0628e-03 eta 0:11:54
epoch [98/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 0.6494 (0.8005) acc 84.3750 (78.1250) lr 1.0628e-03 eta 0:10:20
epoch [98/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.8462 (0.7595) acc 71.8750 (79.3750) lr 1.0628e-03 eta 0:09:32
epoch [98/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.8008 (0.7741) acc 84.3750 (79.0000) lr 1.0628e-03 eta 0:09:04
epoch [98/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6646 (0.7720) acc 81.2500 (78.9583) lr 1.0628e-03 eta 0:08:45
epoch [98/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.5518 (0.7644) acc 87.5000 (79.1964) lr 1.0628e-03 eta 0:08:32
epoch [98/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6680 (0.7646) acc 81.2500 (79.2969) lr 1.0628e-03 eta 0:08:21
epoch [98/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 1.0312 (0.7475) acc 68.7500 (80.0000) lr 1.0628e-03 eta 0:08:12
epoch [98/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5137 (0.7506) acc 84.3750 (79.8125) lr 1.0471e-03 eta 0:08:05
epoch [99/200] batch [5/50] time 0.085 (0.181) data 0.000 (0.096) loss 1.1533 (0.9079) acc 75.0000 (79.3750) lr 1.0471e-03 eta 0:15:23
epoch [99/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.6060 (0.8192) acc 84.3750 (80.6250) lr 1.0471e-03 eta 0:11:16
epoch [99/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.6602 (0.7955) acc 84.3750 (79.7917) lr 1.0471e-03 eta 0:09:53
epoch [99/200] batch [20/50] time 0.086 (0.109) data 0.000 (0.024) loss 0.6372 (0.7664) acc 75.0000 (79.8438) lr 1.0471e-03 eta 0:09:12
epoch [99/200] batch [25/50] time 0.086 (0.104) data 0.000 (0.019) loss 0.7129 (0.7732) acc 78.1250 (79.8750) lr 1.0471e-03 eta 0:08:47
epoch [99/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.7314 (0.7822) acc 78.1250 (79.0625) lr 1.0471e-03 eta 0:08:31
epoch [99/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 0.7095 (0.7809) acc 84.3750 (78.9286) lr 1.0471e-03 eta 0:08:19
epoch [99/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.2158 (0.7847) acc 62.5000 (78.1250) lr 1.0471e-03 eta 0:08:09
epoch [99/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8008 (0.7780) acc 68.7500 (77.9167) lr 1.0471e-03 eta 0:08:01
epoch [99/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.1035 (0.7763) acc 75.0000 (78.0000) lr 1.0314e-03 eta 0:07:54
epoch [100/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.104) loss 0.9268 (0.8643) acc 78.1250 (76.8750) lr 1.0314e-03 eta 0:15:57
epoch [100/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.7515 (0.7148) acc 78.1250 (80.3125) lr 1.0314e-03 eta 0:11:31
epoch [100/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.9785 (0.6617) acc 71.8750 (81.6667) lr 1.0314e-03 eta 0:10:02
epoch [100/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.8677 (0.6728) acc 68.7500 (80.7812) lr 1.0314e-03 eta 0:09:18
epoch [100/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.3113 (0.6730) acc 93.7500 (80.5000) lr 1.0314e-03 eta 0:08:51
epoch [100/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6045 (0.7064) acc 90.6250 (80.0000) lr 1.0314e-03 eta 0:08:33
epoch [100/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.3411 (0.6863) acc 93.7500 (80.9821) lr 1.0314e-03 eta 0:08:20
epoch [100/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.9536 (0.7034) acc 71.8750 (80.2344) lr 1.0314e-03 eta 0:08:10
epoch [100/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7104 (0.7290) acc 84.3750 (79.8611) lr 1.0314e-03 eta 0:08:01
epoch [100/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7495 (0.7267) acc 84.3750 (80.0000) lr 1.0157e-03 eta 0:07:55
epoch [101/200] batch [5/50] time 0.086 (0.192) data 0.000 (0.106) loss 0.9937 (0.7076) acc 65.6250 (76.2500) lr 1.0157e-03 eta 0:16:01
epoch [101/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.053) loss 0.6089 (0.7516) acc 81.2500 (77.8125) lr 1.0157e-03 eta 0:11:31
epoch [101/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.6030 (0.7778) acc 87.5000 (76.8750) lr 1.0157e-03 eta 0:10:00
epoch [101/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.027) loss 0.5010 (0.7183) acc 90.6250 (78.7500) lr 1.0157e-03 eta 0:09:13
epoch [101/200] batch [25/50] time 0.083 (0.106) data 0.000 (0.022) loss 0.7617 (0.7125) acc 78.1250 (78.8750) lr 1.0157e-03 eta 0:08:45
epoch [101/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6909 (0.7177) acc 81.2500 (78.9583) lr 1.0157e-03 eta 0:08:26
epoch [101/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.7554 (0.6996) acc 71.8750 (79.6429) lr 1.0157e-03 eta 0:08:13
epoch [101/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.8892 (0.7018) acc 81.2500 (80.0781) lr 1.0157e-03 eta 0:08:03
epoch [101/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4917 (0.6875) acc 87.5000 (80.6944) lr 1.0157e-03 eta 0:07:54
epoch [101/200] batch [50/50] time 0.085 (0.095) data 0.000 (0.011) loss 1.1865 (0.6965) acc 68.7500 (80.3750) lr 1.0000e-03 eta 0:07:48
epoch [102/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.094) loss 0.9292 (0.7508) acc 75.0000 (78.7500) lr 1.0000e-03 eta 0:14:47
epoch [102/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.5850 (0.7472) acc 81.2500 (79.3750) lr 1.0000e-03 eta 0:10:50
epoch [102/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.031) loss 0.9731 (0.7334) acc 68.7500 (78.9583) lr 1.0000e-03 eta 0:09:32
epoch [102/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.7676 (0.7419) acc 78.1250 (79.0625) lr 1.0000e-03 eta 0:08:53
epoch [102/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.3274 (0.7060) acc 87.5000 (79.2500) lr 1.0000e-03 eta 0:08:29
epoch [102/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.6001 (0.7039) acc 84.3750 (79.8958) lr 1.0000e-03 eta 0:08:13
epoch [102/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.6450 (0.7069) acc 87.5000 (80.1786) lr 1.0000e-03 eta 0:08:02
epoch [102/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7856 (0.7108) acc 81.2500 (80.0000) lr 1.0000e-03 eta 0:07:52
epoch [102/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5435 (0.7096) acc 78.1250 (79.7917) lr 1.0000e-03 eta 0:07:45
epoch [102/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7881 (0.7111) acc 78.1250 (79.6875) lr 9.8429e-04 eta 0:07:39
epoch [103/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.101) loss 0.7163 (0.6893) acc 81.2500 (78.7500) lr 9.8429e-04 eta 0:15:15
epoch [103/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.8750 (0.7289) acc 71.8750 (77.5000) lr 9.8429e-04 eta 0:11:03
epoch [103/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.6812 (0.7146) acc 81.2500 (78.1250) lr 9.8429e-04 eta 0:09:39
epoch [103/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.6743 (0.7229) acc 75.0000 (78.4375) lr 9.8429e-04 eta 0:08:57
epoch [103/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.8721 (0.7319) acc 68.7500 (78.2500) lr 9.8429e-04 eta 0:08:31
epoch [103/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.9102 (0.7278) acc 78.1250 (78.7500) lr 9.8429e-04 eta 0:08:14
epoch [103/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.9951 (0.7531) acc 75.0000 (78.6607) lr 9.8429e-04 eta 0:08:02
epoch [103/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0713 (0.7617) acc 71.8750 (78.5156) lr 9.8429e-04 eta 0:07:52
epoch [103/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 1.0459 (0.7616) acc 71.8750 (78.4722) lr 9.8429e-04 eta 0:07:44
epoch [103/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5176 (0.7630) acc 78.1250 (78.3125) lr 9.6859e-04 eta 0:07:38
epoch [104/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.098) loss 0.5928 (0.6760) acc 78.1250 (79.3750) lr 9.6859e-04 eta 0:14:45
epoch [104/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 1.0566 (0.6969) acc 68.7500 (78.7500) lr 9.6859e-04 eta 0:10:45
epoch [104/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.8730 (0.7353) acc 75.0000 (78.7500) lr 9.6859e-04 eta 0:09:25
epoch [104/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.8066 (0.7409) acc 81.2500 (78.5938) lr 9.6859e-04 eta 0:08:44
epoch [104/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.9165 (0.7651) acc 81.2500 (79.0000) lr 9.6859e-04 eta 0:08:20
epoch [104/200] batch [30/50] time 0.086 (0.101) data 0.000 (0.017) loss 1.0928 (0.7706) acc 62.5000 (78.4375) lr 9.6859e-04 eta 0:08:05
epoch [104/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.7983 (0.7516) acc 78.1250 (78.9286) lr 9.6859e-04 eta 0:07:54
epoch [104/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.9731 (0.7613) acc 71.8750 (78.7500) lr 9.6859e-04 eta 0:07:44
epoch [104/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8560 (0.7754) acc 75.0000 (78.6111) lr 9.6859e-04 eta 0:07:37
epoch [104/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7061 (0.7717) acc 71.8750 (78.5625) lr 9.5289e-04 eta 0:07:31
epoch [105/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.100) loss 0.6680 (0.6331) acc 75.0000 (79.3750) lr 9.5289e-04 eta 0:14:47
epoch [105/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 1.0635 (0.7007) acc 68.7500 (79.0625) lr 9.5289e-04 eta 0:10:45
epoch [105/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.4839 (0.6958) acc 84.3750 (80.2083) lr 9.5289e-04 eta 0:09:24
epoch [105/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.6650 (0.6787) acc 84.3750 (81.2500) lr 9.5289e-04 eta 0:08:43
epoch [105/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.8530 (0.6883) acc 78.1250 (80.6250) lr 9.5289e-04 eta 0:08:18
epoch [105/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.9902 (0.7135) acc 81.2500 (80.4167) lr 9.5289e-04 eta 0:08:02
epoch [105/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.014) loss 0.6450 (0.7396) acc 81.2500 (79.8214) lr 9.5289e-04 eta 0:07:49
epoch [105/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5869 (0.7582) acc 81.2500 (79.2969) lr 9.5289e-04 eta 0:07:40
epoch [105/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8110 (0.7500) acc 75.0000 (79.6528) lr 9.5289e-04 eta 0:07:32
epoch [105/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.4951 (0.7489) acc 90.6250 (79.6875) lr 9.3721e-04 eta 0:07:26
epoch [106/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.098) loss 0.8696 (0.8928) acc 78.1250 (77.5000) lr 9.3721e-04 eta 0:14:32
epoch [106/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.5239 (0.7716) acc 87.5000 (80.0000) lr 9.3721e-04 eta 0:10:34
epoch [106/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.8550 (0.7416) acc 75.0000 (80.4167) lr 9.3721e-04 eta 0:09:16
epoch [106/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.7134 (0.7247) acc 78.1250 (80.1562) lr 9.3721e-04 eta 0:08:36
epoch [106/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 1.0137 (0.7543) acc 65.6250 (79.2500) lr 9.3721e-04 eta 0:08:12
epoch [106/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8530 (0.7538) acc 62.5000 (78.9583) lr 9.3721e-04 eta 0:07:56
epoch [106/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.0596 (0.7596) acc 56.2500 (78.1250) lr 9.3721e-04 eta 0:07:45
epoch [106/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6621 (0.7581) acc 78.1250 (78.0469) lr 9.3721e-04 eta 0:07:36
epoch [106/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0518 (0.7553) acc 75.0000 (77.9167) lr 9.3721e-04 eta 0:07:28
epoch [106/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6831 (0.7488) acc 81.2500 (78.2500) lr 9.2154e-04 eta 0:07:22
epoch [107/200] batch [5/50] time 0.085 (0.182) data 0.000 (0.096) loss 0.7031 (0.6229) acc 81.2500 (81.2500) lr 9.2154e-04 eta 0:14:14
epoch [107/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.6846 (0.6478) acc 81.2500 (80.0000) lr 9.2154e-04 eta 0:10:23
epoch [107/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.8633 (0.7070) acc 75.0000 (79.5833) lr 9.2154e-04 eta 0:09:06
epoch [107/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 1.5088 (0.7836) acc 62.5000 (76.8750) lr 9.2154e-04 eta 0:08:28
epoch [107/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7075 (0.7920) acc 90.6250 (76.8750) lr 9.2154e-04 eta 0:08:04
epoch [107/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 1.0859 (0.7796) acc 68.7500 (77.1875) lr 9.2154e-04 eta 0:07:49
epoch [107/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.9209 (0.8181) acc 71.8750 (76.5179) lr 9.2154e-04 eta 0:07:37
epoch [107/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7090 (0.8121) acc 84.3750 (77.2656) lr 9.2154e-04 eta 0:07:28
epoch [107/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7036 (0.8086) acc 84.3750 (77.2222) lr 9.2154e-04 eta 0:07:21
epoch [107/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9390 (0.8036) acc 78.1250 (77.3750) lr 9.0589e-04 eta 0:07:16
epoch [108/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.107) loss 0.9150 (0.9154) acc 71.8750 (75.6250) lr 9.0589e-04 eta 0:14:52
epoch [108/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.054) loss 0.7866 (0.8061) acc 78.1250 (77.5000) lr 9.0589e-04 eta 0:10:42
epoch [108/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.5093 (0.7530) acc 87.5000 (79.3750) lr 9.0589e-04 eta 0:09:18
epoch [108/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 1.2842 (0.7885) acc 65.6250 (78.2812) lr 9.0589e-04 eta 0:08:36
epoch [108/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.8848 (0.7907) acc 78.1250 (78.2500) lr 9.0589e-04 eta 0:08:10
epoch [108/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.5864 (0.7489) acc 81.2500 (79.6875) lr 9.0589e-04 eta 0:07:54
epoch [108/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.4800 (0.7242) acc 84.3750 (80.1786) lr 9.0589e-04 eta 0:07:41
epoch [108/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5820 (0.7245) acc 78.1250 (79.9219) lr 9.0589e-04 eta 0:07:31
epoch [108/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8955 (0.7279) acc 78.1250 (79.7917) lr 9.0589e-04 eta 0:07:23
epoch [108/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4124 (0.7287) acc 87.5000 (79.7500) lr 8.9027e-04 eta 0:07:17
epoch [109/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 0.7500 (0.7519) acc 84.3750 (79.3750) lr 8.9027e-04 eta 0:13:57
epoch [109/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 1.0078 (0.7835) acc 71.8750 (78.4375) lr 8.9027e-04 eta 0:10:11
epoch [109/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.6777 (0.6983) acc 81.2500 (80.0000) lr 8.9027e-04 eta 0:08:55
epoch [109/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.6016 (0.7006) acc 84.3750 (80.0000) lr 8.9027e-04 eta 0:08:17
epoch [109/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.0410 (0.7166) acc 78.1250 (80.0000) lr 8.9027e-04 eta 0:07:55
epoch [109/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.8018 (0.7209) acc 81.2500 (79.5833) lr 8.9027e-04 eta 0:07:39
epoch [109/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7231 (0.7316) acc 81.2500 (79.3750) lr 8.9027e-04 eta 0:07:28
epoch [109/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8359 (0.7525) acc 71.8750 (79.0625) lr 8.9027e-04 eta 0:07:19
epoch [109/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0176 (0.7674) acc 71.8750 (79.0972) lr 8.9027e-04 eta 0:07:12
epoch [109/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7144 (0.7762) acc 78.1250 (78.7500) lr 8.7467e-04 eta 0:07:06
epoch [110/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.106) loss 0.4495 (0.6770) acc 78.1250 (83.7500) lr 8.7467e-04 eta 0:14:29
epoch [110/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 1.0908 (0.7846) acc 71.8750 (77.8125) lr 8.7467e-04 eta 0:10:26
epoch [110/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.4812 (0.7174) acc 84.3750 (79.5833) lr 8.7467e-04 eta 0:09:04
epoch [110/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.9165 (0.7155) acc 75.0000 (79.6875) lr 8.7467e-04 eta 0:08:23
epoch [110/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.3933 (0.6855) acc 93.7500 (80.6250) lr 8.7467e-04 eta 0:07:59
epoch [110/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6392 (0.6919) acc 78.1250 (80.7292) lr 8.7467e-04 eta 0:07:42
epoch [110/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 1.0977 (0.6925) acc 71.8750 (80.9821) lr 8.7467e-04 eta 0:07:31
epoch [110/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 1.2402 (0.7127) acc 71.8750 (80.7031) lr 8.7467e-04 eta 0:07:21
epoch [110/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.2529 (0.7476) acc 62.5000 (79.3056) lr 8.7467e-04 eta 0:07:13
epoch [110/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7070 (0.7535) acc 81.2500 (79.3125) lr 8.5910e-04 eta 0:07:07
epoch [111/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.107) loss 0.5649 (0.9008) acc 75.0000 (71.2500) lr 8.5910e-04 eta 0:14:21
epoch [111/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.054) loss 0.6455 (0.8053) acc 75.0000 (75.6250) lr 8.5910e-04 eta 0:10:18
epoch [111/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.4473 (0.7615) acc 87.5000 (77.7083) lr 8.5910e-04 eta 0:08:57
epoch [111/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.027) loss 0.3564 (0.7438) acc 84.3750 (77.8125) lr 8.5910e-04 eta 0:08:16
epoch [111/200] batch [25/50] time 0.084 (0.105) data 0.001 (0.022) loss 0.4792 (0.7187) acc 87.5000 (78.7500) lr 8.5910e-04 eta 0:07:51
epoch [111/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.9697 (0.7229) acc 75.0000 (78.8542) lr 8.5910e-04 eta 0:07:35
epoch [111/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 1.0166 (0.7334) acc 78.1250 (78.8393) lr 8.5910e-04 eta 0:07:23
epoch [111/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.9624 (0.7111) acc 75.0000 (79.4531) lr 8.5910e-04 eta 0:07:14
epoch [111/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0557 (0.7299) acc 62.5000 (79.0278) lr 8.5910e-04 eta 0:07:06
epoch [111/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9194 (0.7437) acc 81.2500 (79.0000) lr 8.4357e-04 eta 0:07:00
epoch [112/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.107) loss 0.9453 (0.7688) acc 62.5000 (75.6250) lr 8.4357e-04 eta 0:14:13
epoch [112/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.8906 (0.7335) acc 68.7500 (76.5625) lr 8.4357e-04 eta 0:10:13
epoch [112/200] batch [15/50] time 0.083 (0.120) data 0.000 (0.036) loss 1.1426 (0.7169) acc 65.6250 (77.2917) lr 8.4357e-04 eta 0:08:52
epoch [112/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.2871 (0.6960) acc 93.7500 (78.7500) lr 8.4357e-04 eta 0:08:12
epoch [112/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.6768 (0.7112) acc 81.2500 (78.8750) lr 8.4357e-04 eta 0:07:48
epoch [112/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6494 (0.7118) acc 75.0000 (78.5417) lr 8.4357e-04 eta 0:07:31
epoch [112/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.5835 (0.7135) acc 75.0000 (78.2143) lr 8.4357e-04 eta 0:07:20
epoch [112/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.8228 (0.7226) acc 75.0000 (77.9688) lr 8.4357e-04 eta 0:07:10
epoch [112/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6885 (0.7259) acc 90.6250 (78.4722) lr 8.4357e-04 eta 0:07:03
epoch [112/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9507 (0.7318) acc 71.8750 (78.1875) lr 8.2807e-04 eta 0:06:57
epoch [113/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.100) loss 0.4319 (0.7349) acc 87.5000 (77.5000) lr 8.2807e-04 eta 0:13:34
epoch [113/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.9639 (0.6915) acc 81.2500 (80.6250) lr 8.2807e-04 eta 0:09:52
epoch [113/200] batch [15/50] time 0.083 (0.118) data 0.000 (0.033) loss 0.9058 (0.7310) acc 71.8750 (80.0000) lr 8.2807e-04 eta 0:08:37
epoch [113/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.8257 (0.7681) acc 71.8750 (78.4375) lr 8.2807e-04 eta 0:08:00
epoch [113/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.8730 (0.7654) acc 71.8750 (78.6250) lr 8.2807e-04 eta 0:07:37
epoch [113/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.8584 (0.7897) acc 81.2500 (77.9167) lr 8.2807e-04 eta 0:07:22
epoch [113/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7026 (0.7758) acc 78.1250 (78.3929) lr 8.2807e-04 eta 0:07:11
epoch [113/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7441 (0.7616) acc 78.1250 (78.7500) lr 8.2807e-04 eta 0:07:02
epoch [113/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7959 (0.7676) acc 78.1250 (78.4028) lr 8.2807e-04 eta 0:06:55
epoch [113/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7627 (0.7613) acc 78.1250 (78.5625) lr 8.1262e-04 eta 0:06:50
epoch [114/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.096) loss 0.9141 (0.7121) acc 75.0000 (78.7500) lr 8.1262e-04 eta 0:13:11
epoch [114/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.4832 (0.6783) acc 81.2500 (80.6250) lr 8.1262e-04 eta 0:09:38
epoch [114/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.6313 (0.6528) acc 84.3750 (82.2917) lr 8.1262e-04 eta 0:08:27
epoch [114/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 1.0107 (0.7296) acc 78.1250 (80.9375) lr 8.1262e-04 eta 0:07:52
epoch [114/200] batch [25/50] time 0.085 (0.104) data 0.001 (0.019) loss 0.8496 (0.7527) acc 78.1250 (80.0000) lr 8.1262e-04 eta 0:07:30
epoch [114/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.6294 (0.7434) acc 87.5000 (80.2083) lr 8.1262e-04 eta 0:07:15
epoch [114/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.0918 (0.7343) acc 71.8750 (80.3571) lr 8.1262e-04 eta 0:07:05
epoch [114/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.6577 (0.7296) acc 87.5000 (80.1562) lr 8.1262e-04 eta 0:06:56
epoch [114/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0352 (0.7364) acc 65.6250 (79.7917) lr 8.1262e-04 eta 0:06:49
epoch [114/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6040 (0.7268) acc 81.2500 (79.7500) lr 7.9721e-04 eta 0:06:44
epoch [115/200] batch [5/50] time 0.085 (0.196) data 0.000 (0.111) loss 0.6396 (0.5576) acc 84.3750 (85.0000) lr 7.9721e-04 eta 0:14:00
epoch [115/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.056) loss 0.9487 (0.5714) acc 81.2500 (84.6875) lr 7.9721e-04 eta 0:09:59
epoch [115/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 0.5776 (0.5712) acc 84.3750 (83.3333) lr 7.9721e-04 eta 0:08:39
epoch [115/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.6641 (0.6438) acc 78.1250 (81.0938) lr 7.9721e-04 eta 0:07:59
epoch [115/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.6553 (0.6646) acc 84.3750 (80.6250) lr 7.9721e-04 eta 0:07:35
epoch [115/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.7798 (0.6776) acc 81.2500 (80.5208) lr 7.9721e-04 eta 0:07:18
epoch [115/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6592 (0.6745) acc 81.2500 (81.3393) lr 7.9721e-04 eta 0:07:06
epoch [115/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9551 (0.6791) acc 75.0000 (81.1719) lr 7.9721e-04 eta 0:06:57
epoch [115/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0859 (0.6946) acc 71.8750 (80.7639) lr 7.9721e-04 eta 0:06:50
epoch [115/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7432 (0.7084) acc 81.2500 (80.5000) lr 7.8186e-04 eta 0:06:44
epoch [116/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.105) loss 0.8740 (0.6589) acc 68.7500 (81.2500) lr 7.8186e-04 eta 0:13:28
epoch [116/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 0.5073 (0.7825) acc 87.5000 (80.0000) lr 7.8186e-04 eta 0:09:41
epoch [116/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.8496 (0.7740) acc 71.8750 (78.9583) lr 7.8186e-04 eta 0:08:26
epoch [116/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.4487 (0.7400) acc 90.6250 (80.3125) lr 7.8186e-04 eta 0:07:48
epoch [116/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.5493 (0.7015) acc 81.2500 (80.7500) lr 7.8186e-04 eta 0:07:25
epoch [116/200] batch [30/50] time 0.083 (0.102) data 0.000 (0.018) loss 0.7275 (0.6825) acc 78.1250 (81.0417) lr 7.8186e-04 eta 0:07:09
epoch [116/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.5962 (0.6694) acc 84.3750 (81.4286) lr 7.8186e-04 eta 0:06:58
epoch [116/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.9678 (0.6585) acc 68.7500 (81.7188) lr 7.8186e-04 eta 0:06:49
epoch [116/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6509 (0.6622) acc 90.6250 (81.9444) lr 7.8186e-04 eta 0:06:42
epoch [116/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8848 (0.6886) acc 78.1250 (80.9375) lr 7.6655e-04 eta 0:06:37
epoch [117/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.103) loss 0.9580 (0.8850) acc 71.8750 (73.1250) lr 7.6655e-04 eta 0:13:10
epoch [117/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 1.0840 (0.8372) acc 75.0000 (76.5625) lr 7.6655e-04 eta 0:09:31
epoch [117/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 1.0068 (0.8596) acc 68.7500 (75.6250) lr 7.6655e-04 eta 0:08:19
epoch [117/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.7476 (0.8456) acc 75.0000 (76.5625) lr 7.6655e-04 eta 0:07:42
epoch [117/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.7451 (0.8038) acc 81.2500 (77.8750) lr 7.6655e-04 eta 0:07:19
epoch [117/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.7090 (0.8053) acc 75.0000 (77.7083) lr 7.6655e-04 eta 0:07:04
epoch [117/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.8081 (0.7701) acc 75.0000 (78.7500) lr 7.6655e-04 eta 0:06:53
epoch [117/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.1045 (0.7857) acc 71.8750 (78.4375) lr 7.6655e-04 eta 0:06:44
epoch [117/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8052 (0.7706) acc 78.1250 (78.8194) lr 7.6655e-04 eta 0:06:37
epoch [117/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 0.6748 (0.7761) acc 81.2500 (78.6875) lr 7.5131e-04 eta 0:06:32
epoch [118/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.109) loss 0.6064 (0.7510) acc 81.2500 (77.5000) lr 7.5131e-04 eta 0:13:23
epoch [118/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.055) loss 0.7915 (0.7426) acc 81.2500 (78.7500) lr 7.5131e-04 eta 0:09:36
epoch [118/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 0.5869 (0.7327) acc 87.5000 (79.7917) lr 7.5131e-04 eta 0:08:20
epoch [118/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.7964 (0.7317) acc 81.2500 (80.1562) lr 7.5131e-04 eta 0:07:41
epoch [118/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.3594 (0.7296) acc 87.5000 (79.8750) lr 7.5131e-04 eta 0:07:18
epoch [118/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.7549 (0.7538) acc 78.1250 (79.1667) lr 7.5131e-04 eta 0:07:03
epoch [118/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8569 (0.7750) acc 78.1250 (78.4821) lr 7.5131e-04 eta 0:06:51
epoch [118/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.1436 (0.7824) acc 75.0000 (78.5156) lr 7.5131e-04 eta 0:06:42
epoch [118/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1729 (0.7798) acc 78.1250 (78.7500) lr 7.5131e-04 eta 0:06:35
epoch [118/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4922 (0.7629) acc 84.3750 (79.1250) lr 7.3613e-04 eta 0:06:29
epoch [119/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.101) loss 0.4312 (0.6400) acc 90.6250 (83.1250) lr 7.3613e-04 eta 0:12:42
epoch [119/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.4973 (0.6191) acc 90.6250 (83.4375) lr 7.3613e-04 eta 0:09:13
epoch [119/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.3706 (0.5677) acc 87.5000 (84.5833) lr 7.3613e-04 eta 0:08:04
epoch [119/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.9072 (0.6170) acc 78.1250 (83.5938) lr 7.3613e-04 eta 0:07:29
epoch [119/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.7051 (0.6480) acc 84.3750 (82.8750) lr 7.3613e-04 eta 0:07:08
epoch [119/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.7822 (0.6737) acc 75.0000 (81.5625) lr 7.3613e-04 eta 0:06:54
epoch [119/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.7837 (0.6546) acc 87.5000 (82.3214) lr 7.3613e-04 eta 0:06:43
epoch [119/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6353 (0.6607) acc 87.5000 (82.3438) lr 7.3613e-04 eta 0:06:35
epoch [119/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.9644 (0.6601) acc 75.0000 (82.4306) lr 7.3613e-04 eta 0:06:28
epoch [119/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.6738 (0.6685) acc 81.2500 (82.1250) lr 7.2101e-04 eta 0:06:23
epoch [120/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.102) loss 0.5400 (0.6083) acc 84.3750 (82.5000) lr 7.2101e-04 eta 0:12:41
epoch [120/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.051) loss 0.5977 (0.6760) acc 81.2500 (81.5625) lr 7.2101e-04 eta 0:09:11
epoch [120/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.8877 (0.7389) acc 81.2500 (80.2083) lr 7.2101e-04 eta 0:08:01
epoch [120/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.6743 (0.7676) acc 78.1250 (79.6875) lr 7.2101e-04 eta 0:07:26
epoch [120/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.9404 (0.7832) acc 68.7500 (78.7500) lr 7.2101e-04 eta 0:07:04
epoch [120/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.0918 (0.8022) acc 81.2500 (78.3333) lr 7.2101e-04 eta 0:06:50
epoch [120/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.6396 (0.7828) acc 84.3750 (79.1964) lr 7.2101e-04 eta 0:06:39
epoch [120/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.1182 (0.8034) acc 78.1250 (78.9062) lr 7.2101e-04 eta 0:06:30
epoch [120/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9399 (0.7899) acc 75.0000 (79.5139) lr 7.2101e-04 eta 0:06:24
epoch [120/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 0.6685 (0.7711) acc 81.2500 (79.8125) lr 7.0596e-04 eta 0:06:18
epoch [121/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 0.5815 (0.7157) acc 84.3750 (83.1250) lr 7.0596e-04 eta 0:12:38
epoch [121/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 1.0566 (0.8271) acc 71.8750 (79.0625) lr 7.0596e-04 eta 0:09:07
epoch [121/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.9023 (0.8160) acc 81.2500 (78.7500) lr 7.0596e-04 eta 0:07:55
epoch [121/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.7119 (0.7817) acc 84.3750 (79.6875) lr 7.0596e-04 eta 0:07:20
epoch [121/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.4148 (0.7414) acc 93.7500 (80.7500) lr 7.0596e-04 eta 0:06:59
epoch [121/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6421 (0.7284) acc 81.2500 (80.6250) lr 7.0596e-04 eta 0:06:44
epoch [121/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7388 (0.7137) acc 71.8750 (80.7143) lr 7.0596e-04 eta 0:06:33
epoch [121/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5742 (0.7210) acc 84.3750 (80.3906) lr 7.0596e-04 eta 0:06:25
epoch [121/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.9795 (0.7217) acc 71.8750 (80.4861) lr 7.0596e-04 eta 0:06:19
epoch [121/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4846 (0.7097) acc 84.3750 (80.9375) lr 6.9098e-04 eta 0:06:13
epoch [122/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 0.4199 (0.7030) acc 87.5000 (79.3750) lr 6.9098e-04 eta 0:12:17
epoch [122/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.6372 (0.7284) acc 75.0000 (79.0625) lr 6.9098e-04 eta 0:08:55
epoch [122/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 1.2227 (0.8029) acc 71.8750 (77.2917) lr 6.9098e-04 eta 0:07:47
epoch [122/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.8794 (0.7867) acc 71.8750 (77.6562) lr 6.9098e-04 eta 0:07:13
epoch [122/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.0273 (0.7735) acc 75.0000 (78.0000) lr 6.9098e-04 eta 0:06:52
epoch [122/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.7432 (0.7646) acc 75.0000 (78.3333) lr 6.9098e-04 eta 0:06:38
epoch [122/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6934 (0.7320) acc 75.0000 (79.3750) lr 6.9098e-04 eta 0:06:28
epoch [122/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7739 (0.7327) acc 81.2500 (79.5312) lr 6.9098e-04 eta 0:06:20
epoch [122/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6294 (0.7202) acc 84.3750 (79.8611) lr 6.9098e-04 eta 0:06:14
epoch [122/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.6763 (0.7229) acc 84.3750 (80.1875) lr 6.7608e-04 eta 0:06:08
epoch [123/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 0.6860 (0.7261) acc 90.6250 (83.1250) lr 6.7608e-04 eta 0:12:19
epoch [123/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.8242 (0.7800) acc 78.1250 (80.9375) lr 6.7608e-04 eta 0:08:53
epoch [123/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.3977 (0.7395) acc 93.7500 (81.8750) lr 6.7608e-04 eta 0:07:44
epoch [123/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 1.0068 (0.7636) acc 65.6250 (79.6875) lr 6.7608e-04 eta 0:07:09
epoch [123/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.3523 (0.7246) acc 87.5000 (80.2500) lr 6.7608e-04 eta 0:06:48
epoch [123/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6411 (0.7296) acc 81.2500 (80.3125) lr 6.7608e-04 eta 0:06:34
epoch [123/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.9897 (0.7268) acc 68.7500 (80.0000) lr 6.7608e-04 eta 0:06:24
epoch [123/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.4375 (0.7125) acc 93.7500 (80.5469) lr 6.7608e-04 eta 0:06:16
epoch [123/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.4609 (0.7024) acc 87.5000 (80.6944) lr 6.7608e-04 eta 0:06:09
epoch [123/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6934 (0.7137) acc 71.8750 (80.4375) lr 6.6126e-04 eta 0:06:04
epoch [124/200] batch [5/50] time 0.086 (0.199) data 0.000 (0.113) loss 0.8032 (0.8284) acc 78.1250 (75.0000) lr 6.6126e-04 eta 0:12:44
epoch [124/200] batch [10/50] time 0.084 (0.142) data 0.000 (0.057) loss 1.0791 (0.8540) acc 75.0000 (76.5625) lr 6.6126e-04 eta 0:09:04
epoch [124/200] batch [15/50] time 0.084 (0.123) data 0.000 (0.038) loss 0.7490 (0.8580) acc 81.2500 (76.6667) lr 6.6126e-04 eta 0:07:50
epoch [124/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.029) loss 0.6099 (0.8312) acc 78.1250 (77.0312) lr 6.6126e-04 eta 0:07:13
epoch [124/200] batch [25/50] time 0.085 (0.108) data 0.000 (0.023) loss 1.0361 (0.8136) acc 71.8750 (78.0000) lr 6.6126e-04 eta 0:06:51
epoch [124/200] batch [30/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.9302 (0.8372) acc 75.0000 (77.7083) lr 6.6126e-04 eta 0:06:36
epoch [124/200] batch [35/50] time 0.084 (0.101) data 0.001 (0.016) loss 0.5864 (0.8217) acc 87.5000 (78.3929) lr 6.6126e-04 eta 0:06:25
epoch [124/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.014) loss 0.7217 (0.8151) acc 84.3750 (78.2031) lr 6.6126e-04 eta 0:06:16
epoch [124/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6182 (0.8048) acc 87.5000 (78.3333) lr 6.6126e-04 eta 0:06:09
epoch [124/200] batch [50/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9038 (0.8055) acc 68.7500 (77.9375) lr 6.4653e-04 eta 0:06:03
epoch [125/200] batch [5/50] time 0.085 (0.178) data 0.000 (0.093) loss 0.8701 (0.7213) acc 71.8750 (79.3750) lr 6.4653e-04 eta 0:11:17
epoch [125/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 1.2217 (0.7213) acc 59.3750 (79.0625) lr 6.4653e-04 eta 0:08:17
epoch [125/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.031) loss 0.5439 (0.7817) acc 84.3750 (77.5000) lr 6.4653e-04 eta 0:07:17
epoch [125/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.023) loss 0.3533 (0.7512) acc 90.6250 (78.9062) lr 6.4653e-04 eta 0:06:47
epoch [125/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.8193 (0.7674) acc 78.1250 (78.2500) lr 6.4653e-04 eta 0:06:29
epoch [125/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7148 (0.7706) acc 81.2500 (78.3333) lr 6.4653e-04 eta 0:06:17
epoch [125/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.5518 (0.7623) acc 87.5000 (78.4821) lr 6.4653e-04 eta 0:06:08
epoch [125/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4185 (0.7617) acc 90.6250 (78.6719) lr 6.4653e-04 eta 0:06:01
epoch [125/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9531 (0.7621) acc 81.2500 (79.0972) lr 6.4653e-04 eta 0:05:55
epoch [125/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.6074 (0.7495) acc 84.3750 (79.5000) lr 6.3188e-04 eta 0:05:50
epoch [126/200] batch [5/50] time 0.086 (0.186) data 0.000 (0.101) loss 0.5088 (0.6368) acc 84.3750 (84.3750) lr 6.3188e-04 eta 0:11:38
epoch [126/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.051) loss 0.4785 (0.6839) acc 84.3750 (82.5000) lr 6.3188e-04 eta 0:08:26
epoch [126/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.4961 (0.6710) acc 87.5000 (83.7500) lr 6.3188e-04 eta 0:07:23
epoch [126/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.6279 (0.6801) acc 81.2500 (82.6562) lr 6.3188e-04 eta 0:06:50
epoch [126/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.6636 (0.6791) acc 81.2500 (82.1250) lr 6.3188e-04 eta 0:06:31
epoch [126/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.5786 (0.6856) acc 84.3750 (81.8750) lr 6.3188e-04 eta 0:06:18
epoch [126/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.3352 (0.6731) acc 93.7500 (81.6964) lr 6.3188e-04 eta 0:06:08
epoch [126/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6221 (0.6759) acc 84.3750 (81.9531) lr 6.3188e-04 eta 0:06:00
epoch [126/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.6992 (0.6752) acc 78.1250 (81.6667) lr 6.3188e-04 eta 0:05:54
epoch [126/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.5361 (0.6852) acc 78.1250 (81.0000) lr 6.1732e-04 eta 0:05:49
epoch [127/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 0.5117 (0.6518) acc 84.3750 (82.5000) lr 6.1732e-04 eta 0:11:51
epoch [127/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.3752 (0.7136) acc 90.6250 (80.3125) lr 6.1732e-04 eta 0:08:30
epoch [127/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.6846 (0.7134) acc 84.3750 (81.0417) lr 6.1732e-04 eta 0:07:24
epoch [127/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.8101 (0.6826) acc 78.1250 (82.3438) lr 6.1732e-04 eta 0:06:51
epoch [127/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 1.0996 (0.6894) acc 68.7500 (82.0000) lr 6.1732e-04 eta 0:06:30
epoch [127/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.7876 (0.6909) acc 78.1250 (81.6667) lr 6.1732e-04 eta 0:06:16
epoch [127/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6860 (0.6836) acc 81.2500 (82.2321) lr 6.1732e-04 eta 0:06:06
epoch [127/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.6465 (0.6809) acc 78.1250 (81.8750) lr 6.1732e-04 eta 0:05:58
epoch [127/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6084 (0.6769) acc 84.3750 (81.7361) lr 6.1732e-04 eta 0:05:52
epoch [127/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6606 (0.6599) acc 81.2500 (82.2500) lr 6.0285e-04 eta 0:05:47
epoch [128/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.103) loss 0.3840 (0.5074) acc 84.3750 (83.7500) lr 6.0285e-04 eta 0:11:28
epoch [128/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 1.4014 (0.6810) acc 68.7500 (81.2500) lr 6.0285e-04 eta 0:08:17
epoch [128/200] batch [15/50] time 0.087 (0.119) data 0.000 (0.035) loss 0.6509 (0.7021) acc 90.6250 (80.8333) lr 6.0285e-04 eta 0:07:14
epoch [128/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.4370 (0.6614) acc 87.5000 (82.3438) lr 6.0285e-04 eta 0:06:41
epoch [128/200] batch [25/50] time 0.085 (0.105) data 0.001 (0.021) loss 0.7026 (0.6709) acc 84.3750 (81.8750) lr 6.0285e-04 eta 0:06:22
epoch [128/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.4624 (0.6674) acc 84.3750 (81.8750) lr 6.0285e-04 eta 0:06:09
epoch [128/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.9004 (0.6890) acc 75.0000 (81.2500) lr 6.0285e-04 eta 0:05:59
epoch [128/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5723 (0.6896) acc 84.3750 (81.1719) lr 6.0285e-04 eta 0:05:51
epoch [128/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6562 (0.6901) acc 84.3750 (81.1806) lr 6.0285e-04 eta 0:05:45
epoch [128/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.2764 (0.6924) acc 68.7500 (81.1250) lr 5.8849e-04 eta 0:05:40
epoch [129/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.103) loss 0.5767 (0.5322) acc 84.3750 (85.6250) lr 5.8849e-04 eta 0:11:16
epoch [129/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.052) loss 0.6357 (0.6316) acc 87.5000 (83.1250) lr 5.8849e-04 eta 0:08:09
epoch [129/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.6724 (0.6357) acc 84.3750 (82.9167) lr 5.8849e-04 eta 0:07:07
epoch [129/200] batch [20/50] time 0.086 (0.111) data 0.000 (0.026) loss 0.8545 (0.6320) acc 84.3750 (83.2812) lr 5.8849e-04 eta 0:06:36
epoch [129/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.5190 (0.6810) acc 78.1250 (81.3750) lr 5.8849e-04 eta 0:06:17
epoch [129/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.7524 (0.6931) acc 78.1250 (81.0417) lr 5.8849e-04 eta 0:06:04
epoch [129/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.3120 (0.6749) acc 90.6250 (81.6964) lr 5.8849e-04 eta 0:05:55
epoch [129/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.5869 (0.7146) acc 75.0000 (80.6250) lr 5.8849e-04 eta 0:05:47
epoch [129/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6934 (0.7106) acc 87.5000 (80.9028) lr 5.8849e-04 eta 0:05:41
epoch [129/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.3643 (0.6948) acc 93.7500 (81.4375) lr 5.7422e-04 eta 0:05:36
epoch [130/200] batch [5/50] time 0.083 (0.187) data 0.000 (0.103) loss 0.7432 (0.7208) acc 78.1250 (79.3750) lr 5.7422e-04 eta 0:11:02
epoch [130/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.6978 (0.7047) acc 78.1250 (79.6875) lr 5.7422e-04 eta 0:08:00
epoch [130/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.034) loss 0.5342 (0.7215) acc 81.2500 (79.7917) lr 5.7422e-04 eta 0:06:58
epoch [130/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.6191 (0.7069) acc 81.2500 (79.8438) lr 5.7422e-04 eta 0:06:27
epoch [130/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8765 (0.6937) acc 75.0000 (80.7500) lr 5.7422e-04 eta 0:06:08
epoch [130/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6323 (0.7011) acc 84.3750 (81.0417) lr 5.7422e-04 eta 0:05:56
epoch [130/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.9341 (0.6774) acc 71.8750 (81.7857) lr 5.7422e-04 eta 0:05:47
epoch [130/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7031 (0.6819) acc 81.2500 (81.4844) lr 5.7422e-04 eta 0:05:39
epoch [130/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.4478 (0.6782) acc 87.5000 (81.8056) lr 5.7422e-04 eta 0:05:34
epoch [130/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7739 (0.6967) acc 84.3750 (81.3125) lr 5.6006e-04 eta 0:05:29
epoch [131/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.106) loss 0.9194 (0.6681) acc 78.1250 (83.1250) lr 5.6006e-04 eta 0:11:10
epoch [131/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 1.1660 (0.6824) acc 68.7500 (82.1875) lr 5.6006e-04 eta 0:08:02
epoch [131/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 1.2441 (0.7476) acc 68.7500 (80.0000) lr 5.6006e-04 eta 0:06:59
epoch [131/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.5625 (0.7373) acc 90.6250 (80.3125) lr 5.6006e-04 eta 0:06:27
epoch [131/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.5415 (0.7397) acc 81.2500 (80.3750) lr 5.6006e-04 eta 0:06:08
epoch [131/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.7944 (0.7371) acc 81.2500 (80.5208) lr 5.6006e-04 eta 0:05:55
epoch [131/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.8843 (0.7523) acc 75.0000 (80.0893) lr 5.6006e-04 eta 0:05:46
epoch [131/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.8296 (0.7392) acc 68.7500 (79.8438) lr 5.6006e-04 eta 0:05:38
epoch [131/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7690 (0.7400) acc 78.1250 (80.0694) lr 5.6006e-04 eta 0:05:32
epoch [131/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6733 (0.7415) acc 84.3750 (80.0000) lr 5.4601e-04 eta 0:05:27
epoch [132/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.100) loss 0.8862 (0.7199) acc 81.2500 (82.5000) lr 5.4601e-04 eta 0:10:38
epoch [132/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.3767 (0.7196) acc 90.6250 (82.1875) lr 5.4601e-04 eta 0:07:44
epoch [132/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.2998 (0.8289) acc 75.0000 (78.5417) lr 5.4601e-04 eta 0:06:45
epoch [132/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.6758 (0.7835) acc 81.2500 (79.3750) lr 5.4601e-04 eta 0:06:16
epoch [132/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.6641 (0.7391) acc 84.3750 (81.0000) lr 5.4601e-04 eta 0:05:58
epoch [132/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 1.2812 (0.7685) acc 68.7500 (79.3750) lr 5.4601e-04 eta 0:05:46
epoch [132/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.5020 (0.7679) acc 81.2500 (79.5536) lr 5.4601e-04 eta 0:05:37
epoch [132/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.3408 (0.7785) acc 62.5000 (79.1406) lr 5.4601e-04 eta 0:05:30
epoch [132/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6431 (0.7581) acc 78.1250 (79.6528) lr 5.4601e-04 eta 0:05:25
epoch [132/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6987 (0.7578) acc 78.1250 (79.5000) lr 5.3207e-04 eta 0:05:20
epoch [133/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.097) loss 0.6699 (0.7239) acc 78.1250 (78.1250) lr 5.3207e-04 eta 0:10:20
epoch [133/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.6562 (0.7206) acc 78.1250 (78.7500) lr 5.3207e-04 eta 0:07:32
epoch [133/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.4236 (0.6992) acc 87.5000 (79.5833) lr 5.3207e-04 eta 0:06:37
epoch [133/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.6152 (0.6996) acc 81.2500 (79.6875) lr 5.3207e-04 eta 0:06:09
epoch [133/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.4827 (0.7083) acc 84.3750 (79.7500) lr 5.3207e-04 eta 0:05:51
epoch [133/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.5435 (0.7117) acc 84.3750 (80.1042) lr 5.3207e-04 eta 0:05:40
epoch [133/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 0.8892 (0.7033) acc 75.0000 (80.0000) lr 5.3207e-04 eta 0:05:31
epoch [133/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0322 (0.7084) acc 71.8750 (79.8438) lr 5.3207e-04 eta 0:05:24
epoch [133/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6870 (0.7244) acc 81.2500 (79.4444) lr 5.3207e-04 eta 0:05:19
epoch [133/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7251 (0.7321) acc 84.3750 (79.3125) lr 5.1825e-04 eta 0:05:15
epoch [134/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 0.8418 (0.6997) acc 81.2500 (82.5000) lr 5.1825e-04 eta 0:10:01
epoch [134/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.7114 (0.7151) acc 81.2500 (82.1875) lr 5.1825e-04 eta 0:07:21
epoch [134/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 0.7300 (0.7259) acc 78.1250 (80.8333) lr 5.1825e-04 eta 0:06:27
epoch [134/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.8057 (0.7034) acc 81.2500 (81.8750) lr 5.1825e-04 eta 0:06:00
epoch [134/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.4604 (0.6966) acc 84.3750 (82.1250) lr 5.1825e-04 eta 0:05:43
epoch [134/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.4009 (0.6986) acc 93.7500 (82.0833) lr 5.1825e-04 eta 0:05:32
epoch [134/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 1.0674 (0.7178) acc 68.7500 (81.3393) lr 5.1825e-04 eta 0:05:24
epoch [134/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6836 (0.7082) acc 81.2500 (81.1719) lr 5.1825e-04 eta 0:05:18
epoch [134/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7305 (0.6882) acc 81.2500 (81.4583) lr 5.1825e-04 eta 0:05:13
epoch [134/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.2729 (0.6824) acc 93.7500 (81.4375) lr 5.0454e-04 eta 0:05:08
epoch [135/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.099) loss 0.9658 (0.7252) acc 81.2500 (80.0000) lr 5.0454e-04 eta 0:10:12
epoch [135/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.4756 (0.6022) acc 90.6250 (83.7500) lr 5.0454e-04 eta 0:07:25
epoch [135/200] batch [15/50] time 0.086 (0.119) data 0.000 (0.033) loss 0.5215 (0.5973) acc 84.3750 (83.7500) lr 5.0454e-04 eta 0:06:29
epoch [135/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.6694 (0.6314) acc 78.1250 (82.8125) lr 5.0454e-04 eta 0:06:01
epoch [135/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.7251 (0.6773) acc 81.2500 (82.5000) lr 5.0454e-04 eta 0:05:44
epoch [135/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.9336 (0.7326) acc 71.8750 (80.8333) lr 5.0454e-04 eta 0:05:32
epoch [135/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.6587 (0.7176) acc 78.1250 (80.9821) lr 5.0454e-04 eta 0:05:24
epoch [135/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.4963 (0.6997) acc 93.7500 (81.5625) lr 5.0454e-04 eta 0:05:17
epoch [135/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.7158 (0.6969) acc 78.1250 (81.4583) lr 5.0454e-04 eta 0:05:12
epoch [135/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.7358 (0.6914) acc 78.1250 (81.3750) lr 4.9096e-04 eta 0:05:07
epoch [136/200] batch [5/50] time 0.083 (0.189) data 0.000 (0.105) loss 1.1709 (0.9465) acc 75.0000 (78.1250) lr 4.9096e-04 eta 0:10:14
epoch [136/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.053) loss 0.3105 (0.7855) acc 93.7500 (79.6875) lr 4.9096e-04 eta 0:07:23
epoch [136/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.4561 (0.7386) acc 87.5000 (80.4167) lr 4.9096e-04 eta 0:06:26
epoch [136/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.4282 (0.7091) acc 87.5000 (81.2500) lr 4.9096e-04 eta 0:05:56
epoch [136/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8628 (0.6855) acc 71.8750 (81.2500) lr 4.9096e-04 eta 0:05:39
epoch [136/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6694 (0.6845) acc 84.3750 (81.0417) lr 4.9096e-04 eta 0:05:27
epoch [136/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6597 (0.6683) acc 81.2500 (81.2500) lr 4.9096e-04 eta 0:05:19
epoch [136/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.3945 (0.6758) acc 84.3750 (81.1719) lr 4.9096e-04 eta 0:05:12
epoch [136/200] batch [45/50] time 0.087 (0.096) data 0.000 (0.012) loss 0.5615 (0.6711) acc 75.0000 (81.0417) lr 4.9096e-04 eta 0:05:07
epoch [136/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6450 (0.6628) acc 78.1250 (81.2500) lr 4.7750e-04 eta 0:05:02
epoch [137/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.103) loss 0.8770 (0.8239) acc 71.8750 (80.6250) lr 4.7750e-04 eta 0:10:01
epoch [137/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.052) loss 0.4478 (0.6982) acc 90.6250 (83.4375) lr 4.7750e-04 eta 0:07:13
epoch [137/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.8301 (0.6946) acc 78.1250 (82.7083) lr 4.7750e-04 eta 0:06:18
epoch [137/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.7646 (0.7369) acc 81.2500 (81.8750) lr 4.7750e-04 eta 0:05:49
epoch [137/200] batch [25/50] time 0.083 (0.105) data 0.000 (0.021) loss 0.8286 (0.7464) acc 84.3750 (81.2500) lr 4.7750e-04 eta 0:05:32
epoch [137/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6426 (0.7340) acc 81.2500 (80.7292) lr 4.7750e-04 eta 0:05:21
epoch [137/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.7012 (0.7182) acc 84.3750 (80.8929) lr 4.7750e-04 eta 0:05:12
epoch [137/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6572 (0.7164) acc 78.1250 (80.7031) lr 4.7750e-04 eta 0:05:06
epoch [137/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.012) loss 0.5493 (0.7124) acc 84.3750 (80.6944) lr 4.7750e-04 eta 0:05:01
epoch [137/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5381 (0.7033) acc 81.2500 (80.7500) lr 4.6417e-04 eta 0:04:56
epoch [138/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 0.8052 (0.7236) acc 71.8750 (80.0000) lr 4.6417e-04 eta 0:09:57
epoch [138/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.4272 (0.7487) acc 90.6250 (80.9375) lr 4.6417e-04 eta 0:07:11
epoch [138/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.5806 (0.7496) acc 78.1250 (79.5833) lr 4.6417e-04 eta 0:06:15
epoch [138/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.7563 (0.7572) acc 75.0000 (79.5312) lr 4.6417e-04 eta 0:05:47
epoch [138/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.7271 (0.7212) acc 78.1250 (80.5000) lr 4.6417e-04 eta 0:05:29
epoch [138/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.0693 (0.7352) acc 71.8750 (80.2083) lr 4.6417e-04 eta 0:05:18
epoch [138/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.015) loss 0.2632 (0.7268) acc 93.7500 (80.5357) lr 4.6417e-04 eta 0:05:10
epoch [138/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.4172 (0.7087) acc 90.6250 (81.0938) lr 4.6417e-04 eta 0:05:03
epoch [138/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6890 (0.7058) acc 75.0000 (81.1111) lr 4.6417e-04 eta 0:04:58
epoch [138/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8691 (0.7024) acc 71.8750 (81.0625) lr 4.5098e-04 eta 0:04:53
epoch [139/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.106) loss 0.7231 (0.6864) acc 81.2500 (78.1250) lr 4.5098e-04 eta 0:09:53
epoch [139/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.3450 (0.6651) acc 90.6250 (81.2500) lr 4.5098e-04 eta 0:07:06
epoch [139/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.8892 (0.6659) acc 75.0000 (81.4583) lr 4.5098e-04 eta 0:06:11
epoch [139/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.8228 (0.6798) acc 81.2500 (80.9375) lr 4.5098e-04 eta 0:05:43
epoch [139/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.8403 (0.6655) acc 78.1250 (80.8750) lr 4.5098e-04 eta 0:05:26
epoch [139/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.5044 (0.6793) acc 87.5000 (80.7292) lr 4.5098e-04 eta 0:05:14
epoch [139/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.3235 (0.6814) acc 87.5000 (80.7143) lr 4.5098e-04 eta 0:05:06
epoch [139/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.4980 (0.6952) acc 84.3750 (80.5469) lr 4.5098e-04 eta 0:04:59
epoch [139/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.3159 (0.6707) acc 96.8750 (81.6667) lr 4.5098e-04 eta 0:04:54
epoch [139/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7949 (0.7004) acc 71.8750 (80.8125) lr 4.3792e-04 eta 0:04:50
epoch [140/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.097) loss 0.5474 (0.5916) acc 84.3750 (83.1250) lr 4.3792e-04 eta 0:09:16
epoch [140/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.7812 (0.5883) acc 78.1250 (83.7500) lr 4.3792e-04 eta 0:06:46
epoch [140/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.5444 (0.6268) acc 81.2500 (82.7083) lr 4.3792e-04 eta 0:05:55
epoch [140/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.6665 (0.6357) acc 84.3750 (82.3438) lr 4.3792e-04 eta 0:05:30
epoch [140/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.6514 (0.6635) acc 87.5000 (81.7500) lr 4.3792e-04 eta 0:05:14
epoch [140/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.9243 (0.6914) acc 71.8750 (80.8333) lr 4.3792e-04 eta 0:05:04
epoch [140/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.5654 (0.6818) acc 87.5000 (80.9821) lr 4.3792e-04 eta 0:04:57
epoch [140/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.7051 (0.6806) acc 75.0000 (80.7812) lr 4.3792e-04 eta 0:04:50
epoch [140/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8408 (0.7025) acc 75.0000 (80.3472) lr 4.3792e-04 eta 0:04:46
epoch [140/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.3652 (0.6938) acc 93.7500 (80.6250) lr 4.2499e-04 eta 0:04:42
epoch [141/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.105) loss 0.4170 (0.5354) acc 93.7500 (82.5000) lr 4.2499e-04 eta 0:09:31
epoch [141/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.8022 (0.6774) acc 81.2500 (82.5000) lr 4.2499e-04 eta 0:06:51
epoch [141/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.6895 (0.6914) acc 84.3750 (80.8333) lr 4.2499e-04 eta 0:05:58
epoch [141/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.6938 (0.6884) acc 84.3750 (81.4062) lr 4.2499e-04 eta 0:05:31
epoch [141/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.9341 (0.7029) acc 84.3750 (81.5000) lr 4.2499e-04 eta 0:05:14
epoch [141/200] batch [30/50] time 0.086 (0.102) data 0.000 (0.018) loss 0.5918 (0.7220) acc 84.3750 (80.7292) lr 4.2499e-04 eta 0:05:04
epoch [141/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.8320 (0.7231) acc 71.8750 (80.3571) lr 4.2499e-04 eta 0:04:56
epoch [141/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.7593 (0.7009) acc 71.8750 (80.5469) lr 4.2499e-04 eta 0:04:49
epoch [141/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.3901 (0.6842) acc 87.5000 (80.9028) lr 4.2499e-04 eta 0:04:44
epoch [141/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7026 (0.7017) acc 71.8750 (80.6250) lr 4.1221e-04 eta 0:04:40
epoch [142/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.094) loss 1.3076 (0.8431) acc 68.7500 (78.1250) lr 4.1221e-04 eta 0:08:47
epoch [142/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.047) loss 0.8530 (0.7508) acc 75.0000 (78.7500) lr 4.1221e-04 eta 0:06:26
epoch [142/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.031) loss 0.6235 (0.7527) acc 78.1250 (79.3750) lr 4.1221e-04 eta 0:05:39
epoch [142/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.4443 (0.7168) acc 87.5000 (80.0000) lr 4.1221e-04 eta 0:05:17
epoch [142/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.6606 (0.6967) acc 81.2500 (80.1250) lr 4.1221e-04 eta 0:05:02
epoch [142/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.4719 (0.6896) acc 84.3750 (80.4167) lr 4.1221e-04 eta 0:04:52
epoch [142/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9434 (0.6902) acc 81.2500 (80.9821) lr 4.1221e-04 eta 0:04:45
epoch [142/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7754 (0.7042) acc 75.0000 (80.4688) lr 4.1221e-04 eta 0:04:39
epoch [142/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8501 (0.7035) acc 75.0000 (80.4861) lr 4.1221e-04 eta 0:04:35
epoch [142/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.4983 (0.7001) acc 90.6250 (81.0000) lr 3.9958e-04 eta 0:04:31
epoch [143/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.101) loss 0.6416 (0.8104) acc 78.1250 (73.1250) lr 3.9958e-04 eta 0:08:59
epoch [143/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.051) loss 0.8813 (0.7705) acc 81.2500 (76.8750) lr 3.9958e-04 eta 0:06:31
epoch [143/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.7061 (0.7558) acc 84.3750 (78.7500) lr 3.9958e-04 eta 0:05:41
epoch [143/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.7075 (0.7823) acc 71.8750 (78.5938) lr 3.9958e-04 eta 0:05:16
epoch [143/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.9561 (0.7559) acc 68.7500 (79.0000) lr 3.9958e-04 eta 0:05:01
epoch [143/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.0889 (0.7605) acc 78.1250 (79.1667) lr 3.9958e-04 eta 0:04:51
epoch [143/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7314 (0.7498) acc 78.1250 (79.3750) lr 3.9958e-04 eta 0:04:43
epoch [143/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8159 (0.7535) acc 78.1250 (79.2969) lr 3.9958e-04 eta 0:04:37
epoch [143/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.7603 (0.7394) acc 75.0000 (79.6528) lr 3.9958e-04 eta 0:04:32
epoch [143/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8467 (0.7364) acc 75.0000 (79.6875) lr 3.8709e-04 eta 0:04:28
epoch [144/200] batch [5/50] time 0.084 (0.195) data 0.000 (0.111) loss 0.4524 (0.7260) acc 90.6250 (81.2500) lr 3.8709e-04 eta 0:09:15
epoch [144/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.056) loss 0.5869 (0.7759) acc 78.1250 (79.3750) lr 3.8709e-04 eta 0:06:36
epoch [144/200] batch [15/50] time 0.086 (0.121) data 0.000 (0.037) loss 0.9790 (0.7494) acc 78.1250 (81.0417) lr 3.8709e-04 eta 0:05:43
epoch [144/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.5596 (0.7635) acc 84.3750 (80.4688) lr 3.8709e-04 eta 0:05:16
epoch [144/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.6714 (0.7653) acc 84.3750 (80.2500) lr 3.8709e-04 eta 0:05:00
epoch [144/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.9497 (0.7442) acc 75.0000 (80.5208) lr 3.8709e-04 eta 0:04:49
epoch [144/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.4431 (0.7202) acc 90.6250 (80.8929) lr 3.8709e-04 eta 0:04:41
epoch [144/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7051 (0.7390) acc 78.1250 (80.3906) lr 3.8709e-04 eta 0:04:35
epoch [144/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.013) loss 0.4258 (0.7301) acc 90.6250 (80.8333) lr 3.8709e-04 eta 0:04:30
epoch [144/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.2981 (0.7048) acc 96.8750 (81.6250) lr 3.7476e-04 eta 0:04:26
epoch [145/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.109) loss 1.0850 (0.9029) acc 65.6250 (76.2500) lr 3.7476e-04 eta 0:09:03
epoch [145/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.055) loss 0.8340 (0.7955) acc 78.1250 (79.3750) lr 3.7476e-04 eta 0:06:29
epoch [145/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.037) loss 1.1875 (0.7545) acc 68.7500 (80.4167) lr 3.7476e-04 eta 0:05:37
epoch [145/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.8325 (0.7244) acc 68.7500 (80.9375) lr 3.7476e-04 eta 0:05:11
epoch [145/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 1.4414 (0.7188) acc 65.6250 (81.6250) lr 3.7476e-04 eta 0:04:56
epoch [145/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.5332 (0.7200) acc 84.3750 (81.4583) lr 3.7476e-04 eta 0:04:45
epoch [145/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.6094 (0.7391) acc 78.1250 (80.8929) lr 3.7476e-04 eta 0:04:37
epoch [145/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9238 (0.7519) acc 71.8750 (80.2344) lr 3.7476e-04 eta 0:04:31
epoch [145/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.7695 (0.7352) acc 78.1250 (80.6250) lr 3.7476e-04 eta 0:04:26
epoch [145/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6943 (0.7288) acc 78.1250 (80.7500) lr 3.6258e-04 eta 0:04:22
epoch [146/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.107) loss 0.3684 (0.6857) acc 93.7500 (80.6250) lr 3.6258e-04 eta 0:08:48
epoch [146/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.7993 (0.6603) acc 78.1250 (80.9375) lr 3.6258e-04 eta 0:06:20
epoch [146/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.9365 (0.6534) acc 78.1250 (82.2917) lr 3.6258e-04 eta 0:05:31
epoch [146/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.8325 (0.6757) acc 71.8750 (81.4062) lr 3.6258e-04 eta 0:05:05
epoch [146/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.7021 (0.6935) acc 78.1250 (80.6250) lr 3.6258e-04 eta 0:04:50
epoch [146/200] batch [30/50] time 0.086 (0.103) data 0.000 (0.018) loss 0.4763 (0.6800) acc 87.5000 (81.1458) lr 3.6258e-04 eta 0:04:40
epoch [146/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.9443 (0.6786) acc 75.0000 (80.8036) lr 3.6258e-04 eta 0:04:32
epoch [146/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5962 (0.6752) acc 84.3750 (81.0938) lr 3.6258e-04 eta 0:04:26
epoch [146/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.6655 (0.6772) acc 75.0000 (81.1111) lr 3.6258e-04 eta 0:04:21
epoch [146/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4395 (0.6597) acc 90.6250 (81.7500) lr 3.5055e-04 eta 0:04:17
epoch [147/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.7402 (0.6583) acc 78.1250 (81.2500) lr 3.5055e-04 eta 0:08:09
epoch [147/200] batch [10/50] time 0.083 (0.133) data 0.000 (0.048) loss 0.7642 (0.6581) acc 84.3750 (80.6250) lr 3.5055e-04 eta 0:05:56
epoch [147/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.5527 (0.6552) acc 78.1250 (80.2083) lr 3.5055e-04 eta 0:05:12
epoch [147/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.7432 (0.6796) acc 81.2500 (80.6250) lr 3.5055e-04 eta 0:04:50
epoch [147/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.8018 (0.6564) acc 71.8750 (81.1250) lr 3.5055e-04 eta 0:04:37
epoch [147/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.5781 (0.6342) acc 78.1250 (81.6667) lr 3.5055e-04 eta 0:04:28
epoch [147/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.0449 (0.6412) acc 71.8750 (81.6071) lr 3.5055e-04 eta 0:04:21
epoch [147/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9448 (0.6541) acc 71.8750 (81.2500) lr 3.5055e-04 eta 0:04:16
epoch [147/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1289 (0.6696) acc 65.6250 (80.9028) lr 3.5055e-04 eta 0:04:12
epoch [147/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5742 (0.6712) acc 78.1250 (80.6875) lr 3.3869e-04 eta 0:04:08
epoch [148/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.109) loss 0.4575 (0.4947) acc 93.7500 (90.0000) lr 3.3869e-04 eta 0:08:30
epoch [148/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.6060 (0.6174) acc 87.5000 (85.3125) lr 3.3869e-04 eta 0:06:05
epoch [148/200] batch [15/50] time 0.083 (0.120) data 0.000 (0.036) loss 0.4749 (0.6012) acc 90.6250 (84.7917) lr 3.3869e-04 eta 0:05:16
epoch [148/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.9746 (0.6349) acc 65.6250 (82.3438) lr 3.3869e-04 eta 0:04:52
epoch [148/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.4485 (0.6579) acc 87.5000 (81.8750) lr 3.3869e-04 eta 0:04:37
epoch [148/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6538 (0.6750) acc 75.0000 (81.0417) lr 3.3869e-04 eta 0:04:26
epoch [148/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.016) loss 0.7490 (0.6862) acc 81.2500 (81.1607) lr 3.3869e-04 eta 0:04:19
epoch [148/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.9443 (0.7200) acc 71.8750 (80.5469) lr 3.3869e-04 eta 0:04:14
epoch [148/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6123 (0.7265) acc 75.0000 (80.1389) lr 3.3869e-04 eta 0:04:09
epoch [148/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6040 (0.7289) acc 84.3750 (80.0000) lr 3.2699e-04 eta 0:04:05
epoch [149/200] batch [5/50] time 0.085 (0.197) data 0.000 (0.111) loss 0.8013 (0.6449) acc 75.0000 (80.0000) lr 3.2699e-04 eta 0:08:31
epoch [149/200] batch [10/50] time 0.085 (0.141) data 0.000 (0.056) loss 0.6035 (0.6677) acc 78.1250 (80.3125) lr 3.2699e-04 eta 0:06:05
epoch [149/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 0.7710 (0.6912) acc 81.2500 (80.6250) lr 3.2699e-04 eta 0:05:16
epoch [149/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.028) loss 0.4487 (0.6923) acc 87.5000 (81.0938) lr 3.2699e-04 eta 0:04:51
epoch [149/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 1.1025 (0.7472) acc 68.7500 (79.6250) lr 3.2699e-04 eta 0:04:36
epoch [149/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.4490 (0.7052) acc 87.5000 (80.9375) lr 3.2699e-04 eta 0:04:26
epoch [149/200] batch [35/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.7026 (0.7082) acc 75.0000 (80.5357) lr 3.2699e-04 eta 0:04:18
epoch [149/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.7549 (0.6984) acc 78.1250 (80.8594) lr 3.2699e-04 eta 0:04:12
epoch [149/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6963 (0.6934) acc 87.5000 (81.0417) lr 3.2699e-04 eta 0:04:08
epoch [149/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.4436 (0.7017) acc 90.6250 (81.0000) lr 3.1545e-04 eta 0:04:04
epoch [150/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.108) loss 0.6416 (0.6545) acc 84.3750 (83.1250) lr 3.1545e-04 eta 0:08:10
epoch [150/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.5825 (0.6977) acc 78.1250 (80.0000) lr 3.1545e-04 eta 0:05:51
epoch [150/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 1.0830 (0.7226) acc 78.1250 (79.5833) lr 3.1545e-04 eta 0:05:05
epoch [150/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.027) loss 0.7769 (0.7314) acc 78.1250 (80.0000) lr 3.1545e-04 eta 0:04:41
epoch [150/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.6792 (0.7381) acc 84.3750 (80.3750) lr 3.1545e-04 eta 0:04:27
epoch [150/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.8423 (0.7354) acc 75.0000 (80.6250) lr 3.1545e-04 eta 0:04:17
epoch [150/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7036 (0.7327) acc 81.2500 (80.8036) lr 3.1545e-04 eta 0:04:10
epoch [150/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5786 (0.7134) acc 78.1250 (81.1719) lr 3.1545e-04 eta 0:04:05
epoch [150/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5781 (0.7206) acc 81.2500 (80.8333) lr 3.1545e-04 eta 0:04:00
epoch [150/200] batch [50/50] time 0.085 (0.095) data 0.000 (0.011) loss 0.7290 (0.6952) acc 78.1250 (81.5000) lr 3.0409e-04 eta 0:03:57
epoch [151/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.101) loss 0.4727 (0.7004) acc 90.6250 (81.8750) lr 3.0409e-04 eta 0:07:45
epoch [151/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.051) loss 0.3923 (0.7149) acc 90.6250 (81.5625) lr 3.0409e-04 eta 0:05:37
epoch [151/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.5835 (0.7452) acc 75.0000 (80.8333) lr 3.0409e-04 eta 0:04:54
epoch [151/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.7197 (0.7150) acc 87.5000 (81.4062) lr 3.0409e-04 eta 0:04:33
epoch [151/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.3503 (0.7231) acc 90.6250 (81.3750) lr 3.0409e-04 eta 0:04:19
epoch [151/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.3828 (0.7282) acc 90.6250 (81.6667) lr 3.0409e-04 eta 0:04:11
epoch [151/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.8545 (0.7394) acc 75.0000 (81.3393) lr 3.0409e-04 eta 0:04:04
epoch [151/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5356 (0.7223) acc 84.3750 (81.7188) lr 3.0409e-04 eta 0:03:59
epoch [151/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 1.3496 (0.7244) acc 65.6250 (81.8056) lr 3.0409e-04 eta 0:03:55
epoch [151/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.4490 (0.7173) acc 90.6250 (81.7500) lr 2.9289e-04 eta 0:03:51
epoch [152/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.105) loss 0.5103 (0.6197) acc 87.5000 (85.0000) lr 2.9289e-04 eta 0:07:43
epoch [152/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.7212 (0.7155) acc 81.2500 (81.2500) lr 2.9289e-04 eta 0:05:34
epoch [152/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.8413 (0.6959) acc 75.0000 (81.0417) lr 2.9289e-04 eta 0:04:50
epoch [152/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.7358 (0.6909) acc 78.1250 (81.4062) lr 2.9289e-04 eta 0:04:28
epoch [152/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.0078 (0.7303) acc 81.2500 (80.8750) lr 2.9289e-04 eta 0:04:15
epoch [152/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.8574 (0.7080) acc 81.2500 (81.3542) lr 2.9289e-04 eta 0:04:06
epoch [152/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.7798 (0.7336) acc 75.0000 (80.8036) lr 2.9289e-04 eta 0:04:00
epoch [152/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8374 (0.7531) acc 65.6250 (80.0781) lr 2.9289e-04 eta 0:03:54
epoch [152/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4932 (0.7581) acc 84.3750 (79.8611) lr 2.9289e-04 eta 0:03:50
epoch [152/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5034 (0.7630) acc 90.6250 (80.1875) lr 2.8187e-04 eta 0:03:47
epoch [153/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.106) loss 0.7524 (0.6400) acc 75.0000 (81.2500) lr 2.8187e-04 eta 0:07:36
epoch [153/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.7568 (0.6243) acc 78.1250 (82.8125) lr 2.8187e-04 eta 0:05:29
epoch [153/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.7046 (0.6246) acc 84.3750 (83.3333) lr 2.8187e-04 eta 0:04:46
epoch [153/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.9868 (0.6645) acc 65.6250 (81.5625) lr 2.8187e-04 eta 0:04:24
epoch [153/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.6206 (0.6417) acc 87.5000 (82.2500) lr 2.8187e-04 eta 0:04:11
epoch [153/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.5225 (0.6442) acc 84.3750 (81.8750) lr 2.8187e-04 eta 0:04:02
epoch [153/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.7329 (0.6780) acc 78.1250 (81.2500) lr 2.8187e-04 eta 0:03:55
epoch [153/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.6372 (0.6949) acc 84.3750 (80.9375) lr 2.8187e-04 eta 0:03:50
epoch [153/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4951 (0.6768) acc 87.5000 (81.2500) lr 2.8187e-04 eta 0:03:46
epoch [153/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7324 (0.6768) acc 84.3750 (81.1875) lr 2.7103e-04 eta 0:03:42
epoch [154/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.110) loss 0.6094 (0.6424) acc 84.3750 (84.3750) lr 2.7103e-04 eta 0:07:37
epoch [154/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.4766 (0.6044) acc 93.7500 (85.3125) lr 2.7103e-04 eta 0:05:27
epoch [154/200] batch [15/50] time 0.085 (0.122) data 0.001 (0.037) loss 0.8906 (0.6415) acc 75.0000 (83.9583) lr 2.7103e-04 eta 0:04:43
epoch [154/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.3774 (0.6098) acc 90.6250 (84.6875) lr 2.7103e-04 eta 0:04:21
epoch [154/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 1.0371 (0.6714) acc 71.8750 (82.2500) lr 2.7103e-04 eta 0:04:08
epoch [154/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.5464 (0.6674) acc 78.1250 (81.8750) lr 2.7103e-04 eta 0:03:59
epoch [154/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.8501 (0.7005) acc 81.2500 (81.5179) lr 2.7103e-04 eta 0:03:52
epoch [154/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.3293 (0.6758) acc 90.6250 (81.9531) lr 2.7103e-04 eta 0:03:46
epoch [154/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.7021 (0.6880) acc 75.0000 (81.6667) lr 2.7103e-04 eta 0:03:42
epoch [154/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6343 (0.6907) acc 81.2500 (81.6250) lr 2.6037e-04 eta 0:03:39
epoch [155/200] batch [5/50] time 0.085 (0.182) data 0.000 (0.097) loss 0.5869 (0.6739) acc 84.3750 (81.8750) lr 2.6037e-04 eta 0:06:58
epoch [155/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.6108 (0.7172) acc 84.3750 (81.2500) lr 2.6037e-04 eta 0:05:04
epoch [155/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.8154 (0.7009) acc 84.3750 (81.6667) lr 2.6037e-04 eta 0:04:27
epoch [155/200] batch [20/50] time 0.086 (0.109) data 0.000 (0.025) loss 0.5820 (0.6978) acc 84.3750 (82.1875) lr 2.6037e-04 eta 0:04:07
epoch [155/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.8965 (0.7086) acc 75.0000 (81.6250) lr 2.6037e-04 eta 0:03:56
epoch [155/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.8823 (0.7208) acc 62.5000 (81.1458) lr 2.6037e-04 eta 0:03:48
epoch [155/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6914 (0.7248) acc 81.2500 (81.2500) lr 2.6037e-04 eta 0:03:42
epoch [155/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.6860 (0.7341) acc 78.1250 (80.6250) lr 2.6037e-04 eta 0:03:38
epoch [155/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6235 (0.7361) acc 81.2500 (80.3472) lr 2.6037e-04 eta 0:03:34
epoch [155/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9341 (0.7358) acc 71.8750 (80.2500) lr 2.4989e-04 eta 0:03:31
epoch [156/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.100) loss 0.6094 (0.7642) acc 90.6250 (80.0000) lr 2.4989e-04 eta 0:06:57
epoch [156/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.6699 (0.6748) acc 84.3750 (81.5625) lr 2.4989e-04 eta 0:05:03
epoch [156/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.0322 (0.6754) acc 68.7500 (80.6250) lr 2.4989e-04 eta 0:04:24
epoch [156/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.3047 (0.6460) acc 90.6250 (81.7188) lr 2.4989e-04 eta 0:04:05
epoch [156/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.7305 (0.6538) acc 75.0000 (81.0000) lr 2.4989e-04 eta 0:03:53
epoch [156/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.8696 (0.6626) acc 81.2500 (80.9375) lr 2.4989e-04 eta 0:03:45
epoch [156/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.8418 (0.6601) acc 71.8750 (80.6250) lr 2.4989e-04 eta 0:03:39
epoch [156/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6294 (0.6567) acc 78.1250 (80.8594) lr 2.4989e-04 eta 0:03:34
epoch [156/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 1.0947 (0.6740) acc 68.7500 (80.3472) lr 2.4989e-04 eta 0:03:30
epoch [156/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5005 (0.6679) acc 87.5000 (80.6250) lr 2.3959e-04 eta 0:03:27
epoch [157/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.094) loss 0.6919 (0.7848) acc 78.1250 (76.8750) lr 2.3959e-04 eta 0:06:34
epoch [157/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.047) loss 0.5874 (0.8301) acc 87.5000 (78.1250) lr 2.3959e-04 eta 0:04:49
epoch [157/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.032) loss 0.6475 (0.8530) acc 78.1250 (78.1250) lr 2.3959e-04 eta 0:04:14
epoch [157/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.8145 (0.8640) acc 81.2500 (77.1875) lr 2.3959e-04 eta 0:03:56
epoch [157/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.5815 (0.8167) acc 87.5000 (78.1250) lr 2.3959e-04 eta 0:03:45
epoch [157/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.6436 (0.7670) acc 78.1250 (79.6875) lr 2.3959e-04 eta 0:03:38
epoch [157/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.5576 (0.7563) acc 87.5000 (80.1786) lr 2.3959e-04 eta 0:03:32
epoch [157/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.1826 (0.7588) acc 68.7500 (79.7656) lr 2.3959e-04 eta 0:03:28
epoch [157/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5093 (0.7471) acc 81.2500 (79.9306) lr 2.3959e-04 eta 0:03:24
epoch [157/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6230 (0.7565) acc 75.0000 (79.7500) lr 2.2949e-04 eta 0:03:21
epoch [158/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.101) loss 0.6147 (0.6756) acc 78.1250 (80.6250) lr 2.2949e-04 eta 0:06:40
epoch [158/200] batch [10/50] time 0.086 (0.136) data 0.000 (0.051) loss 0.6401 (0.6767) acc 81.2500 (79.0625) lr 2.2949e-04 eta 0:04:50
epoch [158/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.7349 (0.7158) acc 81.2500 (79.5833) lr 2.2949e-04 eta 0:04:13
epoch [158/200] batch [20/50] time 0.085 (0.110) data 0.001 (0.026) loss 0.2449 (0.6541) acc 93.7500 (81.2500) lr 2.2949e-04 eta 0:03:55
epoch [158/200] batch [25/50] time 0.085 (0.105) data 0.001 (0.020) loss 0.4932 (0.6654) acc 90.6250 (81.0000) lr 2.2949e-04 eta 0:03:43
epoch [158/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.5601 (0.6467) acc 84.3750 (81.3542) lr 2.2949e-04 eta 0:03:36
epoch [158/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.5498 (0.6448) acc 81.2500 (81.1607) lr 2.2949e-04 eta 0:03:30
epoch [158/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.5205 (0.6355) acc 84.3750 (81.4844) lr 2.2949e-04 eta 0:03:25
epoch [158/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5679 (0.6403) acc 78.1250 (81.3889) lr 2.2949e-04 eta 0:03:22
epoch [158/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.6890 (0.6494) acc 84.3750 (81.1875) lr 2.1957e-04 eta 0:03:19
epoch [159/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.099) loss 0.6782 (0.7278) acc 87.5000 (81.8750) lr 2.1957e-04 eta 0:06:26
epoch [159/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.4690 (0.6973) acc 84.3750 (81.5625) lr 2.1957e-04 eta 0:04:41
epoch [159/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.5015 (0.7086) acc 90.6250 (81.6667) lr 2.1957e-04 eta 0:04:05
epoch [159/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.5850 (0.7060) acc 81.2500 (81.8750) lr 2.1957e-04 eta 0:03:47
epoch [159/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.6606 (0.6789) acc 84.3750 (82.3750) lr 2.1957e-04 eta 0:03:36
epoch [159/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.5425 (0.6971) acc 84.3750 (81.7708) lr 2.1957e-04 eta 0:03:29
epoch [159/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.7881 (0.7006) acc 75.0000 (81.5179) lr 2.1957e-04 eta 0:03:23
epoch [159/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6094 (0.7028) acc 78.1250 (81.1719) lr 2.1957e-04 eta 0:03:19
epoch [159/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5317 (0.6867) acc 87.5000 (81.8056) lr 2.1957e-04 eta 0:03:15
epoch [159/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9585 (0.6840) acc 65.6250 (81.5625) lr 2.0984e-04 eta 0:03:12
epoch [160/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 0.7856 (0.7611) acc 78.1250 (79.3750) lr 2.0984e-04 eta 0:06:07
epoch [160/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.6689 (0.7407) acc 81.2500 (80.6250) lr 2.0984e-04 eta 0:04:29
epoch [160/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.032) loss 0.7393 (0.7193) acc 75.0000 (81.0417) lr 2.0984e-04 eta 0:03:55
epoch [160/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.9785 (0.7188) acc 68.7500 (80.1562) lr 2.0984e-04 eta 0:03:39
epoch [160/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.5327 (0.7337) acc 81.2500 (80.2500) lr 2.0984e-04 eta 0:03:29
epoch [160/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.3274 (0.7056) acc 93.7500 (81.1458) lr 2.0984e-04 eta 0:03:22
epoch [160/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6626 (0.6825) acc 84.3750 (81.8750) lr 2.0984e-04 eta 0:03:17
epoch [160/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7959 (0.6780) acc 78.1250 (82.1094) lr 2.0984e-04 eta 0:03:13
epoch [160/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9126 (0.6766) acc 75.0000 (81.8056) lr 2.0984e-04 eta 0:03:09
epoch [160/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5376 (0.6564) acc 87.5000 (82.1250) lr 2.0032e-04 eta 0:03:07
epoch [161/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 0.7339 (0.7163) acc 81.2500 (81.2500) lr 2.0032e-04 eta 0:06:25
epoch [161/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.7236 (0.7150) acc 78.1250 (79.3750) lr 2.0032e-04 eta 0:04:37
epoch [161/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.6421 (0.7330) acc 84.3750 (78.7500) lr 2.0032e-04 eta 0:04:00
epoch [161/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.9761 (0.7315) acc 71.8750 (79.2188) lr 2.0032e-04 eta 0:03:41
epoch [161/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.8130 (0.7349) acc 78.1250 (78.8750) lr 2.0032e-04 eta 0:03:30
epoch [161/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6143 (0.7406) acc 81.2500 (79.0625) lr 2.0032e-04 eta 0:03:22
epoch [161/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.4827 (0.7275) acc 81.2500 (79.1964) lr 2.0032e-04 eta 0:03:16
epoch [161/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8110 (0.7213) acc 75.0000 (79.6094) lr 2.0032e-04 eta 0:03:12
epoch [161/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.9307 (0.7108) acc 71.8750 (79.9306) lr 2.0032e-04 eta 0:03:08
epoch [161/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9092 (0.7098) acc 81.2500 (79.8125) lr 1.9098e-04 eta 0:03:05
epoch [162/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.094) loss 0.8457 (0.7461) acc 78.1250 (79.3750) lr 1.9098e-04 eta 0:05:48
epoch [162/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.7212 (0.6467) acc 84.3750 (81.8750) lr 1.9098e-04 eta 0:04:15
epoch [162/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.032) loss 0.6938 (0.6755) acc 84.3750 (81.2500) lr 1.9098e-04 eta 0:03:44
epoch [162/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 1.1338 (0.7574) acc 62.5000 (79.0625) lr 1.9098e-04 eta 0:03:28
epoch [162/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.3179 (0.7630) acc 87.5000 (79.3750) lr 1.9098e-04 eta 0:03:19
epoch [162/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 1.1172 (0.7658) acc 68.7500 (79.4792) lr 1.9098e-04 eta 0:03:12
epoch [162/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.5986 (0.7570) acc 81.2500 (79.1964) lr 1.9098e-04 eta 0:03:07
epoch [162/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7656 (0.7687) acc 81.2500 (78.5156) lr 1.9098e-04 eta 0:03:03
epoch [162/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7905 (0.7755) acc 68.7500 (78.2639) lr 1.9098e-04 eta 0:03:00
epoch [162/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6743 (0.7616) acc 84.3750 (78.7500) lr 1.8185e-04 eta 0:02:57
epoch [163/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.093) loss 0.7671 (0.7143) acc 84.3750 (81.8750) lr 1.8185e-04 eta 0:05:39
epoch [163/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.2318 (0.6731) acc 96.8750 (82.8125) lr 1.8185e-04 eta 0:04:09
epoch [163/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.031) loss 0.9170 (0.7050) acc 78.1250 (82.7083) lr 1.8185e-04 eta 0:03:39
epoch [163/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.7554 (0.6897) acc 78.1250 (82.6562) lr 1.8185e-04 eta 0:03:23
epoch [163/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.6870 (0.6967) acc 71.8750 (82.1250) lr 1.8185e-04 eta 0:03:14
epoch [163/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.6904 (0.7023) acc 75.0000 (81.7708) lr 1.8185e-04 eta 0:03:07
epoch [163/200] batch [35/50] time 0.086 (0.098) data 0.001 (0.014) loss 0.3865 (0.7070) acc 87.5000 (81.4286) lr 1.8185e-04 eta 0:03:03
epoch [163/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1807 (0.7225) acc 65.6250 (80.7031) lr 1.8185e-04 eta 0:02:59
epoch [163/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6748 (0.7262) acc 81.2500 (80.7639) lr 1.8185e-04 eta 0:02:56
epoch [163/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7031 (0.7309) acc 78.1250 (80.5625) lr 1.7292e-04 eta 0:02:53
epoch [164/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.106) loss 0.8618 (0.7667) acc 81.2500 (79.3750) lr 1.7292e-04 eta 0:05:53
epoch [164/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.9531 (0.6890) acc 75.0000 (81.8750) lr 1.7292e-04 eta 0:04:14
epoch [164/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.7417 (0.6591) acc 78.1250 (82.2917) lr 1.7292e-04 eta 0:03:40
epoch [164/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.5649 (0.6605) acc 90.6250 (81.5625) lr 1.7292e-04 eta 0:03:23
epoch [164/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.7070 (0.6923) acc 75.0000 (80.1250) lr 1.7292e-04 eta 0:03:13
epoch [164/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 1.1455 (0.7010) acc 68.7500 (79.6875) lr 1.7292e-04 eta 0:03:06
epoch [164/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.6646 (0.7130) acc 84.3750 (79.5536) lr 1.7292e-04 eta 0:03:01
epoch [164/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 1.1494 (0.7242) acc 65.6250 (79.2969) lr 1.7292e-04 eta 0:02:57
epoch [164/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6460 (0.7345) acc 71.8750 (79.0972) lr 1.7292e-04 eta 0:02:54
epoch [164/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7690 (0.7379) acc 71.8750 (78.7500) lr 1.6419e-04 eta 0:02:51
epoch [165/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.108) loss 0.7705 (0.7746) acc 78.1250 (78.7500) lr 1.6419e-04 eta 0:05:44
epoch [165/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.054) loss 0.5273 (0.6914) acc 87.5000 (80.6250) lr 1.6419e-04 eta 0:04:07
epoch [165/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.7910 (0.7036) acc 78.1250 (80.6250) lr 1.6419e-04 eta 0:03:34
epoch [165/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.9980 (0.6730) acc 75.0000 (81.7188) lr 1.6419e-04 eta 0:03:18
epoch [165/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.6523 (0.6650) acc 87.5000 (82.0000) lr 1.6419e-04 eta 0:03:08
epoch [165/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.4512 (0.6593) acc 81.2500 (81.6667) lr 1.6419e-04 eta 0:03:01
epoch [165/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.9849 (0.6579) acc 68.7500 (81.7857) lr 1.6419e-04 eta 0:02:56
epoch [165/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7300 (0.6777) acc 81.2500 (81.0156) lr 1.6419e-04 eta 0:02:52
epoch [165/200] batch [45/50] time 0.087 (0.096) data 0.000 (0.012) loss 0.8340 (0.6917) acc 78.1250 (80.7639) lr 1.6419e-04 eta 0:02:49
epoch [165/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4834 (0.6754) acc 87.5000 (81.1875) lr 1.5567e-04 eta 0:02:46
epoch [166/200] batch [5/50] time 0.086 (0.182) data 0.000 (0.096) loss 0.9272 (0.6655) acc 78.1250 (83.7500) lr 1.5567e-04 eta 0:05:18
epoch [166/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.048) loss 0.5312 (0.6574) acc 90.6250 (84.0625) lr 1.5567e-04 eta 0:03:52
epoch [166/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.8311 (0.6420) acc 78.1250 (83.5417) lr 1.5567e-04 eta 0:03:23
epoch [166/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.2583 (0.6605) acc 90.6250 (82.6562) lr 1.5567e-04 eta 0:03:08
epoch [166/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.8716 (0.6836) acc 71.8750 (82.1250) lr 1.5567e-04 eta 0:02:59
epoch [166/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.7900 (0.6736) acc 81.2500 (82.8125) lr 1.5567e-04 eta 0:02:53
epoch [166/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 1.3447 (0.7062) acc 62.5000 (82.1429) lr 1.5567e-04 eta 0:02:49
epoch [166/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 1.0312 (0.7245) acc 75.0000 (81.8750) lr 1.5567e-04 eta 0:02:45
epoch [166/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5327 (0.7266) acc 87.5000 (81.7361) lr 1.5567e-04 eta 0:02:42
epoch [166/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7866 (0.7228) acc 71.8750 (81.5625) lr 1.4736e-04 eta 0:02:40
epoch [167/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.102) loss 0.6025 (0.6559) acc 84.3750 (81.2500) lr 1.4736e-04 eta 0:05:18
epoch [167/200] batch [10/50] time 0.083 (0.136) data 0.000 (0.051) loss 0.8872 (0.6352) acc 75.0000 (82.5000) lr 1.4736e-04 eta 0:03:49
epoch [167/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.3247 (0.7026) acc 87.5000 (81.2500) lr 1.4736e-04 eta 0:03:19
epoch [167/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.4270 (0.6452) acc 87.5000 (83.1250) lr 1.4736e-04 eta 0:03:04
epoch [167/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.5073 (0.6561) acc 81.2500 (82.2500) lr 1.4736e-04 eta 0:02:55
epoch [167/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.7529 (0.6779) acc 78.1250 (81.4583) lr 1.4736e-04 eta 0:02:49
epoch [167/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6094 (0.6577) acc 87.5000 (82.2321) lr 1.4736e-04 eta 0:02:44
epoch [167/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6621 (0.6638) acc 84.3750 (82.0312) lr 1.4736e-04 eta 0:02:41
epoch [167/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.4490 (0.6551) acc 87.5000 (82.0139) lr 1.4736e-04 eta 0:02:38
epoch [167/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.1279 (0.6645) acc 71.8750 (81.8125) lr 1.3926e-04 eta 0:02:35
epoch [168/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.098) loss 0.5835 (0.5799) acc 75.0000 (80.6250) lr 1.3926e-04 eta 0:05:02
epoch [168/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.6045 (0.6191) acc 81.2500 (80.9375) lr 1.3926e-04 eta 0:03:39
epoch [168/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.4175 (0.5911) acc 90.6250 (81.8750) lr 1.3926e-04 eta 0:03:12
epoch [168/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.7314 (0.5866) acc 81.2500 (82.5000) lr 1.3926e-04 eta 0:02:58
epoch [168/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.4241 (0.5839) acc 84.3750 (82.7500) lr 1.3926e-04 eta 0:02:49
epoch [168/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6260 (0.6066) acc 81.2500 (82.1875) lr 1.3926e-04 eta 0:02:43
epoch [168/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.4905 (0.6112) acc 90.6250 (82.3214) lr 1.3926e-04 eta 0:02:39
epoch [168/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.7236 (0.6226) acc 87.5000 (82.2656) lr 1.3926e-04 eta 0:02:35
epoch [168/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4507 (0.6264) acc 87.5000 (82.2917) lr 1.3926e-04 eta 0:02:32
epoch [168/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7944 (0.6341) acc 81.2500 (82.2500) lr 1.3137e-04 eta 0:02:30
epoch [169/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.101) loss 0.6562 (0.6678) acc 75.0000 (80.6250) lr 1.3137e-04 eta 0:04:58
epoch [169/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.7412 (0.6486) acc 84.3750 (81.8750) lr 1.3137e-04 eta 0:03:36
epoch [169/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.6475 (0.6969) acc 78.1250 (80.2083) lr 1.3137e-04 eta 0:03:08
epoch [169/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 1.1709 (0.6899) acc 81.2500 (81.4062) lr 1.3137e-04 eta 0:02:54
epoch [169/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 1.0029 (0.7146) acc 78.1250 (81.3750) lr 1.3137e-04 eta 0:02:45
epoch [169/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.6758 (0.7260) acc 75.0000 (80.7292) lr 1.3137e-04 eta 0:02:39
epoch [169/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.8813 (0.7139) acc 84.3750 (81.1607) lr 1.3137e-04 eta 0:02:35
epoch [169/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.5347 (0.6927) acc 87.5000 (81.6406) lr 1.3137e-04 eta 0:02:31
epoch [169/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.8940 (0.6993) acc 68.7500 (81.0417) lr 1.3137e-04 eta 0:02:28
epoch [169/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.5713 (0.6889) acc 87.5000 (81.3750) lr 1.2369e-04 eta 0:02:26
epoch [170/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.094) loss 0.7056 (0.6661) acc 87.5000 (84.3750) lr 1.2369e-04 eta 0:04:36
epoch [170/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.9951 (0.7299) acc 75.0000 (82.8125) lr 1.2369e-04 eta 0:03:23
epoch [170/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.031) loss 0.4285 (0.7203) acc 90.6250 (82.0833) lr 1.2369e-04 eta 0:02:58
epoch [170/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.5259 (0.7001) acc 84.3750 (81.8750) lr 1.2369e-04 eta 0:02:45
epoch [170/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.6382 (0.7255) acc 87.5000 (81.2500) lr 1.2369e-04 eta 0:02:38
epoch [170/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.9971 (0.7324) acc 68.7500 (80.8333) lr 1.2369e-04 eta 0:02:32
epoch [170/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.3828 (0.7314) acc 87.5000 (80.6250) lr 1.2369e-04 eta 0:02:28
epoch [170/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6782 (0.7284) acc 78.1250 (80.4688) lr 1.2369e-04 eta 0:02:25
epoch [170/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9727 (0.7333) acc 78.1250 (80.0694) lr 1.2369e-04 eta 0:02:22
epoch [170/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.4473 (0.7193) acc 84.3750 (80.3750) lr 1.1623e-04 eta 0:02:20
epoch [171/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.096) loss 0.7080 (0.7655) acc 81.2500 (80.0000) lr 1.1623e-04 eta 0:04:31
epoch [171/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.3652 (0.6644) acc 87.5000 (80.6250) lr 1.1623e-04 eta 0:03:18
epoch [171/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.7544 (0.6459) acc 81.2500 (81.2500) lr 1.1623e-04 eta 0:02:53
epoch [171/200] batch [20/50] time 0.083 (0.108) data 0.000 (0.024) loss 0.8320 (0.6525) acc 78.1250 (81.0938) lr 1.1623e-04 eta 0:02:40
epoch [171/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.3884 (0.6602) acc 87.5000 (81.5000) lr 1.1623e-04 eta 0:02:32
epoch [171/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 0.8511 (0.6489) acc 68.7500 (81.9792) lr 1.1623e-04 eta 0:02:27
epoch [171/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.5474 (0.6546) acc 84.3750 (81.6964) lr 1.1623e-04 eta 0:02:23
epoch [171/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1865 (0.6645) acc 68.7500 (81.8750) lr 1.1623e-04 eta 0:02:20
epoch [171/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5078 (0.6481) acc 87.5000 (82.2917) lr 1.1623e-04 eta 0:02:17
epoch [171/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7764 (0.6648) acc 75.0000 (81.5625) lr 1.0899e-04 eta 0:02:15
epoch [172/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.098) loss 0.6465 (0.5733) acc 81.2500 (85.0000) lr 1.0899e-04 eta 0:04:24
epoch [172/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.7422 (0.6082) acc 81.2500 (83.7500) lr 1.0899e-04 eta 0:03:12
epoch [172/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 0.5122 (0.6326) acc 90.6250 (82.9167) lr 1.0899e-04 eta 0:02:48
epoch [172/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.8706 (0.6915) acc 71.8750 (82.0312) lr 1.0899e-04 eta 0:02:35
epoch [172/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.6699 (0.6792) acc 84.3750 (82.1250) lr 1.0899e-04 eta 0:02:28
epoch [172/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.9287 (0.7004) acc 84.3750 (81.8750) lr 1.0899e-04 eta 0:02:23
epoch [172/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.5059 (0.6733) acc 84.3750 (82.2321) lr 1.0899e-04 eta 0:02:19
epoch [172/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.9580 (0.6796) acc 71.8750 (81.5625) lr 1.0899e-04 eta 0:02:16
epoch [172/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6118 (0.6679) acc 87.5000 (81.8056) lr 1.0899e-04 eta 0:02:13
epoch [172/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6270 (0.6643) acc 84.3750 (81.8750) lr 1.0197e-04 eta 0:02:11
epoch [173/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.098) loss 0.5015 (0.6109) acc 84.3750 (81.8750) lr 1.0197e-04 eta 0:04:16
epoch [173/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.6577 (0.6726) acc 81.2500 (82.1875) lr 1.0197e-04 eta 0:03:06
epoch [173/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.3652 (0.6806) acc 93.7500 (83.3333) lr 1.0197e-04 eta 0:02:42
epoch [173/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.9692 (0.7424) acc 78.1250 (81.7188) lr 1.0197e-04 eta 0:02:31
epoch [173/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.7891 (0.7235) acc 78.1250 (81.5000) lr 1.0197e-04 eta 0:02:23
epoch [173/200] batch [30/50] time 0.086 (0.101) data 0.000 (0.017) loss 0.7896 (0.7167) acc 81.2500 (81.4583) lr 1.0197e-04 eta 0:02:18
epoch [173/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 0.7871 (0.7208) acc 75.0000 (81.1607) lr 1.0197e-04 eta 0:02:14
epoch [173/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6943 (0.7322) acc 78.1250 (80.5469) lr 1.0197e-04 eta 0:02:11
epoch [173/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0215 (0.7301) acc 75.0000 (80.4861) lr 1.0197e-04 eta 0:02:09
epoch [173/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0039 (0.7311) acc 75.0000 (80.5625) lr 9.5173e-05 eta 0:02:07
epoch [174/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.105) loss 0.4175 (0.5412) acc 93.7500 (86.8750) lr 9.5173e-05 eta 0:04:16
epoch [174/200] batch [10/50] time 0.086 (0.138) data 0.000 (0.053) loss 0.8384 (0.6101) acc 71.8750 (82.5000) lr 9.5173e-05 eta 0:03:04
epoch [174/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.6040 (0.6736) acc 84.3750 (81.0417) lr 9.5173e-05 eta 0:02:40
epoch [174/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.026) loss 0.6147 (0.6799) acc 75.0000 (80.1562) lr 9.5173e-05 eta 0:02:28
epoch [174/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.5308 (0.6931) acc 81.2500 (79.6250) lr 9.5173e-05 eta 0:02:20
epoch [174/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.7593 (0.7028) acc 81.2500 (79.6875) lr 9.5173e-05 eta 0:02:15
epoch [174/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.015) loss 0.7534 (0.6991) acc 75.0000 (79.7321) lr 9.5173e-05 eta 0:02:11
epoch [174/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.4666 (0.7140) acc 90.6250 (79.5312) lr 9.5173e-05 eta 0:02:08
epoch [174/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5693 (0.6903) acc 78.1250 (80.1389) lr 9.5173e-05 eta 0:02:05
epoch [174/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6694 (0.6782) acc 78.1250 (80.6250) lr 8.8597e-05 eta 0:02:03
epoch [175/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.108) loss 0.8291 (0.6604) acc 78.1250 (84.3750) lr 8.8597e-05 eta 0:04:08
epoch [175/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.6279 (0.6420) acc 81.2500 (84.0625) lr 8.8597e-05 eta 0:02:58
epoch [175/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 1.1582 (0.6724) acc 71.8750 (82.7083) lr 8.8597e-05 eta 0:02:34
epoch [175/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.5532 (0.6353) acc 90.6250 (83.7500) lr 8.8597e-05 eta 0:02:22
epoch [175/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.6479 (0.6590) acc 81.2500 (83.3750) lr 8.8597e-05 eta 0:02:15
epoch [175/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.8462 (0.6885) acc 71.8750 (81.7708) lr 8.8597e-05 eta 0:02:10
epoch [175/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 1.0879 (0.7029) acc 68.7500 (80.8929) lr 8.8597e-05 eta 0:02:06
epoch [175/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8076 (0.7006) acc 75.0000 (80.4688) lr 8.8597e-05 eta 0:02:03
epoch [175/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7109 (0.7003) acc 84.3750 (80.6250) lr 8.8597e-05 eta 0:02:00
epoch [175/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.3826 (0.6808) acc 90.6250 (81.1875) lr 8.2245e-05 eta 0:01:58
epoch [176/200] batch [5/50] time 0.084 (0.178) data 0.000 (0.093) loss 0.3979 (0.6416) acc 90.6250 (82.5000) lr 8.2245e-05 eta 0:03:41
epoch [176/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.5762 (0.6424) acc 81.2500 (83.1250) lr 8.2245e-05 eta 0:02:42
epoch [176/200] batch [15/50] time 0.084 (0.115) data 0.000 (0.031) loss 0.4451 (0.5907) acc 90.6250 (83.9583) lr 8.2245e-05 eta 0:02:22
epoch [176/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.023) loss 0.5820 (0.6417) acc 78.1250 (81.8750) lr 8.2245e-05 eta 0:02:12
epoch [176/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.6392 (0.6687) acc 87.5000 (82.0000) lr 8.2245e-05 eta 0:02:06
epoch [176/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8892 (0.6764) acc 81.2500 (82.0833) lr 8.2245e-05 eta 0:02:01
epoch [176/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.2766 (0.6849) acc 90.6250 (81.7857) lr 8.2245e-05 eta 0:01:58
epoch [176/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9224 (0.6943) acc 71.8750 (81.4844) lr 8.2245e-05 eta 0:01:55
epoch [176/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6138 (0.7000) acc 87.5000 (81.5278) lr 8.2245e-05 eta 0:01:53
epoch [176/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.009) loss 0.8960 (0.6999) acc 84.3750 (81.3750) lr 7.6120e-05 eta 0:01:51
epoch [177/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.095) loss 0.5591 (0.5518) acc 81.2500 (85.6250) lr 7.6120e-05 eta 0:03:35
epoch [177/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.8257 (0.5515) acc 78.1250 (85.6250) lr 7.6120e-05 eta 0:02:37
epoch [177/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.032) loss 0.3506 (0.5443) acc 90.6250 (85.2083) lr 7.6120e-05 eta 0:02:18
epoch [177/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 1.2002 (0.5916) acc 75.0000 (84.5312) lr 7.6120e-05 eta 0:02:08
epoch [177/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.4321 (0.5829) acc 81.2500 (84.7500) lr 7.6120e-05 eta 0:02:01
epoch [177/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6445 (0.5895) acc 78.1250 (84.6875) lr 7.6120e-05 eta 0:01:57
epoch [177/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.5493 (0.5908) acc 87.5000 (84.5536) lr 7.6120e-05 eta 0:01:54
epoch [177/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.3936 (0.5815) acc 87.5000 (84.6875) lr 7.6120e-05 eta 0:01:51
epoch [177/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7808 (0.5971) acc 75.0000 (84.3056) lr 7.6120e-05 eta 0:01:49
epoch [177/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.4341 (0.6057) acc 87.5000 (84.0625) lr 7.0224e-05 eta 0:01:47
epoch [178/200] batch [5/50] time 0.083 (0.178) data 0.000 (0.093) loss 0.5898 (0.6067) acc 81.2500 (83.1250) lr 7.0224e-05 eta 0:03:23
epoch [178/200] batch [10/50] time 0.084 (0.131) data 0.000 (0.046) loss 0.3708 (0.6388) acc 87.5000 (83.4375) lr 7.0224e-05 eta 0:02:29
epoch [178/200] batch [15/50] time 0.083 (0.115) data 0.000 (0.031) loss 0.9741 (0.6635) acc 68.7500 (82.2917) lr 7.0224e-05 eta 0:02:10
epoch [178/200] batch [20/50] time 0.083 (0.107) data 0.000 (0.023) loss 0.7852 (0.6718) acc 75.0000 (81.4062) lr 7.0224e-05 eta 0:02:01
epoch [178/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 1.0449 (0.7033) acc 75.0000 (80.5000) lr 7.0224e-05 eta 0:01:55
epoch [178/200] batch [30/50] time 0.084 (0.099) data 0.000 (0.016) loss 0.4773 (0.6936) acc 87.5000 (81.1458) lr 7.0224e-05 eta 0:01:51
epoch [178/200] batch [35/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6963 (0.6714) acc 78.1250 (81.7857) lr 7.0224e-05 eta 0:01:48
epoch [178/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5596 (0.6861) acc 84.3750 (81.4062) lr 7.0224e-05 eta 0:01:46
epoch [178/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.5332 (0.6790) acc 84.3750 (81.8056) lr 7.0224e-05 eta 0:01:44
epoch [178/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.009) loss 0.3992 (0.6881) acc 93.7500 (81.7500) lr 6.4556e-05 eta 0:01:42
epoch [179/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 0.8735 (0.6430) acc 78.1250 (81.8750) lr 6.4556e-05 eta 0:03:16
epoch [179/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.7505 (0.6799) acc 75.0000 (80.3125) lr 6.4556e-05 eta 0:02:23
epoch [179/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.032) loss 0.9155 (0.7084) acc 75.0000 (80.4167) lr 6.4556e-05 eta 0:02:05
epoch [179/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.8325 (0.7272) acc 75.0000 (79.6875) lr 6.4556e-05 eta 0:01:56
epoch [179/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.4836 (0.7241) acc 84.3750 (79.7500) lr 6.4556e-05 eta 0:01:50
epoch [179/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.3757 (0.7149) acc 90.6250 (80.2083) lr 6.4556e-05 eta 0:01:46
epoch [179/200] batch [35/50] time 0.083 (0.098) data 0.001 (0.014) loss 0.5747 (0.7149) acc 87.5000 (80.4464) lr 6.4556e-05 eta 0:01:43
epoch [179/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7095 (0.7024) acc 81.2500 (80.9375) lr 6.4556e-05 eta 0:01:41
epoch [179/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.7134 (0.6908) acc 87.5000 (81.1806) lr 6.4556e-05 eta 0:01:39
epoch [179/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.4739 (0.6838) acc 84.3750 (81.5000) lr 5.9119e-05 eta 0:01:37
epoch [180/200] batch [5/50] time 0.084 (0.199) data 0.000 (0.114) loss 1.0283 (0.7107) acc 68.7500 (80.0000) lr 5.9119e-05 eta 0:03:28
epoch [180/200] batch [10/50] time 0.084 (0.142) data 0.000 (0.057) loss 0.6655 (0.6989) acc 81.2500 (79.6875) lr 5.9119e-05 eta 0:02:27
epoch [180/200] batch [15/50] time 0.084 (0.123) data 0.000 (0.038) loss 1.1650 (0.7040) acc 75.0000 (81.0417) lr 5.9119e-05 eta 0:02:06
epoch [180/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.029) loss 0.4927 (0.7307) acc 87.5000 (80.7812) lr 5.9119e-05 eta 0:01:56
epoch [180/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.023) loss 0.4160 (0.7119) acc 87.5000 (81.1250) lr 5.9119e-05 eta 0:01:50
epoch [180/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.5776 (0.7051) acc 81.2500 (80.9375) lr 5.9119e-05 eta 0:01:45
epoch [180/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.5391 (0.7052) acc 78.1250 (80.5357) lr 5.9119e-05 eta 0:01:42
epoch [180/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.014) loss 0.4377 (0.6958) acc 87.5000 (81.0938) lr 5.9119e-05 eta 0:01:39
epoch [180/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.4209 (0.6692) acc 87.5000 (81.8750) lr 5.9119e-05 eta 0:01:37
epoch [180/200] batch [50/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.2239 (0.6537) acc 93.7500 (82.1250) lr 5.3915e-05 eta 0:01:35
epoch [181/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.102) loss 0.5547 (0.7278) acc 84.3750 (82.5000) lr 5.3915e-05 eta 0:03:06
epoch [181/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.6406 (0.6951) acc 87.5000 (82.1875) lr 5.3915e-05 eta 0:02:14
epoch [181/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.6978 (0.6903) acc 81.2500 (81.6667) lr 5.3915e-05 eta 0:01:56
epoch [181/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.3481 (0.6701) acc 87.5000 (81.8750) lr 5.3915e-05 eta 0:01:47
epoch [181/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.7671 (0.6959) acc 78.1250 (81.0000) lr 5.3915e-05 eta 0:01:42
epoch [181/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.7402 (0.6774) acc 84.3750 (81.8750) lr 5.3915e-05 eta 0:01:38
epoch [181/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 1.0566 (0.6825) acc 68.7500 (81.9643) lr 5.3915e-05 eta 0:01:35
epoch [181/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.4790 (0.6817) acc 81.2500 (82.1094) lr 5.3915e-05 eta 0:01:33
epoch [181/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.2418 (0.6690) acc 93.7500 (82.2222) lr 5.3915e-05 eta 0:01:31
epoch [181/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.3799 (0.6617) acc 87.5000 (82.1875) lr 4.8943e-05 eta 0:01:29
epoch [182/200] batch [5/50] time 0.083 (0.184) data 0.000 (0.099) loss 0.6001 (0.7108) acc 81.2500 (80.6250) lr 4.8943e-05 eta 0:02:53
epoch [182/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 1.1670 (0.6999) acc 65.6250 (80.0000) lr 4.8943e-05 eta 0:02:06
epoch [182/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.3794 (0.6262) acc 87.5000 (81.6667) lr 4.8943e-05 eta 0:01:49
epoch [182/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.8145 (0.6216) acc 81.2500 (81.8750) lr 4.8943e-05 eta 0:01:41
epoch [182/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7471 (0.6155) acc 78.1250 (81.7500) lr 4.8943e-05 eta 0:01:36
epoch [182/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.5088 (0.6376) acc 87.5000 (81.2500) lr 4.8943e-05 eta 0:01:32
epoch [182/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.9775 (0.6541) acc 81.2500 (81.6071) lr 4.8943e-05 eta 0:01:30
epoch [182/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6899 (0.6650) acc 84.3750 (81.6406) lr 4.8943e-05 eta 0:01:28
epoch [182/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4175 (0.6532) acc 87.5000 (82.0139) lr 4.8943e-05 eta 0:01:26
epoch [182/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6060 (0.6500) acc 87.5000 (82.2500) lr 4.4207e-05 eta 0:01:24
epoch [183/200] batch [5/50] time 0.085 (0.195) data 0.000 (0.110) loss 0.5181 (0.5264) acc 81.2500 (86.8750) lr 4.4207e-05 eta 0:02:54
epoch [183/200] batch [10/50] time 0.083 (0.139) data 0.000 (0.055) loss 0.5176 (0.6332) acc 78.1250 (84.0625) lr 4.4207e-05 eta 0:02:03
epoch [183/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 0.9370 (0.6581) acc 71.8750 (82.7083) lr 4.4207e-05 eta 0:01:46
epoch [183/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.5991 (0.6717) acc 84.3750 (82.1875) lr 4.4207e-05 eta 0:01:38
epoch [183/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.8521 (0.6544) acc 75.0000 (83.0000) lr 4.4207e-05 eta 0:01:32
epoch [183/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.5786 (0.6735) acc 81.2500 (82.2917) lr 4.4207e-05 eta 0:01:29
epoch [183/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.2275 (0.6451) acc 93.7500 (82.8571) lr 4.4207e-05 eta 0:01:26
epoch [183/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.8340 (0.6631) acc 81.2500 (82.6562) lr 4.4207e-05 eta 0:01:24
epoch [183/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4282 (0.6722) acc 93.7500 (82.6389) lr 4.4207e-05 eta 0:01:22
epoch [183/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6543 (0.6611) acc 84.3750 (82.9375) lr 3.9706e-05 eta 0:01:20
epoch [184/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.098) loss 0.4172 (0.7114) acc 84.3750 (81.8750) lr 3.9706e-05 eta 0:02:35
epoch [184/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.9268 (0.6883) acc 75.0000 (82.1875) lr 3.9706e-05 eta 0:01:52
epoch [184/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.5386 (0.6355) acc 87.5000 (83.5417) lr 3.9706e-05 eta 0:01:38
epoch [184/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.6924 (0.6513) acc 81.2500 (83.1250) lr 3.9706e-05 eta 0:01:30
epoch [184/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.8174 (0.6544) acc 75.0000 (82.6250) lr 3.9706e-05 eta 0:01:26
epoch [184/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8828 (0.6583) acc 81.2500 (82.7083) lr 3.9706e-05 eta 0:01:22
epoch [184/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 1.0371 (0.6630) acc 81.2500 (82.4107) lr 3.9706e-05 eta 0:01:20
epoch [184/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.4915 (0.6661) acc 87.5000 (82.5000) lr 3.9706e-05 eta 0:01:18
epoch [184/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6572 (0.6716) acc 81.2500 (81.9444) lr 3.9706e-05 eta 0:01:16
epoch [184/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5415 (0.6722) acc 84.3750 (82.0625) lr 3.5443e-05 eta 0:01:15
epoch [185/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.101) loss 0.5703 (0.7146) acc 87.5000 (81.8750) lr 3.5443e-05 eta 0:02:28
epoch [185/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.051) loss 0.4963 (0.6651) acc 90.6250 (82.1875) lr 3.5443e-05 eta 0:01:46
epoch [185/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.9316 (0.6686) acc 81.2500 (83.1250) lr 3.5443e-05 eta 0:01:32
epoch [185/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.4639 (0.6857) acc 87.5000 (81.8750) lr 3.5443e-05 eta 0:01:25
epoch [185/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.6743 (0.7081) acc 81.2500 (81.6250) lr 3.5443e-05 eta 0:01:21
epoch [185/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.7520 (0.6727) acc 78.1250 (82.7083) lr 3.5443e-05 eta 0:01:18
epoch [185/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.4526 (0.6839) acc 90.6250 (82.1429) lr 3.5443e-05 eta 0:01:15
epoch [185/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8008 (0.6878) acc 84.3750 (82.5000) lr 3.5443e-05 eta 0:01:13
epoch [185/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.6304 (0.6774) acc 78.1250 (82.5694) lr 3.5443e-05 eta 0:01:12
epoch [185/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.5054 (0.6788) acc 87.5000 (82.2500) lr 3.1417e-05 eta 0:01:10
epoch [186/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 0.5542 (0.7340) acc 84.3750 (78.1250) lr 3.1417e-05 eta 0:02:23
epoch [186/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.3540 (0.6250) acc 90.6250 (82.1875) lr 3.1417e-05 eta 0:01:42
epoch [186/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.8159 (0.7456) acc 78.1250 (79.5833) lr 3.1417e-05 eta 0:01:28
epoch [186/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.027) loss 0.8037 (0.7276) acc 81.2500 (79.6875) lr 3.1417e-05 eta 0:01:21
epoch [186/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.6055 (0.7256) acc 84.3750 (79.7500) lr 3.1417e-05 eta 0:01:16
epoch [186/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.9194 (0.7071) acc 81.2500 (80.7292) lr 3.1417e-05 eta 0:01:13
epoch [186/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.016) loss 0.3970 (0.7194) acc 87.5000 (80.4464) lr 3.1417e-05 eta 0:01:11
epoch [186/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7749 (0.7109) acc 78.1250 (80.7812) lr 3.1417e-05 eta 0:01:09
epoch [186/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.4810 (0.7038) acc 84.3750 (80.9028) lr 3.1417e-05 eta 0:01:07
epoch [186/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5171 (0.7070) acc 93.7500 (81.1250) lr 2.7630e-05 eta 0:01:06
epoch [187/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.097) loss 0.8433 (0.5730) acc 71.8750 (83.7500) lr 2.7630e-05 eta 0:02:07
epoch [187/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.6851 (0.5941) acc 81.2500 (82.8125) lr 2.7630e-05 eta 0:01:32
epoch [187/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.8657 (0.6380) acc 78.1250 (81.6667) lr 2.7630e-05 eta 0:01:20
epoch [187/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 1.0059 (0.6760) acc 68.7500 (80.9375) lr 2.7630e-05 eta 0:01:14
epoch [187/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.8223 (0.6654) acc 81.2500 (81.7500) lr 2.7630e-05 eta 0:01:10
epoch [187/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 1.3213 (0.6923) acc 81.2500 (81.7708) lr 2.7630e-05 eta 0:01:07
epoch [187/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.7896 (0.6990) acc 78.1250 (81.5179) lr 2.7630e-05 eta 0:01:05
epoch [187/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.8608 (0.7124) acc 78.1250 (81.4062) lr 2.7630e-05 eta 0:01:03
epoch [187/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8257 (0.7004) acc 81.2500 (81.5972) lr 2.7630e-05 eta 0:01:02
epoch [187/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8149 (0.6968) acc 81.2500 (81.8750) lr 2.4083e-05 eta 0:01:01
epoch [188/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.096) loss 1.1836 (0.9019) acc 62.5000 (76.2500) lr 2.4083e-05 eta 0:01:57
epoch [188/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.5747 (0.8063) acc 87.5000 (80.3125) lr 2.4083e-05 eta 0:01:25
epoch [188/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.6333 (0.7585) acc 81.2500 (80.4167) lr 2.4083e-05 eta 0:01:14
epoch [188/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.7305 (0.7175) acc 84.3750 (81.5625) lr 2.4083e-05 eta 0:01:08
epoch [188/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.8599 (0.7374) acc 68.7500 (80.5000) lr 2.4083e-05 eta 0:01:04
epoch [188/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.7695 (0.7211) acc 78.1250 (80.3125) lr 2.4083e-05 eta 0:01:02
epoch [188/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4856 (0.7123) acc 93.7500 (80.5357) lr 2.4083e-05 eta 0:01:00
epoch [188/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5459 (0.7123) acc 87.5000 (80.5469) lr 2.4083e-05 eta 0:00:58
epoch [188/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7700 (0.7154) acc 81.2500 (80.1389) lr 2.4083e-05 eta 0:00:57
epoch [188/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5190 (0.6927) acc 84.3750 (80.6875) lr 2.0777e-05 eta 0:00:56
epoch [189/200] batch [5/50] time 0.087 (0.191) data 0.000 (0.106) loss 0.6279 (0.5697) acc 87.5000 (85.0000) lr 2.0777e-05 eta 0:01:53
epoch [189/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.5518 (0.5695) acc 84.3750 (83.4375) lr 2.0777e-05 eta 0:01:21
epoch [189/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.4497 (0.5734) acc 84.3750 (84.1667) lr 2.0777e-05 eta 0:01:10
epoch [189/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.7642 (0.5899) acc 78.1250 (83.5938) lr 2.0777e-05 eta 0:01:04
epoch [189/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.4749 (0.5954) acc 90.6250 (83.5000) lr 2.0777e-05 eta 0:01:00
epoch [189/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.4578 (0.6244) acc 90.6250 (83.1250) lr 2.0777e-05 eta 0:00:58
epoch [189/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.7310 (0.6324) acc 75.0000 (82.8571) lr 2.0777e-05 eta 0:00:56
epoch [189/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.6958 (0.6499) acc 78.1250 (81.9531) lr 2.0777e-05 eta 0:00:54
epoch [189/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1572 (0.6733) acc 71.8750 (81.3889) lr 2.0777e-05 eta 0:00:53
epoch [189/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7310 (0.6785) acc 78.1250 (80.8125) lr 1.7713e-05 eta 0:00:52
epoch [190/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.106) loss 0.6929 (0.6725) acc 87.5000 (81.8750) lr 1.7713e-05 eta 0:01:44
epoch [190/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.6187 (0.6536) acc 84.3750 (81.5625) lr 1.7713e-05 eta 0:01:14
epoch [190/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.3198 (0.6854) acc 93.7500 (80.6250) lr 1.7713e-05 eta 0:01:04
epoch [190/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.7207 (0.6799) acc 84.3750 (82.0312) lr 1.7713e-05 eta 0:00:59
epoch [190/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.7725 (0.6860) acc 81.2500 (81.5000) lr 1.7713e-05 eta 0:00:55
epoch [190/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6338 (0.7037) acc 84.3750 (81.4583) lr 1.7713e-05 eta 0:00:53
epoch [190/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.3552 (0.6971) acc 90.6250 (81.6071) lr 1.7713e-05 eta 0:00:51
epoch [190/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.7168 (0.7060) acc 87.5000 (81.4062) lr 1.7713e-05 eta 0:00:49
epoch [190/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9614 (0.7215) acc 75.0000 (81.5278) lr 1.7713e-05 eta 0:00:48
epoch [190/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9907 (0.7131) acc 84.3750 (82.0000) lr 1.4891e-05 eta 0:00:47
epoch [191/200] batch [5/50] time 0.084 (0.200) data 0.000 (0.115) loss 0.7041 (0.8541) acc 81.2500 (75.6250) lr 1.4891e-05 eta 0:01:39
epoch [191/200] batch [10/50] time 0.084 (0.142) data 0.000 (0.058) loss 0.5796 (0.7028) acc 84.3750 (80.0000) lr 1.4891e-05 eta 0:01:09
epoch [191/200] batch [15/50] time 0.084 (0.123) data 0.000 (0.039) loss 0.5425 (0.6771) acc 87.5000 (80.6250) lr 1.4891e-05 eta 0:00:59
epoch [191/200] batch [20/50] time 0.084 (0.113) data 0.000 (0.029) loss 0.3059 (0.6641) acc 90.6250 (81.0938) lr 1.4891e-05 eta 0:00:54
epoch [191/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.023) loss 0.5645 (0.6632) acc 84.3750 (81.0000) lr 1.4891e-05 eta 0:00:50
epoch [191/200] batch [30/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.7173 (0.6720) acc 81.2500 (80.9375) lr 1.4891e-05 eta 0:00:48
epoch [191/200] batch [35/50] time 0.085 (0.101) data 0.001 (0.017) loss 0.8477 (0.6701) acc 78.1250 (81.1607) lr 1.4891e-05 eta 0:00:46
epoch [191/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.015) loss 1.0127 (0.6545) acc 68.7500 (81.5625) lr 1.4891e-05 eta 0:00:45
epoch [191/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7754 (0.6778) acc 75.0000 (81.1111) lr 1.4891e-05 eta 0:00:44
epoch [191/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.9272 (0.6836) acc 75.0000 (80.9375) lr 1.2312e-05 eta 0:00:43
epoch [192/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.4490 (0.7237) acc 84.3750 (81.8750) lr 1.2312e-05 eta 0:01:22
epoch [192/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.6450 (0.7612) acc 84.3750 (82.1875) lr 1.2312e-05 eta 0:00:59
epoch [192/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.6431 (0.7470) acc 87.5000 (81.8750) lr 1.2312e-05 eta 0:00:51
epoch [192/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.9185 (0.7621) acc 75.0000 (81.2500) lr 1.2312e-05 eta 0:00:47
epoch [192/200] batch [25/50] time 0.086 (0.105) data 0.000 (0.020) loss 0.3584 (0.7033) acc 87.5000 (82.1250) lr 1.2312e-05 eta 0:00:44
epoch [192/200] batch [30/50] time 0.086 (0.102) data 0.000 (0.017) loss 0.6289 (0.7118) acc 75.0000 (81.8750) lr 1.2312e-05 eta 0:00:42
epoch [192/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.5776 (0.7115) acc 84.3750 (81.6071) lr 1.2312e-05 eta 0:00:41
epoch [192/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8779 (0.7210) acc 71.8750 (80.7812) lr 1.2312e-05 eta 0:00:39
epoch [192/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.5015 (0.7273) acc 84.3750 (80.7639) lr 1.2312e-05 eta 0:00:38
epoch [192/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.6763 (0.7099) acc 81.2500 (81.2500) lr 9.9763e-06 eta 0:00:37
epoch [193/200] batch [5/50] time 0.085 (0.181) data 0.000 (0.096) loss 0.8105 (0.8865) acc 78.1250 (77.5000) lr 9.9763e-06 eta 0:01:11
epoch [193/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.5864 (0.8412) acc 87.5000 (78.4375) lr 9.9763e-06 eta 0:00:51
epoch [193/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 1.0195 (0.7937) acc 71.8750 (79.3750) lr 9.9763e-06 eta 0:00:44
epoch [193/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.8989 (0.7384) acc 78.1250 (81.2500) lr 9.9763e-06 eta 0:00:41
epoch [193/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.6948 (0.7187) acc 75.0000 (81.6250) lr 9.9763e-06 eta 0:00:39
epoch [193/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.4128 (0.7030) acc 84.3750 (81.7708) lr 9.9763e-06 eta 0:00:37
epoch [193/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.014) loss 0.5088 (0.6979) acc 84.3750 (81.8750) lr 9.9763e-06 eta 0:00:35
epoch [193/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.5103 (0.6738) acc 84.3750 (82.1875) lr 9.9763e-06 eta 0:00:34
epoch [193/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8184 (0.6721) acc 78.1250 (82.5000) lr 9.9763e-06 eta 0:00:33
epoch [193/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9541 (0.6743) acc 65.6250 (82.1875) lr 7.8853e-06 eta 0:00:32
epoch [194/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.106) loss 1.0137 (0.5974) acc 75.0000 (84.3750) lr 7.8853e-06 eta 0:01:05
epoch [194/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.5410 (0.6926) acc 81.2500 (80.9375) lr 7.8853e-06 eta 0:00:46
epoch [194/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.8740 (0.6896) acc 81.2500 (81.6667) lr 7.8853e-06 eta 0:00:40
epoch [194/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.8525 (0.6700) acc 81.2500 (82.3438) lr 7.8853e-06 eta 0:00:36
epoch [194/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.7354 (0.6910) acc 84.3750 (81.2500) lr 7.8853e-06 eta 0:00:34
epoch [194/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6450 (0.6910) acc 84.3750 (81.8750) lr 7.8853e-06 eta 0:00:32
epoch [194/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.4617 (0.6817) acc 84.3750 (82.1429) lr 7.8853e-06 eta 0:00:31
epoch [194/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.5498 (0.7052) acc 84.3750 (81.0938) lr 7.8853e-06 eta 0:00:30
epoch [194/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.3801 (0.6845) acc 87.5000 (81.3889) lr 7.8853e-06 eta 0:00:29
epoch [194/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4304 (0.6794) acc 90.6250 (81.6875) lr 6.0390e-06 eta 0:00:28
epoch [195/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.094) loss 0.9453 (0.6321) acc 68.7500 (81.8750) lr 6.0390e-06 eta 0:00:53
epoch [195/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.5332 (0.6683) acc 87.5000 (83.4375) lr 6.0390e-06 eta 0:00:38
epoch [195/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.031) loss 0.5620 (0.6306) acc 78.1250 (83.9583) lr 6.0390e-06 eta 0:00:33
epoch [195/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.4668 (0.6500) acc 90.6250 (82.8125) lr 6.0390e-06 eta 0:00:30
epoch [195/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.7305 (0.6289) acc 84.3750 (83.3750) lr 6.0390e-06 eta 0:00:28
epoch [195/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.6372 (0.6175) acc 78.1250 (83.1250) lr 6.0390e-06 eta 0:00:27
epoch [195/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.3770 (0.5993) acc 87.5000 (83.6607) lr 6.0390e-06 eta 0:00:26
epoch [195/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.8896 (0.5965) acc 75.0000 (83.4375) lr 6.0390e-06 eta 0:00:25
epoch [195/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6387 (0.5993) acc 84.3750 (83.3333) lr 6.0390e-06 eta 0:00:24
epoch [195/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0273 (0.6117) acc 81.2500 (82.9375) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.100) loss 0.3340 (0.6807) acc 84.3750 (80.6250) lr 4.4380e-06 eta 0:00:45
epoch [196/200] batch [10/50] time 0.083 (0.134) data 0.000 (0.050) loss 0.6821 (0.6892) acc 81.2500 (81.2500) lr 4.4380e-06 eta 0:00:32
epoch [196/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.034) loss 0.9507 (0.7334) acc 81.2500 (80.4167) lr 4.4380e-06 eta 0:00:27
epoch [196/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 0.7017 (0.7374) acc 78.1250 (79.3750) lr 4.4380e-06 eta 0:00:25
epoch [196/200] batch [25/50] time 0.083 (0.104) data 0.000 (0.020) loss 0.4302 (0.7386) acc 87.5000 (79.2500) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.7314 (0.7304) acc 75.0000 (79.4792) lr 4.4380e-06 eta 0:00:22
epoch [196/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.015) loss 0.9297 (0.7033) acc 81.2500 (80.5357) lr 4.4380e-06 eta 0:00:21
epoch [196/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 0.9600 (0.7073) acc 75.0000 (81.0156) lr 4.4380e-06 eta 0:00:20
epoch [196/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6577 (0.7042) acc 81.2500 (81.0417) lr 4.4380e-06 eta 0:00:19
epoch [196/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9409 (0.6946) acc 81.2500 (81.2500) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [5/50] time 0.084 (0.197) data 0.000 (0.112) loss 0.9424 (0.7975) acc 84.3750 (80.6250) lr 3.0827e-06 eta 0:00:38
epoch [197/200] batch [10/50] time 0.084 (0.141) data 0.000 (0.056) loss 0.3918 (0.7131) acc 93.7500 (82.1875) lr 3.0827e-06 eta 0:00:26
epoch [197/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.037) loss 0.5078 (0.6907) acc 84.3750 (82.0833) lr 3.0827e-06 eta 0:00:22
epoch [197/200] batch [20/50] time 0.084 (0.113) data 0.000 (0.028) loss 0.2786 (0.6270) acc 93.7500 (83.7500) lr 3.0827e-06 eta 0:00:20
epoch [197/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.7305 (0.6404) acc 81.2500 (83.5000) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.6504 (0.6523) acc 81.2500 (82.6042) lr 3.0827e-06 eta 0:00:17
epoch [197/200] batch [35/50] time 0.085 (0.101) data 0.001 (0.016) loss 0.5044 (0.6851) acc 84.3750 (81.7857) lr 3.0827e-06 eta 0:00:16
epoch [197/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.8115 (0.6828) acc 87.5000 (82.1094) lr 3.0827e-06 eta 0:00:15
epoch [197/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6616 (0.6953) acc 78.1250 (81.5278) lr 3.0827e-06 eta 0:00:15
epoch [197/200] batch [50/50] time 0.084 (0.096) data 0.001 (0.011) loss 0.6416 (0.6965) acc 87.5000 (81.3125) lr 1.9733e-06 eta 0:00:14
epoch [198/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.106) loss 1.0391 (0.7731) acc 68.7500 (77.5000) lr 1.9733e-06 eta 0:00:27
epoch [198/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.6797 (0.7175) acc 81.2500 (81.2500) lr 1.9733e-06 eta 0:00:19
epoch [198/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.6992 (0.6915) acc 78.1250 (82.0833) lr 1.9733e-06 eta 0:00:16
epoch [198/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.5894 (0.6343) acc 81.2500 (83.2812) lr 1.9733e-06 eta 0:00:14
epoch [198/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.5259 (0.6206) acc 87.5000 (83.2500) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6104 (0.6017) acc 84.3750 (83.6458) lr 1.9733e-06 eta 0:00:12
epoch [198/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.015) loss 0.8496 (0.6238) acc 78.1250 (82.9464) lr 1.9733e-06 eta 0:00:11
epoch [198/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9990 (0.6534) acc 71.8750 (82.5000) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5996 (0.6555) acc 87.5000 (82.4306) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.2563 (0.6433) acc 93.7500 (83.0000) lr 1.1101e-06 eta 0:00:09
epoch [199/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.099) loss 0.5747 (0.9335) acc 78.1250 (73.1250) lr 1.1101e-06 eta 0:00:17
epoch [199/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 1.0967 (0.8928) acc 78.1250 (77.1875) lr 1.1101e-06 eta 0:00:12
epoch [199/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.7017 (0.8716) acc 78.1250 (77.2917) lr 1.1101e-06 eta 0:00:10
epoch [199/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.8052 (0.8265) acc 81.2500 (78.9062) lr 1.1101e-06 eta 0:00:08
epoch [199/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.6255 (0.7999) acc 78.1250 (79.1250) lr 1.1101e-06 eta 0:00:07
epoch [199/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8447 (0.7791) acc 75.0000 (79.3750) lr 1.1101e-06 eta 0:00:07
epoch [199/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.7012 (0.7603) acc 84.3750 (79.8214) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9795 (0.7450) acc 71.8750 (79.9219) lr 1.1101e-06 eta 0:00:05
epoch [199/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1221 (0.7541) acc 68.7500 (79.4444) lr 1.1101e-06 eta 0:00:05
epoch [199/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.0020 (0.7469) acc 78.1250 (79.6250) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.103) loss 0.4456 (0.7542) acc 87.5000 (79.3750) lr 4.9344e-07 eta 0:00:08
epoch [200/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 0.5000 (0.7162) acc 87.5000 (80.3125) lr 4.9344e-07 eta 0:00:05
epoch [200/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.034) loss 0.7744 (0.6835) acc 81.2500 (82.2917) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [20/50] time 0.086 (0.111) data 0.000 (0.026) loss 0.5332 (0.6455) acc 78.1250 (82.8125) lr 4.9344e-07 eta 0:00:03
epoch [200/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.7144 (0.6511) acc 81.2500 (82.6250) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.4736 (0.6571) acc 84.3750 (82.3958) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.2295 (0.6435) acc 93.7500 (82.5000) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 1.0137 (0.6947) acc 75.0000 (81.4062) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8389 (0.7060) acc 71.8750 (80.9722) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.9292 (0.6957) acc 75.0000 (81.1875) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:01<00:56,  1.52s/it]  5%|▌         | 2/38 [00:01<00:26,  1.37it/s]  8%|▊         | 3/38 [00:01<00:15,  2.22it/s] 11%|█         | 4/38 [00:01<00:10,  3.11it/s] 13%|█▎        | 5/38 [00:02<00:08,  4.01it/s] 16%|█▌        | 6/38 [00:02<00:06,  4.84it/s] 18%|█▊        | 7/38 [00:02<00:05,  5.30it/s] 21%|██        | 8/38 [00:02<00:05,  5.98it/s] 24%|██▎       | 9/38 [00:02<00:04,  6.52it/s] 26%|██▋       | 10/38 [00:02<00:04,  6.96it/s] 29%|██▉       | 11/38 [00:02<00:03,  7.30it/s] 32%|███▏      | 12/38 [00:02<00:03,  7.55it/s] 34%|███▍      | 13/38 [00:03<00:03,  7.72it/s] 37%|███▋      | 14/38 [00:03<00:03,  7.85it/s] 39%|███▉      | 15/38 [00:03<00:03,  7.43it/s] 42%|████▏     | 16/38 [00:03<00:02,  7.64it/s] 45%|████▍     | 17/38 [00:03<00:02,  7.79it/s] 47%|████▋     | 18/38 [00:03<00:02,  7.90it/s] 50%|█████     | 19/38 [00:03<00:02,  7.29it/s] 53%|█████▎    | 20/38 [00:03<00:02,  7.55it/s] 55%|█████▌    | 21/38 [00:04<00:02,  7.73it/s] 58%|█████▊    | 22/38 [00:04<00:02,  7.86it/s] 61%|██████    | 23/38 [00:04<00:01,  7.95it/s] 63%|██████▎   | 24/38 [00:04<00:01,  8.02it/s] 66%|██████▌   | 25/38 [00:04<00:01,  7.67it/s] 68%|██████▊   | 26/38 [00:04<00:01,  7.83it/s] 71%|███████   | 27/38 [00:04<00:01,  7.95it/s] 74%|███████▎  | 28/38 [00:04<00:01,  8.04it/s] 76%|███████▋  | 29/38 [00:05<00:01,  8.10it/s] 79%|███████▉  | 30/38 [00:05<00:00,  8.14it/s] 82%|████████▏ | 31/38 [00:05<00:00,  8.18it/s] 84%|████████▍ | 32/38 [00:05<00:00,  8.20it/s] 87%|████████▋ | 33/38 [00:05<00:00,  8.22it/s] 89%|████████▉ | 34/38 [00:05<00:00,  8.23it/s] 92%|█████████▏| 35/38 [00:05<00:00,  8.23it/s] 95%|█████████▍| 36/38 [00:05<00:00,  8.23it/s] 97%|█████████▋| 37/38 [00:06<00:00,  8.23it/s]100%|██████████| 38/38 [00:06<00:00,  8.58it/s]100%|██████████| 38/38 [00:06<00:00,  6.04it/s]
=> result
* total: 3,783
* correct: 3,119
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 81.5%
Elapsed: 0:16:18
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_train.sh ucf101 3 0 vit_b16_ctxv1 16 CoOp
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_3.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/200] batch [5/50] time 0.084 (0.556) data 0.000 (0.154) loss 1.2188 (1.8059) acc 62.5000 (53.7500) lr 1.0000e-05 eta 1:32:39
epoch [1/200] batch [10/50] time 0.084 (0.320) data 0.000 (0.077) loss 1.7344 (1.8012) acc 53.1250 (54.0625) lr 1.0000e-05 eta 0:53:17
epoch [1/200] batch [15/50] time 0.084 (0.241) data 0.000 (0.052) loss 1.4941 (1.7840) acc 62.5000 (53.9583) lr 1.0000e-05 eta 0:40:10
epoch [1/200] batch [20/50] time 0.085 (0.202) data 0.000 (0.039) loss 2.0723 (1.7917) acc 43.7500 (53.1250) lr 1.0000e-05 eta 0:33:36
epoch [1/200] batch [25/50] time 0.084 (0.179) data 0.000 (0.031) loss 1.4941 (1.7737) acc 56.2500 (53.8750) lr 1.0000e-05 eta 0:29:40
epoch [1/200] batch [30/50] time 0.084 (0.163) data 0.000 (0.026) loss 1.8613 (1.7821) acc 46.8750 (53.4375) lr 1.0000e-05 eta 0:27:03
epoch [1/200] batch [35/50] time 0.084 (0.152) data 0.001 (0.022) loss 2.3945 (1.7861) acc 34.3750 (53.3036) lr 1.0000e-05 eta 0:25:10
epoch [1/200] batch [40/50] time 0.082 (0.143) data 0.000 (0.020) loss 2.2207 (1.7988) acc 43.7500 (52.3438) lr 1.0000e-05 eta 0:23:44
epoch [1/200] batch [45/50] time 0.083 (0.136) data 0.000 (0.017) loss 1.8408 (1.8160) acc 56.2500 (52.3611) lr 1.0000e-05 eta 0:22:37
epoch [1/200] batch [50/50] time 0.083 (0.131) data 0.000 (0.016) loss 2.2109 (1.7955) acc 43.7500 (52.8125) lr 2.0000e-03 eta 0:21:43
epoch [2/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 2.3633 (1.7531) acc 40.6250 (49.3750) lr 2.0000e-03 eta 0:31:27
epoch [2/200] batch [10/50] time 0.083 (0.137) data 0.000 (0.053) loss 1.1523 (1.5189) acc 59.3750 (57.1875) lr 2.0000e-03 eta 0:22:37
epoch [2/200] batch [15/50] time 0.083 (0.119) data 0.000 (0.035) loss 0.9487 (1.5185) acc 75.0000 (60.0000) lr 2.0000e-03 eta 0:19:42
epoch [2/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.026) loss 1.8828 (1.5266) acc 53.1250 (59.3750) lr 2.0000e-03 eta 0:18:14
epoch [2/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.5830 (1.5160) acc 65.6250 (60.3750) lr 2.0000e-03 eta 0:17:19
epoch [2/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.018) loss 1.7832 (1.4694) acc 62.5000 (61.7708) lr 2.0000e-03 eta 0:16:44
epoch [2/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.8389 (1.4685) acc 75.0000 (61.7857) lr 2.0000e-03 eta 0:16:20
epoch [2/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 2.1484 (1.4827) acc 50.0000 (61.3281) lr 2.0000e-03 eta 0:16:00
epoch [2/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 1.2148 (1.4682) acc 65.6250 (61.6667) lr 2.0000e-03 eta 0:15:44
epoch [2/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.5146 (1.4758) acc 62.5000 (61.3750) lr 1.9999e-03 eta 0:15:31
epoch [3/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 0.9438 (1.1940) acc 75.0000 (65.6250) lr 1.9999e-03 eta 0:31:16
epoch [3/200] batch [10/50] time 0.083 (0.137) data 0.000 (0.053) loss 1.3701 (1.2609) acc 59.3750 (64.6875) lr 1.9999e-03 eta 0:22:33
epoch [3/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 1.7061 (1.2689) acc 59.3750 (65.0000) lr 1.9999e-03 eta 0:19:39
epoch [3/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.9155 (1.2328) acc 75.0000 (65.0000) lr 1.9999e-03 eta 0:18:12
epoch [3/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.5479 (1.2805) acc 62.5000 (63.8750) lr 1.9999e-03 eta 0:17:20
epoch [3/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.2021 (1.2626) acc 71.8750 (64.7917) lr 1.9999e-03 eta 0:16:44
epoch [3/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.2676 (1.2846) acc 62.5000 (64.1964) lr 1.9999e-03 eta 0:16:19
epoch [3/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.1719 (1.3384) acc 65.6250 (63.0469) lr 1.9999e-03 eta 0:15:59
epoch [3/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0410 (1.3187) acc 71.8750 (63.8194) lr 1.9999e-03 eta 0:15:43
epoch [3/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.1191 (1.3112) acc 68.7500 (63.7500) lr 1.9995e-03 eta 0:15:30
epoch [4/200] batch [5/50] time 0.083 (0.181) data 0.000 (0.097) loss 1.1680 (1.2132) acc 71.8750 (67.5000) lr 1.9995e-03 eta 0:29:41
epoch [4/200] batch [10/50] time 0.083 (0.132) data 0.000 (0.049) loss 1.6084 (1.3133) acc 59.3750 (65.3125) lr 1.9995e-03 eta 0:21:41
epoch [4/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.033) loss 1.3818 (1.3290) acc 59.3750 (64.1667) lr 1.9995e-03 eta 0:19:00
epoch [4/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.8237 (1.2985) acc 68.7500 (63.4375) lr 1.9995e-03 eta 0:17:41
epoch [4/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.020) loss 1.4551 (1.3001) acc 68.7500 (63.7500) lr 1.9995e-03 eta 0:16:53
epoch [4/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.2607 (1.2873) acc 71.8750 (64.2708) lr 1.9995e-03 eta 0:16:22
epoch [4/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.6631 (1.3171) acc 50.0000 (63.0357) lr 1.9995e-03 eta 0:15:59
epoch [4/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.3711 (1.3210) acc 56.2500 (63.2812) lr 1.9995e-03 eta 0:15:40
epoch [4/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.8188 (1.3028) acc 68.7500 (63.6111) lr 1.9995e-03 eta 0:15:26
epoch [4/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 1.6680 (1.3214) acc 68.7500 (63.4375) lr 1.9989e-03 eta 0:15:14
epoch [5/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.100) loss 1.1348 (1.3341) acc 68.7500 (62.5000) lr 1.9989e-03 eta 0:30:00
epoch [5/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 1.7656 (1.3165) acc 56.2500 (63.7500) lr 1.9989e-03 eta 0:21:50
epoch [5/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 1.2705 (1.3118) acc 65.6250 (63.9583) lr 1.9989e-03 eta 0:19:06
epoch [5/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.8481 (1.3098) acc 68.7500 (63.9062) lr 1.9989e-03 eta 0:17:44
epoch [5/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.9775 (1.2821) acc 65.6250 (64.3750) lr 1.9989e-03 eta 0:16:55
epoch [5/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.4727 (1.3007) acc 65.6250 (64.0625) lr 1.9989e-03 eta 0:16:22
epoch [5/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.0732 (1.2942) acc 62.5000 (64.1964) lr 1.9989e-03 eta 0:16:00
epoch [5/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 1.3906 (1.2925) acc 53.1250 (64.2188) lr 1.9989e-03 eta 0:15:41
epoch [5/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.5430 (1.2820) acc 53.1250 (64.0972) lr 1.9989e-03 eta 0:15:26
epoch [5/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.3027 (1.2614) acc 65.6250 (64.8750) lr 1.9980e-03 eta 0:15:14
epoch [6/200] batch [5/50] time 0.083 (0.176) data 0.000 (0.092) loss 1.4453 (1.1084) acc 56.2500 (68.7500) lr 1.9980e-03 eta 0:28:36
epoch [6/200] batch [10/50] time 0.085 (0.130) data 0.000 (0.046) loss 1.0762 (1.2185) acc 78.1250 (65.6250) lr 1.9980e-03 eta 0:21:08
epoch [6/200] batch [15/50] time 0.084 (0.115) data 0.000 (0.031) loss 1.3232 (1.1634) acc 68.7500 (67.2917) lr 1.9980e-03 eta 0:18:35
epoch [6/200] batch [20/50] time 0.083 (0.107) data 0.000 (0.023) loss 1.4453 (1.1935) acc 56.2500 (66.5625) lr 1.9980e-03 eta 0:17:19
epoch [6/200] batch [25/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.2510 (1.2111) acc 59.3750 (66.5000) lr 1.9980e-03 eta 0:16:32
epoch [6/200] batch [30/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.8008 (1.2424) acc 78.1250 (65.7292) lr 1.9980e-03 eta 0:16:02
epoch [6/200] batch [35/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.2012 (1.2566) acc 71.8750 (65.5357) lr 1.9980e-03 eta 0:15:41
epoch [6/200] batch [40/50] time 0.084 (0.095) data 0.001 (0.012) loss 1.5205 (1.2717) acc 56.2500 (64.8438) lr 1.9980e-03 eta 0:15:24
epoch [6/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8926 (1.2578) acc 78.1250 (65.0694) lr 1.9980e-03 eta 0:15:10
epoch [6/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.009) loss 1.3740 (1.2532) acc 62.5000 (65.0625) lr 1.9969e-03 eta 0:14:59
epoch [7/200] batch [5/50] time 0.083 (0.178) data 0.000 (0.093) loss 2.0117 (1.4270) acc 37.5000 (58.1250) lr 1.9969e-03 eta 0:28:50
epoch [7/200] batch [10/50] time 0.084 (0.131) data 0.000 (0.047) loss 1.0938 (1.3361) acc 62.5000 (60.3125) lr 1.9969e-03 eta 0:21:12
epoch [7/200] batch [15/50] time 0.083 (0.115) data 0.000 (0.031) loss 0.8452 (1.1903) acc 71.8750 (65.0000) lr 1.9969e-03 eta 0:18:36
epoch [7/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 1.3506 (1.1573) acc 65.6250 (66.2500) lr 1.9969e-03 eta 0:17:21
epoch [7/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 1.3906 (1.1489) acc 59.3750 (66.2500) lr 1.9969e-03 eta 0:16:34
epoch [7/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 1.1328 (1.1643) acc 75.0000 (66.6667) lr 1.9969e-03 eta 0:16:03
epoch [7/200] batch [35/50] time 0.084 (0.097) data 0.000 (0.014) loss 0.9775 (1.1800) acc 71.8750 (66.3393) lr 1.9969e-03 eta 0:15:41
epoch [7/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9829 (1.1698) acc 75.0000 (66.7188) lr 1.9969e-03 eta 0:15:23
epoch [7/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.3496 (1.1566) acc 65.6250 (66.7361) lr 1.9969e-03 eta 0:15:09
epoch [7/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 1.2656 (1.1593) acc 65.6250 (66.8125) lr 1.9956e-03 eta 0:14:58
epoch [8/200] batch [5/50] time 0.083 (0.178) data 0.000 (0.093) loss 0.9751 (1.0916) acc 68.7500 (68.1250) lr 1.9956e-03 eta 0:28:39
epoch [8/200] batch [10/50] time 0.084 (0.131) data 0.000 (0.047) loss 1.2178 (1.1556) acc 62.5000 (67.8125) lr 1.9956e-03 eta 0:21:03
epoch [8/200] batch [15/50] time 0.084 (0.115) data 0.000 (0.031) loss 1.1992 (1.1537) acc 71.8750 (67.9167) lr 1.9956e-03 eta 0:18:30
epoch [8/200] batch [20/50] time 0.083 (0.107) data 0.000 (0.024) loss 0.9629 (1.1517) acc 78.1250 (68.4375) lr 1.9956e-03 eta 0:17:14
epoch [8/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.9648 (1.1085) acc 62.5000 (68.8750) lr 1.9956e-03 eta 0:16:28
epoch [8/200] batch [30/50] time 0.083 (0.099) data 0.000 (0.016) loss 1.2549 (1.1129) acc 71.8750 (68.8542) lr 1.9956e-03 eta 0:15:56
epoch [8/200] batch [35/50] time 0.084 (0.097) data 0.000 (0.014) loss 1.0244 (1.1189) acc 68.7500 (68.7500) lr 1.9956e-03 eta 0:15:34
epoch [8/200] batch [40/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.8667 (1.1148) acc 65.6250 (68.5938) lr 1.9956e-03 eta 0:15:17
epoch [8/200] batch [45/50] time 0.084 (0.094) data 0.000 (0.011) loss 1.0762 (1.1195) acc 78.1250 (68.4722) lr 1.9956e-03 eta 0:15:03
epoch [8/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.9272 (1.1087) acc 75.0000 (68.6250) lr 1.9940e-03 eta 0:14:52
epoch [9/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.107) loss 0.7383 (0.9466) acc 81.2500 (72.5000) lr 1.9940e-03 eta 0:30:45
epoch [9/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 1.0586 (1.0198) acc 71.8750 (72.5000) lr 1.9940e-03 eta 0:22:06
epoch [9/200] batch [15/50] time 0.086 (0.120) data 0.000 (0.036) loss 1.0420 (1.0405) acc 75.0000 (72.2917) lr 1.9940e-03 eta 0:19:14
epoch [9/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 1.1504 (1.0263) acc 81.2500 (72.9688) lr 1.9940e-03 eta 0:17:48
epoch [9/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 1.1055 (1.0442) acc 65.6250 (72.0000) lr 1.9940e-03 eta 0:16:55
epoch [9/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.7456 (1.0245) acc 75.0000 (71.5625) lr 1.9940e-03 eta 0:16:20
epoch [9/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6460 (1.0266) acc 75.0000 (70.8036) lr 1.9940e-03 eta 0:15:54
epoch [9/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.0186 (1.0298) acc 65.6250 (70.7031) lr 1.9940e-03 eta 0:15:34
epoch [9/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.3691 (1.0500) acc 59.3750 (69.7917) lr 1.9940e-03 eta 0:15:18
epoch [9/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2480 (1.0750) acc 56.2500 (69.1250) lr 1.9921e-03 eta 0:15:06
epoch [10/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.098) loss 0.7944 (0.9479) acc 78.1250 (75.0000) lr 1.9921e-03 eta 0:29:10
epoch [10/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 1.3906 (1.0460) acc 56.2500 (69.0625) lr 1.9921e-03 eta 0:21:17
epoch [10/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 1.4307 (1.1033) acc 56.2500 (67.9167) lr 1.9921e-03 eta 0:18:38
epoch [10/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.9712 (1.1026) acc 75.0000 (68.5938) lr 1.9921e-03 eta 0:17:19
epoch [10/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7432 (1.0669) acc 81.2500 (69.5000) lr 1.9921e-03 eta 0:16:32
epoch [10/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 1.2070 (1.0671) acc 65.6250 (69.5833) lr 1.9921e-03 eta 0:16:00
epoch [10/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 1.2275 (1.0815) acc 65.6250 (68.7500) lr 1.9921e-03 eta 0:15:37
epoch [10/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0947 (1.0732) acc 65.6250 (69.2969) lr 1.9921e-03 eta 0:15:19
epoch [10/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0957 (1.0736) acc 71.8750 (69.3056) lr 1.9921e-03 eta 0:15:05
epoch [10/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9409 (1.0802) acc 78.1250 (69.0625) lr 1.9900e-03 eta 0:14:53
epoch [11/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.109) loss 0.9321 (1.0628) acc 75.0000 (69.3750) lr 1.9900e-03 eta 0:30:36
epoch [11/200] batch [10/50] time 0.083 (0.139) data 0.000 (0.055) loss 0.8799 (1.0921) acc 71.8750 (67.5000) lr 1.9900e-03 eta 0:21:56
epoch [11/200] batch [15/50] time 0.086 (0.120) data 0.000 (0.037) loss 1.1582 (1.0937) acc 65.6250 (67.5000) lr 1.9900e-03 eta 0:19:02
epoch [11/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.028) loss 1.2832 (1.0708) acc 62.5000 (68.1250) lr 1.9900e-03 eta 0:17:35
epoch [11/200] batch [25/50] time 0.086 (0.106) data 0.000 (0.022) loss 1.2666 (1.0797) acc 50.0000 (67.5000) lr 1.9900e-03 eta 0:16:43
epoch [11/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6475 (1.0517) acc 81.2500 (68.5417) lr 1.9900e-03 eta 0:16:10
epoch [11/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.3262 (1.0493) acc 65.6250 (68.5714) lr 1.9900e-03 eta 0:15:44
epoch [11/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9453 (1.0539) acc 75.0000 (68.8281) lr 1.9900e-03 eta 0:15:24
epoch [11/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.2754 (1.0745) acc 62.5000 (68.6111) lr 1.9900e-03 eta 0:15:09
epoch [11/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.1670 (1.0579) acc 65.6250 (69.0625) lr 1.9877e-03 eta 0:14:56
epoch [12/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 0.7856 (0.8671) acc 78.1250 (76.2500) lr 1.9877e-03 eta 0:29:47
epoch [12/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 1.2510 (0.9862) acc 62.5000 (71.5625) lr 1.9877e-03 eta 0:21:31
epoch [12/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 1.2920 (0.9966) acc 59.3750 (71.6667) lr 1.9877e-03 eta 0:18:47
epoch [12/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 1.1367 (1.0084) acc 65.6250 (71.0938) lr 1.9877e-03 eta 0:17:24
epoch [12/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.7192 (1.0200) acc 84.3750 (70.6250) lr 1.9877e-03 eta 0:16:34
epoch [12/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.7822 (1.0121) acc 78.1250 (71.3542) lr 1.9877e-03 eta 0:16:00
epoch [12/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.0264 (1.0576) acc 71.8750 (70.6250) lr 1.9877e-03 eta 0:15:36
epoch [12/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.0156 (1.0413) acc 71.8750 (70.8594) lr 1.9877e-03 eta 0:15:16
epoch [12/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.1846 (1.0447) acc 62.5000 (70.6944) lr 1.9877e-03 eta 0:15:01
epoch [12/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0684 (1.0550) acc 65.6250 (70.5625) lr 1.9851e-03 eta 0:14:49
epoch [13/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.107) loss 0.9419 (0.8486) acc 75.0000 (77.5000) lr 1.9851e-03 eta 0:30:00
epoch [13/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 1.2500 (0.9996) acc 68.7500 (74.3750) lr 1.9851e-03 eta 0:21:35
epoch [13/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.5879 (1.1049) acc 62.5000 (72.5000) lr 1.9851e-03 eta 0:18:45
epoch [13/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 1.0479 (1.1073) acc 71.8750 (71.2500) lr 1.9851e-03 eta 0:17:23
epoch [13/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 1.3115 (1.1377) acc 65.6250 (70.2500) lr 1.9851e-03 eta 0:16:32
epoch [13/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.8745 (1.1171) acc 78.1250 (70.7292) lr 1.9851e-03 eta 0:15:58
epoch [13/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5244 (1.0773) acc 87.5000 (71.0714) lr 1.9851e-03 eta 0:15:34
epoch [13/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9722 (1.0743) acc 71.8750 (71.2500) lr 1.9851e-03 eta 0:15:14
epoch [13/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8701 (1.0671) acc 75.0000 (71.0417) lr 1.9851e-03 eta 0:14:58
epoch [13/200] batch [50/50] time 0.086 (0.095) data 0.000 (0.011) loss 1.1367 (1.0606) acc 68.7500 (71.4375) lr 1.9823e-03 eta 0:14:47
epoch [14/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.103) loss 1.3018 (0.9800) acc 59.3750 (71.8750) lr 1.9823e-03 eta 0:29:16
epoch [14/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.052) loss 0.6616 (0.8716) acc 87.5000 (76.2500) lr 1.9823e-03 eta 0:21:10
epoch [14/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.8774 (0.8914) acc 71.8750 (74.5833) lr 1.9823e-03 eta 0:18:29
epoch [14/200] batch [20/50] time 0.086 (0.110) data 0.000 (0.026) loss 1.1445 (0.8991) acc 62.5000 (73.1250) lr 1.9823e-03 eta 0:17:08
epoch [14/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.3232 (0.9435) acc 65.6250 (72.0000) lr 1.9823e-03 eta 0:16:20
epoch [14/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.8359 (0.9349) acc 75.0000 (72.7083) lr 1.9823e-03 eta 0:15:47
epoch [14/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.1846 (0.9450) acc 65.6250 (72.9464) lr 1.9823e-03 eta 0:15:23
epoch [14/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.2168 (0.9533) acc 59.3750 (72.6562) lr 1.9823e-03 eta 0:15:04
epoch [14/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8057 (0.9387) acc 71.8750 (72.9167) lr 1.9823e-03 eta 0:14:49
epoch [14/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.4990 (0.9613) acc 62.5000 (72.6875) lr 1.9792e-03 eta 0:14:37
epoch [15/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.105) loss 0.8120 (0.7958) acc 81.2500 (81.2500) lr 1.9792e-03 eta 0:29:33
epoch [15/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.3645 (0.8678) acc 90.6250 (77.8125) lr 1.9792e-03 eta 0:21:18
epoch [15/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.8350 (0.9368) acc 71.8750 (75.2083) lr 1.9792e-03 eta 0:18:32
epoch [15/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.7251 (0.9771) acc 81.2500 (73.1250) lr 1.9792e-03 eta 0:17:11
epoch [15/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 1.2832 (0.9946) acc 59.3750 (72.2500) lr 1.9792e-03 eta 0:16:20
epoch [15/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.4736 (1.0201) acc 65.6250 (71.4583) lr 1.9792e-03 eta 0:15:47
epoch [15/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 1.0791 (1.0560) acc 71.8750 (70.8036) lr 1.9792e-03 eta 0:15:23
epoch [15/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.8623 (1.0507) acc 87.5000 (71.2500) lr 1.9792e-03 eta 0:15:03
epoch [15/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1006 (1.0613) acc 75.0000 (70.9028) lr 1.9792e-03 eta 0:14:48
epoch [15/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8970 (1.0625) acc 75.0000 (71.3125) lr 1.9759e-03 eta 0:14:36
epoch [16/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.4614 (0.7508) acc 84.3750 (77.5000) lr 1.9759e-03 eta 0:27:53
epoch [16/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 1.3164 (0.9905) acc 68.7500 (72.1875) lr 1.9759e-03 eta 0:20:26
epoch [16/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 0.8730 (0.9809) acc 71.8750 (72.9167) lr 1.9759e-03 eta 0:17:55
epoch [16/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.7544 (0.9683) acc 81.2500 (73.7500) lr 1.9759e-03 eta 0:16:39
epoch [16/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.6538 (0.9353) acc 84.3750 (74.6250) lr 1.9759e-03 eta 0:15:55
epoch [16/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.2373 (0.9708) acc 78.1250 (73.7500) lr 1.9759e-03 eta 0:15:24
epoch [16/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.8154 (0.9670) acc 75.0000 (73.7500) lr 1.9759e-03 eta 0:15:03
epoch [16/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.9087 (0.9962) acc 75.0000 (73.2812) lr 1.9759e-03 eta 0:14:46
epoch [16/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2500 (1.0008) acc 68.7500 (73.1944) lr 1.9759e-03 eta 0:14:32
epoch [16/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9028 (1.0129) acc 75.0000 (73.0625) lr 1.9724e-03 eta 0:14:21
epoch [17/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 0.9243 (0.9680) acc 71.8750 (72.5000) lr 1.9724e-03 eta 0:27:55
epoch [17/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 1.1670 (0.9822) acc 65.6250 (72.1875) lr 1.9724e-03 eta 0:20:26
epoch [17/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.7681 (1.0425) acc 75.0000 (70.8333) lr 1.9724e-03 eta 0:17:55
epoch [17/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 1.2354 (1.0190) acc 71.8750 (71.2500) lr 1.9724e-03 eta 0:16:41
epoch [17/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.9429 (1.0049) acc 78.1250 (72.3750) lr 1.9724e-03 eta 0:15:55
epoch [17/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.7769 (0.9911) acc 81.2500 (73.0208) lr 1.9724e-03 eta 0:15:24
epoch [17/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 0.6958 (1.0081) acc 78.1250 (72.2321) lr 1.9724e-03 eta 0:15:03
epoch [17/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0879 (1.0253) acc 71.8750 (71.8750) lr 1.9724e-03 eta 0:14:45
epoch [17/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5562 (0.9906) acc 87.5000 (72.7778) lr 1.9724e-03 eta 0:14:31
epoch [17/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.7031 (0.9911) acc 59.3750 (72.6875) lr 1.9686e-03 eta 0:14:20
epoch [18/200] batch [5/50] time 0.083 (0.192) data 0.000 (0.108) loss 0.8086 (0.8555) acc 84.3750 (75.0000) lr 1.9686e-03 eta 0:29:12
epoch [18/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.054) loss 1.1973 (0.8429) acc 65.6250 (75.3125) lr 1.9686e-03 eta 0:21:00
epoch [18/200] batch [15/50] time 0.083 (0.120) data 0.000 (0.036) loss 0.7632 (0.8840) acc 81.2500 (75.8333) lr 1.9686e-03 eta 0:18:14
epoch [18/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 1.2715 (0.9035) acc 68.7500 (73.9062) lr 1.9686e-03 eta 0:16:52
epoch [18/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 1.4824 (0.9572) acc 53.1250 (72.6250) lr 1.9686e-03 eta 0:16:03
epoch [18/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6387 (0.9553) acc 81.2500 (72.3958) lr 1.9686e-03 eta 0:15:30
epoch [18/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7725 (0.9906) acc 84.3750 (72.1429) lr 1.9686e-03 eta 0:15:06
epoch [18/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 1.0215 (1.0059) acc 75.0000 (72.1094) lr 1.9686e-03 eta 0:14:47
epoch [18/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.5449 (1.0108) acc 56.2500 (71.7361) lr 1.9686e-03 eta 0:14:32
epoch [18/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0029 (1.0101) acc 71.8750 (71.9375) lr 1.9646e-03 eta 0:14:20
epoch [19/200] batch [5/50] time 0.083 (0.177) data 0.000 (0.093) loss 1.0459 (0.8757) acc 71.8750 (74.3750) lr 1.9646e-03 eta 0:26:53
epoch [19/200] batch [10/50] time 0.084 (0.131) data 0.000 (0.046) loss 1.0244 (1.0086) acc 75.0000 (72.5000) lr 1.9646e-03 eta 0:19:49
epoch [19/200] batch [15/50] time 0.084 (0.115) data 0.000 (0.031) loss 1.1260 (0.9823) acc 62.5000 (72.7083) lr 1.9646e-03 eta 0:17:25
epoch [19/200] batch [20/50] time 0.083 (0.107) data 0.000 (0.023) loss 1.2158 (0.9848) acc 62.5000 (72.1875) lr 1.9646e-03 eta 0:16:15
epoch [19/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 1.0371 (0.9914) acc 71.8750 (72.1250) lr 1.9646e-03 eta 0:15:32
epoch [19/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 1.0449 (0.9954) acc 68.7500 (72.3958) lr 1.9646e-03 eta 0:15:03
epoch [19/200] batch [35/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.9878 (0.9847) acc 75.0000 (72.7679) lr 1.9646e-03 eta 0:14:43
epoch [19/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7310 (0.9797) acc 75.0000 (72.6562) lr 1.9646e-03 eta 0:14:26
epoch [19/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.6211 (0.9903) acc 53.1250 (72.2917) lr 1.9646e-03 eta 0:14:14
epoch [19/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.009) loss 1.2080 (0.9908) acc 65.6250 (72.1250) lr 1.9603e-03 eta 0:14:03
epoch [20/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.109) loss 1.0273 (0.7129) acc 71.8750 (79.3750) lr 1.9603e-03 eta 0:29:16
epoch [20/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.055) loss 0.8867 (0.8132) acc 68.7500 (76.2500) lr 1.9603e-03 eta 0:21:00
epoch [20/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 1.0352 (0.8710) acc 75.0000 (76.2500) lr 1.9603e-03 eta 0:18:14
epoch [20/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.6001 (0.9082) acc 75.0000 (74.8438) lr 1.9603e-03 eta 0:16:50
epoch [20/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.8384 (0.9350) acc 75.0000 (73.8750) lr 1.9603e-03 eta 0:16:01
epoch [20/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 1.0557 (0.9565) acc 68.7500 (73.4375) lr 1.9603e-03 eta 0:15:27
epoch [20/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.4551 (0.9532) acc 90.6250 (73.6607) lr 1.9603e-03 eta 0:15:03
epoch [20/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9326 (0.9605) acc 65.6250 (72.8906) lr 1.9603e-03 eta 0:14:44
epoch [20/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1348 (0.9732) acc 65.6250 (72.4306) lr 1.9603e-03 eta 0:14:28
epoch [20/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.4414 (1.0050) acc 56.2500 (71.7500) lr 1.9558e-03 eta 0:14:16
epoch [21/200] batch [5/50] time 0.085 (0.180) data 0.000 (0.095) loss 1.1465 (0.8674) acc 71.8750 (79.3750) lr 1.9558e-03 eta 0:27:03
epoch [21/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.048) loss 0.6714 (0.8803) acc 87.5000 (77.5000) lr 1.9558e-03 eta 0:19:51
epoch [21/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 1.5918 (0.8781) acc 59.3750 (77.5000) lr 1.9558e-03 eta 0:17:26
epoch [21/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.9600 (0.8610) acc 75.0000 (77.1875) lr 1.9558e-03 eta 0:16:14
epoch [21/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.9019 (0.8885) acc 84.3750 (76.2500) lr 1.9558e-03 eta 0:15:30
epoch [21/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.1670 (0.9250) acc 71.8750 (75.6250) lr 1.9558e-03 eta 0:15:00
epoch [21/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7339 (0.9487) acc 78.1250 (74.3750) lr 1.9558e-03 eta 0:14:39
epoch [21/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.2100 (0.9737) acc 71.8750 (73.9062) lr 1.9558e-03 eta 0:14:22
epoch [21/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7627 (0.9752) acc 81.2500 (74.0278) lr 1.9558e-03 eta 0:14:08
epoch [21/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.1445 (0.9765) acc 62.5000 (73.6250) lr 1.9511e-03 eta 0:13:57
epoch [22/200] batch [5/50] time 0.084 (0.177) data 0.000 (0.093) loss 1.2549 (0.9849) acc 71.8750 (74.3750) lr 1.9511e-03 eta 0:26:26
epoch [22/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.046) loss 0.8022 (0.8781) acc 78.1250 (76.8750) lr 1.9511e-03 eta 0:19:29
epoch [22/200] batch [15/50] time 0.083 (0.115) data 0.000 (0.031) loss 1.1611 (0.9426) acc 75.0000 (74.7917) lr 1.9511e-03 eta 0:17:07
epoch [22/200] batch [20/50] time 0.084 (0.107) data 0.000 (0.023) loss 1.0176 (0.9399) acc 78.1250 (75.4688) lr 1.9511e-03 eta 0:15:58
epoch [22/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.8857 (0.9090) acc 81.2500 (75.8750) lr 1.9511e-03 eta 0:15:15
epoch [22/200] batch [30/50] time 0.083 (0.099) data 0.000 (0.016) loss 0.7114 (0.8988) acc 78.1250 (75.9375) lr 1.9511e-03 eta 0:14:46
epoch [22/200] batch [35/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.6406 (0.9115) acc 71.8750 (75.4464) lr 1.9511e-03 eta 0:14:26
epoch [22/200] batch [40/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.9341 (0.9353) acc 71.8750 (75.2344) lr 1.9511e-03 eta 0:14:10
epoch [22/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8086 (0.9396) acc 71.8750 (74.7222) lr 1.9511e-03 eta 0:13:57
epoch [22/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.009) loss 0.8970 (0.9497) acc 75.0000 (74.5625) lr 1.9461e-03 eta 0:13:47
epoch [23/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.109) loss 0.8486 (1.0140) acc 81.2500 (73.7500) lr 1.9461e-03 eta 0:28:47
epoch [23/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.054) loss 0.7373 (0.9519) acc 81.2500 (74.0625) lr 1.9461e-03 eta 0:20:41
epoch [23/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.4788 (0.9454) acc 87.5000 (74.7917) lr 1.9461e-03 eta 0:17:58
epoch [23/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.9111 (0.9457) acc 75.0000 (73.5938) lr 1.9461e-03 eta 0:16:36
epoch [23/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.6006 (0.9015) acc 87.5000 (75.1250) lr 1.9461e-03 eta 0:15:47
epoch [23/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 1.1465 (0.9240) acc 71.8750 (74.3750) lr 1.9461e-03 eta 0:15:13
epoch [23/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.6782 (0.9137) acc 78.1250 (74.2857) lr 1.9461e-03 eta 0:14:49
epoch [23/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.6787 (0.9178) acc 81.2500 (74.4531) lr 1.9461e-03 eta 0:14:30
epoch [23/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.5806 (0.9002) acc 84.3750 (74.7917) lr 1.9461e-03 eta 0:14:15
epoch [23/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1396 (0.8929) acc 56.2500 (74.7500) lr 1.9409e-03 eta 0:14:03
epoch [24/200] batch [5/50] time 0.084 (0.179) data 0.000 (0.094) loss 1.1768 (1.0146) acc 65.6250 (69.3750) lr 1.9409e-03 eta 0:26:25
epoch [24/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.047) loss 0.8911 (0.9189) acc 81.2500 (75.3125) lr 1.9409e-03 eta 0:19:26
epoch [24/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.032) loss 0.9136 (0.9538) acc 75.0000 (74.7917) lr 1.9409e-03 eta 0:17:06
epoch [24/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.5254 (0.8961) acc 81.2500 (75.9375) lr 1.9409e-03 eta 0:15:57
epoch [24/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.9526 (0.8875) acc 78.1250 (76.0000) lr 1.9409e-03 eta 0:15:15
epoch [24/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 1.1611 (0.8944) acc 71.8750 (76.0417) lr 1.9409e-03 eta 0:14:46
epoch [24/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.6865 (0.9003) acc 62.5000 (75.7143) lr 1.9409e-03 eta 0:14:25
epoch [24/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.4141 (0.9163) acc 59.3750 (75.0000) lr 1.9409e-03 eta 0:14:08
epoch [24/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8979 (0.9215) acc 71.8750 (74.5833) lr 1.9409e-03 eta 0:13:55
epoch [24/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9160 (0.9317) acc 59.3750 (74.1875) lr 1.9354e-03 eta 0:13:44
epoch [25/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 0.8604 (0.9178) acc 75.0000 (73.7500) lr 1.9354e-03 eta 0:27:41
epoch [25/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 1.1865 (0.9131) acc 62.5000 (74.6875) lr 1.9354e-03 eta 0:20:02
epoch [25/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.9751 (0.9140) acc 75.0000 (75.0000) lr 1.9354e-03 eta 0:17:29
epoch [25/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.7998 (0.9212) acc 75.0000 (74.8438) lr 1.9354e-03 eta 0:16:12
epoch [25/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.1543 (0.9233) acc 65.6250 (74.8750) lr 1.9354e-03 eta 0:15:25
epoch [25/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.8779 (0.9213) acc 75.0000 (74.6875) lr 1.9354e-03 eta 0:14:54
epoch [25/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.8608 (0.9272) acc 71.8750 (74.4643) lr 1.9354e-03 eta 0:14:32
epoch [25/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9775 (0.9384) acc 75.0000 (74.0625) lr 1.9354e-03 eta 0:14:13
epoch [25/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8330 (0.9388) acc 68.7500 (74.2361) lr 1.9354e-03 eta 0:13:59
epoch [25/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0166 (0.9404) acc 75.0000 (74.0625) lr 1.9298e-03 eta 0:13:48
epoch [26/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.110) loss 0.5972 (0.8243) acc 87.5000 (81.8750) lr 1.9298e-03 eta 0:28:20
epoch [26/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.055) loss 1.3965 (0.9091) acc 65.6250 (78.1250) lr 1.9298e-03 eta 0:20:18
epoch [26/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 1.1719 (0.9714) acc 68.7500 (75.0000) lr 1.9298e-03 eta 0:17:37
epoch [26/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.9561 (0.9874) acc 71.8750 (74.3750) lr 1.9298e-03 eta 0:16:17
epoch [26/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.6328 (0.9303) acc 84.3750 (74.8750) lr 1.9298e-03 eta 0:15:28
epoch [26/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.8218 (0.9400) acc 81.2500 (74.6875) lr 1.9298e-03 eta 0:14:56
epoch [26/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7563 (0.9263) acc 78.1250 (75.0893) lr 1.9298e-03 eta 0:14:32
epoch [26/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9834 (0.9165) acc 68.7500 (74.9219) lr 1.9298e-03 eta 0:14:13
epoch [26/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8555 (0.9174) acc 71.8750 (74.9306) lr 1.9298e-03 eta 0:13:59
epoch [26/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9497 (0.9230) acc 65.6250 (74.3125) lr 1.9239e-03 eta 0:13:47
epoch [27/200] batch [5/50] time 0.083 (0.183) data 0.000 (0.098) loss 1.5645 (1.0586) acc 62.5000 (69.3750) lr 1.9239e-03 eta 0:26:29
epoch [27/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.8701 (0.9237) acc 71.8750 (72.8125) lr 1.9239e-03 eta 0:19:16
epoch [27/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.9932 (0.9278) acc 75.0000 (72.5000) lr 1.9239e-03 eta 0:16:54
epoch [27/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.2930 (0.9238) acc 59.3750 (72.1875) lr 1.9239e-03 eta 0:15:43
epoch [27/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7827 (0.9197) acc 84.3750 (73.2500) lr 1.9239e-03 eta 0:15:00
epoch [27/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6729 (0.8868) acc 81.2500 (74.3750) lr 1.9239e-03 eta 0:14:31
epoch [27/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.0303 (0.8772) acc 62.5000 (74.8214) lr 1.9239e-03 eta 0:14:11
epoch [27/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9673 (0.9002) acc 75.0000 (74.8438) lr 1.9239e-03 eta 0:13:54
epoch [27/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8970 (0.9011) acc 75.0000 (74.8611) lr 1.9239e-03 eta 0:13:41
epoch [27/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0205 (0.9090) acc 68.7500 (74.6875) lr 1.9178e-03 eta 0:13:30
epoch [28/200] batch [5/50] time 0.086 (0.188) data 0.000 (0.102) loss 0.9175 (0.9240) acc 75.0000 (72.5000) lr 1.9178e-03 eta 0:27:08
epoch [28/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 1.0693 (0.8888) acc 65.6250 (73.4375) lr 1.9178e-03 eta 0:19:39
epoch [28/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 1.0117 (0.9008) acc 78.1250 (74.7917) lr 1.9178e-03 eta 0:17:09
epoch [28/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.7773 (0.9156) acc 81.2500 (74.8438) lr 1.9178e-03 eta 0:15:53
epoch [28/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.7090 (0.8733) acc 71.8750 (75.7500) lr 1.9178e-03 eta 0:15:08
epoch [28/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.1348 (0.8602) acc 65.6250 (76.4583) lr 1.9178e-03 eta 0:14:37
epoch [28/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.8560 (0.8732) acc 78.1250 (76.0714) lr 1.9178e-03 eta 0:14:15
epoch [28/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.5073 (0.8713) acc 75.0000 (75.6250) lr 1.9178e-03 eta 0:13:58
epoch [28/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0195 (0.8951) acc 71.8750 (74.7917) lr 1.9178e-03 eta 0:13:44
epoch [28/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.7471 (0.9061) acc 78.1250 (74.3750) lr 1.9114e-03 eta 0:13:34
epoch [29/200] batch [5/50] time 0.086 (0.192) data 0.000 (0.106) loss 0.9839 (0.9389) acc 81.2500 (76.2500) lr 1.9114e-03 eta 0:27:31
epoch [29/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 1.3135 (0.9390) acc 59.3750 (73.7500) lr 1.9114e-03 eta 0:19:47
epoch [29/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.0469 (0.8979) acc 68.7500 (75.6250) lr 1.9114e-03 eta 0:17:13
epoch [29/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.7056 (0.9266) acc 71.8750 (73.5938) lr 1.9114e-03 eta 0:15:55
epoch [29/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.5796 (0.9249) acc 81.2500 (73.7500) lr 1.9114e-03 eta 0:15:07
epoch [29/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.5869 (0.9061) acc 84.3750 (74.3750) lr 1.9114e-03 eta 0:14:36
epoch [29/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.015) loss 1.1621 (0.9448) acc 65.6250 (73.2143) lr 1.9114e-03 eta 0:14:13
epoch [29/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7271 (0.9531) acc 78.1250 (73.0469) lr 1.9114e-03 eta 0:13:56
epoch [29/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5566 (0.9398) acc 78.1250 (73.1944) lr 1.9114e-03 eta 0:13:41
epoch [29/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2559 (0.9317) acc 62.5000 (73.3125) lr 1.9048e-03 eta 0:13:30
epoch [30/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 1.5449 (1.0162) acc 62.5000 (73.7500) lr 1.9048e-03 eta 0:25:45
epoch [30/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.9136 (0.9703) acc 78.1250 (75.6250) lr 1.9048e-03 eta 0:18:53
epoch [30/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 1.5840 (0.9523) acc 50.0000 (74.1667) lr 1.9048e-03 eta 0:16:35
epoch [30/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.8950 (0.9537) acc 81.2500 (74.0625) lr 1.9048e-03 eta 0:15:25
epoch [30/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.7534 (0.9576) acc 75.0000 (74.0000) lr 1.9048e-03 eta 0:14:44
epoch [30/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.8110 (0.9436) acc 75.0000 (73.9583) lr 1.9048e-03 eta 0:14:16
epoch [30/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8247 (0.9399) acc 81.2500 (74.1071) lr 1.9048e-03 eta 0:13:56
epoch [30/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6250 (0.9230) acc 81.2500 (74.1406) lr 1.9048e-03 eta 0:13:40
epoch [30/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8320 (0.9223) acc 81.2500 (74.1667) lr 1.9048e-03 eta 0:13:27
epoch [30/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9961 (0.9204) acc 78.1250 (74.4375) lr 1.8980e-03 eta 0:13:17
epoch [31/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 0.7637 (0.7760) acc 75.0000 (76.2500) lr 1.8980e-03 eta 0:25:26
epoch [31/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.047) loss 0.7812 (0.8325) acc 75.0000 (75.9375) lr 1.8980e-03 eta 0:18:40
epoch [31/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.032) loss 0.6636 (0.7994) acc 84.3750 (77.2917) lr 1.8980e-03 eta 0:16:23
epoch [31/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 1.2041 (0.8286) acc 68.7500 (75.6250) lr 1.8980e-03 eta 0:15:16
epoch [31/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.6577 (0.8071) acc 81.2500 (76.3750) lr 1.8980e-03 eta 0:14:35
epoch [31/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5615 (0.8130) acc 87.5000 (76.2500) lr 1.8980e-03 eta 0:14:08
epoch [31/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 1.3535 (0.8475) acc 68.7500 (75.9821) lr 1.8980e-03 eta 0:13:48
epoch [31/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8740 (0.8645) acc 81.2500 (76.0156) lr 1.8980e-03 eta 0:13:32
epoch [31/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8940 (0.8967) acc 71.8750 (75.1389) lr 1.8980e-03 eta 0:13:19
epoch [31/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.7158 (0.8929) acc 75.0000 (75.2500) lr 1.8910e-03 eta 0:13:09
epoch [32/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 1.2939 (0.8979) acc 65.6250 (73.7500) lr 1.8910e-03 eta 0:26:21
epoch [32/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.7178 (0.8838) acc 81.2500 (75.9375) lr 1.8910e-03 eta 0:19:07
epoch [32/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.6650 (0.8378) acc 87.5000 (78.1250) lr 1.8910e-03 eta 0:16:42
epoch [32/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 1.0723 (0.8572) acc 68.7500 (77.1875) lr 1.8910e-03 eta 0:15:30
epoch [32/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.7241 (0.8451) acc 78.1250 (77.1250) lr 1.8910e-03 eta 0:14:46
epoch [32/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 1.2129 (0.8417) acc 68.7500 (77.6042) lr 1.8910e-03 eta 0:14:17
epoch [32/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.7627 (0.8309) acc 81.2500 (77.3214) lr 1.8910e-03 eta 0:13:56
epoch [32/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9248 (0.8548) acc 75.0000 (76.5625) lr 1.8910e-03 eta 0:13:39
epoch [32/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.2285 (0.8761) acc 65.6250 (75.8333) lr 1.8910e-03 eta 0:13:26
epoch [32/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.8281 (0.8774) acc 81.2500 (75.7500) lr 1.8838e-03 eta 0:13:15
epoch [33/200] batch [5/50] time 0.084 (0.193) data 0.000 (0.108) loss 0.6885 (0.8298) acc 78.1250 (78.7500) lr 1.8838e-03 eta 0:27:02
epoch [33/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.9971 (0.8246) acc 71.8750 (77.5000) lr 1.8838e-03 eta 0:19:22
epoch [33/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.4858 (0.7855) acc 84.3750 (77.5000) lr 1.8838e-03 eta 0:16:50
epoch [33/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 1.2812 (0.8461) acc 71.8750 (77.0312) lr 1.8838e-03 eta 0:15:34
epoch [33/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.9058 (0.8700) acc 71.8750 (76.6250) lr 1.8838e-03 eta 0:14:47
epoch [33/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.9336 (0.8906) acc 68.7500 (76.0417) lr 1.8838e-03 eta 0:14:16
epoch [33/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.0840 (0.9010) acc 71.8750 (75.8036) lr 1.8838e-03 eta 0:13:54
epoch [33/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9326 (0.9095) acc 75.0000 (75.0781) lr 1.8838e-03 eta 0:13:37
epoch [33/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8105 (0.8938) acc 81.2500 (75.7639) lr 1.8838e-03 eta 0:13:23
epoch [33/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2324 (0.9053) acc 68.7500 (75.5625) lr 1.8763e-03 eta 0:13:12
epoch [34/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.105) loss 0.5518 (0.8054) acc 81.2500 (78.1250) lr 1.8763e-03 eta 0:26:24
epoch [34/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.5127 (0.8656) acc 84.3750 (75.3125) lr 1.8763e-03 eta 0:19:03
epoch [34/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 1.0195 (0.9216) acc 68.7500 (74.1667) lr 1.8763e-03 eta 0:16:35
epoch [34/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.5527 (0.8771) acc 84.3750 (75.0000) lr 1.8763e-03 eta 0:15:21
epoch [34/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.7075 (0.8702) acc 78.1250 (74.6250) lr 1.8763e-03 eta 0:14:36
epoch [34/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.2080 (0.8669) acc 68.7500 (75.2083) lr 1.8763e-03 eta 0:14:06
epoch [34/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.4609 (0.9295) acc 59.3750 (74.0179) lr 1.8763e-03 eta 0:13:45
epoch [34/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7056 (0.9072) acc 81.2500 (74.5312) lr 1.8763e-03 eta 0:13:28
epoch [34/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6411 (0.9025) acc 75.0000 (74.9306) lr 1.8763e-03 eta 0:13:15
epoch [34/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.6914 (0.8752) acc 75.0000 (75.8125) lr 1.8686e-03 eta 0:13:04
epoch [35/200] batch [5/50] time 0.083 (0.178) data 0.000 (0.093) loss 0.7520 (1.0114) acc 62.5000 (67.5000) lr 1.8686e-03 eta 0:24:36
epoch [35/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.8794 (0.9378) acc 78.1250 (71.5625) lr 1.8686e-03 eta 0:18:08
epoch [35/200] batch [15/50] time 0.084 (0.115) data 0.000 (0.031) loss 0.9595 (0.9766) acc 75.0000 (71.8750) lr 1.8686e-03 eta 0:15:56
epoch [35/200] batch [20/50] time 0.083 (0.108) data 0.000 (0.023) loss 0.6328 (0.9878) acc 78.1250 (72.0312) lr 1.8686e-03 eta 0:14:50
epoch [35/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.6860 (0.9276) acc 78.1250 (74.1250) lr 1.8686e-03 eta 0:14:10
epoch [35/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.0078 (0.9459) acc 78.1250 (73.5417) lr 1.8686e-03 eta 0:13:44
epoch [35/200] batch [35/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.9712 (0.9618) acc 75.0000 (73.0357) lr 1.8686e-03 eta 0:13:25
epoch [35/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6465 (0.9423) acc 87.5000 (73.5938) lr 1.8686e-03 eta 0:13:10
epoch [35/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.7549 (0.9053) acc 78.1250 (74.6528) lr 1.8686e-03 eta 0:12:59
epoch [35/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.009) loss 1.5928 (0.9155) acc 65.6250 (74.6875) lr 1.8607e-03 eta 0:12:49
epoch [36/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.094) loss 1.0791 (0.9898) acc 71.8750 (76.2500) lr 1.8607e-03 eta 0:24:40
epoch [36/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.5352 (0.8755) acc 93.7500 (78.1250) lr 1.8607e-03 eta 0:18:08
epoch [36/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.031) loss 0.6069 (0.8789) acc 81.2500 (77.5000) lr 1.8607e-03 eta 0:15:57
epoch [36/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 1.0430 (0.8812) acc 65.6250 (76.0938) lr 1.8607e-03 eta 0:14:52
epoch [36/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 1.1328 (0.8786) acc 71.8750 (76.7500) lr 1.8607e-03 eta 0:14:13
epoch [36/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 1.0830 (0.8929) acc 59.3750 (75.9375) lr 1.8607e-03 eta 0:13:46
epoch [36/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9751 (0.8660) acc 65.6250 (75.9821) lr 1.8607e-03 eta 0:13:27
epoch [36/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.2158 (0.8764) acc 75.0000 (75.7812) lr 1.8607e-03 eta 0:13:12
epoch [36/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8735 (0.8691) acc 75.0000 (75.9722) lr 1.8607e-03 eta 0:12:59
epoch [36/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9126 (0.8684) acc 75.0000 (76.0000) lr 1.8526e-03 eta 0:12:49
epoch [37/200] batch [5/50] time 0.083 (0.190) data 0.000 (0.105) loss 1.4189 (0.8920) acc 71.8750 (80.0000) lr 1.8526e-03 eta 0:25:55
epoch [37/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.053) loss 0.8154 (0.9273) acc 84.3750 (77.5000) lr 1.8526e-03 eta 0:18:40
epoch [37/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.9541 (0.9237) acc 62.5000 (76.6667) lr 1.8526e-03 eta 0:16:16
epoch [37/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.8252 (0.8695) acc 71.8750 (77.0312) lr 1.8526e-03 eta 0:15:04
epoch [37/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8232 (0.8753) acc 81.2500 (77.0000) lr 1.8526e-03 eta 0:14:19
epoch [37/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6216 (0.8601) acc 84.3750 (77.5000) lr 1.8526e-03 eta 0:13:51
epoch [37/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6826 (0.8664) acc 81.2500 (77.2321) lr 1.8526e-03 eta 0:13:30
epoch [37/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9331 (0.8666) acc 75.0000 (77.0312) lr 1.8526e-03 eta 0:13:13
epoch [37/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6836 (0.8907) acc 81.2500 (76.3194) lr 1.8526e-03 eta 0:13:00
epoch [37/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.0840 (0.8877) acc 68.7500 (76.1250) lr 1.8443e-03 eta 0:12:49
epoch [38/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 0.7510 (0.7849) acc 75.0000 (77.5000) lr 1.8443e-03 eta 0:25:24
epoch [38/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.2966 (0.7365) acc 96.8750 (79.6875) lr 1.8443e-03 eta 0:18:24
epoch [38/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 1.6406 (0.7870) acc 53.1250 (78.5417) lr 1.8443e-03 eta 0:16:06
epoch [38/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 1.6387 (0.8796) acc 65.6250 (77.3438) lr 1.8443e-03 eta 0:14:55
epoch [38/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.1240 (0.8927) acc 65.6250 (76.3750) lr 1.8443e-03 eta 0:14:13
epoch [38/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.8540 (0.8971) acc 78.1250 (76.3542) lr 1.8443e-03 eta 0:13:45
epoch [38/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.8306 (0.8865) acc 81.2500 (76.9643) lr 1.8443e-03 eta 0:13:24
epoch [38/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9653 (0.8922) acc 68.7500 (76.4844) lr 1.8443e-03 eta 0:13:08
epoch [38/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0098 (0.8800) acc 62.5000 (76.3194) lr 1.8443e-03 eta 0:12:55
epoch [38/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 0.9883 (0.9186) acc 71.8750 (75.5625) lr 1.8358e-03 eta 0:12:45
epoch [39/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 1.0020 (0.7251) acc 75.0000 (80.0000) lr 1.8358e-03 eta 0:24:24
epoch [39/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.8516 (0.7507) acc 68.7500 (79.3750) lr 1.8358e-03 eta 0:17:53
epoch [39/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 1.4053 (0.8311) acc 62.5000 (77.0833) lr 1.8358e-03 eta 0:15:42
epoch [39/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.9092 (0.8331) acc 68.7500 (76.5625) lr 1.8358e-03 eta 0:14:37
epoch [39/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.7529 (0.8003) acc 84.3750 (78.0000) lr 1.8358e-03 eta 0:13:57
epoch [39/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.9336 (0.8154) acc 68.7500 (77.3958) lr 1.8358e-03 eta 0:13:31
epoch [39/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.7441 (0.8279) acc 78.1250 (77.3214) lr 1.8358e-03 eta 0:13:12
epoch [39/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8140 (0.8518) acc 78.1250 (76.7188) lr 1.8358e-03 eta 0:12:57
epoch [39/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.1670 (0.8516) acc 59.3750 (76.6667) lr 1.8358e-03 eta 0:12:45
epoch [39/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9819 (0.8410) acc 75.0000 (76.9375) lr 1.8271e-03 eta 0:12:35
epoch [40/200] batch [5/50] time 0.085 (0.196) data 0.000 (0.110) loss 0.6401 (1.0155) acc 78.1250 (74.3750) lr 1.8271e-03 eta 0:26:18
epoch [40/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.8872 (0.9191) acc 81.2500 (77.1875) lr 1.8271e-03 eta 0:18:48
epoch [40/200] batch [15/50] time 0.084 (0.122) data 0.000 (0.037) loss 0.7051 (0.9125) acc 81.2500 (76.0417) lr 1.8271e-03 eta 0:16:18
epoch [40/200] batch [20/50] time 0.085 (0.113) data 0.000 (0.028) loss 0.9023 (0.9549) acc 75.0000 (75.3125) lr 1.8271e-03 eta 0:15:03
epoch [40/200] batch [25/50] time 0.086 (0.107) data 0.000 (0.022) loss 1.2422 (0.9446) acc 65.6250 (75.2500) lr 1.8271e-03 eta 0:14:18
epoch [40/200] batch [30/50] time 0.086 (0.103) data 0.000 (0.019) loss 0.6030 (0.9133) acc 78.1250 (75.8333) lr 1.8271e-03 eta 0:13:48
epoch [40/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.9727 (0.9306) acc 75.0000 (75.4464) lr 1.8271e-03 eta 0:13:26
epoch [40/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.4900 (0.9077) acc 93.7500 (75.8594) lr 1.8271e-03 eta 0:13:09
epoch [40/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.2402 (0.9059) acc 62.5000 (75.6944) lr 1.8271e-03 eta 0:12:55
epoch [40/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.9424 (0.9019) acc 78.1250 (76.1250) lr 1.8181e-03 eta 0:12:44
epoch [41/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.102) loss 0.8354 (0.6882) acc 75.0000 (81.8750) lr 1.8181e-03 eta 0:25:08
epoch [41/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.051) loss 0.4817 (0.6875) acc 87.5000 (80.9375) lr 1.8181e-03 eta 0:18:12
epoch [41/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.4590 (0.6658) acc 84.3750 (81.8750) lr 1.8181e-03 eta 0:15:53
epoch [41/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.5293 (0.7107) acc 84.3750 (80.1562) lr 1.8181e-03 eta 0:14:44
epoch [41/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 1.1992 (0.7758) acc 68.7500 (78.7500) lr 1.8181e-03 eta 0:14:02
epoch [41/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.9033 (0.7926) acc 68.7500 (77.7083) lr 1.8181e-03 eta 0:13:34
epoch [41/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.7231 (0.8091) acc 81.2500 (77.4107) lr 1.8181e-03 eta 0:13:13
epoch [41/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.3120 (0.8056) acc 84.3750 (77.1094) lr 1.8181e-03 eta 0:12:56
epoch [41/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9121 (0.8124) acc 71.8750 (76.8056) lr 1.8181e-03 eta 0:12:44
epoch [41/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.7920 (0.8195) acc 84.3750 (76.6250) lr 1.8090e-03 eta 0:12:33
epoch [42/200] batch [5/50] time 0.083 (0.185) data 0.000 (0.099) loss 0.5889 (0.7533) acc 78.1250 (80.0000) lr 1.8090e-03 eta 0:24:27
epoch [42/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.8047 (0.8278) acc 75.0000 (76.2500) lr 1.8090e-03 eta 0:17:47
epoch [42/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 1.3936 (0.9293) acc 65.6250 (74.7917) lr 1.8090e-03 eta 0:15:31
epoch [42/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 0.8320 (0.8609) acc 75.0000 (76.7188) lr 1.8090e-03 eta 0:14:23
epoch [42/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.0117 (0.8821) acc 71.8750 (76.0000) lr 1.8090e-03 eta 0:13:43
epoch [42/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.0449 (0.9079) acc 71.8750 (75.5208) lr 1.8090e-03 eta 0:13:16
epoch [42/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7002 (0.8781) acc 71.8750 (75.8036) lr 1.8090e-03 eta 0:12:57
epoch [42/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 1.3604 (0.8945) acc 56.2500 (75.1562) lr 1.8090e-03 eta 0:12:42
epoch [42/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8379 (0.8918) acc 68.7500 (74.9306) lr 1.8090e-03 eta 0:12:30
epoch [42/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9937 (0.9054) acc 68.7500 (74.5000) lr 1.7997e-03 eta 0:12:21
epoch [43/200] batch [5/50] time 0.083 (0.184) data 0.000 (0.099) loss 0.5825 (0.9444) acc 81.2500 (71.2500) lr 1.7997e-03 eta 0:24:09
epoch [43/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 0.6064 (0.9887) acc 81.2500 (72.1875) lr 1.7997e-03 eta 0:17:35
epoch [43/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 1.0430 (0.9543) acc 75.0000 (73.3333) lr 1.7997e-03 eta 0:15:23
epoch [43/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.2705 (0.9442) acc 71.8750 (74.3750) lr 1.7997e-03 eta 0:14:17
epoch [43/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.0635 (0.9404) acc 71.8750 (73.8750) lr 1.7997e-03 eta 0:13:38
epoch [43/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9028 (0.9363) acc 78.1250 (73.9583) lr 1.7997e-03 eta 0:13:11
epoch [43/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.0088 (0.9185) acc 65.6250 (73.9286) lr 1.7997e-03 eta 0:12:53
epoch [43/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 1.2266 (0.9220) acc 78.1250 (74.1406) lr 1.7997e-03 eta 0:12:38
epoch [43/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6177 (0.9000) acc 90.6250 (75.2083) lr 1.7997e-03 eta 0:12:26
epoch [43/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8018 (0.9143) acc 78.1250 (75.0625) lr 1.7902e-03 eta 0:12:16
epoch [44/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 0.8267 (0.8820) acc 81.2500 (75.6250) lr 1.7902e-03 eta 0:24:48
epoch [44/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.4333 (0.7318) acc 87.5000 (80.9375) lr 1.7902e-03 eta 0:17:54
epoch [44/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 1.0674 (0.7539) acc 59.3750 (79.7917) lr 1.7902e-03 eta 0:15:36
epoch [44/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.9072 (0.8156) acc 84.3750 (79.3750) lr 1.7902e-03 eta 0:14:27
epoch [44/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.7144 (0.8291) acc 78.1250 (79.1250) lr 1.7902e-03 eta 0:13:45
epoch [44/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.0439 (0.8557) acc 68.7500 (78.0208) lr 1.7902e-03 eta 0:13:17
epoch [44/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.7632 (0.8327) acc 78.1250 (77.8571) lr 1.7902e-03 eta 0:12:57
epoch [44/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6587 (0.8258) acc 81.2500 (77.8125) lr 1.7902e-03 eta 0:12:41
epoch [44/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9326 (0.8244) acc 65.6250 (77.9167) lr 1.7902e-03 eta 0:12:28
epoch [44/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7998 (0.8164) acc 78.1250 (77.6875) lr 1.7804e-03 eta 0:12:18
epoch [45/200] batch [5/50] time 0.083 (0.188) data 0.000 (0.103) loss 0.8638 (0.8536) acc 84.3750 (76.8750) lr 1.7804e-03 eta 0:24:22
epoch [45/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.052) loss 0.5947 (0.8444) acc 78.1250 (77.1875) lr 1.7804e-03 eta 0:17:39
epoch [45/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.9751 (0.8884) acc 68.7500 (75.4167) lr 1.7804e-03 eta 0:15:24
epoch [45/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.9863 (0.8695) acc 68.7500 (75.7812) lr 1.7804e-03 eta 0:14:17
epoch [45/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 1.0918 (0.8786) acc 62.5000 (75.7500) lr 1.7804e-03 eta 0:13:36
epoch [45/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.6265 (0.8703) acc 84.3750 (76.1458) lr 1.7804e-03 eta 0:13:09
epoch [45/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.9653 (0.8762) acc 78.1250 (76.1607) lr 1.7804e-03 eta 0:12:50
epoch [45/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7485 (0.8525) acc 75.0000 (76.7969) lr 1.7804e-03 eta 0:12:34
epoch [45/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0703 (0.8563) acc 71.8750 (76.3889) lr 1.7804e-03 eta 0:12:21
epoch [45/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.1123 (0.8569) acc 81.2500 (76.8125) lr 1.7705e-03 eta 0:12:11
epoch [46/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.099) loss 0.7168 (0.8392) acc 81.2500 (78.1250) lr 1.7705e-03 eta 0:23:39
epoch [46/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.050) loss 0.8706 (0.8296) acc 75.0000 (77.1875) lr 1.7705e-03 eta 0:17:16
epoch [46/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.7417 (0.7998) acc 81.2500 (77.9167) lr 1.7705e-03 eta 0:15:08
epoch [46/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.1328 (0.8156) acc 68.7500 (77.0312) lr 1.7705e-03 eta 0:14:03
epoch [46/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.0234 (0.8148) acc 71.8750 (77.2500) lr 1.7705e-03 eta 0:13:24
epoch [46/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.1240 (0.8449) acc 65.6250 (76.4583) lr 1.7705e-03 eta 0:12:58
epoch [46/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7383 (0.8431) acc 78.1250 (76.6964) lr 1.7705e-03 eta 0:12:39
epoch [46/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7163 (0.8346) acc 81.2500 (76.7188) lr 1.7705e-03 eta 0:12:24
epoch [46/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0234 (0.8503) acc 71.8750 (76.1806) lr 1.7705e-03 eta 0:12:13
epoch [46/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.2217 (0.8631) acc 56.2500 (75.6250) lr 1.7604e-03 eta 0:12:04
epoch [47/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.105) loss 0.6035 (0.6937) acc 87.5000 (83.1250) lr 1.7604e-03 eta 0:24:26
epoch [47/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 1.1152 (0.8534) acc 78.1250 (79.0625) lr 1.7604e-03 eta 0:17:38
epoch [47/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.6821 (0.8222) acc 81.2500 (79.5833) lr 1.7604e-03 eta 0:15:21
epoch [47/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.8149 (0.8007) acc 75.0000 (79.8438) lr 1.7604e-03 eta 0:14:12
epoch [47/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.5269 (0.8048) acc 81.2500 (78.7500) lr 1.7604e-03 eta 0:13:31
epoch [47/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.8237 (0.8159) acc 78.1250 (77.8125) lr 1.7604e-03 eta 0:13:03
epoch [47/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 1.0615 (0.8158) acc 71.8750 (77.7679) lr 1.7604e-03 eta 0:12:43
epoch [47/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 1.3398 (0.8342) acc 71.8750 (77.1094) lr 1.7604e-03 eta 0:12:27
epoch [47/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9785 (0.8382) acc 65.6250 (76.3889) lr 1.7604e-03 eta 0:12:14
epoch [47/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9331 (0.8495) acc 68.7500 (76.0000) lr 1.7501e-03 eta 0:12:04
epoch [48/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.102) loss 0.9888 (0.9015) acc 71.8750 (76.8750) lr 1.7501e-03 eta 0:23:55
epoch [48/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 1.5576 (0.9547) acc 65.6250 (74.6875) lr 1.7501e-03 eta 0:17:21
epoch [48/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.8433 (0.8996) acc 71.8750 (74.5833) lr 1.7501e-03 eta 0:15:10
epoch [48/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 1.3213 (0.8937) acc 71.8750 (75.1562) lr 1.7501e-03 eta 0:14:03
epoch [48/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8613 (0.9280) acc 75.0000 (75.1250) lr 1.7501e-03 eta 0:13:23
epoch [48/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.3835 (0.9210) acc 93.7500 (75.5208) lr 1.7501e-03 eta 0:12:55
epoch [48/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.8901 (0.9253) acc 78.1250 (75.4464) lr 1.7501e-03 eta 0:12:35
epoch [48/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9629 (0.9089) acc 68.7500 (75.5469) lr 1.7501e-03 eta 0:12:20
epoch [48/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6943 (0.8876) acc 78.1250 (75.9028) lr 1.7501e-03 eta 0:12:08
epoch [48/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 0.9497 (0.9042) acc 78.1250 (75.5000) lr 1.7396e-03 eta 0:11:58
epoch [49/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.103) loss 1.2119 (0.9254) acc 62.5000 (70.0000) lr 1.7396e-03 eta 0:23:56
epoch [49/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.6074 (0.7996) acc 81.2500 (75.6250) lr 1.7396e-03 eta 0:17:19
epoch [49/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.7896 (0.7845) acc 78.1250 (77.0833) lr 1.7396e-03 eta 0:15:06
epoch [49/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.4072 (0.7537) acc 84.3750 (77.3438) lr 1.7396e-03 eta 0:14:00
epoch [49/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.9238 (0.7673) acc 78.1250 (77.6250) lr 1.7396e-03 eta 0:13:19
epoch [49/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.5518 (0.7511) acc 87.5000 (78.3333) lr 1.7396e-03 eta 0:12:52
epoch [49/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 1.1484 (0.7714) acc 65.6250 (78.3036) lr 1.7396e-03 eta 0:12:33
epoch [49/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 1.0420 (0.7964) acc 75.0000 (77.8125) lr 1.7396e-03 eta 0:12:17
epoch [49/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7900 (0.7755) acc 68.7500 (78.0556) lr 1.7396e-03 eta 0:12:05
epoch [49/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7065 (0.7862) acc 81.2500 (77.9375) lr 1.7290e-03 eta 0:11:55
epoch [50/200] batch [5/50] time 0.083 (0.189) data 0.000 (0.105) loss 1.2285 (0.9350) acc 71.8750 (73.7500) lr 1.7290e-03 eta 0:23:46
epoch [50/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 1.2568 (0.9251) acc 75.0000 (75.6250) lr 1.7290e-03 eta 0:17:09
epoch [50/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.8701 (0.8882) acc 78.1250 (76.6667) lr 1.7290e-03 eta 0:14:56
epoch [50/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.026) loss 0.4878 (0.8388) acc 87.5000 (77.5000) lr 1.7290e-03 eta 0:13:49
epoch [50/200] batch [25/50] time 0.083 (0.105) data 0.000 (0.021) loss 0.7539 (0.8546) acc 75.0000 (76.5000) lr 1.7290e-03 eta 0:13:09
epoch [50/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.018) loss 0.6714 (0.8580) acc 81.2500 (76.5625) lr 1.7290e-03 eta 0:12:42
epoch [50/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.8091 (0.8389) acc 81.2500 (77.0536) lr 1.7290e-03 eta 0:12:23
epoch [50/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9004 (0.8544) acc 84.3750 (76.9531) lr 1.7290e-03 eta 0:12:08
epoch [50/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.012) loss 1.2822 (0.8639) acc 68.7500 (76.5278) lr 1.7290e-03 eta 0:11:56
epoch [50/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.0078 (0.8522) acc 65.6250 (76.3750) lr 1.7181e-03 eta 0:11:46
epoch [51/200] batch [5/50] time 0.084 (0.179) data 0.000 (0.094) loss 0.8096 (0.9829) acc 78.1250 (75.0000) lr 1.7181e-03 eta 0:22:21
epoch [51/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.7866 (0.8139) acc 78.1250 (78.1250) lr 1.7181e-03 eta 0:16:25
epoch [51/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.031) loss 1.2168 (0.8870) acc 68.7500 (75.4167) lr 1.7181e-03 eta 0:14:24
epoch [51/200] batch [20/50] time 0.083 (0.108) data 0.000 (0.024) loss 0.9048 (0.9091) acc 78.1250 (75.3125) lr 1.7181e-03 eta 0:13:25
epoch [51/200] batch [25/50] time 0.087 (0.103) data 0.000 (0.019) loss 1.3125 (0.8932) acc 65.6250 (75.6250) lr 1.7181e-03 eta 0:12:49
epoch [51/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 1.1914 (0.8724) acc 68.7500 (76.2500) lr 1.7181e-03 eta 0:12:24
epoch [51/200] batch [35/50] time 0.084 (0.097) data 0.000 (0.014) loss 0.9268 (0.8625) acc 75.0000 (76.1607) lr 1.7181e-03 eta 0:12:07
epoch [51/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9058 (0.8841) acc 68.7500 (75.5469) lr 1.7181e-03 eta 0:11:53
epoch [51/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.8765 (0.8842) acc 78.1250 (75.6944) lr 1.7181e-03 eta 0:11:42
epoch [51/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.8521 (0.8680) acc 78.1250 (75.8750) lr 1.7071e-03 eta 0:11:33
epoch [52/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.8696 (0.9549) acc 71.8750 (73.7500) lr 1.7071e-03 eta 0:22:30
epoch [52/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.8315 (0.8060) acc 81.2500 (78.1250) lr 1.7071e-03 eta 0:16:29
epoch [52/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.9526 (0.7744) acc 71.8750 (79.5833) lr 1.7071e-03 eta 0:14:27
epoch [52/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.6621 (0.7926) acc 75.0000 (78.9062) lr 1.7071e-03 eta 0:13:26
epoch [52/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.8555 (0.8116) acc 81.2500 (78.2500) lr 1.7071e-03 eta 0:12:50
epoch [52/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.016) loss 0.7559 (0.8005) acc 78.1250 (79.1667) lr 1.7071e-03 eta 0:12:25
epoch [52/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.7808 (0.8093) acc 84.3750 (78.8393) lr 1.7071e-03 eta 0:12:08
epoch [52/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5537 (0.8210) acc 84.3750 (78.2031) lr 1.7071e-03 eta 0:11:54
epoch [52/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8174 (0.8380) acc 65.6250 (77.3611) lr 1.7071e-03 eta 0:11:43
epoch [52/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.4082 (0.8386) acc 65.6250 (77.3125) lr 1.6959e-03 eta 0:11:34
epoch [53/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.105) loss 0.5317 (0.9417) acc 87.5000 (76.8750) lr 1.6959e-03 eta 0:23:19
epoch [53/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.053) loss 0.7578 (0.8995) acc 71.8750 (78.1250) lr 1.6959e-03 eta 0:16:53
epoch [53/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.8496 (0.8326) acc 71.8750 (79.1667) lr 1.6959e-03 eta 0:14:43
epoch [53/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 1.3428 (0.8541) acc 68.7500 (78.5938) lr 1.6959e-03 eta 0:13:38
epoch [53/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.4524 (0.8411) acc 87.5000 (78.1250) lr 1.6959e-03 eta 0:12:59
epoch [53/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.5469 (0.8413) acc 84.3750 (78.4375) lr 1.6959e-03 eta 0:12:32
epoch [53/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.5254 (0.8317) acc 90.6250 (78.5714) lr 1.6959e-03 eta 0:12:13
epoch [53/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.7192 (0.8242) acc 75.0000 (78.4375) lr 1.6959e-03 eta 0:11:58
epoch [53/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.3193 (0.8520) acc 71.8750 (77.9167) lr 1.6959e-03 eta 0:11:46
epoch [53/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9268 (0.8412) acc 71.8750 (78.0000) lr 1.6845e-03 eta 0:11:36
epoch [54/200] batch [5/50] time 0.085 (0.182) data 0.000 (0.097) loss 0.7778 (0.6676) acc 84.3750 (80.0000) lr 1.6845e-03 eta 0:22:19
epoch [54/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.8848 (0.7862) acc 75.0000 (78.4375) lr 1.6845e-03 eta 0:16:18
epoch [54/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.7866 (0.8312) acc 65.6250 (76.2500) lr 1.6845e-03 eta 0:14:19
epoch [54/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.4771 (0.8247) acc 87.5000 (76.2500) lr 1.6845e-03 eta 0:13:19
epoch [54/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.9512 (0.8216) acc 78.1250 (76.0000) lr 1.6845e-03 eta 0:12:42
epoch [54/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.9175 (0.7987) acc 78.1250 (76.3542) lr 1.6845e-03 eta 0:12:18
epoch [54/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.0850 (0.8103) acc 71.8750 (76.5179) lr 1.6845e-03 eta 0:12:01
epoch [54/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 1.3867 (0.8247) acc 71.8750 (76.2500) lr 1.6845e-03 eta 0:11:46
epoch [54/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.4795 (0.8371) acc 68.7500 (76.1806) lr 1.6845e-03 eta 0:11:35
epoch [54/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7134 (0.8220) acc 84.3750 (76.4375) lr 1.6730e-03 eta 0:11:26
epoch [55/200] batch [5/50] time 0.084 (0.195) data 0.000 (0.111) loss 0.8818 (0.7315) acc 68.7500 (78.7500) lr 1.6730e-03 eta 0:23:42
epoch [55/200] batch [10/50] time 0.084 (0.140) data 0.000 (0.056) loss 0.8198 (0.7577) acc 78.1250 (75.0000) lr 1.6730e-03 eta 0:16:56
epoch [55/200] batch [15/50] time 0.083 (0.121) data 0.000 (0.037) loss 0.7817 (0.7479) acc 81.2500 (76.2500) lr 1.6730e-03 eta 0:14:40
epoch [55/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.5952 (0.7831) acc 87.5000 (76.5625) lr 1.6730e-03 eta 0:13:33
epoch [55/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.5552 (0.7920) acc 87.5000 (77.3750) lr 1.6730e-03 eta 0:12:52
epoch [55/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.8774 (0.7941) acc 78.1250 (77.3958) lr 1.6730e-03 eta 0:12:25
epoch [55/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.0820 (0.8079) acc 75.0000 (77.5000) lr 1.6730e-03 eta 0:12:06
epoch [55/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9639 (0.8257) acc 65.6250 (76.7969) lr 1.6730e-03 eta 0:11:50
epoch [55/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.013) loss 0.4893 (0.8116) acc 84.3750 (77.1528) lr 1.6730e-03 eta 0:11:38
epoch [55/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5244 (0.8127) acc 87.5000 (77.0625) lr 1.6613e-03 eta 0:11:28
epoch [56/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 0.6465 (0.7661) acc 84.3750 (82.5000) lr 1.6613e-03 eta 0:21:56
epoch [56/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.6626 (0.8042) acc 87.5000 (79.6875) lr 1.6613e-03 eta 0:16:05
epoch [56/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.7285 (0.7599) acc 81.2500 (80.2083) lr 1.6613e-03 eta 0:14:06
epoch [56/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.5947 (0.7246) acc 84.3750 (80.9375) lr 1.6613e-03 eta 0:13:07
epoch [56/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.6709 (0.7339) acc 78.1250 (79.7500) lr 1.6613e-03 eta 0:12:31
epoch [56/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.5269 (0.7500) acc 81.2500 (79.4792) lr 1.6613e-03 eta 0:12:07
epoch [56/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 1.0615 (0.7836) acc 75.0000 (79.1964) lr 1.6613e-03 eta 0:11:49
epoch [56/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7173 (0.7999) acc 84.3750 (78.6719) lr 1.6613e-03 eta 0:11:35
epoch [56/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5010 (0.7947) acc 87.5000 (79.0278) lr 1.6613e-03 eta 0:11:24
epoch [56/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7866 (0.7940) acc 75.0000 (78.8750) lr 1.6494e-03 eta 0:11:15
epoch [57/200] batch [5/50] time 0.083 (0.185) data 0.000 (0.100) loss 0.8921 (0.7953) acc 62.5000 (75.6250) lr 1.6494e-03 eta 0:22:10
epoch [57/200] batch [10/50] time 0.083 (0.134) data 0.000 (0.050) loss 0.3494 (0.8587) acc 90.6250 (76.5625) lr 1.6494e-03 eta 0:16:06
epoch [57/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.034) loss 0.9590 (0.8403) acc 81.2500 (78.1250) lr 1.6494e-03 eta 0:14:04
epoch [57/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 0.5615 (0.8436) acc 87.5000 (77.9688) lr 1.6494e-03 eta 0:13:03
epoch [57/200] batch [25/50] time 0.083 (0.104) data 0.000 (0.020) loss 0.8662 (0.8314) acc 71.8750 (78.2500) lr 1.6494e-03 eta 0:12:27
epoch [57/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.5825 (0.8102) acc 84.3750 (78.2292) lr 1.6494e-03 eta 0:12:01
epoch [57/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.015) loss 0.7178 (0.8008) acc 78.1250 (78.1250) lr 1.6494e-03 eta 0:11:43
epoch [57/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 0.6128 (0.8039) acc 84.3750 (77.6562) lr 1.6494e-03 eta 0:11:30
epoch [57/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7764 (0.8003) acc 78.1250 (77.7083) lr 1.6494e-03 eta 0:11:19
epoch [57/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8926 (0.7976) acc 78.1250 (77.9375) lr 1.6374e-03 eta 0:11:10
epoch [58/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.106) loss 0.7271 (0.9191) acc 81.2500 (76.2500) lr 1.6374e-03 eta 0:22:50
epoch [58/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.6646 (0.8796) acc 81.2500 (78.7500) lr 1.6374e-03 eta 0:16:25
epoch [58/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 1.0283 (0.8681) acc 75.0000 (78.1250) lr 1.6374e-03 eta 0:14:16
epoch [58/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.7998 (0.8401) acc 62.5000 (77.8125) lr 1.6374e-03 eta 0:13:12
epoch [58/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.5654 (0.8048) acc 75.0000 (78.1250) lr 1.6374e-03 eta 0:12:33
epoch [58/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.9121 (0.8160) acc 78.1250 (77.9167) lr 1.6374e-03 eta 0:12:07
epoch [58/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.015) loss 0.6187 (0.8444) acc 84.3750 (76.9643) lr 1.6374e-03 eta 0:11:49
epoch [58/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.7900 (0.8398) acc 71.8750 (76.7188) lr 1.6374e-03 eta 0:11:34
epoch [58/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5254 (0.8267) acc 90.6250 (77.0833) lr 1.6374e-03 eta 0:11:22
epoch [58/200] batch [50/50] time 0.087 (0.095) data 0.000 (0.011) loss 0.6372 (0.8132) acc 81.2500 (77.3125) lr 1.6252e-03 eta 0:11:13
epoch [59/200] batch [5/50] time 0.084 (0.179) data 0.000 (0.094) loss 0.7583 (0.7594) acc 78.1250 (80.0000) lr 1.6252e-03 eta 0:21:06
epoch [59/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.9873 (0.7670) acc 68.7500 (79.3750) lr 1.6252e-03 eta 0:15:29
epoch [59/200] batch [15/50] time 0.084 (0.115) data 0.000 (0.031) loss 0.5186 (0.7545) acc 81.2500 (79.3750) lr 1.6252e-03 eta 0:13:37
epoch [59/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 1.0645 (0.7799) acc 62.5000 (77.8125) lr 1.6252e-03 eta 0:12:42
epoch [59/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.7896 (0.7891) acc 75.0000 (77.7500) lr 1.6252e-03 eta 0:12:08
epoch [59/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.0156 (0.8195) acc 71.8750 (77.2917) lr 1.6252e-03 eta 0:11:46
epoch [59/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7427 (0.8148) acc 78.1250 (77.5000) lr 1.6252e-03 eta 0:11:29
epoch [59/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.9072 (0.8221) acc 75.0000 (77.2656) lr 1.6252e-03 eta 0:11:16
epoch [59/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.0215 (0.8112) acc 68.7500 (77.2917) lr 1.6252e-03 eta 0:11:06
epoch [59/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.010) loss 1.2451 (0.8154) acc 68.7500 (77.2500) lr 1.6129e-03 eta 0:10:58
epoch [60/200] batch [5/50] time 0.084 (0.179) data 0.000 (0.094) loss 0.3611 (0.8033) acc 93.7500 (81.2500) lr 1.6129e-03 eta 0:20:59
epoch [60/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.8818 (0.9765) acc 75.0000 (75.3125) lr 1.6129e-03 eta 0:15:26
epoch [60/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.031) loss 0.7637 (0.9674) acc 87.5000 (76.0417) lr 1.6129e-03 eta 0:13:35
epoch [60/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 1.0605 (0.9636) acc 68.7500 (75.4688) lr 1.6129e-03 eta 0:12:39
epoch [60/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.8892 (0.9544) acc 84.3750 (76.1250) lr 1.6129e-03 eta 0:12:05
epoch [60/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 1.0840 (0.9598) acc 81.2500 (75.9375) lr 1.6129e-03 eta 0:11:43
epoch [60/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4685 (0.9271) acc 81.2500 (76.6964) lr 1.6129e-03 eta 0:11:27
epoch [60/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4028 (0.9067) acc 84.3750 (76.8750) lr 1.6129e-03 eta 0:11:14
epoch [60/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4155 (0.8755) acc 87.5000 (77.6389) lr 1.6129e-03 eta 0:11:03
epoch [60/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0537 (0.8570) acc 71.8750 (77.8750) lr 1.6004e-03 eta 0:10:55
epoch [61/200] batch [5/50] time 0.084 (0.179) data 0.000 (0.094) loss 0.9414 (0.6840) acc 78.1250 (82.5000) lr 1.6004e-03 eta 0:20:53
epoch [61/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.047) loss 0.9360 (0.7602) acc 81.2500 (79.6875) lr 1.6004e-03 eta 0:15:20
epoch [61/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 0.8110 (0.7823) acc 71.8750 (78.9583) lr 1.6004e-03 eta 0:13:30
epoch [61/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.8984 (0.7858) acc 68.7500 (78.9062) lr 1.6004e-03 eta 0:12:34
epoch [61/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.9121 (0.7926) acc 75.0000 (78.7500) lr 1.6004e-03 eta 0:12:01
epoch [61/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.9170 (0.8267) acc 68.7500 (77.9167) lr 1.6004e-03 eta 0:11:38
epoch [61/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.5151 (0.8055) acc 87.5000 (78.7500) lr 1.6004e-03 eta 0:11:22
epoch [61/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5229 (0.7716) acc 87.5000 (79.4531) lr 1.6004e-03 eta 0:11:09
epoch [61/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7129 (0.7728) acc 75.0000 (79.3056) lr 1.6004e-03 eta 0:10:58
epoch [61/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7949 (0.7706) acc 84.3750 (79.1250) lr 1.5878e-03 eta 0:10:50
epoch [62/200] batch [5/50] time 0.085 (0.193) data 0.000 (0.108) loss 1.0283 (0.9552) acc 68.7500 (72.5000) lr 1.5878e-03 eta 0:22:18
epoch [62/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.054) loss 0.9805 (0.9561) acc 75.0000 (73.1250) lr 1.5878e-03 eta 0:16:02
epoch [62/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 0.8369 (0.9159) acc 78.1250 (75.0000) lr 1.5878e-03 eta 0:13:55
epoch [62/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.9463 (0.9184) acc 71.8750 (75.6250) lr 1.5878e-03 eta 0:12:52
epoch [62/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.6816 (0.8804) acc 65.6250 (76.1250) lr 1.5878e-03 eta 0:12:14
epoch [62/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.8721 (0.8630) acc 75.0000 (76.1458) lr 1.5878e-03 eta 0:11:48
epoch [62/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7637 (0.8848) acc 78.1250 (75.7143) lr 1.5878e-03 eta 0:11:30
epoch [62/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.6362 (0.8692) acc 81.2500 (76.0156) lr 1.5878e-03 eta 0:11:15
epoch [62/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9727 (0.8464) acc 65.6250 (76.1111) lr 1.5878e-03 eta 0:11:04
epoch [62/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7925 (0.8508) acc 71.8750 (75.8125) lr 1.5750e-03 eta 0:10:55
epoch [63/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.097) loss 1.0068 (0.8702) acc 75.0000 (78.7500) lr 1.5750e-03 eta 0:21:03
epoch [63/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.6104 (0.8475) acc 87.5000 (80.6250) lr 1.5750e-03 eta 0:15:22
epoch [63/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.6079 (0.8294) acc 84.3750 (80.4167) lr 1.5750e-03 eta 0:13:28
epoch [63/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.9053 (0.8223) acc 81.2500 (80.1562) lr 1.5750e-03 eta 0:12:31
epoch [63/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 1.1582 (0.8262) acc 71.8750 (79.6250) lr 1.5750e-03 eta 0:11:57
epoch [63/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 1.2119 (0.8550) acc 65.6250 (77.9167) lr 1.5750e-03 eta 0:11:34
epoch [63/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 1.3301 (0.8602) acc 71.8750 (77.8571) lr 1.5750e-03 eta 0:11:17
epoch [63/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.5537 (0.8352) acc 81.2500 (78.2031) lr 1.5750e-03 eta 0:11:03
epoch [63/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5942 (0.8054) acc 81.2500 (78.6806) lr 1.5750e-03 eta 0:10:53
epoch [63/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7261 (0.8042) acc 81.2500 (78.6875) lr 1.5621e-03 eta 0:10:44
epoch [64/200] batch [5/50] time 0.085 (0.178) data 0.000 (0.093) loss 0.6743 (0.8253) acc 78.1250 (76.8750) lr 1.5621e-03 eta 0:20:21
epoch [64/200] batch [10/50] time 0.086 (0.132) data 0.000 (0.047) loss 0.7280 (0.7965) acc 78.1250 (79.0625) lr 1.5621e-03 eta 0:14:59
epoch [64/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.031) loss 0.5195 (0.7999) acc 87.5000 (78.5417) lr 1.5621e-03 eta 0:13:12
epoch [64/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.9814 (0.8054) acc 65.6250 (77.5000) lr 1.5621e-03 eta 0:12:18
epoch [64/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.7632 (0.8214) acc 81.2500 (77.1250) lr 1.5621e-03 eta 0:11:45
epoch [64/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.8911 (0.7998) acc 75.0000 (77.8125) lr 1.5621e-03 eta 0:11:24
epoch [64/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.9727 (0.8159) acc 68.7500 (77.4107) lr 1.5621e-03 eta 0:11:08
epoch [64/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6206 (0.8082) acc 87.5000 (77.5781) lr 1.5621e-03 eta 0:10:55
epoch [64/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.3076 (0.8244) acc 62.5000 (77.1528) lr 1.5621e-03 eta 0:10:45
epoch [64/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8350 (0.8288) acc 75.0000 (77.1875) lr 1.5490e-03 eta 0:10:37
epoch [65/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.103) loss 0.5557 (0.6551) acc 84.3750 (80.0000) lr 1.5490e-03 eta 0:21:13
epoch [65/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.8579 (0.7847) acc 78.1250 (78.4375) lr 1.5490e-03 eta 0:15:22
epoch [65/200] batch [15/50] time 0.083 (0.119) data 0.000 (0.034) loss 0.9673 (0.7631) acc 78.1250 (78.5417) lr 1.5490e-03 eta 0:13:24
epoch [65/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.0166 (0.7649) acc 71.8750 (78.9062) lr 1.5490e-03 eta 0:12:25
epoch [65/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 1.3232 (0.7928) acc 59.3750 (78.2500) lr 1.5490e-03 eta 0:11:50
epoch [65/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8730 (0.7949) acc 78.1250 (78.4375) lr 1.5490e-03 eta 0:11:26
epoch [65/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.015) loss 0.5220 (0.8142) acc 78.1250 (77.7679) lr 1.5490e-03 eta 0:11:09
epoch [65/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6870 (0.8369) acc 71.8750 (77.1875) lr 1.5490e-03 eta 0:10:55
epoch [65/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 1.0635 (0.8249) acc 75.0000 (77.2917) lr 1.5490e-03 eta 0:10:44
epoch [65/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7817 (0.8310) acc 78.1250 (77.2500) lr 1.5358e-03 eta 0:10:36
epoch [66/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.109) loss 0.6167 (0.7995) acc 90.6250 (80.0000) lr 1.5358e-03 eta 0:21:49
epoch [66/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.055) loss 0.6172 (0.7397) acc 81.2500 (80.3125) lr 1.5358e-03 eta 0:15:38
epoch [66/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 0.7964 (0.7367) acc 84.3750 (80.2083) lr 1.5358e-03 eta 0:13:33
epoch [66/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.5498 (0.7578) acc 87.5000 (79.6875) lr 1.5358e-03 eta 0:12:31
epoch [66/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 1.1738 (0.7686) acc 71.8750 (79.7500) lr 1.5358e-03 eta 0:11:54
epoch [66/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.7617 (0.7952) acc 78.1250 (79.1667) lr 1.5358e-03 eta 0:11:28
epoch [66/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.016) loss 0.9810 (0.8141) acc 78.1250 (78.3036) lr 1.5358e-03 eta 0:11:11
epoch [66/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.0947 (0.8012) acc 81.2500 (78.8281) lr 1.5358e-03 eta 0:10:56
epoch [66/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8838 (0.8297) acc 71.8750 (78.0556) lr 1.5358e-03 eta 0:10:45
epoch [66/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.3398 (0.8380) acc 65.6250 (77.9375) lr 1.5225e-03 eta 0:10:36
epoch [67/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 0.4043 (0.6967) acc 90.6250 (81.8750) lr 1.5225e-03 eta 0:20:29
epoch [67/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.050) loss 0.8301 (0.7339) acc 78.1250 (80.6250) lr 1.5225e-03 eta 0:14:57
epoch [67/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.5386 (0.7568) acc 90.6250 (80.2083) lr 1.5225e-03 eta 0:13:05
epoch [67/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.7974 (0.7830) acc 81.2500 (79.8438) lr 1.5225e-03 eta 0:12:09
epoch [67/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.5649 (0.7988) acc 84.3750 (79.2500) lr 1.5225e-03 eta 0:11:35
epoch [67/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6064 (0.7788) acc 81.2500 (79.5833) lr 1.5225e-03 eta 0:11:13
epoch [67/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.7212 (0.7652) acc 81.2500 (79.9107) lr 1.5225e-03 eta 0:10:56
epoch [67/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6909 (0.7778) acc 81.2500 (79.8438) lr 1.5225e-03 eta 0:10:43
epoch [67/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1396 (0.8187) acc 68.7500 (79.0278) lr 1.5225e-03 eta 0:10:33
epoch [67/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8345 (0.8195) acc 84.3750 (78.9375) lr 1.5090e-03 eta 0:10:24
epoch [68/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.101) loss 0.7344 (0.6843) acc 78.1250 (78.7500) lr 1.5090e-03 eta 0:20:33
epoch [68/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.8511 (0.7164) acc 75.0000 (78.7500) lr 1.5090e-03 eta 0:14:57
epoch [68/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.034) loss 0.5405 (0.6901) acc 84.3750 (80.2083) lr 1.5090e-03 eta 0:13:05
epoch [68/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.7329 (0.7247) acc 87.5000 (79.8438) lr 1.5090e-03 eta 0:12:09
epoch [68/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.5405 (0.7613) acc 81.2500 (78.7500) lr 1.5090e-03 eta 0:11:35
epoch [68/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.6509 (0.7712) acc 90.6250 (78.1250) lr 1.5090e-03 eta 0:11:12
epoch [68/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7920 (0.7664) acc 81.2500 (78.3036) lr 1.5090e-03 eta 0:10:55
epoch [68/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9146 (0.7519) acc 65.6250 (78.5938) lr 1.5090e-03 eta 0:10:42
epoch [68/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.5840 (0.7495) acc 84.3750 (78.9583) lr 1.5090e-03 eta 0:10:31
epoch [68/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7959 (0.7679) acc 78.1250 (78.3125) lr 1.4955e-03 eta 0:10:23
epoch [69/200] batch [5/50] time 0.084 (0.178) data 0.000 (0.092) loss 0.7139 (0.7601) acc 81.2500 (76.8750) lr 1.4955e-03 eta 0:19:33
epoch [69/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.046) loss 1.0938 (0.8163) acc 62.5000 (76.5625) lr 1.4955e-03 eta 0:14:25
epoch [69/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.031) loss 0.9180 (0.7828) acc 71.8750 (77.0833) lr 1.4955e-03 eta 0:12:41
epoch [69/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.023) loss 1.0596 (0.8091) acc 75.0000 (76.4062) lr 1.4955e-03 eta 0:11:50
epoch [69/200] batch [25/50] time 0.086 (0.103) data 0.000 (0.019) loss 0.6216 (0.7876) acc 81.2500 (77.3750) lr 1.4955e-03 eta 0:11:18
epoch [69/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.8262 (0.7736) acc 81.2500 (78.2292) lr 1.4955e-03 eta 0:10:58
epoch [69/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.013) loss 1.0342 (0.7894) acc 68.7500 (77.5000) lr 1.4955e-03 eta 0:10:43
epoch [69/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0117 (0.8025) acc 62.5000 (76.9531) lr 1.4955e-03 eta 0:10:31
epoch [69/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.7197 (0.8006) acc 78.1250 (77.0139) lr 1.4955e-03 eta 0:10:21
epoch [69/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.009) loss 1.3994 (0.8261) acc 56.2500 (76.4375) lr 1.4818e-03 eta 0:10:13
epoch [70/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.4636 (0.5998) acc 87.5000 (83.1250) lr 1.4818e-03 eta 0:20:13
epoch [70/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 1.2090 (0.6263) acc 62.5000 (82.1875) lr 1.4818e-03 eta 0:14:42
epoch [70/200] batch [15/50] time 0.086 (0.118) data 0.000 (0.033) loss 0.7427 (0.6747) acc 84.3750 (81.4583) lr 1.4818e-03 eta 0:12:52
epoch [70/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 1.0947 (0.6959) acc 59.3750 (80.4688) lr 1.4818e-03 eta 0:11:56
epoch [70/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.9688 (0.7450) acc 71.8750 (79.3750) lr 1.4818e-03 eta 0:11:23
epoch [70/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.8359 (0.7558) acc 71.8750 (78.8542) lr 1.4818e-03 eta 0:11:01
epoch [70/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.8760 (0.7722) acc 71.8750 (78.6607) lr 1.4818e-03 eta 0:10:45
epoch [70/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6274 (0.7601) acc 78.1250 (79.1406) lr 1.4818e-03 eta 0:10:31
epoch [70/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.6714 (0.7504) acc 78.1250 (79.5139) lr 1.4818e-03 eta 0:10:21
epoch [70/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.0176 (0.7784) acc 75.0000 (78.8125) lr 1.4679e-03 eta 0:10:13
epoch [71/200] batch [5/50] time 0.084 (0.188) data 0.000 (0.103) loss 0.6060 (0.6910) acc 81.2500 (82.5000) lr 1.4679e-03 eta 0:20:18
epoch [71/200] batch [10/50] time 0.083 (0.136) data 0.000 (0.051) loss 0.5332 (0.7201) acc 81.2500 (79.3750) lr 1.4679e-03 eta 0:14:42
epoch [71/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.7271 (0.8012) acc 84.3750 (78.3333) lr 1.4679e-03 eta 0:12:48
epoch [71/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.0215 (0.8040) acc 78.1250 (78.9062) lr 1.4679e-03 eta 0:11:52
epoch [71/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.5562 (0.7838) acc 87.5000 (79.5000) lr 1.4679e-03 eta 0:11:18
epoch [71/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6401 (0.7824) acc 78.1250 (78.8542) lr 1.4679e-03 eta 0:10:55
epoch [71/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7314 (0.7787) acc 84.3750 (78.8393) lr 1.4679e-03 eta 0:10:39
epoch [71/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8940 (0.7831) acc 71.8750 (78.6719) lr 1.4679e-03 eta 0:10:26
epoch [71/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.7197 (0.7923) acc 81.2500 (78.1944) lr 1.4679e-03 eta 0:10:15
epoch [71/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8926 (0.8031) acc 78.1250 (78.1250) lr 1.4540e-03 eta 0:10:07
epoch [72/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.098) loss 0.8389 (0.9088) acc 75.0000 (76.2500) lr 1.4540e-03 eta 0:19:39
epoch [72/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.8877 (0.8753) acc 81.2500 (76.8750) lr 1.4540e-03 eta 0:14:21
epoch [72/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.9204 (0.8792) acc 78.1250 (74.7917) lr 1.4540e-03 eta 0:12:35
epoch [72/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.0293 (0.8777) acc 71.8750 (74.8438) lr 1.4540e-03 eta 0:11:42
epoch [72/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.7339 (0.8677) acc 78.1250 (74.7500) lr 1.4540e-03 eta 0:11:10
epoch [72/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.9941 (0.8909) acc 71.8750 (74.0625) lr 1.4540e-03 eta 0:10:48
epoch [72/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.8667 (0.8744) acc 78.1250 (74.5536) lr 1.4540e-03 eta 0:10:33
epoch [72/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.8657 (0.8864) acc 71.8750 (74.5312) lr 1.4540e-03 eta 0:10:20
epoch [72/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1211 (0.8930) acc 78.1250 (74.5139) lr 1.4540e-03 eta 0:10:10
epoch [72/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.0430 (0.8834) acc 71.8750 (75.1875) lr 1.4399e-03 eta 0:10:02
epoch [73/200] batch [5/50] time 0.084 (0.178) data 0.000 (0.094) loss 0.5298 (0.8437) acc 84.3750 (75.0000) lr 1.4399e-03 eta 0:18:59
epoch [73/200] batch [10/50] time 0.084 (0.131) data 0.000 (0.047) loss 0.6533 (0.7554) acc 81.2500 (78.7500) lr 1.4399e-03 eta 0:13:57
epoch [73/200] batch [15/50] time 0.084 (0.115) data 0.000 (0.031) loss 0.5820 (0.7622) acc 90.6250 (79.3750) lr 1.4399e-03 eta 0:12:16
epoch [73/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 1.1768 (0.8030) acc 68.7500 (77.9688) lr 1.4399e-03 eta 0:11:26
epoch [73/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.9556 (0.8073) acc 65.6250 (77.2500) lr 1.4399e-03 eta 0:10:57
epoch [73/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.6265 (0.7906) acc 81.2500 (78.2292) lr 1.4399e-03 eta 0:10:37
epoch [73/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 0.6621 (0.7995) acc 87.5000 (78.1250) lr 1.4399e-03 eta 0:10:23
epoch [73/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5933 (0.7857) acc 87.5000 (78.5938) lr 1.4399e-03 eta 0:10:11
epoch [73/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6567 (0.7918) acc 84.3750 (78.5417) lr 1.4399e-03 eta 0:10:02
epoch [73/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.1113 (0.7760) acc 68.7500 (78.8750) lr 1.4258e-03 eta 0:09:54
epoch [74/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.097) loss 0.5869 (0.7911) acc 81.2500 (77.5000) lr 1.4258e-03 eta 0:19:21
epoch [74/200] batch [10/50] time 0.086 (0.134) data 0.000 (0.049) loss 0.5005 (0.7517) acc 90.6250 (79.3750) lr 1.4258e-03 eta 0:14:10
epoch [74/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.7236 (0.7472) acc 75.0000 (78.3333) lr 1.4258e-03 eta 0:12:25
epoch [74/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.4131 (0.7230) acc 87.5000 (79.0625) lr 1.4258e-03 eta 0:11:32
epoch [74/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 1.1543 (0.7558) acc 78.1250 (78.5000) lr 1.4258e-03 eta 0:11:01
epoch [74/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.9009 (0.7257) acc 78.1250 (79.6875) lr 1.4258e-03 eta 0:10:39
epoch [74/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 1.1084 (0.7702) acc 71.8750 (78.5714) lr 1.4258e-03 eta 0:10:24
epoch [74/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 1.0947 (0.7963) acc 71.8750 (78.1250) lr 1.4258e-03 eta 0:10:12
epoch [74/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.9092 (0.8082) acc 75.0000 (77.9167) lr 1.4258e-03 eta 0:10:02
epoch [74/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7256 (0.8010) acc 78.1250 (78.1250) lr 1.4115e-03 eta 0:09:54
epoch [75/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.100) loss 0.6538 (0.8968) acc 81.2500 (75.0000) lr 1.4115e-03 eta 0:19:29
epoch [75/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 1.0273 (0.8357) acc 71.8750 (78.7500) lr 1.4115e-03 eta 0:14:10
epoch [75/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.034) loss 0.5718 (0.7976) acc 81.2500 (78.3333) lr 1.4115e-03 eta 0:12:24
epoch [75/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.4966 (0.8101) acc 81.2500 (77.8125) lr 1.4115e-03 eta 0:11:31
epoch [75/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.4895 (0.7806) acc 87.5000 (78.2500) lr 1.4115e-03 eta 0:10:58
epoch [75/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.9795 (0.8124) acc 75.0000 (77.2917) lr 1.4115e-03 eta 0:10:36
epoch [75/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.6123 (0.8079) acc 87.5000 (77.2321) lr 1.4115e-03 eta 0:10:20
epoch [75/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8750 (0.8089) acc 78.1250 (77.3438) lr 1.4115e-03 eta 0:10:07
epoch [75/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.8428 (0.7951) acc 78.1250 (77.9861) lr 1.4115e-03 eta 0:09:57
epoch [75/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.5474 (0.8014) acc 81.2500 (77.5625) lr 1.3971e-03 eta 0:09:49
epoch [76/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.7661 (0.8047) acc 71.8750 (80.0000) lr 1.3971e-03 eta 0:18:51
epoch [76/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.9722 (0.7514) acc 75.0000 (80.0000) lr 1.3971e-03 eta 0:13:48
epoch [76/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.5137 (0.7586) acc 78.1250 (79.5833) lr 1.3971e-03 eta 0:12:07
epoch [76/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 1.0371 (0.8007) acc 71.8750 (78.5938) lr 1.3971e-03 eta 0:11:17
epoch [76/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.9141 (0.8030) acc 81.2500 (78.5000) lr 1.3971e-03 eta 0:10:46
epoch [76/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.9224 (0.8108) acc 78.1250 (78.2292) lr 1.3971e-03 eta 0:10:25
epoch [76/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.0908 (0.8498) acc 71.8750 (77.8571) lr 1.3971e-03 eta 0:10:10
epoch [76/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0752 (0.8663) acc 71.8750 (77.0312) lr 1.3971e-03 eta 0:09:58
epoch [76/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6899 (0.8552) acc 71.8750 (76.8750) lr 1.3971e-03 eta 0:09:49
epoch [76/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.3127 (0.8383) acc 90.6250 (77.5000) lr 1.3827e-03 eta 0:09:41
epoch [77/200] batch [5/50] time 0.085 (0.178) data 0.000 (0.093) loss 0.8730 (0.6339) acc 68.7500 (80.6250) lr 1.3827e-03 eta 0:18:25
epoch [77/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.6665 (0.7172) acc 78.1250 (78.1250) lr 1.3827e-03 eta 0:13:32
epoch [77/200] batch [15/50] time 0.083 (0.115) data 0.000 (0.031) loss 0.6343 (0.6935) acc 81.2500 (80.0000) lr 1.3827e-03 eta 0:11:53
epoch [77/200] batch [20/50] time 0.083 (0.108) data 0.000 (0.023) loss 0.6938 (0.7073) acc 84.3750 (79.3750) lr 1.3827e-03 eta 0:11:04
epoch [77/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 1.0098 (0.7214) acc 68.7500 (79.0000) lr 1.3827e-03 eta 0:10:35
epoch [77/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7974 (0.7767) acc 75.0000 (78.0208) lr 1.3827e-03 eta 0:10:15
epoch [77/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7036 (0.7750) acc 81.2500 (77.9464) lr 1.3827e-03 eta 0:10:01
epoch [77/200] batch [40/50] time 0.085 (0.096) data 0.000 (0.012) loss 0.5005 (0.7585) acc 84.3750 (78.7500) lr 1.3827e-03 eta 0:09:50
epoch [77/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.0742 (0.7495) acc 78.1250 (78.8194) lr 1.3827e-03 eta 0:09:40
epoch [77/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.009) loss 0.9736 (0.7620) acc 78.1250 (78.6250) lr 1.3681e-03 eta 0:09:33
epoch [78/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.093) loss 1.0752 (0.9376) acc 68.7500 (74.3750) lr 1.3681e-03 eta 0:18:17
epoch [78/200] batch [10/50] time 0.084 (0.131) data 0.000 (0.046) loss 0.9336 (0.8530) acc 71.8750 (76.8750) lr 1.3681e-03 eta 0:13:27
epoch [78/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.031) loss 0.7896 (0.7839) acc 81.2500 (79.1667) lr 1.3681e-03 eta 0:11:51
epoch [78/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.023) loss 0.8071 (0.7705) acc 71.8750 (78.9062) lr 1.3681e-03 eta 0:11:02
epoch [78/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.4175 (0.7766) acc 81.2500 (78.7500) lr 1.3681e-03 eta 0:10:32
epoch [78/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6172 (0.7897) acc 87.5000 (77.9167) lr 1.3681e-03 eta 0:10:13
epoch [78/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.013) loss 0.7554 (0.8022) acc 81.2500 (77.8571) lr 1.3681e-03 eta 0:09:58
epoch [78/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5776 (0.7859) acc 87.5000 (78.2812) lr 1.3681e-03 eta 0:09:47
epoch [78/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.9575 (0.7947) acc 78.1250 (78.2639) lr 1.3681e-03 eta 0:09:38
epoch [78/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.009) loss 0.6699 (0.7820) acc 75.0000 (78.6250) lr 1.3535e-03 eta 0:09:31
epoch [79/200] batch [5/50] time 0.083 (0.192) data 0.000 (0.107) loss 0.5117 (0.8879) acc 93.7500 (82.5000) lr 1.3535e-03 eta 0:19:28
epoch [79/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.054) loss 0.6890 (0.7408) acc 87.5000 (83.7500) lr 1.3535e-03 eta 0:14:01
epoch [79/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.6968 (0.7699) acc 81.2500 (81.6667) lr 1.3535e-03 eta 0:12:09
epoch [79/200] batch [20/50] time 0.083 (0.111) data 0.000 (0.027) loss 0.9048 (0.7952) acc 71.8750 (80.4688) lr 1.3535e-03 eta 0:11:14
epoch [79/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.022) loss 1.1025 (0.7978) acc 75.0000 (80.2500) lr 1.3535e-03 eta 0:10:40
epoch [79/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.8477 (0.8139) acc 78.1250 (79.3750) lr 1.3535e-03 eta 0:10:17
epoch [79/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.016) loss 0.4412 (0.8054) acc 81.2500 (78.9286) lr 1.3535e-03 eta 0:10:01
epoch [79/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 1.0059 (0.8107) acc 68.7500 (78.1250) lr 1.3535e-03 eta 0:09:49
epoch [79/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8223 (0.8104) acc 71.8750 (77.8472) lr 1.3535e-03 eta 0:09:39
epoch [79/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.8989 (0.8208) acc 75.0000 (77.5000) lr 1.3387e-03 eta 0:09:31
epoch [80/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.106) loss 0.5200 (0.8350) acc 87.5000 (78.1250) lr 1.3387e-03 eta 0:19:14
epoch [80/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.3918 (0.7731) acc 90.6250 (79.3750) lr 1.3387e-03 eta 0:13:51
epoch [80/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.7285 (0.7959) acc 71.8750 (77.5000) lr 1.3387e-03 eta 0:12:03
epoch [80/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.3716 (0.7567) acc 93.7500 (78.2812) lr 1.3387e-03 eta 0:11:09
epoch [80/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.5967 (0.7558) acc 81.2500 (78.7500) lr 1.3387e-03 eta 0:10:36
epoch [80/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.8311 (0.7659) acc 78.1250 (78.3333) lr 1.3387e-03 eta 0:10:15
epoch [80/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.8564 (0.7850) acc 78.1250 (78.1250) lr 1.3387e-03 eta 0:09:59
epoch [80/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.5952 (0.7709) acc 87.5000 (78.2031) lr 1.3387e-03 eta 0:09:46
epoch [80/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.2793 (0.7946) acc 68.7500 (77.8472) lr 1.3387e-03 eta 0:09:36
epoch [80/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0459 (0.7895) acc 71.8750 (78.2500) lr 1.3239e-03 eta 0:09:28
epoch [81/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.102) loss 0.7573 (0.7715) acc 75.0000 (78.1250) lr 1.3239e-03 eta 0:18:41
epoch [81/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.3997 (0.6705) acc 87.5000 (81.5625) lr 1.3239e-03 eta 0:13:31
epoch [81/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.7979 (0.7638) acc 78.1250 (78.5417) lr 1.3239e-03 eta 0:11:48
epoch [81/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.7573 (0.7532) acc 81.2500 (78.5938) lr 1.3239e-03 eta 0:10:55
epoch [81/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.021) loss 0.7490 (0.7981) acc 84.3750 (77.8750) lr 1.3239e-03 eta 0:10:24
epoch [81/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.4946 (0.7702) acc 84.3750 (78.2292) lr 1.3239e-03 eta 0:10:03
epoch [81/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.2676 (0.7771) acc 71.8750 (78.1250) lr 1.3239e-03 eta 0:09:47
epoch [81/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.3691 (0.7852) acc 65.6250 (77.9688) lr 1.3239e-03 eta 0:09:35
epoch [81/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 1.0137 (0.7844) acc 75.0000 (78.0556) lr 1.3239e-03 eta 0:09:26
epoch [81/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9546 (0.7936) acc 71.8750 (77.9375) lr 1.3090e-03 eta 0:09:19
epoch [82/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.101) loss 0.6226 (0.7519) acc 87.5000 (77.5000) lr 1.3090e-03 eta 0:18:27
epoch [82/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.051) loss 0.8838 (0.8207) acc 78.1250 (76.2500) lr 1.3090e-03 eta 0:13:24
epoch [82/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.6934 (0.7544) acc 81.2500 (78.1250) lr 1.3090e-03 eta 0:11:41
epoch [82/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.026) loss 0.5483 (0.7199) acc 84.3750 (79.6875) lr 1.3090e-03 eta 0:10:50
epoch [82/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.9316 (0.7639) acc 75.0000 (78.7500) lr 1.3090e-03 eta 0:10:20
epoch [82/200] batch [30/50] time 0.086 (0.101) data 0.000 (0.017) loss 0.3728 (0.7723) acc 87.5000 (78.0208) lr 1.3090e-03 eta 0:09:59
epoch [82/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.5698 (0.7906) acc 81.2500 (78.1250) lr 1.3090e-03 eta 0:09:45
epoch [82/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.1230 (0.7852) acc 78.1250 (78.5938) lr 1.3090e-03 eta 0:09:33
epoch [82/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.8311 (0.7960) acc 71.8750 (78.1944) lr 1.3090e-03 eta 0:09:24
epoch [82/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8501 (0.7928) acc 71.8750 (78.0625) lr 1.2940e-03 eta 0:09:16
epoch [83/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.103) loss 0.5562 (0.8514) acc 81.2500 (78.7500) lr 1.2940e-03 eta 0:18:35
epoch [83/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 0.9058 (0.8107) acc 75.0000 (79.6875) lr 1.2940e-03 eta 0:13:26
epoch [83/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.6172 (0.8274) acc 81.2500 (78.1250) lr 1.2940e-03 eta 0:11:43
epoch [83/200] batch [20/50] time 0.086 (0.111) data 0.000 (0.026) loss 0.7646 (0.8018) acc 71.8750 (77.9688) lr 1.2940e-03 eta 0:10:52
epoch [83/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.9941 (0.8001) acc 78.1250 (78.3750) lr 1.2940e-03 eta 0:10:21
epoch [83/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.5278 (0.7941) acc 84.3750 (78.4375) lr 1.2940e-03 eta 0:10:00
epoch [83/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 1.4365 (0.8002) acc 68.7500 (78.6607) lr 1.2940e-03 eta 0:09:45
epoch [83/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.8765 (0.7987) acc 71.8750 (78.3594) lr 1.2940e-03 eta 0:09:32
epoch [83/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6489 (0.7958) acc 78.1250 (78.4722) lr 1.2940e-03 eta 0:09:22
epoch [83/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9175 (0.8001) acc 78.1250 (78.5000) lr 1.2790e-03 eta 0:09:14
epoch [84/200] batch [5/50] time 0.085 (0.181) data 0.000 (0.096) loss 0.5083 (0.5939) acc 87.5000 (85.0000) lr 1.2790e-03 eta 0:17:37
epoch [84/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.048) loss 0.7959 (0.7014) acc 78.1250 (81.5625) lr 1.2790e-03 eta 0:12:52
epoch [84/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 0.6587 (0.6759) acc 81.2500 (81.8750) lr 1.2790e-03 eta 0:11:18
epoch [84/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.7144 (0.6970) acc 78.1250 (80.3125) lr 1.2790e-03 eta 0:10:30
epoch [84/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.4790 (0.7066) acc 87.5000 (79.5000) lr 1.2790e-03 eta 0:10:02
epoch [84/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.9419 (0.7246) acc 71.8750 (78.7500) lr 1.2790e-03 eta 0:09:42
epoch [84/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.5640 (0.7263) acc 90.6250 (79.1071) lr 1.2790e-03 eta 0:09:28
epoch [84/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6338 (0.7045) acc 81.2500 (79.6094) lr 1.2790e-03 eta 0:09:17
epoch [84/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8647 (0.7147) acc 75.0000 (79.6528) lr 1.2790e-03 eta 0:09:08
epoch [84/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.3406 (0.7035) acc 90.6250 (80.1250) lr 1.2639e-03 eta 0:09:01
epoch [85/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.101) loss 0.7227 (0.6001) acc 81.2500 (82.5000) lr 1.2639e-03 eta 0:17:58
epoch [85/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.5518 (0.7003) acc 84.3750 (79.6875) lr 1.2639e-03 eta 0:13:04
epoch [85/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.9326 (0.7977) acc 78.1250 (78.3333) lr 1.2639e-03 eta 0:11:26
epoch [85/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 1.2158 (0.8488) acc 68.7500 (77.0312) lr 1.2639e-03 eta 0:10:37
epoch [85/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.4634 (0.7891) acc 87.5000 (78.3750) lr 1.2639e-03 eta 0:10:07
epoch [85/200] batch [30/50] time 0.086 (0.102) data 0.000 (0.017) loss 0.7891 (0.7834) acc 78.1250 (78.7500) lr 1.2639e-03 eta 0:09:47
epoch [85/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.5693 (0.7873) acc 87.5000 (78.6607) lr 1.2639e-03 eta 0:09:32
epoch [85/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8984 (0.7934) acc 71.8750 (78.1250) lr 1.2639e-03 eta 0:09:21
epoch [85/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 1.4463 (0.8120) acc 71.8750 (78.1250) lr 1.2639e-03 eta 0:09:11
epoch [85/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 1.0557 (0.8163) acc 75.0000 (78.5000) lr 1.2487e-03 eta 0:09:03
epoch [86/200] batch [5/50] time 0.083 (0.189) data 0.000 (0.104) loss 0.9526 (0.7998) acc 68.7500 (78.7500) lr 1.2487e-03 eta 0:18:05
epoch [86/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 1.1309 (0.8236) acc 53.1250 (75.3125) lr 1.2487e-03 eta 0:13:03
epoch [86/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.6333 (0.7213) acc 68.7500 (78.3333) lr 1.2487e-03 eta 0:11:24
epoch [86/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.9360 (0.7637) acc 84.3750 (78.1250) lr 1.2487e-03 eta 0:10:34
epoch [86/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 1.0361 (0.7643) acc 68.7500 (77.8750) lr 1.2487e-03 eta 0:10:04
epoch [86/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.9175 (0.7880) acc 78.1250 (77.3958) lr 1.2487e-03 eta 0:09:43
epoch [86/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 1.0059 (0.7737) acc 75.0000 (78.0357) lr 1.2487e-03 eta 0:09:29
epoch [86/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.6401 (0.7626) acc 87.5000 (78.5938) lr 1.2487e-03 eta 0:09:17
epoch [86/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6484 (0.7709) acc 90.6250 (78.6111) lr 1.2487e-03 eta 0:09:07
epoch [86/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6338 (0.7686) acc 81.2500 (78.7500) lr 1.2334e-03 eta 0:09:00
epoch [87/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.9976 (0.7986) acc 65.6250 (75.6250) lr 1.2334e-03 eta 0:17:11
epoch [87/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 1.0156 (0.7864) acc 78.1250 (76.8750) lr 1.2334e-03 eta 0:12:35
epoch [87/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.5488 (0.7731) acc 84.3750 (77.7083) lr 1.2334e-03 eta 0:11:03
epoch [87/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 1.3018 (0.7899) acc 56.2500 (77.1875) lr 1.2334e-03 eta 0:10:17
epoch [87/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.8843 (0.7927) acc 78.1250 (77.3750) lr 1.2334e-03 eta 0:09:49
epoch [87/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.9160 (0.8025) acc 75.0000 (77.3958) lr 1.2334e-03 eta 0:09:30
epoch [87/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.0029 (0.8123) acc 68.7500 (77.2321) lr 1.2334e-03 eta 0:09:17
epoch [87/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0762 (0.8185) acc 71.8750 (77.3438) lr 1.2334e-03 eta 0:09:06
epoch [87/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9814 (0.8112) acc 68.7500 (77.4306) lr 1.2334e-03 eta 0:08:57
epoch [87/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6499 (0.8122) acc 84.3750 (77.5000) lr 1.2181e-03 eta 0:08:50
epoch [88/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.105) loss 0.5781 (0.8516) acc 87.5000 (74.3750) lr 1.2181e-03 eta 0:18:00
epoch [88/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.6113 (0.8112) acc 84.3750 (75.6250) lr 1.2181e-03 eta 0:12:58
epoch [88/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.4905 (0.7713) acc 90.6250 (77.0833) lr 1.2181e-03 eta 0:11:16
epoch [88/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 1.1201 (0.7811) acc 78.1250 (77.8125) lr 1.2181e-03 eta 0:10:25
epoch [88/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.8486 (0.7837) acc 71.8750 (77.7500) lr 1.2181e-03 eta 0:09:55
epoch [88/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6011 (0.7979) acc 81.2500 (77.9167) lr 1.2181e-03 eta 0:09:34
epoch [88/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.8364 (0.7997) acc 75.0000 (77.9464) lr 1.2181e-03 eta 0:09:20
epoch [88/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.7227 (0.7900) acc 87.5000 (78.3594) lr 1.2181e-03 eta 0:09:08
epoch [88/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6650 (0.7984) acc 81.2500 (78.4028) lr 1.2181e-03 eta 0:08:59
epoch [88/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4692 (0.7962) acc 84.3750 (78.4375) lr 1.2028e-03 eta 0:08:51
epoch [89/200] batch [5/50] time 0.085 (0.188) data 0.000 (0.102) loss 0.6831 (0.8524) acc 78.1250 (76.8750) lr 1.2028e-03 eta 0:17:30
epoch [89/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.6265 (0.8132) acc 78.1250 (76.5625) lr 1.2028e-03 eta 0:12:42
epoch [89/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.7695 (0.8052) acc 75.0000 (77.7083) lr 1.2028e-03 eta 0:11:06
epoch [89/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.8481 (0.8066) acc 75.0000 (77.5000) lr 1.2028e-03 eta 0:10:17
epoch [89/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.5991 (0.7996) acc 81.2500 (77.7500) lr 1.2028e-03 eta 0:09:48
epoch [89/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.5225 (0.7677) acc 84.3750 (78.3333) lr 1.2028e-03 eta 0:09:28
epoch [89/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.9072 (0.7600) acc 81.2500 (78.5714) lr 1.2028e-03 eta 0:09:14
epoch [89/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.7759 (0.7532) acc 81.2500 (79.0625) lr 1.2028e-03 eta 0:09:02
epoch [89/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.3047 (0.7738) acc 62.5000 (78.4722) lr 1.2028e-03 eta 0:08:53
epoch [89/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 0.4365 (0.7509) acc 84.3750 (78.8750) lr 1.1874e-03 eta 0:08:45
epoch [90/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.100) loss 1.0215 (0.8407) acc 68.7500 (76.2500) lr 1.1874e-03 eta 0:17:08
epoch [90/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 1.0352 (0.8673) acc 75.0000 (76.5625) lr 1.1874e-03 eta 0:12:26
epoch [90/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.5386 (0.8179) acc 90.6250 (78.5417) lr 1.1874e-03 eta 0:10:52
epoch [90/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.6558 (0.8135) acc 84.3750 (77.5000) lr 1.1874e-03 eta 0:10:06
epoch [90/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 1.0400 (0.8044) acc 71.8750 (77.6250) lr 1.1874e-03 eta 0:09:38
epoch [90/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.7671 (0.8033) acc 81.2500 (77.8125) lr 1.1874e-03 eta 0:09:19
epoch [90/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 1.2588 (0.8306) acc 65.6250 (77.0536) lr 1.1874e-03 eta 0:09:05
epoch [90/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7964 (0.8237) acc 78.1250 (77.5000) lr 1.1874e-03 eta 0:08:54
epoch [90/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.5874 (0.8038) acc 84.3750 (77.8472) lr 1.1874e-03 eta 0:08:45
epoch [90/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9717 (0.7908) acc 68.7500 (78.0625) lr 1.1719e-03 eta 0:08:38
epoch [91/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.109) loss 0.7485 (0.7355) acc 84.3750 (80.6250) lr 1.1719e-03 eta 0:17:44
epoch [91/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.055) loss 0.7563 (0.8207) acc 81.2500 (77.1875) lr 1.1719e-03 eta 0:12:43
epoch [91/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 0.7642 (0.8639) acc 78.1250 (76.2500) lr 1.1719e-03 eta 0:11:02
epoch [91/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 1.1885 (0.8785) acc 75.0000 (75.6250) lr 1.1719e-03 eta 0:10:11
epoch [91/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.6509 (0.8847) acc 78.1250 (75.2500) lr 1.1719e-03 eta 0:09:41
epoch [91/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.4888 (0.8637) acc 87.5000 (75.8333) lr 1.1719e-03 eta 0:09:20
epoch [91/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 1.3291 (0.8775) acc 71.8750 (75.6250) lr 1.1719e-03 eta 0:09:06
epoch [91/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5879 (0.8391) acc 81.2500 (76.2500) lr 1.1719e-03 eta 0:08:54
epoch [91/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7002 (0.8257) acc 78.1250 (76.4583) lr 1.1719e-03 eta 0:08:45
epoch [91/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7026 (0.8263) acc 78.1250 (76.4375) lr 1.1564e-03 eta 0:08:38
epoch [92/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.105) loss 1.7188 (1.0362) acc 59.3750 (74.3750) lr 1.1564e-03 eta 0:17:10
epoch [92/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.5869 (0.9116) acc 93.7500 (77.1875) lr 1.1564e-03 eta 0:12:24
epoch [92/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 1.1143 (0.9319) acc 65.6250 (75.4167) lr 1.1564e-03 eta 0:10:48
epoch [92/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 1.0342 (0.8948) acc 78.1250 (76.5625) lr 1.1564e-03 eta 0:10:00
epoch [92/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 1.1006 (0.8454) acc 75.0000 (77.8750) lr 1.1564e-03 eta 0:09:30
epoch [92/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 1.0605 (0.8267) acc 71.8750 (78.0208) lr 1.1564e-03 eta 0:09:11
epoch [92/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.8198 (0.8127) acc 81.2500 (78.3929) lr 1.1564e-03 eta 0:08:57
epoch [92/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.5342 (0.8213) acc 90.6250 (78.2812) lr 1.1564e-03 eta 0:08:46
epoch [92/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1279 (0.8057) acc 68.7500 (78.6111) lr 1.1564e-03 eta 0:08:37
epoch [92/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.8325 (0.8127) acc 75.0000 (78.3125) lr 1.1409e-03 eta 0:08:30
epoch [93/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.106) loss 1.1816 (0.8118) acc 68.7500 (76.8750) lr 1.1409e-03 eta 0:17:10
epoch [93/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.9395 (0.7215) acc 71.8750 (79.3750) lr 1.1409e-03 eta 0:12:22
epoch [93/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.8330 (0.7374) acc 81.2500 (79.3750) lr 1.1409e-03 eta 0:10:46
epoch [93/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 1.0576 (0.7766) acc 68.7500 (78.4375) lr 1.1409e-03 eta 0:09:58
epoch [93/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.9429 (0.7560) acc 68.7500 (78.6250) lr 1.1409e-03 eta 0:09:29
epoch [93/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 1.1572 (0.7595) acc 65.6250 (78.1250) lr 1.1409e-03 eta 0:09:09
epoch [93/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.015) loss 0.9077 (0.7931) acc 78.1250 (77.5893) lr 1.1409e-03 eta 0:08:55
epoch [93/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9185 (0.7849) acc 81.2500 (78.3594) lr 1.1409e-03 eta 0:08:43
epoch [93/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0488 (0.7878) acc 75.0000 (78.3333) lr 1.1409e-03 eta 0:08:34
epoch [93/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9360 (0.7801) acc 78.1250 (78.5625) lr 1.1253e-03 eta 0:08:27
epoch [94/200] batch [5/50] time 0.085 (0.180) data 0.000 (0.095) loss 1.1943 (0.8064) acc 71.8750 (81.2500) lr 1.1253e-03 eta 0:16:02
epoch [94/200] batch [10/50] time 0.086 (0.132) data 0.000 (0.048) loss 0.8887 (0.7876) acc 78.1250 (79.3750) lr 1.1253e-03 eta 0:11:44
epoch [94/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.032) loss 0.4646 (0.7785) acc 87.5000 (79.5833) lr 1.1253e-03 eta 0:10:18
epoch [94/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.8418 (0.7976) acc 71.8750 (78.4375) lr 1.1253e-03 eta 0:09:35
epoch [94/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.5674 (0.7914) acc 75.0000 (77.7500) lr 1.1253e-03 eta 0:09:09
epoch [94/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 0.8970 (0.7779) acc 71.8750 (77.9167) lr 1.1253e-03 eta 0:08:51
epoch [94/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.3486 (0.7792) acc 62.5000 (77.7679) lr 1.1253e-03 eta 0:08:39
epoch [94/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4382 (0.7751) acc 93.7500 (78.1250) lr 1.1253e-03 eta 0:08:28
epoch [94/200] batch [45/50] time 0.084 (0.094) data 0.000 (0.011) loss 0.7686 (0.7917) acc 78.1250 (78.0556) lr 1.1253e-03 eta 0:08:21
epoch [94/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.010) loss 0.8364 (0.7839) acc 75.0000 (78.2500) lr 1.1097e-03 eta 0:08:14
epoch [95/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.107) loss 0.9170 (0.7506) acc 71.8750 (76.8750) lr 1.1097e-03 eta 0:16:57
epoch [95/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.7471 (0.7582) acc 87.5000 (80.3125) lr 1.1097e-03 eta 0:12:11
epoch [95/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.036) loss 0.8789 (0.7635) acc 84.3750 (80.6250) lr 1.1097e-03 eta 0:10:38
epoch [95/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.9399 (0.7539) acc 78.1250 (80.7812) lr 1.1097e-03 eta 0:09:49
epoch [95/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.6138 (0.7588) acc 84.3750 (80.1250) lr 1.1097e-03 eta 0:09:20
epoch [95/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.5498 (0.7516) acc 87.5000 (79.5833) lr 1.1097e-03 eta 0:09:00
epoch [95/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.9546 (0.7718) acc 75.0000 (78.7500) lr 1.1097e-03 eta 0:08:46
epoch [95/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9141 (0.7835) acc 71.8750 (78.2031) lr 1.1097e-03 eta 0:08:35
epoch [95/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4133 (0.7802) acc 84.3750 (78.2639) lr 1.1097e-03 eta 0:08:26
epoch [95/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.3193 (0.7790) acc 68.7500 (78.4375) lr 1.0941e-03 eta 0:08:19
epoch [96/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.098) loss 0.7559 (0.7812) acc 81.2500 (81.2500) lr 1.0941e-03 eta 0:15:59
epoch [96/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 1.3115 (0.8360) acc 68.7500 (78.4375) lr 1.0941e-03 eta 0:11:40
epoch [96/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.3767 (0.7493) acc 90.6250 (78.3333) lr 1.0941e-03 eta 0:10:14
epoch [96/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.5986 (0.8177) acc 68.7500 (77.3438) lr 1.0941e-03 eta 0:09:30
epoch [96/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.8193 (0.8289) acc 81.2500 (77.5000) lr 1.0941e-03 eta 0:09:04
epoch [96/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.4229 (0.8286) acc 84.3750 (77.3958) lr 1.0941e-03 eta 0:08:46
epoch [96/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.6372 (0.8196) acc 75.0000 (76.7857) lr 1.0941e-03 eta 0:08:34
epoch [96/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.9019 (0.8132) acc 84.3750 (77.1875) lr 1.0941e-03 eta 0:08:24
epoch [96/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8159 (0.8289) acc 75.0000 (76.9444) lr 1.0941e-03 eta 0:08:15
epoch [96/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6055 (0.8131) acc 84.3750 (77.3125) lr 1.0785e-03 eta 0:08:09
epoch [97/200] batch [5/50] time 0.084 (0.179) data 0.000 (0.095) loss 0.7607 (0.8516) acc 81.2500 (80.0000) lr 1.0785e-03 eta 0:15:32
epoch [97/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.048) loss 0.3674 (0.7247) acc 87.5000 (82.5000) lr 1.0785e-03 eta 0:11:23
epoch [97/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 1.0000 (0.6909) acc 75.0000 (81.8750) lr 1.0785e-03 eta 0:10:00
epoch [97/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.5938 (0.6813) acc 90.6250 (82.3438) lr 1.0785e-03 eta 0:09:19
epoch [97/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 1.0303 (0.6798) acc 81.2500 (82.8750) lr 1.0785e-03 eta 0:08:54
epoch [97/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.3728 (0.6843) acc 90.6250 (82.5000) lr 1.0785e-03 eta 0:08:37
epoch [97/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.7446 (0.6790) acc 84.3750 (82.6786) lr 1.0785e-03 eta 0:08:25
epoch [97/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1152 (0.7124) acc 68.7500 (81.5625) lr 1.0785e-03 eta 0:08:15
epoch [97/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8853 (0.7519) acc 78.1250 (80.4167) lr 1.0785e-03 eta 0:08:07
epoch [97/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.1592 (0.7587) acc 62.5000 (80.1250) lr 1.0628e-03 eta 0:08:01
epoch [98/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.094) loss 0.7271 (0.7772) acc 78.1250 (77.5000) lr 1.0628e-03 eta 0:15:23
epoch [98/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.9468 (0.8017) acc 78.1250 (77.8125) lr 1.0628e-03 eta 0:11:18
epoch [98/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.031) loss 0.8271 (0.7085) acc 78.1250 (80.2083) lr 1.0628e-03 eta 0:09:55
epoch [98/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.8032 (0.7180) acc 84.3750 (80.3125) lr 1.0628e-03 eta 0:09:14
epoch [98/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.6479 (0.7280) acc 87.5000 (81.0000) lr 1.0628e-03 eta 0:08:48
epoch [98/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7637 (0.7383) acc 71.8750 (80.2083) lr 1.0628e-03 eta 0:08:32
epoch [98/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6167 (0.7311) acc 75.0000 (79.8214) lr 1.0628e-03 eta 0:08:20
epoch [98/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6079 (0.7300) acc 81.2500 (79.6875) lr 1.0628e-03 eta 0:08:10
epoch [98/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0000 (0.7435) acc 59.3750 (78.9583) lr 1.0628e-03 eta 0:08:02
epoch [98/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.8320 (0.7476) acc 71.8750 (78.7500) lr 1.0471e-03 eta 0:07:56
epoch [99/200] batch [5/50] time 0.083 (0.184) data 0.000 (0.100) loss 1.4023 (0.8570) acc 65.6250 (78.7500) lr 1.0471e-03 eta 0:15:38
epoch [99/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.050) loss 0.4565 (0.7376) acc 87.5000 (80.0000) lr 1.0471e-03 eta 0:11:24
epoch [99/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 1.0029 (0.6726) acc 68.7500 (81.8750) lr 1.0471e-03 eta 0:09:59
epoch [99/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.5898 (0.7079) acc 84.3750 (80.4688) lr 1.0471e-03 eta 0:09:16
epoch [99/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.4929 (0.6918) acc 84.3750 (81.0000) lr 1.0471e-03 eta 0:08:50
epoch [99/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.7798 (0.7130) acc 78.1250 (80.1042) lr 1.0471e-03 eta 0:08:33
epoch [99/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6758 (0.7276) acc 81.2500 (79.8214) lr 1.0471e-03 eta 0:08:20
epoch [99/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.5771 (0.7131) acc 81.2500 (80.0781) lr 1.0471e-03 eta 0:08:10
epoch [99/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0459 (0.7126) acc 71.8750 (80.1389) lr 1.0471e-03 eta 0:08:02
epoch [99/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9355 (0.7240) acc 71.8750 (79.9375) lr 1.0314e-03 eta 0:07:55
epoch [100/200] batch [5/50] time 0.084 (0.185) data 0.000 (0.100) loss 0.7080 (0.8591) acc 78.1250 (75.6250) lr 1.0314e-03 eta 0:15:34
epoch [100/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.4521 (0.7634) acc 78.1250 (77.5000) lr 1.0314e-03 eta 0:11:17
epoch [100/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.9268 (0.7813) acc 81.2500 (76.8750) lr 1.0314e-03 eta 0:09:53
epoch [100/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.6245 (0.7811) acc 81.2500 (77.9688) lr 1.0314e-03 eta 0:09:10
epoch [100/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.2783 (0.7989) acc 59.3750 (77.3750) lr 1.0314e-03 eta 0:08:44
epoch [100/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 1.0859 (0.7884) acc 71.8750 (77.8125) lr 1.0314e-03 eta 0:08:27
epoch [100/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.6348 (0.7635) acc 78.1250 (78.3036) lr 1.0314e-03 eta 0:08:14
epoch [100/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7437 (0.7744) acc 81.2500 (77.7344) lr 1.0314e-03 eta 0:08:04
epoch [100/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7104 (0.7740) acc 84.3750 (77.7083) lr 1.0314e-03 eta 0:07:56
epoch [100/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.5215 (0.7601) acc 87.5000 (78.2500) lr 1.0157e-03 eta 0:07:49
epoch [101/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.097) loss 0.3313 (0.9002) acc 96.8750 (77.5000) lr 1.0157e-03 eta 0:15:14
epoch [101/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.8550 (0.7882) acc 71.8750 (79.6875) lr 1.0157e-03 eta 0:11:07
epoch [101/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 0.9761 (0.8606) acc 75.0000 (78.3333) lr 1.0157e-03 eta 0:09:44
epoch [101/200] batch [20/50] time 0.087 (0.109) data 0.000 (0.025) loss 1.2588 (0.8601) acc 71.8750 (77.0312) lr 1.0157e-03 eta 0:09:03
epoch [101/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.3911 (0.8132) acc 87.5000 (77.3750) lr 1.0157e-03 eta 0:08:38
epoch [101/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.4849 (0.7958) acc 87.5000 (78.4375) lr 1.0157e-03 eta 0:08:21
epoch [101/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.8208 (0.7959) acc 75.0000 (78.4821) lr 1.0157e-03 eta 0:08:09
epoch [101/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.9912 (0.8029) acc 71.8750 (78.5938) lr 1.0157e-03 eta 0:07:59
epoch [101/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0303 (0.8060) acc 75.0000 (78.4722) lr 1.0157e-03 eta 0:07:51
epoch [101/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9316 (0.7980) acc 75.0000 (78.8125) lr 1.0000e-03 eta 0:07:45
epoch [102/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.102) loss 0.6230 (0.7151) acc 84.3750 (83.1250) lr 1.0000e-03 eta 0:15:19
epoch [102/200] batch [10/50] time 0.083 (0.135) data 0.000 (0.051) loss 0.9829 (0.7862) acc 78.1250 (81.2500) lr 1.0000e-03 eta 0:11:07
epoch [102/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.034) loss 0.7651 (0.8640) acc 75.0000 (78.5417) lr 1.0000e-03 eta 0:09:42
epoch [102/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.026) loss 0.5854 (0.8105) acc 84.3750 (79.5312) lr 1.0000e-03 eta 0:08:59
epoch [102/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.021) loss 0.6396 (0.7861) acc 75.0000 (79.6250) lr 1.0000e-03 eta 0:08:34
epoch [102/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.2070 (0.7872) acc 75.0000 (79.4792) lr 1.0000e-03 eta 0:08:16
epoch [102/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.015) loss 1.0576 (0.7892) acc 71.8750 (78.6607) lr 1.0000e-03 eta 0:08:04
epoch [102/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.9702 (0.8183) acc 68.7500 (77.8125) lr 1.0000e-03 eta 0:07:54
epoch [102/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.012) loss 0.9380 (0.8140) acc 78.1250 (77.7083) lr 1.0000e-03 eta 0:07:46
epoch [102/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8516 (0.8029) acc 84.3750 (78.3750) lr 9.8429e-04 eta 0:07:40
epoch [103/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.107) loss 0.8721 (0.7780) acc 81.2500 (78.1250) lr 9.8429e-04 eta 0:15:38
epoch [103/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.5615 (0.7864) acc 87.5000 (77.8125) lr 9.8429e-04 eta 0:11:15
epoch [103/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.6143 (0.7810) acc 84.3750 (78.7500) lr 9.8429e-04 eta 0:09:48
epoch [103/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.3198 (0.7597) acc 93.7500 (79.3750) lr 9.8429e-04 eta 0:09:03
epoch [103/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.5493 (0.7687) acc 84.3750 (78.7500) lr 9.8429e-04 eta 0:08:37
epoch [103/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.5254 (0.7620) acc 84.3750 (79.0625) lr 9.8429e-04 eta 0:08:19
epoch [103/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.4360 (0.7487) acc 87.5000 (79.1964) lr 9.8429e-04 eta 0:08:06
epoch [103/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7925 (0.7525) acc 84.3750 (79.0625) lr 9.8429e-04 eta 0:07:55
epoch [103/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.3076 (0.7541) acc 93.7500 (79.4444) lr 9.8429e-04 eta 0:07:47
epoch [103/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4976 (0.7529) acc 78.1250 (79.2500) lr 9.6859e-04 eta 0:07:40
epoch [104/200] batch [5/50] time 0.083 (0.184) data 0.000 (0.100) loss 0.5679 (0.8430) acc 81.2500 (76.8750) lr 9.6859e-04 eta 0:14:53
epoch [104/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.3860 (0.6857) acc 90.6250 (81.5625) lr 9.6859e-04 eta 0:10:49
epoch [104/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.034) loss 0.7817 (0.7032) acc 78.1250 (81.0417) lr 9.6859e-04 eta 0:09:28
epoch [104/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.9263 (0.7196) acc 75.0000 (80.3125) lr 9.6859e-04 eta 0:08:47
epoch [104/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7720 (0.7306) acc 78.1250 (79.8750) lr 9.6859e-04 eta 0:08:23
epoch [104/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.5645 (0.7405) acc 78.1250 (79.7917) lr 9.6859e-04 eta 0:08:06
epoch [104/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.6890 (0.7194) acc 84.3750 (80.4464) lr 9.6859e-04 eta 0:07:54
epoch [104/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9463 (0.7404) acc 78.1250 (80.0781) lr 9.6859e-04 eta 0:07:44
epoch [104/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7021 (0.7518) acc 78.1250 (79.8611) lr 9.6859e-04 eta 0:07:36
epoch [104/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.3118 (0.7450) acc 90.6250 (80.0000) lr 9.5289e-04 eta 0:07:30
epoch [105/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.094) loss 0.9346 (0.9149) acc 78.1250 (77.5000) lr 9.5289e-04 eta 0:14:22
epoch [105/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.047) loss 0.5420 (0.7263) acc 81.2500 (80.9375) lr 9.5289e-04 eta 0:10:34
epoch [105/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.031) loss 0.5283 (0.7153) acc 87.5000 (81.2500) lr 9.5289e-04 eta 0:09:17
epoch [105/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.9536 (0.6996) acc 75.0000 (81.4062) lr 9.5289e-04 eta 0:08:39
epoch [105/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 1.1465 (0.7182) acc 71.8750 (80.7500) lr 9.5289e-04 eta 0:08:16
epoch [105/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.3760 (0.7286) acc 90.6250 (80.5208) lr 9.5289e-04 eta 0:08:00
epoch [105/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8193 (0.7272) acc 75.0000 (80.3571) lr 9.5289e-04 eta 0:07:49
epoch [105/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0498 (0.7457) acc 68.7500 (80.0000) lr 9.5289e-04 eta 0:07:39
epoch [105/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6323 (0.7510) acc 78.1250 (79.9306) lr 9.5289e-04 eta 0:07:32
epoch [105/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.2217 (0.7852) acc 68.7500 (79.1250) lr 9.3721e-04 eta 0:07:26
epoch [106/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.099) loss 0.7510 (0.8348) acc 78.1250 (79.3750) lr 9.3721e-04 eta 0:14:29
epoch [106/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.4519 (0.6880) acc 84.3750 (80.9375) lr 9.3721e-04 eta 0:10:32
epoch [106/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 0.7783 (0.7164) acc 75.0000 (79.7917) lr 9.3721e-04 eta 0:09:14
epoch [106/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 1.6240 (0.7267) acc 62.5000 (80.0000) lr 9.3721e-04 eta 0:08:34
epoch [106/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.5107 (0.7312) acc 68.7500 (80.5000) lr 9.3721e-04 eta 0:08:10
epoch [106/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6987 (0.7341) acc 81.2500 (80.2083) lr 9.3721e-04 eta 0:07:54
epoch [106/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4265 (0.7226) acc 90.6250 (80.6250) lr 9.3721e-04 eta 0:07:42
epoch [106/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 0.7070 (0.7452) acc 78.1250 (80.1562) lr 9.3721e-04 eta 0:07:33
epoch [106/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7808 (0.7508) acc 81.2500 (80.4167) lr 9.3721e-04 eta 0:07:26
epoch [106/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6260 (0.7536) acc 78.1250 (80.1250) lr 9.2154e-04 eta 0:07:20
epoch [107/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.095) loss 1.0898 (0.7990) acc 71.8750 (78.7500) lr 9.2154e-04 eta 0:14:07
epoch [107/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.047) loss 0.7871 (0.8440) acc 78.1250 (76.8750) lr 9.2154e-04 eta 0:10:21
epoch [107/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.6558 (0.8072) acc 81.2500 (77.2917) lr 9.2154e-04 eta 0:09:06
epoch [107/200] batch [20/50] time 0.085 (0.109) data 0.001 (0.024) loss 0.6562 (0.8223) acc 87.5000 (77.1875) lr 9.2154e-04 eta 0:08:28
epoch [107/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 1.2275 (0.8099) acc 71.8750 (77.7500) lr 9.2154e-04 eta 0:08:05
epoch [107/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.6001 (0.8121) acc 81.2500 (77.5000) lr 9.2154e-04 eta 0:07:49
epoch [107/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.3872 (0.7857) acc 90.6250 (78.1250) lr 9.2154e-04 eta 0:07:38
epoch [107/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 1.0645 (0.7688) acc 68.7500 (78.2031) lr 9.2154e-04 eta 0:07:29
epoch [107/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.3413 (0.7580) acc 90.6250 (78.4028) lr 9.2154e-04 eta 0:07:22
epoch [107/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6099 (0.7611) acc 84.3750 (78.3750) lr 9.0589e-04 eta 0:07:16
epoch [108/200] batch [5/50] time 0.083 (0.191) data 0.000 (0.106) loss 0.9399 (0.8147) acc 68.7500 (78.1250) lr 9.0589e-04 eta 0:14:46
epoch [108/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.7139 (0.7236) acc 78.1250 (80.3125) lr 9.0589e-04 eta 0:10:37
epoch [108/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.6470 (0.6671) acc 78.1250 (81.0417) lr 9.0589e-04 eta 0:09:14
epoch [108/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.6270 (0.6913) acc 81.2500 (80.3125) lr 9.0589e-04 eta 0:08:32
epoch [108/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.4045 (0.7041) acc 87.5000 (80.0000) lr 9.0589e-04 eta 0:08:07
epoch [108/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6777 (0.7317) acc 81.2500 (79.6875) lr 9.0589e-04 eta 0:07:50
epoch [108/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6230 (0.7069) acc 87.5000 (80.6250) lr 9.0589e-04 eta 0:07:38
epoch [108/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0938 (0.7167) acc 78.1250 (80.5469) lr 9.0589e-04 eta 0:07:28
epoch [108/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7939 (0.7378) acc 90.6250 (80.4167) lr 9.0589e-04 eta 0:07:20
epoch [108/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7314 (0.7215) acc 78.1250 (80.6250) lr 8.9027e-04 eta 0:07:14
epoch [109/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.100) loss 0.8496 (0.7570) acc 71.8750 (78.7500) lr 8.9027e-04 eta 0:14:06
epoch [109/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 1.0098 (0.8075) acc 78.1250 (78.4375) lr 8.9027e-04 eta 0:10:15
epoch [109/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 1.0723 (0.8371) acc 65.6250 (76.8750) lr 8.9027e-04 eta 0:08:58
epoch [109/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.4910 (0.7734) acc 84.3750 (78.9062) lr 8.9027e-04 eta 0:08:20
epoch [109/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.4756 (0.7417) acc 84.3750 (80.0000) lr 8.9027e-04 eta 0:07:57
epoch [109/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.017) loss 0.7554 (0.7653) acc 81.2500 (79.6875) lr 8.9027e-04 eta 0:07:41
epoch [109/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.014) loss 1.0449 (0.7825) acc 81.2500 (78.8393) lr 8.9027e-04 eta 0:07:29
epoch [109/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9248 (0.7722) acc 75.0000 (78.7500) lr 8.9027e-04 eta 0:07:20
epoch [109/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9604 (0.7735) acc 65.6250 (78.5417) lr 8.9027e-04 eta 0:07:13
epoch [109/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.4048 (0.7722) acc 90.6250 (78.5000) lr 8.7467e-04 eta 0:07:07
epoch [110/200] batch [5/50] time 0.085 (0.181) data 0.000 (0.095) loss 0.9678 (0.7133) acc 75.0000 (79.3750) lr 8.7467e-04 eta 0:13:41
epoch [110/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.047) loss 0.8418 (0.7339) acc 78.1250 (79.6875) lr 8.7467e-04 eta 0:10:01
epoch [110/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.6021 (0.7537) acc 81.2500 (80.4167) lr 8.7467e-04 eta 0:08:48
epoch [110/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.9380 (0.7771) acc 71.8750 (79.8438) lr 8.7467e-04 eta 0:08:11
epoch [110/200] batch [25/50] time 0.083 (0.104) data 0.000 (0.019) loss 0.8359 (0.7878) acc 78.1250 (79.7500) lr 8.7467e-04 eta 0:07:48
epoch [110/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 1.4609 (0.8133) acc 62.5000 (78.8542) lr 8.7467e-04 eta 0:07:34
epoch [110/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.6318 (0.7903) acc 84.3750 (79.7321) lr 8.7467e-04 eta 0:07:23
epoch [110/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7319 (0.7917) acc 75.0000 (79.7656) lr 8.7467e-04 eta 0:07:14
epoch [110/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7832 (0.7868) acc 81.2500 (79.5833) lr 8.7467e-04 eta 0:07:07
epoch [110/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7388 (0.7803) acc 78.1250 (79.6875) lr 8.5910e-04 eta 0:07:01
epoch [111/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.094) loss 1.1602 (0.6322) acc 71.8750 (83.1250) lr 8.5910e-04 eta 0:13:23
epoch [111/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 1.0898 (0.6851) acc 68.7500 (79.0625) lr 8.5910e-04 eta 0:09:50
epoch [111/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.031) loss 0.7886 (0.7490) acc 78.1250 (77.9167) lr 8.5910e-04 eta 0:08:39
epoch [111/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.8511 (0.7391) acc 75.0000 (78.2812) lr 8.5910e-04 eta 0:08:03
epoch [111/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.8218 (0.7223) acc 75.0000 (79.0000) lr 8.5910e-04 eta 0:07:42
epoch [111/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.7539 (0.7575) acc 75.0000 (78.1250) lr 8.5910e-04 eta 0:07:28
epoch [111/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 0.9595 (0.7556) acc 81.2500 (78.4821) lr 8.5910e-04 eta 0:07:17
epoch [111/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7036 (0.7781) acc 78.1250 (78.1250) lr 8.5910e-04 eta 0:07:09
epoch [111/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.1162 (0.7877) acc 65.6250 (77.7778) lr 8.5910e-04 eta 0:07:02
epoch [111/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9170 (0.7920) acc 75.0000 (77.5000) lr 8.4357e-04 eta 0:06:57
epoch [112/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 1.0752 (0.6971) acc 71.8750 (82.5000) lr 8.4357e-04 eta 0:13:37
epoch [112/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 1.0576 (0.8334) acc 71.8750 (78.4375) lr 8.4357e-04 eta 0:09:54
epoch [112/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.5864 (0.8003) acc 78.1250 (78.5417) lr 8.4357e-04 eta 0:08:40
epoch [112/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.5615 (0.8033) acc 84.3750 (78.1250) lr 8.4357e-04 eta 0:08:03
epoch [112/200] batch [25/50] time 0.086 (0.104) data 0.000 (0.020) loss 0.5464 (0.7657) acc 87.5000 (79.6250) lr 8.4357e-04 eta 0:07:42
epoch [112/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.8916 (0.7920) acc 84.3750 (78.7500) lr 8.4357e-04 eta 0:07:27
epoch [112/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 1.0420 (0.7907) acc 68.7500 (78.3036) lr 8.4357e-04 eta 0:07:16
epoch [112/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9326 (0.7811) acc 71.8750 (78.7500) lr 8.4357e-04 eta 0:07:07
epoch [112/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.8462 (0.7785) acc 78.1250 (78.8194) lr 8.4357e-04 eta 0:07:01
epoch [112/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.1602 (0.7834) acc 65.6250 (78.4375) lr 8.2807e-04 eta 0:06:55
epoch [113/200] batch [5/50] time 0.086 (0.192) data 0.001 (0.105) loss 0.7344 (0.8659) acc 78.1250 (76.2500) lr 8.2807e-04 eta 0:14:02
epoch [113/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.9326 (0.8273) acc 78.1250 (75.6250) lr 8.2807e-04 eta 0:10:07
epoch [113/200] batch [15/50] time 0.085 (0.121) data 0.000 (0.035) loss 0.6792 (0.8117) acc 84.3750 (77.0833) lr 8.2807e-04 eta 0:08:48
epoch [113/200] batch [20/50] time 0.086 (0.112) data 0.000 (0.027) loss 1.0283 (0.7697) acc 68.7500 (78.1250) lr 8.2807e-04 eta 0:08:09
epoch [113/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.7793 (0.7746) acc 81.2500 (78.6250) lr 8.2807e-04 eta 0:07:45
epoch [113/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.5918 (0.7531) acc 87.5000 (79.5833) lr 8.2807e-04 eta 0:07:28
epoch [113/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.6855 (0.7410) acc 84.3750 (79.8214) lr 8.2807e-04 eta 0:07:16
epoch [113/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.5303 (0.7447) acc 87.5000 (79.5312) lr 8.2807e-04 eta 0:07:07
epoch [113/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7905 (0.7512) acc 84.3750 (79.5139) lr 8.2807e-04 eta 0:06:59
epoch [113/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.2754 (0.7450) acc 87.5000 (79.6875) lr 8.1262e-04 eta 0:06:53
epoch [114/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.6470 (0.7990) acc 81.2500 (76.8750) lr 8.1262e-04 eta 0:13:05
epoch [114/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.048) loss 0.5098 (0.7210) acc 84.3750 (80.0000) lr 8.1262e-04 eta 0:09:34
epoch [114/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.032) loss 0.5913 (0.6635) acc 75.0000 (81.2500) lr 8.1262e-04 eta 0:08:24
epoch [114/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.5840 (0.6806) acc 87.5000 (81.7188) lr 8.1262e-04 eta 0:07:48
epoch [114/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.6489 (0.7153) acc 87.5000 (81.0000) lr 8.1262e-04 eta 0:07:27
epoch [114/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.3865 (0.7125) acc 90.6250 (81.2500) lr 8.1262e-04 eta 0:07:13
epoch [114/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 1.0176 (0.7185) acc 71.8750 (80.9821) lr 8.1262e-04 eta 0:07:02
epoch [114/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7124 (0.7305) acc 75.0000 (80.1562) lr 8.1262e-04 eta 0:06:54
epoch [114/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4419 (0.7191) acc 93.7500 (80.3472) lr 8.1262e-04 eta 0:06:47
epoch [114/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6001 (0.7214) acc 78.1250 (80.0625) lr 7.9721e-04 eta 0:06:42
epoch [115/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.105) loss 0.6025 (0.6553) acc 87.5000 (81.8750) lr 7.9721e-04 eta 0:13:36
epoch [115/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.6294 (0.7154) acc 81.2500 (80.0000) lr 7.9721e-04 eta 0:09:48
epoch [115/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.035) loss 0.7651 (0.6960) acc 81.2500 (81.2500) lr 7.9721e-04 eta 0:08:32
epoch [115/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.4712 (0.6937) acc 84.3750 (81.2500) lr 7.9721e-04 eta 0:07:54
epoch [115/200] batch [25/50] time 0.083 (0.105) data 0.000 (0.021) loss 0.6118 (0.7205) acc 84.3750 (81.1250) lr 7.9721e-04 eta 0:07:30
epoch [115/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.5078 (0.7155) acc 90.6250 (81.6667) lr 7.9721e-04 eta 0:07:14
epoch [115/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 1.1904 (0.7277) acc 75.0000 (81.2500) lr 7.9721e-04 eta 0:07:03
epoch [115/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8677 (0.7224) acc 81.2500 (81.7969) lr 7.9721e-04 eta 0:06:54
epoch [115/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5542 (0.7155) acc 78.1250 (81.5278) lr 7.9721e-04 eta 0:06:47
epoch [115/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.3157 (0.7180) acc 87.5000 (81.4375) lr 7.8186e-04 eta 0:06:41
epoch [116/200] batch [5/50] time 0.085 (0.199) data 0.000 (0.113) loss 0.6548 (0.8589) acc 87.5000 (78.1250) lr 7.8186e-04 eta 0:14:04
epoch [116/200] batch [10/50] time 0.085 (0.142) data 0.000 (0.057) loss 0.7334 (0.8134) acc 71.8750 (78.1250) lr 7.8186e-04 eta 0:10:01
epoch [116/200] batch [15/50] time 0.084 (0.123) data 0.000 (0.038) loss 0.4397 (0.7961) acc 87.5000 (78.5417) lr 7.8186e-04 eta 0:08:39
epoch [116/200] batch [20/50] time 0.084 (0.113) data 0.000 (0.029) loss 0.6558 (0.7802) acc 78.1250 (78.5938) lr 7.8186e-04 eta 0:07:58
epoch [116/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.023) loss 1.0664 (0.7711) acc 71.8750 (78.5000) lr 7.8186e-04 eta 0:07:33
epoch [116/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.7998 (0.7722) acc 78.1250 (78.0208) lr 7.8186e-04 eta 0:07:17
epoch [116/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.5049 (0.7761) acc 87.5000 (78.3036) lr 7.8186e-04 eta 0:07:05
epoch [116/200] batch [40/50] time 0.083 (0.099) data 0.000 (0.014) loss 0.9761 (0.7889) acc 71.8750 (78.0469) lr 7.8186e-04 eta 0:06:55
epoch [116/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6465 (0.7558) acc 87.5000 (79.1667) lr 7.8186e-04 eta 0:06:47
epoch [116/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.6011 (0.7550) acc 81.2500 (78.9375) lr 7.6655e-04 eta 0:06:41
epoch [117/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.5923 (0.6066) acc 84.3750 (82.5000) lr 7.6655e-04 eta 0:12:56
epoch [117/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.5488 (0.6113) acc 84.3750 (82.5000) lr 7.6655e-04 eta 0:09:25
epoch [117/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.4158 (0.5902) acc 84.3750 (82.9167) lr 7.6655e-04 eta 0:08:14
epoch [117/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.7617 (0.6278) acc 75.0000 (81.4062) lr 7.6655e-04 eta 0:07:39
epoch [117/200] batch [25/50] time 0.087 (0.105) data 0.000 (0.020) loss 0.6328 (0.6726) acc 84.3750 (80.8750) lr 7.6655e-04 eta 0:07:18
epoch [117/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.4551 (0.6534) acc 90.6250 (81.9792) lr 7.6655e-04 eta 0:07:03
epoch [117/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.014) loss 0.9155 (0.6645) acc 81.2500 (81.7857) lr 7.6655e-04 eta 0:06:52
epoch [117/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6562 (0.6779) acc 81.2500 (81.5625) lr 7.6655e-04 eta 0:06:44
epoch [117/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.9741 (0.7022) acc 71.8750 (80.9722) lr 7.6655e-04 eta 0:06:37
epoch [117/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9268 (0.7106) acc 71.8750 (80.6875) lr 7.5131e-04 eta 0:06:31
epoch [118/200] batch [5/50] time 0.084 (0.179) data 0.000 (0.094) loss 0.4792 (0.5950) acc 87.5000 (83.7500) lr 7.5131e-04 eta 0:12:20
epoch [118/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.5151 (0.5918) acc 81.2500 (82.8125) lr 7.5131e-04 eta 0:09:03
epoch [118/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.031) loss 0.8569 (0.6314) acc 87.5000 (83.7500) lr 7.5131e-04 eta 0:07:57
epoch [118/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.6968 (0.6401) acc 78.1250 (82.9688) lr 7.5131e-04 eta 0:07:24
epoch [118/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.4194 (0.6552) acc 93.7500 (83.0000) lr 7.5131e-04 eta 0:07:04
epoch [118/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.5137 (0.6424) acc 84.3750 (83.2292) lr 7.5131e-04 eta 0:06:51
epoch [118/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.1279 (0.6585) acc 75.0000 (82.8571) lr 7.5131e-04 eta 0:06:41
epoch [118/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7627 (0.6597) acc 90.6250 (83.1250) lr 7.5131e-04 eta 0:06:33
epoch [118/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.7104 (0.6890) acc 81.2500 (82.2917) lr 7.5131e-04 eta 0:06:27
epoch [118/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 1.1025 (0.6997) acc 68.7500 (81.6250) lr 7.3613e-04 eta 0:06:22
epoch [119/200] batch [5/50] time 0.084 (0.194) data 0.000 (0.109) loss 1.0391 (0.8050) acc 68.7500 (76.2500) lr 7.3613e-04 eta 0:13:14
epoch [119/200] batch [10/50] time 0.084 (0.139) data 0.000 (0.055) loss 0.6665 (0.7412) acc 84.3750 (78.4375) lr 7.3613e-04 eta 0:09:29
epoch [119/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 0.3149 (0.7174) acc 93.7500 (79.5833) lr 7.3613e-04 eta 0:08:14
epoch [119/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.7393 (0.7160) acc 78.1250 (79.5312) lr 7.3613e-04 eta 0:07:36
epoch [119/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 0.4529 (0.7002) acc 81.2500 (79.5000) lr 7.3613e-04 eta 0:07:14
epoch [119/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 1.1465 (0.7428) acc 71.8750 (78.6458) lr 7.3613e-04 eta 0:06:58
epoch [119/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7246 (0.7624) acc 78.1250 (78.2143) lr 7.3613e-04 eta 0:06:47
epoch [119/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6255 (0.7835) acc 81.2500 (77.8125) lr 7.3613e-04 eta 0:06:38
epoch [119/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.3193 (0.7708) acc 87.5000 (78.1250) lr 7.3613e-04 eta 0:06:31
epoch [119/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4836 (0.7740) acc 84.3750 (78.1875) lr 7.2101e-04 eta 0:06:25
epoch [120/200] batch [5/50] time 0.083 (0.180) data 0.000 (0.095) loss 0.6602 (0.6113) acc 84.3750 (85.6250) lr 7.2101e-04 eta 0:12:09
epoch [120/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.048) loss 0.9941 (0.7334) acc 68.7500 (81.2500) lr 7.2101e-04 eta 0:08:55
epoch [120/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.3752 (0.6963) acc 87.5000 (81.4583) lr 7.2101e-04 eta 0:07:50
epoch [120/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.8818 (0.7196) acc 59.3750 (80.0000) lr 7.2101e-04 eta 0:07:17
epoch [120/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.6660 (0.7095) acc 84.3750 (80.2500) lr 7.2101e-04 eta 0:06:58
epoch [120/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.7046 (0.7146) acc 78.1250 (80.0000) lr 7.2101e-04 eta 0:06:44
epoch [120/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7441 (0.7168) acc 84.3750 (80.5357) lr 7.2101e-04 eta 0:06:35
epoch [120/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.9102 (0.7241) acc 75.0000 (80.3906) lr 7.2101e-04 eta 0:06:27
epoch [120/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9106 (0.7267) acc 78.1250 (79.9306) lr 7.2101e-04 eta 0:06:20
epoch [120/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8965 (0.7318) acc 75.0000 (79.6875) lr 7.0596e-04 eta 0:06:15
epoch [121/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 1.0391 (0.8522) acc 71.8750 (77.5000) lr 7.0596e-04 eta 0:12:06
epoch [121/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.8496 (0.8163) acc 78.1250 (76.8750) lr 7.0596e-04 eta 0:08:51
epoch [121/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.6445 (0.6922) acc 81.2500 (81.0417) lr 7.0596e-04 eta 0:07:45
epoch [121/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.024) loss 0.7456 (0.7333) acc 84.3750 (80.3125) lr 7.0596e-04 eta 0:07:12
epoch [121/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.8574 (0.7458) acc 81.2500 (80.0000) lr 7.0596e-04 eta 0:06:52
epoch [121/200] batch [30/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.3333 (0.7523) acc 93.7500 (80.2083) lr 7.0596e-04 eta 0:06:38
epoch [121/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4956 (0.7540) acc 87.5000 (80.0000) lr 7.0596e-04 eta 0:06:28
epoch [121/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0088 (0.7509) acc 81.2500 (80.0781) lr 7.0596e-04 eta 0:06:21
epoch [121/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8516 (0.7629) acc 71.8750 (79.6528) lr 7.0596e-04 eta 0:06:15
epoch [121/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.1592 (0.7625) acc 68.7500 (79.9375) lr 6.9098e-04 eta 0:06:10
epoch [122/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.107) loss 0.7881 (0.8004) acc 75.0000 (80.0000) lr 6.9098e-04 eta 0:12:38
epoch [122/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.6299 (0.7495) acc 81.2500 (80.0000) lr 6.9098e-04 eta 0:09:04
epoch [122/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.6704 (0.7388) acc 84.3750 (80.0000) lr 6.9098e-04 eta 0:07:53
epoch [122/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.7832 (0.7142) acc 78.1250 (80.0000) lr 6.9098e-04 eta 0:07:17
epoch [122/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.6851 (0.6949) acc 78.1250 (81.0000) lr 6.9098e-04 eta 0:06:55
epoch [122/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.3860 (0.6593) acc 90.6250 (81.8750) lr 6.9098e-04 eta 0:06:41
epoch [122/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7065 (0.6647) acc 78.1250 (81.6964) lr 6.9098e-04 eta 0:06:30
epoch [122/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 1.1133 (0.6663) acc 78.1250 (81.5625) lr 6.9098e-04 eta 0:06:21
epoch [122/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9907 (0.6773) acc 78.1250 (81.2500) lr 6.9098e-04 eta 0:06:15
epoch [122/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6851 (0.6814) acc 81.2500 (81.1875) lr 6.7608e-04 eta 0:06:09
epoch [123/200] batch [5/50] time 0.085 (0.181) data 0.000 (0.095) loss 0.4114 (0.5555) acc 93.7500 (86.2500) lr 6.7608e-04 eta 0:11:46
epoch [123/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 1.3125 (0.8004) acc 62.5000 (80.0000) lr 6.7608e-04 eta 0:08:36
epoch [123/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 1.2109 (0.8534) acc 75.0000 (78.5417) lr 6.7608e-04 eta 0:07:33
epoch [123/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.7085 (0.8106) acc 78.1250 (78.9062) lr 6.7608e-04 eta 0:07:01
epoch [123/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.019) loss 0.5796 (0.7883) acc 81.2500 (79.1250) lr 6.7608e-04 eta 0:06:42
epoch [123/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.6797 (0.7816) acc 84.3750 (79.2708) lr 6.7608e-04 eta 0:06:29
epoch [123/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6548 (0.7816) acc 78.1250 (79.4643) lr 6.7608e-04 eta 0:06:20
epoch [123/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4375 (0.7569) acc 78.1250 (80.0000) lr 6.7608e-04 eta 0:06:12
epoch [123/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.8037 (0.7577) acc 81.2500 (80.1389) lr 6.7608e-04 eta 0:06:06
epoch [123/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7251 (0.7539) acc 84.3750 (80.5000) lr 6.6126e-04 eta 0:06:01
epoch [124/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 0.8740 (0.7884) acc 78.1250 (80.0000) lr 6.6126e-04 eta 0:11:46
epoch [124/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.9536 (0.8434) acc 65.6250 (77.1875) lr 6.6126e-04 eta 0:08:34
epoch [124/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.5571 (0.7862) acc 84.3750 (78.5417) lr 6.6126e-04 eta 0:07:29
epoch [124/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 0.6455 (0.7235) acc 84.3750 (80.3125) lr 6.6126e-04 eta 0:06:57
epoch [124/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.8853 (0.7440) acc 68.7500 (78.7500) lr 6.6126e-04 eta 0:06:37
epoch [124/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.017) loss 1.0732 (0.7669) acc 68.7500 (78.5417) lr 6.6126e-04 eta 0:06:23
epoch [124/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.4143 (0.7628) acc 90.6250 (78.9286) lr 6.6126e-04 eta 0:06:14
epoch [124/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 0.5396 (0.7830) acc 90.6250 (78.1250) lr 6.6126e-04 eta 0:06:06
epoch [124/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8926 (0.7725) acc 75.0000 (78.6111) lr 6.6126e-04 eta 0:06:00
epoch [124/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7671 (0.7719) acc 75.0000 (78.7500) lr 6.4653e-04 eta 0:05:55
epoch [125/200] batch [5/50] time 0.085 (0.178) data 0.000 (0.093) loss 0.6851 (0.7320) acc 78.1250 (77.5000) lr 6.4653e-04 eta 0:11:16
epoch [125/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.6113 (0.7628) acc 81.2500 (78.4375) lr 6.4653e-04 eta 0:08:17
epoch [125/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.031) loss 1.0771 (0.7531) acc 71.8750 (79.3750) lr 6.4653e-04 eta 0:07:17
epoch [125/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.4658 (0.7259) acc 84.3750 (79.6875) lr 6.4653e-04 eta 0:06:47
epoch [125/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.7241 (0.7181) acc 81.2500 (80.7500) lr 6.4653e-04 eta 0:06:29
epoch [125/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.3340 (0.7366) acc 65.6250 (79.8958) lr 6.4653e-04 eta 0:06:16
epoch [125/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6553 (0.7230) acc 81.2500 (80.3571) lr 6.4653e-04 eta 0:06:07
epoch [125/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7319 (0.6930) acc 84.3750 (81.6406) lr 6.4653e-04 eta 0:06:00
epoch [125/200] batch [45/50] time 0.084 (0.094) data 0.000 (0.011) loss 0.8774 (0.7086) acc 81.2500 (81.5278) lr 6.4653e-04 eta 0:05:54
epoch [125/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.010) loss 0.8491 (0.6955) acc 78.1250 (81.8125) lr 6.3188e-04 eta 0:05:50
epoch [126/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.097) loss 0.8242 (0.6841) acc 78.1250 (83.1250) lr 6.3188e-04 eta 0:11:24
epoch [126/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 0.9292 (0.7394) acc 71.8750 (80.9375) lr 6.3188e-04 eta 0:08:20
epoch [126/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.7642 (0.7485) acc 68.7500 (79.1667) lr 6.3188e-04 eta 0:07:18
epoch [126/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.6221 (0.7596) acc 81.2500 (78.2812) lr 6.3188e-04 eta 0:06:47
epoch [126/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.9883 (0.7591) acc 75.0000 (79.2500) lr 6.3188e-04 eta 0:06:29
epoch [126/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.6567 (0.7633) acc 84.3750 (79.2708) lr 6.3188e-04 eta 0:06:16
epoch [126/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.6514 (0.7641) acc 81.2500 (79.1964) lr 6.3188e-04 eta 0:06:07
epoch [126/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 1.0791 (0.7692) acc 68.7500 (78.6719) lr 6.3188e-04 eta 0:05:59
epoch [126/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5439 (0.7514) acc 78.1250 (79.0972) lr 6.3188e-04 eta 0:05:53
epoch [126/200] batch [50/50] time 0.086 (0.094) data 0.000 (0.010) loss 0.5557 (0.7592) acc 84.3750 (78.8125) lr 6.1732e-04 eta 0:05:48
epoch [127/200] batch [5/50] time 0.083 (0.183) data 0.000 (0.099) loss 0.5186 (0.6654) acc 84.3750 (86.8750) lr 6.1732e-04 eta 0:11:17
epoch [127/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.8027 (0.7140) acc 81.2500 (82.8125) lr 6.1732e-04 eta 0:08:14
epoch [127/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.7070 (0.7004) acc 78.1250 (82.0833) lr 6.1732e-04 eta 0:07:12
epoch [127/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.6265 (0.7348) acc 81.2500 (81.2500) lr 6.1732e-04 eta 0:06:41
epoch [127/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.6138 (0.7553) acc 81.2500 (80.8750) lr 6.1732e-04 eta 0:06:22
epoch [127/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.6450 (0.7719) acc 81.2500 (80.5208) lr 6.1732e-04 eta 0:06:10
epoch [127/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.8584 (0.7767) acc 78.1250 (80.0893) lr 6.1732e-04 eta 0:06:01
epoch [127/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.3579 (0.7574) acc 87.5000 (80.5469) lr 6.1732e-04 eta 0:05:54
epoch [127/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6123 (0.7498) acc 84.3750 (80.4167) lr 6.1732e-04 eta 0:05:48
epoch [127/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9277 (0.7542) acc 75.0000 (80.1875) lr 6.0285e-04 eta 0:05:44
epoch [128/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.099) loss 0.5210 (0.7160) acc 84.3750 (80.6250) lr 6.0285e-04 eta 0:11:09
epoch [128/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 0.7383 (0.7017) acc 81.2500 (80.6250) lr 6.0285e-04 eta 0:08:07
epoch [128/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.9580 (0.7502) acc 71.8750 (80.0000) lr 6.0285e-04 eta 0:07:07
epoch [128/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.7827 (0.7575) acc 78.1250 (79.3750) lr 6.0285e-04 eta 0:06:36
epoch [128/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 1.0156 (0.7545) acc 75.0000 (79.6250) lr 6.0285e-04 eta 0:06:17
epoch [128/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.0420 (0.7720) acc 75.0000 (79.1667) lr 6.0285e-04 eta 0:06:05
epoch [128/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7568 (0.7709) acc 84.3750 (79.6429) lr 6.0285e-04 eta 0:05:56
epoch [128/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0469 (0.7686) acc 71.8750 (79.6094) lr 6.0285e-04 eta 0:05:48
epoch [128/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0098 (0.7683) acc 75.0000 (79.5139) lr 6.0285e-04 eta 0:05:43
epoch [128/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7056 (0.7618) acc 78.1250 (79.6875) lr 5.8849e-04 eta 0:05:38
epoch [129/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 1.0215 (0.6653) acc 78.1250 (81.8750) lr 5.8849e-04 eta 0:11:01
epoch [129/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.5020 (0.7047) acc 84.3750 (80.9375) lr 5.8849e-04 eta 0:08:01
epoch [129/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.7456 (0.7008) acc 84.3750 (82.0833) lr 5.8849e-04 eta 0:07:01
epoch [129/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 1.0938 (0.7413) acc 71.8750 (80.7812) lr 5.8849e-04 eta 0:06:31
epoch [129/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.5703 (0.7293) acc 75.0000 (80.5000) lr 5.8849e-04 eta 0:06:12
epoch [129/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.017) loss 0.7690 (0.7114) acc 78.1250 (81.1458) lr 5.8849e-04 eta 0:05:59
epoch [129/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.9194 (0.7133) acc 78.1250 (81.1607) lr 5.8849e-04 eta 0:05:50
epoch [129/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.9062 (0.7346) acc 68.7500 (80.6250) lr 5.8849e-04 eta 0:05:43
epoch [129/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7280 (0.7340) acc 75.0000 (80.8333) lr 5.8849e-04 eta 0:05:37
epoch [129/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.9980 (0.7385) acc 75.0000 (80.6250) lr 5.7422e-04 eta 0:05:33
epoch [130/200] batch [5/50] time 0.085 (0.186) data 0.000 (0.099) loss 0.4783 (0.6882) acc 87.5000 (83.1250) lr 5.7422e-04 eta 0:10:59
epoch [130/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.050) loss 0.4727 (0.6795) acc 84.3750 (82.1875) lr 5.7422e-04 eta 0:07:59
epoch [130/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.033) loss 0.4966 (0.6917) acc 90.6250 (81.6667) lr 5.7422e-04 eta 0:06:59
epoch [130/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.7769 (0.7120) acc 71.8750 (79.8438) lr 5.7422e-04 eta 0:06:29
epoch [130/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.5908 (0.6748) acc 84.3750 (81.2500) lr 5.7422e-04 eta 0:06:10
epoch [130/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.8555 (0.7151) acc 84.3750 (80.9375) lr 5.7422e-04 eta 0:05:58
epoch [130/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.4395 (0.7073) acc 87.5000 (81.1607) lr 5.7422e-04 eta 0:05:49
epoch [130/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.5913 (0.7018) acc 87.5000 (81.1719) lr 5.7422e-04 eta 0:05:41
epoch [130/200] batch [45/50] time 0.084 (0.096) data 0.001 (0.011) loss 0.5527 (0.6793) acc 78.1250 (81.5972) lr 5.7422e-04 eta 0:05:36
epoch [130/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.010) loss 0.8438 (0.6858) acc 81.2500 (81.5000) lr 5.6006e-04 eta 0:05:31
epoch [131/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.107) loss 0.6670 (0.6617) acc 84.3750 (83.1250) lr 5.6006e-04 eta 0:11:11
epoch [131/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.5884 (0.7166) acc 84.3750 (81.8750) lr 5.6006e-04 eta 0:08:02
epoch [131/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.6562 (0.6544) acc 81.2500 (83.3333) lr 5.6006e-04 eta 0:06:58
epoch [131/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.8398 (0.6707) acc 78.1250 (82.9688) lr 5.6006e-04 eta 0:06:26
epoch [131/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.8643 (0.7013) acc 71.8750 (81.7500) lr 5.6006e-04 eta 0:06:07
epoch [131/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.8169 (0.7041) acc 78.1250 (81.9792) lr 5.6006e-04 eta 0:05:54
epoch [131/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.9551 (0.7232) acc 81.2500 (81.4286) lr 5.6006e-04 eta 0:05:45
epoch [131/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7734 (0.7311) acc 84.3750 (81.3281) lr 5.6006e-04 eta 0:05:37
epoch [131/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5938 (0.7230) acc 81.2500 (81.3194) lr 5.6006e-04 eta 0:05:31
epoch [131/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8403 (0.7277) acc 75.0000 (81.1250) lr 5.4601e-04 eta 0:05:26
epoch [132/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.104) loss 0.2729 (0.7140) acc 90.6250 (82.5000) lr 5.4601e-04 eta 0:10:51
epoch [132/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.5137 (0.7067) acc 87.5000 (83.1250) lr 5.4601e-04 eta 0:07:49
epoch [132/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.6479 (0.8057) acc 84.3750 (80.4167) lr 5.4601e-04 eta 0:06:49
epoch [132/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.4546 (0.7709) acc 90.6250 (80.6250) lr 5.4601e-04 eta 0:06:18
epoch [132/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.7515 (0.7662) acc 75.0000 (80.2500) lr 5.4601e-04 eta 0:06:00
epoch [132/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.8071 (0.7560) acc 81.2500 (80.9375) lr 5.4601e-04 eta 0:05:47
epoch [132/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 1.2461 (0.7705) acc 71.8750 (80.3571) lr 5.4601e-04 eta 0:05:38
epoch [132/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7983 (0.7588) acc 75.0000 (80.4688) lr 5.4601e-04 eta 0:05:31
epoch [132/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.2588 (0.7748) acc 75.0000 (80.0694) lr 5.4601e-04 eta 0:05:25
epoch [132/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.7651 (0.7601) acc 68.7500 (80.1250) lr 5.3207e-04 eta 0:05:20
epoch [133/200] batch [5/50] time 0.083 (0.177) data 0.000 (0.093) loss 0.9575 (0.6611) acc 65.6250 (81.8750) lr 5.3207e-04 eta 0:10:01
epoch [133/200] batch [10/50] time 0.084 (0.131) data 0.000 (0.046) loss 0.7285 (0.7681) acc 84.3750 (81.5625) lr 5.3207e-04 eta 0:07:22
epoch [133/200] batch [15/50] time 0.084 (0.115) data 0.000 (0.031) loss 0.6816 (0.7446) acc 75.0000 (81.4583) lr 5.3207e-04 eta 0:06:28
epoch [133/200] batch [20/50] time 0.084 (0.107) data 0.000 (0.023) loss 0.5337 (0.7551) acc 90.6250 (81.0938) lr 5.3207e-04 eta 0:06:02
epoch [133/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.2416 (0.7331) acc 96.8750 (81.6250) lr 5.3207e-04 eta 0:05:46
epoch [133/200] batch [30/50] time 0.084 (0.099) data 0.000 (0.016) loss 0.8232 (0.7417) acc 75.0000 (81.0417) lr 5.3207e-04 eta 0:05:35
epoch [133/200] batch [35/50] time 0.084 (0.097) data 0.000 (0.013) loss 1.0254 (0.7461) acc 75.0000 (81.0714) lr 5.3207e-04 eta 0:05:27
epoch [133/200] batch [40/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.6528 (0.7397) acc 84.3750 (81.2500) lr 5.3207e-04 eta 0:05:20
epoch [133/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.4019 (0.7258) acc 90.6250 (81.8056) lr 5.3207e-04 eta 0:05:15
epoch [133/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.009) loss 0.4546 (0.7271) acc 90.6250 (81.8125) lr 5.1825e-04 eta 0:05:11
epoch [134/200] batch [5/50] time 0.083 (0.182) data 0.000 (0.097) loss 0.6973 (0.6913) acc 78.1250 (80.0000) lr 5.1825e-04 eta 0:10:08
epoch [134/200] batch [10/50] time 0.083 (0.133) data 0.000 (0.049) loss 0.5576 (0.7326) acc 87.5000 (80.9375) lr 5.1825e-04 eta 0:07:24
epoch [134/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.6938 (0.7699) acc 78.1250 (79.1667) lr 5.1825e-04 eta 0:06:29
epoch [134/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.7549 (0.7189) acc 75.0000 (80.4688) lr 5.1825e-04 eta 0:06:01
epoch [134/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.9214 (0.7405) acc 81.2500 (79.8750) lr 5.1825e-04 eta 0:05:45
epoch [134/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.3132 (0.7130) acc 90.6250 (80.6250) lr 5.1825e-04 eta 0:05:33
epoch [134/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 0.6030 (0.7170) acc 75.0000 (80.2679) lr 5.1825e-04 eta 0:05:25
epoch [134/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9570 (0.7138) acc 75.0000 (80.2344) lr 5.1825e-04 eta 0:05:19
epoch [134/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4905 (0.7040) acc 84.3750 (80.2778) lr 5.1825e-04 eta 0:05:13
epoch [134/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6572 (0.7226) acc 81.2500 (80.1250) lr 5.0454e-04 eta 0:05:09
epoch [135/200] batch [5/50] time 0.084 (0.181) data 0.000 (0.096) loss 0.5278 (0.8941) acc 81.2500 (76.2500) lr 5.0454e-04 eta 0:09:57
epoch [135/200] batch [10/50] time 0.085 (0.133) data 0.000 (0.048) loss 0.7231 (0.8602) acc 78.1250 (75.9375) lr 5.0454e-04 eta 0:07:17
epoch [135/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.6592 (0.8065) acc 87.5000 (78.3333) lr 5.0454e-04 eta 0:06:23
epoch [135/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.9238 (0.7928) acc 81.2500 (79.2188) lr 5.0454e-04 eta 0:05:56
epoch [135/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.5215 (0.7521) acc 84.3750 (80.2500) lr 5.0454e-04 eta 0:05:40
epoch [135/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.3767 (0.7371) acc 90.6250 (80.8333) lr 5.0454e-04 eta 0:05:29
epoch [135/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 0.6807 (0.7560) acc 78.1250 (80.4464) lr 5.0454e-04 eta 0:05:21
epoch [135/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.7583 (0.7387) acc 84.3750 (81.1719) lr 5.0454e-04 eta 0:05:14
epoch [135/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9141 (0.7262) acc 75.0000 (81.5972) lr 5.0454e-04 eta 0:05:09
epoch [135/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9048 (0.7122) acc 81.2500 (82.0625) lr 4.9096e-04 eta 0:05:05
epoch [136/200] batch [5/50] time 0.085 (0.179) data 0.000 (0.093) loss 0.8682 (0.6291) acc 84.3750 (86.8750) lr 4.9096e-04 eta 0:09:39
epoch [136/200] batch [10/50] time 0.083 (0.131) data 0.000 (0.047) loss 0.7949 (0.7330) acc 78.1250 (84.0625) lr 4.9096e-04 eta 0:07:05
epoch [136/200] batch [15/50] time 0.088 (0.116) data 0.000 (0.031) loss 0.8315 (0.7792) acc 68.7500 (81.6667) lr 4.9096e-04 eta 0:06:15
epoch [136/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.023) loss 0.9082 (0.7837) acc 65.6250 (80.3125) lr 4.9096e-04 eta 0:05:48
epoch [136/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.4763 (0.7804) acc 90.6250 (81.2500) lr 4.9096e-04 eta 0:05:33
epoch [136/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8184 (0.8092) acc 81.2500 (80.0000) lr 4.9096e-04 eta 0:05:23
epoch [136/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 1.0654 (0.8032) acc 78.1250 (80.1786) lr 4.9096e-04 eta 0:05:15
epoch [136/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.4531 (0.7745) acc 90.6250 (80.3906) lr 4.9096e-04 eta 0:05:09
epoch [136/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9668 (0.7797) acc 81.2500 (80.3472) lr 4.9096e-04 eta 0:05:04
epoch [136/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8682 (0.7762) acc 78.1250 (80.1250) lr 4.7750e-04 eta 0:04:59
epoch [137/200] batch [5/50] time 0.085 (0.181) data 0.000 (0.095) loss 0.5200 (0.8733) acc 87.5000 (78.7500) lr 4.7750e-04 eta 0:09:36
epoch [137/200] batch [10/50] time 0.084 (0.132) data 0.000 (0.048) loss 0.7471 (0.8002) acc 78.1250 (81.5625) lr 4.7750e-04 eta 0:07:02
epoch [137/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.6548 (0.7346) acc 84.3750 (83.3333) lr 4.7750e-04 eta 0:06:11
epoch [137/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 0.7856 (0.7737) acc 75.0000 (80.7812) lr 4.7750e-04 eta 0:05:45
epoch [137/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.9038 (0.7721) acc 81.2500 (80.8750) lr 4.7750e-04 eta 0:05:29
epoch [137/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.4697 (0.7381) acc 87.5000 (80.9375) lr 4.7750e-04 eta 0:05:19
epoch [137/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.5552 (0.7351) acc 87.5000 (81.0714) lr 4.7750e-04 eta 0:05:11
epoch [137/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.6592 (0.7236) acc 84.3750 (81.2500) lr 4.7750e-04 eta 0:05:04
epoch [137/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5000 (0.7448) acc 81.2500 (80.4861) lr 4.7750e-04 eta 0:04:59
epoch [137/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6152 (0.7373) acc 84.3750 (80.6875) lr 4.6417e-04 eta 0:04:55
epoch [138/200] batch [5/50] time 0.084 (0.178) data 0.000 (0.093) loss 0.6523 (0.6582) acc 78.1250 (83.7500) lr 4.6417e-04 eta 0:09:20
epoch [138/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.047) loss 0.5024 (0.6527) acc 84.3750 (82.8125) lr 4.6417e-04 eta 0:06:53
epoch [138/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.031) loss 0.6812 (0.6689) acc 87.5000 (82.2917) lr 4.6417e-04 eta 0:06:03
epoch [138/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.023) loss 0.5459 (0.6552) acc 87.5000 (82.8125) lr 4.6417e-04 eta 0:05:38
epoch [138/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.8047 (0.6590) acc 78.1250 (82.7500) lr 4.6417e-04 eta 0:05:22
epoch [138/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8428 (0.6884) acc 75.0000 (82.0833) lr 4.6417e-04 eta 0:05:12
epoch [138/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.7490 (0.6981) acc 84.3750 (82.0536) lr 4.6417e-04 eta 0:05:05
epoch [138/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.4744 (0.6792) acc 84.3750 (82.3438) lr 4.6417e-04 eta 0:04:59
epoch [138/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6558 (0.6781) acc 78.1250 (82.2222) lr 4.6417e-04 eta 0:04:54
epoch [138/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5059 (0.6753) acc 87.5000 (82.1875) lr 4.5098e-04 eta 0:04:50
epoch [139/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.096) loss 0.5400 (0.7693) acc 81.2500 (78.1250) lr 4.5098e-04 eta 0:09:24
epoch [139/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.6313 (0.6357) acc 81.2500 (82.1875) lr 4.5098e-04 eta 0:06:52
epoch [139/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.5576 (0.6486) acc 84.3750 (82.7083) lr 4.5098e-04 eta 0:06:00
epoch [139/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.024) loss 1.0215 (0.7328) acc 75.0000 (79.8438) lr 4.5098e-04 eta 0:05:35
epoch [139/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.5972 (0.7227) acc 87.5000 (79.8750) lr 4.5098e-04 eta 0:05:19
epoch [139/200] batch [30/50] time 0.084 (0.101) data 0.001 (0.016) loss 1.2510 (0.7808) acc 62.5000 (78.4375) lr 4.5098e-04 eta 0:05:09
epoch [139/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5693 (0.7731) acc 81.2500 (78.3036) lr 4.5098e-04 eta 0:05:01
epoch [139/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.2188 (0.7763) acc 65.6250 (78.3594) lr 4.5098e-04 eta 0:04:55
epoch [139/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5566 (0.7674) acc 81.2500 (78.5417) lr 4.5098e-04 eta 0:04:50
epoch [139/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8945 (0.7692) acc 84.3750 (78.5625) lr 4.3792e-04 eta 0:04:46
epoch [140/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.5459 (0.9149) acc 90.6250 (74.3750) lr 4.3792e-04 eta 0:09:23
epoch [140/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.8745 (0.7472) acc 81.2500 (79.6875) lr 4.3792e-04 eta 0:06:49
epoch [140/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.6919 (0.7330) acc 81.2500 (81.2500) lr 4.3792e-04 eta 0:05:57
epoch [140/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.3691 (0.6999) acc 84.3750 (81.5625) lr 4.3792e-04 eta 0:05:31
epoch [140/200] batch [25/50] time 0.083 (0.104) data 0.000 (0.020) loss 0.6606 (0.7243) acc 78.1250 (81.2500) lr 4.3792e-04 eta 0:05:15
epoch [140/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6709 (0.7224) acc 81.2500 (81.1458) lr 4.3792e-04 eta 0:05:04
epoch [140/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.5635 (0.7107) acc 75.0000 (81.1607) lr 4.3792e-04 eta 0:04:56
epoch [140/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6084 (0.6913) acc 78.1250 (81.5625) lr 4.3792e-04 eta 0:04:50
epoch [140/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7031 (0.6889) acc 75.0000 (81.4583) lr 4.3792e-04 eta 0:04:45
epoch [140/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7573 (0.6907) acc 81.2500 (81.6875) lr 4.2499e-04 eta 0:04:41
epoch [141/200] batch [5/50] time 0.085 (0.185) data 0.000 (0.099) loss 0.6699 (0.6051) acc 84.3750 (83.1250) lr 4.2499e-04 eta 0:09:14
epoch [141/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.8564 (0.6269) acc 78.1250 (84.0625) lr 4.2499e-04 eta 0:06:42
epoch [141/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.7754 (0.6743) acc 84.3750 (84.3750) lr 4.2499e-04 eta 0:05:51
epoch [141/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.3079 (0.6477) acc 90.6250 (84.5312) lr 4.2499e-04 eta 0:05:26
epoch [141/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.9102 (0.6768) acc 75.0000 (82.7500) lr 4.2499e-04 eta 0:05:10
epoch [141/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.5825 (0.6750) acc 81.2500 (82.8125) lr 4.2499e-04 eta 0:05:00
epoch [141/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.3950 (0.6629) acc 93.7500 (82.7679) lr 4.2499e-04 eta 0:04:52
epoch [141/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8262 (0.6931) acc 78.1250 (82.1875) lr 4.2499e-04 eta 0:04:46
epoch [141/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0508 (0.7115) acc 78.1250 (82.0833) lr 4.2499e-04 eta 0:04:41
epoch [141/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7856 (0.7245) acc 71.8750 (81.3750) lr 4.1221e-04 eta 0:04:37
epoch [142/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.098) loss 0.9326 (0.7017) acc 78.1250 (80.6250) lr 4.1221e-04 eta 0:08:57
epoch [142/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.4854 (0.7569) acc 87.5000 (80.0000) lr 4.1221e-04 eta 0:06:32
epoch [142/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.8398 (0.7139) acc 81.2500 (80.8333) lr 4.1221e-04 eta 0:05:43
epoch [142/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.7104 (0.6738) acc 78.1250 (82.0312) lr 4.1221e-04 eta 0:05:18
epoch [142/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 1.2256 (0.7050) acc 62.5000 (80.5000) lr 4.1221e-04 eta 0:05:04
epoch [142/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.4944 (0.6929) acc 90.6250 (80.5208) lr 4.1221e-04 eta 0:04:54
epoch [142/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 0.3210 (0.6862) acc 87.5000 (81.2500) lr 4.1221e-04 eta 0:04:46
epoch [142/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.8413 (0.6882) acc 78.1250 (81.3281) lr 4.1221e-04 eta 0:04:40
epoch [142/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8262 (0.6878) acc 75.0000 (81.2500) lr 4.1221e-04 eta 0:04:36
epoch [142/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7715 (0.6914) acc 78.1250 (81.1875) lr 3.9958e-04 eta 0:04:32
epoch [143/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.103) loss 0.3508 (0.5975) acc 87.5000 (86.2500) lr 3.9958e-04 eta 0:09:02
epoch [143/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.051) loss 0.5718 (0.6388) acc 87.5000 (85.0000) lr 3.9958e-04 eta 0:06:32
epoch [143/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.9985 (0.6648) acc 75.0000 (83.7500) lr 3.9958e-04 eta 0:05:41
epoch [143/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.026) loss 0.8433 (0.6662) acc 71.8750 (82.9688) lr 3.9958e-04 eta 0:05:16
epoch [143/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.8213 (0.6622) acc 78.1250 (82.7500) lr 3.9958e-04 eta 0:05:00
epoch [143/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.017) loss 0.9702 (0.6771) acc 78.1250 (82.0833) lr 3.9958e-04 eta 0:04:50
epoch [143/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.1974 (0.6819) acc 100.0000 (81.9643) lr 3.9958e-04 eta 0:04:42
epoch [143/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6475 (0.6979) acc 81.2500 (81.9531) lr 3.9958e-04 eta 0:04:36
epoch [143/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 1.2441 (0.7273) acc 62.5000 (81.1111) lr 3.9958e-04 eta 0:04:31
epoch [143/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8623 (0.7351) acc 78.1250 (80.8750) lr 3.8709e-04 eta 0:04:27
epoch [144/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 0.8877 (0.8163) acc 71.8750 (77.5000) lr 3.8709e-04 eta 0:08:43
epoch [144/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.9131 (0.8103) acc 78.1250 (78.7500) lr 3.8709e-04 eta 0:06:20
epoch [144/200] batch [15/50] time 0.086 (0.117) data 0.000 (0.033) loss 0.6235 (0.7875) acc 81.2500 (78.9583) lr 3.8709e-04 eta 0:05:33
epoch [144/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 0.8740 (0.8067) acc 75.0000 (78.9062) lr 3.8709e-04 eta 0:05:08
epoch [144/200] batch [25/50] time 0.083 (0.104) data 0.000 (0.020) loss 0.5396 (0.7623) acc 84.3750 (80.1250) lr 3.8709e-04 eta 0:04:54
epoch [144/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.7080 (0.7564) acc 87.5000 (80.2083) lr 3.8709e-04 eta 0:04:43
epoch [144/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7969 (0.7317) acc 81.2500 (80.8929) lr 3.8709e-04 eta 0:04:36
epoch [144/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 0.6211 (0.7148) acc 84.3750 (81.3281) lr 3.8709e-04 eta 0:04:30
epoch [144/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9170 (0.7151) acc 81.2500 (81.4583) lr 3.8709e-04 eta 0:04:26
epoch [144/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0186 (0.7253) acc 78.1250 (81.5625) lr 3.7476e-04 eta 0:04:22
epoch [145/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.107) loss 1.0352 (0.7992) acc 75.0000 (80.6250) lr 3.7476e-04 eta 0:08:56
epoch [145/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.5332 (0.8236) acc 90.6250 (81.2500) lr 3.7476e-04 eta 0:06:26
epoch [145/200] batch [15/50] time 0.086 (0.121) data 0.000 (0.036) loss 0.6587 (0.7706) acc 78.1250 (80.8333) lr 3.7476e-04 eta 0:05:35
epoch [145/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 0.3049 (0.7623) acc 93.7500 (80.3125) lr 3.7476e-04 eta 0:05:10
epoch [145/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.9111 (0.7782) acc 71.8750 (79.3750) lr 3.7476e-04 eta 0:04:54
epoch [145/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.9243 (0.7639) acc 78.1250 (79.4792) lr 3.7476e-04 eta 0:04:44
epoch [145/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.8706 (0.7536) acc 81.2500 (80.3571) lr 3.7476e-04 eta 0:04:36
epoch [145/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7803 (0.7383) acc 81.2500 (80.8594) lr 3.7476e-04 eta 0:04:30
epoch [145/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6865 (0.7438) acc 75.0000 (80.4167) lr 3.7476e-04 eta 0:04:25
epoch [145/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5586 (0.7376) acc 81.2500 (80.5000) lr 3.6258e-04 eta 0:04:21
epoch [146/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.107) loss 0.3840 (0.6432) acc 90.6250 (84.3750) lr 3.6258e-04 eta 0:08:46
epoch [146/200] batch [10/50] time 0.083 (0.138) data 0.000 (0.054) loss 0.5488 (0.5673) acc 84.3750 (87.1875) lr 3.6258e-04 eta 0:06:18
epoch [146/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.6416 (0.5749) acc 81.2500 (84.7917) lr 3.6258e-04 eta 0:05:28
epoch [146/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.5923 (0.6001) acc 87.5000 (83.9062) lr 3.6258e-04 eta 0:05:03
epoch [146/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.7002 (0.6037) acc 81.2500 (83.6250) lr 3.6258e-04 eta 0:04:47
epoch [146/200] batch [30/50] time 0.083 (0.102) data 0.000 (0.018) loss 0.5303 (0.6054) acc 81.2500 (83.0208) lr 3.6258e-04 eta 0:04:37
epoch [146/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.016) loss 0.5884 (0.6429) acc 84.3750 (81.7857) lr 3.6258e-04 eta 0:04:29
epoch [146/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.8008 (0.6555) acc 81.2500 (81.7188) lr 3.6258e-04 eta 0:04:23
epoch [146/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5830 (0.6749) acc 87.5000 (81.8056) lr 3.6258e-04 eta 0:04:18
epoch [146/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.011) loss 0.3508 (0.6815) acc 87.5000 (81.6875) lr 3.5055e-04 eta 0:04:15
epoch [147/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 0.6157 (0.5405) acc 78.1250 (85.6250) lr 3.5055e-04 eta 0:08:24
epoch [147/200] batch [10/50] time 0.083 (0.135) data 0.000 (0.051) loss 0.8589 (0.6642) acc 78.1250 (84.0625) lr 3.5055e-04 eta 0:06:04
epoch [147/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.6328 (0.6569) acc 78.1250 (83.3333) lr 3.5055e-04 eta 0:05:17
epoch [147/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.8447 (0.6770) acc 71.8750 (82.6562) lr 3.5055e-04 eta 0:04:54
epoch [147/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.8589 (0.6797) acc 78.1250 (82.3750) lr 3.5055e-04 eta 0:04:40
epoch [147/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.5845 (0.6695) acc 84.3750 (82.9167) lr 3.5055e-04 eta 0:04:30
epoch [147/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.9019 (0.6721) acc 71.8750 (82.5000) lr 3.5055e-04 eta 0:04:23
epoch [147/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.0430 (0.6807) acc 65.6250 (81.7969) lr 3.5055e-04 eta 0:04:17
epoch [147/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6040 (0.6888) acc 78.1250 (81.4583) lr 3.5055e-04 eta 0:04:13
epoch [147/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.4248 (0.6711) acc 87.5000 (81.9375) lr 3.3869e-04 eta 0:04:09
epoch [148/200] batch [5/50] time 0.084 (0.183) data 0.000 (0.098) loss 0.4995 (0.5251) acc 81.2500 (82.5000) lr 3.3869e-04 eta 0:08:02
epoch [148/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.8970 (0.6075) acc 81.2500 (82.5000) lr 3.3869e-04 eta 0:05:51
epoch [148/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 0.5298 (0.6996) acc 81.2500 (80.4167) lr 3.3869e-04 eta 0:05:07
epoch [148/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.8672 (0.7168) acc 81.2500 (80.9375) lr 3.3869e-04 eta 0:04:45
epoch [148/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.8604 (0.7203) acc 78.1250 (81.0000) lr 3.3869e-04 eta 0:04:32
epoch [148/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.017) loss 0.7305 (0.7068) acc 81.2500 (81.4583) lr 3.3869e-04 eta 0:04:23
epoch [148/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6719 (0.6832) acc 78.1250 (82.1429) lr 3.3869e-04 eta 0:04:16
epoch [148/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0312 (0.6742) acc 75.0000 (82.5000) lr 3.3869e-04 eta 0:04:11
epoch [148/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8350 (0.6770) acc 71.8750 (82.0833) lr 3.3869e-04 eta 0:04:06
epoch [148/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.6997 (0.6839) acc 78.1250 (82.0000) lr 3.2699e-04 eta 0:04:03
epoch [149/200] batch [5/50] time 0.085 (0.189) data 0.000 (0.103) loss 0.5151 (0.4791) acc 90.6250 (86.8750) lr 3.2699e-04 eta 0:08:09
epoch [149/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 0.9155 (0.6578) acc 71.8750 (82.5000) lr 3.2699e-04 eta 0:05:54
epoch [149/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.9023 (0.7278) acc 75.0000 (80.8333) lr 3.2699e-04 eta 0:05:08
epoch [149/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.026) loss 0.5596 (0.7369) acc 81.2500 (80.3125) lr 3.2699e-04 eta 0:04:45
epoch [149/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 1.0332 (0.7417) acc 71.8750 (79.8750) lr 3.2699e-04 eta 0:04:31
epoch [149/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.6455 (0.7283) acc 84.3750 (80.3125) lr 3.2699e-04 eta 0:04:22
epoch [149/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 1.0654 (0.7270) acc 75.0000 (80.4464) lr 3.2699e-04 eta 0:04:15
epoch [149/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.4636 (0.7335) acc 87.5000 (80.6250) lr 3.2699e-04 eta 0:04:09
epoch [149/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9648 (0.7362) acc 71.8750 (80.2778) lr 3.2699e-04 eta 0:04:05
epoch [149/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4880 (0.7281) acc 90.6250 (80.1875) lr 3.1545e-04 eta 0:04:01
epoch [150/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.100) loss 0.7188 (0.5732) acc 78.1250 (83.7500) lr 3.1545e-04 eta 0:07:52
epoch [150/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.8398 (0.6165) acc 75.0000 (82.5000) lr 3.1545e-04 eta 0:05:42
epoch [150/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.7925 (0.6653) acc 71.8750 (81.2500) lr 3.1545e-04 eta 0:04:59
epoch [150/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.3872 (0.6947) acc 90.6250 (81.2500) lr 3.1545e-04 eta 0:04:37
epoch [150/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.8389 (0.7158) acc 78.1250 (80.5000) lr 3.1545e-04 eta 0:04:24
epoch [150/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.3735 (0.6835) acc 84.3750 (81.4583) lr 3.1545e-04 eta 0:04:15
epoch [150/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.8745 (0.6943) acc 78.1250 (80.8929) lr 3.1545e-04 eta 0:04:08
epoch [150/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7866 (0.6908) acc 75.0000 (81.0938) lr 3.1545e-04 eta 0:04:03
epoch [150/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8774 (0.6920) acc 71.8750 (81.0417) lr 3.1545e-04 eta 0:03:59
epoch [150/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.5415 (0.6837) acc 87.5000 (81.2500) lr 3.0409e-04 eta 0:03:55
epoch [151/200] batch [5/50] time 0.085 (0.178) data 0.000 (0.092) loss 0.8779 (0.6965) acc 75.0000 (76.8750) lr 3.0409e-04 eta 0:07:24
epoch [151/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.046) loss 0.8994 (0.6968) acc 78.1250 (78.7500) lr 3.0409e-04 eta 0:05:28
epoch [151/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.031) loss 0.8633 (0.7035) acc 75.0000 (79.1667) lr 3.0409e-04 eta 0:04:48
epoch [151/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.023) loss 0.4683 (0.6985) acc 84.3750 (79.8438) lr 3.0409e-04 eta 0:04:28
epoch [151/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.4160 (0.6912) acc 84.3750 (80.3750) lr 3.0409e-04 eta 0:04:16
epoch [151/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 1.3555 (0.7297) acc 71.8750 (80.1042) lr 3.0409e-04 eta 0:04:08
epoch [151/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.013) loss 0.7510 (0.7064) acc 71.8750 (80.2679) lr 3.0409e-04 eta 0:04:02
epoch [151/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.7246 (0.7004) acc 81.2500 (80.6250) lr 3.0409e-04 eta 0:03:57
epoch [151/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.010) loss 0.5405 (0.6889) acc 87.5000 (80.9722) lr 3.0409e-04 eta 0:03:53
epoch [151/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.009) loss 0.4104 (0.6883) acc 90.6250 (80.8125) lr 2.9289e-04 eta 0:03:50
epoch [152/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.098) loss 0.8359 (0.6171) acc 71.8750 (81.2500) lr 2.9289e-04 eta 0:07:28
epoch [152/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.8198 (0.7593) acc 75.0000 (79.6875) lr 2.9289e-04 eta 0:05:27
epoch [152/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.5093 (0.6835) acc 84.3750 (81.0417) lr 2.9289e-04 eta 0:04:46
epoch [152/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.8091 (0.7217) acc 78.1250 (80.7812) lr 2.9289e-04 eta 0:04:26
epoch [152/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.3076 (0.6722) acc 96.8750 (82.6250) lr 2.9289e-04 eta 0:04:13
epoch [152/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.5381 (0.6482) acc 81.2500 (83.0208) lr 2.9289e-04 eta 0:04:04
epoch [152/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.014) loss 0.4810 (0.6699) acc 87.5000 (81.9643) lr 2.9289e-04 eta 0:03:58
epoch [152/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.6997 (0.6735) acc 81.2500 (81.4844) lr 2.9289e-04 eta 0:03:53
epoch [152/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 1.0430 (0.6886) acc 75.0000 (81.3194) lr 2.9289e-04 eta 0:03:49
epoch [152/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6953 (0.6834) acc 78.1250 (81.1875) lr 2.8187e-04 eta 0:03:46
epoch [153/200] batch [5/50] time 0.083 (0.195) data 0.000 (0.111) loss 0.5459 (0.8422) acc 81.2500 (76.2500) lr 2.8187e-04 eta 0:07:47
epoch [153/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.2915 (0.7152) acc 93.7500 (79.0625) lr 2.8187e-04 eta 0:05:34
epoch [153/200] batch [15/50] time 0.083 (0.121) data 0.000 (0.037) loss 0.8228 (0.7274) acc 78.1250 (78.5417) lr 2.8187e-04 eta 0:04:49
epoch [153/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.7754 (0.7269) acc 84.3750 (80.0000) lr 2.8187e-04 eta 0:04:26
epoch [153/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 0.7437 (0.7034) acc 75.0000 (80.8750) lr 2.8187e-04 eta 0:04:13
epoch [153/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.6118 (0.7123) acc 84.3750 (81.1458) lr 2.8187e-04 eta 0:04:04
epoch [153/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.3704 (0.6932) acc 90.6250 (82.2321) lr 2.8187e-04 eta 0:03:57
epoch [153/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7534 (0.6804) acc 84.3750 (82.5000) lr 2.8187e-04 eta 0:03:51
epoch [153/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.7192 (0.6723) acc 87.5000 (82.5694) lr 2.8187e-04 eta 0:03:47
epoch [153/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.3137 (0.6713) acc 93.7500 (82.5000) lr 2.7103e-04 eta 0:03:43
epoch [154/200] batch [5/50] time 0.084 (0.190) data 0.000 (0.105) loss 0.6587 (0.7028) acc 84.3750 (80.0000) lr 2.7103e-04 eta 0:07:24
epoch [154/200] batch [10/50] time 0.083 (0.137) data 0.000 (0.053) loss 0.7061 (0.6708) acc 75.0000 (80.6250) lr 2.7103e-04 eta 0:05:20
epoch [154/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.7339 (0.6805) acc 84.3750 (82.0833) lr 2.7103e-04 eta 0:04:38
epoch [154/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.8354 (0.7366) acc 75.0000 (79.5312) lr 2.7103e-04 eta 0:04:16
epoch [154/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.7764 (0.7184) acc 81.2500 (81.1250) lr 2.7103e-04 eta 0:04:04
epoch [154/200] batch [30/50] time 0.083 (0.101) data 0.000 (0.018) loss 0.7031 (0.7105) acc 68.7500 (80.8333) lr 2.7103e-04 eta 0:03:55
epoch [154/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.5181 (0.6840) acc 78.1250 (81.4286) lr 2.7103e-04 eta 0:03:49
epoch [154/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7808 (0.6831) acc 68.7500 (81.2500) lr 2.7103e-04 eta 0:03:44
epoch [154/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5610 (0.6735) acc 87.5000 (81.4583) lr 2.7103e-04 eta 0:03:40
epoch [154/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.011) loss 0.8960 (0.6808) acc 78.1250 (81.3750) lr 2.6037e-04 eta 0:03:37
epoch [155/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.099) loss 0.5757 (0.5213) acc 81.2500 (85.0000) lr 2.6037e-04 eta 0:07:03
epoch [155/200] batch [10/50] time 0.083 (0.134) data 0.000 (0.050) loss 0.9351 (0.5893) acc 71.8750 (84.0625) lr 2.6037e-04 eta 0:05:07
epoch [155/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.7129 (0.6402) acc 84.3750 (83.3333) lr 2.6037e-04 eta 0:04:28
epoch [155/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.6216 (0.6396) acc 84.3750 (83.7500) lr 2.6037e-04 eta 0:04:08
epoch [155/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.6519 (0.6451) acc 81.2500 (83.2500) lr 2.6037e-04 eta 0:03:56
epoch [155/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.7598 (0.6414) acc 78.1250 (83.1250) lr 2.6037e-04 eta 0:03:48
epoch [155/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.8325 (0.6713) acc 71.8750 (81.9643) lr 2.6037e-04 eta 0:03:42
epoch [155/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.013) loss 0.5415 (0.6621) acc 90.6250 (82.4219) lr 2.6037e-04 eta 0:03:37
epoch [155/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0488 (0.6763) acc 71.8750 (82.0139) lr 2.6037e-04 eta 0:03:34
epoch [155/200] batch [50/50] time 0.086 (0.094) data 0.000 (0.010) loss 0.8833 (0.7057) acc 78.1250 (81.3125) lr 2.4989e-04 eta 0:03:31
epoch [156/200] batch [5/50] time 0.085 (0.180) data 0.000 (0.095) loss 0.8774 (0.9896) acc 71.8750 (73.7500) lr 2.4989e-04 eta 0:06:44
epoch [156/200] batch [10/50] time 0.085 (0.132) data 0.000 (0.048) loss 0.8730 (0.8593) acc 75.0000 (77.8125) lr 2.4989e-04 eta 0:04:55
epoch [156/200] batch [15/50] time 0.083 (0.116) data 0.000 (0.032) loss 0.5879 (0.7964) acc 84.3750 (78.7500) lr 2.4989e-04 eta 0:04:19
epoch [156/200] batch [20/50] time 0.083 (0.108) data 0.000 (0.024) loss 1.1641 (0.7711) acc 75.0000 (80.0000) lr 2.4989e-04 eta 0:04:00
epoch [156/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.5483 (0.7416) acc 87.5000 (80.7500) lr 2.4989e-04 eta 0:03:49
epoch [156/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7905 (0.7442) acc 84.3750 (81.0417) lr 2.4989e-04 eta 0:03:41
epoch [156/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.5425 (0.7204) acc 84.3750 (81.6964) lr 2.4989e-04 eta 0:03:36
epoch [156/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8770 (0.7303) acc 65.6250 (81.3281) lr 2.4989e-04 eta 0:03:31
epoch [156/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.9067 (0.7309) acc 75.0000 (81.3194) lr 2.4989e-04 eta 0:03:28
epoch [156/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.5605 (0.7249) acc 75.0000 (80.8750) lr 2.3959e-04 eta 0:03:25
epoch [157/200] batch [5/50] time 0.084 (0.180) data 0.000 (0.094) loss 1.0059 (0.9023) acc 75.0000 (76.2500) lr 2.3959e-04 eta 0:06:34
epoch [157/200] batch [10/50] time 0.083 (0.132) data 0.000 (0.047) loss 1.2637 (0.8650) acc 68.7500 (77.1875) lr 2.3959e-04 eta 0:04:48
epoch [157/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 0.5381 (0.7597) acc 90.6250 (80.8333) lr 2.3959e-04 eta 0:04:13
epoch [157/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.7690 (0.7772) acc 84.3750 (80.1562) lr 2.3959e-04 eta 0:03:55
epoch [157/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 0.9937 (0.7712) acc 71.8750 (80.0000) lr 2.3959e-04 eta 0:03:44
epoch [157/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.4175 (0.7424) acc 87.5000 (80.6250) lr 2.3959e-04 eta 0:03:36
epoch [157/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.6626 (0.7664) acc 81.2500 (80.2679) lr 2.3959e-04 eta 0:03:31
epoch [157/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9712 (0.7503) acc 78.1250 (80.3125) lr 2.3959e-04 eta 0:03:27
epoch [157/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.2820 (0.7321) acc 93.7500 (80.6944) lr 2.3959e-04 eta 0:03:23
epoch [157/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.010) loss 0.7163 (0.7345) acc 78.1250 (80.6875) lr 2.2949e-04 eta 0:03:20
epoch [158/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 0.4705 (0.5849) acc 84.3750 (83.1250) lr 2.2949e-04 eta 0:06:33
epoch [158/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.5649 (0.6705) acc 81.2500 (80.9375) lr 2.2949e-04 eta 0:04:46
epoch [158/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.5518 (0.6951) acc 81.2500 (79.7917) lr 2.2949e-04 eta 0:04:10
epoch [158/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 0.6089 (0.6938) acc 87.5000 (80.4688) lr 2.2949e-04 eta 0:03:52
epoch [158/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.5327 (0.7032) acc 90.6250 (81.1250) lr 2.2949e-04 eta 0:03:41
epoch [158/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.6792 (0.6946) acc 78.1250 (81.0417) lr 2.2949e-04 eta 0:03:33
epoch [158/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4102 (0.6811) acc 93.7500 (81.6071) lr 2.2949e-04 eta 0:03:28
epoch [158/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.8306 (0.6764) acc 78.1250 (81.8750) lr 2.2949e-04 eta 0:03:23
epoch [158/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0273 (0.7102) acc 68.7500 (81.0417) lr 2.2949e-04 eta 0:03:20
epoch [158/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5332 (0.7044) acc 84.3750 (81.1250) lr 2.1957e-04 eta 0:03:17
epoch [159/200] batch [5/50] time 0.084 (0.175) data 0.000 (0.091) loss 1.0264 (0.8973) acc 71.8750 (78.7500) lr 2.1957e-04 eta 0:06:06
epoch [159/200] batch [10/50] time 0.084 (0.130) data 0.000 (0.045) loss 0.6738 (0.8109) acc 81.2500 (80.3125) lr 2.1957e-04 eta 0:04:30
epoch [159/200] batch [15/50] time 0.083 (0.114) data 0.000 (0.030) loss 0.6636 (0.7713) acc 81.2500 (80.4167) lr 2.1957e-04 eta 0:03:58
epoch [159/200] batch [20/50] time 0.083 (0.107) data 0.000 (0.023) loss 0.7085 (0.7532) acc 78.1250 (81.0938) lr 2.1957e-04 eta 0:03:41
epoch [159/200] batch [25/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.6753 (0.7352) acc 75.0000 (81.3750) lr 2.1957e-04 eta 0:03:31
epoch [159/200] batch [30/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7944 (0.7653) acc 71.8750 (80.2083) lr 2.1957e-04 eta 0:03:25
epoch [159/200] batch [35/50] time 0.084 (0.097) data 0.001 (0.013) loss 0.8608 (0.7673) acc 81.2500 (80.0893) lr 2.1957e-04 eta 0:03:20
epoch [159/200] batch [40/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.4453 (0.7638) acc 81.2500 (80.0781) lr 2.1957e-04 eta 0:03:16
epoch [159/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.9658 (0.7589) acc 78.1250 (80.2778) lr 2.1957e-04 eta 0:03:13
epoch [159/200] batch [50/50] time 0.083 (0.093) data 0.000 (0.009) loss 0.6289 (0.7386) acc 81.2500 (80.6875) lr 2.0984e-04 eta 0:03:10
epoch [160/200] batch [5/50] time 0.083 (0.192) data 0.000 (0.107) loss 0.9121 (0.7239) acc 71.8750 (81.8750) lr 2.0984e-04 eta 0:06:32
epoch [160/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.4131 (0.6927) acc 90.6250 (82.1875) lr 2.0984e-04 eta 0:04:41
epoch [160/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.7871 (0.6384) acc 78.1250 (83.1250) lr 2.0984e-04 eta 0:04:04
epoch [160/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 1.1562 (0.6951) acc 78.1250 (82.3438) lr 2.0984e-04 eta 0:03:45
epoch [160/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.6875 (0.6625) acc 90.6250 (83.1250) lr 2.0984e-04 eta 0:03:33
epoch [160/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.7183 (0.6686) acc 84.3750 (83.1250) lr 2.0984e-04 eta 0:03:25
epoch [160/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6914 (0.6579) acc 81.2500 (83.2143) lr 2.0984e-04 eta 0:03:20
epoch [160/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.6519 (0.6571) acc 81.2500 (83.2031) lr 2.0984e-04 eta 0:03:15
epoch [160/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4299 (0.6624) acc 87.5000 (82.9861) lr 2.0984e-04 eta 0:03:12
epoch [160/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2070 (0.6770) acc 75.0000 (82.6250) lr 2.0032e-04 eta 0:03:09
epoch [161/200] batch [5/50] time 0.083 (0.181) data 0.000 (0.097) loss 0.8779 (0.6835) acc 71.8750 (81.8750) lr 2.0032e-04 eta 0:06:01
epoch [161/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.8755 (0.6897) acc 81.2500 (80.9375) lr 2.0032e-04 eta 0:04:23
epoch [161/200] batch [15/50] time 0.084 (0.116) data 0.000 (0.032) loss 1.0059 (0.7223) acc 68.7500 (79.7917) lr 2.0032e-04 eta 0:03:50
epoch [161/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.024) loss 0.9023 (0.7349) acc 75.0000 (79.6875) lr 2.0032e-04 eta 0:03:34
epoch [161/200] batch [25/50] time 0.085 (0.103) data 0.000 (0.020) loss 0.7559 (0.7134) acc 75.0000 (80.2500) lr 2.0032e-04 eta 0:03:24
epoch [161/200] batch [30/50] time 0.083 (0.100) data 0.000 (0.016) loss 0.9976 (0.7479) acc 71.8750 (79.1667) lr 2.0032e-04 eta 0:03:17
epoch [161/200] batch [35/50] time 0.084 (0.098) data 0.001 (0.014) loss 0.8159 (0.7682) acc 84.3750 (78.6607) lr 2.0032e-04 eta 0:03:12
epoch [161/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1855 (0.7635) acc 68.7500 (78.9844) lr 2.0032e-04 eta 0:03:08
epoch [161/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9722 (0.7636) acc 75.0000 (79.0278) lr 2.0032e-04 eta 0:03:04
epoch [161/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5908 (0.7398) acc 84.3750 (79.6250) lr 1.9098e-04 eta 0:03:02
epoch [162/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.100) loss 0.7227 (0.6367) acc 84.3750 (81.8750) lr 1.9098e-04 eta 0:05:58
epoch [162/200] batch [10/50] time 0.083 (0.134) data 0.000 (0.050) loss 0.4724 (0.6820) acc 87.5000 (81.5625) lr 1.9098e-04 eta 0:04:20
epoch [162/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 1.3418 (0.7367) acc 65.6250 (79.5833) lr 1.9098e-04 eta 0:03:47
epoch [162/200] batch [20/50] time 0.089 (0.109) data 0.000 (0.025) loss 0.4729 (0.7183) acc 81.2500 (80.0000) lr 1.9098e-04 eta 0:03:31
epoch [162/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.3335 (0.6937) acc 90.6250 (80.5000) lr 1.9098e-04 eta 0:03:20
epoch [162/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.4600 (0.6756) acc 84.3750 (80.9375) lr 1.9098e-04 eta 0:03:13
epoch [162/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.5312 (0.6881) acc 87.5000 (80.4464) lr 1.9098e-04 eta 0:03:08
epoch [162/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.4146 (0.6903) acc 81.2500 (80.3125) lr 1.9098e-04 eta 0:03:04
epoch [162/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8638 (0.6883) acc 75.0000 (80.8333) lr 1.9098e-04 eta 0:03:01
epoch [162/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6748 (0.6971) acc 84.3750 (80.6875) lr 1.8185e-04 eta 0:02:58
epoch [163/200] batch [5/50] time 0.085 (0.191) data 0.000 (0.106) loss 0.9561 (0.6865) acc 71.8750 (83.7500) lr 1.8185e-04 eta 0:06:02
epoch [163/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.7910 (0.7241) acc 81.2500 (82.1875) lr 1.8185e-04 eta 0:04:20
epoch [163/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 1.0244 (0.7049) acc 68.7500 (81.8750) lr 1.8185e-04 eta 0:03:46
epoch [163/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.4187 (0.6979) acc 87.5000 (82.1875) lr 1.8185e-04 eta 0:03:29
epoch [163/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.7500 (0.7344) acc 78.1250 (80.8750) lr 1.8185e-04 eta 0:03:18
epoch [163/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.5757 (0.7013) acc 87.5000 (81.5625) lr 1.8185e-04 eta 0:03:11
epoch [163/200] batch [35/50] time 0.086 (0.100) data 0.001 (0.015) loss 0.8291 (0.6991) acc 75.0000 (81.6964) lr 1.8185e-04 eta 0:03:06
epoch [163/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.6104 (0.6985) acc 81.2500 (81.5625) lr 1.8185e-04 eta 0:03:02
epoch [163/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5376 (0.7090) acc 87.5000 (81.3889) lr 1.8185e-04 eta 0:02:58
epoch [163/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.3296 (0.6844) acc 93.7500 (82.1875) lr 1.7292e-04 eta 0:02:56
epoch [164/200] batch [5/50] time 0.083 (0.185) data 0.000 (0.101) loss 1.0312 (0.7213) acc 68.7500 (80.6250) lr 1.7292e-04 eta 0:05:41
epoch [164/200] batch [10/50] time 0.083 (0.135) data 0.000 (0.050) loss 0.7817 (0.7912) acc 81.2500 (78.7500) lr 1.7292e-04 eta 0:04:07
epoch [164/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.2832 (0.7855) acc 96.8750 (79.5833) lr 1.7292e-04 eta 0:03:36
epoch [164/200] batch [20/50] time 0.083 (0.109) data 0.000 (0.025) loss 0.8716 (0.7737) acc 78.1250 (79.8438) lr 1.7292e-04 eta 0:03:20
epoch [164/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7153 (0.7362) acc 78.1250 (80.5000) lr 1.7292e-04 eta 0:03:10
epoch [164/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6284 (0.7331) acc 84.3750 (80.7292) lr 1.7292e-04 eta 0:03:03
epoch [164/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7617 (0.7281) acc 71.8750 (80.3571) lr 1.7292e-04 eta 0:02:58
epoch [164/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.4417 (0.7025) acc 84.3750 (80.8594) lr 1.7292e-04 eta 0:02:54
epoch [164/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7847 (0.6751) acc 75.0000 (81.4583) lr 1.7292e-04 eta 0:02:51
epoch [164/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.8032 (0.6818) acc 78.1250 (81.3125) lr 1.6419e-04 eta 0:02:49
epoch [165/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.109) loss 0.7090 (0.7797) acc 78.1250 (77.5000) lr 1.6419e-04 eta 0:05:49
epoch [165/200] batch [10/50] time 0.087 (0.140) data 0.000 (0.055) loss 0.7158 (0.7455) acc 78.1250 (78.4375) lr 1.6419e-04 eta 0:04:10
epoch [165/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.037) loss 0.6426 (0.7066) acc 81.2500 (80.4167) lr 1.6419e-04 eta 0:03:36
epoch [165/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.7568 (0.7269) acc 84.3750 (80.4688) lr 1.6419e-04 eta 0:03:19
epoch [165/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.022) loss 0.7163 (0.7496) acc 75.0000 (79.7500) lr 1.6419e-04 eta 0:03:09
epoch [165/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.3625 (0.7371) acc 93.7500 (79.7917) lr 1.6419e-04 eta 0:03:02
epoch [165/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.016) loss 0.8511 (0.7404) acc 84.3750 (80.0893) lr 1.6419e-04 eta 0:02:57
epoch [165/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.4424 (0.7490) acc 65.6250 (80.0000) lr 1.6419e-04 eta 0:02:52
epoch [165/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.012) loss 1.0049 (0.7531) acc 71.8750 (79.7222) lr 1.6419e-04 eta 0:02:49
epoch [165/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6489 (0.7448) acc 81.2500 (79.6875) lr 1.5567e-04 eta 0:02:46
epoch [166/200] batch [5/50] time 0.085 (0.183) data 0.000 (0.097) loss 0.6230 (0.6947) acc 84.3750 (82.5000) lr 1.5567e-04 eta 0:05:18
epoch [166/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.6118 (0.6684) acc 87.5000 (82.8125) lr 1.5567e-04 eta 0:03:52
epoch [166/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.5015 (0.6450) acc 84.3750 (83.3333) lr 1.5567e-04 eta 0:03:23
epoch [166/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 0.8569 (0.7026) acc 75.0000 (81.4062) lr 1.5567e-04 eta 0:03:08
epoch [166/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.5854 (0.6867) acc 78.1250 (81.8750) lr 1.5567e-04 eta 0:02:59
epoch [166/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.6895 (0.6950) acc 84.3750 (81.7708) lr 1.5567e-04 eta 0:02:53
epoch [166/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.5996 (0.6900) acc 81.2500 (81.8750) lr 1.5567e-04 eta 0:02:48
epoch [166/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.3865 (0.7038) acc 87.5000 (81.3281) lr 1.5567e-04 eta 0:02:45
epoch [166/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.4736 (0.6933) acc 81.2500 (81.5278) lr 1.5567e-04 eta 0:02:42
epoch [166/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0635 (0.7130) acc 71.8750 (81.1875) lr 1.4736e-04 eta 0:02:39
epoch [167/200] batch [5/50] time 0.086 (0.186) data 0.000 (0.099) loss 0.8911 (0.8021) acc 81.2500 (80.6250) lr 1.4736e-04 eta 0:05:14
epoch [167/200] batch [10/50] time 0.086 (0.135) data 0.000 (0.050) loss 1.0176 (0.7052) acc 71.8750 (81.8750) lr 1.4736e-04 eta 0:03:48
epoch [167/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.5918 (0.6819) acc 78.1250 (81.8750) lr 1.4736e-04 eta 0:03:19
epoch [167/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.3740 (0.6502) acc 84.3750 (82.8125) lr 1.4736e-04 eta 0:03:04
epoch [167/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.5156 (0.6461) acc 84.3750 (83.1250) lr 1.4736e-04 eta 0:02:55
epoch [167/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.5889 (0.6424) acc 84.3750 (83.3333) lr 1.4736e-04 eta 0:02:49
epoch [167/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.014) loss 0.6250 (0.6374) acc 78.1250 (83.1250) lr 1.4736e-04 eta 0:02:45
epoch [167/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 1.1875 (0.6519) acc 68.7500 (82.5781) lr 1.4736e-04 eta 0:02:41
epoch [167/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.6089 (0.6510) acc 81.2500 (82.6389) lr 1.4736e-04 eta 0:02:38
epoch [167/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.5195 (0.6485) acc 84.3750 (82.5625) lr 1.3926e-04 eta 0:02:35
epoch [168/200] batch [5/50] time 0.083 (0.181) data 0.000 (0.097) loss 0.6714 (0.7625) acc 87.5000 (81.2500) lr 1.3926e-04 eta 0:04:58
epoch [168/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.2676 (0.6468) acc 96.8750 (83.4375) lr 1.3926e-04 eta 0:03:37
epoch [168/200] batch [15/50] time 0.085 (0.116) data 0.000 (0.032) loss 0.7280 (0.6045) acc 90.6250 (85.0000) lr 1.3926e-04 eta 0:03:10
epoch [168/200] batch [20/50] time 0.085 (0.108) data 0.000 (0.024) loss 0.6470 (0.5997) acc 84.3750 (85.3125) lr 1.3926e-04 eta 0:02:56
epoch [168/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.4155 (0.6251) acc 93.7500 (84.7500) lr 1.3926e-04 eta 0:02:48
epoch [168/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7812 (0.6311) acc 78.1250 (84.2708) lr 1.3926e-04 eta 0:02:42
epoch [168/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 1.1836 (0.6490) acc 59.3750 (83.4821) lr 1.3926e-04 eta 0:02:38
epoch [168/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.5649 (0.6543) acc 81.2500 (83.2812) lr 1.3926e-04 eta 0:02:35
epoch [168/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0273 (0.6811) acc 75.0000 (82.5694) lr 1.3926e-04 eta 0:02:32
epoch [168/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 1.0410 (0.7029) acc 75.0000 (82.2500) lr 1.3137e-04 eta 0:02:29
epoch [169/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 0.8345 (0.5785) acc 75.0000 (86.2500) lr 1.3137e-04 eta 0:04:53
epoch [169/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.050) loss 0.8608 (0.6114) acc 78.1250 (84.0625) lr 1.3137e-04 eta 0:03:33
epoch [169/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.033) loss 1.0488 (0.6722) acc 71.8750 (82.2917) lr 1.3137e-04 eta 0:03:06
epoch [169/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.6479 (0.6511) acc 84.3750 (82.3438) lr 1.3137e-04 eta 0:02:52
epoch [169/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.7627 (0.6396) acc 81.2500 (83.1250) lr 1.3137e-04 eta 0:02:43
epoch [169/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6260 (0.6528) acc 75.0000 (82.3958) lr 1.3137e-04 eta 0:02:38
epoch [169/200] batch [35/50] time 0.085 (0.098) data 0.000 (0.014) loss 0.2883 (0.6438) acc 96.8750 (83.0357) lr 1.3137e-04 eta 0:02:34
epoch [169/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6294 (0.6365) acc 81.2500 (83.2812) lr 1.3137e-04 eta 0:02:30
epoch [169/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.5342 (0.6284) acc 81.2500 (83.5417) lr 1.3137e-04 eta 0:02:27
epoch [169/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7393 (0.6240) acc 78.1250 (83.5000) lr 1.2369e-04 eta 0:02:25
epoch [170/200] batch [5/50] time 0.084 (0.179) data 0.000 (0.094) loss 0.6802 (0.7492) acc 84.3750 (78.1250) lr 1.2369e-04 eta 0:04:36
epoch [170/200] batch [10/50] time 0.084 (0.131) data 0.000 (0.047) loss 0.8564 (0.7039) acc 71.8750 (78.7500) lr 1.2369e-04 eta 0:03:22
epoch [170/200] batch [15/50] time 0.083 (0.115) data 0.000 (0.031) loss 0.9292 (0.7363) acc 68.7500 (78.1250) lr 1.2369e-04 eta 0:02:57
epoch [170/200] batch [20/50] time 0.084 (0.107) data 0.000 (0.024) loss 0.5366 (0.7207) acc 90.6250 (79.8438) lr 1.2369e-04 eta 0:02:44
epoch [170/200] batch [25/50] time 0.084 (0.103) data 0.000 (0.019) loss 1.3916 (0.7673) acc 68.7500 (79.0000) lr 1.2369e-04 eta 0:02:36
epoch [170/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.3357 (0.7457) acc 90.6250 (79.5833) lr 1.2369e-04 eta 0:02:31
epoch [170/200] batch [35/50] time 0.084 (0.097) data 0.000 (0.014) loss 0.3982 (0.7280) acc 87.5000 (80.3571) lr 1.2369e-04 eta 0:02:27
epoch [170/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5527 (0.7220) acc 87.5000 (80.5469) lr 1.2369e-04 eta 0:02:24
epoch [170/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.6606 (0.7139) acc 84.3750 (80.8333) lr 1.2369e-04 eta 0:02:21
epoch [170/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.010) loss 0.4321 (0.6999) acc 90.6250 (81.5625) lr 1.1623e-04 eta 0:02:19
epoch [171/200] batch [5/50] time 0.084 (0.187) data 0.000 (0.102) loss 0.5083 (0.4725) acc 84.3750 (85.0000) lr 1.1623e-04 eta 0:04:39
epoch [171/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.051) loss 0.6992 (0.6543) acc 75.0000 (81.2500) lr 1.1623e-04 eta 0:03:22
epoch [171/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.034) loss 0.8052 (0.6576) acc 78.1250 (81.4583) lr 1.1623e-04 eta 0:02:56
epoch [171/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.8867 (0.7205) acc 78.1250 (80.6250) lr 1.1623e-04 eta 0:02:42
epoch [171/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.6279 (0.7020) acc 81.2500 (80.8750) lr 1.1623e-04 eta 0:02:34
epoch [171/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 1.1074 (0.7481) acc 68.7500 (79.6875) lr 1.1623e-04 eta 0:02:29
epoch [171/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.4104 (0.7230) acc 90.6250 (80.2679) lr 1.1623e-04 eta 0:02:24
epoch [171/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6299 (0.6984) acc 81.2500 (80.7812) lr 1.1623e-04 eta 0:02:21
epoch [171/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.012) loss 0.7690 (0.7193) acc 78.1250 (80.4861) lr 1.1623e-04 eta 0:02:18
epoch [171/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.4370 (0.7054) acc 84.3750 (81.0625) lr 1.0899e-04 eta 0:02:16
epoch [172/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.104) loss 0.8335 (0.6599) acc 78.1250 (80.6250) lr 1.0899e-04 eta 0:04:32
epoch [172/200] batch [10/50] time 0.085 (0.136) data 0.000 (0.052) loss 0.9067 (0.8589) acc 81.2500 (77.8125) lr 1.0899e-04 eta 0:03:16
epoch [172/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.5044 (0.7864) acc 87.5000 (79.3750) lr 1.0899e-04 eta 0:02:50
epoch [172/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.026) loss 0.6226 (0.7664) acc 78.1250 (79.5312) lr 1.0899e-04 eta 0:02:37
epoch [172/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.4509 (0.7716) acc 81.2500 (78.3750) lr 1.0899e-04 eta 0:02:29
epoch [172/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.7910 (0.7295) acc 75.0000 (79.3750) lr 1.0899e-04 eta 0:02:24
epoch [172/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.015) loss 0.4070 (0.7152) acc 87.5000 (79.7321) lr 1.0899e-04 eta 0:02:20
epoch [172/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7744 (0.7153) acc 71.8750 (79.6875) lr 1.0899e-04 eta 0:02:17
epoch [172/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.7593 (0.7170) acc 75.0000 (79.6528) lr 1.0899e-04 eta 0:02:14
epoch [172/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 0.5654 (0.7153) acc 84.3750 (79.8750) lr 1.0197e-04 eta 0:02:12
epoch [173/200] batch [5/50] time 0.085 (0.187) data 0.000 (0.103) loss 0.5464 (0.7126) acc 87.5000 (81.2500) lr 1.0197e-04 eta 0:04:21
epoch [173/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.052) loss 0.8784 (0.6966) acc 81.2500 (80.9375) lr 1.0197e-04 eta 0:03:08
epoch [173/200] batch [15/50] time 0.083 (0.118) data 0.000 (0.034) loss 0.3750 (0.6370) acc 93.7500 (83.3333) lr 1.0197e-04 eta 0:02:44
epoch [173/200] batch [20/50] time 0.083 (0.110) data 0.000 (0.026) loss 0.5625 (0.6252) acc 84.3750 (83.1250) lr 1.0197e-04 eta 0:02:31
epoch [173/200] batch [25/50] time 0.083 (0.104) data 0.000 (0.021) loss 0.8447 (0.6419) acc 81.2500 (83.0000) lr 1.0197e-04 eta 0:02:23
epoch [173/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.3750 (0.6461) acc 90.6250 (83.1250) lr 1.0197e-04 eta 0:02:18
epoch [173/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.015) loss 0.3782 (0.6606) acc 90.6250 (82.7679) lr 1.0197e-04 eta 0:02:14
epoch [173/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5215 (0.6580) acc 81.2500 (82.5781) lr 1.0197e-04 eta 0:02:11
epoch [173/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.8491 (0.6725) acc 71.8750 (82.2917) lr 1.0197e-04 eta 0:02:08
epoch [173/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.4292 (0.6758) acc 90.6250 (82.1875) lr 9.5173e-05 eta 0:02:06
epoch [174/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 0.4417 (0.7060) acc 93.7500 (84.3750) lr 9.5173e-05 eta 0:04:04
epoch [174/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.3486 (0.6048) acc 84.3750 (85.3125) lr 9.5173e-05 eta 0:02:58
epoch [174/200] batch [15/50] time 0.083 (0.117) data 0.000 (0.032) loss 0.6377 (0.6461) acc 81.2500 (83.5417) lr 9.5173e-05 eta 0:02:35
epoch [174/200] batch [20/50] time 0.083 (0.108) data 0.000 (0.024) loss 0.5537 (0.6474) acc 84.3750 (83.1250) lr 9.5173e-05 eta 0:02:24
epoch [174/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.5723 (0.6517) acc 81.2500 (82.2500) lr 9.5173e-05 eta 0:02:17
epoch [174/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.7983 (0.6734) acc 75.0000 (81.9792) lr 9.5173e-05 eta 0:02:12
epoch [174/200] batch [35/50] time 0.085 (0.098) data 0.001 (0.014) loss 0.9673 (0.6857) acc 75.0000 (81.6964) lr 9.5173e-05 eta 0:02:09
epoch [174/200] batch [40/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7651 (0.6712) acc 84.3750 (82.5781) lr 9.5173e-05 eta 0:02:06
epoch [174/200] batch [45/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9854 (0.6794) acc 68.7500 (82.2917) lr 9.5173e-05 eta 0:02:03
epoch [174/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 1.1299 (0.6951) acc 65.6250 (81.8125) lr 8.8597e-05 eta 0:02:01
epoch [175/200] batch [5/50] time 0.083 (0.178) data 0.000 (0.093) loss 0.9268 (0.6081) acc 81.2500 (82.5000) lr 8.8597e-05 eta 0:03:51
epoch [175/200] batch [10/50] time 0.085 (0.131) data 0.000 (0.047) loss 0.8633 (0.6978) acc 81.2500 (82.1875) lr 8.8597e-05 eta 0:02:49
epoch [175/200] batch [15/50] time 0.084 (0.115) data 0.000 (0.031) loss 1.0420 (0.7696) acc 75.0000 (80.8333) lr 8.8597e-05 eta 0:02:28
epoch [175/200] batch [20/50] time 0.084 (0.108) data 0.000 (0.023) loss 0.6577 (0.7231) acc 81.2500 (81.2500) lr 8.8597e-05 eta 0:02:17
epoch [175/200] batch [25/50] time 0.083 (0.103) data 0.000 (0.019) loss 0.4783 (0.6970) acc 90.6250 (82.5000) lr 8.8597e-05 eta 0:02:11
epoch [175/200] batch [30/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.1016 (0.7034) acc 78.1250 (82.0833) lr 8.8597e-05 eta 0:02:06
epoch [175/200] batch [35/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7837 (0.6907) acc 75.0000 (82.4107) lr 8.8597e-05 eta 0:02:03
epoch [175/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.3792 (0.6746) acc 90.6250 (82.5000) lr 8.8597e-05 eta 0:02:00
epoch [175/200] batch [45/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.1318 (0.6872) acc 65.6250 (81.9444) lr 8.8597e-05 eta 0:01:58
epoch [175/200] batch [50/50] time 0.084 (0.093) data 0.000 (0.009) loss 0.4429 (0.6785) acc 87.5000 (82.1875) lr 8.2245e-05 eta 0:01:56
epoch [176/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.099) loss 0.5034 (0.6898) acc 81.2500 (83.1250) lr 8.2245e-05 eta 0:03:49
epoch [176/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.049) loss 1.0225 (0.6958) acc 71.8750 (81.5625) lr 8.2245e-05 eta 0:02:46
epoch [176/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.033) loss 0.5381 (0.6756) acc 81.2500 (82.2917) lr 8.2245e-05 eta 0:02:25
epoch [176/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.4204 (0.6645) acc 84.3750 (82.0312) lr 8.2245e-05 eta 0:02:14
epoch [176/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.7476 (0.6986) acc 78.1250 (81.6250) lr 8.2245e-05 eta 0:02:07
epoch [176/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.8774 (0.6868) acc 78.1250 (82.3958) lr 8.2245e-05 eta 0:02:03
epoch [176/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.8154 (0.7010) acc 75.0000 (81.8750) lr 8.2245e-05 eta 0:01:59
epoch [176/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.5259 (0.6951) acc 87.5000 (82.1875) lr 8.2245e-05 eta 0:01:56
epoch [176/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.9102 (0.6814) acc 84.3750 (82.5694) lr 8.2245e-05 eta 0:01:54
epoch [176/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7544 (0.6807) acc 75.0000 (82.4375) lr 7.6120e-05 eta 0:01:52
epoch [177/200] batch [5/50] time 0.084 (0.184) data 0.000 (0.099) loss 0.3625 (0.7549) acc 90.6250 (80.0000) lr 7.6120e-05 eta 0:03:39
epoch [177/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.050) loss 0.8403 (0.7769) acc 75.0000 (79.6875) lr 7.6120e-05 eta 0:02:39
epoch [177/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.8071 (0.7727) acc 84.3750 (80.2083) lr 7.6120e-05 eta 0:02:18
epoch [177/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 1.0508 (0.7573) acc 71.8750 (80.0000) lr 7.6120e-05 eta 0:02:08
epoch [177/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.8647 (0.7808) acc 81.2500 (80.0000) lr 7.6120e-05 eta 0:02:02
epoch [177/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.5024 (0.7449) acc 84.3750 (81.0417) lr 7.6120e-05 eta 0:01:57
epoch [177/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4595 (0.7144) acc 90.6250 (81.6071) lr 7.6120e-05 eta 0:01:54
epoch [177/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.4163 (0.7087) acc 87.5000 (81.5625) lr 7.6120e-05 eta 0:01:52
epoch [177/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.3682 (0.6936) acc 90.6250 (81.8056) lr 7.6120e-05 eta 0:01:49
epoch [177/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.7383 (0.7085) acc 78.1250 (81.3125) lr 7.0224e-05 eta 0:01:48
epoch [178/200] batch [5/50] time 0.084 (0.186) data 0.000 (0.100) loss 0.7617 (0.6158) acc 81.2500 (83.1250) lr 7.0224e-05 eta 0:03:32
epoch [178/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.050) loss 0.7578 (0.5934) acc 71.8750 (83.1250) lr 7.0224e-05 eta 0:02:33
epoch [178/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.5659 (0.6162) acc 84.3750 (83.3333) lr 7.0224e-05 eta 0:02:14
epoch [178/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.025) loss 0.6196 (0.6280) acc 78.1250 (82.6562) lr 7.0224e-05 eta 0:02:03
epoch [178/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.8477 (0.6308) acc 75.0000 (82.7500) lr 7.0224e-05 eta 0:01:57
epoch [178/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 1.0391 (0.6275) acc 75.0000 (83.4375) lr 7.0224e-05 eta 0:01:53
epoch [178/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.7456 (0.6501) acc 78.1250 (83.3036) lr 7.0224e-05 eta 0:01:50
epoch [178/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.6729 (0.6436) acc 87.5000 (83.2031) lr 7.0224e-05 eta 0:01:47
epoch [178/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.2070 (0.6498) acc 65.6250 (82.9861) lr 7.0224e-05 eta 0:01:45
epoch [178/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.5439 (0.6624) acc 90.6250 (82.8125) lr 6.4556e-05 eta 0:01:43
epoch [179/200] batch [5/50] time 0.086 (0.181) data 0.000 (0.095) loss 0.6323 (0.6063) acc 84.3750 (83.7500) lr 6.4556e-05 eta 0:03:18
epoch [179/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.048) loss 0.5669 (0.7028) acc 84.3750 (80.3125) lr 6.4556e-05 eta 0:02:24
epoch [179/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.4958 (0.7602) acc 84.3750 (79.7917) lr 6.4556e-05 eta 0:02:06
epoch [179/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.9194 (0.7397) acc 71.8750 (79.5312) lr 6.4556e-05 eta 0:01:57
epoch [179/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.5649 (0.7258) acc 81.2500 (79.5000) lr 6.4556e-05 eta 0:01:51
epoch [179/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.2474 (0.7188) acc 93.7500 (79.4792) lr 6.4556e-05 eta 0:01:47
epoch [179/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.4570 (0.7220) acc 87.5000 (79.7321) lr 6.4556e-05 eta 0:01:44
epoch [179/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.9600 (0.7336) acc 71.8750 (79.7656) lr 6.4556e-05 eta 0:01:42
epoch [179/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.1982 (0.7444) acc 62.5000 (79.6528) lr 6.4556e-05 eta 0:01:40
epoch [179/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.8262 (0.7355) acc 84.3750 (80.0625) lr 5.9119e-05 eta 0:01:38
epoch [180/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.107) loss 0.5820 (0.7856) acc 87.5000 (78.7500) lr 5.9119e-05 eta 0:03:20
epoch [180/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.054) loss 0.9282 (0.7939) acc 75.0000 (78.4375) lr 5.9119e-05 eta 0:02:23
epoch [180/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.4873 (0.7667) acc 93.7500 (79.1667) lr 5.9119e-05 eta 0:02:04
epoch [180/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.027) loss 0.6318 (0.7407) acc 78.1250 (79.8438) lr 5.9119e-05 eta 0:01:54
epoch [180/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.4954 (0.7071) acc 87.5000 (81.1250) lr 5.9119e-05 eta 0:01:48
epoch [180/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6118 (0.6798) acc 90.6250 (82.0833) lr 5.9119e-05 eta 0:01:44
epoch [180/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.016) loss 0.8423 (0.6984) acc 75.0000 (81.6964) lr 5.9119e-05 eta 0:01:41
epoch [180/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.7939 (0.7402) acc 78.1250 (80.9375) lr 5.9119e-05 eta 0:01:38
epoch [180/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.1562 (0.7462) acc 71.8750 (80.6250) lr 5.9119e-05 eta 0:01:36
epoch [180/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6494 (0.7284) acc 81.2500 (81.0000) lr 5.3915e-05 eta 0:01:34
epoch [181/200] batch [5/50] time 0.085 (0.196) data 0.000 (0.110) loss 0.7319 (0.6566) acc 84.3750 (82.5000) lr 5.3915e-05 eta 0:03:14
epoch [181/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.055) loss 0.6431 (0.7059) acc 81.2500 (81.8750) lr 5.3915e-05 eta 0:02:18
epoch [181/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 0.5918 (0.7183) acc 81.2500 (81.6667) lr 5.3915e-05 eta 0:01:59
epoch [181/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.028) loss 0.5898 (0.6780) acc 81.2500 (82.8125) lr 5.3915e-05 eta 0:01:50
epoch [181/200] batch [25/50] time 0.084 (0.107) data 0.000 (0.022) loss 0.8882 (0.6749) acc 81.2500 (83.0000) lr 5.3915e-05 eta 0:01:44
epoch [181/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.5933 (0.6980) acc 81.2500 (81.8750) lr 5.3915e-05 eta 0:01:39
epoch [181/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.016) loss 1.0332 (0.7145) acc 78.1250 (81.7857) lr 5.3915e-05 eta 0:01:36
epoch [181/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.3010 (0.6929) acc 90.6250 (82.4219) lr 5.3915e-05 eta 0:01:34
epoch [181/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.012) loss 0.7114 (0.6918) acc 71.8750 (81.9444) lr 5.3915e-05 eta 0:01:32
epoch [181/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4954 (0.6704) acc 90.6250 (82.4375) lr 4.8943e-05 eta 0:01:30
epoch [182/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.097) loss 0.6509 (0.7592) acc 71.8750 (73.7500) lr 4.8943e-05 eta 0:02:52
epoch [182/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.049) loss 0.5850 (0.6631) acc 84.3750 (79.3750) lr 4.8943e-05 eta 0:02:05
epoch [182/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.033) loss 0.9453 (0.6705) acc 84.3750 (80.6250) lr 4.8943e-05 eta 0:01:49
epoch [182/200] batch [20/50] time 0.085 (0.109) data 0.000 (0.025) loss 1.0566 (0.6829) acc 68.7500 (80.9375) lr 4.8943e-05 eta 0:01:41
epoch [182/200] batch [25/50] time 0.084 (0.104) data 0.000 (0.020) loss 0.8701 (0.6746) acc 78.1250 (81.3750) lr 4.8943e-05 eta 0:01:36
epoch [182/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.4526 (0.6629) acc 87.5000 (81.4583) lr 4.8943e-05 eta 0:01:32
epoch [182/200] batch [35/50] time 0.084 (0.099) data 0.001 (0.014) loss 0.7183 (0.6817) acc 81.2500 (80.8036) lr 4.8943e-05 eta 0:01:30
epoch [182/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.9458 (0.6949) acc 75.0000 (80.7812) lr 4.8943e-05 eta 0:01:27
epoch [182/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.6406 (0.7019) acc 81.2500 (80.6250) lr 4.8943e-05 eta 0:01:26
epoch [182/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.2568 (0.7001) acc 90.6250 (80.6875) lr 4.4207e-05 eta 0:01:24
epoch [183/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.108) loss 0.6685 (0.4864) acc 78.1250 (87.5000) lr 4.4207e-05 eta 0:02:51
epoch [183/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.8901 (0.6896) acc 75.0000 (84.0625) lr 4.4207e-05 eta 0:02:02
epoch [183/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.7886 (0.6941) acc 81.2500 (82.7083) lr 4.4207e-05 eta 0:01:46
epoch [183/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.9653 (0.7327) acc 78.1250 (81.8750) lr 4.4207e-05 eta 0:01:37
epoch [183/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.3926 (0.6901) acc 90.6250 (82.5000) lr 4.4207e-05 eta 0:01:32
epoch [183/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.3945 (0.6818) acc 90.6250 (82.8125) lr 4.4207e-05 eta 0:01:29
epoch [183/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 0.6226 (0.6816) acc 87.5000 (82.6786) lr 4.4207e-05 eta 0:01:26
epoch [183/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.5933 (0.6927) acc 81.2500 (82.3438) lr 4.4207e-05 eta 0:01:24
epoch [183/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8203 (0.6905) acc 81.2500 (82.7083) lr 4.4207e-05 eta 0:01:22
epoch [183/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8706 (0.6960) acc 78.1250 (82.8125) lr 3.9706e-05 eta 0:01:20
epoch [184/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.106) loss 0.6812 (0.7038) acc 78.1250 (80.6250) lr 3.9706e-05 eta 0:02:41
epoch [184/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.8564 (0.7591) acc 75.0000 (79.0625) lr 3.9706e-05 eta 0:01:55
epoch [184/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 1.1973 (0.7284) acc 75.0000 (81.2500) lr 3.9706e-05 eta 0:01:40
epoch [184/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 1.4072 (0.7644) acc 65.6250 (80.3125) lr 3.9706e-05 eta 0:01:32
epoch [184/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.6362 (0.7467) acc 78.1250 (80.2500) lr 3.9706e-05 eta 0:01:27
epoch [184/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.7476 (0.7366) acc 78.1250 (80.2083) lr 3.9706e-05 eta 0:01:24
epoch [184/200] batch [35/50] time 0.084 (0.100) data 0.001 (0.015) loss 0.8667 (0.7098) acc 71.8750 (80.8036) lr 3.9706e-05 eta 0:01:21
epoch [184/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.8047 (0.6796) acc 78.1250 (81.7969) lr 3.9706e-05 eta 0:01:19
epoch [184/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.8589 (0.7049) acc 71.8750 (81.1806) lr 3.9706e-05 eta 0:01:17
epoch [184/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.2274 (0.6963) acc 93.7500 (81.2500) lr 3.5443e-05 eta 0:01:16
epoch [185/200] batch [5/50] time 0.084 (0.189) data 0.000 (0.105) loss 1.0449 (0.7885) acc 75.0000 (83.1250) lr 3.5443e-05 eta 0:02:30
epoch [185/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.052) loss 0.9712 (0.7769) acc 75.0000 (82.5000) lr 3.5443e-05 eta 0:01:48
epoch [185/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.035) loss 0.7275 (0.7497) acc 84.3750 (81.8750) lr 3.5443e-05 eta 0:01:33
epoch [185/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.3325 (0.7160) acc 84.3750 (81.8750) lr 3.5443e-05 eta 0:01:26
epoch [185/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.021) loss 0.4966 (0.6828) acc 87.5000 (82.5000) lr 3.5443e-05 eta 0:01:21
epoch [185/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.7310 (0.6836) acc 75.0000 (82.0833) lr 3.5443e-05 eta 0:01:18
epoch [185/200] batch [35/50] time 0.083 (0.099) data 0.000 (0.015) loss 0.4817 (0.6710) acc 84.3750 (82.5000) lr 3.5443e-05 eta 0:01:15
epoch [185/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.7959 (0.6735) acc 81.2500 (82.4219) lr 3.5443e-05 eta 0:01:13
epoch [185/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.012) loss 0.6851 (0.6703) acc 87.5000 (82.4306) lr 3.5443e-05 eta 0:01:12
epoch [185/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.011) loss 1.0928 (0.6558) acc 75.0000 (82.8750) lr 3.1417e-05 eta 0:01:10
epoch [186/200] batch [5/50] time 0.084 (0.191) data 0.000 (0.106) loss 0.6533 (0.7950) acc 84.3750 (81.2500) lr 3.1417e-05 eta 0:02:22
epoch [186/200] batch [10/50] time 0.085 (0.138) data 0.000 (0.053) loss 0.9429 (0.7766) acc 78.1250 (80.6250) lr 3.1417e-05 eta 0:01:41
epoch [186/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.6455 (0.7431) acc 78.1250 (81.0417) lr 3.1417e-05 eta 0:01:28
epoch [186/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.3162 (0.7295) acc 90.6250 (82.0312) lr 3.1417e-05 eta 0:01:21
epoch [186/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.3237 (0.7061) acc 93.7500 (82.1250) lr 3.1417e-05 eta 0:01:16
epoch [186/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.018) loss 0.9229 (0.6969) acc 75.0000 (82.5000) lr 3.1417e-05 eta 0:01:13
epoch [186/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.5005 (0.6803) acc 81.2500 (82.5893) lr 3.1417e-05 eta 0:01:11
epoch [186/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.8721 (0.6702) acc 75.0000 (82.9688) lr 3.1417e-05 eta 0:01:09
epoch [186/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4841 (0.6812) acc 87.5000 (82.7778) lr 3.1417e-05 eta 0:01:07
epoch [186/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5049 (0.6794) acc 90.6250 (82.8125) lr 2.7630e-05 eta 0:01:06
epoch [187/200] batch [5/50] time 0.085 (0.190) data 0.000 (0.104) loss 1.0322 (0.8664) acc 78.1250 (77.5000) lr 2.7630e-05 eta 0:02:11
epoch [187/200] batch [10/50] time 0.085 (0.137) data 0.000 (0.052) loss 0.4285 (0.7911) acc 90.6250 (80.3125) lr 2.7630e-05 eta 0:01:34
epoch [187/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.6919 (0.7479) acc 84.3750 (81.8750) lr 2.7630e-05 eta 0:01:22
epoch [187/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.026) loss 0.5376 (0.7170) acc 84.3750 (82.0312) lr 2.7630e-05 eta 0:01:15
epoch [187/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.021) loss 0.3188 (0.6788) acc 84.3750 (82.7500) lr 2.7630e-05 eta 0:01:11
epoch [187/200] batch [30/50] time 0.085 (0.102) data 0.000 (0.017) loss 0.6572 (0.6816) acc 78.1250 (82.5000) lr 2.7630e-05 eta 0:01:08
epoch [187/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.015) loss 0.9502 (0.6865) acc 78.1250 (82.4107) lr 2.7630e-05 eta 0:01:06
epoch [187/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.7046 (0.7005) acc 84.3750 (82.3438) lr 2.7630e-05 eta 0:01:04
epoch [187/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.6001 (0.6909) acc 84.3750 (82.1528) lr 2.7630e-05 eta 0:01:03
epoch [187/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6763 (0.6854) acc 75.0000 (82.1875) lr 2.4083e-05 eta 0:01:01
epoch [188/200] batch [5/50] time 0.086 (0.181) data 0.000 (0.094) loss 0.6255 (0.6309) acc 75.0000 (81.2500) lr 2.4083e-05 eta 0:01:56
epoch [188/200] batch [10/50] time 0.084 (0.133) data 0.000 (0.047) loss 1.1641 (0.7029) acc 68.7500 (79.3750) lr 2.4083e-05 eta 0:01:24
epoch [188/200] batch [15/50] time 0.084 (0.117) data 0.000 (0.032) loss 0.8193 (0.7803) acc 78.1250 (78.1250) lr 2.4083e-05 eta 0:01:14
epoch [188/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.7412 (0.8020) acc 78.1250 (77.8125) lr 2.4083e-05 eta 0:01:08
epoch [188/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.7041 (0.7798) acc 75.0000 (77.6250) lr 2.4083e-05 eta 0:01:04
epoch [188/200] batch [30/50] time 0.085 (0.101) data 0.001 (0.016) loss 0.7271 (0.7403) acc 71.8750 (78.8542) lr 2.4083e-05 eta 0:01:02
epoch [188/200] batch [35/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.7910 (0.7359) acc 78.1250 (79.2857) lr 2.4083e-05 eta 0:01:00
epoch [188/200] batch [40/50] time 0.083 (0.096) data 0.000 (0.012) loss 0.4167 (0.7126) acc 90.6250 (80.1562) lr 2.4083e-05 eta 0:00:58
epoch [188/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5649 (0.7040) acc 81.2500 (80.3472) lr 2.4083e-05 eta 0:00:57
epoch [188/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.5850 (0.7151) acc 81.2500 (80.1250) lr 2.0777e-05 eta 0:00:56
epoch [189/200] batch [5/50] time 0.084 (0.196) data 0.000 (0.111) loss 0.4568 (0.6770) acc 90.6250 (83.1250) lr 2.0777e-05 eta 0:01:56
epoch [189/200] batch [10/50] time 0.085 (0.140) data 0.000 (0.056) loss 1.6104 (0.7689) acc 59.3750 (80.3125) lr 2.0777e-05 eta 0:01:22
epoch [189/200] batch [15/50] time 0.085 (0.122) data 0.000 (0.037) loss 0.5425 (0.7184) acc 87.5000 (81.2500) lr 2.0777e-05 eta 0:01:11
epoch [189/200] batch [20/50] time 0.085 (0.112) data 0.000 (0.028) loss 0.3311 (0.6678) acc 93.7500 (82.3438) lr 2.0777e-05 eta 0:01:05
epoch [189/200] batch [25/50] time 0.085 (0.107) data 0.000 (0.023) loss 0.8062 (0.6700) acc 84.3750 (82.2500) lr 2.0777e-05 eta 0:01:01
epoch [189/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.019) loss 0.5713 (0.6920) acc 81.2500 (81.5625) lr 2.0777e-05 eta 0:00:58
epoch [189/200] batch [35/50] time 0.084 (0.101) data 0.000 (0.016) loss 0.6025 (0.6979) acc 84.3750 (81.1607) lr 2.0777e-05 eta 0:00:56
epoch [189/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.6030 (0.6925) acc 78.1250 (81.0156) lr 2.0777e-05 eta 0:00:55
epoch [189/200] batch [45/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.2213 (0.6842) acc 96.8750 (81.3889) lr 2.0777e-05 eta 0:00:53
epoch [189/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.9858 (0.6825) acc 62.5000 (81.4375) lr 1.7713e-05 eta 0:00:52
epoch [190/200] batch [5/50] time 0.085 (0.200) data 0.000 (0.114) loss 0.5664 (0.8566) acc 93.7500 (79.3750) lr 1.7713e-05 eta 0:01:48
epoch [190/200] batch [10/50] time 0.085 (0.142) data 0.000 (0.057) loss 0.4795 (0.7414) acc 87.5000 (81.5625) lr 1.7713e-05 eta 0:01:16
epoch [190/200] batch [15/50] time 0.089 (0.123) data 0.000 (0.038) loss 0.8120 (0.6858) acc 78.1250 (82.5000) lr 1.7713e-05 eta 0:01:05
epoch [190/200] batch [20/50] time 0.086 (0.114) data 0.000 (0.029) loss 0.9795 (0.7268) acc 75.0000 (80.7812) lr 1.7713e-05 eta 0:01:00
epoch [190/200] batch [25/50] time 0.085 (0.108) data 0.000 (0.023) loss 0.8711 (0.7059) acc 71.8750 (80.3750) lr 1.7713e-05 eta 0:00:56
epoch [190/200] batch [30/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.7031 (0.6879) acc 87.5000 (81.2500) lr 1.7713e-05 eta 0:00:54
epoch [190/200] batch [35/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.4478 (0.6660) acc 93.7500 (81.9643) lr 1.7713e-05 eta 0:00:52
epoch [190/200] batch [40/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.6523 (0.6790) acc 84.3750 (81.6406) lr 1.7713e-05 eta 0:00:50
epoch [190/200] batch [45/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.8535 (0.6763) acc 75.0000 (81.7361) lr 1.7713e-05 eta 0:00:49
epoch [190/200] batch [50/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7109 (0.6724) acc 75.0000 (81.8750) lr 1.4891e-05 eta 0:00:48
epoch [191/200] batch [5/50] time 0.083 (0.190) data 0.000 (0.105) loss 0.3899 (0.6308) acc 93.7500 (83.1250) lr 1.4891e-05 eta 0:01:34
epoch [191/200] batch [10/50] time 0.084 (0.137) data 0.000 (0.053) loss 0.5161 (0.7195) acc 78.1250 (80.3125) lr 1.4891e-05 eta 0:01:07
epoch [191/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.035) loss 0.4961 (0.7032) acc 90.6250 (81.8750) lr 1.4891e-05 eta 0:00:58
epoch [191/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.4546 (0.6900) acc 84.3750 (81.4062) lr 1.4891e-05 eta 0:00:53
epoch [191/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.021) loss 0.3535 (0.6729) acc 90.6250 (81.8750) lr 1.4891e-05 eta 0:00:50
epoch [191/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.8970 (0.6566) acc 81.2500 (82.2917) lr 1.4891e-05 eta 0:00:47
epoch [191/200] batch [35/50] time 0.085 (0.100) data 0.001 (0.015) loss 0.2339 (0.6427) acc 93.7500 (82.8571) lr 1.4891e-05 eta 0:00:46
epoch [191/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.013) loss 0.5581 (0.6625) acc 87.5000 (82.4219) lr 1.4891e-05 eta 0:00:44
epoch [191/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.8145 (0.6744) acc 78.1250 (82.2917) lr 1.4891e-05 eta 0:00:43
epoch [191/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.7910 (0.6767) acc 78.1250 (81.8125) lr 1.2312e-05 eta 0:00:42
epoch [192/200] batch [5/50] time 0.084 (0.182) data 0.000 (0.096) loss 0.9751 (0.6029) acc 71.8750 (83.1250) lr 1.2312e-05 eta 0:01:20
epoch [192/200] batch [10/50] time 0.086 (0.133) data 0.001 (0.048) loss 0.6025 (0.6744) acc 78.1250 (81.5625) lr 1.2312e-05 eta 0:00:58
epoch [192/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.032) loss 0.2568 (0.6619) acc 90.6250 (81.4583) lr 1.2312e-05 eta 0:00:50
epoch [192/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.024) loss 0.7114 (0.6447) acc 84.3750 (82.6562) lr 1.2312e-05 eta 0:00:46
epoch [192/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.019) loss 0.8188 (0.6684) acc 68.7500 (81.8750) lr 1.2312e-05 eta 0:00:44
epoch [192/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.016) loss 0.4946 (0.7234) acc 84.3750 (81.0417) lr 1.2312e-05 eta 0:00:42
epoch [192/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 1.0342 (0.7181) acc 65.6250 (80.9821) lr 1.2312e-05 eta 0:00:40
epoch [192/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.4890 (0.7010) acc 84.3750 (81.4062) lr 1.2312e-05 eta 0:00:39
epoch [192/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.5889 (0.6965) acc 81.2500 (81.4583) lr 1.2312e-05 eta 0:00:38
epoch [192/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7095 (0.6880) acc 81.2500 (81.6250) lr 9.9763e-06 eta 0:00:37
epoch [193/200] batch [5/50] time 0.083 (0.188) data 0.000 (0.104) loss 0.4883 (0.7625) acc 84.3750 (77.5000) lr 9.9763e-06 eta 0:01:14
epoch [193/200] batch [10/50] time 0.084 (0.136) data 0.000 (0.052) loss 0.4712 (0.7173) acc 87.5000 (79.0625) lr 9.9763e-06 eta 0:00:53
epoch [193/200] batch [15/50] time 0.084 (0.119) data 0.000 (0.035) loss 0.8184 (0.7669) acc 71.8750 (78.3333) lr 9.9763e-06 eta 0:00:45
epoch [193/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 1.0654 (0.7406) acc 71.8750 (79.3750) lr 9.9763e-06 eta 0:00:41
epoch [193/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.021) loss 0.7202 (0.7164) acc 81.2500 (80.0000) lr 9.9763e-06 eta 0:00:39
epoch [193/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.5728 (0.7000) acc 81.2500 (80.5208) lr 9.9763e-06 eta 0:00:37
epoch [193/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.6172 (0.6806) acc 81.2500 (81.3393) lr 9.9763e-06 eta 0:00:36
epoch [193/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.4756 (0.6790) acc 87.5000 (81.6406) lr 9.9763e-06 eta 0:00:35
epoch [193/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.5132 (0.6757) acc 90.6250 (82.0833) lr 9.9763e-06 eta 0:00:33
epoch [193/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.011) loss 0.8232 (0.6852) acc 78.1250 (81.7500) lr 7.8853e-06 eta 0:00:33
epoch [194/200] batch [5/50] time 0.085 (0.194) data 0.000 (0.109) loss 0.8926 (0.7319) acc 75.0000 (77.5000) lr 7.8853e-06 eta 0:01:06
epoch [194/200] batch [10/50] time 0.085 (0.139) data 0.000 (0.054) loss 0.6362 (0.7342) acc 81.2500 (78.4375) lr 7.8853e-06 eta 0:00:47
epoch [194/200] batch [15/50] time 0.084 (0.121) data 0.000 (0.036) loss 0.9272 (0.7875) acc 75.0000 (78.5417) lr 7.8853e-06 eta 0:00:40
epoch [194/200] batch [20/50] time 0.084 (0.112) data 0.000 (0.027) loss 1.2080 (0.7819) acc 65.6250 (78.4375) lr 7.8853e-06 eta 0:00:36
epoch [194/200] batch [25/50] time 0.084 (0.106) data 0.000 (0.022) loss 0.8306 (0.7877) acc 75.0000 (78.5000) lr 7.8853e-06 eta 0:00:34
epoch [194/200] batch [30/50] time 0.085 (0.103) data 0.000 (0.018) loss 0.6870 (0.7705) acc 78.1250 (78.6458) lr 7.8853e-06 eta 0:00:32
epoch [194/200] batch [35/50] time 0.084 (0.100) data 0.000 (0.016) loss 1.2100 (0.7758) acc 71.8750 (78.6607) lr 7.8853e-06 eta 0:00:31
epoch [194/200] batch [40/50] time 0.083 (0.098) data 0.000 (0.014) loss 0.9360 (0.7637) acc 75.0000 (78.9062) lr 7.8853e-06 eta 0:00:30
epoch [194/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.012) loss 1.0703 (0.7621) acc 68.7500 (78.8889) lr 7.8853e-06 eta 0:00:29
epoch [194/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.6987 (0.7441) acc 75.0000 (79.0000) lr 6.0390e-06 eta 0:00:28
epoch [195/200] batch [5/50] time 0.084 (0.192) data 0.000 (0.108) loss 0.6621 (0.5941) acc 81.2500 (84.3750) lr 6.0390e-06 eta 0:00:56
epoch [195/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.054) loss 0.5610 (0.6703) acc 87.5000 (82.8125) lr 6.0390e-06 eta 0:00:40
epoch [195/200] batch [15/50] time 0.085 (0.120) data 0.000 (0.036) loss 0.9927 (0.7333) acc 68.7500 (80.8333) lr 6.0390e-06 eta 0:00:34
epoch [195/200] batch [20/50] time 0.084 (0.111) data 0.000 (0.027) loss 0.6323 (0.7106) acc 81.2500 (81.5625) lr 6.0390e-06 eta 0:00:31
epoch [195/200] batch [25/50] time 0.083 (0.106) data 0.000 (0.022) loss 0.4849 (0.6818) acc 81.2500 (82.3750) lr 6.0390e-06 eta 0:00:29
epoch [195/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.018) loss 0.3232 (0.6781) acc 90.6250 (82.3958) lr 6.0390e-06 eta 0:00:27
epoch [195/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.016) loss 0.5059 (0.6747) acc 90.6250 (82.5000) lr 6.0390e-06 eta 0:00:26
epoch [195/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.014) loss 0.7808 (0.6695) acc 75.0000 (82.7344) lr 6.0390e-06 eta 0:00:25
epoch [195/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.7422 (0.6656) acc 87.5000 (83.1250) lr 6.0390e-06 eta 0:00:24
epoch [195/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.4749 (0.6648) acc 90.6250 (83.1875) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [5/50] time 0.085 (0.184) data 0.000 (0.098) loss 0.6602 (0.7901) acc 84.3750 (84.3750) lr 4.4380e-06 eta 0:00:45
epoch [196/200] batch [10/50] time 0.085 (0.134) data 0.000 (0.049) loss 0.6113 (0.6985) acc 84.3750 (84.6875) lr 4.4380e-06 eta 0:00:32
epoch [196/200] batch [15/50] time 0.085 (0.118) data 0.000 (0.033) loss 0.6177 (0.6969) acc 84.3750 (83.3333) lr 4.4380e-06 eta 0:00:27
epoch [196/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.7861 (0.7041) acc 75.0000 (81.7188) lr 4.4380e-06 eta 0:00:25
epoch [196/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.8203 (0.6919) acc 75.0000 (82.2500) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [30/50] time 0.084 (0.101) data 0.000 (0.017) loss 0.6978 (0.7151) acc 84.3750 (81.3542) lr 4.4380e-06 eta 0:00:22
epoch [196/200] batch [35/50] time 0.085 (0.099) data 0.000 (0.014) loss 0.9297 (0.7158) acc 75.0000 (81.2500) lr 4.4380e-06 eta 0:00:21
epoch [196/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.3396 (0.6994) acc 93.7500 (81.4844) lr 4.4380e-06 eta 0:00:20
epoch [196/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.011) loss 0.6860 (0.6854) acc 78.1250 (81.7361) lr 4.4380e-06 eta 0:00:19
epoch [196/200] batch [50/50] time 0.084 (0.094) data 0.000 (0.010) loss 0.3877 (0.6974) acc 93.7500 (81.4375) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [5/50] time 0.086 (0.187) data 0.000 (0.101) loss 0.8477 (0.7301) acc 84.3750 (83.1250) lr 3.0827e-06 eta 0:00:36
epoch [197/200] batch [10/50] time 0.084 (0.135) data 0.000 (0.050) loss 0.8467 (0.7021) acc 78.1250 (82.1875) lr 3.0827e-06 eta 0:00:25
epoch [197/200] batch [15/50] time 0.085 (0.119) data 0.000 (0.034) loss 0.7119 (0.7463) acc 81.2500 (80.2083) lr 3.0827e-06 eta 0:00:21
epoch [197/200] batch [20/50] time 0.085 (0.110) data 0.000 (0.025) loss 0.7451 (0.7755) acc 81.2500 (79.8438) lr 3.0827e-06 eta 0:00:19
epoch [197/200] batch [25/50] time 0.085 (0.105) data 0.000 (0.020) loss 0.8770 (0.7735) acc 75.0000 (79.8750) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [30/50] time 0.084 (0.102) data 0.000 (0.017) loss 0.4460 (0.7632) acc 90.6250 (80.5208) lr 3.0827e-06 eta 0:00:17
epoch [197/200] batch [35/50] time 0.085 (0.099) data 0.001 (0.015) loss 0.8345 (0.7652) acc 78.1250 (80.0893) lr 3.0827e-06 eta 0:00:16
epoch [197/200] batch [40/50] time 0.084 (0.097) data 0.000 (0.013) loss 0.7100 (0.7483) acc 81.2500 (80.5469) lr 3.0827e-06 eta 0:00:15
epoch [197/200] batch [45/50] time 0.083 (0.096) data 0.000 (0.011) loss 0.6313 (0.7378) acc 90.6250 (80.9028) lr 3.0827e-06 eta 0:00:14
epoch [197/200] batch [50/50] time 0.083 (0.095) data 0.000 (0.010) loss 0.6758 (0.7319) acc 78.1250 (80.9375) lr 1.9733e-06 eta 0:00:14
epoch [198/200] batch [5/50] time 0.083 (0.183) data 0.000 (0.098) loss 0.6802 (0.6947) acc 78.1250 (81.2500) lr 1.9733e-06 eta 0:00:26
epoch [198/200] batch [10/50] time 0.084 (0.134) data 0.000 (0.049) loss 0.5425 (0.6692) acc 81.2500 (81.2500) lr 1.9733e-06 eta 0:00:18
epoch [198/200] batch [15/50] time 0.085 (0.117) data 0.000 (0.033) loss 0.3618 (0.6559) acc 87.5000 (81.2500) lr 1.9733e-06 eta 0:00:15
epoch [198/200] batch [20/50] time 0.084 (0.109) data 0.000 (0.025) loss 0.5938 (0.6409) acc 78.1250 (81.5625) lr 1.9733e-06 eta 0:00:14
epoch [198/200] batch [25/50] time 0.085 (0.104) data 0.000 (0.020) loss 0.6001 (0.6375) acc 84.3750 (82.3750) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.6821 (0.6299) acc 81.2500 (83.0208) lr 1.9733e-06 eta 0:00:12
epoch [198/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.014) loss 0.7310 (0.6352) acc 81.2500 (82.5893) lr 1.9733e-06 eta 0:00:11
epoch [198/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.012) loss 0.5405 (0.6408) acc 90.6250 (82.8125) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 0.8633 (0.6384) acc 75.0000 (83.0556) lr 1.9733e-06 eta 0:00:09
epoch [198/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.6440 (0.6364) acc 87.5000 (83.3750) lr 1.1101e-06 eta 0:00:09
epoch [199/200] batch [5/50] time 0.083 (0.186) data 0.000 (0.102) loss 0.3491 (0.5922) acc 93.7500 (86.2500) lr 1.1101e-06 eta 0:00:17
epoch [199/200] batch [10/50] time 0.085 (0.135) data 0.000 (0.051) loss 0.8945 (0.6469) acc 78.1250 (82.8125) lr 1.1101e-06 eta 0:00:12
epoch [199/200] batch [15/50] time 0.084 (0.118) data 0.000 (0.034) loss 0.3447 (0.6444) acc 93.7500 (83.3333) lr 1.1101e-06 eta 0:00:10
epoch [199/200] batch [20/50] time 0.084 (0.110) data 0.000 (0.026) loss 0.9390 (0.6927) acc 71.8750 (82.0312) lr 1.1101e-06 eta 0:00:08
epoch [199/200] batch [25/50] time 0.084 (0.105) data 0.000 (0.020) loss 0.5625 (0.7033) acc 84.3750 (81.7500) lr 1.1101e-06 eta 0:00:07
epoch [199/200] batch [30/50] time 0.085 (0.101) data 0.000 (0.017) loss 0.7822 (0.7101) acc 81.2500 (81.5625) lr 1.1101e-06 eta 0:00:07
epoch [199/200] batch [35/50] time 0.084 (0.099) data 0.000 (0.015) loss 0.4678 (0.7306) acc 87.5000 (81.3393) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [40/50] time 0.083 (0.097) data 0.000 (0.013) loss 0.4629 (0.7074) acc 93.7500 (82.0312) lr 1.1101e-06 eta 0:00:05
epoch [199/200] batch [45/50] time 0.083 (0.095) data 0.000 (0.011) loss 1.0088 (0.7006) acc 75.0000 (82.1528) lr 1.1101e-06 eta 0:00:05
epoch [199/200] batch [50/50] time 0.083 (0.094) data 0.000 (0.010) loss 0.7617 (0.7149) acc 78.1250 (81.6250) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [5/50] time 0.085 (0.192) data 0.000 (0.107) loss 0.6499 (0.7796) acc 81.2500 (81.8750) lr 4.9344e-07 eta 0:00:08
epoch [200/200] batch [10/50] time 0.084 (0.138) data 0.000 (0.053) loss 0.8188 (0.7230) acc 81.2500 (81.5625) lr 4.9344e-07 eta 0:00:05
epoch [200/200] batch [15/50] time 0.084 (0.120) data 0.000 (0.036) loss 0.9570 (0.7145) acc 75.0000 (79.5833) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [20/50] time 0.085 (0.111) data 0.000 (0.027) loss 0.6484 (0.7287) acc 78.1250 (78.7500) lr 4.9344e-07 eta 0:00:03
epoch [200/200] batch [25/50] time 0.085 (0.106) data 0.000 (0.022) loss 0.4883 (0.6955) acc 81.2500 (79.5000) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [30/50] time 0.084 (0.103) data 0.000 (0.018) loss 0.4326 (0.6900) acc 90.6250 (80.0000) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [35/50] time 0.085 (0.100) data 0.000 (0.015) loss 0.5723 (0.6798) acc 81.2500 (80.4464) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [40/50] time 0.084 (0.098) data 0.000 (0.014) loss 0.3821 (0.6714) acc 90.6250 (80.6250) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [45/50] time 0.084 (0.096) data 0.000 (0.012) loss 0.4814 (0.6704) acc 81.2500 (80.8333) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [50/50] time 0.084 (0.095) data 0.000 (0.011) loss 0.7646 (0.6809) acc 81.2500 (80.6875) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:01<00:45,  1.24s/it]  5%|▌         | 2/38 [00:01<00:21,  1.64it/s]  8%|▊         | 3/38 [00:01<00:13,  2.53it/s] 11%|█         | 4/38 [00:01<00:09,  3.48it/s] 13%|█▎        | 5/38 [00:01<00:07,  4.40it/s] 16%|█▌        | 6/38 [00:01<00:06,  5.22it/s] 18%|█▊        | 7/38 [00:02<00:05,  5.92it/s] 21%|██        | 8/38 [00:02<00:04,  6.50it/s] 24%|██▎       | 9/38 [00:02<00:04,  6.95it/s] 26%|██▋       | 10/38 [00:02<00:03,  7.29it/s] 29%|██▉       | 11/38 [00:02<00:03,  7.12it/s] 32%|███▏      | 12/38 [00:02<00:03,  7.43it/s] 34%|███▍      | 13/38 [00:02<00:03,  7.65it/s] 37%|███▋      | 14/38 [00:02<00:03,  7.81it/s] 39%|███▉      | 15/38 [00:03<00:02,  7.92it/s] 42%|████▏     | 16/38 [00:03<00:02,  8.00it/s] 45%|████▍     | 17/38 [00:03<00:02,  8.06it/s] 47%|████▋     | 18/38 [00:03<00:02,  8.10it/s] 50%|█████     | 19/38 [00:03<00:02,  8.11it/s] 53%|█████▎    | 20/38 [00:03<00:02,  8.12it/s] 55%|█████▌    | 21/38 [00:03<00:02,  8.15it/s] 58%|█████▊    | 22/38 [00:03<00:01,  8.17it/s] 61%|██████    | 23/38 [00:04<00:01,  8.19it/s] 63%|██████▎   | 24/38 [00:04<00:01,  8.19it/s] 66%|██████▌   | 25/38 [00:04<00:01,  8.18it/s] 68%|██████▊   | 26/38 [00:04<00:01,  8.20it/s] 71%|███████   | 27/38 [00:04<00:01,  8.21it/s] 74%|███████▎  | 28/38 [00:04<00:01,  8.22it/s] 76%|███████▋  | 29/38 [00:04<00:01,  8.22it/s] 79%|███████▉  | 30/38 [00:04<00:00,  8.23it/s] 82%|████████▏ | 31/38 [00:04<00:00,  8.24it/s] 84%|████████▍ | 32/38 [00:05<00:00,  8.25it/s] 87%|████████▋ | 33/38 [00:05<00:00,  8.26it/s] 89%|████████▉ | 34/38 [00:05<00:00,  8.25it/s] 92%|█████████▏| 35/38 [00:05<00:00,  8.25it/s] 95%|█████████▍| 36/38 [00:05<00:00,  8.20it/s] 97%|█████████▋| 37/38 [00:05<00:00,  8.22it/s]100%|██████████| 38/38 [00:05<00:00,  8.58it/s]100%|██████████| 38/38 [00:05<00:00,  6.43it/s]
=> result
* total: 3,783
* correct: 3,073
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 80.5%
Elapsed: 0:16:10

for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat 
do
    for seed in 1 2 3
    do
        # evaluation
        sh scripts/coop/crossdataset_test.sh ucf101 ${dataset} ${seed} ${GPU} ${cfg} ${SHOT} ${EPOCH} ${TRAINER}
    done
done
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 imagenet 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/imagenet/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/imagenet/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:ImageNet
Loading dataset: ImageNet
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ImageNet/split_fewshot_taesup/shot_16-seed_1.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:04<34:51,  4.19s/it]  0%|          | 2/500 [00:04<15:44,  1.90s/it]  1%|          | 3/500 [00:04<09:37,  1.16s/it]  1%|          | 4/500 [00:05<06:45,  1.22it/s]  1%|          | 5/500 [00:05<05:11,  1.59it/s]  1%|          | 6/500 [00:05<04:13,  1.95it/s]  1%|▏         | 7/500 [00:05<03:37,  2.27it/s]  2%|▏         | 8/500 [00:06<03:13,  2.54it/s]  2%|▏         | 9/500 [00:06<02:57,  2.76it/s]  2%|▏         | 10/500 [00:06<02:46,  2.94it/s]  2%|▏         | 11/500 [00:07<02:39,  3.06it/s]  2%|▏         | 12/500 [00:07<02:34,  3.16it/s]  3%|▎         | 13/500 [00:07<02:30,  3.23it/s]  3%|▎         | 14/500 [00:07<02:27,  3.29it/s]  3%|▎         | 15/500 [00:08<02:26,  3.32it/s]  3%|▎         | 16/500 [00:08<02:24,  3.35it/s]  3%|▎         | 17/500 [00:08<02:23,  3.37it/s]  4%|▎         | 18/500 [00:09<02:22,  3.38it/s]  4%|▍         | 19/500 [00:09<02:21,  3.39it/s]  4%|▍         | 20/500 [00:09<02:21,  3.40it/s]  4%|▍         | 21/500 [00:10<02:20,  3.40it/s]  4%|▍         | 22/500 [00:10<02:20,  3.41it/s]  5%|▍         | 23/500 [00:10<02:19,  3.41it/s]  5%|▍         | 24/500 [00:10<02:19,  3.41it/s]  5%|▌         | 25/500 [00:11<02:19,  3.41it/s]  5%|▌         | 26/500 [00:11<02:19,  3.41it/s]  5%|▌         | 27/500 [00:11<02:18,  3.41it/s]  6%|▌         | 28/500 [00:12<02:18,  3.41it/s]  6%|▌         | 29/500 [00:12<02:18,  3.39it/s]  6%|▌         | 30/500 [00:12<02:18,  3.40it/s]  6%|▌         | 31/500 [00:12<02:17,  3.41it/s]  6%|▋         | 32/500 [00:13<02:17,  3.41it/s]  7%|▋         | 33/500 [00:13<02:17,  3.41it/s]  7%|▋         | 34/500 [00:13<02:16,  3.41it/s]  7%|▋         | 35/500 [00:14<02:16,  3.40it/s]  7%|▋         | 36/500 [00:14<02:16,  3.40it/s]  7%|▋         | 37/500 [00:14<02:15,  3.41it/s]  8%|▊         | 38/500 [00:15<02:15,  3.41it/s]  8%|▊         | 39/500 [00:15<02:15,  3.41it/s]  8%|▊         | 40/500 [00:15<02:14,  3.41it/s]  8%|▊         | 41/500 [00:15<02:14,  3.41it/s]  8%|▊         | 42/500 [00:16<02:14,  3.41it/s]  9%|▊         | 43/500 [00:16<02:14,  3.41it/s]  9%|▉         | 44/500 [00:16<02:13,  3.40it/s]  9%|▉         | 45/500 [00:17<02:13,  3.40it/s]  9%|▉         | 46/500 [00:17<02:13,  3.40it/s]  9%|▉         | 47/500 [00:17<02:13,  3.40it/s] 10%|▉         | 48/500 [00:17<02:12,  3.40it/s] 10%|▉         | 49/500 [00:18<02:12,  3.40it/s] 10%|█         | 50/500 [00:18<02:12,  3.40it/s] 10%|█         | 51/500 [00:18<02:12,  3.40it/s] 10%|█         | 52/500 [00:19<02:11,  3.40it/s] 11%|█         | 53/500 [00:19<02:11,  3.40it/s] 11%|█         | 54/500 [00:19<02:11,  3.40it/s] 11%|█         | 55/500 [00:20<02:10,  3.40it/s] 11%|█         | 56/500 [00:20<02:10,  3.40it/s] 11%|█▏        | 57/500 [00:20<02:10,  3.40it/s] 12%|█▏        | 58/500 [00:20<02:09,  3.40it/s] 12%|█▏        | 59/500 [00:21<02:09,  3.40it/s] 12%|█▏        | 60/500 [00:21<02:09,  3.40it/s] 12%|█▏        | 61/500 [00:21<02:09,  3.40it/s] 12%|█▏        | 62/500 [00:22<02:08,  3.40it/s] 13%|█▎        | 63/500 [00:22<02:08,  3.39it/s] 13%|█▎        | 64/500 [00:22<02:08,  3.40it/s] 13%|█▎        | 65/500 [00:22<02:08,  3.40it/s] 13%|█▎        | 66/500 [00:23<02:08,  3.39it/s] 13%|█▎        | 67/500 [00:23<02:07,  3.39it/s] 14%|█▎        | 68/500 [00:23<02:07,  3.40it/s] 14%|█▍        | 69/500 [00:24<02:06,  3.39it/s] 14%|█▍        | 70/500 [00:24<02:06,  3.39it/s] 14%|█▍        | 71/500 [00:24<02:06,  3.39it/s] 14%|█▍        | 72/500 [00:25<02:06,  3.39it/s] 15%|█▍        | 73/500 [00:25<02:06,  3.39it/s] 15%|█▍        | 74/500 [00:25<02:05,  3.39it/s] 15%|█▌        | 75/500 [00:25<02:05,  3.39it/s] 15%|█▌        | 76/500 [00:26<02:05,  3.39it/s] 15%|█▌        | 77/500 [00:26<02:04,  3.39it/s] 16%|█▌        | 78/500 [00:26<02:04,  3.38it/s] 16%|█▌        | 79/500 [00:27<02:04,  3.39it/s] 16%|█▌        | 80/500 [00:27<02:03,  3.39it/s] 16%|█▌        | 81/500 [00:27<02:03,  3.39it/s] 16%|█▋        | 82/500 [00:27<02:03,  3.39it/s] 17%|█▋        | 83/500 [00:28<02:02,  3.39it/s] 17%|█▋        | 84/500 [00:28<02:02,  3.39it/s] 17%|█▋        | 85/500 [00:28<02:02,  3.39it/s] 17%|█▋        | 86/500 [00:29<02:02,  3.39it/s] 17%|█▋        | 87/500 [00:29<02:01,  3.39it/s] 18%|█▊        | 88/500 [00:29<02:01,  3.39it/s] 18%|█▊        | 89/500 [00:30<02:01,  3.39it/s] 18%|█▊        | 90/500 [00:30<02:00,  3.40it/s] 18%|█▊        | 91/500 [00:30<02:00,  3.40it/s] 18%|█▊        | 92/500 [00:30<02:00,  3.39it/s] 19%|█▊        | 93/500 [00:31<02:00,  3.39it/s] 19%|█▉        | 94/500 [00:31<01:59,  3.39it/s] 19%|█▉        | 95/500 [00:31<01:59,  3.39it/s] 19%|█▉        | 96/500 [00:32<01:59,  3.39it/s] 19%|█▉        | 97/500 [00:32<01:58,  3.39it/s] 20%|█▉        | 98/500 [00:32<01:58,  3.39it/s] 20%|█▉        | 99/500 [00:32<01:58,  3.39it/s] 20%|██        | 100/500 [00:33<01:58,  3.39it/s] 20%|██        | 101/500 [00:33<01:57,  3.39it/s] 20%|██        | 102/500 [00:33<01:57,  3.39it/s] 21%|██        | 103/500 [00:34<01:57,  3.39it/s] 21%|██        | 104/500 [00:34<01:56,  3.39it/s] 21%|██        | 105/500 [00:34<01:56,  3.39it/s] 21%|██        | 106/500 [00:35<01:56,  3.39it/s] 21%|██▏       | 107/500 [00:35<01:56,  3.38it/s] 22%|██▏       | 108/500 [00:35<01:56,  3.38it/s] 22%|██▏       | 109/500 [00:35<01:55,  3.38it/s] 22%|██▏       | 110/500 [00:36<01:55,  3.38it/s] 22%|██▏       | 111/500 [00:36<01:54,  3.39it/s] 22%|██▏       | 112/500 [00:36<01:54,  3.39it/s] 23%|██▎       | 113/500 [00:37<01:54,  3.39it/s] 23%|██▎       | 114/500 [00:37<01:54,  3.39it/s] 23%|██▎       | 115/500 [00:37<01:53,  3.38it/s] 23%|██▎       | 116/500 [00:38<01:53,  3.39it/s] 23%|██▎       | 117/500 [00:38<01:53,  3.39it/s] 24%|██▎       | 118/500 [00:38<01:52,  3.39it/s] 24%|██▍       | 119/500 [00:38<01:52,  3.38it/s] 24%|██▍       | 120/500 [00:39<01:52,  3.39it/s] 24%|██▍       | 121/500 [00:39<01:52,  3.38it/s] 24%|██▍       | 122/500 [00:39<01:51,  3.39it/s] 25%|██▍       | 123/500 [00:40<01:51,  3.38it/s] 25%|██▍       | 124/500 [00:40<01:51,  3.38it/s] 25%|██▌       | 125/500 [00:40<01:50,  3.38it/s] 25%|██▌       | 126/500 [00:40<01:50,  3.38it/s] 25%|██▌       | 127/500 [00:41<01:50,  3.38it/s] 26%|██▌       | 128/500 [00:41<01:50,  3.38it/s] 26%|██▌       | 129/500 [00:41<01:49,  3.38it/s] 26%|██▌       | 130/500 [00:42<01:49,  3.38it/s] 26%|██▌       | 131/500 [00:42<01:49,  3.38it/s] 26%|██▋       | 132/500 [00:42<01:48,  3.38it/s] 27%|██▋       | 133/500 [00:43<01:48,  3.38it/s] 27%|██▋       | 134/500 [00:43<01:48,  3.38it/s] 27%|██▋       | 135/500 [00:43<01:47,  3.38it/s] 27%|██▋       | 136/500 [00:43<01:47,  3.38it/s] 27%|██▋       | 137/500 [00:44<01:47,  3.37it/s] 28%|██▊       | 138/500 [00:44<01:47,  3.37it/s] 28%|██▊       | 139/500 [00:44<01:47,  3.37it/s] 28%|██▊       | 140/500 [00:45<01:46,  3.37it/s] 28%|██▊       | 141/500 [00:45<01:46,  3.37it/s] 28%|██▊       | 142/500 [00:45<01:45,  3.38it/s] 29%|██▊       | 143/500 [00:46<01:45,  3.38it/s] 29%|██▉       | 144/500 [00:46<01:45,  3.38it/s] 29%|██▉       | 145/500 [00:46<01:45,  3.38it/s] 29%|██▉       | 146/500 [00:46<01:44,  3.38it/s] 29%|██▉       | 147/500 [00:47<01:44,  3.37it/s] 30%|██▉       | 148/500 [00:47<01:44,  3.37it/s] 30%|██▉       | 149/500 [00:47<01:44,  3.37it/s] 30%|███       | 150/500 [00:48<01:43,  3.38it/s] 30%|███       | 151/500 [00:48<01:43,  3.37it/s] 30%|███       | 152/500 [00:48<01:43,  3.37it/s] 31%|███       | 153/500 [00:48<01:42,  3.37it/s] 31%|███       | 154/500 [00:49<01:42,  3.37it/s] 31%|███       | 155/500 [00:49<01:42,  3.37it/s] 31%|███       | 156/500 [00:49<01:42,  3.37it/s] 31%|███▏      | 157/500 [00:50<01:41,  3.37it/s] 32%|███▏      | 158/500 [00:50<01:41,  3.38it/s] 32%|███▏      | 159/500 [00:50<01:40,  3.38it/s] 32%|███▏      | 160/500 [00:51<01:40,  3.38it/s] 32%|███▏      | 161/500 [00:51<01:40,  3.38it/s] 32%|███▏      | 162/500 [00:51<01:40,  3.37it/s] 33%|███▎      | 163/500 [00:51<01:40,  3.37it/s] 33%|███▎      | 164/500 [00:52<01:39,  3.37it/s] 33%|███▎      | 165/500 [00:52<01:39,  3.37it/s] 33%|███▎      | 166/500 [00:52<01:38,  3.38it/s] 33%|███▎      | 167/500 [00:53<01:38,  3.38it/s] 34%|███▎      | 168/500 [00:53<01:38,  3.38it/s] 34%|███▍      | 169/500 [00:53<01:37,  3.38it/s] 34%|███▍      | 170/500 [00:54<01:37,  3.38it/s] 34%|███▍      | 171/500 [00:54<01:37,  3.38it/s] 34%|███▍      | 172/500 [00:54<01:37,  3.38it/s] 35%|███▍      | 173/500 [00:54<01:36,  3.38it/s] 35%|███▍      | 174/500 [00:55<01:36,  3.37it/s] 35%|███▌      | 175/500 [00:55<01:36,  3.37it/s] 35%|███▌      | 176/500 [00:55<01:36,  3.37it/s] 35%|███▌      | 177/500 [00:56<01:35,  3.37it/s] 36%|███▌      | 178/500 [00:56<01:35,  3.37it/s] 36%|███▌      | 179/500 [00:56<01:35,  3.37it/s] 36%|███▌      | 180/500 [00:56<01:34,  3.37it/s] 36%|███▌      | 181/500 [00:57<01:35,  3.35it/s] 36%|███▋      | 182/500 [00:57<01:34,  3.36it/s] 37%|███▋      | 183/500 [00:57<01:34,  3.37it/s] 37%|███▋      | 184/500 [00:58<01:33,  3.37it/s] 37%|███▋      | 185/500 [00:58<01:33,  3.37it/s] 37%|███▋      | 186/500 [00:58<01:33,  3.38it/s] 37%|███▋      | 187/500 [00:59<01:32,  3.38it/s] 38%|███▊      | 188/500 [00:59<01:32,  3.37it/s] 38%|███▊      | 189/500 [00:59<01:32,  3.38it/s] 38%|███▊      | 190/500 [00:59<01:31,  3.38it/s] 38%|███▊      | 191/500 [01:00<01:31,  3.38it/s] 38%|███▊      | 192/500 [01:00<01:31,  3.38it/s] 39%|███▊      | 193/500 [01:00<01:31,  3.37it/s] 39%|███▉      | 194/500 [01:01<01:30,  3.36it/s] 39%|███▉      | 195/500 [01:01<01:30,  3.36it/s] 39%|███▉      | 196/500 [01:01<01:30,  3.36it/s] 39%|███▉      | 197/500 [01:02<01:30,  3.37it/s] 40%|███▉      | 198/500 [01:02<01:29,  3.36it/s] 40%|███▉      | 199/500 [01:02<01:29,  3.37it/s] 40%|████      | 200/500 [01:02<01:29,  3.37it/s] 40%|████      | 201/500 [01:03<01:28,  3.37it/s] 40%|████      | 202/500 [01:03<01:28,  3.37it/s] 41%|████      | 203/500 [01:03<01:28,  3.37it/s] 41%|████      | 204/500 [01:04<01:27,  3.37it/s] 41%|████      | 205/500 [01:04<01:27,  3.37it/s] 41%|████      | 206/500 [01:04<01:27,  3.38it/s] 41%|████▏     | 207/500 [01:04<01:26,  3.37it/s] 42%|████▏     | 208/500 [01:05<01:26,  3.36it/s] 42%|████▏     | 209/500 [01:05<01:26,  3.37it/s] 42%|████▏     | 210/500 [01:05<01:26,  3.36it/s] 42%|████▏     | 211/500 [01:06<01:25,  3.36it/s] 42%|████▏     | 212/500 [01:06<01:25,  3.36it/s] 43%|████▎     | 213/500 [01:06<01:25,  3.36it/s] 43%|████▎     | 214/500 [01:07<01:25,  3.35it/s] 43%|████▎     | 215/500 [01:07<01:24,  3.35it/s] 43%|████▎     | 216/500 [01:07<01:24,  3.36it/s] 43%|████▎     | 217/500 [01:07<01:24,  3.36it/s] 44%|████▎     | 218/500 [01:08<01:23,  3.36it/s] 44%|████▍     | 219/500 [01:08<01:23,  3.36it/s] 44%|████▍     | 220/500 [01:08<01:23,  3.36it/s] 44%|████▍     | 221/500 [01:09<01:23,  3.36it/s] 44%|████▍     | 222/500 [01:09<01:22,  3.36it/s] 45%|████▍     | 223/500 [01:09<01:22,  3.36it/s] 45%|████▍     | 224/500 [01:10<01:22,  3.36it/s] 45%|████▌     | 225/500 [01:10<01:21,  3.36it/s] 45%|████▌     | 226/500 [01:10<01:21,  3.36it/s] 45%|████▌     | 227/500 [01:10<01:21,  3.36it/s] 46%|████▌     | 228/500 [01:11<01:20,  3.36it/s] 46%|████▌     | 229/500 [01:11<01:20,  3.36it/s] 46%|████▌     | 230/500 [01:11<01:20,  3.36it/s] 46%|████▌     | 231/500 [01:12<01:20,  3.36it/s] 46%|████▋     | 232/500 [01:12<01:19,  3.36it/s] 47%|████▋     | 233/500 [01:12<01:19,  3.36it/s] 47%|████▋     | 234/500 [01:13<01:19,  3.36it/s] 47%|████▋     | 235/500 [01:13<01:18,  3.36it/s] 47%|████▋     | 236/500 [01:13<01:18,  3.36it/s] 47%|████▋     | 237/500 [01:13<01:18,  3.37it/s] 48%|████▊     | 238/500 [01:14<01:17,  3.37it/s] 48%|████▊     | 239/500 [01:14<01:17,  3.37it/s] 48%|████▊     | 240/500 [01:14<01:17,  3.37it/s] 48%|████▊     | 241/500 [01:15<01:16,  3.36it/s] 48%|████▊     | 242/500 [01:15<01:16,  3.37it/s] 49%|████▊     | 243/500 [01:15<01:16,  3.37it/s] 49%|████▉     | 244/500 [01:15<01:16,  3.37it/s] 49%|████▉     | 245/500 [01:16<01:15,  3.37it/s] 49%|████▉     | 246/500 [01:16<01:15,  3.37it/s] 49%|████▉     | 247/500 [01:16<01:15,  3.36it/s] 50%|████▉     | 248/500 [01:17<01:14,  3.37it/s] 50%|████▉     | 249/500 [01:17<01:14,  3.37it/s] 50%|█████     | 250/500 [01:17<01:14,  3.36it/s] 50%|█████     | 251/500 [01:18<01:14,  3.36it/s] 50%|█████     | 252/500 [01:18<01:13,  3.36it/s] 51%|█████     | 253/500 [01:18<01:13,  3.37it/s] 51%|█████     | 254/500 [01:18<01:13,  3.37it/s] 51%|█████     | 255/500 [01:19<01:12,  3.37it/s] 51%|█████     | 256/500 [01:19<01:12,  3.36it/s] 51%|█████▏    | 257/500 [01:19<01:12,  3.36it/s] 52%|█████▏    | 258/500 [01:20<01:11,  3.36it/s] 52%|█████▏    | 259/500 [01:20<01:11,  3.36it/s] 52%|█████▏    | 260/500 [01:20<01:11,  3.36it/s] 52%|█████▏    | 261/500 [01:21<01:11,  3.36it/s] 52%|█████▏    | 262/500 [01:21<01:10,  3.36it/s] 53%|█████▎    | 263/500 [01:21<01:10,  3.37it/s] 53%|█████▎    | 264/500 [01:21<01:10,  3.37it/s] 53%|█████▎    | 265/500 [01:22<01:09,  3.37it/s] 53%|█████▎    | 266/500 [01:22<01:09,  3.37it/s] 53%|█████▎    | 267/500 [01:22<01:09,  3.37it/s] 54%|█████▎    | 268/500 [01:23<01:08,  3.36it/s] 54%|█████▍    | 269/500 [01:23<01:08,  3.36it/s] 54%|█████▍    | 270/500 [01:23<01:08,  3.36it/s] 54%|█████▍    | 271/500 [01:24<01:08,  3.36it/s] 54%|█████▍    | 272/500 [01:24<01:07,  3.36it/s] 55%|█████▍    | 273/500 [01:24<01:07,  3.36it/s] 55%|█████▍    | 274/500 [01:24<01:07,  3.37it/s] 55%|█████▌    | 275/500 [01:25<01:06,  3.36it/s] 55%|█████▌    | 276/500 [01:25<01:06,  3.36it/s] 55%|█████▌    | 277/500 [01:25<01:06,  3.36it/s] 56%|█████▌    | 278/500 [01:26<01:06,  3.36it/s] 56%|█████▌    | 279/500 [01:26<01:05,  3.36it/s] 56%|█████▌    | 280/500 [01:26<01:05,  3.36it/s] 56%|█████▌    | 281/500 [01:26<01:05,  3.36it/s] 56%|█████▋    | 282/500 [01:27<01:04,  3.36it/s] 57%|█████▋    | 283/500 [01:27<01:04,  3.35it/s] 57%|█████▋    | 284/500 [01:27<01:04,  3.36it/s] 57%|█████▋    | 285/500 [01:28<01:04,  3.36it/s] 57%|█████▋    | 286/500 [01:28<01:03,  3.36it/s] 57%|█████▋    | 287/500 [01:28<01:03,  3.35it/s] 58%|█████▊    | 288/500 [01:29<01:03,  3.35it/s] 58%|█████▊    | 289/500 [01:29<01:02,  3.35it/s] 58%|█████▊    | 290/500 [01:29<01:02,  3.35it/s] 58%|█████▊    | 291/500 [01:29<01:02,  3.36it/s] 58%|█████▊    | 292/500 [01:30<01:01,  3.36it/s] 59%|█████▊    | 293/500 [01:30<01:01,  3.35it/s] 59%|█████▉    | 294/500 [01:30<01:01,  3.35it/s] 59%|█████▉    | 295/500 [01:31<01:01,  3.35it/s] 59%|█████▉    | 296/500 [01:31<01:00,  3.36it/s] 59%|█████▉    | 297/500 [01:31<01:00,  3.36it/s] 60%|█████▉    | 298/500 [01:32<01:00,  3.36it/s] 60%|█████▉    | 299/500 [01:32<00:59,  3.36it/s] 60%|██████    | 300/500 [01:32<00:59,  3.36it/s] 60%|██████    | 301/500 [01:32<00:59,  3.36it/s] 60%|██████    | 302/500 [01:33<00:58,  3.37it/s] 61%|██████    | 303/500 [01:33<00:58,  3.37it/s] 61%|██████    | 304/500 [01:33<00:58,  3.37it/s] 61%|██████    | 305/500 [01:34<00:57,  3.37it/s] 61%|██████    | 306/500 [01:34<00:57,  3.36it/s] 61%|██████▏   | 307/500 [01:34<00:57,  3.36it/s] 62%|██████▏   | 308/500 [01:35<00:57,  3.35it/s] 62%|██████▏   | 309/500 [01:35<00:56,  3.36it/s] 62%|██████▏   | 310/500 [01:35<00:56,  3.36it/s] 62%|██████▏   | 311/500 [01:35<00:56,  3.36it/s] 62%|██████▏   | 312/500 [01:36<00:55,  3.36it/s] 63%|██████▎   | 313/500 [01:36<00:55,  3.36it/s] 63%|██████▎   | 314/500 [01:36<00:55,  3.36it/s] 63%|██████▎   | 315/500 [01:37<00:55,  3.36it/s] 63%|██████▎   | 316/500 [01:37<00:54,  3.36it/s] 63%|██████▎   | 317/500 [01:37<00:54,  3.36it/s] 64%|██████▎   | 318/500 [01:38<00:54,  3.36it/s] 64%|██████▍   | 319/500 [01:38<00:53,  3.36it/s] 64%|██████▍   | 320/500 [01:38<00:53,  3.37it/s] 64%|██████▍   | 321/500 [01:38<00:53,  3.37it/s] 64%|██████▍   | 322/500 [01:39<00:52,  3.37it/s] 65%|██████▍   | 323/500 [01:39<00:52,  3.37it/s] 65%|██████▍   | 324/500 [01:39<00:52,  3.36it/s] 65%|██████▌   | 325/500 [01:40<00:52,  3.36it/s] 65%|██████▌   | 326/500 [01:40<00:51,  3.36it/s] 65%|██████▌   | 327/500 [01:40<00:51,  3.37it/s] 66%|██████▌   | 328/500 [01:40<00:51,  3.37it/s] 66%|██████▌   | 329/500 [01:41<00:50,  3.37it/s] 66%|██████▌   | 330/500 [01:41<00:50,  3.37it/s] 66%|██████▌   | 331/500 [01:41<00:50,  3.37it/s] 66%|██████▋   | 332/500 [01:42<00:50,  3.36it/s] 67%|██████▋   | 333/500 [01:42<00:49,  3.36it/s] 67%|██████▋   | 334/500 [01:42<00:49,  3.36it/s] 67%|██████▋   | 335/500 [01:43<00:49,  3.36it/s] 67%|██████▋   | 336/500 [01:43<00:48,  3.36it/s] 67%|██████▋   | 337/500 [01:43<00:48,  3.36it/s] 68%|██████▊   | 338/500 [01:43<00:48,  3.36it/s] 68%|██████▊   | 339/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 340/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 341/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 342/500 [01:45<00:47,  3.36it/s] 69%|██████▊   | 343/500 [01:45<00:46,  3.36it/s] 69%|██████▉   | 344/500 [01:45<00:46,  3.36it/s] 69%|██████▉   | 345/500 [01:46<00:46,  3.36it/s] 69%|██████▉   | 346/500 [01:46<00:45,  3.36it/s] 69%|██████▉   | 347/500 [01:46<00:45,  3.36it/s] 70%|██████▉   | 348/500 [01:46<00:45,  3.36it/s] 70%|██████▉   | 349/500 [01:47<00:45,  3.36it/s] 70%|███████   | 350/500 [01:47<00:44,  3.36it/s] 70%|███████   | 351/500 [01:47<00:44,  3.36it/s] 70%|███████   | 352/500 [01:48<00:44,  3.36it/s] 71%|███████   | 353/500 [01:48<00:43,  3.36it/s] 71%|███████   | 354/500 [01:48<00:43,  3.36it/s] 71%|███████   | 355/500 [01:49<00:43,  3.36it/s] 71%|███████   | 356/500 [01:49<00:42,  3.36it/s] 71%|███████▏  | 357/500 [01:49<00:42,  3.36it/s] 72%|███████▏  | 358/500 [01:49<00:42,  3.35it/s] 72%|███████▏  | 359/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 360/500 [01:50<00:41,  3.35it/s] 72%|███████▏  | 361/500 [01:50<00:41,  3.36it/s] 72%|███████▏  | 362/500 [01:51<00:41,  3.36it/s] 73%|███████▎  | 363/500 [01:51<00:40,  3.36it/s] 73%|███████▎  | 364/500 [01:51<00:40,  3.36it/s] 73%|███████▎  | 365/500 [01:51<00:40,  3.36it/s] 73%|███████▎  | 366/500 [01:52<00:39,  3.36it/s] 73%|███████▎  | 367/500 [01:52<00:39,  3.35it/s] 74%|███████▎  | 368/500 [01:52<00:39,  3.35it/s] 74%|███████▍  | 369/500 [01:53<00:39,  3.35it/s] 74%|███████▍  | 370/500 [01:53<00:38,  3.35it/s] 74%|███████▍  | 371/500 [01:53<00:38,  3.36it/s] 74%|███████▍  | 372/500 [01:54<00:38,  3.36it/s] 75%|███████▍  | 373/500 [01:54<00:37,  3.36it/s] 75%|███████▍  | 374/500 [01:54<00:37,  3.35it/s] 75%|███████▌  | 375/500 [01:54<00:37,  3.36it/s] 75%|███████▌  | 376/500 [01:55<00:36,  3.36it/s] 75%|███████▌  | 377/500 [01:55<00:36,  3.36it/s] 76%|███████▌  | 378/500 [01:55<00:36,  3.36it/s] 76%|███████▌  | 379/500 [01:56<00:36,  3.35it/s] 76%|███████▌  | 380/500 [01:56<00:35,  3.35it/s] 76%|███████▌  | 381/500 [01:56<00:35,  3.35it/s] 76%|███████▋  | 382/500 [01:57<00:35,  3.35it/s] 77%|███████▋  | 383/500 [01:57<00:34,  3.35it/s] 77%|███████▋  | 384/500 [01:57<00:34,  3.35it/s] 77%|███████▋  | 385/500 [01:57<00:34,  3.36it/s] 77%|███████▋  | 386/500 [01:58<00:34,  3.35it/s] 77%|███████▋  | 387/500 [01:58<00:33,  3.35it/s] 78%|███████▊  | 388/500 [01:58<00:33,  3.36it/s] 78%|███████▊  | 389/500 [01:59<00:33,  3.36it/s] 78%|███████▊  | 390/500 [01:59<00:32,  3.36it/s] 78%|███████▊  | 391/500 [01:59<00:32,  3.37it/s] 78%|███████▊  | 392/500 [02:00<00:32,  3.37it/s] 79%|███████▊  | 393/500 [02:00<00:31,  3.37it/s] 79%|███████▉  | 394/500 [02:00<00:31,  3.37it/s] 79%|███████▉  | 395/500 [02:00<00:31,  3.37it/s] 79%|███████▉  | 396/500 [02:01<00:30,  3.36it/s] 79%|███████▉  | 397/500 [02:01<00:30,  3.36it/s] 80%|███████▉  | 398/500 [02:01<00:30,  3.37it/s] 80%|███████▉  | 399/500 [02:02<00:30,  3.37it/s] 80%|████████  | 400/500 [02:02<00:29,  3.36it/s] 80%|████████  | 401/500 [02:02<00:29,  3.36it/s] 80%|████████  | 402/500 [02:03<00:29,  3.36it/s] 81%|████████  | 403/500 [02:03<00:28,  3.36it/s] 81%|████████  | 404/500 [02:03<00:28,  3.36it/s] 81%|████████  | 405/500 [02:03<00:28,  3.36it/s] 81%|████████  | 406/500 [02:04<00:27,  3.36it/s] 81%|████████▏ | 407/500 [02:04<00:27,  3.36it/s] 82%|████████▏ | 408/500 [02:04<00:27,  3.36it/s] 82%|████████▏ | 409/500 [02:05<00:27,  3.36it/s] 82%|████████▏ | 410/500 [02:05<00:26,  3.36it/s] 82%|████████▏ | 411/500 [02:05<00:26,  3.36it/s] 82%|████████▏ | 412/500 [02:05<00:26,  3.36it/s] 83%|████████▎ | 413/500 [02:06<00:25,  3.36it/s] 83%|████████▎ | 414/500 [02:06<00:25,  3.36it/s] 83%|████████▎ | 415/500 [02:06<00:25,  3.36it/s] 83%|████████▎ | 416/500 [02:07<00:25,  3.36it/s] 83%|████████▎ | 417/500 [02:07<00:24,  3.36it/s] 84%|████████▎ | 418/500 [02:07<00:24,  3.36it/s] 84%|████████▍ | 419/500 [02:08<00:24,  3.36it/s] 84%|████████▍ | 420/500 [02:08<00:23,  3.35it/s] 84%|████████▍ | 421/500 [02:08<00:23,  3.36it/s] 84%|████████▍ | 422/500 [02:08<00:23,  3.36it/s] 85%|████████▍ | 423/500 [02:09<00:22,  3.36it/s] 85%|████████▍ | 424/500 [02:09<00:22,  3.36it/s] 85%|████████▌ | 425/500 [02:09<00:22,  3.36it/s] 85%|████████▌ | 426/500 [02:10<00:22,  3.36it/s] 85%|████████▌ | 427/500 [02:10<00:21,  3.36it/s] 86%|████████▌ | 428/500 [02:10<00:21,  3.36it/s] 86%|████████▌ | 429/500 [02:11<00:21,  3.36it/s] 86%|████████▌ | 430/500 [02:11<00:20,  3.36it/s] 86%|████████▌ | 431/500 [02:11<00:20,  3.36it/s] 86%|████████▋ | 432/500 [02:11<00:20,  3.36it/s] 87%|████████▋ | 433/500 [02:12<00:19,  3.36it/s] 87%|████████▋ | 434/500 [02:12<00:19,  3.35it/s] 87%|████████▋ | 435/500 [02:12<00:19,  3.35it/s] 87%|████████▋ | 436/500 [02:13<00:19,  3.36it/s] 87%|████████▋ | 437/500 [02:13<00:18,  3.36it/s] 88%|████████▊ | 438/500 [02:13<00:18,  3.36it/s] 88%|████████▊ | 439/500 [02:14<00:18,  3.36it/s] 88%|████████▊ | 440/500 [02:14<00:17,  3.36it/s] 88%|████████▊ | 441/500 [02:14<00:17,  3.36it/s] 88%|████████▊ | 442/500 [02:14<00:17,  3.36it/s] 89%|████████▊ | 443/500 [02:15<00:16,  3.36it/s] 89%|████████▉ | 444/500 [02:15<00:16,  3.36it/s] 89%|████████▉ | 445/500 [02:15<00:16,  3.36it/s] 89%|████████▉ | 446/500 [02:16<00:16,  3.36it/s] 89%|████████▉ | 447/500 [02:16<00:15,  3.36it/s] 90%|████████▉ | 448/500 [02:16<00:15,  3.36it/s] 90%|████████▉ | 449/500 [02:17<00:15,  3.36it/s] 90%|█████████ | 450/500 [02:17<00:14,  3.35it/s] 90%|█████████ | 451/500 [02:17<00:14,  3.36it/s] 90%|█████████ | 452/500 [02:17<00:14,  3.36it/s] 91%|█████████ | 453/500 [02:18<00:14,  3.36it/s] 91%|█████████ | 454/500 [02:18<00:13,  3.36it/s] 91%|█████████ | 455/500 [02:18<00:13,  3.35it/s] 91%|█████████ | 456/500 [02:19<00:13,  3.35it/s] 91%|█████████▏| 457/500 [02:19<00:12,  3.35it/s] 92%|█████████▏| 458/500 [02:19<00:12,  3.36it/s] 92%|█████████▏| 459/500 [02:19<00:12,  3.36it/s] 92%|█████████▏| 460/500 [02:20<00:11,  3.36it/s] 92%|█████████▏| 461/500 [02:20<00:11,  3.36it/s] 92%|█████████▏| 462/500 [02:20<00:11,  3.36it/s] 93%|█████████▎| 463/500 [02:21<00:11,  3.35it/s] 93%|█████████▎| 464/500 [02:21<00:10,  3.35it/s] 93%|█████████▎| 465/500 [02:21<00:10,  3.35it/s] 93%|█████████▎| 466/500 [02:22<00:10,  3.36it/s] 93%|█████████▎| 467/500 [02:22<00:09,  3.36it/s] 94%|█████████▎| 468/500 [02:22<00:09,  3.36it/s] 94%|█████████▍| 469/500 [02:22<00:09,  3.36it/s] 94%|█████████▍| 470/500 [02:23<00:08,  3.36it/s] 94%|█████████▍| 471/500 [02:23<00:08,  3.36it/s] 94%|█████████▍| 472/500 [02:23<00:08,  3.36it/s] 95%|█████████▍| 473/500 [02:24<00:08,  3.36it/s] 95%|█████████▍| 474/500 [02:24<00:07,  3.36it/s] 95%|█████████▌| 475/500 [02:24<00:07,  3.36it/s] 95%|█████████▌| 476/500 [02:25<00:07,  3.36it/s] 95%|█████████▌| 477/500 [02:25<00:06,  3.36it/s] 96%|█████████▌| 478/500 [02:25<00:06,  3.36it/s] 96%|█████████▌| 479/500 [02:25<00:06,  3.36it/s] 96%|█████████▌| 480/500 [02:26<00:05,  3.36it/s] 96%|█████████▌| 481/500 [02:26<00:05,  3.36it/s] 96%|█████████▋| 482/500 [02:26<00:05,  3.36it/s] 97%|█████████▋| 483/500 [02:27<00:05,  3.36it/s] 97%|█████████▋| 484/500 [02:27<00:04,  3.36it/s] 97%|█████████▋| 485/500 [02:27<00:04,  3.36it/s] 97%|█████████▋| 486/500 [02:28<00:04,  3.36it/s] 97%|█████████▋| 487/500 [02:28<00:03,  3.36it/s] 98%|█████████▊| 488/500 [02:28<00:03,  3.37it/s] 98%|█████████▊| 489/500 [02:28<00:03,  3.37it/s] 98%|█████████▊| 490/500 [02:29<00:02,  3.37it/s] 98%|█████████▊| 491/500 [02:29<00:02,  3.37it/s] 98%|█████████▊| 492/500 [02:29<00:02,  3.38it/s] 99%|█████████▊| 493/500 [02:30<00:02,  3.38it/s] 99%|█████████▉| 494/500 [02:30<00:01,  3.37it/s] 99%|█████████▉| 495/500 [02:30<00:01,  3.37it/s] 99%|█████████▉| 496/500 [02:30<00:01,  3.38it/s] 99%|█████████▉| 497/500 [02:31<00:00,  3.37it/s]100%|█████████▉| 498/500 [02:31<00:00,  3.38it/s]100%|█████████▉| 499/500 [02:31<00:00,  3.38it/s]100%|██████████| 500/500 [02:32<00:00,  3.38it/s]100%|██████████| 500/500 [02:32<00:00,  3.28it/s]
=> result
* total: 50,000
* correct: 19,928
* accuracy: 39.9%
* error: 60.1%
* macro_f1: 37.0%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 imagenet 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/imagenet/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/imagenet/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:ImageNet
Loading dataset: ImageNet
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ImageNet/split_fewshot_taesup/shot_16-seed_2.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:03<33:12,  3.99s/it]  0%|          | 2/500 [00:04<15:04,  1.82s/it]  1%|          | 3/500 [00:04<09:16,  1.12s/it]  1%|          | 4/500 [00:04<06:33,  1.26it/s]  1%|          | 5/500 [00:05<05:03,  1.63it/s]  1%|          | 6/500 [00:05<04:09,  1.98it/s]  1%|▏         | 7/500 [00:05<03:34,  2.30it/s]  2%|▏         | 8/500 [00:06<03:11,  2.56it/s]  2%|▏         | 9/500 [00:06<02:56,  2.78it/s]  2%|▏         | 10/500 [00:06<02:46,  2.95it/s]  2%|▏         | 11/500 [00:06<02:38,  3.08it/s]  2%|▏         | 12/500 [00:07<02:33,  3.17it/s]  3%|▎         | 13/500 [00:07<02:30,  3.24it/s]  3%|▎         | 14/500 [00:07<02:27,  3.29it/s]  3%|▎         | 15/500 [00:08<02:25,  3.32it/s]  3%|▎         | 16/500 [00:08<02:24,  3.35it/s]  3%|▎         | 17/500 [00:08<02:23,  3.37it/s]  4%|▎         | 18/500 [00:08<02:22,  3.38it/s]  4%|▍         | 19/500 [00:09<02:21,  3.39it/s]  4%|▍         | 20/500 [00:09<02:21,  3.40it/s]  4%|▍         | 21/500 [00:09<02:20,  3.40it/s]  4%|▍         | 22/500 [00:10<02:20,  3.40it/s]  5%|▍         | 23/500 [00:10<02:20,  3.40it/s]  5%|▍         | 24/500 [00:10<02:19,  3.41it/s]  5%|▌         | 25/500 [00:11<02:19,  3.40it/s]  5%|▌         | 26/500 [00:11<02:19,  3.40it/s]  5%|▌         | 27/500 [00:11<02:19,  3.40it/s]  6%|▌         | 28/500 [00:11<02:18,  3.40it/s]  6%|▌         | 29/500 [00:12<02:18,  3.40it/s]  6%|▌         | 30/500 [00:12<02:18,  3.40it/s]  6%|▌         | 31/500 [00:12<02:17,  3.40it/s]  6%|▋         | 32/500 [00:13<02:17,  3.40it/s]  7%|▋         | 33/500 [00:13<02:17,  3.40it/s]  7%|▋         | 34/500 [00:13<02:16,  3.41it/s]  7%|▋         | 35/500 [00:13<02:16,  3.40it/s]  7%|▋         | 36/500 [00:14<02:16,  3.40it/s]  7%|▋         | 37/500 [00:14<02:16,  3.40it/s]  8%|▊         | 38/500 [00:14<02:15,  3.40it/s]  8%|▊         | 39/500 [00:15<02:15,  3.40it/s]  8%|▊         | 40/500 [00:15<02:15,  3.40it/s]  8%|▊         | 41/500 [00:15<02:14,  3.40it/s]  8%|▊         | 42/500 [00:16<02:15,  3.39it/s]  9%|▊         | 43/500 [00:16<02:14,  3.40it/s]  9%|▉         | 44/500 [00:16<02:14,  3.39it/s]  9%|▉         | 45/500 [00:16<02:14,  3.39it/s]  9%|▉         | 46/500 [00:17<02:13,  3.39it/s]  9%|▉         | 47/500 [00:17<02:13,  3.39it/s] 10%|▉         | 48/500 [00:17<02:13,  3.38it/s] 10%|▉         | 49/500 [00:18<02:13,  3.38it/s] 10%|█         | 50/500 [00:18<02:13,  3.38it/s] 10%|█         | 51/500 [00:18<02:12,  3.38it/s] 10%|█         | 52/500 [00:18<02:12,  3.38it/s] 11%|█         | 53/500 [00:19<02:12,  3.38it/s] 11%|█         | 54/500 [00:19<02:11,  3.38it/s] 11%|█         | 55/500 [00:19<02:11,  3.39it/s] 11%|█         | 56/500 [00:20<02:10,  3.39it/s] 11%|█▏        | 57/500 [00:20<02:10,  3.40it/s] 12%|█▏        | 58/500 [00:20<02:10,  3.39it/s] 12%|█▏        | 59/500 [00:21<02:09,  3.39it/s] 12%|█▏        | 60/500 [00:21<02:09,  3.39it/s] 12%|█▏        | 61/500 [00:21<02:09,  3.39it/s] 12%|█▏        | 62/500 [00:21<02:09,  3.40it/s] 13%|█▎        | 63/500 [00:22<02:08,  3.40it/s] 13%|█▎        | 64/500 [00:22<02:08,  3.39it/s] 13%|█▎        | 65/500 [00:22<02:08,  3.40it/s] 13%|█▎        | 66/500 [00:23<02:07,  3.40it/s] 13%|█▎        | 67/500 [00:23<02:07,  3.40it/s] 14%|█▎        | 68/500 [00:23<02:07,  3.40it/s] 14%|█▍        | 69/500 [00:23<02:06,  3.40it/s] 14%|█▍        | 70/500 [00:24<02:06,  3.39it/s] 14%|█▍        | 71/500 [00:24<02:06,  3.39it/s] 14%|█▍        | 72/500 [00:24<02:06,  3.39it/s] 15%|█▍        | 73/500 [00:25<02:05,  3.39it/s] 15%|█▍        | 74/500 [00:25<02:05,  3.40it/s] 15%|█▌        | 75/500 [00:25<02:05,  3.39it/s] 15%|█▌        | 76/500 [00:26<02:05,  3.39it/s] 15%|█▌        | 77/500 [00:26<02:04,  3.39it/s] 16%|█▌        | 78/500 [00:26<02:04,  3.39it/s] 16%|█▌        | 79/500 [00:26<02:04,  3.39it/s] 16%|█▌        | 80/500 [00:27<02:03,  3.39it/s] 16%|█▌        | 81/500 [00:27<02:03,  3.39it/s] 16%|█▋        | 82/500 [00:27<02:03,  3.39it/s] 17%|█▋        | 83/500 [00:28<02:03,  3.39it/s] 17%|█▋        | 84/500 [00:28<02:02,  3.39it/s] 17%|█▋        | 85/500 [00:28<02:02,  3.39it/s] 17%|█▋        | 86/500 [00:29<02:02,  3.39it/s] 17%|█▋        | 87/500 [00:29<02:01,  3.39it/s] 18%|█▊        | 88/500 [00:29<02:01,  3.39it/s] 18%|█▊        | 89/500 [00:29<02:01,  3.38it/s] 18%|█▊        | 90/500 [00:30<02:01,  3.38it/s] 18%|█▊        | 91/500 [00:30<02:00,  3.38it/s] 18%|█▊        | 92/500 [00:30<02:00,  3.37it/s] 19%|█▊        | 93/500 [00:31<02:00,  3.37it/s] 19%|█▉        | 94/500 [00:31<02:00,  3.38it/s] 19%|█▉        | 95/500 [00:31<01:59,  3.38it/s] 19%|█▉        | 96/500 [00:31<01:59,  3.38it/s] 19%|█▉        | 97/500 [00:32<01:59,  3.38it/s] 20%|█▉        | 98/500 [00:32<01:58,  3.38it/s] 20%|█▉        | 99/500 [00:32<01:58,  3.38it/s] 20%|██        | 100/500 [00:33<01:58,  3.38it/s] 20%|██        | 101/500 [00:33<01:57,  3.38it/s] 20%|██        | 102/500 [00:33<01:57,  3.38it/s] 21%|██        | 103/500 [00:34<01:57,  3.39it/s] 21%|██        | 104/500 [00:34<01:56,  3.39it/s] 21%|██        | 105/500 [00:34<01:56,  3.39it/s] 21%|██        | 106/500 [00:34<01:56,  3.39it/s] 21%|██▏       | 107/500 [00:35<01:56,  3.38it/s] 22%|██▏       | 108/500 [00:35<01:55,  3.39it/s] 22%|██▏       | 109/500 [00:35<01:55,  3.38it/s] 22%|██▏       | 110/500 [00:36<01:55,  3.38it/s] 22%|██▏       | 111/500 [00:36<01:54,  3.38it/s] 22%|██▏       | 112/500 [00:36<01:54,  3.38it/s] 23%|██▎       | 113/500 [00:36<01:54,  3.38it/s] 23%|██▎       | 114/500 [00:37<01:53,  3.39it/s] 23%|██▎       | 115/500 [00:37<01:53,  3.39it/s] 23%|██▎       | 116/500 [00:37<01:53,  3.39it/s] 23%|██▎       | 117/500 [00:38<01:52,  3.39it/s] 24%|██▎       | 118/500 [00:38<01:52,  3.39it/s] 24%|██▍       | 119/500 [00:38<01:52,  3.39it/s] 24%|██▍       | 120/500 [00:39<01:52,  3.38it/s] 24%|██▍       | 121/500 [00:39<01:51,  3.38it/s] 24%|██▍       | 122/500 [00:39<01:51,  3.38it/s] 25%|██▍       | 123/500 [00:39<01:51,  3.38it/s] 25%|██▍       | 124/500 [00:40<01:51,  3.38it/s] 25%|██▌       | 125/500 [00:40<01:50,  3.38it/s] 25%|██▌       | 126/500 [00:40<01:50,  3.37it/s] 25%|██▌       | 127/500 [00:41<01:50,  3.38it/s] 26%|██▌       | 128/500 [00:41<01:50,  3.38it/s] 26%|██▌       | 129/500 [00:41<01:49,  3.38it/s] 26%|██▌       | 130/500 [00:42<01:49,  3.38it/s] 26%|██▌       | 131/500 [00:42<01:49,  3.38it/s] 26%|██▋       | 132/500 [00:42<01:48,  3.38it/s] 27%|██▋       | 133/500 [00:42<01:48,  3.37it/s] 27%|██▋       | 134/500 [00:43<01:48,  3.37it/s] 27%|██▋       | 135/500 [00:43<01:48,  3.37it/s] 27%|██▋       | 136/500 [00:43<01:47,  3.37it/s] 27%|██▋       | 137/500 [00:44<01:47,  3.37it/s] 28%|██▊       | 138/500 [00:44<01:47,  3.37it/s] 28%|██▊       | 139/500 [00:44<01:47,  3.37it/s] 28%|██▊       | 140/500 [00:44<01:46,  3.37it/s] 28%|██▊       | 141/500 [00:45<01:46,  3.37it/s] 28%|██▊       | 142/500 [00:45<01:46,  3.37it/s] 29%|██▊       | 143/500 [00:45<01:45,  3.38it/s] 29%|██▉       | 144/500 [00:46<01:45,  3.38it/s] 29%|██▉       | 145/500 [00:46<01:45,  3.38it/s] 29%|██▉       | 146/500 [00:46<01:44,  3.38it/s] 29%|██▉       | 147/500 [00:47<01:44,  3.38it/s] 30%|██▉       | 148/500 [00:47<01:44,  3.38it/s] 30%|██▉       | 149/500 [00:47<01:44,  3.37it/s] 30%|███       | 150/500 [00:47<01:43,  3.37it/s] 30%|███       | 151/500 [00:48<01:43,  3.37it/s] 30%|███       | 152/500 [00:48<01:43,  3.37it/s] 31%|███       | 153/500 [00:48<01:43,  3.37it/s] 31%|███       | 154/500 [00:49<01:42,  3.37it/s] 31%|███       | 155/500 [00:49<01:42,  3.37it/s] 31%|███       | 156/500 [00:49<01:42,  3.37it/s] 31%|███▏      | 157/500 [00:50<01:41,  3.37it/s] 32%|███▏      | 158/500 [00:50<01:41,  3.37it/s] 32%|███▏      | 159/500 [00:50<01:41,  3.37it/s] 32%|███▏      | 160/500 [00:50<01:40,  3.37it/s] 32%|███▏      | 161/500 [00:51<01:40,  3.38it/s] 32%|███▏      | 162/500 [00:51<01:40,  3.38it/s] 33%|███▎      | 163/500 [00:51<01:39,  3.38it/s] 33%|███▎      | 164/500 [00:52<01:39,  3.38it/s] 33%|███▎      | 165/500 [00:52<01:39,  3.37it/s] 33%|███▎      | 166/500 [00:52<01:39,  3.37it/s] 33%|███▎      | 167/500 [00:52<01:38,  3.38it/s] 34%|███▎      | 168/500 [00:53<01:38,  3.37it/s] 34%|███▍      | 169/500 [00:53<01:38,  3.37it/s] 34%|███▍      | 170/500 [00:53<01:37,  3.37it/s] 34%|███▍      | 171/500 [00:54<01:37,  3.37it/s] 34%|███▍      | 172/500 [00:54<01:37,  3.37it/s] 35%|███▍      | 173/500 [00:54<01:37,  3.37it/s] 35%|███▍      | 174/500 [00:55<01:36,  3.37it/s] 35%|███▌      | 175/500 [00:55<01:36,  3.37it/s] 35%|███▌      | 176/500 [00:55<01:36,  3.36it/s] 35%|███▌      | 177/500 [00:55<01:36,  3.36it/s] 36%|███▌      | 178/500 [00:56<01:35,  3.36it/s] 36%|███▌      | 179/500 [00:56<01:35,  3.36it/s] 36%|███▌      | 180/500 [00:56<01:35,  3.36it/s] 36%|███▌      | 181/500 [00:57<01:34,  3.36it/s] 36%|███▋      | 182/500 [00:57<01:34,  3.36it/s] 37%|███▋      | 183/500 [00:57<01:34,  3.36it/s] 37%|███▋      | 184/500 [00:58<01:34,  3.36it/s] 37%|███▋      | 185/500 [00:58<01:33,  3.36it/s] 37%|███▋      | 186/500 [00:58<01:33,  3.36it/s] 37%|███▋      | 187/500 [00:58<01:33,  3.36it/s] 38%|███▊      | 188/500 [00:59<01:32,  3.36it/s] 38%|███▊      | 189/500 [00:59<01:32,  3.36it/s] 38%|███▊      | 190/500 [00:59<01:32,  3.37it/s] 38%|███▊      | 191/500 [01:00<01:31,  3.37it/s] 38%|███▊      | 192/500 [01:00<01:31,  3.37it/s] 39%|███▊      | 193/500 [01:00<01:31,  3.37it/s] 39%|███▉      | 194/500 [01:01<01:30,  3.37it/s] 39%|███▉      | 195/500 [01:01<01:30,  3.37it/s] 39%|███▉      | 196/500 [01:01<01:30,  3.37it/s] 39%|███▉      | 197/500 [01:01<01:29,  3.37it/s] 40%|███▉      | 198/500 [01:02<01:29,  3.37it/s] 40%|███▉      | 199/500 [01:02<01:29,  3.36it/s] 40%|████      | 200/500 [01:02<01:29,  3.36it/s] 40%|████      | 201/500 [01:03<01:28,  3.37it/s] 40%|████      | 202/500 [01:03<01:28,  3.37it/s] 41%|████      | 203/500 [01:03<01:28,  3.37it/s] 41%|████      | 204/500 [01:03<01:28,  3.36it/s] 41%|████      | 205/500 [01:04<01:27,  3.37it/s] 41%|████      | 206/500 [01:04<01:27,  3.37it/s] 41%|████▏     | 207/500 [01:04<01:27,  3.37it/s] 42%|████▏     | 208/500 [01:05<01:26,  3.37it/s] 42%|████▏     | 209/500 [01:05<01:26,  3.37it/s] 42%|████▏     | 210/500 [01:05<01:26,  3.37it/s] 42%|████▏     | 211/500 [01:06<01:25,  3.36it/s] 42%|████▏     | 212/500 [01:06<01:25,  3.36it/s] 43%|████▎     | 213/500 [01:06<01:25,  3.37it/s] 43%|████▎     | 214/500 [01:06<01:25,  3.36it/s] 43%|████▎     | 215/500 [01:07<01:24,  3.36it/s] 43%|████▎     | 216/500 [01:07<01:24,  3.36it/s] 43%|████▎     | 217/500 [01:07<01:24,  3.37it/s] 44%|████▎     | 218/500 [01:08<01:23,  3.36it/s] 44%|████▍     | 219/500 [01:08<01:23,  3.36it/s] 44%|████▍     | 220/500 [01:08<01:23,  3.37it/s] 44%|████▍     | 221/500 [01:09<01:23,  3.36it/s] 44%|████▍     | 222/500 [01:09<01:22,  3.36it/s] 45%|████▍     | 223/500 [01:09<01:22,  3.36it/s] 45%|████▍     | 224/500 [01:09<01:22,  3.35it/s] 45%|████▌     | 225/500 [01:10<01:21,  3.36it/s] 45%|████▌     | 226/500 [01:10<01:21,  3.36it/s] 45%|████▌     | 227/500 [01:10<01:21,  3.36it/s] 46%|████▌     | 228/500 [01:11<01:21,  3.36it/s] 46%|████▌     | 229/500 [01:11<01:20,  3.36it/s] 46%|████▌     | 230/500 [01:11<01:20,  3.35it/s] 46%|████▌     | 231/500 [01:12<01:20,  3.36it/s] 46%|████▋     | 232/500 [01:12<01:20,  3.35it/s] 47%|████▋     | 233/500 [01:12<01:19,  3.36it/s] 47%|████▋     | 234/500 [01:12<01:19,  3.36it/s] 47%|████▋     | 235/500 [01:13<01:18,  3.37it/s] 47%|████▋     | 236/500 [01:13<01:18,  3.37it/s] 47%|████▋     | 237/500 [01:13<01:18,  3.36it/s] 48%|████▊     | 238/500 [01:14<01:17,  3.37it/s] 48%|████▊     | 239/500 [01:14<01:17,  3.36it/s] 48%|████▊     | 240/500 [01:14<01:17,  3.36it/s] 48%|████▊     | 241/500 [01:14<01:17,  3.36it/s] 48%|████▊     | 242/500 [01:15<01:16,  3.36it/s] 49%|████▊     | 243/500 [01:15<01:16,  3.36it/s] 49%|████▉     | 244/500 [01:15<01:16,  3.35it/s] 49%|████▉     | 245/500 [01:16<01:15,  3.36it/s] 49%|████▉     | 246/500 [01:16<01:15,  3.36it/s] 49%|████▉     | 247/500 [01:16<01:15,  3.36it/s] 50%|████▉     | 248/500 [01:17<01:14,  3.36it/s] 50%|████▉     | 249/500 [01:17<01:14,  3.36it/s] 50%|█████     | 250/500 [01:17<01:14,  3.36it/s] 50%|█████     | 251/500 [01:17<01:14,  3.36it/s] 50%|█████     | 252/500 [01:18<01:13,  3.36it/s] 51%|█████     | 253/500 [01:18<01:13,  3.36it/s] 51%|█████     | 254/500 [01:18<01:13,  3.36it/s] 51%|█████     | 255/500 [01:19<01:12,  3.36it/s] 51%|█████     | 256/500 [01:19<01:12,  3.36it/s] 51%|█████▏    | 257/500 [01:19<01:12,  3.36it/s] 52%|█████▏    | 258/500 [01:20<01:12,  3.36it/s] 52%|█████▏    | 259/500 [01:20<01:11,  3.36it/s] 52%|█████▏    | 260/500 [01:20<01:11,  3.36it/s] 52%|█████▏    | 261/500 [01:20<01:11,  3.35it/s] 52%|█████▏    | 262/500 [01:21<01:10,  3.35it/s] 53%|█████▎    | 263/500 [01:21<01:10,  3.36it/s] 53%|█████▎    | 264/500 [01:21<01:10,  3.36it/s] 53%|█████▎    | 265/500 [01:22<01:10,  3.35it/s] 53%|█████▎    | 266/500 [01:22<01:09,  3.36it/s] 53%|█████▎    | 267/500 [01:22<01:09,  3.36it/s] 54%|█████▎    | 268/500 [01:23<01:09,  3.36it/s] 54%|█████▍    | 269/500 [01:23<01:08,  3.36it/s] 54%|█████▍    | 270/500 [01:23<01:08,  3.36it/s] 54%|█████▍    | 271/500 [01:23<01:08,  3.35it/s] 54%|█████▍    | 272/500 [01:24<01:07,  3.36it/s] 55%|█████▍    | 273/500 [01:24<01:07,  3.36it/s] 55%|█████▍    | 274/500 [01:24<01:07,  3.36it/s] 55%|█████▌    | 275/500 [01:25<01:07,  3.35it/s] 55%|█████▌    | 276/500 [01:25<01:06,  3.36it/s] 55%|█████▌    | 277/500 [01:25<01:06,  3.36it/s] 56%|█████▌    | 278/500 [01:26<01:06,  3.35it/s] 56%|█████▌    | 279/500 [01:26<01:05,  3.35it/s] 56%|█████▌    | 280/500 [01:26<01:05,  3.36it/s] 56%|█████▌    | 281/500 [01:26<01:05,  3.36it/s] 56%|█████▋    | 282/500 [01:27<01:04,  3.36it/s] 57%|█████▋    | 283/500 [01:27<01:04,  3.36it/s] 57%|█████▋    | 284/500 [01:27<01:04,  3.35it/s] 57%|█████▋    | 285/500 [01:28<01:04,  3.35it/s] 57%|█████▋    | 286/500 [01:28<01:03,  3.35it/s] 57%|█████▋    | 287/500 [01:28<01:03,  3.36it/s] 58%|█████▊    | 288/500 [01:28<01:03,  3.36it/s] 58%|█████▊    | 289/500 [01:29<01:02,  3.36it/s] 58%|█████▊    | 290/500 [01:29<01:02,  3.35it/s] 58%|█████▊    | 291/500 [01:29<01:02,  3.36it/s] 58%|█████▊    | 292/500 [01:30<01:02,  3.35it/s] 59%|█████▊    | 293/500 [01:30<01:01,  3.36it/s] 59%|█████▉    | 294/500 [01:30<01:01,  3.36it/s] 59%|█████▉    | 295/500 [01:31<01:00,  3.36it/s] 59%|█████▉    | 296/500 [01:31<01:00,  3.36it/s] 59%|█████▉    | 297/500 [01:31<01:00,  3.36it/s] 60%|█████▉    | 298/500 [01:31<01:00,  3.36it/s] 60%|█████▉    | 299/500 [01:32<00:59,  3.36it/s] 60%|██████    | 300/500 [01:32<00:59,  3.36it/s] 60%|██████    | 301/500 [01:32<00:59,  3.36it/s] 60%|██████    | 302/500 [01:33<00:58,  3.36it/s] 61%|██████    | 303/500 [01:33<00:58,  3.36it/s] 61%|██████    | 304/500 [01:33<00:58,  3.35it/s] 61%|██████    | 305/500 [01:34<00:58,  3.35it/s] 61%|██████    | 306/500 [01:34<00:58,  3.34it/s] 61%|██████▏   | 307/500 [01:34<00:57,  3.35it/s] 62%|██████▏   | 308/500 [01:34<00:57,  3.35it/s] 62%|██████▏   | 309/500 [01:35<00:56,  3.36it/s] 62%|██████▏   | 310/500 [01:35<00:56,  3.35it/s] 62%|██████▏   | 311/500 [01:35<00:56,  3.36it/s] 62%|██████▏   | 312/500 [01:36<00:56,  3.36it/s] 63%|██████▎   | 313/500 [01:36<00:55,  3.35it/s] 63%|██████▎   | 314/500 [01:36<00:55,  3.35it/s] 63%|██████▎   | 315/500 [01:37<00:55,  3.36it/s] 63%|██████▎   | 316/500 [01:37<00:54,  3.36it/s] 63%|██████▎   | 317/500 [01:37<00:54,  3.36it/s] 64%|██████▎   | 318/500 [01:37<00:54,  3.36it/s] 64%|██████▍   | 319/500 [01:38<00:53,  3.36it/s] 64%|██████▍   | 320/500 [01:38<00:53,  3.35it/s] 64%|██████▍   | 321/500 [01:38<00:53,  3.36it/s] 64%|██████▍   | 322/500 [01:39<00:52,  3.36it/s] 65%|██████▍   | 323/500 [01:39<00:52,  3.36it/s] 65%|██████▍   | 324/500 [01:39<00:52,  3.37it/s] 65%|██████▌   | 325/500 [01:40<00:52,  3.36it/s] 65%|██████▌   | 326/500 [01:40<00:51,  3.37it/s] 65%|██████▌   | 327/500 [01:40<00:51,  3.37it/s] 66%|██████▌   | 328/500 [01:40<00:51,  3.37it/s] 66%|██████▌   | 329/500 [01:41<00:50,  3.37it/s] 66%|██████▌   | 330/500 [01:41<00:50,  3.37it/s] 66%|██████▌   | 331/500 [01:41<00:50,  3.37it/s] 66%|██████▋   | 332/500 [01:42<00:49,  3.37it/s] 67%|██████▋   | 333/500 [01:42<00:49,  3.37it/s] 67%|██████▋   | 334/500 [01:42<00:49,  3.36it/s] 67%|██████▋   | 335/500 [01:42<00:49,  3.36it/s] 67%|██████▋   | 336/500 [01:43<00:48,  3.36it/s] 67%|██████▋   | 337/500 [01:43<00:48,  3.36it/s] 68%|██████▊   | 338/500 [01:43<00:48,  3.36it/s] 68%|██████▊   | 339/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 340/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 341/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 342/500 [01:45<00:47,  3.36it/s] 69%|██████▊   | 343/500 [01:45<00:46,  3.35it/s] 69%|██████▉   | 344/500 [01:45<00:46,  3.36it/s] 69%|██████▉   | 345/500 [01:45<00:46,  3.36it/s] 69%|██████▉   | 346/500 [01:46<00:45,  3.36it/s] 69%|██████▉   | 347/500 [01:46<00:45,  3.36it/s] 70%|██████▉   | 348/500 [01:46<00:45,  3.36it/s] 70%|██████▉   | 349/500 [01:47<00:44,  3.36it/s] 70%|███████   | 350/500 [01:47<00:44,  3.36it/s] 70%|███████   | 351/500 [01:47<00:44,  3.36it/s] 70%|███████   | 352/500 [01:48<00:44,  3.35it/s] 71%|███████   | 353/500 [01:48<00:43,  3.35it/s] 71%|███████   | 354/500 [01:48<00:43,  3.35it/s] 71%|███████   | 355/500 [01:48<00:43,  3.35it/s] 71%|███████   | 356/500 [01:49<00:43,  3.35it/s] 71%|███████▏  | 357/500 [01:49<00:42,  3.35it/s] 72%|███████▏  | 358/500 [01:49<00:42,  3.35it/s] 72%|███████▏  | 359/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 360/500 [01:50<00:41,  3.35it/s] 72%|███████▏  | 361/500 [01:50<00:41,  3.35it/s] 72%|███████▏  | 362/500 [01:51<00:41,  3.35it/s] 73%|███████▎  | 363/500 [01:51<00:40,  3.35it/s] 73%|███████▎  | 364/500 [01:51<00:40,  3.35it/s] 73%|███████▎  | 365/500 [01:51<00:40,  3.35it/s] 73%|███████▎  | 366/500 [01:52<00:39,  3.35it/s] 73%|███████▎  | 367/500 [01:52<00:39,  3.35it/s] 74%|███████▎  | 368/500 [01:52<00:39,  3.35it/s] 74%|███████▍  | 369/500 [01:53<00:39,  3.35it/s] 74%|███████▍  | 370/500 [01:53<00:38,  3.35it/s] 74%|███████▍  | 371/500 [01:53<00:38,  3.35it/s] 74%|███████▍  | 372/500 [01:54<00:38,  3.35it/s] 75%|███████▍  | 373/500 [01:54<00:37,  3.35it/s] 75%|███████▍  | 374/500 [01:54<00:37,  3.35it/s] 75%|███████▌  | 375/500 [01:54<00:37,  3.35it/s] 75%|███████▌  | 376/500 [01:55<00:36,  3.35it/s] 75%|███████▌  | 377/500 [01:55<00:36,  3.35it/s] 76%|███████▌  | 378/500 [01:55<00:36,  3.35it/s] 76%|███████▌  | 379/500 [01:56<00:36,  3.35it/s] 76%|███████▌  | 380/500 [01:56<00:35,  3.35it/s] 76%|███████▌  | 381/500 [01:56<00:35,  3.35it/s] 76%|███████▋  | 382/500 [01:56<00:35,  3.36it/s] 77%|███████▋  | 383/500 [01:57<00:34,  3.36it/s] 77%|███████▋  | 384/500 [01:57<00:34,  3.36it/s] 77%|███████▋  | 385/500 [01:57<00:34,  3.35it/s] 77%|███████▋  | 386/500 [01:58<00:34,  3.35it/s] 77%|███████▋  | 387/500 [01:58<00:33,  3.35it/s] 78%|███████▊  | 388/500 [01:58<00:33,  3.35it/s] 78%|███████▊  | 389/500 [01:59<00:33,  3.35it/s] 78%|███████▊  | 390/500 [01:59<00:32,  3.36it/s] 78%|███████▊  | 391/500 [01:59<00:32,  3.35it/s] 78%|███████▊  | 392/500 [01:59<00:32,  3.35it/s] 79%|███████▊  | 393/500 [02:00<00:31,  3.35it/s] 79%|███████▉  | 394/500 [02:00<00:31,  3.35it/s] 79%|███████▉  | 395/500 [02:00<00:31,  3.35it/s] 79%|███████▉  | 396/500 [02:01<00:31,  3.35it/s] 79%|███████▉  | 397/500 [02:01<00:30,  3.36it/s] 80%|███████▉  | 398/500 [02:01<00:30,  3.36it/s] 80%|███████▉  | 399/500 [02:02<00:30,  3.36it/s] 80%|████████  | 400/500 [02:02<00:29,  3.36it/s] 80%|████████  | 401/500 [02:02<00:29,  3.35it/s] 80%|████████  | 402/500 [02:02<00:29,  3.35it/s] 81%|████████  | 403/500 [02:03<00:28,  3.35it/s] 81%|████████  | 404/500 [02:03<00:28,  3.36it/s] 81%|████████  | 405/500 [02:03<00:28,  3.36it/s] 81%|████████  | 406/500 [02:04<00:28,  3.35it/s] 81%|████████▏ | 407/500 [02:04<00:27,  3.36it/s] 82%|████████▏ | 408/500 [02:04<00:27,  3.36it/s] 82%|████████▏ | 409/500 [02:05<00:27,  3.36it/s] 82%|████████▏ | 410/500 [02:05<00:26,  3.35it/s] 82%|████████▏ | 411/500 [02:05<00:26,  3.36it/s] 82%|████████▏ | 412/500 [02:05<00:26,  3.36it/s] 83%|████████▎ | 413/500 [02:06<00:25,  3.36it/s] 83%|████████▎ | 414/500 [02:06<00:25,  3.36it/s] 83%|████████▎ | 415/500 [02:06<00:25,  3.36it/s] 83%|████████▎ | 416/500 [02:07<00:25,  3.35it/s] 83%|████████▎ | 417/500 [02:07<00:24,  3.35it/s] 84%|████████▎ | 418/500 [02:07<00:24,  3.35it/s] 84%|████████▍ | 419/500 [02:08<00:24,  3.35it/s] 84%|████████▍ | 420/500 [02:08<00:23,  3.35it/s] 84%|████████▍ | 421/500 [02:08<00:23,  3.35it/s] 84%|████████▍ | 422/500 [02:08<00:23,  3.35it/s] 85%|████████▍ | 423/500 [02:09<00:22,  3.36it/s] 85%|████████▍ | 424/500 [02:09<00:22,  3.36it/s] 85%|████████▌ | 425/500 [02:09<00:22,  3.36it/s] 85%|████████▌ | 426/500 [02:10<00:22,  3.36it/s] 85%|████████▌ | 427/500 [02:10<00:21,  3.36it/s] 86%|████████▌ | 428/500 [02:10<00:21,  3.36it/s] 86%|████████▌ | 429/500 [02:11<00:21,  3.36it/s] 86%|████████▌ | 430/500 [02:11<00:20,  3.36it/s] 86%|████████▌ | 431/500 [02:11<00:20,  3.36it/s] 86%|████████▋ | 432/500 [02:11<00:20,  3.36it/s] 87%|████████▋ | 433/500 [02:12<00:20,  3.35it/s] 87%|████████▋ | 434/500 [02:12<00:19,  3.35it/s] 87%|████████▋ | 435/500 [02:12<00:19,  3.35it/s] 87%|████████▋ | 436/500 [02:13<00:19,  3.35it/s] 87%|████████▋ | 437/500 [02:13<00:18,  3.35it/s] 88%|████████▊ | 438/500 [02:13<00:18,  3.35it/s] 88%|████████▊ | 439/500 [02:13<00:18,  3.35it/s] 88%|████████▊ | 440/500 [02:14<00:17,  3.35it/s] 88%|████████▊ | 441/500 [02:14<00:17,  3.35it/s] 88%|████████▊ | 442/500 [02:14<00:17,  3.35it/s] 89%|████████▊ | 443/500 [02:15<00:16,  3.36it/s] 89%|████████▉ | 444/500 [02:15<00:16,  3.36it/s] 89%|████████▉ | 445/500 [02:15<00:16,  3.36it/s] 89%|████████▉ | 446/500 [02:16<00:16,  3.36it/s] 89%|████████▉ | 447/500 [02:16<00:15,  3.36it/s] 90%|████████▉ | 448/500 [02:16<00:15,  3.36it/s] 90%|████████▉ | 449/500 [02:16<00:15,  3.36it/s] 90%|█████████ | 450/500 [02:17<00:14,  3.36it/s] 90%|█████████ | 451/500 [02:17<00:14,  3.36it/s] 90%|█████████ | 452/500 [02:17<00:14,  3.36it/s] 91%|█████████ | 453/500 [02:18<00:14,  3.35it/s] 91%|█████████ | 454/500 [02:18<00:13,  3.35it/s] 91%|█████████ | 455/500 [02:18<00:13,  3.35it/s] 91%|█████████ | 456/500 [02:19<00:13,  3.35it/s] 91%|█████████▏| 457/500 [02:19<00:12,  3.35it/s] 92%|█████████▏| 458/500 [02:19<00:12,  3.36it/s] 92%|█████████▏| 459/500 [02:19<00:12,  3.36it/s] 92%|█████████▏| 460/500 [02:20<00:11,  3.36it/s] 92%|█████████▏| 461/500 [02:20<00:11,  3.36it/s] 92%|█████████▏| 462/500 [02:20<00:11,  3.36it/s] 93%|█████████▎| 463/500 [02:21<00:11,  3.36it/s] 93%|█████████▎| 464/500 [02:21<00:10,  3.36it/s] 93%|█████████▎| 465/500 [02:21<00:10,  3.36it/s] 93%|█████████▎| 466/500 [02:22<00:10,  3.36it/s] 93%|█████████▎| 467/500 [02:22<00:09,  3.37it/s] 94%|█████████▎| 468/500 [02:22<00:09,  3.37it/s] 94%|█████████▍| 469/500 [02:22<00:09,  3.36it/s] 94%|█████████▍| 470/500 [02:23<00:08,  3.36it/s] 94%|█████████▍| 471/500 [02:23<00:08,  3.37it/s] 94%|█████████▍| 472/500 [02:23<00:08,  3.37it/s] 95%|█████████▍| 473/500 [02:24<00:08,  3.36it/s] 95%|█████████▍| 474/500 [02:24<00:07,  3.36it/s] 95%|█████████▌| 475/500 [02:24<00:07,  3.36it/s] 95%|█████████▌| 476/500 [02:25<00:07,  3.35it/s] 95%|█████████▌| 477/500 [02:25<00:06,  3.35it/s] 96%|█████████▌| 478/500 [02:25<00:06,  3.36it/s] 96%|█████████▌| 479/500 [02:25<00:06,  3.36it/s] 96%|█████████▌| 480/500 [02:26<00:05,  3.36it/s] 96%|█████████▌| 481/500 [02:26<00:05,  3.36it/s] 96%|█████████▋| 482/500 [02:26<00:05,  3.36it/s] 97%|█████████▋| 483/500 [02:27<00:05,  3.36it/s] 97%|█████████▋| 484/500 [02:27<00:04,  3.36it/s] 97%|█████████▋| 485/500 [02:27<00:04,  3.36it/s] 97%|█████████▋| 486/500 [02:27<00:04,  3.36it/s] 97%|█████████▋| 487/500 [02:28<00:03,  3.36it/s] 98%|█████████▊| 488/500 [02:28<00:03,  3.37it/s] 98%|█████████▊| 489/500 [02:28<00:03,  3.37it/s] 98%|█████████▊| 490/500 [02:29<00:02,  3.37it/s] 98%|█████████▊| 491/500 [02:29<00:02,  3.37it/s] 98%|█████████▊| 492/500 [02:29<00:02,  3.37it/s] 99%|█████████▊| 493/500 [02:30<00:02,  3.37it/s] 99%|█████████▉| 494/500 [02:30<00:01,  3.37it/s] 99%|█████████▉| 495/500 [02:30<00:01,  3.37it/s] 99%|█████████▉| 496/500 [02:30<00:01,  3.38it/s] 99%|█████████▉| 497/500 [02:31<00:00,  3.37it/s]100%|█████████▉| 498/500 [02:31<00:00,  3.38it/s]100%|█████████▉| 499/500 [02:31<00:00,  3.38it/s]100%|██████████| 500/500 [02:32<00:00,  3.38it/s]100%|██████████| 500/500 [02:32<00:00,  3.28it/s]
=> result
* total: 50,000
* correct: 20,580
* accuracy: 41.2%
* error: 58.8%
* macro_f1: 38.0%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 imagenet 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/imagenet/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/imagenet/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:ImageNet
Loading dataset: ImageNet
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ImageNet/split_fewshot_taesup/shot_16-seed_3.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:03<33:04,  3.98s/it]  0%|          | 2/500 [00:04<15:00,  1.81s/it]  1%|          | 3/500 [00:04<09:14,  1.12s/it]  1%|          | 4/500 [00:04<06:32,  1.26it/s]  1%|          | 5/500 [00:05<05:02,  1.63it/s]  1%|          | 6/500 [00:05<04:08,  1.99it/s]  1%|▏         | 7/500 [00:05<03:34,  2.30it/s]  2%|▏         | 8/500 [00:06<03:11,  2.57it/s]  2%|▏         | 9/500 [00:06<02:56,  2.78it/s]  2%|▏         | 10/500 [00:06<02:46,  2.95it/s]  2%|▏         | 11/500 [00:06<02:38,  3.08it/s]  2%|▏         | 12/500 [00:07<02:33,  3.17it/s]  3%|▎         | 13/500 [00:07<02:30,  3.24it/s]  3%|▎         | 14/500 [00:07<02:27,  3.29it/s]  3%|▎         | 15/500 [00:08<02:25,  3.33it/s]  3%|▎         | 16/500 [00:08<02:24,  3.35it/s]  3%|▎         | 17/500 [00:08<02:23,  3.37it/s]  4%|▎         | 18/500 [00:08<02:22,  3.37it/s]  4%|▍         | 19/500 [00:09<02:22,  3.38it/s]  4%|▍         | 20/500 [00:09<02:21,  3.39it/s]  4%|▍         | 21/500 [00:09<02:21,  3.40it/s]  4%|▍         | 22/500 [00:10<02:20,  3.40it/s]  5%|▍         | 23/500 [00:10<02:20,  3.39it/s]  5%|▍         | 24/500 [00:10<02:20,  3.39it/s]  5%|▌         | 25/500 [00:11<02:19,  3.40it/s]  5%|▌         | 26/500 [00:11<02:19,  3.39it/s]  5%|▌         | 27/500 [00:11<02:19,  3.39it/s]  6%|▌         | 28/500 [00:11<02:18,  3.40it/s]  6%|▌         | 29/500 [00:12<02:18,  3.40it/s]  6%|▌         | 30/500 [00:12<02:18,  3.40it/s]  6%|▌         | 31/500 [00:12<02:18,  3.40it/s]  6%|▋         | 32/500 [00:13<02:17,  3.40it/s]  7%|▋         | 33/500 [00:13<02:17,  3.40it/s]  7%|▋         | 34/500 [00:13<02:17,  3.39it/s]  7%|▋         | 35/500 [00:13<02:16,  3.40it/s]  7%|▋         | 36/500 [00:14<02:16,  3.40it/s]  7%|▋         | 37/500 [00:14<02:16,  3.40it/s]  8%|▊         | 38/500 [00:14<02:16,  3.39it/s]  8%|▊         | 39/500 [00:15<02:16,  3.39it/s]  8%|▊         | 40/500 [00:15<02:15,  3.39it/s]  8%|▊         | 41/500 [00:15<02:15,  3.39it/s]  8%|▊         | 42/500 [00:16<02:15,  3.39it/s]  9%|▊         | 43/500 [00:16<02:14,  3.39it/s]  9%|▉         | 44/500 [00:16<02:14,  3.40it/s]  9%|▉         | 45/500 [00:16<02:14,  3.39it/s]  9%|▉         | 46/500 [00:17<02:13,  3.39it/s]  9%|▉         | 47/500 [00:17<02:13,  3.40it/s] 10%|▉         | 48/500 [00:17<02:13,  3.38it/s] 10%|▉         | 49/500 [00:18<02:13,  3.39it/s] 10%|█         | 50/500 [00:18<02:12,  3.39it/s] 10%|█         | 51/500 [00:18<02:12,  3.39it/s] 10%|█         | 52/500 [00:18<02:12,  3.39it/s] 11%|█         | 53/500 [00:19<02:11,  3.39it/s] 11%|█         | 54/500 [00:19<02:11,  3.39it/s] 11%|█         | 55/500 [00:19<02:11,  3.39it/s] 11%|█         | 56/500 [00:20<02:10,  3.39it/s] 11%|█▏        | 57/500 [00:20<02:10,  3.39it/s] 12%|█▏        | 58/500 [00:20<02:10,  3.39it/s] 12%|█▏        | 59/500 [00:21<02:10,  3.38it/s] 12%|█▏        | 60/500 [00:21<02:10,  3.38it/s] 12%|█▏        | 61/500 [00:21<02:09,  3.39it/s] 12%|█▏        | 62/500 [00:21<02:09,  3.39it/s] 13%|█▎        | 63/500 [00:22<02:08,  3.39it/s] 13%|█▎        | 64/500 [00:22<02:08,  3.39it/s] 13%|█▎        | 65/500 [00:22<02:08,  3.39it/s] 13%|█▎        | 66/500 [00:23<02:08,  3.39it/s] 13%|█▎        | 67/500 [00:23<02:07,  3.38it/s] 14%|█▎        | 68/500 [00:23<02:07,  3.39it/s] 14%|█▍        | 69/500 [00:23<02:07,  3.39it/s] 14%|█▍        | 70/500 [00:24<02:07,  3.38it/s] 14%|█▍        | 71/500 [00:24<02:06,  3.38it/s] 14%|█▍        | 72/500 [00:24<02:06,  3.38it/s] 15%|█▍        | 73/500 [00:25<02:06,  3.39it/s] 15%|█▍        | 74/500 [00:25<02:05,  3.38it/s] 15%|█▌        | 75/500 [00:25<02:05,  3.38it/s] 15%|█▌        | 76/500 [00:26<02:05,  3.38it/s] 15%|█▌        | 77/500 [00:26<02:04,  3.39it/s] 16%|█▌        | 78/500 [00:26<02:04,  3.39it/s] 16%|█▌        | 79/500 [00:26<02:04,  3.39it/s] 16%|█▌        | 80/500 [00:27<02:04,  3.39it/s] 16%|█▌        | 81/500 [00:27<02:03,  3.39it/s] 16%|█▋        | 82/500 [00:27<02:03,  3.38it/s] 17%|█▋        | 83/500 [00:28<02:03,  3.38it/s] 17%|█▋        | 84/500 [00:28<02:03,  3.38it/s] 17%|█▋        | 85/500 [00:28<02:02,  3.38it/s] 17%|█▋        | 86/500 [00:29<02:02,  3.38it/s] 17%|█▋        | 87/500 [00:29<02:01,  3.39it/s] 18%|█▊        | 88/500 [00:29<02:01,  3.39it/s] 18%|█▊        | 89/500 [00:29<02:01,  3.38it/s] 18%|█▊        | 90/500 [00:30<02:01,  3.38it/s] 18%|█▊        | 91/500 [00:30<02:00,  3.38it/s] 18%|█▊        | 92/500 [00:30<02:00,  3.38it/s] 19%|█▊        | 93/500 [00:31<02:00,  3.38it/s] 19%|█▉        | 94/500 [00:31<02:00,  3.38it/s] 19%|█▉        | 95/500 [00:31<01:59,  3.38it/s] 19%|█▉        | 96/500 [00:31<01:59,  3.38it/s] 19%|█▉        | 97/500 [00:32<01:59,  3.38it/s] 20%|█▉        | 98/500 [00:32<01:59,  3.38it/s] 20%|█▉        | 99/500 [00:32<01:58,  3.38it/s] 20%|██        | 100/500 [00:33<01:58,  3.38it/s] 20%|██        | 101/500 [00:33<01:57,  3.39it/s] 20%|██        | 102/500 [00:33<01:57,  3.38it/s] 21%|██        | 103/500 [00:34<01:57,  3.39it/s] 21%|██        | 104/500 [00:34<01:56,  3.39it/s] 21%|██        | 105/500 [00:34<01:56,  3.39it/s] 21%|██        | 106/500 [00:34<01:56,  3.38it/s] 21%|██▏       | 107/500 [00:35<01:56,  3.38it/s] 22%|██▏       | 108/500 [00:35<01:55,  3.38it/s] 22%|██▏       | 109/500 [00:35<01:55,  3.38it/s] 22%|██▏       | 110/500 [00:36<01:55,  3.38it/s] 22%|██▏       | 111/500 [00:36<01:54,  3.39it/s] 22%|██▏       | 112/500 [00:36<01:54,  3.39it/s] 23%|██▎       | 113/500 [00:36<01:54,  3.38it/s] 23%|██▎       | 114/500 [00:37<01:54,  3.38it/s] 23%|██▎       | 115/500 [00:37<01:54,  3.38it/s] 23%|██▎       | 116/500 [00:37<01:53,  3.37it/s] 23%|██▎       | 117/500 [00:38<01:53,  3.38it/s] 24%|██▎       | 118/500 [00:38<01:52,  3.38it/s] 24%|██▍       | 119/500 [00:38<01:52,  3.38it/s] 24%|██▍       | 120/500 [00:39<01:52,  3.38it/s] 24%|██▍       | 121/500 [00:39<01:52,  3.38it/s] 24%|██▍       | 122/500 [00:39<01:51,  3.38it/s] 25%|██▍       | 123/500 [00:39<01:51,  3.38it/s] 25%|██▍       | 124/500 [00:40<01:51,  3.38it/s] 25%|██▌       | 125/500 [00:40<01:50,  3.38it/s] 25%|██▌       | 126/500 [00:40<01:50,  3.38it/s] 25%|██▌       | 127/500 [00:41<01:50,  3.38it/s] 26%|██▌       | 128/500 [00:41<01:50,  3.38it/s] 26%|██▌       | 129/500 [00:41<01:49,  3.37it/s] 26%|██▌       | 130/500 [00:42<01:49,  3.37it/s] 26%|██▌       | 131/500 [00:42<01:49,  3.37it/s] 26%|██▋       | 132/500 [00:42<01:49,  3.37it/s] 27%|██▋       | 133/500 [00:42<01:48,  3.37it/s] 27%|██▋       | 134/500 [00:43<01:48,  3.37it/s] 27%|██▋       | 135/500 [00:43<01:48,  3.37it/s] 27%|██▋       | 136/500 [00:43<01:47,  3.37it/s] 27%|██▋       | 137/500 [00:44<01:47,  3.37it/s] 28%|██▊       | 138/500 [00:44<01:47,  3.37it/s] 28%|██▊       | 139/500 [00:44<01:47,  3.37it/s] 28%|██▊       | 140/500 [00:45<01:46,  3.37it/s] 28%|██▊       | 141/500 [00:45<01:46,  3.37it/s] 28%|██▊       | 142/500 [00:45<01:46,  3.37it/s] 29%|██▊       | 143/500 [00:45<01:45,  3.37it/s] 29%|██▉       | 144/500 [00:46<01:45,  3.37it/s] 29%|██▉       | 145/500 [00:46<01:45,  3.36it/s] 29%|██▉       | 146/500 [00:46<01:45,  3.37it/s] 29%|██▉       | 147/500 [00:47<01:44,  3.37it/s] 30%|██▉       | 148/500 [00:47<01:44,  3.37it/s] 30%|██▉       | 149/500 [00:47<01:44,  3.37it/s] 30%|███       | 150/500 [00:47<01:43,  3.37it/s] 30%|███       | 151/500 [00:48<01:43,  3.37it/s] 30%|███       | 152/500 [00:48<01:43,  3.37it/s] 31%|███       | 153/500 [00:48<01:42,  3.37it/s] 31%|███       | 154/500 [00:49<01:42,  3.37it/s] 31%|███       | 155/500 [00:49<01:42,  3.37it/s] 31%|███       | 156/500 [00:49<01:42,  3.37it/s] 31%|███▏      | 157/500 [00:50<01:41,  3.37it/s] 32%|███▏      | 158/500 [00:50<01:41,  3.37it/s] 32%|███▏      | 159/500 [00:50<01:41,  3.37it/s] 32%|███▏      | 160/500 [00:50<01:40,  3.37it/s] 32%|███▏      | 161/500 [00:51<01:40,  3.37it/s] 32%|███▏      | 162/500 [00:51<01:40,  3.37it/s] 33%|███▎      | 163/500 [00:51<01:40,  3.37it/s] 33%|███▎      | 164/500 [00:52<01:39,  3.37it/s] 33%|███▎      | 165/500 [00:52<01:39,  3.37it/s] 33%|███▎      | 166/500 [00:52<01:39,  3.37it/s] 33%|███▎      | 167/500 [00:53<01:38,  3.37it/s] 34%|███▎      | 168/500 [00:53<01:38,  3.37it/s] 34%|███▍      | 169/500 [00:53<01:38,  3.37it/s] 34%|███▍      | 170/500 [00:53<01:37,  3.37it/s] 34%|███▍      | 171/500 [00:54<01:37,  3.37it/s] 34%|███▍      | 172/500 [00:54<01:37,  3.37it/s] 35%|███▍      | 173/500 [00:54<01:37,  3.37it/s] 35%|███▍      | 174/500 [00:55<01:36,  3.37it/s] 35%|███▌      | 175/500 [00:55<01:36,  3.37it/s] 35%|███▌      | 176/500 [00:55<01:36,  3.37it/s] 35%|███▌      | 177/500 [00:55<01:36,  3.36it/s] 36%|███▌      | 178/500 [00:56<01:35,  3.36it/s] 36%|███▌      | 179/500 [00:56<01:35,  3.36it/s] 36%|███▌      | 180/500 [00:56<01:35,  3.36it/s] 36%|███▌      | 181/500 [00:57<01:34,  3.36it/s] 36%|███▋      | 182/500 [00:57<01:34,  3.36it/s] 37%|███▋      | 183/500 [00:57<01:34,  3.36it/s] 37%|███▋      | 184/500 [00:58<01:33,  3.36it/s] 37%|███▋      | 185/500 [00:58<01:33,  3.36it/s] 37%|███▋      | 186/500 [00:58<01:33,  3.36it/s] 37%|███▋      | 187/500 [00:58<01:33,  3.36it/s] 38%|███▊      | 188/500 [00:59<01:32,  3.37it/s] 38%|███▊      | 189/500 [00:59<01:32,  3.37it/s] 38%|███▊      | 190/500 [00:59<01:32,  3.37it/s] 38%|███▊      | 191/500 [01:00<01:31,  3.37it/s] 38%|███▊      | 192/500 [01:00<01:31,  3.37it/s] 39%|███▊      | 193/500 [01:00<01:31,  3.37it/s] 39%|███▉      | 194/500 [01:01<01:30,  3.37it/s] 39%|███▉      | 195/500 [01:01<01:30,  3.36it/s] 39%|███▉      | 196/500 [01:01<01:30,  3.36it/s] 39%|███▉      | 197/500 [01:01<01:30,  3.36it/s] 40%|███▉      | 198/500 [01:02<01:29,  3.37it/s] 40%|███▉      | 199/500 [01:02<01:29,  3.37it/s] 40%|████      | 200/500 [01:02<01:29,  3.37it/s] 40%|████      | 201/500 [01:03<01:28,  3.37it/s] 40%|████      | 202/500 [01:03<01:28,  3.37it/s] 41%|████      | 203/500 [01:03<01:28,  3.37it/s] 41%|████      | 204/500 [01:04<01:27,  3.37it/s] 41%|████      | 205/500 [01:04<01:27,  3.37it/s] 41%|████      | 206/500 [01:04<01:27,  3.37it/s] 41%|████▏     | 207/500 [01:04<01:26,  3.37it/s] 42%|████▏     | 208/500 [01:05<01:26,  3.37it/s] 42%|████▏     | 209/500 [01:05<01:26,  3.37it/s] 42%|████▏     | 210/500 [01:05<01:26,  3.36it/s] 42%|████▏     | 211/500 [01:06<01:25,  3.36it/s] 42%|████▏     | 212/500 [01:06<01:25,  3.36it/s] 43%|████▎     | 213/500 [01:06<01:25,  3.36it/s] 43%|████▎     | 214/500 [01:06<01:25,  3.36it/s] 43%|████▎     | 215/500 [01:07<01:24,  3.36it/s] 43%|████▎     | 216/500 [01:07<01:24,  3.36it/s] 43%|████▎     | 217/500 [01:07<01:24,  3.36it/s] 44%|████▎     | 218/500 [01:08<01:24,  3.35it/s] 44%|████▍     | 219/500 [01:08<01:23,  3.35it/s] 44%|████▍     | 220/500 [01:08<01:23,  3.35it/s] 44%|████▍     | 221/500 [01:09<01:23,  3.35it/s] 44%|████▍     | 222/500 [01:09<01:22,  3.36it/s] 45%|████▍     | 223/500 [01:09<01:22,  3.36it/s] 45%|████▍     | 224/500 [01:09<01:22,  3.36it/s] 45%|████▌     | 225/500 [01:10<01:21,  3.36it/s] 45%|████▌     | 226/500 [01:10<01:21,  3.35it/s] 45%|████▌     | 227/500 [01:10<01:21,  3.36it/s] 46%|████▌     | 228/500 [01:11<01:20,  3.36it/s] 46%|████▌     | 229/500 [01:11<01:20,  3.36it/s] 46%|████▌     | 230/500 [01:11<01:20,  3.36it/s] 46%|████▌     | 231/500 [01:12<01:20,  3.36it/s] 46%|████▋     | 232/500 [01:12<01:19,  3.36it/s] 47%|████▋     | 233/500 [01:12<01:19,  3.36it/s] 47%|████▋     | 234/500 [01:12<01:19,  3.36it/s] 47%|████▋     | 235/500 [01:13<01:18,  3.37it/s] 47%|████▋     | 236/500 [01:13<01:18,  3.37it/s] 47%|████▋     | 237/500 [01:13<01:18,  3.36it/s] 48%|████▊     | 238/500 [01:14<01:17,  3.36it/s] 48%|████▊     | 239/500 [01:14<01:17,  3.36it/s] 48%|████▊     | 240/500 [01:14<01:17,  3.35it/s] 48%|████▊     | 241/500 [01:15<01:17,  3.35it/s] 48%|████▊     | 242/500 [01:15<01:16,  3.35it/s] 49%|████▊     | 243/500 [01:15<01:16,  3.35it/s] 49%|████▉     | 244/500 [01:15<01:16,  3.36it/s] 49%|████▉     | 245/500 [01:16<01:15,  3.36it/s] 49%|████▉     | 246/500 [01:16<01:15,  3.36it/s] 49%|████▉     | 247/500 [01:16<01:15,  3.37it/s] 50%|████▉     | 248/500 [01:17<01:14,  3.37it/s] 50%|████▉     | 249/500 [01:17<01:14,  3.37it/s] 50%|█████     | 250/500 [01:17<01:14,  3.36it/s] 50%|█████     | 251/500 [01:17<01:14,  3.35it/s] 50%|█████     | 252/500 [01:18<01:13,  3.35it/s] 51%|█████     | 253/500 [01:18<01:13,  3.35it/s] 51%|█████     | 254/500 [01:18<01:13,  3.35it/s] 51%|█████     | 255/500 [01:19<01:12,  3.36it/s] 51%|█████     | 256/500 [01:19<01:12,  3.36it/s] 51%|█████▏    | 257/500 [01:19<01:12,  3.36it/s] 52%|█████▏    | 258/500 [01:20<01:11,  3.36it/s] 52%|█████▏    | 259/500 [01:20<01:11,  3.36it/s] 52%|█████▏    | 260/500 [01:20<01:11,  3.37it/s] 52%|█████▏    | 261/500 [01:20<01:11,  3.37it/s] 52%|█████▏    | 262/500 [01:21<01:10,  3.37it/s] 53%|█████▎    | 263/500 [01:21<01:10,  3.37it/s] 53%|█████▎    | 264/500 [01:21<01:10,  3.37it/s] 53%|█████▎    | 265/500 [01:22<01:09,  3.37it/s] 53%|█████▎    | 266/500 [01:22<01:09,  3.36it/s] 53%|█████▎    | 267/500 [01:22<01:09,  3.36it/s] 54%|█████▎    | 268/500 [01:23<01:09,  3.36it/s] 54%|█████▍    | 269/500 [01:23<01:08,  3.36it/s] 54%|█████▍    | 270/500 [01:23<01:08,  3.37it/s] 54%|█████▍    | 271/500 [01:23<01:07,  3.37it/s] 54%|█████▍    | 272/500 [01:24<01:07,  3.37it/s] 55%|█████▍    | 273/500 [01:24<01:07,  3.36it/s] 55%|█████▍    | 274/500 [01:24<01:07,  3.36it/s] 55%|█████▌    | 275/500 [01:25<01:07,  3.36it/s] 55%|█████▌    | 276/500 [01:25<01:06,  3.36it/s] 55%|█████▌    | 277/500 [01:25<01:06,  3.36it/s] 56%|█████▌    | 278/500 [01:26<01:06,  3.36it/s] 56%|█████▌    | 279/500 [01:26<01:05,  3.37it/s] 56%|█████▌    | 280/500 [01:26<01:05,  3.37it/s] 56%|█████▌    | 281/500 [01:26<01:05,  3.36it/s] 56%|█████▋    | 282/500 [01:27<01:04,  3.36it/s] 57%|█████▋    | 283/500 [01:27<01:04,  3.36it/s] 57%|█████▋    | 284/500 [01:27<01:04,  3.36it/s] 57%|█████▋    | 285/500 [01:28<01:04,  3.36it/s] 57%|█████▋    | 286/500 [01:28<01:03,  3.35it/s] 57%|█████▋    | 287/500 [01:28<01:03,  3.36it/s] 58%|█████▊    | 288/500 [01:29<01:03,  3.36it/s] 58%|█████▊    | 289/500 [01:29<01:02,  3.36it/s] 58%|█████▊    | 290/500 [01:29<01:02,  3.36it/s] 58%|█████▊    | 291/500 [01:29<01:02,  3.36it/s] 58%|█████▊    | 292/500 [01:30<01:01,  3.36it/s] 59%|█████▊    | 293/500 [01:30<01:01,  3.36it/s] 59%|█████▉    | 294/500 [01:30<01:01,  3.36it/s] 59%|█████▉    | 295/500 [01:31<01:00,  3.36it/s] 59%|█████▉    | 296/500 [01:31<01:00,  3.36it/s] 59%|█████▉    | 297/500 [01:31<01:00,  3.36it/s] 60%|█████▉    | 298/500 [01:31<01:00,  3.36it/s] 60%|█████▉    | 299/500 [01:32<00:59,  3.36it/s] 60%|██████    | 300/500 [01:32<00:59,  3.36it/s] 60%|██████    | 301/500 [01:32<00:59,  3.36it/s] 60%|██████    | 302/500 [01:33<00:59,  3.36it/s] 61%|██████    | 303/500 [01:33<00:58,  3.34it/s] 61%|██████    | 304/500 [01:33<00:58,  3.35it/s] 61%|██████    | 305/500 [01:34<00:58,  3.35it/s] 61%|██████    | 306/500 [01:34<00:57,  3.35it/s] 61%|██████▏   | 307/500 [01:34<00:57,  3.36it/s] 62%|██████▏   | 308/500 [01:34<00:57,  3.36it/s] 62%|██████▏   | 309/500 [01:35<00:56,  3.36it/s] 62%|██████▏   | 310/500 [01:35<00:56,  3.36it/s] 62%|██████▏   | 311/500 [01:35<00:56,  3.36it/s] 62%|██████▏   | 312/500 [01:36<00:55,  3.36it/s] 63%|██████▎   | 313/500 [01:36<00:55,  3.36it/s] 63%|██████▎   | 314/500 [01:36<00:55,  3.35it/s] 63%|██████▎   | 315/500 [01:37<00:55,  3.35it/s] 63%|██████▎   | 316/500 [01:37<00:54,  3.35it/s] 63%|██████▎   | 317/500 [01:37<00:54,  3.36it/s] 64%|██████▎   | 318/500 [01:37<00:54,  3.35it/s] 64%|██████▍   | 319/500 [01:38<00:53,  3.35it/s] 64%|██████▍   | 320/500 [01:38<00:53,  3.36it/s] 64%|██████▍   | 321/500 [01:38<00:53,  3.36it/s] 64%|██████▍   | 322/500 [01:39<00:52,  3.36it/s] 65%|██████▍   | 323/500 [01:39<00:52,  3.36it/s] 65%|██████▍   | 324/500 [01:39<00:52,  3.36it/s] 65%|██████▌   | 325/500 [01:40<00:52,  3.36it/s] 65%|██████▌   | 326/500 [01:40<00:51,  3.36it/s] 65%|██████▌   | 327/500 [01:40<00:51,  3.36it/s] 66%|██████▌   | 328/500 [01:40<00:51,  3.36it/s] 66%|██████▌   | 329/500 [01:41<00:50,  3.36it/s] 66%|██████▌   | 330/500 [01:41<00:50,  3.37it/s] 66%|██████▌   | 331/500 [01:41<00:50,  3.37it/s] 66%|██████▋   | 332/500 [01:42<00:49,  3.37it/s] 67%|██████▋   | 333/500 [01:42<00:49,  3.36it/s] 67%|██████▋   | 334/500 [01:42<00:49,  3.36it/s] 67%|██████▋   | 335/500 [01:42<00:49,  3.37it/s] 67%|██████▋   | 336/500 [01:43<00:48,  3.36it/s] 67%|██████▋   | 337/500 [01:43<00:48,  3.36it/s] 68%|██████▊   | 338/500 [01:43<00:48,  3.36it/s] 68%|██████▊   | 339/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 340/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 341/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 342/500 [01:45<00:46,  3.36it/s] 69%|██████▊   | 343/500 [01:45<00:46,  3.36it/s] 69%|██████▉   | 344/500 [01:45<00:46,  3.36it/s] 69%|██████▉   | 345/500 [01:45<00:46,  3.36it/s] 69%|██████▉   | 346/500 [01:46<00:45,  3.36it/s] 69%|██████▉   | 347/500 [01:46<00:45,  3.36it/s] 70%|██████▉   | 348/500 [01:46<00:45,  3.36it/s] 70%|██████▉   | 349/500 [01:47<00:44,  3.36it/s] 70%|███████   | 350/500 [01:47<00:44,  3.36it/s] 70%|███████   | 351/500 [01:47<00:44,  3.36it/s] 70%|███████   | 352/500 [01:48<00:44,  3.36it/s] 71%|███████   | 353/500 [01:48<00:43,  3.36it/s] 71%|███████   | 354/500 [01:48<00:43,  3.36it/s] 71%|███████   | 355/500 [01:48<00:43,  3.36it/s] 71%|███████   | 356/500 [01:49<00:42,  3.36it/s] 71%|███████▏  | 357/500 [01:49<00:42,  3.36it/s] 72%|███████▏  | 358/500 [01:49<00:42,  3.36it/s] 72%|███████▏  | 359/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 360/500 [01:50<00:41,  3.35it/s] 72%|███████▏  | 361/500 [01:50<00:41,  3.35it/s] 72%|███████▏  | 362/500 [01:51<00:41,  3.35it/s] 73%|███████▎  | 363/500 [01:51<00:40,  3.35it/s] 73%|███████▎  | 364/500 [01:51<00:40,  3.35it/s] 73%|███████▎  | 365/500 [01:51<00:40,  3.36it/s] 73%|███████▎  | 366/500 [01:52<00:39,  3.36it/s] 73%|███████▎  | 367/500 [01:52<00:39,  3.36it/s] 74%|███████▎  | 368/500 [01:52<00:39,  3.36it/s] 74%|███████▍  | 369/500 [01:53<00:38,  3.36it/s] 74%|███████▍  | 370/500 [01:53<00:38,  3.36it/s] 74%|███████▍  | 371/500 [01:53<00:38,  3.35it/s] 74%|███████▍  | 372/500 [01:54<00:38,  3.35it/s] 75%|███████▍  | 373/500 [01:54<00:37,  3.35it/s] 75%|███████▍  | 374/500 [01:54<00:37,  3.35it/s] 75%|███████▌  | 375/500 [01:54<00:37,  3.35it/s] 75%|███████▌  | 376/500 [01:55<00:36,  3.35it/s] 75%|███████▌  | 377/500 [01:55<00:36,  3.35it/s] 76%|███████▌  | 378/500 [01:55<00:36,  3.35it/s] 76%|███████▌  | 379/500 [01:56<00:36,  3.35it/s] 76%|███████▌  | 380/500 [01:56<00:35,  3.35it/s] 76%|███████▌  | 381/500 [01:56<00:35,  3.35it/s] 76%|███████▋  | 382/500 [01:56<00:35,  3.36it/s] 77%|███████▋  | 383/500 [01:57<00:34,  3.35it/s] 77%|███████▋  | 384/500 [01:57<00:34,  3.35it/s] 77%|███████▋  | 385/500 [01:57<00:34,  3.35it/s] 77%|███████▋  | 386/500 [01:58<00:34,  3.35it/s] 77%|███████▋  | 387/500 [01:58<00:33,  3.35it/s] 78%|███████▊  | 388/500 [01:58<00:33,  3.35it/s] 78%|███████▊  | 389/500 [01:59<00:33,  3.35it/s] 78%|███████▊  | 390/500 [01:59<00:32,  3.34it/s] 78%|███████▊  | 391/500 [01:59<00:32,  3.34it/s] 78%|███████▊  | 392/500 [01:59<00:32,  3.35it/s] 79%|███████▊  | 393/500 [02:00<00:31,  3.35it/s] 79%|███████▉  | 394/500 [02:00<00:31,  3.35it/s] 79%|███████▉  | 395/500 [02:00<00:31,  3.35it/s] 79%|███████▉  | 396/500 [02:01<00:30,  3.36it/s] 79%|███████▉  | 397/500 [02:01<00:30,  3.36it/s] 80%|███████▉  | 398/500 [02:01<00:30,  3.35it/s] 80%|███████▉  | 399/500 [02:02<00:30,  3.36it/s] 80%|████████  | 400/500 [02:02<00:29,  3.35it/s] 80%|████████  | 401/500 [02:02<00:29,  3.35it/s] 80%|████████  | 402/500 [02:02<00:29,  3.36it/s] 81%|████████  | 403/500 [02:03<00:28,  3.36it/s] 81%|████████  | 404/500 [02:03<00:28,  3.35it/s] 81%|████████  | 405/500 [02:03<00:28,  3.36it/s] 81%|████████  | 406/500 [02:04<00:27,  3.36it/s] 81%|████████▏ | 407/500 [02:04<00:27,  3.36it/s] 82%|████████▏ | 408/500 [02:04<00:27,  3.36it/s] 82%|████████▏ | 409/500 [02:05<00:27,  3.36it/s] 82%|████████▏ | 410/500 [02:05<00:26,  3.36it/s] 82%|████████▏ | 411/500 [02:05<00:26,  3.36it/s] 82%|████████▏ | 412/500 [02:05<00:26,  3.36it/s] 83%|████████▎ | 413/500 [02:06<00:25,  3.36it/s] 83%|████████▎ | 414/500 [02:06<00:25,  3.36it/s] 83%|████████▎ | 415/500 [02:06<00:25,  3.35it/s] 83%|████████▎ | 416/500 [02:07<00:25,  3.35it/s] 83%|████████▎ | 417/500 [02:07<00:24,  3.36it/s] 84%|████████▎ | 418/500 [02:07<00:24,  3.36it/s] 84%|████████▍ | 419/500 [02:08<00:24,  3.36it/s] 84%|████████▍ | 420/500 [02:08<00:23,  3.35it/s] 84%|████████▍ | 421/500 [02:08<00:23,  3.36it/s] 84%|████████▍ | 422/500 [02:08<00:23,  3.36it/s] 85%|████████▍ | 423/500 [02:09<00:22,  3.36it/s] 85%|████████▍ | 424/500 [02:09<00:22,  3.36it/s] 85%|████████▌ | 425/500 [02:09<00:22,  3.36it/s] 85%|████████▌ | 426/500 [02:10<00:22,  3.36it/s] 85%|████████▌ | 427/500 [02:10<00:21,  3.36it/s] 86%|████████▌ | 428/500 [02:10<00:21,  3.36it/s] 86%|████████▌ | 429/500 [02:11<00:21,  3.36it/s] 86%|████████▌ | 430/500 [02:11<00:20,  3.36it/s] 86%|████████▌ | 431/500 [02:11<00:20,  3.36it/s] 86%|████████▋ | 432/500 [02:11<00:20,  3.36it/s] 87%|████████▋ | 433/500 [02:12<00:19,  3.36it/s] 87%|████████▋ | 434/500 [02:12<00:19,  3.35it/s] 87%|████████▋ | 435/500 [02:12<00:19,  3.35it/s] 87%|████████▋ | 436/500 [02:13<00:19,  3.36it/s] 87%|████████▋ | 437/500 [02:13<00:18,  3.36it/s] 88%|████████▊ | 438/500 [02:13<00:18,  3.35it/s] 88%|████████▊ | 439/500 [02:13<00:18,  3.35it/s] 88%|████████▊ | 440/500 [02:14<00:17,  3.36it/s] 88%|████████▊ | 441/500 [02:14<00:17,  3.36it/s] 88%|████████▊ | 442/500 [02:14<00:17,  3.36it/s] 89%|████████▊ | 443/500 [02:15<00:16,  3.36it/s] 89%|████████▉ | 444/500 [02:15<00:16,  3.36it/s] 89%|████████▉ | 445/500 [02:15<00:16,  3.36it/s] 89%|████████▉ | 446/500 [02:16<00:16,  3.36it/s] 89%|████████▉ | 447/500 [02:16<00:15,  3.35it/s] 90%|████████▉ | 448/500 [02:16<00:15,  3.35it/s] 90%|████████▉ | 449/500 [02:16<00:15,  3.36it/s] 90%|█████████ | 450/500 [02:17<00:14,  3.36it/s] 90%|█████████ | 451/500 [02:17<00:14,  3.36it/s] 90%|█████████ | 452/500 [02:17<00:14,  3.36it/s] 91%|█████████ | 453/500 [02:18<00:13,  3.36it/s] 91%|█████████ | 454/500 [02:18<00:13,  3.36it/s] 91%|█████████ | 455/500 [02:18<00:13,  3.36it/s] 91%|█████████ | 456/500 [02:19<00:13,  3.35it/s] 91%|█████████▏| 457/500 [02:19<00:12,  3.36it/s] 92%|█████████▏| 458/500 [02:19<00:12,  3.36it/s] 92%|█████████▏| 459/500 [02:19<00:12,  3.35it/s] 92%|█████████▏| 460/500 [02:20<00:11,  3.36it/s] 92%|█████████▏| 461/500 [02:20<00:11,  3.36it/s] 92%|█████████▏| 462/500 [02:20<00:11,  3.35it/s] 93%|█████████▎| 463/500 [02:21<00:11,  3.36it/s] 93%|█████████▎| 464/500 [02:21<00:10,  3.36it/s] 93%|█████████▎| 465/500 [02:21<00:10,  3.35it/s] 93%|█████████▎| 466/500 [02:22<00:10,  3.35it/s] 93%|█████████▎| 467/500 [02:22<00:09,  3.35it/s] 94%|█████████▎| 468/500 [02:22<00:09,  3.34it/s] 94%|█████████▍| 469/500 [02:22<00:09,  3.34it/s] 94%|█████████▍| 470/500 [02:23<00:08,  3.34it/s] 94%|█████████▍| 471/500 [02:23<00:08,  3.34it/s] 94%|█████████▍| 472/500 [02:23<00:08,  3.34it/s] 95%|█████████▍| 473/500 [02:24<00:08,  3.34it/s] 95%|█████████▍| 474/500 [02:24<00:07,  3.34it/s] 95%|█████████▌| 475/500 [02:24<00:07,  3.35it/s] 95%|█████████▌| 476/500 [02:25<00:07,  3.35it/s] 95%|█████████▌| 477/500 [02:25<00:06,  3.35it/s] 96%|█████████▌| 478/500 [02:25<00:06,  3.36it/s] 96%|█████████▌| 479/500 [02:25<00:06,  3.36it/s] 96%|█████████▌| 480/500 [02:26<00:05,  3.36it/s] 96%|█████████▌| 481/500 [02:26<00:05,  3.36it/s] 96%|█████████▋| 482/500 [02:26<00:05,  3.36it/s] 97%|█████████▋| 483/500 [02:27<00:05,  3.36it/s] 97%|█████████▋| 484/500 [02:27<00:04,  3.36it/s] 97%|█████████▋| 485/500 [02:27<00:04,  3.35it/s] 97%|█████████▋| 486/500 [02:27<00:04,  3.36it/s] 97%|█████████▋| 487/500 [02:28<00:03,  3.36it/s] 98%|█████████▊| 488/500 [02:28<00:03,  3.36it/s] 98%|█████████▊| 489/500 [02:28<00:03,  3.37it/s] 98%|█████████▊| 490/500 [02:29<00:02,  3.37it/s] 98%|█████████▊| 491/500 [02:29<00:02,  3.37it/s] 98%|█████████▊| 492/500 [02:29<00:02,  3.37it/s] 99%|█████████▊| 493/500 [02:30<00:02,  3.37it/s] 99%|█████████▉| 494/500 [02:30<00:01,  3.37it/s] 99%|█████████▉| 495/500 [02:30<00:01,  3.37it/s] 99%|█████████▉| 496/500 [02:30<00:01,  3.38it/s] 99%|█████████▉| 497/500 [02:31<00:00,  3.37it/s]100%|█████████▉| 498/500 [02:31<00:00,  3.37it/s]100%|█████████▉| 499/500 [02:31<00:00,  3.37it/s]100%|██████████| 500/500 [02:32<00:00,  3.37it/s]100%|██████████| 500/500 [02:32<00:00,  3.28it/s]
=> result
* total: 50,000
* correct: 20,123
* accuracy: 40.2%
* error: 59.8%
* macro_f1: 37.3%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 caltech101 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/caltech101/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/caltech101/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_1.pkl
1600 1649 2465
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      1,649
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:19,  3.30s/it]  8%|▊         | 2/25 [00:03<00:32,  1.43s/it] 12%|█▏        | 3/25 [00:03<00:18,  1.20it/s] 16%|█▌        | 4/25 [00:03<00:11,  1.81it/s] 20%|██        | 5/25 [00:03<00:07,  2.52it/s] 24%|██▍       | 6/25 [00:03<00:05,  3.30it/s] 28%|██▊       | 7/25 [00:04<00:04,  4.11it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.89it/s] 36%|███▌      | 9/25 [00:04<00:02,  5.61it/s] 40%|████      | 10/25 [00:04<00:02,  6.22it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.73it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.13it/s] 52%|█████▏    | 13/25 [00:04<00:01,  7.45it/s] 56%|█████▌    | 14/25 [00:04<00:01,  7.70it/s] 60%|██████    | 15/25 [00:04<00:01,  7.88it/s] 64%|██████▍   | 16/25 [00:05<00:01,  8.01it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.10it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.17it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.21it/s] 80%|████████  | 20/25 [00:05<00:00,  8.25it/s] 84%|████████▍ | 21/25 [00:05<00:00,  8.27it/s] 88%|████████▊ | 22/25 [00:05<00:00,  8.28it/s] 92%|█████████▏| 23/25 [00:05<00:00,  8.29it/s] 96%|█████████▌| 24/25 [00:06<00:00,  8.30it/s]100%|██████████| 25/25 [00:06<00:00,  4.01it/s]
=> result
* total: 2,465
* correct: 1,618
* accuracy: 65.6%
* error: 34.4%
* macro_f1: 64.6%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 caltech101 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/caltech101/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/caltech101/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_2.pkl
1600 1649 2465
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      1,649
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:02<01:11,  2.96s/it]  8%|▊         | 2/25 [00:03<00:29,  1.29s/it] 12%|█▏        | 3/25 [00:03<00:16,  1.32it/s] 16%|█▌        | 4/25 [00:03<00:10,  1.98it/s] 20%|██        | 5/25 [00:03<00:07,  2.73it/s] 24%|██▍       | 6/25 [00:03<00:05,  3.54it/s] 28%|██▊       | 7/25 [00:03<00:04,  4.36it/s] 32%|███▏      | 8/25 [00:03<00:03,  5.14it/s] 36%|███▌      | 9/25 [00:03<00:02,  5.84it/s] 40%|████      | 10/25 [00:04<00:02,  6.42it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.91it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.29it/s] 52%|█████▏    | 13/25 [00:04<00:01,  7.57it/s] 56%|█████▌    | 14/25 [00:04<00:01,  7.78it/s] 60%|██████    | 15/25 [00:04<00:01,  7.94it/s] 64%|██████▍   | 16/25 [00:04<00:01,  8.06it/s] 68%|██████▊   | 17/25 [00:04<00:00,  8.14it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.19it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.24it/s] 80%|████████  | 20/25 [00:05<00:00,  8.27it/s] 84%|████████▍ | 21/25 [00:05<00:00,  8.29it/s] 88%|████████▊ | 22/25 [00:05<00:00,  8.29it/s] 92%|█████████▏| 23/25 [00:05<00:00,  8.30it/s] 96%|█████████▌| 24/25 [00:05<00:00,  8.31it/s]100%|██████████| 25/25 [00:05<00:00,  4.25it/s]
=> result
* total: 2,465
* correct: 1,640
* accuracy: 66.5%
* error: 33.5%
* macro_f1: 64.0%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 caltech101 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/caltech101/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/caltech101/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_3.pkl
1600 1649 2465
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      1,649
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:02<01:11,  2.98s/it]  8%|▊         | 2/25 [00:03<00:29,  1.30s/it] 12%|█▏        | 3/25 [00:03<00:16,  1.31it/s] 16%|█▌        | 4/25 [00:03<00:10,  1.97it/s] 20%|██        | 5/25 [00:03<00:07,  2.72it/s] 24%|██▍       | 6/25 [00:03<00:05,  3.53it/s] 28%|██▊       | 7/25 [00:03<00:04,  4.35it/s] 32%|███▏      | 8/25 [00:03<00:03,  5.13it/s] 36%|███▌      | 9/25 [00:03<00:02,  5.83it/s] 40%|████      | 10/25 [00:04<00:02,  6.42it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.91it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.30it/s] 52%|█████▏    | 13/25 [00:04<00:01,  7.60it/s] 56%|█████▌    | 14/25 [00:04<00:01,  7.82it/s] 60%|██████    | 15/25 [00:04<00:01,  7.99it/s] 64%|██████▍   | 16/25 [00:04<00:01,  8.10it/s] 68%|██████▊   | 17/25 [00:04<00:00,  8.17it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.23it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.27it/s] 80%|████████  | 20/25 [00:05<00:00,  8.30it/s] 84%|████████▍ | 21/25 [00:05<00:00,  8.32it/s] 88%|████████▊ | 22/25 [00:05<00:00,  8.34it/s] 92%|█████████▏| 23/25 [00:05<00:00,  8.35it/s] 96%|█████████▌| 24/25 [00:05<00:00,  8.35it/s]100%|██████████| 25/25 [00:05<00:00,  4.23it/s]
=> result
* total: 2,465
* correct: 1,815
* accuracy: 73.6%
* error: 26.4%
* macro_f1: 67.5%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 oxford_pets 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/oxford_pets/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/oxford_pets/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_1.pkl
592 736 3669
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      736
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/37 [00:00<?, ?it/s]  3%|▎         | 1/37 [00:03<02:03,  3.44s/it]  5%|▌         | 2/37 [00:03<00:51,  1.48s/it]  8%|▊         | 3/37 [00:03<00:29,  1.17it/s] 11%|█         | 4/37 [00:03<00:18,  1.79it/s] 14%|█▎        | 5/37 [00:03<00:12,  2.52it/s] 16%|█▌        | 6/37 [00:03<00:09,  3.35it/s] 19%|█▉        | 7/37 [00:04<00:07,  4.24it/s] 22%|██▏       | 8/37 [00:04<00:05,  5.13it/s] 24%|██▍       | 9/37 [00:04<00:04,  5.96it/s] 27%|██▋       | 10/37 [00:04<00:04,  6.70it/s] 30%|██▉       | 11/37 [00:04<00:03,  7.30it/s] 32%|███▏      | 12/37 [00:04<00:03,  7.78it/s] 35%|███▌      | 13/37 [00:04<00:02,  8.16it/s] 38%|███▊      | 14/37 [00:04<00:02,  8.47it/s] 41%|████      | 15/37 [00:04<00:02,  8.68it/s] 43%|████▎     | 16/37 [00:05<00:02,  8.82it/s] 46%|████▌     | 17/37 [00:05<00:02,  8.95it/s] 49%|████▊     | 18/37 [00:05<00:02,  9.02it/s] 51%|█████▏    | 19/37 [00:05<00:01,  9.05it/s] 54%|█████▍    | 20/37 [00:05<00:01,  9.13it/s] 57%|█████▋    | 21/37 [00:05<00:01,  9.18it/s] 59%|█████▉    | 22/37 [00:05<00:01,  9.19it/s] 62%|██████▏   | 23/37 [00:05<00:01,  9.22it/s] 65%|██████▍   | 24/37 [00:05<00:01,  9.24it/s] 68%|██████▊   | 25/37 [00:06<00:01,  9.19it/s] 70%|███████   | 26/37 [00:06<00:01,  9.22it/s] 73%|███████▎  | 27/37 [00:06<00:01,  9.23it/s] 76%|███████▌  | 28/37 [00:06<00:00,  9.25it/s] 78%|███████▊  | 29/37 [00:06<00:00,  9.29it/s] 81%|████████  | 30/37 [00:06<00:00,  9.30it/s] 84%|████████▍ | 31/37 [00:06<00:00,  9.31it/s] 86%|████████▋ | 32/37 [00:06<00:00,  9.33it/s] 89%|████████▉ | 33/37 [00:06<00:00,  9.34it/s] 92%|█████████▏| 34/37 [00:07<00:00,  9.34it/s] 95%|█████████▍| 35/37 [00:07<00:00,  9.35it/s] 97%|█████████▋| 36/37 [00:07<00:00,  9.36it/s]100%|██████████| 37/37 [00:07<00:00,  5.02it/s]
=> result
* total: 3,669
* correct: 2,202
* accuracy: 60.0%
* error: 40.0%
* macro_f1: 53.3%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 oxford_pets 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/oxford_pets/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/oxford_pets/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_2.pkl
592 736 3669
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      736
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/37 [00:00<?, ?it/s]  3%|▎         | 1/37 [00:03<02:07,  3.53s/it]  5%|▌         | 2/37 [00:03<00:53,  1.52s/it]  8%|▊         | 3/37 [00:03<00:29,  1.14it/s] 11%|█         | 4/37 [00:03<00:18,  1.75it/s] 14%|█▎        | 5/37 [00:03<00:12,  2.47it/s] 16%|█▌        | 6/37 [00:04<00:09,  3.30it/s] 19%|█▉        | 7/37 [00:04<00:07,  4.18it/s] 22%|██▏       | 8/37 [00:04<00:05,  5.06it/s] 24%|██▍       | 9/37 [00:04<00:04,  5.90it/s] 27%|██▋       | 10/37 [00:04<00:04,  6.64it/s] 30%|██▉       | 11/37 [00:04<00:03,  7.28it/s] 32%|███▏      | 12/37 [00:04<00:03,  7.79it/s] 35%|███▌      | 13/37 [00:04<00:02,  8.20it/s] 38%|███▊      | 14/37 [00:04<00:02,  8.47it/s] 41%|████      | 15/37 [00:05<00:02,  8.65it/s] 43%|████▎     | 16/37 [00:05<00:02,  8.82it/s] 46%|████▌     | 17/37 [00:05<00:02,  8.95it/s] 49%|████▊     | 18/37 [00:05<00:02,  9.05it/s] 51%|█████▏    | 19/37 [00:05<00:01,  9.10it/s] 54%|█████▍    | 20/37 [00:05<00:01,  9.16it/s] 57%|█████▋    | 21/37 [00:05<00:01,  9.15it/s] 59%|█████▉    | 22/37 [00:05<00:01,  9.20it/s] 62%|██████▏   | 23/37 [00:05<00:01,  9.23it/s] 65%|██████▍   | 24/37 [00:06<00:01,  9.26it/s] 68%|██████▊   | 25/37 [00:06<00:01,  9.27it/s] 70%|███████   | 26/37 [00:06<00:01,  9.28it/s] 73%|███████▎  | 27/37 [00:06<00:01,  9.29it/s] 76%|███████▌  | 28/37 [00:06<00:00,  9.32it/s] 78%|███████▊  | 29/37 [00:06<00:00,  9.34it/s] 81%|████████  | 30/37 [00:06<00:00,  9.35it/s] 84%|████████▍ | 31/37 [00:06<00:00,  9.35it/s] 86%|████████▋ | 32/37 [00:06<00:00,  9.36it/s] 89%|████████▉ | 33/37 [00:06<00:00,  9.24it/s] 92%|█████████▏| 34/37 [00:07<00:00,  9.29it/s] 95%|█████████▍| 35/37 [00:07<00:00,  9.30it/s] 97%|█████████▋| 36/37 [00:07<00:00,  9.33it/s]100%|██████████| 37/37 [00:07<00:00,  4.96it/s]
=> result
* total: 3,669
* correct: 1,749
* accuracy: 47.7%
* error: 52.3%
* macro_f1: 38.3%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 oxford_pets 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/oxford_pets/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/oxford_pets/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_3.pkl
592 736 3669
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      736
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/37 [00:00<?, ?it/s]  3%|▎         | 1/37 [00:03<02:00,  3.34s/it]  5%|▌         | 2/37 [00:03<00:50,  1.44s/it]  8%|▊         | 3/37 [00:03<00:28,  1.20it/s] 11%|█         | 4/37 [00:03<00:18,  1.83it/s] 14%|█▎        | 5/37 [00:03<00:12,  2.57it/s] 16%|█▌        | 6/37 [00:03<00:09,  3.41it/s] 19%|█▉        | 7/37 [00:03<00:06,  4.31it/s] 22%|██▏       | 8/37 [00:04<00:05,  5.18it/s] 24%|██▍       | 9/37 [00:04<00:04,  6.00it/s] 27%|██▋       | 10/37 [00:04<00:04,  6.72it/s] 30%|██▉       | 11/37 [00:04<00:03,  7.34it/s] 32%|███▏      | 12/37 [00:04<00:03,  7.83it/s] 35%|███▌      | 13/37 [00:04<00:02,  8.18it/s] 38%|███▊      | 14/37 [00:04<00:02,  8.46it/s] 41%|████      | 15/37 [00:04<00:02,  8.67it/s] 43%|████▎     | 16/37 [00:04<00:02,  8.64it/s] 46%|████▌     | 17/37 [00:05<00:02,  8.80it/s] 49%|████▊     | 18/37 [00:05<00:02,  8.92it/s] 51%|█████▏    | 19/37 [00:05<00:01,  9.01it/s] 54%|█████▍    | 20/37 [00:05<00:01,  9.07it/s] 57%|█████▋    | 21/37 [00:05<00:01,  9.11it/s] 59%|█████▉    | 22/37 [00:05<00:01,  9.12it/s] 62%|██████▏   | 23/37 [00:05<00:01,  9.17it/s] 65%|██████▍   | 24/37 [00:05<00:01,  9.21it/s] 68%|██████▊   | 25/37 [00:05<00:01,  9.25it/s] 70%|███████   | 26/37 [00:06<00:01,  9.26it/s] 73%|███████▎  | 27/37 [00:06<00:01,  9.27it/s] 76%|███████▌  | 28/37 [00:06<00:00,  9.30it/s] 78%|███████▊  | 29/37 [00:06<00:00,  9.32it/s] 81%|████████  | 30/37 [00:06<00:00,  9.34it/s] 84%|████████▍ | 31/37 [00:06<00:00,  9.35it/s] 86%|████████▋ | 32/37 [00:06<00:00,  9.36it/s] 89%|████████▉ | 33/37 [00:06<00:00,  9.36it/s] 92%|█████████▏| 34/37 [00:06<00:00,  9.37it/s] 95%|█████████▍| 35/37 [00:07<00:00,  9.37it/s] 97%|█████████▋| 36/37 [00:07<00:00,  9.37it/s]100%|██████████| 37/37 [00:07<00:00,  5.08it/s]
=> result
* total: 3,669
* correct: 2,111
* accuracy: 57.5%
* error: 42.5%
* macro_f1: 47.2%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 stanford_cars 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/stanford_cars/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/stanford_cars/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_1.pkl
3136 1635 8041
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  196
# train_x  3,136
# val      1,635
# test     8,041
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:04<05:23,  4.04s/it]  2%|▏         | 2/81 [00:04<02:17,  1.74s/it]  4%|▎         | 3/81 [00:04<01:18,  1.01s/it]  5%|▍         | 4/81 [00:04<00:51,  1.50it/s]  6%|▌         | 5/81 [00:04<00:36,  2.10it/s]  7%|▋         | 6/81 [00:04<00:27,  2.77it/s]  9%|▊         | 7/81 [00:04<00:21,  3.47it/s] 10%|▉         | 8/81 [00:05<00:17,  4.16it/s] 11%|█         | 9/81 [00:05<00:15,  4.80it/s] 12%|█▏        | 10/81 [00:05<00:13,  5.33it/s] 14%|█▎        | 11/81 [00:05<00:12,  5.80it/s] 15%|█▍        | 12/81 [00:05<00:11,  6.18it/s] 16%|█▌        | 13/81 [00:05<00:10,  6.47it/s] 17%|█▋        | 14/81 [00:05<00:10,  6.68it/s] 19%|█▊        | 15/81 [00:05<00:09,  6.84it/s] 20%|█▉        | 16/81 [00:06<00:09,  6.95it/s] 21%|██        | 17/81 [00:06<00:09,  7.03it/s] 22%|██▏       | 18/81 [00:06<00:08,  7.10it/s] 23%|██▎       | 19/81 [00:06<00:08,  7.14it/s] 25%|██▍       | 20/81 [00:06<00:08,  7.17it/s] 26%|██▌       | 21/81 [00:06<00:08,  7.20it/s] 27%|██▋       | 22/81 [00:06<00:08,  7.20it/s] 28%|██▊       | 23/81 [00:07<00:08,  7.22it/s] 30%|██▉       | 24/81 [00:07<00:07,  7.22it/s] 31%|███       | 25/81 [00:07<00:07,  7.21it/s] 32%|███▏      | 26/81 [00:08<00:17,  3.07it/s] 33%|███▎      | 27/81 [00:08<00:14,  3.71it/s] 35%|███▍      | 28/81 [00:08<00:12,  4.34it/s] 36%|███▌      | 29/81 [00:08<00:10,  4.93it/s] 37%|███▋      | 30/81 [00:08<00:09,  5.44it/s] 38%|███▊      | 31/81 [00:08<00:08,  5.88it/s] 40%|███▉      | 32/81 [00:08<00:07,  6.22it/s] 41%|████      | 33/81 [00:09<00:12,  3.86it/s] 42%|████▏     | 34/81 [00:09<00:10,  4.48it/s] 43%|████▎     | 35/81 [00:09<00:09,  5.05it/s] 44%|████▍     | 36/81 [00:09<00:08,  5.54it/s] 46%|████▌     | 37/81 [00:09<00:07,  5.94it/s] 47%|████▋     | 38/81 [00:10<00:08,  5.22it/s] 48%|████▊     | 39/81 [00:10<00:07,  5.68it/s] 49%|████▉     | 40/81 [00:10<00:06,  6.07it/s] 51%|█████     | 41/81 [00:10<00:08,  4.45it/s] 52%|█████▏    | 42/81 [00:11<00:07,  5.03it/s] 53%|█████▎    | 43/81 [00:11<00:09,  3.90it/s] 54%|█████▍    | 44/81 [00:11<00:08,  4.52it/s] 56%|█████▌    | 45/81 [00:11<00:07,  5.09it/s] 57%|█████▋    | 46/81 [00:11<00:06,  5.58it/s] 58%|█████▊    | 47/81 [00:11<00:05,  5.99it/s] 59%|█████▉    | 48/81 [00:12<00:06,  4.84it/s] 60%|██████    | 49/81 [00:12<00:07,  4.45it/s] 62%|██████▏   | 50/81 [00:12<00:06,  5.02it/s] 63%|██████▎   | 51/81 [00:13<00:07,  3.80it/s] 64%|██████▍   | 52/81 [00:13<00:06,  4.42it/s] 65%|██████▌   | 53/81 [00:13<00:05,  4.98it/s] 67%|██████▋   | 54/81 [00:13<00:05,  5.33it/s] 68%|██████▊   | 55/81 [00:13<00:04,  5.78it/s] 69%|██████▉   | 56/81 [00:13<00:04,  6.15it/s] 70%|███████   | 57/81 [00:14<00:05,  4.65it/s] 72%|███████▏  | 58/81 [00:14<00:04,  5.20it/s] 73%|███████▎  | 59/81 [00:14<00:06,  3.25it/s] 74%|███████▍  | 60/81 [00:14<00:05,  3.89it/s] 75%|███████▌  | 61/81 [00:15<00:04,  4.50it/s] 77%|███████▋  | 62/81 [00:15<00:03,  5.07it/s] 78%|███████▊  | 63/81 [00:15<00:03,  5.55it/s] 79%|███████▉  | 64/81 [00:15<00:02,  5.96it/s] 80%|████████  | 65/81 [00:16<00:04,  3.33it/s] 81%|████████▏ | 66/81 [00:16<00:03,  3.97it/s] 83%|████████▎ | 67/81 [00:16<00:04,  2.94it/s] 84%|████████▍ | 68/81 [00:16<00:03,  3.57it/s] 85%|████████▌ | 69/81 [00:17<00:02,  4.21it/s] 86%|████████▋ | 70/81 [00:17<00:02,  4.79it/s] 88%|████████▊ | 71/81 [00:17<00:01,  5.32it/s] 89%|████████▉ | 72/81 [00:17<00:01,  5.77it/s] 90%|█████████ | 73/81 [00:17<00:01,  6.06it/s] 91%|█████████▏| 74/81 [00:17<00:01,  6.36it/s] 93%|█████████▎| 75/81 [00:18<00:01,  3.15it/s] 94%|█████████▍| 76/81 [00:18<00:01,  3.80it/s] 95%|█████████▌| 77/81 [00:18<00:00,  4.43it/s] 96%|█████████▋| 78/81 [00:18<00:00,  5.02it/s] 98%|█████████▊| 79/81 [00:19<00:00,  5.53it/s] 99%|█████████▉| 80/81 [00:19<00:00,  5.95it/s]100%|██████████| 81/81 [00:19<00:00,  4.18it/s]
=> result
* total: 8,041
* correct: 3,477
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 38.7%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 stanford_cars 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/stanford_cars/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/stanford_cars/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_2.pkl
3136 1635 8041
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  196
# train_x  3,136
# val      1,635
# test     8,041
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:03<04:59,  3.74s/it]  2%|▏         | 2/81 [00:03<02:08,  1.62s/it]  4%|▎         | 3/81 [00:04<01:13,  1.06it/s]  5%|▍         | 4/81 [00:04<00:48,  1.60it/s]  6%|▌         | 5/81 [00:04<00:34,  2.22it/s]  7%|▋         | 6/81 [00:04<00:25,  2.91it/s]  9%|▊         | 7/81 [00:04<00:20,  3.62it/s] 10%|▉         | 8/81 [00:04<00:16,  4.30it/s] 11%|█         | 9/81 [00:04<00:14,  4.93it/s] 12%|█▏        | 10/81 [00:04<00:13,  5.46it/s] 14%|█▎        | 11/81 [00:05<00:11,  5.90it/s] 15%|█▍        | 12/81 [00:05<00:11,  6.24it/s] 16%|█▌        | 13/81 [00:05<00:10,  6.50it/s] 17%|█▋        | 14/81 [00:05<00:10,  6.69it/s] 19%|█▊        | 15/81 [00:05<00:09,  6.83it/s] 20%|█▉        | 16/81 [00:05<00:09,  6.94it/s] 21%|██        | 17/81 [00:05<00:09,  7.01it/s] 22%|██▏       | 18/81 [00:06<00:08,  7.06it/s] 23%|██▎       | 19/81 [00:06<00:08,  7.10it/s] 25%|██▍       | 20/81 [00:06<00:08,  7.12it/s] 26%|██▌       | 21/81 [00:06<00:08,  7.14it/s] 27%|██▋       | 22/81 [00:06<00:08,  7.15it/s] 28%|██▊       | 23/81 [00:06<00:08,  7.16it/s] 30%|██▉       | 24/81 [00:06<00:07,  7.16it/s] 31%|███       | 25/81 [00:07<00:07,  7.16it/s] 32%|███▏      | 26/81 [00:07<00:07,  7.17it/s] 33%|███▎      | 27/81 [00:07<00:07,  7.18it/s] 35%|███▍      | 28/81 [00:07<00:07,  7.18it/s] 36%|███▌      | 29/81 [00:07<00:07,  7.18it/s] 37%|███▋      | 30/81 [00:08<00:15,  3.20it/s] 38%|███▊      | 31/81 [00:08<00:13,  3.84it/s] 40%|███▉      | 32/81 [00:08<00:10,  4.47it/s] 41%|████      | 33/81 [00:08<00:09,  5.04it/s] 42%|████▏     | 34/81 [00:08<00:08,  5.54it/s] 43%|████▎     | 35/81 [00:09<00:07,  5.94it/s] 44%|████▍     | 36/81 [00:09<00:07,  6.26it/s] 46%|████▌     | 37/81 [00:09<00:06,  6.50it/s] 47%|████▋     | 38/81 [00:09<00:09,  4.52it/s] 48%|████▊     | 39/81 [00:09<00:08,  5.08it/s] 49%|████▉     | 40/81 [00:09<00:07,  5.57it/s] 51%|█████     | 41/81 [00:10<00:06,  5.98it/s] 52%|█████▏    | 42/81 [00:10<00:06,  6.29it/s] 53%|█████▎    | 43/81 [00:10<00:05,  6.52it/s] 54%|█████▍    | 44/81 [00:10<00:05,  6.70it/s] 56%|█████▌    | 45/81 [00:10<00:05,  6.83it/s] 57%|█████▋    | 46/81 [00:10<00:06,  5.58it/s] 58%|█████▊    | 47/81 [00:11<00:05,  5.97it/s] 59%|█████▉    | 48/81 [00:11<00:05,  6.28it/s] 60%|██████    | 49/81 [00:11<00:04,  6.52it/s] 62%|██████▏   | 50/81 [00:11<00:04,  6.70it/s] 63%|██████▎   | 51/81 [00:11<00:04,  6.83it/s] 64%|██████▍   | 52/81 [00:11<00:04,  6.94it/s] 65%|██████▌   | 53/81 [00:11<00:03,  7.01it/s] 67%|██████▋   | 54/81 [00:12<00:06,  4.38it/s] 68%|██████▊   | 55/81 [00:12<00:05,  4.95it/s] 69%|██████▉   | 56/81 [00:12<00:04,  5.45it/s] 70%|███████   | 57/81 [00:12<00:04,  5.87it/s] 72%|███████▏  | 58/81 [00:12<00:03,  6.20it/s] 73%|███████▎  | 59/81 [00:13<00:03,  6.39it/s] 74%|███████▍  | 60/81 [00:13<00:03,  6.58it/s] 75%|███████▌  | 61/81 [00:13<00:02,  6.74it/s] 77%|███████▋  | 62/81 [00:13<00:02,  6.68it/s] 78%|███████▊  | 63/81 [00:13<00:02,  6.81it/s] 79%|███████▉  | 64/81 [00:14<00:04,  3.96it/s] 80%|████████  | 65/81 [00:14<00:03,  4.56it/s] 81%|████████▏ | 66/81 [00:14<00:02,  5.12it/s] 83%|████████▎ | 67/81 [00:14<00:02,  5.60it/s] 84%|████████▍ | 68/81 [00:14<00:02,  5.99it/s] 85%|████████▌ | 69/81 [00:14<00:01,  6.31it/s] 86%|████████▋ | 70/81 [00:14<00:01,  6.54it/s] 88%|████████▊ | 71/81 [00:15<00:01,  6.72it/s] 89%|████████▉ | 72/81 [00:15<00:02,  3.52it/s] 90%|█████████ | 73/81 [00:15<00:01,  4.16it/s] 91%|█████████▏| 74/81 [00:15<00:01,  4.77it/s] 93%|█████████▎| 75/81 [00:16<00:01,  5.30it/s] 94%|█████████▍| 76/81 [00:16<00:00,  5.77it/s] 95%|█████████▌| 77/81 [00:16<00:00,  6.14it/s] 96%|█████████▋| 78/81 [00:16<00:00,  6.43it/s] 98%|█████████▊| 79/81 [00:16<00:00,  6.65it/s] 99%|█████████▉| 80/81 [00:16<00:00,  6.81it/s]100%|██████████| 81/81 [00:16<00:00,  4.77it/s]
=> result
* total: 8,041
* correct: 3,743
* accuracy: 46.5%
* error: 53.5%
* macro_f1: 41.2%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 stanford_cars 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/stanford_cars/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/stanford_cars/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_3.pkl
3136 1635 8041
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  196
# train_x  3,136
# val      1,635
# test     8,041
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:04<05:37,  4.22s/it]  2%|▏         | 2/81 [00:04<02:23,  1.82s/it]  4%|▎         | 3/81 [00:04<01:21,  1.05s/it]  5%|▍         | 4/81 [00:04<00:53,  1.45it/s]  6%|▌         | 5/81 [00:04<00:37,  2.03it/s]  7%|▋         | 6/81 [00:04<00:27,  2.68it/s]  9%|▊         | 7/81 [00:05<00:21,  3.37it/s] 10%|▉         | 8/81 [00:05<00:18,  4.06it/s] 11%|█         | 9/81 [00:05<00:15,  4.69it/s] 12%|█▏        | 10/81 [00:05<00:13,  5.26it/s] 14%|█▎        | 11/81 [00:05<00:12,  5.73it/s] 15%|█▍        | 12/81 [00:05<00:11,  6.10it/s] 16%|█▌        | 13/81 [00:05<00:10,  6.37it/s] 17%|█▋        | 14/81 [00:06<00:10,  6.56it/s] 19%|█▊        | 15/81 [00:06<00:09,  6.73it/s] 20%|█▉        | 16/81 [00:06<00:09,  6.84it/s] 21%|██        | 17/81 [00:06<00:09,  6.94it/s] 22%|██▏       | 18/81 [00:06<00:08,  7.01it/s] 23%|██▎       | 19/81 [00:06<00:08,  7.07it/s] 25%|██▍       | 20/81 [00:06<00:08,  7.10it/s] 26%|██▌       | 21/81 [00:07<00:08,  7.13it/s] 27%|██▋       | 22/81 [00:07<00:08,  7.15it/s] 28%|██▊       | 23/81 [00:07<00:08,  7.16it/s] 30%|██▉       | 24/81 [00:07<00:07,  7.16it/s] 31%|███       | 25/81 [00:07<00:07,  7.17it/s] 32%|███▏      | 26/81 [00:07<00:07,  7.18it/s] 33%|███▎      | 27/81 [00:07<00:07,  7.19it/s] 35%|███▍      | 28/81 [00:07<00:07,  7.19it/s] 36%|███▌      | 29/81 [00:08<00:07,  7.19it/s] 37%|███▋      | 30/81 [00:08<00:10,  4.67it/s] 38%|███▊      | 31/81 [00:08<00:09,  5.22it/s] 40%|███▉      | 32/81 [00:08<00:08,  5.69it/s] 41%|████      | 33/81 [00:09<00:13,  3.60it/s] 42%|████▏     | 34/81 [00:09<00:11,  4.23it/s] 43%|████▎     | 35/81 [00:09<00:09,  4.83it/s] 44%|████▍     | 36/81 [00:09<00:08,  5.36it/s] 46%|████▌     | 37/81 [00:09<00:07,  5.79it/s] 47%|████▋     | 38/81 [00:10<00:08,  4.93it/s] 48%|████▊     | 39/81 [00:10<00:07,  5.44it/s] 49%|████▉     | 40/81 [00:10<00:06,  5.87it/s] 51%|█████     | 41/81 [00:10<00:06,  6.21it/s] 52%|█████▏    | 42/81 [00:10<00:06,  6.46it/s] 53%|█████▎    | 43/81 [00:10<00:05,  6.66it/s] 54%|█████▍    | 44/81 [00:10<00:05,  6.80it/s] 56%|█████▌    | 45/81 [00:11<00:05,  6.91it/s] 57%|█████▋    | 46/81 [00:11<00:05,  6.98it/s] 58%|█████▊    | 47/81 [00:11<00:04,  7.04it/s] 59%|█████▉    | 48/81 [00:11<00:04,  7.08it/s] 60%|██████    | 49/81 [00:11<00:04,  6.53it/s] 62%|██████▏   | 50/81 [00:11<00:04,  6.71it/s] 63%|██████▎   | 51/81 [00:11<00:04,  6.84it/s] 64%|██████▍   | 52/81 [00:12<00:04,  6.93it/s] 65%|██████▌   | 53/81 [00:12<00:03,  7.00it/s] 67%|██████▋   | 54/81 [00:12<00:07,  3.44it/s] 68%|██████▊   | 55/81 [00:13<00:06,  4.07it/s] 69%|██████▉   | 56/81 [00:13<00:05,  4.68it/s] 70%|███████   | 57/81 [00:13<00:04,  5.22it/s] 72%|███████▏  | 58/81 [00:13<00:04,  5.66it/s] 73%|███████▎  | 59/81 [00:13<00:03,  6.04it/s] 74%|███████▍  | 60/81 [00:13<00:03,  6.34it/s] 75%|███████▌  | 61/81 [00:13<00:03,  6.57it/s] 77%|███████▋  | 62/81 [00:14<00:05,  3.20it/s] 78%|███████▊  | 63/81 [00:14<00:04,  3.84it/s] 79%|███████▉  | 64/81 [00:14<00:03,  4.46it/s] 80%|████████  | 65/81 [00:14<00:03,  5.03it/s] 81%|████████▏ | 66/81 [00:15<00:02,  5.52it/s] 83%|████████▎ | 67/81 [00:15<00:02,  5.93it/s] 84%|████████▍ | 68/81 [00:15<00:02,  6.26it/s] 85%|████████▌ | 69/81 [00:15<00:01,  6.51it/s] 86%|████████▋ | 70/81 [00:15<00:01,  6.69it/s] 88%|████████▊ | 71/81 [00:15<00:01,  6.84it/s] 89%|████████▉ | 72/81 [00:15<00:01,  6.95it/s] 90%|█████████ | 73/81 [00:16<00:01,  7.03it/s] 91%|█████████▏| 74/81 [00:16<00:00,  7.10it/s] 93%|█████████▎| 75/81 [00:16<00:00,  7.14it/s] 94%|█████████▍| 76/81 [00:16<00:00,  7.17it/s] 95%|█████████▌| 77/81 [00:16<00:00,  7.20it/s] 96%|█████████▋| 78/81 [00:16<00:00,  7.21it/s] 98%|█████████▊| 79/81 [00:16<00:00,  7.22it/s] 99%|█████████▉| 80/81 [00:17<00:00,  7.24it/s]100%|██████████| 81/81 [00:17<00:00,  4.70it/s]
=> result
* total: 8,041
* correct: 3,815
* accuracy: 47.4%
* error: 52.6%
* macro_f1: 42.6%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 oxford_flowers 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/oxford_flowers/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/oxford_flowers/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_1.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:32,  3.86s/it]  8%|▊         | 2/25 [00:03<00:38,  1.66s/it] 12%|█▏        | 3/25 [00:04<00:21,  1.04it/s] 16%|█▌        | 4/25 [00:04<00:13,  1.59it/s] 20%|██        | 5/25 [00:04<00:08,  2.25it/s] 24%|██▍       | 6/25 [00:04<00:06,  2.99it/s] 28%|██▊       | 7/25 [00:04<00:04,  3.78it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.57it/s] 36%|███▌      | 9/25 [00:04<00:03,  5.31it/s] 40%|████      | 10/25 [00:04<00:02,  5.97it/s] 44%|████▍     | 11/25 [00:05<00:02,  6.52it/s] 48%|████▊     | 12/25 [00:05<00:01,  6.91it/s] 52%|█████▏    | 13/25 [00:05<00:01,  7.29it/s] 56%|█████▌    | 14/25 [00:05<00:01,  7.56it/s] 60%|██████    | 15/25 [00:05<00:01,  7.78it/s] 64%|██████▍   | 16/25 [00:05<00:01,  7.92it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.03it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.13it/s] 76%|███████▌  | 19/25 [00:06<00:00,  8.20it/s] 80%|████████  | 20/25 [00:06<00:00,  8.25it/s] 84%|████████▍ | 21/25 [00:06<00:00,  8.28it/s] 88%|████████▊ | 22/25 [00:06<00:00,  8.30it/s] 92%|█████████▏| 23/25 [00:06<00:00,  8.31it/s] 96%|█████████▌| 24/25 [00:06<00:00,  8.32it/s]100%|██████████| 25/25 [00:06<00:00,  3.68it/s]
=> result
* total: 2,463
* correct: 855
* accuracy: 34.7%
* error: 65.3%
* macro_f1: 27.8%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 oxford_flowers 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/oxford_flowers/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/oxford_flowers/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_2.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:27,  3.64s/it]  8%|▊         | 2/25 [00:03<00:36,  1.57s/it] 12%|█▏        | 3/25 [00:03<00:19,  1.10it/s] 16%|█▌        | 4/25 [00:04<00:12,  1.68it/s] 20%|██        | 5/25 [00:04<00:08,  2.35it/s] 24%|██▍       | 6/25 [00:04<00:06,  3.11it/s] 28%|██▊       | 7/25 [00:04<00:04,  3.90it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.68it/s] 36%|███▌      | 9/25 [00:04<00:02,  5.41it/s] 40%|████      | 10/25 [00:04<00:02,  6.05it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.60it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.04it/s] 52%|█████▏    | 13/25 [00:05<00:01,  7.37it/s] 56%|█████▌    | 14/25 [00:05<00:01,  7.63it/s] 60%|██████    | 15/25 [00:05<00:01,  7.83it/s] 64%|██████▍   | 16/25 [00:05<00:01,  7.99it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.09it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.17it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.22it/s] 80%|████████  | 20/25 [00:05<00:00,  8.26it/s] 84%|████████▍ | 21/25 [00:06<00:00,  8.28it/s] 88%|████████▊ | 22/25 [00:06<00:00,  8.30it/s] 92%|█████████▏| 23/25 [00:06<00:00,  8.33it/s] 96%|█████████▌| 24/25 [00:06<00:00,  8.33it/s]100%|██████████| 25/25 [00:06<00:00,  3.81it/s]
=> result
* total: 2,463
* correct: 1,088
* accuracy: 44.2%
* error: 55.8%
* macro_f1: 37.0%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 oxford_flowers 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/oxford_flowers/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/oxford_flowers/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_3.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:28,  3.67s/it]  8%|▊         | 2/25 [00:03<00:36,  1.58s/it] 12%|█▏        | 3/25 [00:03<00:20,  1.09it/s] 16%|█▌        | 4/25 [00:04<00:12,  1.66it/s] 20%|██        | 5/25 [00:04<00:08,  2.34it/s] 24%|██▍       | 6/25 [00:04<00:06,  3.09it/s] 28%|██▊       | 7/25 [00:04<00:04,  3.88it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.67it/s] 36%|███▌      | 9/25 [00:04<00:02,  5.41it/s] 40%|████      | 10/25 [00:04<00:02,  6.06it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.60it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.04it/s] 52%|█████▏    | 13/25 [00:05<00:01,  7.38it/s] 56%|█████▌    | 14/25 [00:05<00:01,  7.63it/s] 60%|██████    | 15/25 [00:05<00:01,  7.82it/s] 64%|██████▍   | 16/25 [00:05<00:01,  7.96it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.07it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.15it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.22it/s] 80%|████████  | 20/25 [00:05<00:00,  8.25it/s] 84%|████████▍ | 21/25 [00:06<00:00,  8.28it/s] 88%|████████▊ | 22/25 [00:06<00:00,  8.30it/s] 92%|█████████▏| 23/25 [00:06<00:00,  8.32it/s] 96%|█████████▌| 24/25 [00:06<00:00,  8.33it/s]100%|██████████| 25/25 [00:06<00:00,  3.79it/s]
=> result
* total: 2,463
* correct: 1,011
* accuracy: 41.0%
* error: 59.0%
* macro_f1: 32.3%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 food101 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/food101/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/food101/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_1.pkl
1616 20200 30300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  101
# train_x  1,616
# val      20,200
# test     30,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/303 [00:00<?, ?it/s]  0%|          | 1/303 [00:03<16:48,  3.34s/it]  1%|          | 2/303 [00:03<07:15,  1.45s/it]  1%|          | 3/303 [00:03<04:12,  1.19it/s]  1%|▏         | 4/303 [00:03<02:46,  1.80it/s]  2%|▏         | 5/303 [00:03<01:58,  2.50it/s]  2%|▏         | 6/303 [00:03<01:30,  3.28it/s]  2%|▏         | 7/303 [00:04<01:12,  4.09it/s]  3%|▎         | 8/303 [00:04<01:00,  4.88it/s]  3%|▎         | 9/303 [00:04<00:52,  5.60it/s]  3%|▎         | 10/303 [00:04<00:47,  6.22it/s]  4%|▎         | 11/303 [00:04<00:43,  6.73it/s]  4%|▍         | 12/303 [00:04<00:40,  7.13it/s]  4%|▍         | 13/303 [00:04<00:38,  7.44it/s]  5%|▍         | 14/303 [00:04<00:37,  7.68it/s]  5%|▍         | 15/303 [00:05<00:36,  7.84it/s]  5%|▌         | 16/303 [00:05<00:36,  7.96it/s]  6%|▌         | 17/303 [00:05<00:35,  8.05it/s]  6%|▌         | 18/303 [00:05<00:35,  8.10it/s]  6%|▋         | 19/303 [00:05<00:34,  8.15it/s]  7%|▋         | 20/303 [00:05<00:34,  8.19it/s]  7%|▋         | 21/303 [00:05<00:34,  8.23it/s]  7%|▋         | 22/303 [00:05<00:34,  8.24it/s]  8%|▊         | 23/303 [00:05<00:33,  8.25it/s]  8%|▊         | 24/303 [00:06<00:33,  8.25it/s]  8%|▊         | 25/303 [00:06<00:33,  8.26it/s]  9%|▊         | 26/303 [00:06<00:33,  8.27it/s]  9%|▉         | 27/303 [00:06<00:33,  8.25it/s]  9%|▉         | 28/303 [00:06<00:33,  8.25it/s] 10%|▉         | 29/303 [00:06<00:33,  8.26it/s] 10%|▉         | 30/303 [00:06<00:33,  8.25it/s] 10%|█         | 31/303 [00:06<00:32,  8.26it/s] 11%|█         | 32/303 [00:07<00:32,  8.27it/s] 11%|█         | 33/303 [00:07<00:32,  8.27it/s] 11%|█         | 34/303 [00:07<00:32,  8.26it/s] 12%|█▏        | 35/303 [00:07<00:32,  8.26it/s] 12%|█▏        | 36/303 [00:07<00:32,  8.26it/s] 12%|█▏        | 37/303 [00:07<00:32,  8.26it/s] 13%|█▎        | 38/303 [00:07<00:32,  8.25it/s] 13%|█▎        | 39/303 [00:07<00:32,  8.24it/s] 13%|█▎        | 40/303 [00:08<00:31,  8.25it/s] 14%|█▎        | 41/303 [00:08<00:31,  8.25it/s] 14%|█▍        | 42/303 [00:08<00:31,  8.26it/s] 14%|█▍        | 43/303 [00:08<00:31,  8.27it/s] 15%|█▍        | 44/303 [00:08<00:31,  8.27it/s] 15%|█▍        | 45/303 [00:08<00:31,  8.28it/s] 15%|█▌        | 46/303 [00:08<00:31,  8.27it/s] 16%|█▌        | 47/303 [00:08<00:32,  7.94it/s] 16%|█▌        | 48/303 [00:09<00:31,  8.02it/s] 16%|█▌        | 49/303 [00:09<00:31,  8.09it/s] 17%|█▋        | 50/303 [00:09<00:31,  8.16it/s] 17%|█▋        | 51/303 [00:09<00:30,  8.20it/s] 17%|█▋        | 52/303 [00:09<00:30,  8.22it/s] 17%|█▋        | 53/303 [00:09<00:30,  8.23it/s] 18%|█▊        | 54/303 [00:09<00:30,  8.22it/s] 18%|█▊        | 55/303 [00:09<00:30,  8.25it/s] 18%|█▊        | 56/303 [00:10<00:29,  8.25it/s] 19%|█▉        | 57/303 [00:10<00:29,  8.26it/s] 19%|█▉        | 58/303 [00:10<00:29,  8.26it/s] 19%|█▉        | 59/303 [00:10<00:29,  8.24it/s] 20%|█▉        | 60/303 [00:10<00:29,  8.24it/s] 20%|██        | 61/303 [00:10<00:29,  8.25it/s] 20%|██        | 62/303 [00:10<00:29,  8.25it/s] 21%|██        | 63/303 [00:10<00:29,  8.26it/s] 21%|██        | 64/303 [00:10<00:29,  8.23it/s] 21%|██▏       | 65/303 [00:11<00:28,  8.24it/s] 22%|██▏       | 66/303 [00:11<00:28,  8.26it/s] 22%|██▏       | 67/303 [00:11<00:28,  8.23it/s] 22%|██▏       | 68/303 [00:11<00:28,  8.24it/s] 23%|██▎       | 69/303 [00:11<00:28,  8.23it/s] 23%|██▎       | 70/303 [00:11<00:28,  8.24it/s] 23%|██▎       | 71/303 [00:11<00:28,  8.25it/s] 24%|██▍       | 72/303 [00:11<00:27,  8.26it/s] 24%|██▍       | 73/303 [00:12<00:27,  8.25it/s] 24%|██▍       | 74/303 [00:12<00:27,  8.25it/s] 25%|██▍       | 75/303 [00:12<00:27,  8.23it/s] 25%|██▌       | 76/303 [00:12<00:27,  8.22it/s] 25%|██▌       | 77/303 [00:12<00:27,  8.23it/s] 26%|██▌       | 78/303 [00:12<00:27,  8.25it/s] 26%|██▌       | 79/303 [00:12<00:27,  8.27it/s] 26%|██▋       | 80/303 [00:12<00:26,  8.28it/s] 27%|██▋       | 81/303 [00:13<00:26,  8.28it/s] 27%|██▋       | 82/303 [00:13<00:26,  8.29it/s] 27%|██▋       | 83/303 [00:13<00:26,  8.30it/s] 28%|██▊       | 84/303 [00:13<00:26,  8.30it/s] 28%|██▊       | 85/303 [00:13<00:26,  8.30it/s] 28%|██▊       | 86/303 [00:13<00:26,  8.30it/s] 29%|██▊       | 87/303 [00:13<00:26,  8.29it/s] 29%|██▉       | 88/303 [00:13<00:25,  8.29it/s] 29%|██▉       | 89/303 [00:14<00:48,  4.43it/s] 30%|██▉       | 90/303 [00:14<00:41,  5.15it/s] 30%|███       | 91/303 [00:15<01:19,  2.65it/s] 30%|███       | 92/303 [00:15<01:18,  2.70it/s] 31%|███       | 93/303 [00:15<01:02,  3.38it/s] 31%|███       | 94/303 [00:15<00:50,  4.11it/s] 31%|███▏      | 95/303 [00:15<00:42,  4.84it/s] 32%|███▏      | 96/303 [00:16<00:37,  5.53it/s] 32%|███▏      | 97/303 [00:16<00:33,  6.13it/s] 32%|███▏      | 98/303 [00:16<00:30,  6.65it/s] 33%|███▎      | 99/303 [00:16<00:28,  7.06it/s] 33%|███▎      | 100/303 [00:16<00:27,  7.39it/s] 33%|███▎      | 101/303 [00:16<00:26,  7.63it/s] 34%|███▎      | 102/303 [00:16<00:25,  7.80it/s] 34%|███▍      | 103/303 [00:16<00:25,  7.94it/s] 34%|███▍      | 104/303 [00:17<00:24,  8.04it/s] 35%|███▍      | 105/303 [00:17<00:24,  8.10it/s] 35%|███▍      | 106/303 [00:17<00:24,  8.15it/s] 35%|███▌      | 107/303 [00:17<00:23,  8.19it/s] 36%|███▌      | 108/303 [00:17<00:23,  8.20it/s] 36%|███▌      | 109/303 [00:17<00:23,  8.23it/s] 36%|███▋      | 110/303 [00:17<00:23,  8.23it/s] 37%|███▋      | 111/303 [00:17<00:23,  8.24it/s] 37%|███▋      | 112/303 [00:18<00:23,  8.25it/s] 37%|███▋      | 113/303 [00:18<00:22,  8.26it/s] 38%|███▊      | 114/303 [00:18<00:22,  8.24it/s] 38%|███▊      | 115/303 [00:18<00:22,  8.19it/s] 38%|███▊      | 116/303 [00:18<00:22,  8.22it/s] 39%|███▊      | 117/303 [00:18<00:22,  8.24it/s] 39%|███▉      | 118/303 [00:18<00:22,  8.23it/s] 39%|███▉      | 119/303 [00:18<00:22,  8.24it/s] 40%|███▉      | 120/303 [00:19<00:22,  8.24it/s] 40%|███▉      | 121/303 [00:19<00:22,  8.23it/s] 40%|████      | 122/303 [00:19<00:22,  8.22it/s] 41%|████      | 123/303 [00:19<00:21,  8.22it/s] 41%|████      | 124/303 [00:19<00:21,  8.23it/s] 41%|████▏     | 125/303 [00:19<00:21,  8.15it/s] 42%|████▏     | 126/303 [00:19<00:21,  8.17it/s] 42%|████▏     | 127/303 [00:19<00:21,  8.19it/s] 42%|████▏     | 128/303 [00:20<00:21,  8.20it/s] 43%|████▎     | 129/303 [00:20<00:21,  8.21it/s] 43%|████▎     | 130/303 [00:20<00:21,  8.22it/s] 43%|████▎     | 131/303 [00:20<00:20,  8.24it/s] 44%|████▎     | 132/303 [00:20<00:20,  8.24it/s] 44%|████▍     | 133/303 [00:20<00:20,  8.24it/s] 44%|████▍     | 134/303 [00:20<00:20,  8.25it/s] 45%|████▍     | 135/303 [00:20<00:20,  8.25it/s] 45%|████▍     | 136/303 [00:20<00:20,  8.26it/s] 45%|████▌     | 137/303 [00:21<00:20,  8.25it/s] 46%|████▌     | 138/303 [00:21<00:19,  8.27it/s] 46%|████▌     | 139/303 [00:21<00:19,  8.27it/s] 46%|████▌     | 140/303 [00:21<00:19,  8.27it/s] 47%|████▋     | 141/303 [00:21<00:19,  8.28it/s] 47%|████▋     | 142/303 [00:21<00:19,  8.28it/s] 47%|████▋     | 143/303 [00:21<00:19,  8.28it/s] 48%|████▊     | 144/303 [00:21<00:19,  8.27it/s] 48%|████▊     | 145/303 [00:22<00:19,  8.26it/s] 48%|████▊     | 146/303 [00:22<00:18,  8.26it/s] 49%|████▊     | 147/303 [00:22<00:18,  8.26it/s] 49%|████▉     | 148/303 [00:22<00:18,  8.26it/s] 49%|████▉     | 149/303 [00:22<00:18,  8.26it/s] 50%|████▉     | 150/303 [00:22<00:18,  8.24it/s] 50%|████▉     | 151/303 [00:22<00:18,  8.24it/s] 50%|█████     | 152/303 [00:22<00:18,  8.24it/s] 50%|█████     | 153/303 [00:23<00:18,  8.22it/s] 51%|█████     | 154/303 [00:23<00:18,  8.22it/s] 51%|█████     | 155/303 [00:23<00:18,  8.20it/s] 51%|█████▏    | 156/303 [00:23<00:17,  8.21it/s] 52%|█████▏    | 157/303 [00:23<00:17,  8.22it/s] 52%|█████▏    | 158/303 [00:23<00:17,  8.21it/s] 52%|█████▏    | 159/303 [00:23<00:17,  8.20it/s] 53%|█████▎    | 160/303 [00:23<00:17,  8.20it/s] 53%|█████▎    | 161/303 [00:24<00:17,  8.20it/s] 53%|█████▎    | 162/303 [00:24<00:17,  8.20it/s] 54%|█████▍    | 163/303 [00:24<00:17,  8.20it/s] 54%|█████▍    | 164/303 [00:24<00:16,  8.20it/s] 54%|█████▍    | 165/303 [00:24<00:16,  8.20it/s] 55%|█████▍    | 166/303 [00:24<00:16,  8.20it/s] 55%|█████▌    | 167/303 [00:24<00:16,  8.20it/s] 55%|█████▌    | 168/303 [00:24<00:16,  8.20it/s] 56%|█████▌    | 169/303 [00:24<00:16,  8.21it/s] 56%|█████▌    | 170/303 [00:25<00:16,  8.22it/s] 56%|█████▋    | 171/303 [00:25<00:16,  8.21it/s] 57%|█████▋    | 172/303 [00:25<00:15,  8.21it/s] 57%|█████▋    | 173/303 [00:25<00:15,  8.23it/s] 57%|█████▋    | 174/303 [00:25<00:15,  8.22it/s] 58%|█████▊    | 175/303 [00:25<00:15,  8.23it/s] 58%|█████▊    | 176/303 [00:25<00:15,  8.24it/s] 58%|█████▊    | 177/303 [00:25<00:15,  8.23it/s] 59%|█████▊    | 178/303 [00:26<00:15,  8.22it/s] 59%|█████▉    | 179/303 [00:26<00:15,  8.22it/s] 59%|█████▉    | 180/303 [00:26<00:14,  8.22it/s] 60%|█████▉    | 181/303 [00:26<00:14,  8.21it/s] 60%|██████    | 182/303 [00:26<00:14,  8.22it/s] 60%|██████    | 183/303 [00:26<00:14,  8.22it/s] 61%|██████    | 184/303 [00:26<00:14,  8.20it/s] 61%|██████    | 185/303 [00:26<00:14,  8.21it/s] 61%|██████▏   | 186/303 [00:27<00:14,  8.22it/s] 62%|██████▏   | 187/303 [00:27<00:14,  8.21it/s] 62%|██████▏   | 188/303 [00:27<00:14,  8.21it/s] 62%|██████▏   | 189/303 [00:27<00:13,  8.21it/s] 63%|██████▎   | 190/303 [00:27<00:13,  8.21it/s] 63%|██████▎   | 191/303 [00:27<00:13,  8.21it/s] 63%|██████▎   | 192/303 [00:27<00:13,  8.21it/s] 64%|██████▎   | 193/303 [00:27<00:13,  8.20it/s] 64%|██████▍   | 194/303 [00:28<00:13,  8.20it/s] 64%|██████▍   | 195/303 [00:28<00:13,  8.19it/s] 65%|██████▍   | 196/303 [00:28<00:13,  8.14it/s] 65%|██████▌   | 197/303 [00:28<00:12,  8.16it/s] 65%|██████▌   | 198/303 [00:28<00:12,  8.17it/s] 66%|██████▌   | 199/303 [00:28<00:12,  8.18it/s] 66%|██████▌   | 200/303 [00:28<00:12,  8.17it/s] 66%|██████▋   | 201/303 [00:28<00:12,  8.18it/s] 67%|██████▋   | 202/303 [00:29<00:12,  8.17it/s] 67%|██████▋   | 203/303 [00:29<00:12,  8.16it/s] 67%|██████▋   | 204/303 [00:29<00:12,  8.16it/s] 68%|██████▊   | 205/303 [00:29<00:12,  8.17it/s] 68%|██████▊   | 206/303 [00:29<00:11,  8.17it/s] 68%|██████▊   | 207/303 [00:29<00:11,  8.18it/s] 69%|██████▊   | 208/303 [00:29<00:11,  8.19it/s] 69%|██████▉   | 209/303 [00:29<00:11,  8.19it/s] 69%|██████▉   | 210/303 [00:29<00:11,  8.18it/s] 70%|██████▉   | 211/303 [00:30<00:11,  8.18it/s] 70%|██████▉   | 212/303 [00:30<00:11,  8.16it/s] 70%|███████   | 213/303 [00:30<00:11,  8.17it/s] 71%|███████   | 214/303 [00:30<00:10,  8.18it/s] 71%|███████   | 215/303 [00:30<00:10,  8.17it/s] 71%|███████▏  | 216/303 [00:30<00:10,  8.17it/s] 72%|███████▏  | 217/303 [00:30<00:10,  8.17it/s] 72%|███████▏  | 218/303 [00:30<00:10,  8.17it/s] 72%|███████▏  | 219/303 [00:31<00:10,  8.17it/s] 73%|███████▎  | 220/303 [00:31<00:10,  8.16it/s] 73%|███████▎  | 221/303 [00:31<00:10,  8.16it/s] 73%|███████▎  | 222/303 [00:31<00:09,  8.15it/s] 74%|███████▎  | 223/303 [00:31<00:09,  8.15it/s] 74%|███████▍  | 224/303 [00:31<00:09,  8.03it/s] 74%|███████▍  | 225/303 [00:31<00:09,  8.07it/s] 75%|███████▍  | 226/303 [00:31<00:09,  8.07it/s] 75%|███████▍  | 227/303 [00:32<00:09,  8.11it/s] 75%|███████▌  | 228/303 [00:32<00:09,  8.14it/s] 76%|███████▌  | 229/303 [00:32<00:09,  8.16it/s] 76%|███████▌  | 230/303 [00:32<00:08,  8.19it/s] 76%|███████▌  | 231/303 [00:32<00:08,  8.20it/s] 77%|███████▋  | 232/303 [00:32<00:08,  8.20it/s] 77%|███████▋  | 233/303 [00:32<00:08,  8.20it/s] 77%|███████▋  | 234/303 [00:32<00:08,  8.19it/s] 78%|███████▊  | 235/303 [00:33<00:08,  8.20it/s] 78%|███████▊  | 236/303 [00:33<00:08,  8.20it/s] 78%|███████▊  | 237/303 [00:33<00:08,  8.16it/s] 79%|███████▊  | 238/303 [00:33<00:07,  8.17it/s] 79%|███████▉  | 239/303 [00:33<00:07,  8.18it/s] 79%|███████▉  | 240/303 [00:33<00:07,  8.17it/s] 80%|███████▉  | 241/303 [00:33<00:07,  8.17it/s] 80%|███████▉  | 242/303 [00:33<00:07,  8.17it/s] 80%|████████  | 243/303 [00:34<00:07,  8.17it/s] 81%|████████  | 244/303 [00:34<00:07,  8.18it/s] 81%|████████  | 245/303 [00:34<00:07,  8.18it/s] 81%|████████  | 246/303 [00:34<00:06,  8.18it/s] 82%|████████▏ | 247/303 [00:34<00:06,  8.17it/s] 82%|████████▏ | 248/303 [00:34<00:06,  8.16it/s] 82%|████████▏ | 249/303 [00:34<00:06,  8.12it/s] 83%|████████▎ | 250/303 [00:34<00:06,  8.15it/s] 83%|████████▎ | 251/303 [00:35<00:06,  8.17it/s] 83%|████████▎ | 252/303 [00:35<00:06,  8.18it/s] 83%|████████▎ | 253/303 [00:35<00:06,  8.18it/s] 84%|████████▍ | 254/303 [00:35<00:06,  8.16it/s] 84%|████████▍ | 255/303 [00:35<00:05,  8.16it/s] 84%|████████▍ | 256/303 [00:35<00:05,  8.15it/s] 85%|████████▍ | 257/303 [00:35<00:05,  8.15it/s] 85%|████████▌ | 258/303 [00:35<00:05,  8.17it/s] 85%|████████▌ | 259/303 [00:35<00:05,  8.18it/s] 86%|████████▌ | 260/303 [00:36<00:05,  8.19it/s] 86%|████████▌ | 261/303 [00:36<00:05,  8.19it/s] 86%|████████▋ | 262/303 [00:36<00:05,  8.16it/s] 87%|████████▋ | 263/303 [00:36<00:04,  8.17it/s] 87%|████████▋ | 264/303 [00:36<00:04,  8.19it/s] 87%|████████▋ | 265/303 [00:36<00:04,  8.19it/s] 88%|████████▊ | 266/303 [00:36<00:04,  8.19it/s] 88%|████████▊ | 267/303 [00:36<00:04,  8.20it/s] 88%|████████▊ | 268/303 [00:37<00:04,  8.20it/s] 89%|████████▉ | 269/303 [00:37<00:04,  8.21it/s] 89%|████████▉ | 270/303 [00:37<00:04,  8.21it/s] 89%|████████▉ | 271/303 [00:37<00:03,  8.21it/s] 90%|████████▉ | 272/303 [00:37<00:03,  8.20it/s] 90%|█████████ | 273/303 [00:37<00:03,  8.20it/s] 90%|█████████ | 274/303 [00:37<00:03,  8.20it/s] 91%|█████████ | 275/303 [00:37<00:03,  8.20it/s] 91%|█████████ | 276/303 [00:38<00:03,  8.19it/s] 91%|█████████▏| 277/303 [00:38<00:03,  8.19it/s] 92%|█████████▏| 278/303 [00:38<00:03,  8.19it/s] 92%|█████████▏| 279/303 [00:38<00:02,  8.19it/s] 92%|█████████▏| 280/303 [00:38<00:02,  8.20it/s] 93%|█████████▎| 281/303 [00:38<00:02,  8.20it/s] 93%|█████████▎| 282/303 [00:38<00:02,  8.18it/s] 93%|█████████▎| 283/303 [00:38<00:02,  8.19it/s] 94%|█████████▎| 284/303 [00:39<00:02,  8.16it/s] 94%|█████████▍| 285/303 [00:39<00:02,  8.17it/s] 94%|█████████▍| 286/303 [00:39<00:02,  8.17it/s] 95%|█████████▍| 287/303 [00:39<00:01,  8.19it/s] 95%|█████████▌| 288/303 [00:39<00:01,  8.19it/s] 95%|█████████▌| 289/303 [00:39<00:01,  8.21it/s] 96%|█████████▌| 290/303 [00:39<00:01,  8.21it/s] 96%|█████████▌| 291/303 [00:39<00:01,  8.22it/s] 96%|█████████▋| 292/303 [00:40<00:01,  8.22it/s] 97%|█████████▋| 293/303 [00:40<00:01,  8.22it/s] 97%|█████████▋| 294/303 [00:40<00:01,  8.23it/s] 97%|█████████▋| 295/303 [00:40<00:00,  8.24it/s] 98%|█████████▊| 296/303 [00:40<00:00,  8.25it/s] 98%|█████████▊| 297/303 [00:40<00:00,  8.26it/s] 98%|█████████▊| 298/303 [00:40<00:00,  8.27it/s] 99%|█████████▊| 299/303 [00:40<00:00,  8.27it/s] 99%|█████████▉| 300/303 [00:40<00:00,  8.27it/s] 99%|█████████▉| 301/303 [00:41<00:00,  8.27it/s]100%|█████████▉| 302/303 [00:41<00:00,  8.27it/s]100%|██████████| 303/303 [00:41<00:00,  8.27it/s]100%|██████████| 303/303 [00:41<00:00,  7.31it/s]
=> result
* total: 30,300
* correct: 19,486
* accuracy: 64.3%
* error: 35.7%
* macro_f1: 62.5%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 food101 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/food101/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/food101/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_2.pkl
1616 20200 30300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  101
# train_x  1,616
# val      20,200
# test     30,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/303 [00:00<?, ?it/s]  0%|          | 1/303 [00:03<16:33,  3.29s/it]  1%|          | 2/303 [00:03<07:08,  1.43s/it]  1%|          | 3/303 [00:03<04:08,  1.21it/s]  1%|▏         | 4/303 [00:03<02:44,  1.82it/s]  2%|▏         | 5/303 [00:03<01:57,  2.54it/s]  2%|▏         | 6/303 [00:03<01:29,  3.32it/s]  2%|▏         | 7/303 [00:04<01:11,  4.13it/s]  3%|▎         | 8/303 [00:04<01:00,  4.91it/s]  3%|▎         | 9/303 [00:04<00:52,  5.63it/s]  3%|▎         | 10/303 [00:04<00:46,  6.25it/s]  4%|▎         | 11/303 [00:04<00:43,  6.76it/s]  4%|▍         | 12/303 [00:04<00:40,  7.15it/s]  4%|▍         | 13/303 [00:04<00:38,  7.45it/s]  5%|▍         | 14/303 [00:04<00:37,  7.69it/s]  5%|▍         | 15/303 [00:04<00:36,  7.86it/s]  5%|▌         | 16/303 [00:05<00:35,  7.98it/s]  6%|▌         | 17/303 [00:05<00:35,  8.07it/s]  6%|▌         | 18/303 [00:05<00:35,  8.14it/s]  6%|▋         | 19/303 [00:05<00:34,  8.18it/s]  7%|▋         | 20/303 [00:05<00:34,  8.22it/s]  7%|▋         | 21/303 [00:05<00:34,  8.23it/s]  7%|▋         | 22/303 [00:05<00:34,  8.24it/s]  8%|▊         | 23/303 [00:05<00:33,  8.25it/s]  8%|▊         | 24/303 [00:06<00:33,  8.25it/s]  8%|▊         | 25/303 [00:06<00:33,  8.26it/s]  9%|▊         | 26/303 [00:06<00:33,  8.26it/s]  9%|▉         | 27/303 [00:06<00:33,  8.26it/s]  9%|▉         | 28/303 [00:06<00:33,  8.27it/s] 10%|▉         | 29/303 [00:06<00:33,  8.26it/s] 10%|▉         | 30/303 [00:06<00:33,  8.27it/s] 10%|█         | 31/303 [00:06<00:32,  8.26it/s] 11%|█         | 32/303 [00:07<00:32,  8.26it/s] 11%|█         | 33/303 [00:07<00:32,  8.27it/s] 11%|█         | 34/303 [00:07<00:32,  8.27it/s] 12%|█▏        | 35/303 [00:07<00:32,  8.27it/s] 12%|█▏        | 36/303 [00:07<00:32,  8.26it/s] 12%|█▏        | 37/303 [00:07<00:32,  8.26it/s] 13%|█▎        | 38/303 [00:07<00:32,  8.26it/s] 13%|█▎        | 39/303 [00:07<00:32,  8.20it/s] 13%|█▎        | 40/303 [00:08<00:31,  8.23it/s] 14%|█▎        | 41/303 [00:08<00:31,  8.24it/s] 14%|█▍        | 42/303 [00:08<00:31,  8.24it/s] 14%|█▍        | 43/303 [00:08<00:31,  8.24it/s] 15%|█▍        | 44/303 [00:08<00:31,  8.25it/s] 15%|█▍        | 45/303 [00:08<00:31,  8.25it/s] 15%|█▌        | 46/303 [00:08<00:31,  8.25it/s] 16%|█▌        | 47/303 [00:08<00:31,  8.25it/s] 16%|█▌        | 48/303 [00:08<00:30,  8.26it/s] 16%|█▌        | 49/303 [00:09<00:30,  8.26it/s] 17%|█▋        | 50/303 [00:09<00:30,  8.25it/s] 17%|█▋        | 51/303 [00:09<00:31,  8.13it/s] 17%|█▋        | 52/303 [00:09<00:30,  8.18it/s] 17%|█▋        | 53/303 [00:09<00:30,  8.20it/s] 18%|█▊        | 54/303 [00:09<00:30,  8.22it/s] 18%|█▊        | 55/303 [00:09<00:30,  8.23it/s] 18%|█▊        | 56/303 [00:09<00:30,  8.21it/s] 19%|█▉        | 57/303 [00:10<00:29,  8.23it/s] 19%|█▉        | 58/303 [00:10<00:29,  8.23it/s] 19%|█▉        | 59/303 [00:10<00:29,  8.23it/s] 20%|█▉        | 60/303 [00:10<00:29,  8.23it/s] 20%|██        | 61/303 [00:10<00:29,  8.24it/s] 20%|██        | 62/303 [00:10<00:29,  8.23it/s] 21%|██        | 63/303 [00:10<00:29,  8.23it/s] 21%|██        | 64/303 [00:10<00:29,  8.24it/s] 21%|██▏       | 65/303 [00:11<00:28,  8.24it/s] 22%|██▏       | 66/303 [00:11<00:28,  8.23it/s] 22%|██▏       | 67/303 [00:11<00:28,  8.24it/s] 22%|██▏       | 68/303 [00:11<00:28,  8.25it/s] 23%|██▎       | 69/303 [00:11<00:28,  8.25it/s] 23%|██▎       | 70/303 [00:11<00:28,  8.24it/s] 23%|██▎       | 71/303 [00:11<00:28,  8.23it/s] 24%|██▍       | 72/303 [00:11<00:28,  8.25it/s] 24%|██▍       | 73/303 [00:12<00:27,  8.25it/s] 24%|██▍       | 74/303 [00:12<00:27,  8.24it/s] 25%|██▍       | 75/303 [00:12<00:27,  8.24it/s] 25%|██▌       | 76/303 [00:12<00:27,  8.25it/s] 25%|██▌       | 77/303 [00:12<00:27,  8.24it/s] 26%|██▌       | 78/303 [00:12<00:27,  8.24it/s] 26%|██▌       | 79/303 [00:12<00:27,  8.25it/s] 26%|██▋       | 80/303 [00:12<00:27,  8.24it/s] 27%|██▋       | 81/303 [00:12<00:26,  8.23it/s] 27%|██▋       | 82/303 [00:13<00:26,  8.21it/s] 27%|██▋       | 83/303 [00:13<00:26,  8.21it/s] 28%|██▊       | 84/303 [00:13<00:26,  8.22it/s] 28%|██▊       | 85/303 [00:13<00:26,  8.22it/s] 28%|██▊       | 86/303 [00:13<00:26,  8.23it/s] 29%|██▊       | 87/303 [00:13<00:26,  8.23it/s] 29%|██▉       | 88/303 [00:13<00:26,  8.23it/s] 29%|██▉       | 89/303 [00:13<00:26,  8.23it/s] 30%|██▉       | 90/303 [00:14<00:25,  8.22it/s] 30%|███       | 91/303 [00:14<00:25,  8.22it/s] 30%|███       | 92/303 [00:14<00:25,  8.23it/s] 31%|███       | 93/303 [00:14<00:25,  8.24it/s] 31%|███       | 94/303 [00:14<00:25,  8.25it/s] 31%|███▏      | 95/303 [00:14<00:25,  8.24it/s] 32%|███▏      | 96/303 [00:14<00:25,  8.24it/s] 32%|███▏      | 97/303 [00:14<00:25,  8.24it/s] 32%|███▏      | 98/303 [00:15<00:24,  8.24it/s] 33%|███▎      | 99/303 [00:15<00:24,  8.23it/s] 33%|███▎      | 100/303 [00:15<00:24,  8.23it/s] 33%|███▎      | 101/303 [00:15<00:24,  8.22it/s] 34%|███▎      | 102/303 [00:15<00:24,  8.22it/s] 34%|███▍      | 103/303 [00:15<00:24,  8.21it/s] 34%|███▍      | 104/303 [00:15<00:24,  8.22it/s] 35%|███▍      | 105/303 [00:15<00:24,  8.24it/s] 35%|███▍      | 106/303 [00:16<00:23,  8.24it/s] 35%|███▌      | 107/303 [00:16<00:23,  8.25it/s] 36%|███▌      | 108/303 [00:16<00:23,  8.24it/s] 36%|███▌      | 109/303 [00:16<00:23,  8.17it/s] 36%|███▋      | 110/303 [00:16<00:23,  8.19it/s] 37%|███▋      | 111/303 [00:16<00:23,  8.20it/s] 37%|███▋      | 112/303 [00:16<00:23,  8.21it/s] 37%|███▋      | 113/303 [00:16<00:23,  8.22it/s] 38%|███▊      | 114/303 [00:16<00:22,  8.22it/s] 38%|███▊      | 115/303 [00:17<00:22,  8.23it/s] 38%|███▊      | 116/303 [00:17<00:22,  8.23it/s] 39%|███▊      | 117/303 [00:17<00:22,  8.22it/s] 39%|███▉      | 118/303 [00:17<00:22,  8.18it/s] 39%|███▉      | 119/303 [00:17<00:22,  8.19it/s] 40%|███▉      | 120/303 [00:17<00:22,  8.20it/s] 40%|███▉      | 121/303 [00:17<00:22,  8.21it/s] 40%|████      | 122/303 [00:17<00:22,  8.14it/s] 41%|████      | 123/303 [00:18<00:22,  8.17it/s] 41%|████      | 124/303 [00:18<00:21,  8.19it/s] 41%|████▏     | 125/303 [00:18<00:21,  8.20it/s] 42%|████▏     | 126/303 [00:18<00:21,  8.21it/s] 42%|████▏     | 127/303 [00:18<00:21,  8.20it/s] 42%|████▏     | 128/303 [00:18<00:21,  8.21it/s] 43%|████▎     | 129/303 [00:18<00:21,  8.21it/s] 43%|████▎     | 130/303 [00:18<00:21,  8.20it/s] 43%|████▎     | 131/303 [00:19<00:20,  8.21it/s] 44%|████▎     | 132/303 [00:19<00:20,  8.21it/s] 44%|████▍     | 133/303 [00:19<00:20,  8.22it/s] 44%|████▍     | 134/303 [00:19<00:20,  8.20it/s] 45%|████▍     | 135/303 [00:19<00:20,  8.20it/s] 45%|████▍     | 136/303 [00:19<00:20,  8.20it/s] 45%|████▌     | 137/303 [00:19<00:20,  8.20it/s] 46%|████▌     | 138/303 [00:19<00:20,  8.21it/s] 46%|████▌     | 139/303 [00:20<00:19,  8.21it/s] 46%|████▌     | 140/303 [00:20<00:19,  8.21it/s] 47%|████▋     | 141/303 [00:20<00:19,  8.22it/s] 47%|████▋     | 142/303 [00:20<00:19,  8.23it/s] 47%|████▋     | 143/303 [00:20<00:19,  8.22it/s] 48%|████▊     | 144/303 [00:20<00:19,  8.22it/s] 48%|████▊     | 145/303 [00:20<00:19,  8.20it/s] 48%|████▊     | 146/303 [00:20<00:19,  8.20it/s] 49%|████▊     | 147/303 [00:21<00:18,  8.21it/s] 49%|████▉     | 148/303 [00:21<00:18,  8.22it/s] 49%|████▉     | 149/303 [00:21<00:18,  8.20it/s] 50%|████▉     | 150/303 [00:21<00:18,  8.20it/s] 50%|████▉     | 151/303 [00:21<00:18,  8.21it/s] 50%|█████     | 152/303 [00:21<00:18,  8.22it/s] 50%|█████     | 153/303 [00:21<00:18,  8.21it/s] 51%|█████     | 154/303 [00:21<00:18,  8.20it/s] 51%|█████     | 155/303 [00:21<00:18,  8.21it/s] 51%|█████▏    | 156/303 [00:22<00:17,  8.21it/s] 52%|█████▏    | 157/303 [00:22<00:17,  8.22it/s] 52%|█████▏    | 158/303 [00:22<00:17,  8.22it/s] 52%|█████▏    | 159/303 [00:22<00:17,  8.22it/s] 53%|█████▎    | 160/303 [00:22<00:17,  8.21it/s] 53%|█████▎    | 161/303 [00:22<00:17,  8.20it/s] 53%|█████▎    | 162/303 [00:22<00:17,  8.19it/s] 54%|█████▍    | 163/303 [00:22<00:17,  8.19it/s] 54%|█████▍    | 164/303 [00:23<00:16,  8.20it/s] 54%|█████▍    | 165/303 [00:23<00:16,  8.19it/s] 55%|█████▍    | 166/303 [00:23<00:16,  8.20it/s] 55%|█████▌    | 167/303 [00:23<00:16,  8.19it/s] 55%|█████▌    | 168/303 [00:23<00:16,  8.18it/s] 56%|█████▌    | 169/303 [00:23<00:16,  8.19it/s] 56%|█████▌    | 170/303 [00:23<00:16,  8.19it/s] 56%|█████▋    | 171/303 [00:23<00:16,  8.19it/s] 57%|█████▋    | 172/303 [00:24<00:15,  8.20it/s] 57%|█████▋    | 173/303 [00:24<00:15,  8.20it/s] 57%|█████▋    | 174/303 [00:24<00:15,  8.20it/s] 58%|█████▊    | 175/303 [00:24<00:15,  8.19it/s] 58%|█████▊    | 176/303 [00:24<00:15,  8.20it/s] 58%|█████▊    | 177/303 [00:24<00:15,  8.20it/s] 59%|█████▊    | 178/303 [00:24<00:15,  8.20it/s] 59%|█████▉    | 179/303 [00:24<00:15,  8.20it/s] 59%|█████▉    | 180/303 [00:25<00:15,  8.20it/s] 60%|█████▉    | 181/303 [00:25<00:14,  8.20it/s] 60%|██████    | 182/303 [00:25<00:14,  8.19it/s] 60%|██████    | 183/303 [00:25<00:14,  8.19it/s] 61%|██████    | 184/303 [00:25<00:14,  8.17it/s] 61%|██████    | 185/303 [00:25<00:14,  8.18it/s] 61%|██████▏   | 186/303 [00:25<00:14,  8.19it/s] 62%|██████▏   | 187/303 [00:25<00:14,  8.19it/s] 62%|██████▏   | 188/303 [00:26<00:14,  8.19it/s] 62%|██████▏   | 189/303 [00:26<00:13,  8.17it/s] 63%|██████▎   | 190/303 [00:26<00:13,  8.16it/s] 63%|██████▎   | 191/303 [00:26<00:13,  8.16it/s] 63%|██████▎   | 192/303 [00:26<00:13,  8.16it/s] 64%|██████▎   | 193/303 [00:26<00:13,  8.14it/s] 64%|██████▍   | 194/303 [00:26<00:13,  8.15it/s] 64%|██████▍   | 195/303 [00:26<00:13,  8.16it/s] 65%|██████▍   | 196/303 [00:26<00:13,  8.17it/s] 65%|██████▌   | 197/303 [00:27<00:12,  8.18it/s] 65%|██████▌   | 198/303 [00:27<00:12,  8.17it/s] 66%|██████▌   | 199/303 [00:27<00:12,  8.16it/s] 66%|██████▌   | 200/303 [00:27<00:12,  8.16it/s] 66%|██████▋   | 201/303 [00:27<00:12,  8.15it/s] 67%|██████▋   | 202/303 [00:27<00:12,  8.16it/s] 67%|██████▋   | 203/303 [00:27<00:12,  8.17it/s] 67%|██████▋   | 204/303 [00:27<00:12,  8.17it/s] 68%|██████▊   | 205/303 [00:28<00:11,  8.18it/s] 68%|██████▊   | 206/303 [00:28<00:11,  8.18it/s] 68%|██████▊   | 207/303 [00:28<00:11,  8.18it/s] 69%|██████▊   | 208/303 [00:28<00:11,  8.16it/s] 69%|██████▉   | 209/303 [00:28<00:11,  8.18it/s] 69%|██████▉   | 210/303 [00:28<00:11,  8.19it/s] 70%|██████▉   | 211/303 [00:28<00:11,  8.19it/s] 70%|██████▉   | 212/303 [00:28<00:11,  8.19it/s] 70%|███████   | 213/303 [00:29<00:10,  8.18it/s] 71%|███████   | 214/303 [00:29<00:10,  8.20it/s] 71%|███████   | 215/303 [00:29<00:10,  8.20it/s] 71%|███████▏  | 216/303 [00:29<00:10,  8.20it/s] 72%|███████▏  | 217/303 [00:29<00:10,  8.21it/s] 72%|███████▏  | 218/303 [00:29<00:10,  8.22it/s] 72%|███████▏  | 219/303 [00:29<00:10,  8.22it/s] 73%|███████▎  | 220/303 [00:29<00:10,  8.22it/s] 73%|███████▎  | 221/303 [00:30<00:09,  8.22it/s] 73%|███████▎  | 222/303 [00:30<00:09,  8.19it/s] 74%|███████▎  | 223/303 [00:30<00:09,  8.20it/s] 74%|███████▍  | 224/303 [00:30<00:09,  8.21it/s] 74%|███████▍  | 225/303 [00:30<00:09,  8.22it/s] 75%|███████▍  | 226/303 [00:30<00:09,  8.21it/s] 75%|███████▍  | 227/303 [00:30<00:09,  8.16it/s] 75%|███████▌  | 228/303 [00:30<00:09,  8.16it/s] 76%|███████▌  | 229/303 [00:31<00:09,  8.18it/s] 76%|███████▌  | 230/303 [00:31<00:08,  8.19it/s] 76%|███████▌  | 231/303 [00:31<00:08,  8.20it/s] 77%|███████▋  | 232/303 [00:31<00:08,  8.21it/s] 77%|███████▋  | 233/303 [00:31<00:08,  8.21it/s] 77%|███████▋  | 234/303 [00:31<00:08,  8.20it/s] 78%|███████▊  | 235/303 [00:31<00:08,  8.17it/s] 78%|███████▊  | 236/303 [00:31<00:08,  8.17it/s] 78%|███████▊  | 237/303 [00:32<00:08,  8.17it/s] 79%|███████▊  | 238/303 [00:32<00:07,  8.17it/s] 79%|███████▉  | 239/303 [00:32<00:07,  8.19it/s] 79%|███████▉  | 240/303 [00:32<00:07,  8.14it/s] 80%|███████▉  | 241/303 [00:32<00:07,  8.16it/s] 80%|███████▉  | 242/303 [00:32<00:07,  8.17it/s] 80%|████████  | 243/303 [00:32<00:07,  8.18it/s] 81%|████████  | 244/303 [00:32<00:07,  8.17it/s] 81%|████████  | 245/303 [00:32<00:07,  8.16it/s] 81%|████████  | 246/303 [00:33<00:06,  8.16it/s] 82%|████████▏ | 247/303 [00:33<00:06,  8.17it/s] 82%|████████▏ | 248/303 [00:33<00:06,  8.17it/s] 82%|████████▏ | 249/303 [00:33<00:06,  8.14it/s] 83%|████████▎ | 250/303 [00:33<00:06,  8.15it/s] 83%|████████▎ | 251/303 [00:33<00:06,  8.16it/s] 83%|████████▎ | 252/303 [00:33<00:06,  8.16it/s] 83%|████████▎ | 253/303 [00:33<00:06,  8.17it/s] 84%|████████▍ | 254/303 [00:34<00:06,  8.16it/s] 84%|████████▍ | 255/303 [00:34<00:05,  8.17it/s] 84%|████████▍ | 256/303 [00:34<00:05,  8.16it/s] 85%|████████▍ | 257/303 [00:34<00:05,  8.16it/s] 85%|████████▌ | 258/303 [00:34<00:05,  8.17it/s] 85%|████████▌ | 259/303 [00:34<00:05,  8.18it/s] 86%|████████▌ | 260/303 [00:34<00:05,  8.18it/s] 86%|████████▌ | 261/303 [00:34<00:05,  8.18it/s] 86%|████████▋ | 262/303 [00:35<00:05,  8.19it/s] 87%|████████▋ | 263/303 [00:35<00:04,  8.20it/s] 87%|████████▋ | 264/303 [00:35<00:04,  8.21it/s] 87%|████████▋ | 265/303 [00:35<00:04,  8.22it/s] 88%|████████▊ | 266/303 [00:35<00:04,  8.22it/s] 88%|████████▊ | 267/303 [00:35<00:04,  8.21it/s] 88%|████████▊ | 268/303 [00:35<00:04,  8.21it/s] 89%|████████▉ | 269/303 [00:35<00:04,  8.20it/s] 89%|████████▉ | 270/303 [00:36<00:04,  8.19it/s] 89%|████████▉ | 271/303 [00:36<00:03,  8.20it/s] 90%|████████▉ | 272/303 [00:36<00:03,  8.21it/s] 90%|█████████ | 273/303 [00:36<00:03,  8.20it/s] 90%|█████████ | 274/303 [00:36<00:03,  8.21it/s] 91%|█████████ | 275/303 [00:36<00:03,  8.20it/s] 91%|█████████ | 276/303 [00:36<00:03,  8.19it/s] 91%|█████████▏| 277/303 [00:36<00:03,  8.20it/s] 92%|█████████▏| 278/303 [00:37<00:03,  8.17it/s] 92%|█████████▏| 279/303 [00:37<00:02,  8.19it/s] 92%|█████████▏| 280/303 [00:37<00:02,  8.19it/s] 93%|█████████▎| 281/303 [00:37<00:02,  8.19it/s] 93%|█████████▎| 282/303 [00:37<00:02,  8.19it/s] 93%|█████████▎| 283/303 [00:37<00:02,  8.20it/s] 94%|█████████▎| 284/303 [00:37<00:02,  8.20it/s] 94%|█████████▍| 285/303 [00:37<00:02,  8.20it/s] 94%|█████████▍| 286/303 [00:37<00:02,  8.20it/s] 95%|█████████▍| 287/303 [00:38<00:01,  8.19it/s] 95%|█████████▌| 288/303 [00:38<00:01,  8.19it/s] 95%|█████████▌| 289/303 [00:38<00:01,  8.20it/s] 96%|█████████▌| 290/303 [00:38<00:01,  8.21it/s] 96%|█████████▌| 291/303 [00:38<00:01,  8.21it/s] 96%|█████████▋| 292/303 [00:38<00:01,  8.21it/s] 97%|█████████▋| 293/303 [00:38<00:01,  8.22it/s] 97%|█████████▋| 294/303 [00:38<00:01,  8.24it/s] 97%|█████████▋| 295/303 [00:39<00:00,  8.24it/s] 98%|█████████▊| 296/303 [00:39<00:00,  8.24it/s] 98%|█████████▊| 297/303 [00:39<00:00,  8.25it/s] 98%|█████████▊| 298/303 [00:39<00:00,  8.25it/s] 99%|█████████▊| 299/303 [00:39<00:00,  8.26it/s] 99%|█████████▉| 300/303 [00:39<00:00,  8.26it/s] 99%|█████████▉| 301/303 [00:39<00:00,  8.26it/s]100%|█████████▉| 302/303 [00:39<00:00,  8.27it/s]100%|██████████| 303/303 [00:40<00:00,  8.26it/s]100%|██████████| 303/303 [00:40<00:00,  7.55it/s]
=> result
* total: 30,300
* correct: 19,848
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 63.2%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 food101 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/food101/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/food101/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_3.pkl
1616 20200 30300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  101
# train_x  1,616
# val      20,200
# test     30,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/303 [00:00<?, ?it/s]  0%|          | 1/303 [00:03<17:12,  3.42s/it]  1%|          | 2/303 [00:03<07:25,  1.48s/it]  1%|          | 3/303 [00:03<04:17,  1.17it/s]  1%|▏         | 4/303 [00:03<02:49,  1.76it/s]  2%|▏         | 5/303 [00:03<02:00,  2.47it/s]  2%|▏         | 6/303 [00:04<01:31,  3.24it/s]  2%|▏         | 7/303 [00:04<01:13,  4.05it/s]  3%|▎         | 8/303 [00:04<01:00,  4.84it/s]  3%|▎         | 9/303 [00:04<00:52,  5.57it/s]  3%|▎         | 10/303 [00:04<00:47,  6.20it/s]  4%|▎         | 11/303 [00:04<00:43,  6.71it/s]  4%|▍         | 12/303 [00:04<00:40,  7.11it/s]  4%|▍         | 13/303 [00:04<00:39,  7.43it/s]  5%|▍         | 14/303 [00:04<00:37,  7.67it/s]  5%|▍         | 15/303 [00:05<00:36,  7.84it/s]  5%|▌         | 16/303 [00:05<00:36,  7.97it/s]  6%|▌         | 17/303 [00:05<00:35,  8.06it/s]  6%|▌         | 18/303 [00:05<00:35,  8.11it/s]  6%|▋         | 19/303 [00:05<00:34,  8.16it/s]  7%|▋         | 20/303 [00:05<00:34,  8.19it/s]  7%|▋         | 21/303 [00:05<00:34,  8.19it/s]  7%|▋         | 22/303 [00:05<00:34,  8.22it/s]  8%|▊         | 23/303 [00:06<00:34,  8.22it/s]  8%|▊         | 24/303 [00:06<00:33,  8.22it/s]  8%|▊         | 25/303 [00:06<00:33,  8.22it/s]  9%|▊         | 26/303 [00:06<00:33,  8.21it/s]  9%|▉         | 27/303 [00:06<00:33,  8.22it/s]  9%|▉         | 28/303 [00:06<00:33,  8.22it/s] 10%|▉         | 29/303 [00:06<00:33,  8.22it/s] 10%|▉         | 30/303 [00:06<00:33,  8.22it/s] 10%|█         | 31/303 [00:07<00:33,  8.12it/s] 11%|█         | 32/303 [00:07<00:33,  8.17it/s] 11%|█         | 33/303 [00:07<00:32,  8.19it/s] 11%|█         | 34/303 [00:07<00:32,  8.19it/s] 12%|█▏        | 35/303 [00:07<00:32,  8.20it/s] 12%|█▏        | 36/303 [00:07<00:32,  8.22it/s] 12%|█▏        | 37/303 [00:07<00:32,  8.23it/s] 13%|█▎        | 38/303 [00:07<00:32,  8.23it/s] 13%|█▎        | 39/303 [00:08<00:32,  8.22it/s] 13%|█▎        | 40/303 [00:08<00:31,  8.24it/s] 14%|█▎        | 41/303 [00:08<00:31,  8.25it/s] 14%|█▍        | 42/303 [00:08<00:31,  8.26it/s] 14%|█▍        | 43/303 [00:08<00:31,  8.28it/s] 15%|█▍        | 44/303 [00:08<00:31,  8.27it/s] 15%|█▍        | 45/303 [00:08<00:31,  8.28it/s] 15%|█▌        | 46/303 [00:08<00:31,  8.24it/s] 16%|█▌        | 47/303 [00:08<00:31,  8.26it/s] 16%|█▌        | 48/303 [00:09<00:30,  8.26it/s] 16%|█▌        | 49/303 [00:09<00:30,  8.26it/s] 17%|█▋        | 50/303 [00:09<00:30,  8.24it/s] 17%|█▋        | 51/303 [00:09<00:30,  8.21it/s] 17%|█▋        | 52/303 [00:09<00:30,  8.18it/s] 17%|█▋        | 53/303 [00:09<00:30,  8.19it/s] 18%|█▊        | 54/303 [00:09<00:30,  8.20it/s] 18%|█▊        | 55/303 [00:09<00:30,  8.19it/s] 18%|█▊        | 56/303 [00:10<00:30,  8.20it/s] 19%|█▉        | 57/303 [00:10<00:29,  8.22it/s] 19%|█▉        | 58/303 [00:10<00:29,  8.22it/s] 19%|█▉        | 59/303 [00:10<00:29,  8.22it/s] 20%|█▉        | 60/303 [00:10<00:29,  8.19it/s] 20%|██        | 61/303 [00:10<00:29,  8.21it/s] 20%|██        | 62/303 [00:10<00:29,  8.21it/s] 21%|██        | 63/303 [00:10<00:29,  8.22it/s] 21%|██        | 64/303 [00:11<00:29,  8.23it/s] 21%|██▏       | 65/303 [00:11<00:28,  8.23it/s] 22%|██▏       | 66/303 [00:11<00:28,  8.24it/s] 22%|██▏       | 67/303 [00:11<00:28,  8.23it/s] 22%|██▏       | 68/303 [00:11<00:28,  8.24it/s] 23%|██▎       | 69/303 [00:11<00:28,  8.24it/s] 23%|██▎       | 70/303 [00:11<00:28,  8.18it/s] 23%|██▎       | 71/303 [00:11<00:28,  8.20it/s] 24%|██▍       | 72/303 [00:12<00:28,  8.19it/s] 24%|██▍       | 73/303 [00:12<00:28,  8.21it/s] 24%|██▍       | 74/303 [00:12<00:27,  8.22it/s] 25%|██▍       | 75/303 [00:12<00:27,  8.21it/s] 25%|██▌       | 76/303 [00:12<00:27,  8.22it/s] 25%|██▌       | 77/303 [00:12<00:27,  8.23it/s] 26%|██▌       | 78/303 [00:12<00:27,  8.21it/s] 26%|██▌       | 79/303 [00:12<00:27,  8.23it/s] 26%|██▋       | 80/303 [00:13<00:27,  8.24it/s] 27%|██▋       | 81/303 [00:13<00:27,  8.21it/s] 27%|██▋       | 82/303 [00:13<00:26,  8.20it/s] 27%|██▋       | 83/303 [00:13<00:26,  8.22it/s] 28%|██▊       | 84/303 [00:13<00:26,  8.22it/s] 28%|██▊       | 85/303 [00:13<00:26,  8.23it/s] 28%|██▊       | 86/303 [00:13<00:26,  8.22it/s] 29%|██▊       | 87/303 [00:13<00:26,  8.22it/s] 29%|██▉       | 88/303 [00:13<00:26,  8.23it/s] 29%|██▉       | 89/303 [00:14<00:25,  8.23it/s] 30%|██▉       | 90/303 [00:14<00:25,  8.23it/s] 30%|███       | 91/303 [00:14<00:25,  8.25it/s] 30%|███       | 92/303 [00:14<00:25,  8.25it/s] 31%|███       | 93/303 [00:14<00:25,  8.24it/s] 31%|███       | 94/303 [00:14<00:25,  8.21it/s] 31%|███▏      | 95/303 [00:14<00:25,  8.21it/s] 32%|███▏      | 96/303 [00:14<00:25,  8.23it/s] 32%|███▏      | 97/303 [00:15<00:25,  8.22it/s] 32%|███▏      | 98/303 [00:15<00:24,  8.21it/s] 33%|███▎      | 99/303 [00:15<00:24,  8.20it/s] 33%|███▎      | 100/303 [00:15<00:24,  8.22it/s] 33%|███▎      | 101/303 [00:15<00:24,  8.22it/s] 34%|███▎      | 102/303 [00:15<00:24,  8.22it/s] 34%|███▍      | 103/303 [00:15<00:24,  8.22it/s] 34%|███▍      | 104/303 [00:15<00:24,  8.22it/s] 35%|███▍      | 105/303 [00:16<00:24,  8.22it/s] 35%|███▍      | 106/303 [00:16<00:23,  8.21it/s] 35%|███▌      | 107/303 [00:16<00:23,  8.21it/s] 36%|███▌      | 108/303 [00:16<00:23,  8.16it/s] 36%|███▌      | 109/303 [00:16<00:23,  8.19it/s] 36%|███▋      | 110/303 [00:16<00:23,  8.20it/s] 37%|███▋      | 111/303 [00:16<00:23,  8.19it/s] 37%|███▋      | 112/303 [00:16<00:23,  8.21it/s] 37%|███▋      | 113/303 [00:17<00:23,  8.23it/s] 38%|███▊      | 114/303 [00:17<00:22,  8.23it/s] 38%|███▊      | 115/303 [00:17<00:22,  8.23it/s] 38%|███▊      | 116/303 [00:17<00:22,  8.23it/s] 39%|███▊      | 117/303 [00:17<00:22,  8.24it/s] 39%|███▉      | 118/303 [00:17<00:22,  8.23it/s] 39%|███▉      | 119/303 [00:17<00:22,  8.22it/s] 40%|███▉      | 120/303 [00:17<00:22,  8.23it/s] 40%|███▉      | 121/303 [00:17<00:22,  8.23it/s] 40%|████      | 122/303 [00:18<00:22,  8.22it/s] 41%|████      | 123/303 [00:18<00:21,  8.21it/s] 41%|████      | 124/303 [00:18<00:21,  8.22it/s] 41%|████▏     | 125/303 [00:18<00:21,  8.23it/s] 42%|████▏     | 126/303 [00:18<00:21,  8.21it/s] 42%|████▏     | 127/303 [00:18<00:21,  8.19it/s] 42%|████▏     | 128/303 [00:18<00:21,  8.20it/s] 43%|████▎     | 129/303 [00:18<00:21,  8.21it/s] 43%|████▎     | 130/303 [00:19<00:21,  8.20it/s] 43%|████▎     | 131/303 [00:19<00:20,  8.21it/s] 44%|████▎     | 132/303 [00:19<00:20,  8.22it/s] 44%|████▍     | 133/303 [00:19<00:20,  8.23it/s] 44%|████▍     | 134/303 [00:19<00:20,  8.23it/s] 45%|████▍     | 135/303 [00:19<00:20,  8.21it/s] 45%|████▍     | 136/303 [00:19<00:20,  8.22it/s] 45%|████▌     | 137/303 [00:19<00:20,  8.22it/s] 46%|████▌     | 138/303 [00:20<00:20,  8.21it/s] 46%|████▌     | 139/303 [00:20<00:20,  8.08it/s] 46%|████▌     | 140/303 [00:20<00:20,  8.12it/s] 47%|████▋     | 141/303 [00:20<00:19,  8.12it/s] 47%|████▋     | 142/303 [00:20<00:19,  8.15it/s] 47%|████▋     | 143/303 [00:20<00:19,  8.15it/s] 48%|████▊     | 144/303 [00:20<00:19,  8.17it/s] 48%|████▊     | 145/303 [00:20<00:19,  8.18it/s] 48%|████▊     | 146/303 [00:21<00:19,  8.18it/s] 49%|████▊     | 147/303 [00:21<00:19,  8.19it/s] 49%|████▉     | 148/303 [00:21<00:18,  8.16it/s] 49%|████▉     | 149/303 [00:21<00:18,  8.18it/s] 50%|████▉     | 150/303 [00:21<00:18,  8.18it/s] 50%|████▉     | 151/303 [00:21<00:18,  8.19it/s] 50%|█████     | 152/303 [00:21<00:18,  8.21it/s] 50%|█████     | 153/303 [00:21<00:18,  8.22it/s] 51%|█████     | 154/303 [00:22<00:18,  8.22it/s] 51%|█████     | 155/303 [00:22<00:18,  8.22it/s] 51%|█████▏    | 156/303 [00:22<00:17,  8.21it/s] 52%|█████▏    | 157/303 [00:22<00:17,  8.20it/s] 52%|█████▏    | 158/303 [00:22<00:17,  8.21it/s] 52%|█████▏    | 159/303 [00:22<00:17,  8.21it/s] 53%|█████▎    | 160/303 [00:22<00:17,  8.22it/s] 53%|█████▎    | 161/303 [00:22<00:17,  8.21it/s] 53%|█████▎    | 162/303 [00:22<00:17,  8.22it/s] 54%|█████▍    | 163/303 [00:23<00:17,  8.22it/s] 54%|█████▍    | 164/303 [00:23<00:16,  8.20it/s] 54%|█████▍    | 165/303 [00:23<00:16,  8.19it/s] 55%|█████▍    | 166/303 [00:23<00:16,  8.20it/s] 55%|█████▌    | 167/303 [00:23<00:16,  8.20it/s] 55%|█████▌    | 168/303 [00:23<00:16,  8.14it/s] 56%|█████▌    | 169/303 [00:23<00:16,  8.17it/s] 56%|█████▌    | 170/303 [00:23<00:16,  8.17it/s] 56%|█████▋    | 171/303 [00:24<00:16,  8.16it/s] 57%|█████▋    | 172/303 [00:24<00:16,  8.17it/s] 57%|█████▋    | 173/303 [00:24<00:15,  8.17it/s] 57%|█████▋    | 174/303 [00:24<00:15,  8.15it/s] 58%|█████▊    | 175/303 [00:24<00:15,  8.16it/s] 58%|█████▊    | 176/303 [00:24<00:15,  8.16it/s] 58%|█████▊    | 177/303 [00:24<00:15,  8.18it/s] 59%|█████▊    | 178/303 [00:24<00:15,  8.18it/s] 59%|█████▉    | 179/303 [00:25<00:15,  8.17it/s] 59%|█████▉    | 180/303 [00:25<00:15,  8.18it/s] 60%|█████▉    | 181/303 [00:25<00:14,  8.18it/s] 60%|██████    | 182/303 [00:25<00:14,  8.17it/s] 60%|██████    | 183/303 [00:25<00:14,  8.17it/s] 61%|██████    | 184/303 [00:25<00:14,  8.15it/s] 61%|██████    | 185/303 [00:25<00:14,  8.15it/s] 61%|██████▏   | 186/303 [00:25<00:14,  8.17it/s] 62%|██████▏   | 187/303 [00:26<00:14,  8.18it/s] 62%|██████▏   | 188/303 [00:26<00:14,  8.20it/s] 62%|██████▏   | 189/303 [00:26<00:13,  8.21it/s] 63%|██████▎   | 190/303 [00:26<00:13,  8.22it/s] 63%|██████▎   | 191/303 [00:26<00:13,  8.23it/s] 63%|██████▎   | 192/303 [00:26<00:13,  8.22it/s] 64%|██████▎   | 193/303 [00:26<00:13,  8.21it/s] 64%|██████▍   | 194/303 [00:26<00:13,  8.21it/s] 64%|██████▍   | 195/303 [00:27<00:13,  8.20it/s] 65%|██████▍   | 196/303 [00:27<00:13,  8.20it/s] 65%|██████▌   | 197/303 [00:27<00:12,  8.22it/s] 65%|██████▌   | 198/303 [00:27<00:12,  8.22it/s] 66%|██████▌   | 199/303 [00:27<00:12,  8.23it/s] 66%|██████▌   | 200/303 [00:27<00:12,  8.22it/s] 66%|██████▋   | 201/303 [00:27<00:12,  8.23it/s] 67%|██████▋   | 202/303 [00:27<00:12,  8.23it/s] 67%|██████▋   | 203/303 [00:28<00:12,  8.22it/s] 67%|██████▋   | 204/303 [00:28<00:12,  8.22it/s] 68%|██████▊   | 205/303 [00:28<00:12,  8.15it/s] 68%|██████▊   | 206/303 [00:28<00:11,  8.18it/s] 68%|██████▊   | 207/303 [00:28<00:11,  8.18it/s] 69%|██████▊   | 208/303 [00:28<00:11,  8.19it/s] 69%|██████▉   | 209/303 [00:28<00:11,  8.20it/s] 69%|██████▉   | 210/303 [00:28<00:11,  8.20it/s] 70%|██████▉   | 211/303 [00:28<00:11,  8.21it/s] 70%|██████▉   | 212/303 [00:29<00:11,  8.21it/s] 70%|███████   | 213/303 [00:29<00:10,  8.21it/s] 71%|███████   | 214/303 [00:29<00:10,  8.20it/s] 71%|███████   | 215/303 [00:29<00:10,  8.20it/s] 71%|███████▏  | 216/303 [00:29<00:10,  8.21it/s] 72%|███████▏  | 217/303 [00:29<00:10,  8.22it/s] 72%|███████▏  | 218/303 [00:29<00:10,  8.21it/s] 72%|███████▏  | 219/303 [00:29<00:10,  8.22it/s] 73%|███████▎  | 220/303 [00:30<00:10,  8.22it/s] 73%|███████▎  | 221/303 [00:30<00:09,  8.21it/s] 73%|███████▎  | 222/303 [00:30<00:09,  8.19it/s] 74%|███████▎  | 223/303 [00:30<00:09,  8.20it/s] 74%|███████▍  | 224/303 [00:30<00:09,  8.20it/s] 74%|███████▍  | 225/303 [00:30<00:09,  8.19it/s] 75%|███████▍  | 226/303 [00:30<00:09,  8.18it/s] 75%|███████▍  | 227/303 [00:30<00:09,  8.18it/s] 75%|███████▌  | 228/303 [00:31<00:09,  8.19it/s] 76%|███████▌  | 229/303 [00:31<00:09,  8.19it/s] 76%|███████▌  | 230/303 [00:31<00:08,  8.20it/s] 76%|███████▌  | 231/303 [00:31<00:08,  8.21it/s] 77%|███████▋  | 232/303 [00:31<00:08,  8.20it/s] 77%|███████▋  | 233/303 [00:31<00:08,  8.16it/s] 77%|███████▋  | 234/303 [00:31<00:08,  8.17it/s] 78%|███████▊  | 235/303 [00:31<00:08,  8.18it/s] 78%|███████▊  | 236/303 [00:32<00:08,  8.19it/s] 78%|███████▊  | 237/303 [00:32<00:08,  8.18it/s] 79%|███████▊  | 238/303 [00:32<00:07,  8.18it/s] 79%|███████▉  | 239/303 [00:32<00:07,  8.19it/s] 79%|███████▉  | 240/303 [00:32<00:07,  8.20it/s] 80%|███████▉  | 241/303 [00:32<00:07,  8.20it/s] 80%|███████▉  | 242/303 [00:32<00:07,  8.20it/s] 80%|████████  | 243/303 [00:32<00:07,  8.19it/s] 81%|████████  | 244/303 [00:33<00:07,  8.19it/s] 81%|████████  | 245/303 [00:33<00:07,  8.20it/s] 81%|████████  | 246/303 [00:33<00:06,  8.18it/s] 82%|████████▏ | 247/303 [00:33<00:06,  8.17it/s] 82%|████████▏ | 248/303 [00:33<00:06,  8.17it/s] 82%|████████▏ | 249/303 [00:33<00:06,  8.18it/s] 83%|████████▎ | 250/303 [00:33<00:06,  8.17it/s] 83%|████████▎ | 251/303 [00:33<00:06,  8.18it/s] 83%|████████▎ | 252/303 [00:33<00:06,  8.18it/s] 83%|████████▎ | 253/303 [00:34<00:06,  8.18it/s] 84%|████████▍ | 254/303 [00:34<00:05,  8.18it/s] 84%|████████▍ | 255/303 [00:34<00:05,  8.17it/s] 84%|████████▍ | 256/303 [00:34<00:05,  8.18it/s] 85%|████████▍ | 257/303 [00:34<00:05,  8.18it/s] 85%|████████▌ | 258/303 [00:34<00:05,  8.16it/s] 85%|████████▌ | 259/303 [00:34<00:05,  8.14it/s] 86%|████████▌ | 260/303 [00:34<00:05,  8.15it/s] 86%|████████▌ | 261/303 [00:35<00:05,  8.16it/s] 86%|████████▋ | 262/303 [00:35<00:05,  8.17it/s] 87%|████████▋ | 263/303 [00:35<00:04,  8.18it/s] 87%|████████▋ | 264/303 [00:35<00:04,  8.19it/s] 87%|████████▋ | 265/303 [00:35<00:04,  8.19it/s] 88%|████████▊ | 266/303 [00:35<00:04,  8.19it/s] 88%|████████▊ | 267/303 [00:35<00:04,  8.18it/s] 88%|████████▊ | 268/303 [00:35<00:04,  8.18it/s] 89%|████████▉ | 269/303 [00:36<00:04,  8.18it/s] 89%|████████▉ | 270/303 [00:36<00:04,  8.18it/s] 89%|████████▉ | 271/303 [00:36<00:03,  8.20it/s] 90%|████████▉ | 272/303 [00:36<00:03,  8.19it/s] 90%|█████████ | 273/303 [00:36<00:03,  8.20it/s] 90%|█████████ | 274/303 [00:36<00:03,  8.19it/s] 91%|█████████ | 275/303 [00:36<00:03,  8.18it/s] 91%|█████████ | 276/303 [00:36<00:03,  8.18it/s] 91%|█████████▏| 277/303 [00:37<00:03,  8.18it/s] 92%|█████████▏| 278/303 [00:37<00:03,  8.19it/s] 92%|█████████▏| 279/303 [00:37<00:02,  8.19it/s] 92%|█████████▏| 280/303 [00:37<00:02,  8.19it/s] 93%|█████████▎| 281/303 [00:37<00:02,  8.20it/s] 93%|█████████▎| 282/303 [00:37<00:02,  8.19it/s] 93%|█████████▎| 283/303 [00:37<00:02,  8.19it/s] 94%|█████████▎| 284/303 [00:37<00:02,  8.19it/s] 94%|█████████▍| 285/303 [00:38<00:02,  8.19it/s] 94%|█████████▍| 286/303 [00:38<00:02,  8.19it/s] 95%|█████████▍| 287/303 [00:38<00:01,  8.19it/s] 95%|█████████▌| 288/303 [00:38<00:01,  8.19it/s] 95%|█████████▌| 289/303 [00:38<00:01,  8.20it/s] 96%|█████████▌| 290/303 [00:38<00:01,  8.20it/s] 96%|█████████▌| 291/303 [00:38<00:01,  8.21it/s] 96%|█████████▋| 292/303 [00:38<00:01,  8.21it/s] 97%|█████████▋| 293/303 [00:38<00:01,  8.21it/s] 97%|█████████▋| 294/303 [00:39<00:01,  8.22it/s] 97%|█████████▋| 295/303 [00:39<00:00,  8.23it/s] 98%|█████████▊| 296/303 [00:39<00:00,  8.24it/s] 98%|█████████▊| 297/303 [00:39<00:00,  8.25it/s] 98%|█████████▊| 298/303 [00:39<00:00,  8.25it/s] 99%|█████████▊| 299/303 [00:39<00:00,  8.19it/s] 99%|█████████▉| 300/303 [00:39<00:00,  8.21it/s] 99%|█████████▉| 301/303 [00:39<00:00,  8.23it/s]100%|█████████▉| 302/303 [00:40<00:00,  8.23it/s]100%|██████████| 303/303 [00:40<00:00,  8.23it/s]100%|██████████| 303/303 [00:40<00:00,  7.52it/s]
=> result
* total: 30,300
* correct: 19,948
* accuracy: 65.8%
* error: 34.2%
* macro_f1: 63.0%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 ucf101 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/ucf101/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/ucf101/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_1.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:03<01:54,  3.10s/it]  5%|▌         | 2/38 [00:03<00:48,  1.35s/it]  8%|▊         | 3/38 [00:03<00:27,  1.27it/s] 11%|█         | 4/38 [00:03<00:17,  1.91it/s] 13%|█▎        | 5/38 [00:03<00:12,  2.64it/s] 16%|█▌        | 6/38 [00:03<00:09,  3.44it/s] 18%|█▊        | 7/38 [00:03<00:07,  4.25it/s] 21%|██        | 8/38 [00:03<00:05,  5.03it/s] 24%|██▎       | 9/38 [00:04<00:05,  5.72it/s] 26%|██▋       | 10/38 [00:04<00:04,  6.31it/s] 29%|██▉       | 11/38 [00:04<00:03,  6.80it/s] 32%|███▏      | 12/38 [00:04<00:03,  7.18it/s] 34%|███▍      | 13/38 [00:04<00:03,  7.47it/s] 37%|███▋      | 14/38 [00:04<00:03,  7.68it/s] 39%|███▉      | 15/38 [00:04<00:02,  7.84it/s] 42%|████▏     | 16/38 [00:04<00:02,  7.96it/s] 45%|████▍     | 17/38 [00:05<00:02,  8.05it/s] 47%|████▋     | 18/38 [00:05<00:02,  8.10it/s] 50%|█████     | 19/38 [00:05<00:02,  8.14it/s] 53%|█████▎    | 20/38 [00:05<00:02,  8.18it/s] 55%|█████▌    | 21/38 [00:05<00:02,  8.20it/s] 58%|█████▊    | 22/38 [00:05<00:01,  8.22it/s] 61%|██████    | 23/38 [00:05<00:01,  8.22it/s] 63%|██████▎   | 24/38 [00:05<00:01,  8.24it/s] 66%|██████▌   | 25/38 [00:06<00:01,  8.25it/s] 68%|██████▊   | 26/38 [00:06<00:01,  8.26it/s] 71%|███████   | 27/38 [00:06<00:01,  8.28it/s] 74%|███████▎  | 28/38 [00:06<00:01,  8.30it/s] 76%|███████▋  | 29/38 [00:06<00:01,  8.31it/s] 79%|███████▉  | 30/38 [00:06<00:00,  8.30it/s] 82%|████████▏ | 31/38 [00:06<00:00,  8.30it/s] 84%|████████▍ | 32/38 [00:06<00:00,  8.30it/s] 87%|████████▋ | 33/38 [00:06<00:00,  8.30it/s] 89%|████████▉ | 34/38 [00:07<00:00,  8.30it/s] 92%|█████████▏| 35/38 [00:07<00:00,  8.22it/s] 95%|█████████▍| 36/38 [00:07<00:00,  8.25it/s] 97%|█████████▋| 37/38 [00:07<00:00,  8.27it/s]100%|██████████| 38/38 [00:07<00:00,  8.64it/s]100%|██████████| 38/38 [00:07<00:00,  4.98it/s]
=> result
* total: 3,783
* correct: 3,157
* accuracy: 83.5%
* error: 16.5%
* macro_f1: 82.6%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 ucf101 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/ucf101/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/ucf101/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_2.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:03<01:52,  3.04s/it]  5%|▌         | 2/38 [00:03<00:47,  1.32s/it]  8%|▊         | 3/38 [00:03<00:27,  1.29it/s] 11%|█         | 4/38 [00:03<00:17,  1.94it/s] 13%|█▎        | 5/38 [00:03<00:12,  2.68it/s] 16%|█▌        | 6/38 [00:03<00:09,  3.48it/s] 18%|█▊        | 7/38 [00:03<00:07,  4.30it/s] 21%|██        | 8/38 [00:03<00:05,  5.08it/s] 24%|██▎       | 9/38 [00:04<00:05,  5.78it/s] 26%|██▋       | 10/38 [00:04<00:04,  6.37it/s] 29%|██▉       | 11/38 [00:04<00:03,  6.86it/s] 32%|███▏      | 12/38 [00:04<00:03,  7.24it/s] 34%|███▍      | 13/38 [00:04<00:03,  7.53it/s] 37%|███▋      | 14/38 [00:04<00:03,  7.75it/s] 39%|███▉      | 15/38 [00:04<00:02,  7.91it/s] 42%|████▏     | 16/38 [00:04<00:02,  8.02it/s] 45%|████▍     | 17/38 [00:04<00:02,  8.10it/s] 47%|████▋     | 18/38 [00:05<00:02,  8.16it/s] 50%|█████     | 19/38 [00:05<00:02,  8.21it/s] 53%|█████▎    | 20/38 [00:05<00:02,  8.23it/s] 55%|█████▌    | 21/38 [00:05<00:02,  8.25it/s] 58%|█████▊    | 22/38 [00:05<00:01,  8.26it/s] 61%|██████    | 23/38 [00:05<00:01,  8.26it/s] 63%|██████▎   | 24/38 [00:05<00:01,  8.28it/s] 66%|██████▌   | 25/38 [00:05<00:01,  8.29it/s] 68%|██████▊   | 26/38 [00:06<00:01,  8.31it/s] 71%|███████   | 27/38 [00:06<00:01,  8.32it/s] 74%|███████▎  | 28/38 [00:06<00:01,  8.32it/s] 76%|███████▋  | 29/38 [00:06<00:01,  8.33it/s] 79%|███████▉  | 30/38 [00:06<00:00,  8.34it/s] 82%|████████▏ | 31/38 [00:06<00:00,  8.33it/s] 84%|████████▍ | 32/38 [00:06<00:00,  8.33it/s] 87%|████████▋ | 33/38 [00:06<00:00,  8.33it/s] 89%|████████▉ | 34/38 [00:07<00:00,  8.33it/s] 92%|█████████▏| 35/38 [00:07<00:00,  8.33it/s] 95%|█████████▍| 36/38 [00:07<00:00,  8.33it/s] 97%|█████████▋| 37/38 [00:07<00:00,  8.33it/s]100%|██████████| 38/38 [00:07<00:00,  8.69it/s]100%|██████████| 38/38 [00:07<00:00,  5.03it/s]
=> result
* total: 3,783
* correct: 3,119
* accuracy: 82.4%
* error: 17.6%
* macro_f1: 81.5%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 ucf101 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/ucf101/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/ucf101/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_3.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:02<01:50,  2.98s/it]  5%|▌         | 2/38 [00:03<00:46,  1.30s/it]  8%|▊         | 3/38 [00:03<00:26,  1.31it/s] 11%|█         | 4/38 [00:03<00:17,  1.97it/s] 13%|█▎        | 5/38 [00:03<00:12,  2.72it/s] 16%|█▌        | 6/38 [00:03<00:09,  3.53it/s] 18%|█▊        | 7/38 [00:03<00:07,  4.34it/s] 21%|██        | 8/38 [00:03<00:05,  5.11it/s] 24%|██▎       | 9/38 [00:03<00:04,  5.82it/s] 26%|██▋       | 10/38 [00:04<00:04,  6.41it/s] 29%|██▉       | 11/38 [00:04<00:03,  6.89it/s] 32%|███▏      | 12/38 [00:04<00:03,  7.26it/s] 34%|███▍      | 13/38 [00:04<00:03,  7.54it/s] 37%|███▋      | 14/38 [00:04<00:03,  7.76it/s] 39%|███▉      | 15/38 [00:04<00:02,  7.91it/s] 42%|████▏     | 16/38 [00:04<00:02,  8.01it/s] 45%|████▍     | 17/38 [00:04<00:02,  8.10it/s] 47%|████▋     | 18/38 [00:05<00:02,  8.17it/s] 50%|█████     | 19/38 [00:05<00:02,  8.21it/s] 53%|█████▎    | 20/38 [00:05<00:02,  8.23it/s] 55%|█████▌    | 21/38 [00:05<00:02,  8.24it/s] 58%|█████▊    | 22/38 [00:05<00:01,  8.22it/s] 61%|██████    | 23/38 [00:05<00:01,  8.24it/s] 63%|██████▎   | 24/38 [00:05<00:01,  8.27it/s] 66%|██████▌   | 25/38 [00:05<00:01,  8.29it/s] 68%|██████▊   | 26/38 [00:05<00:01,  8.31it/s] 71%|███████   | 27/38 [00:06<00:01,  8.32it/s] 74%|███████▎  | 28/38 [00:06<00:01,  8.33it/s] 76%|███████▋  | 29/38 [00:06<00:01,  8.34it/s] 79%|███████▉  | 30/38 [00:06<00:00,  8.34it/s] 82%|████████▏ | 31/38 [00:06<00:00,  8.34it/s] 84%|████████▍ | 32/38 [00:06<00:00,  8.34it/s] 87%|████████▋ | 33/38 [00:06<00:00,  8.35it/s] 89%|████████▉ | 34/38 [00:06<00:00,  8.35it/s] 92%|█████████▏| 35/38 [00:07<00:00,  8.35it/s] 95%|█████████▍| 36/38 [00:07<00:00,  8.36it/s] 97%|█████████▋| 37/38 [00:07<00:00,  8.36it/s]100%|██████████| 38/38 [00:07<00:00,  8.72it/s]100%|██████████| 38/38 [00:07<00:00,  5.08it/s]
=> result
* total: 3,783
* correct: 3,073
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 80.5%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 sun397 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/sun397/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/sun397/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_1.pkl
6352 3970 19850
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  397
# train_x  6,352
# val      3,970
# test     19,850
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/199 [00:00<?, ?it/s]  1%|          | 1/199 [00:06<22:07,  6.70s/it]  1%|          | 2/199 [00:06<09:24,  2.87s/it]  2%|▏         | 3/199 [00:07<05:21,  1.64s/it]  2%|▏         | 4/199 [00:07<03:27,  1.06s/it]  3%|▎         | 5/199 [00:07<02:24,  1.35it/s]  3%|▎         | 6/199 [00:07<01:46,  1.82it/s]  4%|▎         | 7/199 [00:07<01:22,  2.33it/s]  4%|▍         | 8/199 [00:07<01:06,  2.87it/s]  5%|▍         | 9/199 [00:08<01:42,  1.85it/s]  5%|▌         | 10/199 [00:09<01:27,  2.17it/s]  6%|▌         | 11/199 [00:11<02:51,  1.10it/s]  6%|▌         | 12/199 [00:11<02:08,  1.45it/s]  7%|▋         | 13/199 [00:11<01:39,  1.87it/s]  7%|▋         | 14/199 [00:11<01:19,  2.34it/s]  8%|▊         | 15/199 [00:11<01:04,  2.84it/s]  8%|▊         | 16/199 [00:12<00:54,  3.33it/s]  9%|▊         | 17/199 [00:12<00:47,  3.79it/s]  9%|▉         | 18/199 [00:12<00:43,  4.19it/s] 10%|▉         | 19/199 [00:13<01:34,  1.90it/s] 10%|█         | 20/199 [00:13<01:15,  2.37it/s] 11%|█         | 21/199 [00:13<01:02,  2.87it/s] 11%|█         | 22/199 [00:14<00:52,  3.36it/s] 12%|█▏        | 23/199 [00:14<00:46,  3.82it/s] 12%|█▏        | 24/199 [00:14<00:41,  4.22it/s] 13%|█▎        | 25/199 [00:14<00:38,  4.55it/s] 13%|█▎        | 26/199 [00:14<00:35,  4.82it/s] 14%|█▎        | 27/199 [00:17<02:22,  1.21it/s] 14%|█▍        | 28/199 [00:17<01:48,  1.58it/s] 15%|█▍        | 29/199 [00:17<01:24,  2.02it/s] 15%|█▌        | 30/199 [00:17<01:07,  2.50it/s] 16%|█▌        | 31/199 [00:17<00:56,  3.00it/s] 16%|█▌        | 32/199 [00:17<00:47,  3.49it/s] 17%|█▋        | 33/199 [00:18<00:42,  3.93it/s] 17%|█▋        | 34/199 [00:18<00:38,  4.30it/s] 18%|█▊        | 35/199 [00:19<01:31,  1.79it/s] 18%|█▊        | 36/199 [00:19<01:12,  2.25it/s] 19%|█▊        | 37/199 [00:20<00:59,  2.74it/s] 19%|█▉        | 38/199 [00:20<00:49,  3.23it/s] 20%|█▉        | 39/199 [00:20<00:43,  3.71it/s] 20%|██        | 40/199 [00:20<00:38,  4.13it/s] 21%|██        | 41/199 [00:20<00:35,  4.48it/s] 21%|██        | 42/199 [00:20<00:32,  4.77it/s] 22%|██▏       | 43/199 [00:23<02:10,  1.20it/s] 22%|██▏       | 44/199 [00:23<01:39,  1.56it/s] 23%|██▎       | 45/199 [00:23<01:17,  1.99it/s] 23%|██▎       | 46/199 [00:23<01:01,  2.47it/s] 24%|██▎       | 47/199 [00:23<00:51,  2.97it/s] 24%|██▍       | 48/199 [00:24<00:43,  3.46it/s] 25%|██▍       | 49/199 [00:24<00:38,  3.88it/s] 25%|██▌       | 50/199 [00:24<00:34,  4.28it/s] 26%|██▌       | 51/199 [00:26<02:08,  1.15it/s] 26%|██▌       | 52/199 [00:27<01:37,  1.51it/s] 27%|██▋       | 53/199 [00:27<01:15,  1.93it/s] 27%|██▋       | 54/199 [00:27<01:00,  2.41it/s] 28%|██▊       | 55/199 [00:27<00:49,  2.91it/s] 28%|██▊       | 56/199 [00:27<00:42,  3.40it/s] 29%|██▊       | 57/199 [00:27<00:36,  3.85it/s] 29%|██▉       | 58/199 [00:28<00:33,  4.25it/s] 30%|██▉       | 59/199 [00:28<00:58,  2.40it/s] 30%|███       | 60/199 [00:29<00:59,  2.34it/s] 31%|███       | 61/199 [00:29<00:48,  2.84it/s] 31%|███       | 62/199 [00:29<00:41,  3.33it/s] 32%|███▏      | 63/199 [00:29<00:35,  3.78it/s] 32%|███▏      | 64/199 [00:30<00:32,  4.18it/s] 33%|███▎      | 65/199 [00:30<00:29,  4.51it/s] 33%|███▎      | 66/199 [00:30<00:27,  4.78it/s] 34%|███▎      | 67/199 [00:31<00:56,  2.33it/s] 34%|███▍      | 68/199 [00:33<01:48,  1.21it/s] 35%|███▍      | 69/199 [00:33<01:22,  1.58it/s] 35%|███▌      | 70/199 [00:33<01:03,  2.02it/s] 36%|███▌      | 71/199 [00:33<00:51,  2.49it/s] 36%|███▌      | 72/199 [00:33<00:42,  2.99it/s] 37%|███▋      | 73/199 [00:34<00:36,  3.47it/s] 37%|███▋      | 74/199 [00:34<00:31,  3.92it/s] 38%|███▊      | 75/199 [00:35<01:17,  1.59it/s] 38%|███▊      | 76/199 [00:35<01:00,  2.02it/s] 39%|███▊      | 77/199 [00:36<00:48,  2.50it/s] 39%|███▉      | 78/199 [00:36<00:40,  3.00it/s] 40%|███▉      | 79/199 [00:36<00:34,  3.48it/s] 40%|████      | 80/199 [00:36<00:30,  3.93it/s] 41%|████      | 81/199 [00:36<00:27,  4.30it/s] 41%|████      | 82/199 [00:37<00:28,  4.13it/s] 42%|████▏     | 83/199 [00:39<01:47,  1.08it/s] 42%|████▏     | 84/199 [00:39<01:20,  1.43it/s] 43%|████▎     | 85/199 [00:39<01:02,  1.84it/s] 43%|████▎     | 86/199 [00:40<00:49,  2.30it/s] 44%|████▎     | 87/199 [00:40<00:40,  2.79it/s] 44%|████▍     | 88/199 [00:40<00:33,  3.29it/s] 45%|████▍     | 89/199 [00:40<00:29,  3.75it/s] 45%|████▌     | 90/199 [00:42<01:21,  1.34it/s] 46%|████▌     | 91/199 [00:42<01:02,  1.74it/s] 46%|████▌     | 92/199 [00:42<00:49,  2.15it/s] 47%|████▋     | 93/199 [00:43<00:40,  2.64it/s] 47%|████▋     | 94/199 [00:43<00:33,  3.14it/s] 48%|████▊     | 95/199 [00:43<00:28,  3.61it/s] 48%|████▊     | 96/199 [00:43<00:25,  4.04it/s] 49%|████▊     | 97/199 [00:43<00:23,  4.40it/s] 49%|████▉     | 98/199 [00:45<01:06,  1.51it/s] 50%|████▉     | 99/199 [00:45<00:51,  1.93it/s] 50%|█████     | 100/199 [00:47<01:25,  1.15it/s] 51%|█████     | 101/199 [00:47<01:04,  1.51it/s] 51%|█████▏    | 102/199 [00:47<00:50,  1.94it/s] 52%|█████▏    | 103/199 [00:47<00:39,  2.41it/s] 52%|█████▏    | 104/199 [00:48<00:32,  2.91it/s] 53%|█████▎    | 105/199 [00:48<00:27,  3.39it/s] 53%|█████▎    | 106/199 [00:49<00:49,  1.87it/s] 54%|█████▍    | 107/199 [00:49<00:39,  2.33it/s] 54%|█████▍    | 108/199 [00:51<01:27,  1.04it/s] 55%|█████▍    | 109/199 [00:51<01:05,  1.38it/s] 55%|█████▌    | 110/199 [00:52<00:50,  1.78it/s] 56%|█████▌    | 111/199 [00:52<00:39,  2.24it/s] 56%|█████▋    | 112/199 [00:52<00:31,  2.73it/s] 57%|█████▋    | 113/199 [00:52<00:26,  3.22it/s] 57%|█████▋    | 114/199 [00:52<00:23,  3.69it/s] 58%|█████▊    | 115/199 [00:52<00:20,  4.11it/s] 58%|█████▊    | 116/199 [00:55<01:09,  1.20it/s] 59%|█████▉    | 117/199 [00:55<00:52,  1.57it/s] 59%|█████▉    | 118/199 [00:55<00:40,  2.00it/s] 60%|█████▉    | 119/199 [00:55<00:32,  2.47it/s] 60%|██████    | 120/199 [00:55<00:26,  2.97it/s] 61%|██████    | 121/199 [00:56<00:22,  3.45it/s] 61%|██████▏   | 122/199 [00:57<00:43,  1.77it/s] 62%|██████▏   | 123/199 [00:57<00:34,  2.23it/s] 62%|██████▏   | 124/199 [00:58<00:47,  1.59it/s] 63%|██████▎   | 125/199 [00:58<00:36,  2.02it/s] 63%|██████▎   | 126/199 [00:58<00:29,  2.50it/s] 64%|██████▍   | 127/199 [00:59<00:24,  3.00it/s] 64%|██████▍   | 128/199 [00:59<00:20,  3.48it/s] 65%|██████▍   | 129/199 [00:59<00:17,  3.92it/s] 65%|██████▌   | 130/199 [00:59<00:16,  4.30it/s] 66%|██████▌   | 131/199 [00:59<00:14,  4.62it/s] 66%|██████▋   | 132/199 [01:01<00:35,  1.89it/s] 67%|██████▋   | 133/199 [01:01<00:28,  2.35it/s] 67%|██████▋   | 134/199 [01:01<00:22,  2.84it/s] 68%|██████▊   | 135/199 [01:01<00:19,  3.33it/s] 68%|██████▊   | 136/199 [01:01<00:16,  3.79it/s] 69%|██████▉   | 137/199 [01:01<00:14,  4.19it/s] 69%|██████▉   | 138/199 [01:04<00:50,  1.21it/s] 70%|██████▉   | 139/199 [01:04<00:37,  1.58it/s] 70%|███████   | 140/199 [01:04<00:30,  1.97it/s] 71%|███████   | 141/199 [01:04<00:23,  2.44it/s] 71%|███████▏  | 142/199 [01:04<00:19,  2.94it/s] 72%|███████▏  | 143/199 [01:05<00:16,  3.43it/s] 72%|███████▏  | 144/199 [01:05<00:14,  3.88it/s] 73%|███████▎  | 145/199 [01:05<00:12,  4.27it/s] 73%|███████▎  | 146/199 [01:07<00:41,  1.29it/s] 74%|███████▍  | 147/199 [01:07<00:31,  1.67it/s] 74%|███████▍  | 148/199 [01:07<00:24,  2.12it/s] 75%|███████▍  | 149/199 [01:07<00:19,  2.61it/s] 75%|███████▌  | 150/199 [01:08<00:15,  3.10it/s] 76%|███████▌  | 151/199 [01:08<00:13,  3.58it/s] 76%|███████▋  | 152/199 [01:08<00:11,  4.01it/s] 77%|███████▋  | 153/199 [01:08<00:10,  4.37it/s] 77%|███████▋  | 154/199 [01:11<00:50,  1.13s/it] 78%|███████▊  | 155/199 [01:12<00:37,  1.19it/s] 78%|███████▊  | 156/199 [01:12<00:27,  1.56it/s] 79%|███████▉  | 157/199 [01:12<00:21,  1.99it/s] 79%|███████▉  | 158/199 [01:12<00:16,  2.46it/s] 80%|███████▉  | 159/199 [01:12<00:13,  2.96it/s] 80%|████████  | 160/199 [01:13<00:11,  3.44it/s] 81%|████████  | 161/199 [01:13<00:09,  3.87it/s] 81%|████████▏ | 162/199 [01:14<00:17,  2.09it/s] 82%|████████▏ | 163/199 [01:14<00:14,  2.57it/s] 82%|████████▏ | 164/199 [01:14<00:11,  3.06it/s] 83%|████████▎ | 165/199 [01:14<00:09,  3.53it/s] 83%|████████▎ | 166/199 [01:14<00:08,  3.96it/s] 84%|████████▍ | 167/199 [01:15<00:07,  4.33it/s] 84%|████████▍ | 168/199 [01:15<00:06,  4.64it/s] 85%|████████▍ | 169/199 [01:15<00:06,  4.88it/s] 85%|████████▌ | 170/199 [01:15<00:08,  3.55it/s] 86%|████████▌ | 171/199 [01:16<00:07,  3.98it/s] 86%|████████▋ | 172/199 [01:17<00:15,  1.69it/s] 87%|████████▋ | 173/199 [01:17<00:12,  2.14it/s] 87%|████████▋ | 174/199 [01:17<00:09,  2.62it/s] 88%|████████▊ | 175/199 [01:18<00:07,  3.12it/s] 88%|████████▊ | 176/199 [01:18<00:06,  3.59it/s] 89%|████████▉ | 177/199 [01:18<00:05,  4.01it/s] 89%|████████▉ | 178/199 [01:18<00:04,  4.38it/s] 90%|████████▉ | 179/199 [01:18<00:05,  3.98it/s] 90%|█████████ | 180/199 [01:19<00:07,  2.56it/s] 91%|█████████ | 181/199 [01:19<00:05,  3.06it/s] 91%|█████████▏| 182/199 [01:20<00:08,  1.96it/s] 92%|█████████▏| 183/199 [01:20<00:06,  2.43it/s] 92%|█████████▏| 184/199 [01:21<00:05,  2.93it/s] 93%|█████████▎| 185/199 [01:21<00:04,  3.42it/s] 93%|█████████▎| 186/199 [01:21<00:04,  2.71it/s] 94%|█████████▍| 187/199 [01:22<00:04,  2.77it/s] 94%|█████████▍| 188/199 [01:22<00:03,  3.26it/s] 95%|█████████▍| 189/199 [01:22<00:02,  3.73it/s] 95%|█████████▌| 190/199 [01:24<00:07,  1.27it/s] 96%|█████████▌| 191/199 [01:24<00:04,  1.65it/s] 96%|█████████▋| 192/199 [01:24<00:03,  2.10it/s] 97%|█████████▋| 193/199 [01:25<00:02,  2.58it/s] 97%|█████████▋| 194/199 [01:25<00:01,  3.08it/s] 98%|█████████▊| 195/199 [01:25<00:01,  3.57it/s] 98%|█████████▊| 196/199 [01:25<00:00,  4.01it/s] 99%|█████████▉| 197/199 [01:25<00:00,  4.39it/s] 99%|█████████▉| 198/199 [01:28<00:00,  1.07it/s]100%|██████████| 199/199 [01:28<00:00,  1.44it/s]100%|██████████| 199/199 [01:28<00:00,  2.25it/s]
=> result
* total: 19,850
* correct: 7,698
* accuracy: 38.8%
* error: 61.2%
* macro_f1: 36.0%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 sun397 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/sun397/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/sun397/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_2.pkl
6352 3970 19850
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  397
# train_x  6,352
# val      3,970
# test     19,850
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/199 [00:00<?, ?it/s]  1%|          | 1/199 [00:06<20:10,  6.11s/it]  1%|          | 2/199 [00:06<08:37,  2.62s/it]  2%|▏         | 3/199 [00:06<04:55,  1.51s/it]  2%|▏         | 4/199 [00:06<03:11,  1.02it/s]  3%|▎         | 5/199 [00:06<02:14,  1.44it/s]  3%|▎         | 6/199 [00:07<01:39,  1.93it/s]  4%|▎         | 7/199 [00:07<01:18,  2.46it/s]  4%|▍         | 8/199 [00:07<01:03,  2.99it/s]  5%|▍         | 9/199 [00:08<01:37,  1.95it/s]  5%|▌         | 10/199 [00:08<01:34,  2.00it/s]  6%|▌         | 11/199 [00:10<02:25,  1.29it/s]  6%|▌         | 12/199 [00:10<01:51,  1.68it/s]  7%|▋         | 13/199 [00:10<01:27,  2.14it/s]  7%|▋         | 14/199 [00:10<01:10,  2.63it/s]  8%|▊         | 15/199 [00:10<00:58,  3.13it/s]  8%|▊         | 16/199 [00:11<00:50,  3.60it/s]  9%|▊         | 17/199 [00:11<00:45,  4.04it/s]  9%|▉         | 18/199 [00:11<00:41,  4.40it/s] 10%|▉         | 19/199 [00:12<01:32,  1.95it/s] 10%|█         | 20/199 [00:12<01:13,  2.43it/s] 11%|█         | 21/199 [00:13<01:09,  2.56it/s] 11%|█         | 22/199 [00:13<00:57,  3.05it/s] 12%|█▏        | 23/199 [00:13<00:49,  3.53it/s] 12%|█▏        | 24/199 [00:13<00:44,  3.97it/s] 13%|█▎        | 25/199 [00:13<00:46,  3.73it/s] 13%|█▎        | 26/199 [00:14<01:01,  2.83it/s] 14%|█▎        | 27/199 [00:16<02:15,  1.27it/s] 14%|█▍        | 28/199 [00:16<01:43,  1.65it/s] 15%|█▍        | 29/199 [00:16<01:21,  2.09it/s] 15%|█▌        | 30/199 [00:16<01:05,  2.58it/s] 16%|█▌        | 31/199 [00:17<00:54,  3.07it/s] 16%|█▌        | 32/199 [00:17<00:47,  3.55it/s] 17%|█▋        | 33/199 [00:17<00:41,  3.98it/s] 17%|█▋        | 34/199 [00:17<00:37,  4.35it/s] 18%|█▊        | 35/199 [00:19<01:43,  1.58it/s] 18%|█▊        | 36/199 [00:19<01:20,  2.01it/s] 19%|█▊        | 37/199 [00:19<01:28,  1.83it/s] 19%|█▉        | 38/199 [00:20<01:10,  2.29it/s] 20%|█▉        | 39/199 [00:20<00:57,  2.78it/s] 20%|██        | 40/199 [00:20<00:48,  3.28it/s] 21%|██        | 41/199 [00:20<00:42,  3.74it/s] 21%|██        | 42/199 [00:20<00:37,  4.15it/s] 22%|██▏       | 43/199 [00:22<01:31,  1.71it/s] 22%|██▏       | 44/199 [00:22<01:11,  2.16it/s] 23%|██▎       | 45/199 [00:22<00:58,  2.65it/s] 23%|██▎       | 46/199 [00:22<00:48,  3.14it/s] 24%|██▎       | 47/199 [00:22<00:41,  3.62it/s] 24%|██▍       | 48/199 [00:23<00:37,  4.05it/s] 25%|██▍       | 49/199 [00:23<00:33,  4.42it/s] 25%|██▌       | 50/199 [00:23<00:31,  4.72it/s] 26%|██▌       | 51/199 [00:25<01:52,  1.31it/s] 26%|██▌       | 52/199 [00:25<01:26,  1.70it/s] 27%|██▋       | 53/199 [00:25<01:07,  2.15it/s] 27%|██▋       | 54/199 [00:26<00:55,  2.63it/s] 28%|██▊       | 55/199 [00:26<00:46,  3.13it/s] 28%|██▊       | 56/199 [00:26<00:39,  3.60it/s] 29%|██▊       | 57/199 [00:26<00:35,  4.02it/s] 29%|██▉       | 58/199 [00:27<00:59,  2.36it/s] 30%|██▉       | 59/199 [00:28<01:10,  1.99it/s] 30%|███       | 60/199 [00:29<01:49,  1.27it/s] 31%|███       | 61/199 [00:29<01:23,  1.65it/s] 31%|███       | 62/199 [00:29<01:05,  2.10it/s] 32%|███▏      | 63/199 [00:30<00:52,  2.58it/s] 32%|███▏      | 64/199 [00:30<00:43,  3.08it/s] 33%|███▎      | 65/199 [00:30<00:37,  3.55it/s] 33%|███▎      | 66/199 [00:31<01:18,  1.70it/s] 34%|███▎      | 67/199 [00:31<01:01,  2.15it/s] 34%|███▍      | 68/199 [00:33<01:56,  1.12it/s] 35%|███▍      | 69/199 [00:34<01:27,  1.48it/s] 35%|███▌      | 70/199 [00:34<01:08,  1.90it/s] 36%|███▌      | 71/199 [00:34<00:54,  2.37it/s] 36%|███▌      | 72/199 [00:34<00:44,  2.86it/s] 37%|███▋      | 73/199 [00:34<00:37,  3.34it/s] 37%|███▋      | 74/199 [00:35<00:43,  2.87it/s] 38%|███▊      | 75/199 [00:35<00:41,  3.00it/s] 38%|███▊      | 76/199 [00:35<00:35,  3.48it/s] 39%|███▊      | 77/199 [00:35<00:31,  3.92it/s] 39%|███▉      | 78/199 [00:36<00:28,  4.30it/s] 40%|███▉      | 79/199 [00:36<00:25,  4.62it/s] 40%|████      | 80/199 [00:36<00:24,  4.87it/s] 41%|████      | 81/199 [00:36<00:23,  5.05it/s] 41%|████      | 82/199 [00:38<01:14,  1.58it/s] 42%|████▏     | 83/199 [00:39<01:23,  1.39it/s] 42%|████▏     | 84/199 [00:39<01:04,  1.79it/s] 43%|████▎     | 85/199 [00:39<00:50,  2.25it/s] 43%|████▎     | 86/199 [00:39<00:41,  2.74it/s] 44%|████▎     | 87/199 [00:39<00:34,  3.23it/s] 44%|████▍     | 88/199 [00:40<00:30,  3.69it/s] 45%|████▍     | 89/199 [00:40<00:26,  4.10it/s] 45%|████▌     | 90/199 [00:43<02:03,  1.13s/it] 46%|████▌     | 91/199 [00:43<01:31,  1.18it/s] 46%|████▌     | 92/199 [00:43<01:09,  1.55it/s] 47%|████▋     | 93/199 [00:43<00:53,  1.98it/s] 47%|████▋     | 94/199 [00:44<00:42,  2.45it/s] 48%|████▊     | 95/199 [00:44<00:35,  2.95it/s] 48%|████▊     | 96/199 [00:44<00:29,  3.43it/s] 49%|████▊     | 97/199 [00:44<00:26,  3.88it/s] 49%|████▉     | 98/199 [00:45<00:55,  1.81it/s] 50%|████▉     | 99/199 [00:46<00:43,  2.27it/s] 50%|█████     | 100/199 [00:47<01:08,  1.44it/s] 51%|█████     | 101/199 [00:47<00:52,  1.85it/s] 51%|█████▏    | 102/199 [00:47<00:41,  2.31it/s] 52%|█████▏    | 103/199 [00:47<00:34,  2.81it/s] 52%|█████▏    | 104/199 [00:48<00:28,  3.30it/s] 53%|█████▎    | 105/199 [00:48<00:25,  3.75it/s] 53%|█████▎    | 106/199 [00:49<00:55,  1.69it/s] 54%|█████▍    | 107/199 [00:49<00:43,  2.13it/s] 54%|█████▍    | 108/199 [00:51<01:16,  1.20it/s] 55%|█████▍    | 109/199 [00:51<00:57,  1.56it/s] 55%|█████▌    | 110/199 [00:51<00:44,  1.99it/s] 56%|█████▌    | 111/199 [00:52<00:35,  2.47it/s] 56%|█████▋    | 112/199 [00:52<00:29,  2.96it/s] 57%|█████▋    | 113/199 [00:52<00:24,  3.45it/s] 57%|█████▋    | 114/199 [00:52<00:28,  2.95it/s] 58%|█████▊    | 115/199 [00:53<00:24,  3.44it/s] 58%|█████▊    | 116/199 [00:54<01:03,  1.31it/s] 59%|█████▉    | 117/199 [00:55<00:48,  1.70it/s] 59%|█████▉    | 118/199 [00:55<00:37,  2.15it/s] 60%|█████▉    | 119/199 [00:55<00:30,  2.64it/s] 60%|██████    | 120/199 [00:55<00:25,  3.13it/s] 61%|██████    | 121/199 [00:55<00:21,  3.61it/s] 61%|██████▏   | 122/199 [00:57<00:49,  1.55it/s] 62%|██████▏   | 123/199 [00:57<00:38,  1.98it/s] 62%|██████▏   | 124/199 [00:58<00:40,  1.83it/s] 63%|██████▎   | 125/199 [00:58<00:32,  2.29it/s] 63%|██████▎   | 126/199 [00:58<00:26,  2.78it/s] 64%|██████▍   | 127/199 [00:58<00:21,  3.28it/s] 64%|██████▍   | 128/199 [00:58<00:18,  3.74it/s] 65%|██████▍   | 129/199 [00:59<00:16,  4.15it/s] 65%|██████▌   | 130/199 [00:59<00:20,  3.29it/s] 66%|██████▌   | 131/199 [00:59<00:18,  3.74it/s] 66%|██████▋   | 132/199 [01:00<00:35,  1.87it/s] 67%|██████▋   | 133/199 [01:01<00:28,  2.34it/s] 67%|██████▋   | 134/199 [01:01<00:22,  2.83it/s] 68%|██████▊   | 135/199 [01:01<00:19,  3.32it/s] 68%|██████▊   | 136/199 [01:01<00:16,  3.77it/s] 69%|██████▉   | 137/199 [01:01<00:14,  4.17it/s] 69%|██████▉   | 138/199 [01:03<00:50,  1.20it/s] 70%|██████▉   | 139/199 [01:04<00:38,  1.57it/s] 70%|███████   | 140/199 [01:04<00:29,  2.00it/s] 71%|███████   | 141/199 [01:04<00:23,  2.48it/s] 71%|███████▏  | 142/199 [01:04<00:19,  2.97it/s] 72%|███████▏  | 143/199 [01:04<00:16,  3.46it/s] 72%|███████▏  | 144/199 [01:05<00:14,  3.90it/s] 73%|███████▎  | 145/199 [01:05<00:12,  4.29it/s] 73%|███████▎  | 146/199 [01:07<00:45,  1.17it/s] 74%|███████▍  | 147/199 [01:07<00:34,  1.53it/s] 74%|███████▍  | 148/199 [01:07<00:26,  1.96it/s] 75%|███████▍  | 149/199 [01:08<00:20,  2.43it/s] 75%|███████▌  | 150/199 [01:08<00:16,  2.92it/s] 76%|███████▌  | 151/199 [01:08<00:14,  3.40it/s] 76%|███████▋  | 152/199 [01:08<00:12,  3.84it/s] 77%|███████▋  | 153/199 [01:08<00:10,  4.23it/s] 77%|███████▋  | 154/199 [01:11<00:41,  1.10it/s] 78%|███████▊  | 155/199 [01:11<00:30,  1.44it/s] 78%|███████▊  | 156/199 [01:11<00:23,  1.86it/s] 79%|███████▉  | 157/199 [01:11<00:18,  2.32it/s] 79%|███████▉  | 158/199 [01:11<00:14,  2.81it/s] 80%|███████▉  | 159/199 [01:12<00:12,  3.31it/s] 80%|████████  | 160/199 [01:12<00:10,  3.77it/s] 81%|████████  | 161/199 [01:12<00:09,  4.17it/s] 81%|████████▏ | 162/199 [01:13<00:13,  2.77it/s] 82%|████████▏ | 163/199 [01:13<00:11,  3.26it/s] 82%|████████▏ | 164/199 [01:13<00:09,  3.72it/s] 83%|████████▎ | 165/199 [01:13<00:08,  4.13it/s] 83%|████████▎ | 166/199 [01:13<00:07,  4.48it/s] 84%|████████▍ | 167/199 [01:14<00:06,  4.76it/s] 84%|████████▍ | 168/199 [01:14<00:06,  4.96it/s] 85%|████████▍ | 169/199 [01:14<00:05,  5.12it/s] 85%|████████▌ | 170/199 [01:15<00:10,  2.69it/s] 86%|████████▌ | 171/199 [01:15<00:08,  3.16it/s] 86%|████████▋ | 172/199 [01:16<00:18,  1.47it/s] 87%|████████▋ | 173/199 [01:17<00:13,  1.89it/s] 87%|████████▋ | 174/199 [01:17<00:10,  2.36it/s] 88%|████████▊ | 175/199 [01:17<00:08,  2.85it/s] 88%|████████▊ | 176/199 [01:17<00:06,  3.34it/s] 89%|████████▉ | 177/199 [01:17<00:05,  3.79it/s] 89%|████████▉ | 178/199 [01:18<00:05,  4.18it/s] 90%|████████▉ | 179/199 [01:18<00:04,  4.52it/s] 90%|█████████ | 180/199 [01:18<00:07,  2.55it/s] 91%|█████████ | 181/199 [01:19<00:05,  3.04it/s] 91%|█████████▏| 182/199 [01:19<00:04,  3.51it/s] 92%|█████████▏| 183/199 [01:19<00:04,  3.95it/s] 92%|█████████▏| 184/199 [01:19<00:03,  4.33it/s] 93%|█████████▎| 185/199 [01:19<00:03,  4.63it/s] 93%|█████████▎| 186/199 [01:21<00:06,  1.97it/s] 94%|█████████▍| 187/199 [01:21<00:04,  2.45it/s] 94%|█████████▍| 188/199 [01:21<00:03,  2.94it/s] 95%|█████████▍| 189/199 [01:21<00:02,  3.42it/s] 95%|█████████▌| 190/199 [01:21<00:02,  3.87it/s] 96%|█████████▌| 191/199 [01:21<00:01,  4.26it/s] 96%|█████████▋| 192/199 [01:22<00:01,  4.59it/s] 97%|█████████▋| 193/199 [01:22<00:01,  4.84it/s] 97%|█████████▋| 194/199 [01:23<00:02,  1.86it/s] 98%|█████████▊| 195/199 [01:23<00:01,  2.33it/s] 98%|█████████▊| 196/199 [01:23<00:01,  2.83it/s] 99%|█████████▉| 197/199 [01:24<00:00,  3.33it/s] 99%|█████████▉| 198/199 [01:25<00:00,  1.74it/s]100%|██████████| 199/199 [01:25<00:00,  2.26it/s]100%|██████████| 199/199 [01:25<00:00,  2.33it/s]
=> result
* total: 19,850
* correct: 7,905
* accuracy: 39.8%
* error: 60.2%
* macro_f1: 36.5%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 sun397 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/sun397/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/sun397/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_3.pkl
6352 3970 19850
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  397
# train_x  6,352
# val      3,970
# test     19,850
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/199 [00:00<?, ?it/s]  1%|          | 1/199 [00:05<17:43,  5.37s/it]  1%|          | 2/199 [00:05<07:40,  2.34s/it]  2%|▏         | 3/199 [00:05<04:24,  1.35s/it]  2%|▏         | 4/199 [00:05<02:53,  1.13it/s]  3%|▎         | 5/199 [00:06<02:02,  1.58it/s]  3%|▎         | 6/199 [00:06<01:32,  2.09it/s]  4%|▎         | 7/199 [00:06<01:13,  2.63it/s]  4%|▍         | 8/199 [00:06<01:00,  3.16it/s]  5%|▍         | 9/199 [00:07<01:29,  2.12it/s]  5%|▌         | 10/199 [00:08<01:51,  1.70it/s]  6%|▌         | 11/199 [00:09<02:05,  1.50it/s]  6%|▌         | 12/199 [00:09<01:37,  1.93it/s]  7%|▋         | 13/199 [00:09<01:17,  2.40it/s]  7%|▋         | 14/199 [00:09<01:03,  2.90it/s]  8%|▊         | 15/199 [00:09<00:54,  3.39it/s]  8%|▊         | 16/199 [00:10<00:47,  3.85it/s]  9%|▊         | 17/199 [00:10<00:43,  4.21it/s]  9%|▉         | 18/199 [00:10<00:39,  4.54it/s] 10%|▉         | 19/199 [00:11<01:14,  2.43it/s] 10%|█         | 20/199 [00:11<01:01,  2.93it/s] 11%|█         | 21/199 [00:11<00:52,  3.42it/s] 11%|█         | 22/199 [00:11<00:45,  3.87it/s] 12%|█▏        | 23/199 [00:12<00:41,  4.26it/s] 12%|█▏        | 24/199 [00:12<00:38,  4.59it/s] 13%|█▎        | 25/199 [00:12<00:44,  3.90it/s] 13%|█▎        | 26/199 [00:13<01:08,  2.53it/s] 14%|█▎        | 27/199 [00:14<02:02,  1.40it/s] 14%|█▍        | 28/199 [00:14<01:34,  1.81it/s] 15%|█▍        | 29/199 [00:15<01:14,  2.27it/s] 15%|█▌        | 30/199 [00:15<01:01,  2.76it/s] 16%|█▌        | 31/199 [00:15<00:51,  3.25it/s] 16%|█▌        | 32/199 [00:15<00:44,  3.71it/s] 17%|█▋        | 33/199 [00:15<00:40,  4.13it/s] 17%|█▋        | 34/199 [00:15<00:36,  4.48it/s] 18%|█▊        | 35/199 [00:17<01:28,  1.84it/s] 18%|█▊        | 36/199 [00:17<01:35,  1.70it/s] 19%|█▊        | 37/199 [00:18<01:15,  2.15it/s] 19%|█▉        | 38/199 [00:18<01:01,  2.64it/s] 20%|█▉        | 39/199 [00:18<00:51,  3.14it/s] 20%|██        | 40/199 [00:18<00:44,  3.61it/s] 21%|██        | 41/199 [00:18<00:39,  4.04it/s] 21%|██        | 42/199 [00:19<00:35,  4.41it/s] 22%|██▏       | 43/199 [00:20<01:19,  1.96it/s] 22%|██▏       | 44/199 [00:22<02:21,  1.10it/s] 23%|██▎       | 45/199 [00:22<01:46,  1.45it/s] 23%|██▎       | 46/199 [00:22<01:22,  1.86it/s] 24%|██▎       | 47/199 [00:22<01:05,  2.32it/s] 24%|██▍       | 48/199 [00:22<00:53,  2.82it/s] 25%|██▍       | 49/199 [00:22<00:45,  3.31it/s] 25%|██▌       | 50/199 [00:23<00:39,  3.77it/s] 26%|██▌       | 51/199 [00:23<00:43,  3.39it/s] 26%|██▌       | 52/199 [00:25<01:39,  1.48it/s] 27%|██▋       | 53/199 [00:25<01:16,  1.90it/s] 27%|██▋       | 54/199 [00:25<01:01,  2.37it/s] 28%|██▊       | 55/199 [00:25<00:50,  2.87it/s] 28%|██▊       | 56/199 [00:25<00:42,  3.36it/s] 29%|██▊       | 57/199 [00:25<00:37,  3.81it/s] 29%|██▉       | 58/199 [00:26<00:33,  4.21it/s] 30%|██▉       | 59/199 [00:26<00:30,  4.55it/s] 30%|███       | 60/199 [00:28<01:51,  1.24it/s] 31%|███       | 61/199 [00:28<01:25,  1.62it/s] 31%|███       | 62/199 [00:28<01:06,  2.06it/s] 32%|███▏      | 63/199 [00:28<00:53,  2.54it/s] 32%|███▏      | 64/199 [00:29<00:44,  3.04it/s] 33%|███▎      | 65/199 [00:29<00:38,  3.52it/s] 33%|███▎      | 66/199 [00:29<00:33,  3.96it/s] 34%|███▎      | 67/199 [00:29<00:30,  4.34it/s] 34%|███▍      | 68/199 [00:32<01:53,  1.16it/s] 35%|███▍      | 69/199 [00:32<01:25,  1.52it/s] 35%|███▌      | 70/199 [00:32<01:06,  1.95it/s] 36%|███▌      | 71/199 [00:32<00:52,  2.42it/s] 36%|███▌      | 72/199 [00:32<00:43,  2.92it/s] 37%|███▋      | 73/199 [00:32<00:36,  3.41it/s] 37%|███▋      | 74/199 [00:33<00:32,  3.86it/s] 38%|███▊      | 75/199 [00:33<00:29,  4.25it/s] 38%|███▊      | 76/199 [00:33<00:39,  3.14it/s] 39%|███▊      | 77/199 [00:33<00:33,  3.62it/s] 39%|███▉      | 78/199 [00:34<00:29,  4.05it/s] 40%|███▉      | 79/199 [00:34<00:27,  4.42it/s] 40%|████      | 80/199 [00:34<00:25,  4.72it/s] 41%|████      | 81/199 [00:34<00:23,  4.94it/s] 41%|████      | 82/199 [00:36<01:26,  1.35it/s] 42%|████▏     | 83/199 [00:37<01:12,  1.60it/s] 42%|████▏     | 84/199 [00:37<00:56,  2.03it/s] 43%|████▎     | 85/199 [00:37<00:45,  2.51it/s] 43%|████▎     | 86/199 [00:37<00:37,  3.01it/s] 44%|████▎     | 87/199 [00:37<00:32,  3.48it/s] 44%|████▍     | 88/199 [00:37<00:28,  3.92it/s] 45%|████▍     | 89/199 [00:38<00:25,  4.30it/s] 45%|████▌     | 90/199 [00:41<02:20,  1.29s/it] 46%|████▌     | 91/199 [00:42<01:43,  1.04it/s] 46%|████▌     | 92/199 [00:42<01:17,  1.38it/s] 47%|████▋     | 93/199 [00:42<00:59,  1.79it/s] 47%|████▋     | 94/199 [00:42<00:46,  2.24it/s] 48%|████▊     | 95/199 [00:42<00:37,  2.74it/s] 48%|████▊     | 96/199 [00:42<00:31,  3.23it/s] 49%|████▊     | 97/199 [00:43<00:27,  3.70it/s] 49%|████▉     | 98/199 [00:44<00:55,  1.82it/s] 50%|████▉     | 99/199 [00:44<00:43,  2.28it/s] 50%|█████     | 100/199 [00:45<01:08,  1.44it/s] 51%|█████     | 101/199 [00:45<00:52,  1.86it/s] 51%|█████▏    | 102/199 [00:46<00:41,  2.32it/s] 52%|█████▏    | 103/199 [00:46<00:34,  2.82it/s] 52%|█████▏    | 104/199 [00:46<00:28,  3.31it/s] 53%|█████▎    | 105/199 [00:46<00:24,  3.78it/s] 53%|█████▎    | 106/199 [00:48<00:55,  1.68it/s] 54%|█████▍    | 107/199 [00:48<00:43,  2.12it/s] 54%|█████▍    | 108/199 [00:51<01:45,  1.16s/it] 55%|█████▍    | 109/199 [00:51<01:18,  1.15it/s] 55%|█████▌    | 110/199 [00:51<00:58,  1.51it/s] 56%|█████▌    | 111/199 [00:51<00:45,  1.93it/s] 56%|█████▋    | 112/199 [00:51<00:36,  2.40it/s] 57%|█████▋    | 113/199 [00:51<00:29,  2.89it/s] 57%|█████▋    | 114/199 [00:52<00:25,  3.38it/s] 58%|█████▊    | 115/199 [00:52<00:21,  3.82it/s] 58%|█████▊    | 116/199 [00:54<01:11,  1.16it/s] 59%|█████▉    | 117/199 [00:54<00:53,  1.53it/s] 59%|█████▉    | 118/199 [00:54<00:41,  1.95it/s] 60%|█████▉    | 119/199 [00:55<00:32,  2.43it/s] 60%|██████    | 120/199 [00:55<00:27,  2.92it/s] 61%|██████    | 121/199 [00:55<00:22,  3.40it/s] 61%|██████▏   | 122/199 [00:55<00:22,  3.40it/s] 62%|██████▏   | 123/199 [00:55<00:19,  3.85it/s] 62%|██████▏   | 124/199 [00:57<00:50,  1.48it/s] 63%|██████▎   | 125/199 [00:57<00:39,  1.89it/s] 63%|██████▎   | 126/199 [00:57<00:30,  2.36it/s] 64%|██████▍   | 127/199 [00:58<00:25,  2.86it/s] 64%|██████▍   | 128/199 [00:58<00:21,  3.35it/s] 65%|██████▍   | 129/199 [00:58<00:18,  3.80it/s] 65%|██████▌   | 130/199 [00:58<00:16,  4.21it/s] 66%|██████▌   | 131/199 [00:58<00:15,  4.53it/s] 66%|██████▋   | 132/199 [00:59<00:33,  2.00it/s] 67%|██████▋   | 133/199 [01:00<00:26,  2.46it/s] 67%|██████▋   | 134/199 [01:00<00:21,  2.96it/s] 68%|██████▊   | 135/199 [01:00<00:18,  3.44it/s] 68%|██████▊   | 136/199 [01:00<00:16,  3.89it/s] 69%|██████▉   | 137/199 [01:00<00:14,  4.27it/s] 69%|██████▉   | 138/199 [01:02<00:39,  1.54it/s] 70%|██████▉   | 139/199 [01:02<00:30,  1.97it/s] 70%|███████   | 140/199 [01:03<00:34,  1.74it/s] 71%|███████   | 141/199 [01:03<00:26,  2.19it/s] 71%|███████▏  | 142/199 [01:03<00:21,  2.67it/s] 72%|███████▏  | 143/199 [01:03<00:17,  3.17it/s] 72%|███████▏  | 144/199 [01:04<00:15,  3.64it/s] 73%|███████▎  | 145/199 [01:04<00:13,  4.05it/s] 73%|███████▎  | 146/199 [01:05<00:30,  1.71it/s] 74%|███████▍  | 147/199 [01:05<00:24,  2.16it/s] 74%|███████▍  | 148/199 [01:06<00:19,  2.64it/s] 75%|███████▍  | 149/199 [01:06<00:15,  3.14it/s] 75%|███████▌  | 150/199 [01:06<00:13,  3.61it/s] 76%|███████▌  | 151/199 [01:06<00:11,  4.04it/s] 76%|███████▋  | 152/199 [01:06<00:10,  4.40it/s] 77%|███████▋  | 153/199 [01:06<00:09,  4.69it/s] 77%|███████▋  | 154/199 [01:09<00:40,  1.11it/s] 78%|███████▊  | 155/199 [01:09<00:30,  1.46it/s] 78%|███████▊  | 156/199 [01:09<00:22,  1.88it/s] 79%|███████▉  | 157/199 [01:09<00:17,  2.34it/s] 79%|███████▉  | 158/199 [01:10<00:14,  2.84it/s] 80%|███████▉  | 159/199 [01:10<00:12,  3.33it/s] 80%|████████  | 160/199 [01:10<00:10,  3.79it/s] 81%|████████  | 161/199 [01:10<00:09,  4.19it/s] 81%|████████▏ | 162/199 [01:11<00:20,  1.84it/s] 82%|████████▏ | 163/199 [01:12<00:15,  2.30it/s] 82%|████████▏ | 164/199 [01:12<00:12,  2.79it/s] 83%|████████▎ | 165/199 [01:12<00:10,  3.28it/s] 83%|████████▎ | 166/199 [01:12<00:08,  3.74it/s] 84%|████████▍ | 167/199 [01:12<00:07,  4.15it/s] 84%|████████▍ | 168/199 [01:13<00:06,  4.50it/s] 85%|████████▍ | 169/199 [01:13<00:06,  4.78it/s] 85%|████████▌ | 170/199 [01:13<00:10,  2.80it/s] 86%|████████▌ | 171/199 [01:14<00:08,  3.30it/s] 86%|████████▋ | 172/199 [01:15<00:20,  1.31it/s] 87%|████████▋ | 173/199 [01:16<00:15,  1.70it/s] 87%|████████▋ | 174/199 [01:16<00:11,  2.14it/s] 88%|████████▊ | 175/199 [01:16<00:09,  2.63it/s] 88%|████████▊ | 176/199 [01:16<00:07,  3.12it/s] 89%|████████▉ | 177/199 [01:16<00:06,  3.60it/s] 89%|████████▉ | 178/199 [01:17<00:05,  4.02it/s] 90%|████████▉ | 179/199 [01:17<00:04,  4.39it/s] 90%|█████████ | 180/199 [01:18<00:08,  2.24it/s] 91%|█████████ | 181/199 [01:18<00:06,  2.73it/s] 91%|█████████▏| 182/199 [01:18<00:06,  2.48it/s] 92%|█████████▏| 183/199 [01:19<00:05,  2.78it/s] 92%|█████████▏| 184/199 [01:19<00:04,  3.27it/s] 93%|█████████▎| 185/199 [01:19<00:03,  3.73it/s] 93%|█████████▎| 186/199 [01:20<00:05,  2.19it/s] 94%|█████████▍| 187/199 [01:20<00:04,  2.68it/s] 94%|█████████▍| 188/199 [01:20<00:03,  3.18it/s] 95%|█████████▍| 189/199 [01:20<00:02,  3.66it/s] 95%|█████████▌| 190/199 [01:22<00:06,  1.30it/s] 96%|█████████▌| 191/199 [01:22<00:04,  1.69it/s] 96%|█████████▋| 192/199 [01:23<00:03,  2.14it/s] 97%|█████████▋| 193/199 [01:23<00:02,  2.62it/s] 97%|█████████▋| 194/199 [01:23<00:01,  3.13it/s] 98%|█████████▊| 195/199 [01:23<00:01,  3.61it/s] 98%|█████████▊| 196/199 [01:23<00:00,  4.04it/s] 99%|█████████▉| 197/199 [01:24<00:00,  4.41it/s] 99%|█████████▉| 198/199 [01:26<00:00,  1.02it/s]100%|██████████| 199/199 [01:26<00:00,  1.37it/s]100%|██████████| 199/199 [01:27<00:00,  2.29it/s]
=> result
* total: 19,850
* correct: 7,402
* accuracy: 37.3%
* error: 62.7%
* macro_f1: 34.2%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 dtd 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/dtd/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/dtd/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_1.pkl
752 1128 1692
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  47
# train_x  752
# val      1,128
# test     1,692
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:03<00:58,  3.67s/it] 12%|█▏        | 2/17 [00:03<00:23,  1.58s/it] 18%|█▊        | 3/17 [00:03<00:12,  1.10it/s] 24%|██▎       | 4/17 [00:04<00:07,  1.69it/s] 29%|██▉       | 5/17 [00:04<00:05,  2.39it/s] 35%|███▌      | 6/17 [00:04<00:03,  3.20it/s] 41%|████      | 7/17 [00:04<00:02,  4.07it/s] 47%|████▋     | 8/17 [00:04<00:01,  4.94it/s] 53%|█████▎    | 9/17 [00:04<00:01,  5.78it/s] 59%|█████▉    | 10/17 [00:04<00:01,  6.52it/s] 65%|██████▍   | 11/17 [00:04<00:00,  7.16it/s] 71%|███████   | 12/17 [00:04<00:00,  7.67it/s] 76%|███████▋  | 13/17 [00:04<00:00,  8.07it/s] 82%|████████▏ | 14/17 [00:05<00:00,  8.37it/s] 88%|████████▊ | 15/17 [00:05<00:00,  8.61it/s] 94%|█████████▍| 16/17 [00:05<00:00,  8.77it/s]100%|██████████| 17/17 [00:05<00:00,  9.06it/s]100%|██████████| 17/17 [00:05<00:00,  3.10it/s]
=> result
* total: 1,692
* correct: 403
* accuracy: 23.8%
* error: 76.2%
* macro_f1: 19.7%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 dtd 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/dtd/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/dtd/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_2.pkl
752 1128 1692
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  47
# train_x  752
# val      1,128
# test     1,692
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:03<00:54,  3.40s/it] 12%|█▏        | 2/17 [00:03<00:21,  1.47s/it] 18%|█▊        | 3/17 [00:03<00:11,  1.18it/s] 24%|██▎       | 4/17 [00:03<00:07,  1.80it/s] 29%|██▉       | 5/17 [00:03<00:04,  2.53it/s] 35%|███▌      | 6/17 [00:03<00:03,  3.36it/s] 41%|████      | 7/17 [00:04<00:02,  4.24it/s] 47%|████▋     | 8/17 [00:04<00:01,  5.12it/s] 53%|█████▎    | 9/17 [00:04<00:01,  5.94it/s] 59%|█████▉    | 10/17 [00:04<00:01,  6.63it/s] 65%|██████▍   | 11/17 [00:04<00:00,  7.24it/s] 71%|███████   | 12/17 [00:04<00:00,  7.74it/s] 76%|███████▋  | 13/17 [00:04<00:00,  8.13it/s] 82%|████████▏ | 14/17 [00:04<00:00,  8.43it/s] 88%|████████▊ | 15/17 [00:04<00:00,  8.65it/s] 94%|█████████▍| 16/17 [00:05<00:00,  8.81it/s]100%|██████████| 17/17 [00:05<00:00,  9.10it/s]100%|██████████| 17/17 [00:05<00:00,  3.26it/s]
=> result
* total: 1,692
* correct: 361
* accuracy: 21.3%
* error: 78.7%
* macro_f1: 15.7%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 dtd 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/dtd/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/dtd/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_3.pkl
752 1128 1692
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  47
# train_x  752
# val      1,128
# test     1,692
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:03<00:53,  3.37s/it] 12%|█▏        | 2/17 [00:03<00:21,  1.45s/it] 18%|█▊        | 3/17 [00:03<00:11,  1.19it/s] 24%|██▎       | 4/17 [00:03<00:07,  1.81it/s] 29%|██▉       | 5/17 [00:03<00:04,  2.55it/s] 35%|███▌      | 6/17 [00:03<00:03,  3.38it/s] 41%|████      | 7/17 [00:04<00:02,  4.26it/s] 47%|████▋     | 8/17 [00:04<00:01,  5.14it/s] 53%|█████▎    | 9/17 [00:04<00:01,  5.95it/s] 59%|█████▉    | 10/17 [00:04<00:01,  6.68it/s] 65%|██████▍   | 11/17 [00:04<00:00,  7.29it/s] 71%|███████   | 12/17 [00:04<00:00,  7.78it/s] 76%|███████▋  | 13/17 [00:04<00:00,  8.17it/s] 82%|████████▏ | 14/17 [00:04<00:00,  8.37it/s] 88%|████████▊ | 15/17 [00:04<00:00,  8.62it/s] 94%|█████████▍| 16/17 [00:05<00:00,  8.79it/s]100%|██████████| 17/17 [00:05<00:00,  9.09it/s]100%|██████████| 17/17 [00:05<00:00,  3.28it/s]
=> result
* total: 1,692
* correct: 320
* accuracy: 18.9%
* error: 81.1%
* macro_f1: 15.0%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 eurosat 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/eurosat/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/eurosat/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_1.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:02<03:44,  2.80s/it]  2%|▏         | 2/81 [00:02<01:36,  1.22s/it]  4%|▎         | 3/81 [00:03<00:55,  1.41it/s]  5%|▍         | 4/81 [00:03<00:36,  2.13it/s]  6%|▌         | 5/81 [00:03<00:25,  2.96it/s]  7%|▋         | 6/81 [00:03<00:19,  3.87it/s]  9%|▊         | 7/81 [00:03<00:15,  4.80it/s] 10%|▉         | 8/81 [00:03<00:12,  5.70it/s] 11%|█         | 9/81 [00:03<00:11,  6.51it/s] 12%|█▏        | 10/81 [00:03<00:09,  7.20it/s] 14%|█▎        | 11/81 [00:03<00:09,  7.77it/s] 15%|█▍        | 12/81 [00:03<00:08,  8.23it/s] 16%|█▌        | 13/81 [00:04<00:07,  8.60it/s] 17%|█▋        | 14/81 [00:04<00:07,  8.86it/s] 19%|█▊        | 15/81 [00:04<00:07,  8.95it/s] 20%|█▉        | 16/81 [00:04<00:07,  9.09it/s] 21%|██        | 17/81 [00:04<00:06,  9.15it/s] 22%|██▏       | 18/81 [00:04<00:06,  9.26it/s] 23%|██▎       | 19/81 [00:04<00:06,  9.31it/s] 25%|██▍       | 20/81 [00:04<00:06,  9.37it/s] 26%|██▌       | 21/81 [00:04<00:06,  9.41it/s] 27%|██▋       | 22/81 [00:05<00:06,  9.46it/s] 28%|██▊       | 23/81 [00:05<00:06,  9.51it/s] 30%|██▉       | 24/81 [00:05<00:05,  9.54it/s] 31%|███       | 25/81 [00:05<00:05,  9.55it/s] 32%|███▏      | 26/81 [00:05<00:05,  9.54it/s] 33%|███▎      | 27/81 [00:05<00:05,  9.55it/s] 35%|███▍      | 28/81 [00:05<00:05,  9.53it/s] 36%|███▌      | 29/81 [00:05<00:05,  9.56it/s] 37%|███▋      | 30/81 [00:05<00:05,  9.57it/s] 38%|███▊      | 31/81 [00:05<00:05,  9.57it/s] 40%|███▉      | 32/81 [00:06<00:05,  9.58it/s] 41%|████      | 33/81 [00:06<00:05,  9.57it/s] 42%|████▏     | 34/81 [00:06<00:04,  9.57it/s] 43%|████▎     | 35/81 [00:06<00:04,  9.57it/s] 44%|████▍     | 36/81 [00:06<00:04,  9.56it/s] 46%|████▌     | 37/81 [00:06<00:04,  9.55it/s] 47%|████▋     | 38/81 [00:06<00:04,  9.57it/s] 48%|████▊     | 39/81 [00:06<00:04,  9.58it/s] 49%|████▉     | 40/81 [00:06<00:04,  9.58it/s] 51%|█████     | 41/81 [00:06<00:04,  9.57it/s] 52%|█████▏    | 42/81 [00:07<00:04,  9.57it/s] 53%|█████▎    | 43/81 [00:07<00:03,  9.56it/s] 54%|█████▍    | 44/81 [00:07<00:03,  9.55it/s] 56%|█████▌    | 45/81 [00:07<00:03,  9.57it/s] 57%|█████▋    | 46/81 [00:07<00:03,  9.58it/s] 58%|█████▊    | 47/81 [00:07<00:03,  9.57it/s] 59%|█████▉    | 48/81 [00:07<00:03,  9.56it/s] 60%|██████    | 49/81 [00:07<00:03,  9.57it/s] 62%|██████▏   | 50/81 [00:07<00:03,  9.57it/s] 63%|██████▎   | 51/81 [00:08<00:03,  9.57it/s] 64%|██████▍   | 52/81 [00:08<00:03,  9.54it/s] 65%|██████▌   | 53/81 [00:08<00:02,  9.58it/s] 67%|██████▋   | 54/81 [00:08<00:02,  9.58it/s] 68%|██████▊   | 55/81 [00:08<00:02,  9.57it/s] 69%|██████▉   | 56/81 [00:08<00:02,  9.56it/s] 70%|███████   | 57/81 [00:08<00:02,  9.55it/s] 72%|███████▏  | 58/81 [00:08<00:02,  9.55it/s] 73%|███████▎  | 59/81 [00:08<00:02,  9.55it/s] 74%|███████▍  | 60/81 [00:08<00:02,  9.55it/s] 75%|███████▌  | 61/81 [00:09<00:02,  9.57it/s] 77%|███████▋  | 62/81 [00:09<00:01,  9.57it/s] 78%|███████▊  | 63/81 [00:09<00:01,  9.55it/s] 79%|███████▉  | 64/81 [00:09<00:01,  9.55it/s] 80%|████████  | 65/81 [00:09<00:01,  9.54it/s] 81%|████████▏ | 66/81 [00:09<00:01,  9.54it/s] 83%|████████▎ | 67/81 [00:09<00:01,  9.55it/s] 84%|████████▍ | 68/81 [00:09<00:01,  9.45it/s] 85%|████████▌ | 69/81 [00:09<00:01,  9.51it/s] 86%|████████▋ | 70/81 [00:10<00:01,  9.55it/s] 88%|████████▊ | 71/81 [00:10<00:01,  9.59it/s] 89%|████████▉ | 72/81 [00:10<00:00,  9.61it/s] 90%|█████████ | 73/81 [00:10<00:00,  9.62it/s] 91%|█████████▏| 74/81 [00:10<00:00,  9.63it/s] 93%|█████████▎| 75/81 [00:10<00:00,  9.63it/s] 94%|█████████▍| 76/81 [00:10<00:00,  9.64it/s] 95%|█████████▌| 77/81 [00:10<00:00,  9.64it/s] 96%|█████████▋| 78/81 [00:10<00:00,  9.64it/s] 98%|█████████▊| 79/81 [00:10<00:00,  9.64it/s] 99%|█████████▉| 80/81 [00:11<00:00,  9.65it/s]100%|██████████| 81/81 [00:11<00:00,  9.65it/s]100%|██████████| 81/81 [00:11<00:00,  7.20it/s]
=> result
* total: 8,100
* correct: 3,438
* accuracy: 42.4%
* error: 57.6%
* macro_f1: 36.7%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 eurosat 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/eurosat/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/eurosat/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_2.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:02<03:43,  2.80s/it]  2%|▏         | 2/81 [00:02<01:35,  1.21s/it]  4%|▎         | 3/81 [00:03<00:55,  1.41it/s]  5%|▍         | 4/81 [00:03<00:36,  2.13it/s]  6%|▌         | 5/81 [00:03<00:25,  2.96it/s]  7%|▋         | 6/81 [00:03<00:19,  3.87it/s]  9%|▊         | 7/81 [00:03<00:15,  4.81it/s] 10%|▉         | 8/81 [00:03<00:12,  5.71it/s] 11%|█         | 9/81 [00:03<00:11,  6.52it/s] 12%|█▏        | 10/81 [00:03<00:09,  7.23it/s] 14%|█▎        | 11/81 [00:03<00:08,  7.81it/s] 15%|█▍        | 12/81 [00:03<00:08,  8.16it/s] 16%|█▌        | 13/81 [00:04<00:07,  8.55it/s] 17%|█▋        | 14/81 [00:04<00:07,  8.85it/s] 19%|█▊        | 15/81 [00:04<00:07,  9.09it/s] 20%|█▉        | 16/81 [00:04<00:07,  9.23it/s] 21%|██        | 17/81 [00:04<00:06,  9.32it/s] 22%|██▏       | 18/81 [00:04<00:06,  9.39it/s] 23%|██▎       | 19/81 [00:04<00:06,  9.43it/s] 25%|██▍       | 20/81 [00:04<00:06,  9.47it/s] 26%|██▌       | 21/81 [00:04<00:06,  9.52it/s] 27%|██▋       | 22/81 [00:04<00:06,  9.56it/s] 28%|██▊       | 23/81 [00:05<00:06,  9.59it/s] 30%|██▉       | 24/81 [00:05<00:05,  9.59it/s] 31%|███       | 25/81 [00:05<00:05,  9.58it/s] 32%|███▏      | 26/81 [00:05<00:05,  9.55it/s] 33%|███▎      | 27/81 [00:05<00:05,  9.56it/s] 35%|███▍      | 28/81 [00:05<00:05,  9.55it/s] 36%|███▌      | 29/81 [00:05<00:05,  9.55it/s] 37%|███▋      | 30/81 [00:05<00:05,  9.57it/s] 38%|███▊      | 31/81 [00:05<00:05,  9.60it/s] 40%|███▉      | 32/81 [00:06<00:05,  9.60it/s] 41%|████      | 33/81 [00:06<00:05,  9.58it/s] 42%|████▏     | 34/81 [00:06<00:04,  9.57it/s] 43%|████▎     | 35/81 [00:06<00:04,  9.55it/s] 44%|████▍     | 36/81 [00:06<00:04,  9.55it/s] 46%|████▌     | 37/81 [00:06<00:04,  9.55it/s] 47%|████▋     | 38/81 [00:06<00:04,  9.50it/s] 48%|████▊     | 39/81 [00:06<00:04,  9.54it/s] 49%|████▉     | 40/81 [00:06<00:04,  9.56it/s] 51%|█████     | 41/81 [00:06<00:04,  9.55it/s] 52%|█████▏    | 42/81 [00:07<00:04,  9.55it/s] 53%|█████▎    | 43/81 [00:07<00:03,  9.54it/s] 54%|█████▍    | 44/81 [00:07<00:03,  9.54it/s] 56%|█████▌    | 45/81 [00:07<00:03,  9.55it/s] 57%|█████▋    | 46/81 [00:07<00:03,  9.57it/s] 58%|█████▊    | 47/81 [00:07<00:03,  9.60it/s] 59%|█████▉    | 48/81 [00:07<00:03,  9.58it/s] 60%|██████    | 49/81 [00:07<00:03,  9.57it/s] 62%|██████▏   | 50/81 [00:07<00:03,  9.57it/s] 63%|██████▎   | 51/81 [00:08<00:03,  9.55it/s] 64%|██████▍   | 52/81 [00:08<00:03,  9.50it/s] 65%|██████▌   | 53/81 [00:08<00:02,  9.52it/s] 67%|██████▋   | 54/81 [00:08<00:02,  9.55it/s] 68%|██████▊   | 55/81 [00:08<00:02,  9.58it/s] 69%|██████▉   | 56/81 [00:08<00:02,  9.57it/s] 70%|███████   | 57/81 [00:08<00:02,  9.56it/s] 72%|███████▏  | 58/81 [00:08<00:02,  9.57it/s] 73%|███████▎  | 59/81 [00:08<00:02,  9.56it/s] 74%|███████▍  | 60/81 [00:08<00:02,  9.55it/s] 75%|███████▌  | 61/81 [00:09<00:02,  9.55it/s] 77%|███████▋  | 62/81 [00:09<00:01,  9.57it/s] 78%|███████▊  | 63/81 [00:09<00:01,  9.59it/s] 79%|███████▉  | 64/81 [00:09<00:01,  9.58it/s] 80%|████████  | 65/81 [00:09<00:01,  9.57it/s] 81%|████████▏ | 66/81 [00:09<00:01,  9.56it/s] 83%|████████▎ | 67/81 [00:09<00:01,  9.58it/s] 84%|████████▍ | 68/81 [00:09<00:01,  9.60it/s] 85%|████████▌ | 69/81 [00:09<00:01,  9.61it/s] 86%|████████▋ | 70/81 [00:10<00:01,  9.62it/s] 88%|████████▊ | 71/81 [00:10<00:01,  9.64it/s] 89%|████████▉ | 72/81 [00:10<00:00,  9.64it/s] 90%|█████████ | 73/81 [00:10<00:00,  9.64it/s] 91%|█████████▏| 74/81 [00:10<00:00,  9.65it/s] 93%|█████████▎| 75/81 [00:10<00:00,  9.65it/s] 94%|█████████▍| 76/81 [00:10<00:00,  9.65it/s] 95%|█████████▌| 77/81 [00:10<00:00,  9.66it/s] 96%|█████████▋| 78/81 [00:10<00:00,  9.65it/s] 98%|█████████▊| 79/81 [00:10<00:00,  9.62it/s] 99%|█████████▉| 80/81 [00:11<00:00,  9.62it/s]100%|██████████| 81/81 [00:11<00:00,  9.63it/s]100%|██████████| 81/81 [00:11<00:00,  7.21it/s]
=> result
* total: 8,100
* correct: 2,309
* accuracy: 28.5%
* error: 71.5%
* macro_f1: 25.4%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh ucf101 eurosat 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_ucf101/eurosat/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_ucf101/eurosat/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_3.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/ucf101/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:02<03:37,  2.72s/it]  2%|▏         | 2/81 [00:02<01:33,  1.18s/it]  4%|▎         | 3/81 [00:02<00:53,  1.45it/s]  5%|▍         | 4/81 [00:03<00:35,  2.18it/s]  6%|▌         | 5/81 [00:03<00:25,  3.02it/s]  7%|▋         | 6/81 [00:03<00:19,  3.93it/s]  9%|▊         | 7/81 [00:03<00:15,  4.88it/s] 10%|▉         | 8/81 [00:03<00:12,  5.78it/s] 11%|█         | 9/81 [00:03<00:10,  6.59it/s] 12%|█▏        | 10/81 [00:03<00:09,  7.28it/s] 14%|█▎        | 11/81 [00:03<00:08,  7.86it/s] 15%|█▍        | 12/81 [00:03<00:08,  8.30it/s] 16%|█▌        | 13/81 [00:03<00:07,  8.64it/s] 17%|█▋        | 14/81 [00:04<00:07,  8.91it/s] 19%|█▊        | 15/81 [00:04<00:07,  9.11it/s] 20%|█▉        | 16/81 [00:04<00:07,  9.24it/s] 21%|██        | 17/81 [00:04<00:06,  9.33it/s] 22%|██▏       | 18/81 [00:04<00:06,  9.40it/s] 23%|██▎       | 19/81 [00:04<00:06,  9.44it/s] 25%|██▍       | 20/81 [00:04<00:06,  9.46it/s] 26%|██▌       | 21/81 [00:04<00:06,  9.48it/s] 27%|██▋       | 22/81 [00:04<00:06,  9.49it/s] 28%|██▊       | 23/81 [00:05<00:06,  9.53it/s] 30%|██▉       | 24/81 [00:05<00:05,  9.54it/s] 31%|███       | 25/81 [00:05<00:05,  9.54it/s] 32%|███▏      | 26/81 [00:05<00:05,  9.54it/s] 33%|███▎      | 27/81 [00:05<00:05,  9.55it/s] 35%|███▍      | 28/81 [00:05<00:05,  9.55it/s] 36%|███▌      | 29/81 [00:05<00:05,  9.54it/s] 37%|███▋      | 30/81 [00:05<00:05,  9.55it/s] 38%|███▊      | 31/81 [00:05<00:05,  9.57it/s] 40%|███▉      | 32/81 [00:05<00:05,  9.56it/s] 41%|████      | 33/81 [00:06<00:05,  9.56it/s] 42%|████▏     | 34/81 [00:06<00:04,  9.57it/s] 43%|████▎     | 35/81 [00:06<00:04,  9.58it/s] 44%|████▍     | 36/81 [00:06<00:04,  9.57it/s] 46%|████▌     | 37/81 [00:06<00:04,  9.56it/s] 47%|████▋     | 38/81 [00:06<00:04,  9.55it/s] 48%|████▊     | 39/81 [00:06<00:04,  9.58it/s] 49%|████▉     | 40/81 [00:06<00:04,  9.59it/s] 51%|█████     | 41/81 [00:06<00:04,  9.56it/s] 52%|█████▏    | 42/81 [00:07<00:04,  9.58it/s] 53%|█████▎    | 43/81 [00:07<00:03,  9.57it/s] 54%|█████▍    | 44/81 [00:07<00:03,  9.57it/s] 56%|█████▌    | 45/81 [00:07<00:03,  9.55it/s] 57%|█████▋    | 46/81 [00:07<00:03,  9.55it/s] 58%|█████▊    | 47/81 [00:07<00:03,  9.57it/s] 59%|█████▉    | 48/81 [00:07<00:03,  9.58it/s] 60%|██████    | 49/81 [00:07<00:03,  9.57it/s] 62%|██████▏   | 50/81 [00:07<00:03,  9.58it/s] 63%|██████▎   | 51/81 [00:07<00:03,  9.57it/s] 64%|██████▍   | 52/81 [00:08<00:03,  9.57it/s] 65%|██████▌   | 53/81 [00:08<00:02,  9.56it/s] 67%|██████▋   | 54/81 [00:08<00:02,  9.56it/s] 68%|██████▊   | 55/81 [00:08<00:02,  9.58it/s] 69%|██████▉   | 56/81 [00:08<00:02,  9.49it/s] 70%|███████   | 57/81 [00:08<00:02,  9.52it/s] 72%|███████▏  | 58/81 [00:08<00:02,  9.54it/s] 73%|███████▎  | 59/81 [00:08<00:02,  9.56it/s] 74%|███████▍  | 60/81 [00:08<00:02,  9.55it/s] 75%|███████▌  | 61/81 [00:08<00:02,  9.55it/s] 77%|███████▋  | 62/81 [00:09<00:01,  9.55it/s] 78%|███████▊  | 63/81 [00:09<00:01,  9.57it/s] 79%|███████▉  | 64/81 [00:09<00:01,  9.57it/s] 80%|████████  | 65/81 [00:09<00:01,  9.56it/s] 81%|████████▏ | 66/81 [00:09<00:01,  9.58it/s] 83%|████████▎ | 67/81 [00:09<00:01,  9.60it/s] 84%|████████▍ | 68/81 [00:09<00:01,  9.61it/s] 85%|████████▌ | 69/81 [00:09<00:01,  9.62it/s] 86%|████████▋ | 70/81 [00:09<00:01,  9.63it/s] 88%|████████▊ | 71/81 [00:10<00:01,  9.63it/s] 89%|████████▉ | 72/81 [00:10<00:00,  9.62it/s] 90%|█████████ | 73/81 [00:10<00:00,  9.62it/s] 91%|█████████▏| 74/81 [00:10<00:00,  9.62it/s] 93%|█████████▎| 75/81 [00:10<00:00,  9.63it/s] 94%|█████████▍| 76/81 [00:10<00:00,  9.63it/s] 95%|█████████▌| 77/81 [00:10<00:00,  9.62it/s] 96%|█████████▋| 78/81 [00:10<00:00,  9.62it/s] 98%|█████████▊| 79/81 [00:10<00:00,  9.63it/s] 99%|█████████▉| 80/81 [00:10<00:00,  9.62it/s]100%|██████████| 81/81 [00:11<00:00,  9.62it/s]100%|██████████| 81/81 [00:11<00:00,  7.26it/s]
=> result
* total: 8,100
* correct: 2,719
* accuracy: 33.6%
* error: 66.4%
* macro_f1: 23.7%

set -e
set -x

eval "$(conda shell.bash hook)"
++ conda shell.bash hook
+ eval 'export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We're not allowing PS1 to be unbound. It must at least be set.
    # However, we're not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi
++ '[' -z x ']'

conda activate base
++ conda activate base
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate base
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate base
+++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate base
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(base) '
+++ PS1='(base) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
+++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
+++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda'
+++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda
+++ CONDA_PREFIX=/home/s2/mjoolee/anaconda
export CONDA_SHLVL='3'
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
export CONDA_DEFAULT_ENV='base'
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
export CONDA_PROMPT_MODIFIER='(base) '
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
export CONDA_PREFIX_2='/home/s2/mjoolee/anaconda/envs/dassl'
+++ export CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
+++ CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
+++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
+++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
+++ export _CE_M=
+++ _CE_M=
export _CE_CONDA=''
+++ export _CE_CONDA=
+++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
+++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
conda activate dassl
+ conda activate dassl
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate dassl
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate dassl
++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate dassl
+ ask_conda='PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
+ eval 'PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(dassl) '
++ PS1='(dassl) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda/envs/dassl'
++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
++ CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_SHLVL='4'
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
export CONDA_DEFAULT_ENV='dassl'
++ export CONDA_DEFAULT_ENV=dassl
++ CONDA_DEFAULT_ENV=dassl
export CONDA_PROMPT_MODIFIER='(dassl) '
++ export 'CONDA_PROMPT_MODIFIER=(dassl) '
++ CONDA_PROMPT_MODIFIER='(dassl) '
export CONDA_PREFIX_3='/home/s2/mjoolee/anaconda'
++ export CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
++ CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r

GPU=0
+ GPU=0
SHOT=16
+ SHOT=16
EPOCH=200
+ EPOCH=200
cfg=vit_b16_ctxv1
+ cfg=vit_b16_ctxv1
TRAINER=CoOp
+ TRAINER=CoOp


for seed in 1 2 3
 do
     #training
     sh scripts/coop/crossdataset_train.sh oxford_flowers ${seed} ${GPU} ${cfg} ${SHOT} ${TRAINER}
 done         
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_train.sh oxford_flowers 1 0 vit_b16_ctxv1 16 CoOp
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_1.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/200] batch [5/51] time 0.086 (0.577) data 0.000 (0.192) loss 2.0898 (2.3488) acc 56.2500 (53.7500) lr 1.0000e-05 eta 1:38:00
epoch [1/200] batch [10/51] time 0.085 (0.331) data 0.000 (0.096) loss 1.5879 (2.1114) acc 53.1250 (55.3125) lr 1.0000e-05 eta 0:56:16
epoch [1/200] batch [15/51] time 0.086 (0.250) data 0.000 (0.064) loss 2.4277 (2.0589) acc 43.7500 (56.8750) lr 1.0000e-05 eta 0:42:21
epoch [1/200] batch [20/51] time 0.086 (0.209) data 0.000 (0.048) loss 1.9326 (2.0612) acc 59.3750 (57.9688) lr 1.0000e-05 eta 0:35:23
epoch [1/200] batch [25/51] time 0.085 (0.184) data 0.000 (0.039) loss 0.9541 (1.9845) acc 75.0000 (59.2500) lr 1.0000e-05 eta 0:31:12
epoch [1/200] batch [30/51] time 0.086 (0.168) data 0.000 (0.032) loss 2.3887 (1.9840) acc 59.3750 (60.1042) lr 1.0000e-05 eta 0:28:26
epoch [1/200] batch [35/51] time 0.086 (0.156) data 0.000 (0.028) loss 2.1719 (1.9780) acc 59.3750 (60.7143) lr 1.0000e-05 eta 0:26:26
epoch [1/200] batch [40/51] time 0.085 (0.147) data 0.000 (0.024) loss 2.0996 (1.9714) acc 62.5000 (60.6250) lr 1.0000e-05 eta 0:24:56
epoch [1/200] batch [45/51] time 0.085 (0.140) data 0.000 (0.022) loss 2.4141 (1.9665) acc 56.2500 (61.1806) lr 1.0000e-05 eta 0:23:44
epoch [1/200] batch [50/51] time 0.085 (0.135) data 0.000 (0.019) loss 2.6152 (1.9854) acc 50.0000 (61.1875) lr 1.0000e-05 eta 0:22:48
epoch [2/200] batch [5/51] time 0.086 (0.224) data 0.000 (0.137) loss 1.8965 (1.7355) acc 50.0000 (60.6250) lr 2.0000e-03 eta 0:37:48
epoch [2/200] batch [10/51] time 0.086 (0.155) data 0.000 (0.069) loss 0.7910 (1.5797) acc 78.1250 (62.1875) lr 2.0000e-03 eta 0:26:10
epoch [2/200] batch [15/51] time 0.085 (0.132) data 0.000 (0.046) loss 1.7354 (1.5555) acc 62.5000 (62.7083) lr 2.0000e-03 eta 0:22:14
epoch [2/200] batch [20/51] time 0.088 (0.120) data 0.000 (0.034) loss 2.1953 (1.5633) acc 46.8750 (62.1875) lr 2.0000e-03 eta 0:20:18
epoch [2/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.028) loss 1.3330 (1.5266) acc 75.0000 (63.1250) lr 2.0000e-03 eta 0:19:07
epoch [2/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.023) loss 0.8926 (1.5162) acc 71.8750 (62.5000) lr 2.0000e-03 eta 0:18:21
epoch [2/200] batch [35/51] time 0.085 (0.106) data 0.000 (0.020) loss 0.9902 (1.4704) acc 71.8750 (63.5714) lr 2.0000e-03 eta 0:17:47
epoch [2/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 1.7021 (1.4877) acc 62.5000 (63.5938) lr 2.0000e-03 eta 0:17:20
epoch [2/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 1.1279 (1.4753) acc 68.7500 (64.0972) lr 2.0000e-03 eta 0:16:59
epoch [2/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.014) loss 1.2637 (1.4624) acc 71.8750 (64.4375) lr 2.0000e-03 eta 0:16:43
epoch [3/200] batch [5/51] time 0.086 (0.211) data 0.000 (0.125) loss 1.1611 (1.1982) acc 65.6250 (67.5000) lr 1.9999e-03 eta 0:35:32
epoch [3/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 1.0283 (1.1155) acc 75.0000 (69.6875) lr 1.9999e-03 eta 0:24:58
epoch [3/200] batch [15/51] time 0.085 (0.128) data 0.000 (0.042) loss 0.9868 (1.1200) acc 62.5000 (68.5417) lr 1.9999e-03 eta 0:21:25
epoch [3/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.031) loss 0.5322 (1.0763) acc 84.3750 (70.6250) lr 1.9999e-03 eta 0:19:41
epoch [3/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.025) loss 0.9795 (1.0847) acc 78.1250 (70.8750) lr 1.9999e-03 eta 0:18:38
epoch [3/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.021) loss 0.5371 (1.0723) acc 90.6250 (71.2500) lr 1.9999e-03 eta 0:17:55
epoch [3/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.018) loss 1.0586 (1.0864) acc 65.6250 (70.9821) lr 1.9999e-03 eta 0:17:25
epoch [3/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 1.5156 (1.0807) acc 65.6250 (71.3281) lr 1.9999e-03 eta 0:17:01
epoch [3/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.8999 (1.0666) acc 78.1250 (71.5278) lr 1.9999e-03 eta 0:16:42
epoch [3/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.013) loss 1.0635 (1.0643) acc 78.1250 (71.8125) lr 1.9999e-03 eta 0:16:27
epoch [4/200] batch [5/51] time 0.086 (0.212) data 0.000 (0.126) loss 1.1006 (1.0285) acc 65.6250 (69.3750) lr 1.9995e-03 eta 0:35:32
epoch [4/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.063) loss 1.2949 (1.0937) acc 62.5000 (69.3750) lr 1.9995e-03 eta 0:24:58
epoch [4/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.042) loss 0.8579 (1.0203) acc 75.0000 (71.0417) lr 1.9995e-03 eta 0:21:25
epoch [4/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.032) loss 0.7656 (0.9568) acc 84.3750 (73.4375) lr 1.9995e-03 eta 0:19:39
epoch [4/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.025) loss 0.5742 (0.9475) acc 84.3750 (73.7500) lr 1.9995e-03 eta 0:18:36
epoch [4/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.021) loss 0.7832 (0.9211) acc 75.0000 (74.3750) lr 1.9995e-03 eta 0:17:54
epoch [4/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 1.3027 (0.9502) acc 65.6250 (73.8393) lr 1.9995e-03 eta 0:17:24
epoch [4/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.8848 (0.9110) acc 78.1250 (75.0000) lr 1.9995e-03 eta 0:17:00
epoch [4/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 1.3643 (0.9020) acc 65.6250 (75.2083) lr 1.9995e-03 eta 0:16:41
epoch [4/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.4536 (0.8828) acc 90.6250 (75.6875) lr 1.9995e-03 eta 0:16:26
epoch [5/200] batch [5/51] time 0.086 (0.198) data 0.000 (0.110) loss 1.0205 (0.8272) acc 78.1250 (77.5000) lr 1.9989e-03 eta 0:32:58
epoch [5/200] batch [10/51] time 0.086 (0.142) data 0.000 (0.055) loss 0.5146 (0.7806) acc 78.1250 (77.5000) lr 1.9989e-03 eta 0:23:41
epoch [5/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.9980 (0.7765) acc 65.6250 (76.8750) lr 1.9989e-03 eta 0:20:34
epoch [5/200] batch [20/51] time 0.086 (0.114) data 0.000 (0.028) loss 0.6494 (0.8012) acc 78.1250 (76.7188) lr 1.9989e-03 eta 0:19:01
epoch [5/200] batch [25/51] time 0.085 (0.109) data 0.000 (0.022) loss 0.7104 (0.7875) acc 87.5000 (77.2500) lr 1.9989e-03 eta 0:18:03
epoch [5/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.8735 (0.7691) acc 68.7500 (78.0208) lr 1.9989e-03 eta 0:17:26
epoch [5/200] batch [35/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.4990 (0.7559) acc 87.5000 (78.5714) lr 1.9989e-03 eta 0:16:59
epoch [5/200] batch [40/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.6318 (0.7584) acc 81.2500 (78.3594) lr 1.9989e-03 eta 0:16:38
epoch [5/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.8604 (0.7693) acc 68.7500 (78.5417) lr 1.9989e-03 eta 0:16:21
epoch [5/200] batch [50/51] time 0.085 (0.097) data 0.000 (0.011) loss 0.6831 (0.7948) acc 75.0000 (77.8125) lr 1.9989e-03 eta 0:16:07
epoch [6/200] batch [5/51] time 0.086 (0.220) data 0.000 (0.134) loss 0.9067 (0.7318) acc 71.8750 (79.3750) lr 1.9980e-03 eta 0:36:27
epoch [6/200] batch [10/51] time 0.086 (0.153) data 0.000 (0.067) loss 0.7939 (0.7976) acc 78.1250 (76.8750) lr 1.9980e-03 eta 0:25:24
epoch [6/200] batch [15/51] time 0.085 (0.131) data 0.000 (0.045) loss 0.5308 (0.7379) acc 81.2500 (78.9583) lr 1.9980e-03 eta 0:21:42
epoch [6/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.034) loss 0.4722 (0.7317) acc 84.3750 (79.8438) lr 1.9980e-03 eta 0:19:49
epoch [6/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.027) loss 0.5703 (0.7244) acc 71.8750 (79.5000) lr 1.9980e-03 eta 0:18:42
epoch [6/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.023) loss 0.6924 (0.7377) acc 78.1250 (79.2708) lr 1.9980e-03 eta 0:17:57
epoch [6/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.8325 (0.7323) acc 81.2500 (79.7321) lr 1.9980e-03 eta 0:17:25
epoch [6/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.7046 (0.7316) acc 78.1250 (79.3750) lr 1.9980e-03 eta 0:17:00
epoch [6/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.6685 (0.7238) acc 81.2500 (79.5139) lr 1.9980e-03 eta 0:16:40
epoch [6/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.014) loss 0.4956 (0.7127) acc 93.7500 (79.9375) lr 1.9980e-03 eta 0:16:24
epoch [7/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.111) loss 0.9287 (0.7687) acc 75.0000 (78.7500) lr 1.9969e-03 eta 0:32:53
epoch [7/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.3860 (0.7136) acc 90.6250 (81.2500) lr 1.9969e-03 eta 0:23:35
epoch [7/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.4556 (0.6575) acc 87.5000 (82.9167) lr 1.9969e-03 eta 0:20:28
epoch [7/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4326 (0.6666) acc 87.5000 (82.5000) lr 1.9969e-03 eta 0:18:55
epoch [7/200] batch [25/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.6934 (0.6621) acc 78.1250 (82.3750) lr 1.9969e-03 eta 0:17:59
epoch [7/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.7549 (0.6897) acc 81.2500 (81.6667) lr 1.9969e-03 eta 0:17:21
epoch [7/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4001 (0.6671) acc 87.5000 (82.1429) lr 1.9969e-03 eta 0:16:55
epoch [7/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.6895 (0.6848) acc 78.1250 (81.4844) lr 1.9969e-03 eta 0:16:33
epoch [7/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4421 (0.6782) acc 87.5000 (81.7361) lr 1.9969e-03 eta 0:16:16
epoch [7/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.6426 (0.6834) acc 78.1250 (81.5625) lr 1.9969e-03 eta 0:16:03
epoch [8/200] batch [5/51] time 0.086 (0.216) data 0.000 (0.129) loss 0.5068 (0.6251) acc 87.5000 (82.5000) lr 1.9956e-03 eta 0:35:21
epoch [8/200] batch [10/51] time 0.086 (0.151) data 0.000 (0.065) loss 0.6328 (0.6395) acc 81.2500 (82.1875) lr 1.9956e-03 eta 0:24:46
epoch [8/200] batch [15/51] time 0.088 (0.130) data 0.000 (0.043) loss 0.6196 (0.7043) acc 81.2500 (80.8333) lr 1.9956e-03 eta 0:21:13
epoch [8/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.7256 (0.6704) acc 75.0000 (81.7188) lr 1.9956e-03 eta 0:19:26
epoch [8/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.026) loss 0.7329 (0.6749) acc 87.5000 (82.2500) lr 1.9956e-03 eta 0:18:21
epoch [8/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.022) loss 0.4429 (0.6621) acc 87.5000 (83.0208) lr 1.9956e-03 eta 0:17:38
epoch [8/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.8452 (0.6866) acc 75.0000 (82.5893) lr 1.9956e-03 eta 0:17:08
epoch [8/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.9399 (0.6841) acc 65.6250 (81.7188) lr 1.9956e-03 eta 0:16:44
epoch [8/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.8496 (0.6921) acc 81.2500 (81.5278) lr 1.9956e-03 eta 0:16:25
epoch [8/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3611 (0.6879) acc 90.6250 (81.5625) lr 1.9956e-03 eta 0:16:10
epoch [9/200] batch [5/51] time 0.086 (0.214) data 0.000 (0.127) loss 0.3879 (0.5584) acc 87.5000 (85.0000) lr 1.9940e-03 eta 0:34:59
epoch [9/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.4282 (0.5496) acc 87.5000 (85.3125) lr 1.9940e-03 eta 0:24:36
epoch [9/200] batch [15/51] time 0.086 (0.129) data 0.000 (0.043) loss 0.4763 (0.6029) acc 87.5000 (84.7917) lr 1.9940e-03 eta 0:21:05
epoch [9/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.6025 (0.5978) acc 93.7500 (84.6875) lr 1.9940e-03 eta 0:19:21
epoch [9/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.026) loss 0.4497 (0.6171) acc 87.5000 (84.0000) lr 1.9940e-03 eta 0:18:17
epoch [9/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.021) loss 0.4412 (0.6106) acc 87.5000 (84.3750) lr 1.9940e-03 eta 0:17:35
epoch [9/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.5942 (0.6173) acc 84.3750 (83.7500) lr 1.9940e-03 eta 0:17:05
epoch [9/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4358 (0.6088) acc 90.6250 (84.2188) lr 1.9940e-03 eta 0:16:40
epoch [9/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.7808 (0.6069) acc 75.0000 (84.0972) lr 1.9940e-03 eta 0:16:21
epoch [9/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4717 (0.6029) acc 84.3750 (84.1875) lr 1.9940e-03 eta 0:16:06
epoch [10/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.3962 (0.5708) acc 90.6250 (85.6250) lr 1.9921e-03 eta 0:33:01
epoch [10/200] batch [10/51] time 0.088 (0.145) data 0.000 (0.058) loss 0.6206 (0.6088) acc 87.5000 (84.6875) lr 1.9921e-03 eta 0:23:34
epoch [10/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.4614 (0.5496) acc 87.5000 (85.0000) lr 1.9921e-03 eta 0:20:25
epoch [10/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.5303 (0.5452) acc 90.6250 (85.6250) lr 1.9921e-03 eta 0:18:49
epoch [10/200] batch [25/51] time 0.089 (0.110) data 0.000 (0.023) loss 0.5830 (0.5433) acc 81.2500 (85.5000) lr 1.9921e-03 eta 0:17:53
epoch [10/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.020) loss 0.8193 (0.5748) acc 84.3750 (85.2083) lr 1.9921e-03 eta 0:17:14
epoch [10/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3462 (0.5701) acc 93.7500 (85.3571) lr 1.9921e-03 eta 0:16:46
epoch [10/200] batch [40/51] time 0.088 (0.102) data 0.000 (0.015) loss 0.3894 (0.5568) acc 87.5000 (85.3906) lr 1.9921e-03 eta 0:16:25
epoch [10/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.5688 (0.5440) acc 87.5000 (85.5556) lr 1.9921e-03 eta 0:16:07
epoch [10/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.5923 (0.5497) acc 84.3750 (85.5000) lr 1.9921e-03 eta 0:15:53
epoch [11/200] batch [5/51] time 0.088 (0.211) data 0.000 (0.122) loss 1.1396 (0.6559) acc 75.0000 (81.8750) lr 1.9900e-03 eta 0:34:00
epoch [11/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.061) loss 0.6372 (0.5757) acc 81.2500 (84.0625) lr 1.9900e-03 eta 0:23:59
epoch [11/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.5225 (0.5648) acc 87.5000 (84.7917) lr 1.9900e-03 eta 0:20:39
epoch [11/200] batch [20/51] time 0.088 (0.118) data 0.000 (0.031) loss 0.4595 (0.5646) acc 84.3750 (85.1562) lr 1.9900e-03 eta 0:18:59
epoch [11/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3574 (0.5625) acc 87.5000 (86.0000) lr 1.9900e-03 eta 0:17:59
epoch [11/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.6304 (0.5552) acc 81.2500 (86.1458) lr 1.9900e-03 eta 0:17:19
epoch [11/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.6299 (0.5667) acc 81.2500 (85.5357) lr 1.9900e-03 eta 0:16:50
epoch [11/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.4702 (0.5656) acc 81.2500 (85.3125) lr 1.9900e-03 eta 0:16:27
epoch [11/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.9980 (0.5662) acc 75.0000 (85.2083) lr 1.9900e-03 eta 0:16:09
epoch [11/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.9873 (0.5771) acc 71.8750 (84.8125) lr 1.9900e-03 eta 0:15:54
epoch [12/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.6982 (0.6012) acc 93.7500 (87.5000) lr 1.9877e-03 eta 0:32:10
epoch [12/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.4500 (0.5872) acc 87.5000 (86.2500) lr 1.9877e-03 eta 0:23:03
epoch [12/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.4795 (0.5782) acc 87.5000 (86.0417) lr 1.9877e-03 eta 0:20:01
epoch [12/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.7383 (0.5977) acc 78.1250 (84.5312) lr 1.9877e-03 eta 0:18:30
epoch [12/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.6172 (0.5828) acc 84.3750 (85.0000) lr 1.9877e-03 eta 0:17:34
epoch [12/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3682 (0.5709) acc 90.6250 (85.0000) lr 1.9877e-03 eta 0:16:57
epoch [12/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2715 (0.5428) acc 93.7500 (85.8036) lr 1.9877e-03 eta 0:16:31
epoch [12/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.8047 (0.5407) acc 68.7500 (85.4688) lr 1.9877e-03 eta 0:16:10
epoch [12/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4094 (0.5289) acc 93.7500 (85.9028) lr 1.9877e-03 eta 0:15:53
epoch [12/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.7969 (0.5310) acc 78.1250 (85.9375) lr 1.9877e-03 eta 0:15:40
epoch [13/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.5117 (0.4682) acc 81.2500 (86.2500) lr 1.9851e-03 eta 0:31:56
epoch [13/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.4668 (0.4868) acc 84.3750 (86.2500) lr 1.9851e-03 eta 0:22:53
epoch [13/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.4597 (0.4837) acc 84.3750 (86.2500) lr 1.9851e-03 eta 0:19:50
epoch [13/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3357 (0.5004) acc 84.3750 (85.4688) lr 1.9851e-03 eta 0:18:21
epoch [13/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.3267 (0.5225) acc 96.8750 (84.5000) lr 1.9851e-03 eta 0:17:25
epoch [13/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.2915 (0.5319) acc 90.6250 (84.0625) lr 1.9851e-03 eta 0:16:48
epoch [13/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.6675 (0.5486) acc 78.1250 (83.8393) lr 1.9851e-03 eta 0:16:22
epoch [13/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.4902 (0.5454) acc 81.2500 (83.8281) lr 1.9851e-03 eta 0:16:01
epoch [13/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.4023 (0.5444) acc 90.6250 (84.2361) lr 1.9851e-03 eta 0:15:44
epoch [13/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.5049 (0.5461) acc 90.6250 (84.3125) lr 1.9851e-03 eta 0:15:31
epoch [14/200] batch [5/51] time 0.086 (0.222) data 0.000 (0.136) loss 0.3142 (0.4640) acc 93.7500 (87.5000) lr 1.9823e-03 eta 0:35:16
epoch [14/200] batch [10/51] time 0.086 (0.154) data 0.000 (0.068) loss 0.4148 (0.4693) acc 87.5000 (87.1875) lr 1.9823e-03 eta 0:24:30
epoch [14/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.4902 (0.4448) acc 84.3750 (87.9167) lr 1.9823e-03 eta 0:20:54
epoch [14/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.034) loss 0.2864 (0.4647) acc 93.7500 (87.8125) lr 1.9823e-03 eta 0:19:05
epoch [14/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.4917 (0.4794) acc 84.3750 (87.5000) lr 1.9823e-03 eta 0:18:00
epoch [14/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.6055 (0.4849) acc 90.6250 (87.5000) lr 1.9823e-03 eta 0:17:16
epoch [14/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.020) loss 0.3635 (0.4930) acc 96.8750 (87.4107) lr 1.9823e-03 eta 0:16:45
epoch [14/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.6631 (0.5012) acc 78.1250 (86.6406) lr 1.9823e-03 eta 0:16:21
epoch [14/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.7236 (0.5013) acc 78.1250 (86.3194) lr 1.9823e-03 eta 0:16:01
epoch [14/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.6157 (0.5008) acc 84.3750 (86.1250) lr 1.9823e-03 eta 0:15:45
epoch [15/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.112) loss 0.5625 (0.4430) acc 90.6250 (86.2500) lr 1.9792e-03 eta 0:31:30
epoch [15/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.4058 (0.4624) acc 87.5000 (85.9375) lr 1.9792e-03 eta 0:22:35
epoch [15/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.038) loss 0.4944 (0.5050) acc 84.3750 (85.0000) lr 1.9792e-03 eta 0:19:36
epoch [15/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.6362 (0.5261) acc 84.3750 (84.5312) lr 1.9792e-03 eta 0:18:07
epoch [15/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.6084 (0.5148) acc 81.2500 (85.0000) lr 1.9792e-03 eta 0:17:14
epoch [15/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 1.0195 (0.5313) acc 71.8750 (84.0625) lr 1.9792e-03 eta 0:16:39
epoch [15/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4551 (0.5283) acc 87.5000 (84.4643) lr 1.9792e-03 eta 0:16:13
epoch [15/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2162 (0.5396) acc 100.0000 (84.8438) lr 1.9792e-03 eta 0:15:53
epoch [15/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.6226 (0.5252) acc 78.1250 (85.2778) lr 1.9792e-03 eta 0:15:37
epoch [15/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.5591 (0.5287) acc 90.6250 (85.3125) lr 1.9792e-03 eta 0:15:24
epoch [16/200] batch [5/51] time 0.089 (0.199) data 0.000 (0.112) loss 0.7290 (0.6183) acc 81.2500 (85.6250) lr 1.9759e-03 eta 0:31:21
epoch [16/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.056) loss 0.6143 (0.5847) acc 81.2500 (85.6250) lr 1.9759e-03 eta 0:22:31
epoch [16/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.2634 (0.4950) acc 96.8750 (88.3333) lr 1.9759e-03 eta 0:19:31
epoch [16/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4619 (0.4917) acc 87.5000 (88.2812) lr 1.9759e-03 eta 0:18:04
epoch [16/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.7393 (0.5046) acc 81.2500 (87.8750) lr 1.9759e-03 eta 0:17:10
epoch [16/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.5215 (0.4795) acc 93.7500 (88.7500) lr 1.9759e-03 eta 0:16:34
epoch [16/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.6025 (0.4850) acc 87.5000 (88.7500) lr 1.9759e-03 eta 0:16:08
epoch [16/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5752 (0.4899) acc 87.5000 (88.5156) lr 1.9759e-03 eta 0:15:49
epoch [16/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4978 (0.4805) acc 84.3750 (88.6806) lr 1.9759e-03 eta 0:15:32
epoch [16/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3020 (0.4896) acc 90.6250 (88.6250) lr 1.9759e-03 eta 0:15:19
epoch [17/200] batch [5/51] time 0.089 (0.205) data 0.001 (0.116) loss 0.3455 (0.4707) acc 87.5000 (86.8750) lr 1.9724e-03 eta 0:32:06
epoch [17/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.058) loss 0.7202 (0.4696) acc 75.0000 (87.5000) lr 1.9724e-03 eta 0:22:55
epoch [17/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.2367 (0.4726) acc 96.8750 (87.2917) lr 1.9724e-03 eta 0:19:50
epoch [17/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.029) loss 0.5200 (0.4972) acc 87.5000 (86.4062) lr 1.9724e-03 eta 0:18:17
epoch [17/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.8213 (0.4895) acc 84.3750 (87.2500) lr 1.9724e-03 eta 0:17:20
epoch [17/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.5044 (0.4835) acc 93.7500 (87.5000) lr 1.9724e-03 eta 0:16:41
epoch [17/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.6528 (0.4910) acc 87.5000 (87.7679) lr 1.9724e-03 eta 0:16:14
epoch [17/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.6743 (0.4963) acc 71.8750 (87.1875) lr 1.9724e-03 eta 0:15:53
epoch [17/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5757 (0.5017) acc 87.5000 (87.1528) lr 1.9724e-03 eta 0:15:36
epoch [17/200] batch [50/51] time 0.089 (0.099) data 0.000 (0.012) loss 0.4548 (0.5037) acc 96.8750 (87.2500) lr 1.9724e-03 eta 0:15:22
epoch [18/200] batch [5/51] time 0.086 (0.211) data 0.000 (0.125) loss 0.4492 (0.4773) acc 87.5000 (86.2500) lr 1.9686e-03 eta 0:32:50
epoch [18/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 0.4797 (0.4426) acc 84.3750 (87.1875) lr 1.9686e-03 eta 0:23:07
epoch [18/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.042) loss 0.1963 (0.4477) acc 100.0000 (87.7083) lr 1.9686e-03 eta 0:19:53
epoch [18/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.5898 (0.4683) acc 81.2500 (86.8750) lr 1.9686e-03 eta 0:18:17
epoch [18/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.2974 (0.4776) acc 87.5000 (86.7500) lr 1.9686e-03 eta 0:17:18
epoch [18/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.6968 (0.4913) acc 93.7500 (86.4583) lr 1.9686e-03 eta 0:16:39
epoch [18/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.7261 (0.4989) acc 75.0000 (86.3393) lr 1.9686e-03 eta 0:16:11
epoch [18/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.6348 (0.4944) acc 84.3750 (86.4844) lr 1.9686e-03 eta 0:15:49
epoch [18/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 1.0361 (0.4894) acc 75.0000 (86.9444) lr 1.9686e-03 eta 0:15:32
epoch [18/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.6436 (0.4824) acc 87.5000 (87.3125) lr 1.9686e-03 eta 0:15:18
epoch [19/200] batch [5/51] time 0.088 (0.199) data 0.001 (0.112) loss 0.3062 (0.3418) acc 93.7500 (91.2500) lr 1.9646e-03 eta 0:30:48
epoch [19/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.056) loss 0.5669 (0.3271) acc 81.2500 (91.5625) lr 1.9646e-03 eta 0:22:06
epoch [19/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.4072 (0.3561) acc 87.5000 (90.2083) lr 1.9646e-03 eta 0:19:11
epoch [19/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.5986 (0.3967) acc 87.5000 (89.5312) lr 1.9646e-03 eta 0:17:44
epoch [19/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.2347 (0.3963) acc 96.8750 (89.6250) lr 1.9646e-03 eta 0:16:51
epoch [19/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.5942 (0.4062) acc 84.3750 (89.6875) lr 1.9646e-03 eta 0:16:15
epoch [19/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.5166 (0.4096) acc 84.3750 (89.6429) lr 1.9646e-03 eta 0:15:50
epoch [19/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4932 (0.4345) acc 90.6250 (89.2969) lr 1.9646e-03 eta 0:15:30
epoch [19/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.4431 (0.4420) acc 90.6250 (89.1667) lr 1.9646e-03 eta 0:15:14
epoch [19/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4058 (0.4376) acc 90.6250 (89.1250) lr 1.9646e-03 eta 0:15:01
epoch [20/200] batch [5/51] time 0.088 (0.202) data 0.000 (0.114) loss 0.3562 (0.4123) acc 84.3750 (88.1250) lr 1.9603e-03 eta 0:31:04
epoch [20/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.7041 (0.4467) acc 81.2500 (87.1875) lr 1.9603e-03 eta 0:22:11
epoch [20/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.3135 (0.4533) acc 90.6250 (87.2917) lr 1.9603e-03 eta 0:19:14
epoch [20/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.6426 (0.4420) acc 84.3750 (87.9688) lr 1.9603e-03 eta 0:17:45
epoch [20/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2869 (0.4121) acc 90.6250 (88.6250) lr 1.9603e-03 eta 0:16:51
epoch [20/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.4226 (0.4502) acc 90.6250 (87.0833) lr 1.9603e-03 eta 0:16:16
epoch [20/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.6323 (0.4680) acc 87.5000 (87.0536) lr 1.9603e-03 eta 0:15:50
epoch [20/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1523 (0.4610) acc 96.8750 (87.0312) lr 1.9603e-03 eta 0:15:30
epoch [20/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4258 (0.4637) acc 90.6250 (86.8750) lr 1.9603e-03 eta 0:15:14
epoch [20/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.5771 (0.4674) acc 84.3750 (86.7500) lr 1.9603e-03 eta 0:15:00
epoch [21/200] batch [5/51] time 0.088 (0.215) data 0.000 (0.127) loss 0.5137 (0.4391) acc 84.3750 (88.7500) lr 1.9558e-03 eta 0:32:50
epoch [21/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.063) loss 0.3757 (0.4367) acc 84.3750 (88.1250) lr 1.9558e-03 eta 0:23:03
epoch [21/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.042) loss 0.6611 (0.4722) acc 87.5000 (87.2917) lr 1.9558e-03 eta 0:19:47
epoch [21/200] batch [20/51] time 0.088 (0.119) data 0.000 (0.032) loss 0.5020 (0.4653) acc 87.5000 (87.1875) lr 1.9558e-03 eta 0:18:10
epoch [21/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.4712 (0.4605) acc 90.6250 (87.6250) lr 1.9558e-03 eta 0:17:11
epoch [21/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2048 (0.4467) acc 96.8750 (88.0208) lr 1.9558e-03 eta 0:16:32
epoch [21/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.5537 (0.4480) acc 75.0000 (87.8571) lr 1.9558e-03 eta 0:16:04
epoch [21/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.6152 (0.4517) acc 87.5000 (88.2812) lr 1.9558e-03 eta 0:15:41
epoch [21/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 1.0615 (0.4720) acc 84.3750 (87.7083) lr 1.9558e-03 eta 0:15:23
epoch [21/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4414 (0.4676) acc 90.6250 (88.1250) lr 1.9558e-03 eta 0:15:09
epoch [22/200] batch [5/51] time 0.088 (0.217) data 0.000 (0.129) loss 0.2622 (0.4129) acc 93.7500 (91.2500) lr 1.9511e-03 eta 0:33:03
epoch [22/200] batch [10/51] time 0.088 (0.153) data 0.000 (0.065) loss 0.2418 (0.4459) acc 90.6250 (88.7500) lr 1.9511e-03 eta 0:23:11
epoch [22/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.043) loss 0.4429 (0.4507) acc 81.2500 (88.7500) lr 1.9511e-03 eta 0:19:52
epoch [22/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.4038 (0.4519) acc 87.5000 (88.7500) lr 1.9511e-03 eta 0:18:12
epoch [22/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.9790 (0.4808) acc 84.3750 (88.3750) lr 1.9511e-03 eta 0:17:10
epoch [22/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2761 (0.4751) acc 90.6250 (88.2292) lr 1.9511e-03 eta 0:16:31
epoch [22/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3162 (0.4565) acc 90.6250 (88.8393) lr 1.9511e-03 eta 0:16:02
epoch [22/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.5498 (0.4563) acc 87.5000 (88.9062) lr 1.9511e-03 eta 0:15:38
epoch [22/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3826 (0.4591) acc 93.7500 (89.0278) lr 1.9511e-03 eta 0:15:20
epoch [22/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5928 (0.4611) acc 84.3750 (89.0000) lr 1.9511e-03 eta 0:15:06
epoch [23/200] batch [5/51] time 0.087 (0.220) data 0.000 (0.133) loss 0.5210 (0.4059) acc 87.5000 (90.6250) lr 1.9461e-03 eta 0:33:15
epoch [23/200] batch [10/51] time 0.086 (0.153) data 0.000 (0.067) loss 0.6523 (0.4633) acc 87.5000 (89.0625) lr 1.9461e-03 eta 0:23:10
epoch [23/200] batch [15/51] time 0.086 (0.131) data 0.000 (0.044) loss 0.4092 (0.4528) acc 84.3750 (88.9583) lr 1.9461e-03 eta 0:19:48
epoch [23/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3821 (0.4225) acc 90.6250 (90.0000) lr 1.9461e-03 eta 0:18:07
epoch [23/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.7578 (0.4176) acc 84.3750 (90.2500) lr 1.9461e-03 eta 0:17:06
epoch [23/200] batch [30/51] time 0.089 (0.109) data 0.000 (0.022) loss 0.4419 (0.4388) acc 90.6250 (89.6875) lr 1.9461e-03 eta 0:16:26
epoch [23/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2469 (0.4326) acc 90.6250 (89.5536) lr 1.9461e-03 eta 0:15:57
epoch [23/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.8667 (0.4333) acc 75.0000 (89.2969) lr 1.9461e-03 eta 0:15:34
epoch [23/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.4602 (0.4311) acc 90.6250 (89.4444) lr 1.9461e-03 eta 0:15:16
epoch [23/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3843 (0.4280) acc 87.5000 (89.3750) lr 1.9461e-03 eta 0:15:01
epoch [24/200] batch [5/51] time 0.088 (0.218) data 0.000 (0.130) loss 0.3108 (0.4131) acc 93.7500 (89.3750) lr 1.9409e-03 eta 0:32:48
epoch [24/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.065) loss 0.3203 (0.3760) acc 93.7500 (90.9375) lr 1.9409e-03 eta 0:22:57
epoch [24/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.7065 (0.3688) acc 84.3750 (91.2500) lr 1.9409e-03 eta 0:19:39
epoch [24/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.2676 (0.4298) acc 96.8750 (88.7500) lr 1.9409e-03 eta 0:18:00
epoch [24/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.4668 (0.4379) acc 90.6250 (88.7500) lr 1.9409e-03 eta 0:17:00
epoch [24/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.8574 (0.4506) acc 71.8750 (88.5417) lr 1.9409e-03 eta 0:16:20
epoch [24/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4795 (0.4533) acc 93.7500 (88.6607) lr 1.9409e-03 eta 0:15:52
epoch [24/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.2644 (0.4399) acc 90.6250 (88.8281) lr 1.9409e-03 eta 0:15:30
epoch [24/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5156 (0.4409) acc 90.6250 (88.7500) lr 1.9409e-03 eta 0:15:12
epoch [24/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3801 (0.4438) acc 87.5000 (88.7500) lr 1.9409e-03 eta 0:14:57
epoch [25/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.3572 (0.4910) acc 87.5000 (85.6250) lr 1.9354e-03 eta 0:30:26
epoch [25/200] batch [10/51] time 0.086 (0.145) data 0.000 (0.058) loss 0.4688 (0.4315) acc 87.5000 (88.1250) lr 1.9354e-03 eta 0:21:43
epoch [25/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.3645 (0.4402) acc 90.6250 (87.2917) lr 1.9354e-03 eta 0:18:49
epoch [25/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.5537 (0.4621) acc 84.3750 (87.3438) lr 1.9354e-03 eta 0:17:21
epoch [25/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2189 (0.4204) acc 93.7500 (88.7500) lr 1.9354e-03 eta 0:16:28
epoch [25/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.2458 (0.4233) acc 93.7500 (88.9583) lr 1.9354e-03 eta 0:15:53
epoch [25/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.6177 (0.4317) acc 81.2500 (88.6607) lr 1.9354e-03 eta 0:15:27
epoch [25/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.4385 (0.4287) acc 90.6250 (88.6719) lr 1.9354e-03 eta 0:15:07
epoch [25/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.4575 (0.4382) acc 87.5000 (88.6806) lr 1.9354e-03 eta 0:14:51
epoch [25/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.2971 (0.4366) acc 93.7500 (88.8750) lr 1.9354e-03 eta 0:14:37
epoch [26/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.3652 (0.4228) acc 90.6250 (88.1250) lr 1.9298e-03 eta 0:29:25
epoch [26/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.055) loss 0.2571 (0.3665) acc 93.7500 (90.0000) lr 1.9298e-03 eta 0:21:12
epoch [26/200] batch [15/51] time 0.088 (0.124) data 0.000 (0.037) loss 0.4692 (0.3936) acc 96.8750 (90.6250) lr 1.9298e-03 eta 0:18:27
epoch [26/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.5220 (0.4055) acc 96.8750 (91.0938) lr 1.9298e-03 eta 0:17:04
epoch [26/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.022) loss 0.4070 (0.4142) acc 90.6250 (90.7500) lr 1.9298e-03 eta 0:16:15
epoch [26/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.3596 (0.3971) acc 87.5000 (90.7292) lr 1.9298e-03 eta 0:15:41
epoch [26/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4072 (0.4100) acc 93.7500 (90.3571) lr 1.9298e-03 eta 0:15:17
epoch [26/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2993 (0.4251) acc 93.7500 (90.2344) lr 1.9298e-03 eta 0:14:58
epoch [26/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5078 (0.4222) acc 87.5000 (90.4861) lr 1.9298e-03 eta 0:14:43
epoch [26/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3359 (0.4273) acc 93.7500 (90.3125) lr 1.9298e-03 eta 0:14:30
epoch [27/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.130) loss 0.5566 (0.3910) acc 90.6250 (91.8750) lr 1.9239e-03 eta 0:32:07
epoch [27/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.3911 (0.4041) acc 90.6250 (89.3750) lr 1.9239e-03 eta 0:22:28
epoch [27/200] batch [15/51] time 0.086 (0.130) data 0.000 (0.044) loss 0.1876 (0.3925) acc 96.8750 (88.9583) lr 1.9239e-03 eta 0:19:14
epoch [27/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.033) loss 0.4441 (0.3900) acc 87.5000 (89.6875) lr 1.9239e-03 eta 0:17:36
epoch [27/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2454 (0.3946) acc 93.7500 (89.8750) lr 1.9239e-03 eta 0:16:39
epoch [27/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.6953 (0.4034) acc 78.1250 (89.5833) lr 1.9239e-03 eta 0:16:01
epoch [27/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.9043 (0.4324) acc 78.1250 (88.7500) lr 1.9239e-03 eta 0:15:34
epoch [27/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.8257 (0.4575) acc 81.2500 (88.2812) lr 1.9239e-03 eta 0:15:11
epoch [27/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2793 (0.4555) acc 93.7500 (88.2639) lr 1.9239e-03 eta 0:14:53
epoch [27/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.2380 (0.4550) acc 93.7500 (88.1875) lr 1.9239e-03 eta 0:14:39
epoch [28/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.114) loss 0.2798 (0.3908) acc 90.6250 (92.5000) lr 1.9178e-03 eta 0:29:44
epoch [28/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.4856 (0.4065) acc 87.5000 (91.5625) lr 1.9178e-03 eta 0:21:15
epoch [28/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.5532 (0.4323) acc 90.6250 (89.5833) lr 1.9178e-03 eta 0:18:24
epoch [28/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.4116 (0.4372) acc 90.6250 (89.0625) lr 1.9178e-03 eta 0:16:58
epoch [28/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4268 (0.4339) acc 84.3750 (89.0000) lr 1.9178e-03 eta 0:16:07
epoch [28/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.4102 (0.4558) acc 90.6250 (88.6458) lr 1.9178e-03 eta 0:15:32
epoch [28/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.017) loss 0.1893 (0.4425) acc 96.8750 (88.9286) lr 1.9178e-03 eta 0:15:08
epoch [28/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.5776 (0.4448) acc 81.2500 (88.8281) lr 1.9178e-03 eta 0:14:48
epoch [28/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3755 (0.4396) acc 93.7500 (89.2361) lr 1.9178e-03 eta 0:14:33
epoch [28/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2642 (0.4354) acc 96.8750 (89.5000) lr 1.9178e-03 eta 0:14:20
epoch [29/200] batch [5/51] time 0.087 (0.219) data 0.000 (0.132) loss 0.7510 (0.4419) acc 84.3750 (91.2500) lr 1.9114e-03 eta 0:32:04
epoch [29/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.2893 (0.3810) acc 90.6250 (91.5625) lr 1.9114e-03 eta 0:22:22
epoch [29/200] batch [15/51] time 0.086 (0.131) data 0.000 (0.044) loss 0.4849 (0.4165) acc 84.3750 (89.7917) lr 1.9114e-03 eta 0:19:07
epoch [29/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.2324 (0.4318) acc 90.6250 (88.7500) lr 1.9114e-03 eta 0:17:30
epoch [29/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.5122 (0.4283) acc 84.3750 (88.8750) lr 1.9114e-03 eta 0:16:32
epoch [29/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.5630 (0.4552) acc 90.6250 (88.1250) lr 1.9114e-03 eta 0:15:52
epoch [29/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4216 (0.4538) acc 90.6250 (88.2143) lr 1.9114e-03 eta 0:15:24
epoch [29/200] batch [40/51] time 0.088 (0.103) data 0.000 (0.017) loss 0.3604 (0.4509) acc 93.7500 (88.5156) lr 1.9114e-03 eta 0:15:03
epoch [29/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2316 (0.4431) acc 93.7500 (88.9583) lr 1.9114e-03 eta 0:14:46
epoch [29/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.6582 (0.4511) acc 78.1250 (88.6875) lr 1.9114e-03 eta 0:14:31
epoch [30/200] batch [5/51] time 0.088 (0.211) data 0.000 (0.122) loss 0.5005 (0.3373) acc 84.3750 (88.1250) lr 1.9048e-03 eta 0:30:34
epoch [30/200] batch [10/51] time 0.088 (0.149) data 0.000 (0.061) loss 0.2637 (0.3402) acc 90.6250 (88.1250) lr 1.9048e-03 eta 0:21:37
epoch [30/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.3938 (0.3801) acc 90.6250 (88.3333) lr 1.9048e-03 eta 0:18:36
epoch [30/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.7051 (0.3877) acc 84.3750 (88.7500) lr 1.9048e-03 eta 0:17:07
epoch [30/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2893 (0.4151) acc 93.7500 (88.3750) lr 1.9048e-03 eta 0:16:12
epoch [30/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2018 (0.4097) acc 96.8750 (88.9583) lr 1.9048e-03 eta 0:15:36
epoch [30/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.4207 (0.4048) acc 90.6250 (89.1964) lr 1.9048e-03 eta 0:15:09
epoch [30/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3069 (0.4109) acc 90.6250 (88.9844) lr 1.9048e-03 eta 0:14:48
epoch [30/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4653 (0.4048) acc 90.6250 (89.3056) lr 1.9048e-03 eta 0:14:32
epoch [30/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5195 (0.4098) acc 84.3750 (89.3125) lr 1.9048e-03 eta 0:14:19
epoch [31/200] batch [5/51] time 0.087 (0.223) data 0.000 (0.135) loss 0.4392 (0.3751) acc 87.5000 (87.5000) lr 1.8980e-03 eta 0:32:09
epoch [31/200] batch [10/51] time 0.086 (0.155) data 0.000 (0.068) loss 0.5010 (0.4826) acc 87.5000 (86.5625) lr 1.8980e-03 eta 0:22:20
epoch [31/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.6377 (0.4781) acc 84.3750 (87.2917) lr 1.8980e-03 eta 0:19:04
epoch [31/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.4705 (0.4810) acc 90.6250 (87.8125) lr 1.8980e-03 eta 0:17:25
epoch [31/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.1912 (0.4583) acc 96.8750 (88.2500) lr 1.8980e-03 eta 0:16:26
epoch [31/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3594 (0.4375) acc 93.7500 (88.8542) lr 1.8980e-03 eta 0:15:47
epoch [31/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.4673 (0.4345) acc 84.3750 (88.7500) lr 1.8980e-03 eta 0:15:18
epoch [31/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.5610 (0.4380) acc 78.1250 (88.6719) lr 1.8980e-03 eta 0:14:56
epoch [31/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5830 (0.4357) acc 90.6250 (88.9583) lr 1.8980e-03 eta 0:14:39
epoch [31/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3862 (0.4505) acc 87.5000 (88.1250) lr 1.8980e-03 eta 0:14:24
epoch [32/200] batch [5/51] time 0.088 (0.202) data 0.000 (0.113) loss 0.4478 (0.3816) acc 90.6250 (91.2500) lr 1.8910e-03 eta 0:28:56
epoch [32/200] batch [10/51] time 0.088 (0.145) data 0.000 (0.056) loss 0.4419 (0.3569) acc 87.5000 (92.1875) lr 1.8910e-03 eta 0:20:44
epoch [32/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.3330 (0.3747) acc 87.5000 (91.6667) lr 1.8910e-03 eta 0:18:00
epoch [32/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.5435 (0.4056) acc 90.6250 (90.4688) lr 1.8910e-03 eta 0:16:36
epoch [32/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2195 (0.4206) acc 96.8750 (90.5000) lr 1.8910e-03 eta 0:15:46
epoch [32/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3679 (0.4113) acc 84.3750 (90.4167) lr 1.8910e-03 eta 0:15:12
epoch [32/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.5176 (0.4237) acc 93.7500 (90.1786) lr 1.8910e-03 eta 0:14:48
epoch [32/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.6162 (0.4199) acc 84.3750 (89.9219) lr 1.8910e-03 eta 0:14:29
epoch [32/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3228 (0.4231) acc 93.7500 (89.7917) lr 1.8910e-03 eta 0:14:13
epoch [32/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.6025 (0.4275) acc 90.6250 (89.8125) lr 1.8910e-03 eta 0:14:01
epoch [33/200] batch [5/51] time 0.088 (0.205) data 0.000 (0.116) loss 0.5679 (0.5947) acc 84.3750 (84.3750) lr 1.8838e-03 eta 0:29:12
epoch [33/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.4756 (0.5270) acc 87.5000 (86.5625) lr 1.8838e-03 eta 0:20:51
epoch [33/200] batch [15/51] time 0.088 (0.127) data 0.000 (0.039) loss 0.8315 (0.5444) acc 75.0000 (86.0417) lr 1.8838e-03 eta 0:18:02
epoch [33/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.029) loss 0.4792 (0.5374) acc 87.5000 (85.9375) lr 1.8838e-03 eta 0:16:37
epoch [33/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.023) loss 0.2554 (0.5028) acc 96.8750 (87.3750) lr 1.8838e-03 eta 0:15:47
epoch [33/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.3635 (0.4680) acc 90.6250 (88.2292) lr 1.8838e-03 eta 0:15:12
epoch [33/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.5752 (0.4663) acc 84.3750 (87.9464) lr 1.8838e-03 eta 0:14:48
epoch [33/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3870 (0.4607) acc 87.5000 (87.8125) lr 1.8838e-03 eta 0:14:28
epoch [33/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3765 (0.4434) acc 90.6250 (88.3333) lr 1.8838e-03 eta 0:14:12
epoch [33/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5928 (0.4414) acc 87.5000 (88.6875) lr 1.8838e-03 eta 0:14:00
epoch [34/200] batch [5/51] time 0.087 (0.221) data 0.000 (0.134) loss 0.4312 (0.4118) acc 93.7500 (90.0000) lr 1.8763e-03 eta 0:31:23
epoch [34/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.2000 (0.3763) acc 96.8750 (90.6250) lr 1.8763e-03 eta 0:21:53
epoch [34/200] batch [15/51] time 0.088 (0.132) data 0.000 (0.045) loss 0.2454 (0.4015) acc 96.8750 (90.2083) lr 1.8763e-03 eta 0:18:41
epoch [34/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.2534 (0.3857) acc 93.7500 (90.0000) lr 1.8763e-03 eta 0:17:05
epoch [34/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3015 (0.3938) acc 93.7500 (89.5000) lr 1.8763e-03 eta 0:16:07
epoch [34/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 1.1484 (0.4326) acc 68.7500 (88.4375) lr 1.8763e-03 eta 0:15:29
epoch [34/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4648 (0.4198) acc 87.5000 (89.2857) lr 1.8763e-03 eta 0:15:01
epoch [34/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1932 (0.4134) acc 93.7500 (89.6094) lr 1.8763e-03 eta 0:14:39
epoch [34/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5171 (0.4141) acc 90.6250 (89.7222) lr 1.8763e-03 eta 0:14:21
epoch [34/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4041 (0.4080) acc 90.6250 (89.8750) lr 1.8763e-03 eta 0:14:07
epoch [35/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.125) loss 0.3660 (0.4984) acc 90.6250 (90.0000) lr 1.8686e-03 eta 0:29:57
epoch [35/200] batch [10/51] time 0.090 (0.150) data 0.000 (0.063) loss 0.1417 (0.4005) acc 96.8750 (90.6250) lr 1.8686e-03 eta 0:21:09
epoch [35/200] batch [15/51] time 0.086 (0.129) data 0.000 (0.042) loss 0.9189 (0.4081) acc 62.5000 (89.1667) lr 1.8686e-03 eta 0:18:09
epoch [35/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.2769 (0.3953) acc 93.7500 (89.3750) lr 1.8686e-03 eta 0:16:40
epoch [35/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.4436 (0.3998) acc 87.5000 (89.5000) lr 1.8686e-03 eta 0:15:46
epoch [35/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.4751 (0.4123) acc 84.3750 (89.1667) lr 1.8686e-03 eta 0:15:10
epoch [35/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.3330 (0.4266) acc 90.6250 (88.6607) lr 1.8686e-03 eta 0:14:44
epoch [35/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.7148 (0.4331) acc 81.2500 (88.6719) lr 1.8686e-03 eta 0:14:23
epoch [35/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2152 (0.4219) acc 93.7500 (88.8194) lr 1.8686e-03 eta 0:14:07
epoch [35/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4795 (0.4158) acc 84.3750 (89.0625) lr 1.8686e-03 eta 0:13:55
epoch [36/200] batch [5/51] time 0.087 (0.221) data 0.000 (0.134) loss 0.6597 (0.5432) acc 87.5000 (88.7500) lr 1.8607e-03 eta 0:30:58
epoch [36/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.2744 (0.4758) acc 93.7500 (89.6875) lr 1.8607e-03 eta 0:21:34
epoch [36/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.3242 (0.4111) acc 90.6250 (90.4167) lr 1.8607e-03 eta 0:18:25
epoch [36/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.034) loss 0.3503 (0.3843) acc 93.7500 (91.4062) lr 1.8607e-03 eta 0:16:51
epoch [36/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2399 (0.3948) acc 93.7500 (91.2500) lr 1.8607e-03 eta 0:15:54
epoch [36/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.023) loss 0.3806 (0.3984) acc 87.5000 (90.8333) lr 1.8607e-03 eta 0:15:15
epoch [36/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.2673 (0.4021) acc 93.7500 (90.8036) lr 1.8607e-03 eta 0:14:48
epoch [36/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.4060 (0.3993) acc 90.6250 (90.5469) lr 1.8607e-03 eta 0:14:27
epoch [36/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2307 (0.3910) acc 100.0000 (90.6944) lr 1.8607e-03 eta 0:14:09
epoch [36/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4280 (0.3943) acc 93.7500 (90.3750) lr 1.8607e-03 eta 0:13:56
epoch [37/200] batch [5/51] time 0.087 (0.216) data 0.000 (0.128) loss 0.3762 (0.4093) acc 90.6250 (90.0000) lr 1.8526e-03 eta 0:30:03
epoch [37/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.064) loss 0.3818 (0.3706) acc 93.7500 (90.9375) lr 1.8526e-03 eta 0:21:07
epoch [37/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.2148 (0.3874) acc 96.8750 (90.2083) lr 1.8526e-03 eta 0:18:07
epoch [37/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.032) loss 0.4292 (0.3917) acc 90.6250 (89.5312) lr 1.8526e-03 eta 0:16:37
epoch [37/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.3823 (0.3970) acc 90.6250 (89.6250) lr 1.8526e-03 eta 0:15:43
epoch [37/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.4172 (0.4114) acc 81.2500 (88.5417) lr 1.8526e-03 eta 0:15:06
epoch [37/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.018) loss 0.2244 (0.4032) acc 96.8750 (89.1964) lr 1.8526e-03 eta 0:14:40
epoch [37/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3916 (0.4107) acc 90.6250 (88.8281) lr 1.8526e-03 eta 0:14:19
epoch [37/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1746 (0.4045) acc 100.0000 (89.5139) lr 1.8526e-03 eta 0:14:03
epoch [37/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3906 (0.4143) acc 90.6250 (89.3125) lr 1.8526e-03 eta 0:13:50
epoch [38/200] batch [5/51] time 0.089 (0.211) data 0.000 (0.121) loss 0.8613 (0.4063) acc 75.0000 (89.3750) lr 1.8443e-03 eta 0:29:12
epoch [38/200] batch [10/51] time 0.088 (0.149) data 0.000 (0.061) loss 0.3379 (0.3424) acc 87.5000 (91.5625) lr 1.8443e-03 eta 0:20:40
epoch [38/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.041) loss 0.4429 (0.3809) acc 93.7500 (91.2500) lr 1.8443e-03 eta 0:17:50
epoch [38/200] batch [20/51] time 0.088 (0.119) data 0.000 (0.031) loss 0.4119 (0.3908) acc 87.5000 (90.9375) lr 1.8443e-03 eta 0:16:24
epoch [38/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.024) loss 0.4963 (0.3914) acc 87.5000 (90.5000) lr 1.8443e-03 eta 0:15:32
epoch [38/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.020) loss 0.1669 (0.3644) acc 96.8750 (91.2500) lr 1.8443e-03 eta 0:14:57
epoch [38/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.4111 (0.3765) acc 90.6250 (90.7143) lr 1.8443e-03 eta 0:14:31
epoch [38/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.015) loss 0.3020 (0.3933) acc 90.6250 (90.0781) lr 1.8443e-03 eta 0:14:11
epoch [38/200] batch [45/51] time 0.087 (0.101) data 0.000 (0.014) loss 0.5938 (0.3959) acc 87.5000 (89.8611) lr 1.8443e-03 eta 0:13:55
epoch [38/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.012) loss 0.5967 (0.3961) acc 81.2500 (89.6250) lr 1.8443e-03 eta 0:13:43
epoch [39/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.135) loss 0.3745 (0.3971) acc 93.7500 (90.0000) lr 1.8358e-03 eta 0:30:30
epoch [39/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.068) loss 0.3821 (0.3933) acc 93.7500 (90.0000) lr 1.8358e-03 eta 0:21:13
epoch [39/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.3726 (0.4001) acc 90.6250 (90.0000) lr 1.8358e-03 eta 0:18:05
epoch [39/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.034) loss 0.2192 (0.4091) acc 93.7500 (89.5312) lr 1.8358e-03 eta 0:16:31
epoch [39/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.1318 (0.4171) acc 96.8750 (89.5000) lr 1.8358e-03 eta 0:15:35
epoch [39/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.023) loss 0.3604 (0.4087) acc 87.5000 (89.5833) lr 1.8358e-03 eta 0:14:56
epoch [39/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.1232 (0.3970) acc 100.0000 (90.4464) lr 1.8358e-03 eta 0:14:30
epoch [39/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.4561 (0.4059) acc 90.6250 (89.9219) lr 1.8358e-03 eta 0:14:09
epoch [39/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.2275 (0.4077) acc 93.7500 (90.0694) lr 1.8358e-03 eta 0:13:53
epoch [39/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4224 (0.4079) acc 87.5000 (89.7500) lr 1.8358e-03 eta 0:13:39
epoch [40/200] batch [5/51] time 0.087 (0.220) data 0.000 (0.133) loss 0.2620 (0.3524) acc 96.8750 (90.6250) lr 1.8271e-03 eta 0:30:08
epoch [40/200] batch [10/51] time 0.088 (0.154) data 0.000 (0.067) loss 0.4995 (0.3550) acc 87.5000 (90.9375) lr 1.8271e-03 eta 0:21:03
epoch [40/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.044) loss 0.6382 (0.3916) acc 90.6250 (90.4167) lr 1.8271e-03 eta 0:17:59
epoch [40/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.033) loss 0.2539 (0.3935) acc 93.7500 (90.6250) lr 1.8271e-03 eta 0:16:27
epoch [40/200] batch [25/51] time 0.088 (0.114) data 0.000 (0.027) loss 0.5161 (0.3990) acc 87.5000 (90.3750) lr 1.8271e-03 eta 0:15:32
epoch [40/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.2146 (0.3977) acc 96.8750 (90.1042) lr 1.8271e-03 eta 0:14:55
epoch [40/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.4336 (0.3880) acc 90.6250 (90.5357) lr 1.8271e-03 eta 0:14:29
epoch [40/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3884 (0.3936) acc 90.6250 (90.3125) lr 1.8271e-03 eta 0:14:08
epoch [40/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5835 (0.3929) acc 81.2500 (90.2778) lr 1.8271e-03 eta 0:13:52
epoch [40/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5049 (0.3967) acc 87.5000 (90.1875) lr 1.8271e-03 eta 0:13:38
epoch [41/200] batch [5/51] time 0.087 (0.209) data 0.000 (0.122) loss 0.4724 (0.3472) acc 84.3750 (89.3750) lr 1.8181e-03 eta 0:28:28
epoch [41/200] batch [10/51] time 0.086 (0.148) data 0.000 (0.061) loss 0.2478 (0.3350) acc 96.8750 (90.9375) lr 1.8181e-03 eta 0:20:06
epoch [41/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.5713 (0.3250) acc 84.3750 (91.6667) lr 1.8181e-03 eta 0:17:18
epoch [41/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.031) loss 0.1677 (0.3062) acc 96.8750 (92.3438) lr 1.8181e-03 eta 0:15:54
epoch [41/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.025) loss 0.5918 (0.3303) acc 81.2500 (91.7500) lr 1.8181e-03 eta 0:15:04
epoch [41/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.7114 (0.3472) acc 78.1250 (90.6250) lr 1.8181e-03 eta 0:14:30
epoch [41/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.4690 (0.3547) acc 84.3750 (90.3571) lr 1.8181e-03 eta 0:14:06
epoch [41/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4656 (0.3666) acc 87.5000 (90.0781) lr 1.8181e-03 eta 0:13:47
epoch [41/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3352 (0.3662) acc 93.7500 (90.3472) lr 1.8181e-03 eta 0:13:32
epoch [41/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5723 (0.3667) acc 84.3750 (90.4375) lr 1.8181e-03 eta 0:13:20
epoch [42/200] batch [5/51] time 0.090 (0.199) data 0.000 (0.111) loss 0.1067 (0.4153) acc 100.0000 (90.6250) lr 1.8090e-03 eta 0:26:52
epoch [42/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.3340 (0.4274) acc 93.7500 (90.3125) lr 1.8090e-03 eta 0:19:18
epoch [42/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.4187 (0.3868) acc 96.8750 (92.0833) lr 1.8090e-03 eta 0:16:47
epoch [42/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2832 (0.3619) acc 90.6250 (92.1875) lr 1.8090e-03 eta 0:15:30
epoch [42/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.5996 (0.3648) acc 84.3750 (91.8750) lr 1.8090e-03 eta 0:14:44
epoch [42/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.3296 (0.3748) acc 87.5000 (91.2500) lr 1.8090e-03 eta 0:14:14
epoch [42/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1613 (0.3542) acc 96.8750 (91.3393) lr 1.8090e-03 eta 0:13:52
epoch [42/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3135 (0.3744) acc 93.7500 (90.5469) lr 1.8090e-03 eta 0:13:34
epoch [42/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2705 (0.3788) acc 90.6250 (90.2778) lr 1.8090e-03 eta 0:13:20
epoch [42/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3550 (0.3931) acc 87.5000 (89.8125) lr 1.8090e-03 eta 0:13:09
epoch [43/200] batch [5/51] time 0.089 (0.222) data 0.000 (0.134) loss 0.3540 (0.4626) acc 90.6250 (87.5000) lr 1.7997e-03 eta 0:29:50
epoch [43/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.067) loss 0.6182 (0.4672) acc 81.2500 (87.8125) lr 1.7997e-03 eta 0:20:46
epoch [43/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.5137 (0.4352) acc 90.6250 (88.7500) lr 1.7997e-03 eta 0:17:44
epoch [43/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.3054 (0.4346) acc 93.7500 (88.5938) lr 1.7997e-03 eta 0:16:12
epoch [43/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3035 (0.4107) acc 93.7500 (89.2500) lr 1.7997e-03 eta 0:15:18
epoch [43/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5088 (0.4282) acc 81.2500 (88.7500) lr 1.7997e-03 eta 0:14:42
epoch [43/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.019) loss 0.1241 (0.4135) acc 96.8750 (88.9286) lr 1.7997e-03 eta 0:14:15
epoch [43/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3206 (0.3960) acc 87.5000 (89.3750) lr 1.7997e-03 eta 0:13:54
epoch [43/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4917 (0.3939) acc 81.2500 (89.3056) lr 1.7997e-03 eta 0:13:37
epoch [43/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3267 (0.3846) acc 90.6250 (89.5625) lr 1.7997e-03 eta 0:13:24
epoch [44/200] batch [5/51] time 0.087 (0.223) data 0.000 (0.136) loss 0.2079 (0.2524) acc 100.0000 (95.0000) lr 1.7902e-03 eta 0:29:46
epoch [44/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.3840 (0.3020) acc 93.7500 (92.5000) lr 1.7902e-03 eta 0:20:40
epoch [44/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.4392 (0.3351) acc 90.6250 (92.2917) lr 1.7902e-03 eta 0:17:38
epoch [44/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.3167 (0.3637) acc 87.5000 (91.0938) lr 1.7902e-03 eta 0:16:07
epoch [44/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3359 (0.3710) acc 87.5000 (90.6250) lr 1.7902e-03 eta 0:15:12
epoch [44/200] batch [30/51] time 0.090 (0.110) data 0.000 (0.023) loss 0.3877 (0.3689) acc 90.6250 (90.7292) lr 1.7902e-03 eta 0:14:36
epoch [44/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3403 (0.3638) acc 90.6250 (90.9821) lr 1.7902e-03 eta 0:14:09
epoch [44/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.5542 (0.3572) acc 87.5000 (91.4062) lr 1.7902e-03 eta 0:13:48
epoch [44/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4509 (0.3523) acc 84.3750 (91.3889) lr 1.7902e-03 eta 0:13:32
epoch [44/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.6060 (0.3660) acc 78.1250 (90.7500) lr 1.7902e-03 eta 0:13:18
epoch [45/200] batch [5/51] time 0.088 (0.195) data 0.000 (0.107) loss 0.2089 (0.2298) acc 96.8750 (93.1250) lr 1.7804e-03 eta 0:25:49
epoch [45/200] batch [10/51] time 0.087 (0.141) data 0.000 (0.054) loss 0.3904 (0.2961) acc 93.7500 (92.5000) lr 1.7804e-03 eta 0:18:38
epoch [45/200] batch [15/51] time 0.086 (0.123) data 0.000 (0.036) loss 0.2710 (0.3115) acc 96.8750 (92.7083) lr 1.7804e-03 eta 0:16:14
epoch [45/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3533 (0.3635) acc 87.5000 (90.7812) lr 1.7804e-03 eta 0:15:03
epoch [45/200] batch [25/51] time 0.087 (0.108) data 0.001 (0.022) loss 0.3665 (0.3717) acc 93.7500 (90.7500) lr 1.7804e-03 eta 0:14:20
epoch [45/200] batch [30/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.1967 (0.3658) acc 96.8750 (91.1458) lr 1.7804e-03 eta 0:13:51
epoch [45/200] batch [35/51] time 0.087 (0.102) data 0.000 (0.016) loss 0.6094 (0.3765) acc 81.2500 (90.8036) lr 1.7804e-03 eta 0:13:31
epoch [45/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1963 (0.3749) acc 96.8750 (90.6250) lr 1.7804e-03 eta 0:13:15
epoch [45/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3918 (0.3823) acc 93.7500 (90.6250) lr 1.7804e-03 eta 0:13:01
epoch [45/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.5098 (0.3815) acc 90.6250 (90.6250) lr 1.7804e-03 eta 0:12:51
epoch [46/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.134) loss 0.2130 (0.2798) acc 93.7500 (92.5000) lr 1.7705e-03 eta 0:29:14
epoch [46/200] batch [10/51] time 0.089 (0.155) data 0.000 (0.067) loss 0.4011 (0.3368) acc 87.5000 (91.5625) lr 1.7705e-03 eta 0:20:22
epoch [46/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.6226 (0.4013) acc 90.6250 (90.2083) lr 1.7705e-03 eta 0:17:22
epoch [46/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.1687 (0.3514) acc 96.8750 (91.8750) lr 1.7705e-03 eta 0:15:53
epoch [46/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2578 (0.3439) acc 96.8750 (92.1250) lr 1.7705e-03 eta 0:14:58
epoch [46/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3062 (0.3645) acc 90.6250 (91.3542) lr 1.7705e-03 eta 0:14:22
epoch [46/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.5830 (0.3641) acc 87.5000 (90.9821) lr 1.7705e-03 eta 0:13:57
epoch [46/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2245 (0.3749) acc 96.8750 (90.8594) lr 1.7705e-03 eta 0:13:36
epoch [46/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4670 (0.3678) acc 84.3750 (91.0417) lr 1.7705e-03 eta 0:13:20
epoch [46/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3472 (0.3645) acc 90.6250 (91.0000) lr 1.7705e-03 eta 0:13:07
epoch [47/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.124) loss 0.2302 (0.4023) acc 96.8750 (91.8750) lr 1.7604e-03 eta 0:27:45
epoch [47/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.062) loss 0.4224 (0.3722) acc 90.6250 (91.8750) lr 1.7604e-03 eta 0:19:33
epoch [47/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.4280 (0.3814) acc 90.6250 (90.8333) lr 1.7604e-03 eta 0:16:49
epoch [47/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.2396 (0.3576) acc 93.7500 (91.0938) lr 1.7604e-03 eta 0:15:26
epoch [47/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3459 (0.3609) acc 90.6250 (91.3750) lr 1.7604e-03 eta 0:14:37
epoch [47/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.4861 (0.3734) acc 90.6250 (91.2500) lr 1.7604e-03 eta 0:14:04
epoch [47/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.5317 (0.3943) acc 81.2500 (90.1786) lr 1.7604e-03 eta 0:13:40
epoch [47/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4810 (0.3901) acc 93.7500 (90.7031) lr 1.7604e-03 eta 0:13:21
epoch [47/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2864 (0.3976) acc 90.6250 (90.5556) lr 1.7604e-03 eta 0:13:06
epoch [47/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2262 (0.3990) acc 90.6250 (90.3750) lr 1.7604e-03 eta 0:12:55
epoch [48/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.4424 (0.2266) acc 87.5000 (93.7500) lr 1.7501e-03 eta 0:26:01
epoch [48/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.3867 (0.2629) acc 87.5000 (92.8125) lr 1.7501e-03 eta 0:18:38
epoch [48/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.7925 (0.3183) acc 78.1250 (91.2500) lr 1.7501e-03 eta 0:16:10
epoch [48/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.5557 (0.3351) acc 84.3750 (90.7812) lr 1.7501e-03 eta 0:14:55
epoch [48/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3740 (0.3438) acc 87.5000 (90.7500) lr 1.7501e-03 eta 0:14:11
epoch [48/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4258 (0.3460) acc 90.6250 (91.1458) lr 1.7501e-03 eta 0:13:42
epoch [48/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3831 (0.3475) acc 96.8750 (91.2500) lr 1.7501e-03 eta 0:13:21
epoch [48/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.3538 (0.3449) acc 87.5000 (91.0156) lr 1.7501e-03 eta 0:13:03
epoch [48/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.1619 (0.3437) acc 100.0000 (91.1111) lr 1.7501e-03 eta 0:12:50
epoch [48/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3235 (0.3510) acc 90.6250 (90.9375) lr 1.7501e-03 eta 0:12:39
epoch [49/200] batch [5/51] time 0.090 (0.200) data 0.000 (0.111) loss 0.2544 (0.3252) acc 93.7500 (91.2500) lr 1.7396e-03 eta 0:25:47
epoch [49/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.056) loss 0.4722 (0.4110) acc 87.5000 (89.0625) lr 1.7396e-03 eta 0:18:32
epoch [49/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.037) loss 0.4065 (0.3915) acc 96.8750 (90.6250) lr 1.7396e-03 eta 0:16:07
epoch [49/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.028) loss 0.3760 (0.3851) acc 84.3750 (90.3125) lr 1.7396e-03 eta 0:14:53
epoch [49/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.7139 (0.3957) acc 78.1250 (89.8750) lr 1.7396e-03 eta 0:14:09
epoch [49/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2244 (0.3758) acc 93.7500 (90.3125) lr 1.7396e-03 eta 0:13:39
epoch [49/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4727 (0.3915) acc 81.2500 (89.5536) lr 1.7396e-03 eta 0:13:17
epoch [49/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2095 (0.3912) acc 93.7500 (89.4531) lr 1.7396e-03 eta 0:13:00
epoch [49/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4097 (0.4025) acc 93.7500 (89.3750) lr 1.7396e-03 eta 0:12:47
epoch [49/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.5679 (0.4107) acc 87.5000 (88.9375) lr 1.7396e-03 eta 0:12:35
epoch [50/200] batch [5/51] time 0.088 (0.220) data 0.000 (0.132) loss 0.5835 (0.4979) acc 84.3750 (87.5000) lr 1.7290e-03 eta 0:28:11
epoch [50/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.066) loss 0.4814 (0.4841) acc 93.7500 (87.8125) lr 1.7290e-03 eta 0:19:42
epoch [50/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.044) loss 0.4058 (0.4707) acc 90.6250 (88.5417) lr 1.7290e-03 eta 0:16:50
epoch [50/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.2598 (0.4623) acc 93.7500 (88.2812) lr 1.7290e-03 eta 0:15:23
epoch [50/200] batch [25/51] time 0.088 (0.114) data 0.000 (0.027) loss 0.2086 (0.4488) acc 96.8750 (88.8750) lr 1.7290e-03 eta 0:14:31
epoch [50/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2155 (0.4267) acc 93.7500 (89.3750) lr 1.7290e-03 eta 0:13:57
epoch [50/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2468 (0.4122) acc 96.8750 (90.0893) lr 1.7290e-03 eta 0:13:33
epoch [50/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3083 (0.4028) acc 93.7500 (90.0781) lr 1.7290e-03 eta 0:13:13
epoch [50/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4973 (0.4065) acc 90.6250 (90.0694) lr 1.7290e-03 eta 0:12:57
epoch [50/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2510 (0.4070) acc 96.8750 (90.1250) lr 1.7290e-03 eta 0:12:45
epoch [51/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.114) loss 0.3638 (0.4702) acc 90.6250 (88.1250) lr 1.7181e-03 eta 0:25:36
epoch [51/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.4480 (0.3713) acc 87.5000 (90.9375) lr 1.7181e-03 eta 0:18:21
epoch [51/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.3608 (0.3653) acc 93.7500 (91.2500) lr 1.7181e-03 eta 0:15:54
epoch [51/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.029) loss 0.1796 (0.3539) acc 90.6250 (91.0938) lr 1.7181e-03 eta 0:14:41
epoch [51/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5361 (0.3759) acc 87.5000 (90.3750) lr 1.7181e-03 eta 0:13:57
epoch [51/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1648 (0.3664) acc 96.8750 (90.8333) lr 1.7181e-03 eta 0:13:27
epoch [51/200] batch [35/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1606 (0.3609) acc 100.0000 (91.1607) lr 1.7181e-03 eta 0:13:05
epoch [51/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3674 (0.3523) acc 93.7500 (91.3281) lr 1.7181e-03 eta 0:12:48
epoch [51/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.3313 (0.3535) acc 90.6250 (91.1806) lr 1.7181e-03 eta 0:12:35
epoch [51/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.3838 (0.3581) acc 90.6250 (90.9375) lr 1.7181e-03 eta 0:12:24
epoch [52/200] batch [5/51] time 0.086 (0.224) data 0.000 (0.137) loss 0.3916 (0.3516) acc 93.7500 (93.1250) lr 1.7071e-03 eta 0:28:20
epoch [52/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.069) loss 0.2798 (0.3346) acc 93.7500 (92.1875) lr 1.7071e-03 eta 0:19:38
epoch [52/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.046) loss 0.3079 (0.3462) acc 93.7500 (91.4583) lr 1.7071e-03 eta 0:16:43
epoch [52/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.7573 (0.3717) acc 78.1250 (90.4688) lr 1.7071e-03 eta 0:15:16
epoch [52/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.028) loss 0.2466 (0.3797) acc 90.6250 (90.5000) lr 1.7071e-03 eta 0:14:24
epoch [52/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4902 (0.3938) acc 84.3750 (90.1042) lr 1.7071e-03 eta 0:13:49
epoch [52/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.5112 (0.3961) acc 87.5000 (90.0000) lr 1.7071e-03 eta 0:13:23
epoch [52/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.3660 (0.3974) acc 90.6250 (90.0781) lr 1.7071e-03 eta 0:13:04
epoch [52/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3684 (0.3891) acc 93.7500 (90.2083) lr 1.7071e-03 eta 0:12:48
epoch [52/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2998 (0.3936) acc 87.5000 (89.6875) lr 1.7071e-03 eta 0:12:35
epoch [53/200] batch [5/51] time 0.088 (0.227) data 0.000 (0.138) loss 0.2959 (0.3186) acc 93.7500 (93.7500) lr 1.6959e-03 eta 0:28:29
epoch [53/200] batch [10/51] time 0.087 (0.157) data 0.000 (0.069) loss 0.4033 (0.3571) acc 84.3750 (91.8750) lr 1.6959e-03 eta 0:19:43
epoch [53/200] batch [15/51] time 0.087 (0.134) data 0.000 (0.046) loss 0.3298 (0.3371) acc 90.6250 (92.0833) lr 1.6959e-03 eta 0:16:46
epoch [53/200] batch [20/51] time 0.088 (0.122) data 0.000 (0.035) loss 0.2422 (0.3520) acc 93.7500 (91.4062) lr 1.6959e-03 eta 0:15:18
epoch [53/200] batch [25/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.5801 (0.3629) acc 87.5000 (91.3750) lr 1.6959e-03 eta 0:14:25
epoch [53/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3262 (0.3492) acc 93.7500 (91.8750) lr 1.6959e-03 eta 0:13:50
epoch [53/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2634 (0.3469) acc 96.8750 (92.1429) lr 1.6959e-03 eta 0:13:24
epoch [53/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.2888 (0.3371) acc 96.8750 (92.1094) lr 1.6959e-03 eta 0:13:03
epoch [53/200] batch [45/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.3970 (0.3409) acc 84.3750 (91.7361) lr 1.6959e-03 eta 0:12:47
epoch [53/200] batch [50/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.2734 (0.3492) acc 87.5000 (91.3750) lr 1.6959e-03 eta 0:12:34
epoch [54/200] batch [5/51] time 0.087 (0.203) data 0.000 (0.116) loss 0.3735 (0.2740) acc 90.6250 (95.6250) lr 1.6845e-03 eta 0:25:23
epoch [54/200] batch [10/51] time 0.086 (0.145) data 0.000 (0.058) loss 0.5303 (0.3408) acc 87.5000 (91.5625) lr 1.6845e-03 eta 0:18:05
epoch [54/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.4360 (0.3840) acc 84.3750 (91.0417) lr 1.6845e-03 eta 0:15:39
epoch [54/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.4932 (0.3777) acc 90.6250 (90.9375) lr 1.6845e-03 eta 0:14:25
epoch [54/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4895 (0.3688) acc 84.3750 (90.7500) lr 1.6845e-03 eta 0:13:42
epoch [54/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.020) loss 0.3416 (0.3767) acc 90.6250 (90.6250) lr 1.6845e-03 eta 0:13:13
epoch [54/200] batch [35/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.2905 (0.3623) acc 90.6250 (91.0714) lr 1.6845e-03 eta 0:12:51
epoch [54/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2773 (0.3550) acc 96.8750 (91.1719) lr 1.6845e-03 eta 0:12:35
epoch [54/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2546 (0.3601) acc 96.8750 (91.1111) lr 1.6845e-03 eta 0:12:21
epoch [54/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3521 (0.3658) acc 84.3750 (90.5625) lr 1.6845e-03 eta 0:12:11
epoch [55/200] batch [5/51] time 0.086 (0.214) data 0.000 (0.127) loss 0.2358 (0.4946) acc 93.7500 (88.1250) lr 1.6730e-03 eta 0:26:30
epoch [55/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.4954 (0.4893) acc 90.6250 (87.8125) lr 1.6730e-03 eta 0:18:37
epoch [55/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.3127 (0.4147) acc 93.7500 (90.2083) lr 1.6730e-03 eta 0:16:00
epoch [55/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.1320 (0.4158) acc 100.0000 (89.8438) lr 1.6730e-03 eta 0:14:40
epoch [55/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1755 (0.3915) acc 96.8750 (89.8750) lr 1.6730e-03 eta 0:13:52
epoch [55/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3445 (0.3982) acc 93.7500 (90.2083) lr 1.6730e-03 eta 0:13:20
epoch [55/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.1560 (0.3812) acc 96.8750 (90.5357) lr 1.6730e-03 eta 0:12:57
epoch [55/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2437 (0.3669) acc 96.8750 (90.9375) lr 1.6730e-03 eta 0:12:39
epoch [55/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3269 (0.3674) acc 87.5000 (90.5556) lr 1.6730e-03 eta 0:12:25
epoch [55/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3054 (0.3625) acc 93.7500 (90.5625) lr 1.6730e-03 eta 0:12:14
epoch [56/200] batch [5/51] time 0.088 (0.199) data 0.000 (0.111) loss 0.3926 (0.3156) acc 84.3750 (91.2500) lr 1.6613e-03 eta 0:24:34
epoch [56/200] batch [10/51] time 0.086 (0.143) data 0.000 (0.056) loss 0.4690 (0.3320) acc 90.6250 (91.2500) lr 1.6613e-03 eta 0:17:35
epoch [56/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.3376 (0.3331) acc 93.7500 (91.6667) lr 1.6613e-03 eta 0:15:16
epoch [56/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.5039 (0.3421) acc 81.2500 (91.5625) lr 1.6613e-03 eta 0:14:06
epoch [56/200] batch [25/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.2399 (0.3257) acc 93.7500 (91.8750) lr 1.6613e-03 eta 0:13:26
epoch [56/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1181 (0.3187) acc 100.0000 (91.9792) lr 1.6613e-03 eta 0:12:58
epoch [56/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.5547 (0.3369) acc 90.6250 (91.6071) lr 1.6613e-03 eta 0:12:39
epoch [56/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5254 (0.3516) acc 90.6250 (91.4062) lr 1.6613e-03 eta 0:12:23
epoch [56/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4229 (0.3540) acc 87.5000 (91.3889) lr 1.6613e-03 eta 0:12:10
epoch [56/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.5967 (0.3637) acc 81.2500 (90.8750) lr 1.6613e-03 eta 0:12:00
epoch [57/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.115) loss 0.2539 (0.3335) acc 93.7500 (90.6250) lr 1.6494e-03 eta 0:24:51
epoch [57/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.7173 (0.4427) acc 84.3750 (88.1250) lr 1.6494e-03 eta 0:17:45
epoch [57/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.3101 (0.4088) acc 96.8750 (89.1667) lr 1.6494e-03 eta 0:15:22
epoch [57/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2302 (0.4193) acc 93.7500 (88.4375) lr 1.6494e-03 eta 0:14:10
epoch [57/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1755 (0.3962) acc 96.8750 (88.8750) lr 1.6494e-03 eta 0:13:27
epoch [57/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2461 (0.3875) acc 90.6250 (89.0625) lr 1.6494e-03 eta 0:12:58
epoch [57/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3369 (0.3925) acc 90.6250 (89.2857) lr 1.6494e-03 eta 0:12:37
epoch [57/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5425 (0.3958) acc 87.5000 (89.3750) lr 1.6494e-03 eta 0:12:21
epoch [57/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2893 (0.3942) acc 90.6250 (89.6528) lr 1.6494e-03 eta 0:12:08
epoch [57/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2859 (0.3906) acc 93.7500 (89.7500) lr 1.6494e-03 eta 0:11:57
epoch [58/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.115) loss 0.3811 (0.3737) acc 93.7500 (91.2500) lr 1.6374e-03 eta 0:24:35
epoch [58/200] batch [10/51] time 0.088 (0.145) data 0.000 (0.057) loss 0.3599 (0.4017) acc 81.2500 (88.7500) lr 1.6374e-03 eta 0:17:34
epoch [58/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.3955 (0.3973) acc 84.3750 (89.1667) lr 1.6374e-03 eta 0:15:12
epoch [58/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.3467 (0.3882) acc 90.6250 (89.6875) lr 1.6374e-03 eta 0:14:01
epoch [58/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.2971 (0.3819) acc 96.8750 (90.3750) lr 1.6374e-03 eta 0:13:19
epoch [58/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4458 (0.3829) acc 93.7500 (90.3125) lr 1.6374e-03 eta 0:12:50
epoch [58/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.017) loss 0.2185 (0.3941) acc 96.8750 (89.9107) lr 1.6374e-03 eta 0:12:30
epoch [58/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.4795 (0.3880) acc 87.5000 (90.0000) lr 1.6374e-03 eta 0:12:14
epoch [58/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.1482 (0.3821) acc 100.0000 (90.4861) lr 1.6374e-03 eta 0:12:01
epoch [58/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.3115 (0.3728) acc 96.8750 (90.6875) lr 1.6374e-03 eta 0:11:50
epoch [59/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.118) loss 0.5234 (0.2719) acc 87.5000 (95.6250) lr 1.6252e-03 eta 0:24:46
epoch [59/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.4116 (0.3175) acc 93.7500 (92.8125) lr 1.6252e-03 eta 0:17:37
epoch [59/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.3989 (0.3299) acc 87.5000 (91.2500) lr 1.6252e-03 eta 0:15:13
epoch [59/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.5332 (0.3366) acc 90.6250 (91.5625) lr 1.6252e-03 eta 0:14:02
epoch [59/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.4854 (0.3427) acc 90.6250 (91.7500) lr 1.6252e-03 eta 0:13:19
epoch [59/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.2255 (0.3616) acc 96.8750 (91.8750) lr 1.6252e-03 eta 0:12:50
epoch [59/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.5596 (0.3773) acc 90.6250 (91.2500) lr 1.6252e-03 eta 0:12:30
epoch [59/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1885 (0.3621) acc 90.6250 (91.5625) lr 1.6252e-03 eta 0:12:14
epoch [59/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3118 (0.3515) acc 90.6250 (91.5972) lr 1.6252e-03 eta 0:12:01
epoch [59/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2098 (0.3556) acc 93.7500 (91.6875) lr 1.6252e-03 eta 0:11:50
epoch [60/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.5356 (0.3318) acc 90.6250 (93.7500) lr 1.6129e-03 eta 0:23:43
epoch [60/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.2634 (0.3521) acc 90.6250 (92.1875) lr 1.6129e-03 eta 0:17:02
epoch [60/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.2568 (0.3722) acc 90.6250 (91.0417) lr 1.6129e-03 eta 0:14:48
epoch [60/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.028) loss 0.4338 (0.3962) acc 87.5000 (90.1562) lr 1.6129e-03 eta 0:13:41
epoch [60/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3474 (0.4086) acc 87.5000 (89.8750) lr 1.6129e-03 eta 0:13:00
epoch [60/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.4849 (0.3974) acc 87.5000 (90.2083) lr 1.6129e-03 eta 0:12:33
epoch [60/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2400 (0.3910) acc 93.7500 (90.1786) lr 1.6129e-03 eta 0:12:13
epoch [60/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2285 (0.3880) acc 93.7500 (90.3125) lr 1.6129e-03 eta 0:11:58
epoch [60/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3188 (0.3758) acc 87.5000 (90.5556) lr 1.6129e-03 eta 0:11:46
epoch [60/200] batch [50/51] time 0.086 (0.097) data 0.000 (0.011) loss 0.3523 (0.3725) acc 87.5000 (90.5625) lr 1.6129e-03 eta 0:11:36
epoch [61/200] batch [5/51] time 0.088 (0.204) data 0.000 (0.116) loss 0.6357 (0.3941) acc 84.3750 (90.6250) lr 1.6004e-03 eta 0:24:14
epoch [61/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.2302 (0.3126) acc 93.7500 (91.8750) lr 1.6004e-03 eta 0:17:18
epoch [61/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.7227 (0.3132) acc 84.3750 (91.8750) lr 1.6004e-03 eta 0:14:57
epoch [61/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.1576 (0.3187) acc 96.8750 (92.1875) lr 1.6004e-03 eta 0:13:47
epoch [61/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.7358 (0.3554) acc 84.3750 (91.3750) lr 1.6004e-03 eta 0:13:04
epoch [61/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.7769 (0.3889) acc 78.1250 (90.4167) lr 1.6004e-03 eta 0:12:36
epoch [61/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3823 (0.3958) acc 87.5000 (90.0893) lr 1.6004e-03 eta 0:12:16
epoch [61/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1548 (0.3915) acc 96.8750 (90.4688) lr 1.6004e-03 eta 0:12:00
epoch [61/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3174 (0.3886) acc 93.7500 (90.6250) lr 1.6004e-03 eta 0:11:47
epoch [61/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2084 (0.3844) acc 96.8750 (90.5625) lr 1.6004e-03 eta 0:11:36
epoch [62/200] batch [5/51] time 0.086 (0.209) data 0.000 (0.122) loss 0.4443 (0.3081) acc 90.6250 (92.5000) lr 1.5878e-03 eta 0:24:43
epoch [62/200] batch [10/51] time 0.088 (0.148) data 0.000 (0.061) loss 0.2930 (0.2860) acc 90.6250 (93.7500) lr 1.5878e-03 eta 0:17:31
epoch [62/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.5571 (0.3396) acc 81.2500 (91.4583) lr 1.5878e-03 eta 0:15:06
epoch [62/200] batch [20/51] time 0.088 (0.118) data 0.000 (0.031) loss 0.3494 (0.3228) acc 87.5000 (91.4062) lr 1.5878e-03 eta 0:13:53
epoch [62/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2021 (0.3525) acc 96.8750 (90.6250) lr 1.5878e-03 eta 0:13:09
epoch [62/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3237 (0.3487) acc 87.5000 (90.6250) lr 1.5878e-03 eta 0:12:41
epoch [62/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3945 (0.3466) acc 90.6250 (90.8929) lr 1.5878e-03 eta 0:12:19
epoch [62/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.3184 (0.3470) acc 93.7500 (91.0156) lr 1.5878e-03 eta 0:12:02
epoch [62/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3755 (0.3531) acc 90.6250 (90.7639) lr 1.5878e-03 eta 0:11:48
epoch [62/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.6753 (0.3641) acc 81.2500 (90.5625) lr 1.5878e-03 eta 0:11:37
epoch [63/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.3904 (0.5007) acc 87.5000 (86.8750) lr 1.5750e-03 eta 0:23:09
epoch [63/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.1415 (0.3903) acc 100.0000 (89.0625) lr 1.5750e-03 eta 0:16:39
epoch [63/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.5073 (0.3996) acc 90.6250 (88.9583) lr 1.5750e-03 eta 0:14:27
epoch [63/200] batch [20/51] time 0.086 (0.114) data 0.000 (0.028) loss 0.1636 (0.4090) acc 96.8750 (89.3750) lr 1.5750e-03 eta 0:13:22
epoch [63/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2866 (0.3850) acc 87.5000 (89.8750) lr 1.5750e-03 eta 0:12:43
epoch [63/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.3931 (0.3748) acc 93.7500 (90.3125) lr 1.5750e-03 eta 0:12:17
epoch [63/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3350 (0.3826) acc 93.7500 (90.2679) lr 1.5750e-03 eta 0:11:58
epoch [63/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3113 (0.3737) acc 93.7500 (90.7031) lr 1.5750e-03 eta 0:11:43
epoch [63/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3994 (0.3797) acc 93.7500 (90.8333) lr 1.5750e-03 eta 0:11:31
epoch [63/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1808 (0.3877) acc 93.7500 (90.5000) lr 1.5750e-03 eta 0:11:22
epoch [64/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.115) loss 0.4600 (0.3560) acc 93.7500 (90.0000) lr 1.5621e-03 eta 0:23:37
epoch [64/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.2529 (0.3419) acc 93.7500 (90.9375) lr 1.5621e-03 eta 0:16:51
epoch [64/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.6455 (0.3636) acc 84.3750 (90.6250) lr 1.5621e-03 eta 0:14:36
epoch [64/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2769 (0.3309) acc 90.6250 (91.2500) lr 1.5621e-03 eta 0:13:27
epoch [64/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3799 (0.3436) acc 93.7500 (90.7500) lr 1.5621e-03 eta 0:12:46
epoch [64/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3970 (0.3528) acc 93.7500 (90.9375) lr 1.5621e-03 eta 0:12:19
epoch [64/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3931 (0.3568) acc 93.7500 (90.6250) lr 1.5621e-03 eta 0:11:59
epoch [64/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3740 (0.3531) acc 84.3750 (90.6250) lr 1.5621e-03 eta 0:11:44
epoch [64/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1123 (0.3460) acc 100.0000 (91.1806) lr 1.5621e-03 eta 0:11:31
epoch [64/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.8394 (0.3512) acc 81.2500 (91.0625) lr 1.5621e-03 eta 0:11:21
epoch [65/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.117) loss 0.4854 (0.2928) acc 90.6250 (95.0000) lr 1.5490e-03 eta 0:23:38
epoch [65/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.6196 (0.3423) acc 84.3750 (91.8750) lr 1.5490e-03 eta 0:16:51
epoch [65/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.1007 (0.3454) acc 100.0000 (91.4583) lr 1.5490e-03 eta 0:14:34
epoch [65/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.029) loss 0.1003 (0.3378) acc 100.0000 (92.1875) lr 1.5490e-03 eta 0:13:25
epoch [65/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4319 (0.3567) acc 84.3750 (91.5000) lr 1.5490e-03 eta 0:12:44
epoch [65/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2651 (0.3621) acc 96.8750 (90.9375) lr 1.5490e-03 eta 0:12:16
epoch [65/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3450 (0.3621) acc 93.7500 (90.8929) lr 1.5490e-03 eta 0:11:56
epoch [65/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4851 (0.3472) acc 90.6250 (91.5625) lr 1.5490e-03 eta 0:11:41
epoch [65/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1118 (0.3535) acc 100.0000 (91.3889) lr 1.5490e-03 eta 0:11:28
epoch [65/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5132 (0.3519) acc 90.6250 (91.4375) lr 1.5490e-03 eta 0:11:18
epoch [66/200] batch [5/51] time 0.086 (0.210) data 0.000 (0.123) loss 0.1869 (0.4308) acc 96.8750 (88.1250) lr 1.5358e-03 eta 0:24:07
epoch [66/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 0.2373 (0.3864) acc 93.7500 (89.3750) lr 1.5358e-03 eta 0:17:01
epoch [66/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.2076 (0.3466) acc 93.7500 (91.2500) lr 1.5358e-03 eta 0:14:39
epoch [66/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.4326 (0.3523) acc 84.3750 (90.4688) lr 1.5358e-03 eta 0:13:27
epoch [66/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.025) loss 0.1938 (0.3505) acc 93.7500 (90.2500) lr 1.5358e-03 eta 0:12:44
epoch [66/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.3259 (0.3684) acc 93.7500 (89.8958) lr 1.5358e-03 eta 0:12:15
epoch [66/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.2041 (0.3560) acc 96.8750 (90.4464) lr 1.5358e-03 eta 0:11:55
epoch [66/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.6074 (0.3604) acc 84.3750 (90.5469) lr 1.5358e-03 eta 0:11:38
epoch [66/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.3989 (0.3557) acc 90.6250 (90.7639) lr 1.5358e-03 eta 0:11:25
epoch [66/200] batch [50/51] time 0.087 (0.099) data 0.000 (0.013) loss 0.3250 (0.3533) acc 90.6250 (90.9375) lr 1.5358e-03 eta 0:11:15
epoch [67/200] batch [5/51] time 0.088 (0.197) data 0.000 (0.110) loss 0.2571 (0.3994) acc 93.7500 (91.8750) lr 1.5225e-03 eta 0:22:26
epoch [67/200] batch [10/51] time 0.088 (0.142) data 0.000 (0.055) loss 0.4587 (0.3490) acc 87.5000 (91.8750) lr 1.5225e-03 eta 0:16:09
epoch [67/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.2764 (0.3717) acc 87.5000 (90.4167) lr 1.5225e-03 eta 0:14:02
epoch [67/200] batch [20/51] time 0.086 (0.114) data 0.000 (0.028) loss 0.2157 (0.3327) acc 93.7500 (91.5625) lr 1.5225e-03 eta 0:12:59
epoch [67/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2279 (0.3333) acc 93.7500 (91.1250) lr 1.5225e-03 eta 0:12:20
epoch [67/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.6001 (0.3408) acc 87.5000 (91.0417) lr 1.5225e-03 eta 0:11:54
epoch [67/200] batch [35/51] time 0.087 (0.102) data 0.000 (0.016) loss 0.5479 (0.3505) acc 81.2500 (90.7143) lr 1.5225e-03 eta 0:11:36
epoch [67/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3115 (0.3518) acc 93.7500 (90.4688) lr 1.5225e-03 eta 0:11:21
epoch [67/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5874 (0.3605) acc 78.1250 (90.2083) lr 1.5225e-03 eta 0:11:10
epoch [67/200] batch [50/51] time 0.086 (0.097) data 0.000 (0.011) loss 0.1250 (0.3459) acc 100.0000 (90.9375) lr 1.5225e-03 eta 0:11:01
epoch [68/200] batch [5/51] time 0.086 (0.210) data 0.000 (0.123) loss 0.1685 (0.2299) acc 100.0000 (95.0000) lr 1.5090e-03 eta 0:23:42
epoch [68/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.7041 (0.3232) acc 84.3750 (91.8750) lr 1.5090e-03 eta 0:16:46
epoch [68/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.1489 (0.3009) acc 96.8750 (92.9167) lr 1.5090e-03 eta 0:14:25
epoch [68/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.5093 (0.3062) acc 84.3750 (92.3438) lr 1.5090e-03 eta 0:13:15
epoch [68/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.025) loss 0.1384 (0.3090) acc 96.8750 (92.2500) lr 1.5090e-03 eta 0:12:32
epoch [68/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.7886 (0.3337) acc 78.1250 (91.5625) lr 1.5090e-03 eta 0:12:04
epoch [68/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.4885 (0.3373) acc 90.6250 (91.2500) lr 1.5090e-03 eta 0:11:44
epoch [68/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.3455 (0.3495) acc 93.7500 (91.1719) lr 1.5090e-03 eta 0:11:28
epoch [68/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3035 (0.3496) acc 93.7500 (91.1806) lr 1.5090e-03 eta 0:11:15
epoch [68/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2272 (0.3374) acc 93.7500 (91.3750) lr 1.5090e-03 eta 0:11:05
epoch [69/200] batch [5/51] time 0.086 (0.204) data 0.000 (0.117) loss 0.3577 (0.3572) acc 87.5000 (90.6250) lr 1.4955e-03 eta 0:22:54
epoch [69/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.2986 (0.3209) acc 93.7500 (92.1875) lr 1.4955e-03 eta 0:16:20
epoch [69/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.039) loss 0.1440 (0.3173) acc 96.8750 (92.2917) lr 1.4955e-03 eta 0:14:09
epoch [69/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.029) loss 0.3335 (0.3280) acc 90.6250 (91.8750) lr 1.4955e-03 eta 0:13:02
epoch [69/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4148 (0.3310) acc 84.3750 (91.6250) lr 1.4955e-03 eta 0:12:23
epoch [69/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.3076 (0.3260) acc 90.6250 (91.6667) lr 1.4955e-03 eta 0:11:56
epoch [69/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3167 (0.3331) acc 84.3750 (91.5179) lr 1.4955e-03 eta 0:11:36
epoch [69/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1766 (0.3349) acc 96.8750 (91.4062) lr 1.4955e-03 eta 0:11:21
epoch [69/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2334 (0.3336) acc 96.8750 (91.5972) lr 1.4955e-03 eta 0:11:09
epoch [69/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4834 (0.3347) acc 87.5000 (91.5000) lr 1.4955e-03 eta 0:10:59
epoch [70/200] batch [5/51] time 0.087 (0.214) data 0.000 (0.126) loss 0.2314 (0.3689) acc 93.7500 (89.3750) lr 1.4818e-03 eta 0:23:45
epoch [70/200] batch [10/51] time 0.086 (0.150) data 0.000 (0.063) loss 0.2896 (0.3356) acc 90.6250 (90.6250) lr 1.4818e-03 eta 0:16:41
epoch [70/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.6689 (0.3752) acc 84.3750 (90.0000) lr 1.4818e-03 eta 0:14:19
epoch [70/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.032) loss 0.1210 (0.3494) acc 100.0000 (90.7812) lr 1.4818e-03 eta 0:13:08
epoch [70/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2263 (0.3553) acc 96.8750 (90.8750) lr 1.4818e-03 eta 0:12:25
epoch [70/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.1439 (0.3467) acc 100.0000 (91.1458) lr 1.4818e-03 eta 0:11:57
epoch [70/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.2096 (0.3509) acc 96.8750 (90.9821) lr 1.4818e-03 eta 0:11:36
epoch [70/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.3042 (0.3486) acc 93.7500 (91.3281) lr 1.4818e-03 eta 0:11:20
epoch [70/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.2067 (0.3454) acc 90.6250 (91.4583) lr 1.4818e-03 eta 0:11:07
epoch [70/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2754 (0.3504) acc 93.7500 (91.0625) lr 1.4818e-03 eta 0:10:57
epoch [71/200] batch [5/51] time 0.087 (0.197) data 0.000 (0.109) loss 0.3145 (0.3332) acc 87.5000 (90.6250) lr 1.4679e-03 eta 0:21:46
epoch [71/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.6079 (0.3014) acc 87.5000 (92.5000) lr 1.4679e-03 eta 0:15:40
epoch [71/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2739 (0.3260) acc 93.7500 (91.8750) lr 1.4679e-03 eta 0:13:38
epoch [71/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.2130 (0.3204) acc 96.8750 (92.0312) lr 1.4679e-03 eta 0:12:37
epoch [71/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.5010 (0.3414) acc 87.5000 (91.3750) lr 1.4679e-03 eta 0:12:00
epoch [71/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1769 (0.3359) acc 100.0000 (92.0833) lr 1.4679e-03 eta 0:11:35
epoch [71/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2930 (0.3460) acc 96.8750 (91.6964) lr 1.4679e-03 eta 0:11:17
epoch [71/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2196 (0.3506) acc 93.7500 (91.4844) lr 1.4679e-03 eta 0:11:03
epoch [71/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.0738 (0.3385) acc 100.0000 (91.8056) lr 1.4679e-03 eta 0:10:52
epoch [71/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2495 (0.3512) acc 96.8750 (91.6250) lr 1.4679e-03 eta 0:10:43
epoch [72/200] batch [5/51] time 0.088 (0.205) data 0.000 (0.117) loss 0.6177 (0.4171) acc 84.3750 (86.8750) lr 1.4540e-03 eta 0:22:29
epoch [72/200] batch [10/51] time 0.088 (0.146) data 0.000 (0.059) loss 0.2450 (0.3696) acc 96.8750 (90.3125) lr 1.4540e-03 eta 0:16:01
epoch [72/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.4150 (0.3240) acc 90.6250 (92.0833) lr 1.4540e-03 eta 0:13:51
epoch [72/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.1671 (0.3042) acc 96.8750 (92.1875) lr 1.4540e-03 eta 0:12:45
epoch [72/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3896 (0.3114) acc 90.6250 (92.2500) lr 1.4540e-03 eta 0:12:05
epoch [72/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.5103 (0.3226) acc 81.2500 (91.3542) lr 1.4540e-03 eta 0:11:39
epoch [72/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3079 (0.3458) acc 93.7500 (91.2500) lr 1.4540e-03 eta 0:11:20
epoch [72/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2676 (0.3459) acc 93.7500 (91.1719) lr 1.4540e-03 eta 0:11:05
epoch [72/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1423 (0.3519) acc 96.8750 (91.2500) lr 1.4540e-03 eta 0:10:53
epoch [72/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3379 (0.3576) acc 90.6250 (91.0625) lr 1.4540e-03 eta 0:10:44
epoch [73/200] batch [5/51] time 0.087 (0.203) data 0.000 (0.115) loss 0.2593 (0.3666) acc 93.7500 (90.0000) lr 1.4399e-03 eta 0:22:03
epoch [73/200] batch [10/51] time 0.088 (0.145) data 0.000 (0.058) loss 0.3635 (0.3579) acc 90.6250 (90.3125) lr 1.4399e-03 eta 0:15:46
epoch [73/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.2546 (0.3398) acc 93.7500 (91.8750) lr 1.4399e-03 eta 0:13:39
epoch [73/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3284 (0.3341) acc 93.7500 (92.0312) lr 1.4399e-03 eta 0:12:36
epoch [73/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5005 (0.3379) acc 84.3750 (91.7500) lr 1.4399e-03 eta 0:11:57
epoch [73/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2666 (0.3354) acc 93.7500 (92.0833) lr 1.4399e-03 eta 0:11:31
epoch [73/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2111 (0.3363) acc 90.6250 (91.7857) lr 1.4399e-03 eta 0:11:12
epoch [73/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2488 (0.3364) acc 90.6250 (91.9531) lr 1.4399e-03 eta 0:10:58
epoch [73/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4448 (0.3379) acc 81.2500 (91.6667) lr 1.4399e-03 eta 0:10:46
epoch [73/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3672 (0.3343) acc 90.6250 (91.6875) lr 1.4399e-03 eta 0:10:37
epoch [74/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.135) loss 0.4553 (0.3373) acc 90.6250 (92.5000) lr 1.4258e-03 eta 0:23:59
epoch [74/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.3862 (0.3936) acc 87.5000 (90.3125) lr 1.4258e-03 eta 0:16:40
epoch [74/200] batch [15/51] time 0.086 (0.132) data 0.000 (0.045) loss 0.3477 (0.3536) acc 90.6250 (91.4583) lr 1.4258e-03 eta 0:14:12
epoch [74/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.6084 (0.3476) acc 81.2500 (91.7188) lr 1.4258e-03 eta 0:12:58
epoch [74/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.6514 (0.3872) acc 84.3750 (90.5000) lr 1.4258e-03 eta 0:12:14
epoch [74/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.5210 (0.3815) acc 90.6250 (90.5208) lr 1.4258e-03 eta 0:11:44
epoch [74/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.5522 (0.3892) acc 84.3750 (90.2679) lr 1.4258e-03 eta 0:11:23
epoch [74/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2864 (0.3771) acc 93.7500 (90.5469) lr 1.4258e-03 eta 0:11:06
epoch [74/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1653 (0.3713) acc 96.8750 (90.6250) lr 1.4258e-03 eta 0:10:53
epoch [74/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2241 (0.3635) acc 93.7500 (90.6875) lr 1.4258e-03 eta 0:10:42
epoch [75/200] batch [5/51] time 0.087 (0.223) data 0.000 (0.136) loss 0.4895 (0.3808) acc 87.5000 (90.0000) lr 1.4115e-03 eta 0:23:50
epoch [75/200] batch [10/51] time 0.086 (0.155) data 0.000 (0.068) loss 0.2246 (0.3639) acc 96.8750 (91.5625) lr 1.4115e-03 eta 0:16:34
epoch [75/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.2537 (0.3492) acc 96.8750 (91.4583) lr 1.4115e-03 eta 0:14:07
epoch [75/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.5908 (0.3475) acc 87.5000 (91.5625) lr 1.4115e-03 eta 0:12:54
epoch [75/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2174 (0.3424) acc 93.7500 (91.6250) lr 1.4115e-03 eta 0:12:09
epoch [75/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4844 (0.3511) acc 87.5000 (91.6667) lr 1.4115e-03 eta 0:11:40
epoch [75/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.3621 (0.3454) acc 87.5000 (91.8750) lr 1.4115e-03 eta 0:11:19
epoch [75/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.6714 (0.3471) acc 81.2500 (91.9531) lr 1.4115e-03 eta 0:11:02
epoch [75/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4639 (0.3595) acc 90.6250 (91.5972) lr 1.4115e-03 eta 0:10:49
epoch [75/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1924 (0.3469) acc 96.8750 (91.7500) lr 1.4115e-03 eta 0:10:38
epoch [76/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.4229 (0.3570) acc 90.6250 (87.5000) lr 1.3971e-03 eta 0:20:59
epoch [76/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.4304 (0.3743) acc 87.5000 (87.8125) lr 1.3971e-03 eta 0:15:05
epoch [76/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.2842 (0.3525) acc 93.7500 (89.1667) lr 1.3971e-03 eta 0:13:06
epoch [76/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.5820 (0.3582) acc 84.3750 (89.2188) lr 1.3971e-03 eta 0:12:06
epoch [76/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1685 (0.3661) acc 96.8750 (89.8750) lr 1.3971e-03 eta 0:11:31
epoch [76/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.2947 (0.3552) acc 93.7500 (90.3125) lr 1.3971e-03 eta 0:11:07
epoch [76/200] batch [35/51] time 0.087 (0.102) data 0.000 (0.016) loss 0.3157 (0.3569) acc 93.7500 (90.2679) lr 1.3971e-03 eta 0:10:49
epoch [76/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1709 (0.3458) acc 96.8750 (90.5469) lr 1.3971e-03 eta 0:10:36
epoch [76/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2078 (0.3419) acc 93.7500 (90.8333) lr 1.3971e-03 eta 0:10:25
epoch [76/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.6494 (0.3422) acc 90.6250 (90.9375) lr 1.3971e-03 eta 0:10:16
epoch [77/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.130) loss 0.4333 (0.3895) acc 87.5000 (91.2500) lr 1.3827e-03 eta 0:22:51
epoch [77/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.1919 (0.3386) acc 96.8750 (93.1250) lr 1.3827e-03 eta 0:15:59
epoch [77/200] batch [15/51] time 0.086 (0.130) data 0.000 (0.043) loss 0.2449 (0.3380) acc 93.7500 (92.5000) lr 1.3827e-03 eta 0:13:42
epoch [77/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.1259 (0.3074) acc 96.8750 (93.2812) lr 1.3827e-03 eta 0:12:33
epoch [77/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.1759 (0.2993) acc 100.0000 (93.6250) lr 1.3827e-03 eta 0:11:52
epoch [77/200] batch [30/51] time 0.089 (0.109) data 0.000 (0.022) loss 0.2467 (0.3214) acc 90.6250 (92.6042) lr 1.3827e-03 eta 0:11:24
epoch [77/200] batch [35/51] time 0.090 (0.106) data 0.000 (0.019) loss 0.5049 (0.3144) acc 87.5000 (92.5893) lr 1.3827e-03 eta 0:11:05
epoch [77/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.016) loss 0.3035 (0.3094) acc 90.6250 (92.8125) lr 1.3827e-03 eta 0:10:50
epoch [77/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3618 (0.3152) acc 87.5000 (92.5694) lr 1.3827e-03 eta 0:10:37
epoch [77/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2177 (0.3304) acc 93.7500 (92.1250) lr 1.3827e-03 eta 0:10:27
epoch [78/200] batch [5/51] time 0.087 (0.207) data 0.000 (0.120) loss 0.3931 (0.3780) acc 93.7500 (93.1250) lr 1.3681e-03 eta 0:21:38
epoch [78/200] batch [10/51] time 0.086 (0.147) data 0.000 (0.060) loss 0.2295 (0.3483) acc 96.8750 (92.5000) lr 1.3681e-03 eta 0:15:21
epoch [78/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.3196 (0.3133) acc 93.7500 (93.1250) lr 1.3681e-03 eta 0:13:14
epoch [78/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.2452 (0.3151) acc 93.7500 (92.5000) lr 1.3681e-03 eta 0:12:10
epoch [78/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4165 (0.3327) acc 93.7500 (92.2500) lr 1.3681e-03 eta 0:11:32
epoch [78/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3940 (0.3273) acc 90.6250 (92.0833) lr 1.3681e-03 eta 0:11:07
epoch [78/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2676 (0.3318) acc 93.7500 (91.9643) lr 1.3681e-03 eta 0:10:49
epoch [78/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4543 (0.3323) acc 93.7500 (92.1094) lr 1.3681e-03 eta 0:10:34
epoch [78/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2201 (0.3295) acc 96.8750 (92.1528) lr 1.3681e-03 eta 0:10:23
epoch [78/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1842 (0.3227) acc 96.8750 (92.3750) lr 1.3681e-03 eta 0:10:13
epoch [79/200] batch [5/51] time 0.087 (0.225) data 0.000 (0.137) loss 0.2773 (0.2999) acc 93.7500 (92.5000) lr 1.3535e-03 eta 0:23:21
epoch [79/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.3896 (0.3213) acc 90.6250 (90.9375) lr 1.3535e-03 eta 0:16:09
epoch [79/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.4724 (0.3528) acc 93.7500 (89.7917) lr 1.3535e-03 eta 0:13:46
epoch [79/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.034) loss 0.4705 (0.3559) acc 87.5000 (89.3750) lr 1.3535e-03 eta 0:12:33
epoch [79/200] batch [25/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.2717 (0.3355) acc 93.7500 (90.3750) lr 1.3535e-03 eta 0:11:50
epoch [79/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3696 (0.3330) acc 90.6250 (90.8333) lr 1.3535e-03 eta 0:11:21
epoch [79/200] batch [35/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.6108 (0.3445) acc 87.5000 (90.6250) lr 1.3535e-03 eta 0:11:01
epoch [79/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2496 (0.3424) acc 93.7500 (90.6250) lr 1.3535e-03 eta 0:10:44
epoch [79/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1294 (0.3297) acc 96.8750 (90.9722) lr 1.3535e-03 eta 0:10:31
epoch [79/200] batch [50/51] time 0.087 (0.101) data 0.000 (0.014) loss 0.3938 (0.3275) acc 84.3750 (91.1250) lr 1.3535e-03 eta 0:10:21
epoch [80/200] batch [5/51] time 0.089 (0.198) data 0.000 (0.109) loss 0.5127 (0.3045) acc 87.5000 (92.5000) lr 1.3387e-03 eta 0:20:20
epoch [80/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.1310 (0.2894) acc 96.8750 (93.1250) lr 1.3387e-03 eta 0:14:39
epoch [80/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.1896 (0.2893) acc 96.8750 (93.7500) lr 1.3387e-03 eta 0:12:45
epoch [80/200] batch [20/51] time 0.088 (0.115) data 0.001 (0.028) loss 0.3997 (0.3184) acc 90.6250 (93.1250) lr 1.3387e-03 eta 0:11:48
epoch [80/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.2034 (0.3150) acc 96.8750 (93.0000) lr 1.3387e-03 eta 0:11:13
epoch [80/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.018) loss 0.3748 (0.3188) acc 90.6250 (92.7083) lr 1.3387e-03 eta 0:10:50
epoch [80/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.3381 (0.3141) acc 87.5000 (92.6786) lr 1.3387e-03 eta 0:10:33
epoch [80/200] batch [40/51] time 0.087 (0.101) data 0.000 (0.014) loss 0.2800 (0.3266) acc 93.7500 (92.3438) lr 1.3387e-03 eta 0:10:20
epoch [80/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.012) loss 0.1003 (0.3243) acc 100.0000 (92.1528) lr 1.3387e-03 eta 0:10:09
epoch [80/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3740 (0.3209) acc 93.7500 (92.1875) lr 1.3387e-03 eta 0:10:01
epoch [81/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.123) loss 0.3374 (0.3467) acc 87.5000 (89.3750) lr 1.3239e-03 eta 0:21:30
epoch [81/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.2637 (0.3057) acc 93.7500 (90.9375) lr 1.3239e-03 eta 0:15:10
epoch [81/200] batch [15/51] time 0.088 (0.128) data 0.000 (0.041) loss 0.2246 (0.2963) acc 96.8750 (92.0833) lr 1.3239e-03 eta 0:13:04
epoch [81/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.3638 (0.3190) acc 90.6250 (91.5625) lr 1.3239e-03 eta 0:12:00
epoch [81/200] batch [25/51] time 0.088 (0.112) data 0.000 (0.025) loss 0.5713 (0.3446) acc 87.5000 (91.1250) lr 1.3239e-03 eta 0:11:20
epoch [81/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3000 (0.3211) acc 93.7500 (91.9792) lr 1.3239e-03 eta 0:10:55
epoch [81/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.3115 (0.3150) acc 96.8750 (92.2321) lr 1.3239e-03 eta 0:10:36
epoch [81/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.4285 (0.3191) acc 81.2500 (91.6406) lr 1.3239e-03 eta 0:10:22
epoch [81/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1738 (0.3055) acc 96.8750 (92.1528) lr 1.3239e-03 eta 0:10:10
epoch [81/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2751 (0.3182) acc 96.8750 (91.7500) lr 1.3239e-03 eta 0:10:01
epoch [82/200] batch [5/51] time 0.087 (0.210) data 0.000 (0.123) loss 0.2749 (0.3381) acc 93.7500 (92.5000) lr 1.3090e-03 eta 0:21:15
epoch [82/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.2878 (0.3478) acc 93.7500 (92.1875) lr 1.3090e-03 eta 0:15:01
epoch [82/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.2407 (0.3472) acc 90.6250 (91.8750) lr 1.3090e-03 eta 0:12:55
epoch [82/200] batch [20/51] time 0.085 (0.118) data 0.000 (0.031) loss 0.3325 (0.3327) acc 93.7500 (92.5000) lr 1.3090e-03 eta 0:11:51
epoch [82/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1672 (0.3180) acc 96.8750 (92.6250) lr 1.3090e-03 eta 0:11:14
epoch [82/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.021) loss 0.3843 (0.3183) acc 90.6250 (92.3958) lr 1.3090e-03 eta 0:10:48
epoch [82/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.4163 (0.3200) acc 84.3750 (91.9643) lr 1.3090e-03 eta 0:10:30
epoch [82/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2224 (0.3056) acc 93.7500 (92.5781) lr 1.3090e-03 eta 0:10:16
epoch [82/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.5347 (0.3121) acc 93.7500 (92.7778) lr 1.3090e-03 eta 0:10:04
epoch [82/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.5254 (0.3174) acc 81.2500 (92.5000) lr 1.3090e-03 eta 0:09:55
epoch [83/200] batch [5/51] time 0.087 (0.221) data 0.000 (0.133) loss 0.3091 (0.3669) acc 93.7500 (93.1250) lr 1.2940e-03 eta 0:22:10
epoch [83/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.1907 (0.3217) acc 93.7500 (93.1250) lr 1.2940e-03 eta 0:15:26
epoch [83/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.044) loss 0.2874 (0.2844) acc 96.8750 (93.7500) lr 1.2940e-03 eta 0:13:10
epoch [83/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.033) loss 0.1246 (0.3141) acc 100.0000 (92.8125) lr 1.2940e-03 eta 0:12:03
epoch [83/200] batch [25/51] time 0.088 (0.114) data 0.000 (0.027) loss 0.1583 (0.3066) acc 96.8750 (93.2500) lr 1.2940e-03 eta 0:11:22
epoch [83/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2520 (0.3040) acc 96.8750 (93.3333) lr 1.2940e-03 eta 0:10:54
epoch [83/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2468 (0.3000) acc 90.6250 (93.1250) lr 1.2940e-03 eta 0:10:35
epoch [83/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2500 (0.3056) acc 90.6250 (92.8906) lr 1.2940e-03 eta 0:10:19
epoch [83/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4106 (0.3100) acc 90.6250 (92.8472) lr 1.2940e-03 eta 0:10:07
epoch [83/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4312 (0.3181) acc 90.6250 (92.5625) lr 1.2940e-03 eta 0:09:57
epoch [84/200] batch [5/51] time 0.087 (0.218) data 0.000 (0.130) loss 0.3047 (0.3067) acc 93.7500 (91.2500) lr 1.2790e-03 eta 0:21:37
epoch [84/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.1956 (0.3621) acc 93.7500 (90.3125) lr 1.2790e-03 eta 0:15:06
epoch [84/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.3069 (0.3496) acc 87.5000 (90.2083) lr 1.2790e-03 eta 0:12:55
epoch [84/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.033) loss 0.1245 (0.3350) acc 96.8750 (90.7812) lr 1.2790e-03 eta 0:11:50
epoch [84/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.026) loss 0.3384 (0.3286) acc 93.7500 (91.1250) lr 1.2790e-03 eta 0:11:10
epoch [84/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.022) loss 0.4124 (0.3295) acc 90.6250 (91.1458) lr 1.2790e-03 eta 0:10:43
epoch [84/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.3403 (0.3315) acc 87.5000 (91.0714) lr 1.2790e-03 eta 0:10:24
epoch [84/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3594 (0.3280) acc 93.7500 (91.2500) lr 1.2790e-03 eta 0:10:10
epoch [84/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2427 (0.3310) acc 96.8750 (91.3889) lr 1.2790e-03 eta 0:09:58
epoch [84/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4773 (0.3268) acc 84.3750 (91.6250) lr 1.2790e-03 eta 0:09:48
epoch [85/200] batch [5/51] time 0.089 (0.206) data 0.000 (0.117) loss 0.3418 (0.2908) acc 90.6250 (91.8750) lr 1.2639e-03 eta 0:20:18
epoch [85/200] batch [10/51] time 0.088 (0.146) data 0.000 (0.059) loss 0.2158 (0.3365) acc 96.8750 (90.9375) lr 1.2639e-03 eta 0:14:25
epoch [85/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.039) loss 0.1788 (0.3500) acc 96.8750 (90.8333) lr 1.2639e-03 eta 0:12:26
epoch [85/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.029) loss 0.0927 (0.3236) acc 100.0000 (91.7188) lr 1.2639e-03 eta 0:11:27
epoch [85/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3618 (0.3173) acc 87.5000 (91.7500) lr 1.2639e-03 eta 0:10:51
epoch [85/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3103 (0.3302) acc 93.7500 (91.4583) lr 1.2639e-03 eta 0:10:28
epoch [85/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1044 (0.3278) acc 100.0000 (91.6964) lr 1.2639e-03 eta 0:10:10
epoch [85/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2295 (0.3233) acc 93.7500 (91.7188) lr 1.2639e-03 eta 0:09:57
epoch [85/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4033 (0.3357) acc 96.8750 (91.5278) lr 1.2639e-03 eta 0:09:46
epoch [85/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3716 (0.3392) acc 93.7500 (91.4375) lr 1.2639e-03 eta 0:09:37
epoch [86/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.117) loss 0.3394 (0.3264) acc 90.6250 (91.8750) lr 1.2487e-03 eta 0:20:01
epoch [86/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.2935 (0.3371) acc 87.5000 (91.2500) lr 1.2487e-03 eta 0:14:13
epoch [86/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.039) loss 0.4011 (0.3442) acc 87.5000 (91.0417) lr 1.2487e-03 eta 0:12:18
epoch [86/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.4365 (0.3475) acc 84.3750 (91.0938) lr 1.2487e-03 eta 0:11:20
epoch [86/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.2739 (0.3391) acc 93.7500 (91.3750) lr 1.2487e-03 eta 0:10:45
epoch [86/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3230 (0.3290) acc 93.7500 (91.6667) lr 1.2487e-03 eta 0:10:22
epoch [86/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2830 (0.3315) acc 96.8750 (92.0536) lr 1.2487e-03 eta 0:10:06
epoch [86/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3777 (0.3336) acc 93.7500 (92.1094) lr 1.2487e-03 eta 0:09:53
epoch [86/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2465 (0.3383) acc 90.6250 (92.0139) lr 1.2487e-03 eta 0:09:42
epoch [86/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4797 (0.3396) acc 90.6250 (91.8125) lr 1.2487e-03 eta 0:09:33
epoch [87/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.124) loss 0.3545 (0.3090) acc 87.5000 (91.2500) lr 1.2334e-03 eta 0:20:30
epoch [87/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.062) loss 0.5464 (0.3483) acc 84.3750 (90.9375) lr 1.2334e-03 eta 0:14:28
epoch [87/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.0813 (0.3697) acc 100.0000 (90.6250) lr 1.2334e-03 eta 0:12:26
epoch [87/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.2001 (0.3574) acc 100.0000 (91.0938) lr 1.2334e-03 eta 0:11:24
epoch [87/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.6787 (0.3580) acc 81.2500 (90.8750) lr 1.2334e-03 eta 0:10:48
epoch [87/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2141 (0.3554) acc 93.7500 (90.7292) lr 1.2334e-03 eta 0:10:23
epoch [87/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.3193 (0.3588) acc 93.7500 (90.6250) lr 1.2334e-03 eta 0:10:05
epoch [87/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.5010 (0.3518) acc 84.3750 (90.7812) lr 1.2334e-03 eta 0:09:52
epoch [87/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.6270 (0.3593) acc 84.3750 (90.6250) lr 1.2334e-03 eta 0:09:40
epoch [87/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3879 (0.3590) acc 81.2500 (90.3750) lr 1.2334e-03 eta 0:09:31
epoch [88/200] batch [5/51] time 0.087 (0.206) data 0.000 (0.118) loss 0.6025 (0.3376) acc 78.1250 (90.6250) lr 1.2181e-03 eta 0:19:47
epoch [88/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.1553 (0.3310) acc 100.0000 (91.2500) lr 1.2181e-03 eta 0:14:04
epoch [88/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.5503 (0.3318) acc 84.3750 (90.6250) lr 1.2181e-03 eta 0:12:09
epoch [88/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.030) loss 0.2007 (0.3372) acc 96.8750 (90.6250) lr 1.2181e-03 eta 0:11:12
epoch [88/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.6279 (0.3454) acc 84.3750 (90.5000) lr 1.2181e-03 eta 0:10:38
epoch [88/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1406 (0.3304) acc 96.8750 (90.7292) lr 1.2181e-03 eta 0:10:14
epoch [88/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3564 (0.3214) acc 93.7500 (91.0714) lr 1.2181e-03 eta 0:09:58
epoch [88/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5137 (0.3340) acc 87.5000 (90.9375) lr 1.2181e-03 eta 0:09:44
epoch [88/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.2837 (0.3440) acc 96.8750 (90.6944) lr 1.2181e-03 eta 0:09:33
epoch [88/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.6040 (0.3451) acc 84.3750 (90.8750) lr 1.2181e-03 eta 0:09:24
epoch [89/200] batch [5/51] time 0.087 (0.207) data 0.000 (0.120) loss 0.1613 (0.3659) acc 96.8750 (91.2500) lr 1.2028e-03 eta 0:19:42
epoch [89/200] batch [10/51] time 0.086 (0.147) data 0.000 (0.060) loss 0.1886 (0.3235) acc 96.8750 (92.5000) lr 1.2028e-03 eta 0:13:57
epoch [89/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.2091 (0.3157) acc 96.8750 (92.5000) lr 1.2028e-03 eta 0:12:02
epoch [89/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3379 (0.3091) acc 93.7500 (92.8125) lr 1.2028e-03 eta 0:11:05
epoch [89/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.2881 (0.3209) acc 93.7500 (92.1250) lr 1.2028e-03 eta 0:10:31
epoch [89/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3625 (0.3172) acc 90.6250 (92.1875) lr 1.2028e-03 eta 0:10:08
epoch [89/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.4062 (0.3316) acc 90.6250 (91.7857) lr 1.2028e-03 eta 0:09:52
epoch [89/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1172 (0.3263) acc 96.8750 (91.6406) lr 1.2028e-03 eta 0:09:38
epoch [89/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.5283 (0.3336) acc 84.3750 (91.3194) lr 1.2028e-03 eta 0:09:28
epoch [89/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2788 (0.3265) acc 93.7500 (91.3750) lr 1.2028e-03 eta 0:09:19
epoch [90/200] batch [5/51] time 0.086 (0.220) data 0.000 (0.133) loss 0.1522 (0.1905) acc 100.0000 (96.2500) lr 1.1874e-03 eta 0:20:46
epoch [90/200] batch [10/51] time 0.088 (0.154) data 0.000 (0.067) loss 0.0977 (0.2449) acc 100.0000 (94.6875) lr 1.1874e-03 eta 0:14:30
epoch [90/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.1973 (0.2497) acc 96.8750 (95.2083) lr 1.1874e-03 eta 0:12:24
epoch [90/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.033) loss 0.2170 (0.2708) acc 93.7500 (94.3750) lr 1.1874e-03 eta 0:11:20
epoch [90/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2327 (0.2709) acc 96.8750 (94.2500) lr 1.1874e-03 eta 0:10:42
epoch [90/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.5293 (0.2852) acc 87.5000 (93.6458) lr 1.1874e-03 eta 0:10:16
epoch [90/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4258 (0.2904) acc 84.3750 (93.3036) lr 1.1874e-03 eta 0:09:57
epoch [90/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.4143 (0.2965) acc 90.6250 (93.2812) lr 1.1874e-03 eta 0:09:43
epoch [90/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4282 (0.3084) acc 90.6250 (92.9167) lr 1.1874e-03 eta 0:09:31
epoch [90/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1439 (0.3009) acc 96.8750 (93.1875) lr 1.1874e-03 eta 0:09:22
epoch [91/200] batch [5/51] time 0.087 (0.209) data 0.000 (0.120) loss 0.4421 (0.4194) acc 90.6250 (88.7500) lr 1.1719e-03 eta 0:19:29
epoch [91/200] batch [10/51] time 0.086 (0.148) data 0.000 (0.060) loss 0.2842 (0.3772) acc 90.6250 (90.9375) lr 1.1719e-03 eta 0:13:47
epoch [91/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.3242 (0.3461) acc 93.7500 (91.8750) lr 1.1719e-03 eta 0:11:53
epoch [91/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.1340 (0.3198) acc 100.0000 (92.5000) lr 1.1719e-03 eta 0:10:55
epoch [91/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.6724 (0.3230) acc 87.5000 (92.3750) lr 1.1719e-03 eta 0:10:20
epoch [91/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2031 (0.3317) acc 100.0000 (92.2917) lr 1.1719e-03 eta 0:09:57
epoch [91/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2382 (0.3385) acc 93.7500 (92.3214) lr 1.1719e-03 eta 0:09:40
epoch [91/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2137 (0.3331) acc 96.8750 (92.4219) lr 1.1719e-03 eta 0:09:27
epoch [91/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.7285 (0.3345) acc 81.2500 (92.2222) lr 1.1719e-03 eta 0:09:17
epoch [91/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3303 (0.3381) acc 93.7500 (92.2500) lr 1.1719e-03 eta 0:09:08
epoch [92/200] batch [5/51] time 0.087 (0.227) data 0.000 (0.139) loss 0.1298 (0.3422) acc 96.8750 (91.2500) lr 1.1564e-03 eta 0:21:00
epoch [92/200] batch [10/51] time 0.088 (0.157) data 0.000 (0.070) loss 0.3486 (0.3339) acc 93.7500 (92.5000) lr 1.1564e-03 eta 0:14:32
epoch [92/200] batch [15/51] time 0.087 (0.134) data 0.000 (0.046) loss 0.3628 (0.2993) acc 93.7500 (93.5417) lr 1.1564e-03 eta 0:12:21
epoch [92/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.3154 (0.3082) acc 87.5000 (92.5000) lr 1.1564e-03 eta 0:11:16
epoch [92/200] batch [25/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.3635 (0.3222) acc 90.6250 (92.3750) lr 1.1564e-03 eta 0:10:37
epoch [92/200] batch [30/51] time 0.087 (0.111) data 0.000 (0.023) loss 0.2131 (0.3282) acc 93.7500 (92.0833) lr 1.1564e-03 eta 0:10:11
epoch [92/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2192 (0.3421) acc 96.8750 (91.8750) lr 1.1564e-03 eta 0:09:52
epoch [92/200] batch [40/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.6011 (0.3500) acc 81.2500 (91.5625) lr 1.1564e-03 eta 0:09:37
epoch [92/200] batch [45/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2791 (0.3438) acc 93.7500 (91.5278) lr 1.1564e-03 eta 0:09:25
epoch [92/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3152 (0.3390) acc 96.8750 (91.8750) lr 1.1564e-03 eta 0:09:15
epoch [93/200] batch [5/51] time 0.088 (0.198) data 0.000 (0.110) loss 0.2377 (0.2874) acc 93.7500 (93.1250) lr 1.1409e-03 eta 0:18:10
epoch [93/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.2847 (0.3358) acc 90.6250 (90.3125) lr 1.1409e-03 eta 0:13:05
epoch [93/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.3291 (0.3586) acc 90.6250 (90.0000) lr 1.1409e-03 eta 0:11:22
epoch [93/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3474 (0.3390) acc 87.5000 (90.6250) lr 1.1409e-03 eta 0:10:31
epoch [93/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.6470 (0.3304) acc 87.5000 (91.2500) lr 1.1409e-03 eta 0:10:00
epoch [93/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3037 (0.3181) acc 93.7500 (91.6667) lr 1.1409e-03 eta 0:09:39
epoch [93/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3157 (0.3251) acc 93.7500 (91.6071) lr 1.1409e-03 eta 0:09:24
epoch [93/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.4526 (0.3273) acc 90.6250 (91.7188) lr 1.1409e-03 eta 0:09:12
epoch [93/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4167 (0.3247) acc 90.6250 (91.6667) lr 1.1409e-03 eta 0:09:02
epoch [93/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.2241 (0.3309) acc 96.8750 (91.5625) lr 1.1409e-03 eta 0:08:54
epoch [94/200] batch [5/51] time 0.088 (0.208) data 0.000 (0.120) loss 0.2426 (0.2916) acc 93.7500 (91.8750) lr 1.1253e-03 eta 0:18:54
epoch [94/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.2883 (0.3221) acc 93.7500 (90.9375) lr 1.1253e-03 eta 0:13:24
epoch [94/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.2378 (0.3154) acc 96.8750 (91.8750) lr 1.1253e-03 eta 0:11:33
epoch [94/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3950 (0.3397) acc 84.3750 (91.0938) lr 1.1253e-03 eta 0:10:37
epoch [94/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1454 (0.3205) acc 100.0000 (91.8750) lr 1.1253e-03 eta 0:10:04
epoch [94/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.020) loss 0.1954 (0.3242) acc 96.8750 (91.6667) lr 1.1253e-03 eta 0:09:41
epoch [94/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.6128 (0.3480) acc 81.2500 (90.7143) lr 1.1253e-03 eta 0:09:25
epoch [94/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3955 (0.3620) acc 93.7500 (90.6250) lr 1.1253e-03 eta 0:09:12
epoch [94/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2917 (0.3576) acc 90.6250 (90.4167) lr 1.1253e-03 eta 0:09:02
epoch [94/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2318 (0.3509) acc 90.6250 (90.6250) lr 1.1253e-03 eta 0:08:54
epoch [95/200] batch [5/51] time 0.087 (0.208) data 0.000 (0.120) loss 0.2515 (0.3002) acc 93.7500 (94.3750) lr 1.1097e-03 eta 0:18:42
epoch [95/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.1459 (0.2907) acc 96.8750 (93.7500) lr 1.1097e-03 eta 0:13:16
epoch [95/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.2285 (0.3173) acc 93.7500 (92.9167) lr 1.1097e-03 eta 0:11:25
epoch [95/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3398 (0.3359) acc 87.5000 (91.8750) lr 1.1097e-03 eta 0:10:30
epoch [95/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.3970 (0.3349) acc 90.6250 (91.3750) lr 1.1097e-03 eta 0:09:57
epoch [95/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.020) loss 0.2903 (0.3282) acc 93.7500 (91.7708) lr 1.1097e-03 eta 0:09:35
epoch [95/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3064 (0.3413) acc 93.7500 (91.4286) lr 1.1097e-03 eta 0:09:19
epoch [95/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3550 (0.3458) acc 87.5000 (91.1719) lr 1.1097e-03 eta 0:09:06
epoch [95/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2783 (0.3400) acc 96.8750 (91.5972) lr 1.1097e-03 eta 0:08:56
epoch [95/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5503 (0.3404) acc 87.5000 (91.7500) lr 1.1097e-03 eta 0:08:48
epoch [96/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.123) loss 0.4805 (0.3518) acc 84.3750 (91.2500) lr 1.0941e-03 eta 0:18:47
epoch [96/200] batch [10/51] time 0.088 (0.149) data 0.000 (0.062) loss 0.1122 (0.3595) acc 100.0000 (90.9375) lr 1.0941e-03 eta 0:13:15
epoch [96/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.4407 (0.3485) acc 87.5000 (91.0417) lr 1.0941e-03 eta 0:11:24
epoch [96/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.4290 (0.3570) acc 90.6250 (91.0938) lr 1.0941e-03 eta 0:10:29
epoch [96/200] batch [25/51] time 0.088 (0.112) data 0.000 (0.025) loss 0.2603 (0.3448) acc 90.6250 (91.5000) lr 1.0941e-03 eta 0:09:55
epoch [96/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3137 (0.3527) acc 93.7500 (91.0417) lr 1.0941e-03 eta 0:09:33
epoch [96/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.5352 (0.3478) acc 84.3750 (91.2500) lr 1.0941e-03 eta 0:09:16
epoch [96/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.3259 (0.3516) acc 93.7500 (91.0938) lr 1.0941e-03 eta 0:09:03
epoch [96/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1920 (0.3354) acc 96.8750 (91.7361) lr 1.0941e-03 eta 0:08:53
epoch [96/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3926 (0.3269) acc 93.7500 (92.1250) lr 1.0941e-03 eta 0:08:45
epoch [97/200] batch [5/51] time 0.088 (0.200) data 0.000 (0.112) loss 0.3240 (0.3054) acc 90.6250 (92.5000) lr 1.0785e-03 eta 0:17:42
epoch [97/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.3809 (0.2822) acc 87.5000 (93.1250) lr 1.0785e-03 eta 0:12:41
epoch [97/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.038) loss 0.3105 (0.2862) acc 93.7500 (92.9167) lr 1.0785e-03 eta 0:11:01
epoch [97/200] batch [20/51] time 0.087 (0.116) data 0.001 (0.028) loss 0.2991 (0.2713) acc 90.6250 (93.2812) lr 1.0785e-03 eta 0:10:11
epoch [97/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4954 (0.2894) acc 87.5000 (93.0000) lr 1.0785e-03 eta 0:09:40
epoch [97/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.3015 (0.2913) acc 90.6250 (92.7083) lr 1.0785e-03 eta 0:09:19
epoch [97/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.5088 (0.3039) acc 84.3750 (92.4107) lr 1.0785e-03 eta 0:09:05
epoch [97/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3438 (0.3045) acc 90.6250 (92.1875) lr 1.0785e-03 eta 0:08:53
epoch [97/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4116 (0.3053) acc 87.5000 (92.1528) lr 1.0785e-03 eta 0:08:43
epoch [97/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2208 (0.3172) acc 96.8750 (91.8125) lr 1.0785e-03 eta 0:08:36
epoch [98/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.117) loss 0.4160 (0.3131) acc 90.6250 (93.1250) lr 1.0628e-03 eta 0:17:53
epoch [98/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.1907 (0.3290) acc 100.0000 (92.5000) lr 1.0628e-03 eta 0:12:44
epoch [98/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.2754 (0.3134) acc 96.8750 (93.3333) lr 1.0628e-03 eta 0:11:01
epoch [98/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.029) loss 0.6299 (0.3308) acc 81.2500 (92.9688) lr 1.0628e-03 eta 0:10:09
epoch [98/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.5317 (0.3247) acc 87.5000 (93.1250) lr 1.0628e-03 eta 0:09:37
epoch [98/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.6069 (0.3406) acc 90.6250 (92.9167) lr 1.0628e-03 eta 0:09:16
epoch [98/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.6729 (0.3526) acc 84.3750 (92.4107) lr 1.0628e-03 eta 0:09:01
epoch [98/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1614 (0.3504) acc 93.7500 (92.3438) lr 1.0628e-03 eta 0:08:49
epoch [98/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4968 (0.3601) acc 90.6250 (91.9444) lr 1.0628e-03 eta 0:08:39
epoch [98/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3584 (0.3497) acc 87.5000 (92.1875) lr 1.0628e-03 eta 0:08:31
epoch [99/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.2015 (0.3233) acc 96.8750 (93.1250) lr 1.0471e-03 eta 0:17:19
epoch [99/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.5361 (0.3470) acc 84.3750 (91.5625) lr 1.0471e-03 eta 0:12:26
epoch [99/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.037) loss 0.3215 (0.3369) acc 87.5000 (91.4583) lr 1.0471e-03 eta 0:10:48
epoch [99/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.4329 (0.3482) acc 93.7500 (91.7188) lr 1.0471e-03 eta 0:09:58
epoch [99/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4636 (0.3588) acc 87.5000 (90.7500) lr 1.0471e-03 eta 0:09:28
epoch [99/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.3574 (0.3585) acc 93.7500 (90.6250) lr 1.0471e-03 eta 0:09:08
epoch [99/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.4275 (0.3660) acc 93.7500 (90.5357) lr 1.0471e-03 eta 0:08:53
epoch [99/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3828 (0.3591) acc 90.6250 (90.8594) lr 1.0471e-03 eta 0:08:42
epoch [99/200] batch [45/51] time 0.087 (0.099) data 0.000 (0.013) loss 0.1820 (0.3498) acc 100.0000 (91.1111) lr 1.0471e-03 eta 0:08:33
epoch [99/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4060 (0.3643) acc 87.5000 (90.8125) lr 1.0471e-03 eta 0:08:25
epoch [100/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.134) loss 0.2350 (0.2962) acc 93.7500 (93.1250) lr 1.0314e-03 eta 0:19:00
epoch [100/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.4207 (0.3325) acc 90.6250 (92.1875) lr 1.0314e-03 eta 0:13:13
epoch [100/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.1251 (0.3489) acc 100.0000 (91.4583) lr 1.0314e-03 eta 0:11:17
epoch [100/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.2502 (0.3426) acc 90.6250 (91.7188) lr 1.0314e-03 eta 0:10:19
epoch [100/200] batch [25/51] time 0.088 (0.114) data 0.000 (0.027) loss 0.5718 (0.3507) acc 84.3750 (91.1250) lr 1.0314e-03 eta 0:09:44
epoch [100/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.3203 (0.3423) acc 93.7500 (91.4583) lr 1.0314e-03 eta 0:09:20
epoch [100/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.2668 (0.3296) acc 90.6250 (91.5179) lr 1.0314e-03 eta 0:09:03
epoch [100/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.5747 (0.3283) acc 90.6250 (91.6406) lr 1.0314e-03 eta 0:08:50
epoch [100/200] batch [45/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.2355 (0.3274) acc 96.8750 (91.5972) lr 1.0314e-03 eta 0:08:39
epoch [100/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2064 (0.3222) acc 93.7500 (91.8125) lr 1.0314e-03 eta 0:08:30
epoch [101/200] batch [5/51] time 0.088 (0.216) data 0.000 (0.128) loss 0.1422 (0.2018) acc 96.8750 (96.2500) lr 1.0157e-03 eta 0:18:18
epoch [101/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.3364 (0.2580) acc 90.6250 (94.0625) lr 1.0157e-03 eta 0:12:50
epoch [101/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.3354 (0.2928) acc 84.3750 (92.2917) lr 1.0157e-03 eta 0:11:00
epoch [101/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.5459 (0.2946) acc 84.3750 (92.8125) lr 1.0157e-03 eta 0:10:05
epoch [101/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2208 (0.2959) acc 96.8750 (93.1250) lr 1.0157e-03 eta 0:09:32
epoch [101/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.022) loss 0.3167 (0.3096) acc 93.7500 (93.0208) lr 1.0157e-03 eta 0:09:09
epoch [101/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3193 (0.3146) acc 93.7500 (92.7679) lr 1.0157e-03 eta 0:08:53
epoch [101/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4412 (0.3363) acc 90.6250 (92.3438) lr 1.0157e-03 eta 0:08:41
epoch [101/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5024 (0.3466) acc 87.5000 (91.5972) lr 1.0157e-03 eta 0:08:31
epoch [101/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2585 (0.3442) acc 93.7500 (91.6250) lr 1.0157e-03 eta 0:08:23
epoch [102/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.125) loss 0.2288 (0.3070) acc 93.7500 (93.1250) lr 1.0000e-03 eta 0:17:55
epoch [102/200] batch [10/51] time 0.086 (0.150) data 0.000 (0.063) loss 0.1847 (0.2727) acc 96.8750 (94.6875) lr 1.0000e-03 eta 0:12:35
epoch [102/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.4529 (0.3333) acc 84.3750 (92.0833) lr 1.0000e-03 eta 0:10:48
epoch [102/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.3733 (0.3121) acc 87.5000 (92.1875) lr 1.0000e-03 eta 0:09:54
epoch [102/200] batch [25/51] time 0.088 (0.112) data 0.000 (0.025) loss 0.2411 (0.3034) acc 93.7500 (92.5000) lr 1.0000e-03 eta 0:09:22
epoch [102/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3792 (0.3179) acc 84.3750 (91.6667) lr 1.0000e-03 eta 0:09:01
epoch [102/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3525 (0.3076) acc 93.7500 (92.2321) lr 1.0000e-03 eta 0:08:45
epoch [102/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2600 (0.3085) acc 96.8750 (92.3438) lr 1.0000e-03 eta 0:08:33
epoch [102/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3494 (0.3056) acc 96.8750 (92.5694) lr 1.0000e-03 eta 0:08:23
epoch [102/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1238 (0.3037) acc 100.0000 (92.5000) lr 1.0000e-03 eta 0:08:15
epoch [103/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.117) loss 0.3003 (0.3746) acc 93.7500 (91.2500) lr 9.8429e-04 eta 0:17:01
epoch [103/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.4529 (0.4430) acc 93.7500 (89.6875) lr 9.8429e-04 eta 0:12:08
epoch [103/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.1942 (0.4102) acc 93.7500 (90.4167) lr 9.8429e-04 eta 0:10:28
epoch [103/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.2448 (0.4081) acc 93.7500 (90.4688) lr 9.8429e-04 eta 0:09:39
epoch [103/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.2871 (0.4000) acc 93.7500 (90.7500) lr 9.8429e-04 eta 0:09:09
epoch [103/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.4556 (0.3977) acc 87.5000 (90.7292) lr 9.8429e-04 eta 0:08:48
epoch [103/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2993 (0.3939) acc 93.7500 (91.2500) lr 9.8429e-04 eta 0:08:34
epoch [103/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3970 (0.3886) acc 87.5000 (91.0938) lr 9.8429e-04 eta 0:08:23
epoch [103/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4478 (0.3807) acc 87.5000 (91.2500) lr 9.8429e-04 eta 0:08:13
epoch [103/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2375 (0.3706) acc 93.7500 (91.6250) lr 9.8429e-04 eta 0:08:06
epoch [104/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.125) loss 0.1733 (0.3324) acc 96.8750 (92.5000) lr 9.6859e-04 eta 0:17:31
epoch [104/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.4392 (0.3192) acc 84.3750 (92.8125) lr 9.6859e-04 eta 0:12:20
epoch [104/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.4961 (0.3738) acc 87.5000 (90.4167) lr 9.6859e-04 eta 0:10:36
epoch [104/200] batch [20/51] time 0.088 (0.118) data 0.000 (0.031) loss 0.2803 (0.3533) acc 93.7500 (91.4062) lr 9.6859e-04 eta 0:09:43
epoch [104/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.3145 (0.3405) acc 93.7500 (91.6250) lr 9.6859e-04 eta 0:09:12
epoch [104/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3862 (0.3447) acc 93.7500 (92.0833) lr 9.6859e-04 eta 0:08:51
epoch [104/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3682 (0.3327) acc 87.5000 (92.2321) lr 9.6859e-04 eta 0:08:35
epoch [104/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2100 (0.3233) acc 96.8750 (92.2656) lr 9.6859e-04 eta 0:08:23
epoch [104/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5459 (0.3314) acc 87.5000 (92.0139) lr 9.6859e-04 eta 0:08:13
epoch [104/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.5000 (0.3250) acc 90.6250 (92.3125) lr 9.6859e-04 eta 0:08:05
epoch [105/200] batch [5/51] time 0.087 (0.209) data 0.000 (0.122) loss 0.2854 (0.2330) acc 96.8750 (95.6250) lr 9.5289e-04 eta 0:17:02
epoch [105/200] batch [10/51] time 0.088 (0.148) data 0.000 (0.061) loss 0.2196 (0.2434) acc 96.8750 (95.3125) lr 9.5289e-04 eta 0:12:04
epoch [105/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.2820 (0.2505) acc 93.7500 (95.0000) lr 9.5289e-04 eta 0:10:24
epoch [105/200] batch [20/51] time 0.090 (0.118) data 0.000 (0.031) loss 0.3638 (0.2737) acc 90.6250 (94.0625) lr 9.5289e-04 eta 0:09:34
epoch [105/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2554 (0.2702) acc 96.8750 (94.0000) lr 9.5289e-04 eta 0:09:04
epoch [105/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.021) loss 0.1105 (0.2868) acc 96.8750 (93.4375) lr 9.5289e-04 eta 0:08:44
epoch [105/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1254 (0.2867) acc 96.8750 (93.5714) lr 9.5289e-04 eta 0:08:29
epoch [105/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3538 (0.2815) acc 93.7500 (93.9844) lr 9.5289e-04 eta 0:08:17
epoch [105/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5581 (0.2950) acc 87.5000 (93.5417) lr 9.5289e-04 eta 0:08:08
epoch [105/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.6040 (0.2953) acc 84.3750 (93.5000) lr 9.5289e-04 eta 0:08:00
epoch [106/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.1974 (0.3381) acc 93.7500 (92.5000) lr 9.3721e-04 eta 0:16:07
epoch [106/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.056) loss 0.2319 (0.2813) acc 90.6250 (94.0625) lr 9.3721e-04 eta 0:11:34
epoch [106/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.037) loss 0.1674 (0.3037) acc 96.8750 (93.1250) lr 9.3721e-04 eta 0:10:02
epoch [106/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3569 (0.2976) acc 93.7500 (93.4375) lr 9.3721e-04 eta 0:09:16
epoch [106/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4084 (0.2921) acc 90.6250 (93.3750) lr 9.3721e-04 eta 0:08:48
epoch [106/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3093 (0.2995) acc 93.7500 (93.3333) lr 9.3721e-04 eta 0:08:29
epoch [106/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2418 (0.2996) acc 93.7500 (93.4821) lr 9.3721e-04 eta 0:08:15
epoch [106/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2334 (0.3122) acc 93.7500 (92.8906) lr 9.3721e-04 eta 0:08:05
epoch [106/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4116 (0.3090) acc 90.6250 (92.9167) lr 9.3721e-04 eta 0:07:56
epoch [106/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4431 (0.3127) acc 87.5000 (92.7500) lr 9.3721e-04 eta 0:07:49
epoch [107/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.113) loss 0.2438 (0.2992) acc 93.7500 (91.8750) lr 9.2154e-04 eta 0:16:01
epoch [107/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.057) loss 0.3386 (0.3448) acc 90.6250 (90.6250) lr 9.2154e-04 eta 0:11:29
epoch [107/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.3274 (0.3289) acc 90.6250 (91.4583) lr 9.2154e-04 eta 0:09:56
epoch [107/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4336 (0.3164) acc 84.3750 (91.5625) lr 9.2154e-04 eta 0:09:10
epoch [107/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1649 (0.3069) acc 96.8750 (92.2500) lr 9.2154e-04 eta 0:08:43
epoch [107/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.1577 (0.3083) acc 100.0000 (92.3958) lr 9.2154e-04 eta 0:08:25
epoch [107/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.1619 (0.3129) acc 93.7500 (92.0536) lr 9.2154e-04 eta 0:08:12
epoch [107/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3616 (0.3238) acc 93.7500 (91.7969) lr 9.2154e-04 eta 0:08:01
epoch [107/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4075 (0.3198) acc 93.7500 (92.0139) lr 9.2154e-04 eta 0:07:53
epoch [107/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2913 (0.3152) acc 93.7500 (92.0625) lr 9.2154e-04 eta 0:07:46
epoch [108/200] batch [5/51] time 0.087 (0.206) data 0.000 (0.118) loss 0.3303 (0.3055) acc 90.6250 (90.6250) lr 9.0589e-04 eta 0:16:16
epoch [108/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.4138 (0.3918) acc 96.8750 (90.6250) lr 9.0589e-04 eta 0:11:33
epoch [108/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.040) loss 0.4915 (0.3693) acc 87.5000 (91.2500) lr 9.0589e-04 eta 0:09:58
epoch [108/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.3379 (0.3635) acc 87.5000 (90.7812) lr 9.0589e-04 eta 0:09:10
epoch [108/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.6201 (0.3561) acc 81.2500 (90.7500) lr 9.0589e-04 eta 0:08:41
epoch [108/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.6826 (0.3515) acc 87.5000 (91.1458) lr 9.0589e-04 eta 0:08:22
epoch [108/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1126 (0.3370) acc 100.0000 (91.6964) lr 9.0589e-04 eta 0:08:08
epoch [108/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2554 (0.3226) acc 93.7500 (92.0312) lr 9.0589e-04 eta 0:07:57
epoch [108/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3865 (0.3358) acc 87.5000 (91.4583) lr 9.0589e-04 eta 0:07:49
epoch [108/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.2286 (0.3408) acc 93.7500 (91.3750) lr 9.0589e-04 eta 0:07:42
epoch [109/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.113) loss 0.4048 (0.3474) acc 90.6250 (91.8750) lr 8.9027e-04 eta 0:15:41
epoch [109/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.2549 (0.2749) acc 93.7500 (94.0625) lr 8.9027e-04 eta 0:11:13
epoch [109/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.5083 (0.3033) acc 87.5000 (93.3333) lr 8.9027e-04 eta 0:09:43
epoch [109/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.028) loss 0.2303 (0.2986) acc 96.8750 (93.5938) lr 8.9027e-04 eta 0:08:58
epoch [109/200] batch [25/51] time 0.088 (0.109) data 0.000 (0.023) loss 0.2391 (0.2845) acc 90.6250 (93.7500) lr 8.9027e-04 eta 0:08:30
epoch [109/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.4919 (0.2871) acc 90.6250 (93.6458) lr 8.9027e-04 eta 0:08:12
epoch [109/200] batch [35/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2181 (0.2841) acc 93.7500 (93.8393) lr 8.9027e-04 eta 0:07:59
epoch [109/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2263 (0.2922) acc 93.7500 (93.2812) lr 8.9027e-04 eta 0:07:49
epoch [109/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.5312 (0.2994) acc 93.7500 (93.1250) lr 8.9027e-04 eta 0:07:40
epoch [109/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2566 (0.2968) acc 93.7500 (93.1875) lr 8.9027e-04 eta 0:07:34
epoch [110/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.114) loss 0.1974 (0.3020) acc 93.7500 (90.0000) lr 8.7467e-04 eta 0:15:36
epoch [110/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.2642 (0.3132) acc 93.7500 (90.9375) lr 8.7467e-04 eta 0:11:09
epoch [110/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.038) loss 0.3374 (0.3135) acc 90.6250 (91.0417) lr 8.7467e-04 eta 0:09:40
epoch [110/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.4241 (0.3339) acc 93.7500 (90.7812) lr 8.7467e-04 eta 0:08:54
epoch [110/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3354 (0.3450) acc 90.6250 (90.1250) lr 8.7467e-04 eta 0:08:27
epoch [110/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2283 (0.3169) acc 96.8750 (91.4583) lr 8.7467e-04 eta 0:08:09
epoch [110/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2715 (0.3176) acc 93.7500 (91.6071) lr 8.7467e-04 eta 0:07:56
epoch [110/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.4709 (0.3206) acc 90.6250 (91.7969) lr 8.7467e-04 eta 0:07:45
epoch [110/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2085 (0.3162) acc 96.8750 (92.0139) lr 8.7467e-04 eta 0:07:37
epoch [110/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.5771 (0.3241) acc 90.6250 (91.9375) lr 8.7467e-04 eta 0:07:30
epoch [111/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.114) loss 0.2712 (0.3070) acc 93.7500 (93.7500) lr 8.5910e-04 eta 0:15:28
epoch [111/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.3181 (0.3021) acc 93.7500 (94.0625) lr 8.5910e-04 eta 0:11:02
epoch [111/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.2766 (0.2989) acc 93.7500 (93.9583) lr 8.5910e-04 eta 0:09:33
epoch [111/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2939 (0.3167) acc 90.6250 (92.8125) lr 8.5910e-04 eta 0:08:48
epoch [111/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.1231 (0.3055) acc 93.7500 (92.7500) lr 8.5910e-04 eta 0:08:21
epoch [111/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3149 (0.3051) acc 93.7500 (93.1250) lr 8.5910e-04 eta 0:08:04
epoch [111/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1181 (0.2979) acc 96.8750 (93.2143) lr 8.5910e-04 eta 0:07:50
epoch [111/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.5361 (0.3140) acc 90.6250 (92.9688) lr 8.5910e-04 eta 0:07:40
epoch [111/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.5039 (0.3116) acc 90.6250 (93.0556) lr 8.5910e-04 eta 0:07:32
epoch [111/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.6577 (0.3249) acc 87.5000 (92.9375) lr 8.5910e-04 eta 0:07:25
epoch [112/200] batch [5/51] time 0.087 (0.219) data 0.000 (0.131) loss 0.5425 (0.3603) acc 84.3750 (91.2500) lr 8.4357e-04 eta 0:16:30
epoch [112/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.065) loss 0.4185 (0.3329) acc 87.5000 (91.2500) lr 8.4357e-04 eta 0:11:32
epoch [112/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.1960 (0.3211) acc 96.8750 (92.0833) lr 8.4357e-04 eta 0:09:52
epoch [112/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.2034 (0.3251) acc 96.8750 (92.0312) lr 8.4357e-04 eta 0:09:02
epoch [112/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.4700 (0.3448) acc 84.3750 (91.8750) lr 8.4357e-04 eta 0:08:31
epoch [112/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3147 (0.3300) acc 87.5000 (91.8750) lr 8.4357e-04 eta 0:08:11
epoch [112/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3069 (0.3268) acc 87.5000 (91.6964) lr 8.4357e-04 eta 0:07:56
epoch [112/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.4397 (0.3222) acc 84.3750 (91.8750) lr 8.4357e-04 eta 0:07:44
epoch [112/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2190 (0.3160) acc 93.7500 (91.9444) lr 8.4357e-04 eta 0:07:35
epoch [112/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1522 (0.3088) acc 96.8750 (91.8750) lr 8.4357e-04 eta 0:07:28
epoch [113/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.130) loss 0.3782 (0.3614) acc 93.7500 (93.1250) lr 8.2807e-04 eta 0:16:13
epoch [113/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.3589 (0.3355) acc 90.6250 (92.1875) lr 8.2807e-04 eta 0:11:20
epoch [113/200] batch [15/51] time 0.086 (0.130) data 0.000 (0.043) loss 0.3022 (0.3126) acc 96.8750 (92.2917) lr 8.2807e-04 eta 0:09:41
epoch [113/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.033) loss 0.2489 (0.2996) acc 93.7500 (92.6562) lr 8.2807e-04 eta 0:08:52
epoch [113/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.5322 (0.3076) acc 90.6250 (92.7500) lr 8.2807e-04 eta 0:08:22
epoch [113/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.022) loss 0.5225 (0.3012) acc 87.5000 (93.0208) lr 8.2807e-04 eta 0:08:02
epoch [113/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.3865 (0.3098) acc 90.6250 (92.7679) lr 8.2807e-04 eta 0:07:48
epoch [113/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2791 (0.3120) acc 93.7500 (92.6562) lr 8.2807e-04 eta 0:07:37
epoch [113/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1914 (0.3084) acc 100.0000 (92.9167) lr 8.2807e-04 eta 0:07:28
epoch [113/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1550 (0.3043) acc 100.0000 (93.0000) lr 8.2807e-04 eta 0:07:21
epoch [114/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.110) loss 0.1796 (0.2670) acc 96.8750 (94.3750) lr 8.1262e-04 eta 0:14:40
epoch [114/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.1476 (0.3098) acc 100.0000 (93.1250) lr 8.1262e-04 eta 0:10:31
epoch [114/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.2334 (0.2938) acc 93.7500 (93.9583) lr 8.1262e-04 eta 0:09:08
epoch [114/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.1962 (0.2958) acc 96.8750 (93.4375) lr 8.1262e-04 eta 0:08:27
epoch [114/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2493 (0.2882) acc 96.8750 (93.7500) lr 8.1262e-04 eta 0:08:01
epoch [114/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3638 (0.2808) acc 93.7500 (94.0625) lr 8.1262e-04 eta 0:07:44
epoch [114/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1293 (0.2926) acc 100.0000 (93.8393) lr 8.1262e-04 eta 0:07:32
epoch [114/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.6274 (0.3198) acc 87.5000 (93.1250) lr 8.1262e-04 eta 0:07:23
epoch [114/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.3647 (0.3153) acc 96.8750 (93.1944) lr 8.1262e-04 eta 0:07:15
epoch [114/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1733 (0.3125) acc 96.8750 (93.1250) lr 8.1262e-04 eta 0:07:08
epoch [115/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.117) loss 0.1951 (0.2197) acc 96.8750 (95.0000) lr 7.9721e-04 eta 0:14:58
epoch [115/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.3743 (0.2102) acc 93.7500 (96.2500) lr 7.9721e-04 eta 0:10:38
epoch [115/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.039) loss 0.0939 (0.2282) acc 100.0000 (95.4167) lr 7.9721e-04 eta 0:09:10
epoch [115/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.030) loss 0.2563 (0.2577) acc 90.6250 (94.6875) lr 7.9721e-04 eta 0:08:27
epoch [115/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.1148 (0.2699) acc 100.0000 (94.0000) lr 7.9721e-04 eta 0:08:00
epoch [115/200] batch [30/51] time 0.085 (0.106) data 0.000 (0.020) loss 0.2966 (0.2754) acc 93.7500 (93.6458) lr 7.9721e-04 eta 0:07:42
epoch [115/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.017) loss 0.2448 (0.3011) acc 93.7500 (92.7679) lr 7.9721e-04 eta 0:07:30
epoch [115/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3269 (0.2899) acc 93.7500 (93.1250) lr 7.9721e-04 eta 0:07:20
epoch [115/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2328 (0.2791) acc 90.6250 (93.4028) lr 7.9721e-04 eta 0:07:12
epoch [115/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2568 (0.2777) acc 93.7500 (93.5000) lr 7.9721e-04 eta 0:07:05
epoch [116/200] batch [5/51] time 0.086 (0.220) data 0.000 (0.133) loss 0.6367 (0.3724) acc 90.6250 (92.5000) lr 7.8186e-04 eta 0:15:54
epoch [116/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.3027 (0.3617) acc 90.6250 (92.5000) lr 7.8186e-04 eta 0:11:04
epoch [116/200] batch [15/51] time 0.086 (0.131) data 0.000 (0.045) loss 0.3860 (0.3592) acc 93.7500 (92.2917) lr 7.8186e-04 eta 0:09:26
epoch [116/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.034) loss 0.3032 (0.3563) acc 87.5000 (91.5625) lr 7.8186e-04 eta 0:08:37
epoch [116/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.2620 (0.3387) acc 96.8750 (91.8750) lr 7.8186e-04 eta 0:08:08
epoch [116/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.1317 (0.3226) acc 100.0000 (92.3958) lr 7.8186e-04 eta 0:07:48
epoch [116/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4094 (0.3197) acc 93.7500 (92.5000) lr 7.8186e-04 eta 0:07:34
epoch [116/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.2412 (0.3162) acc 96.8750 (92.7344) lr 7.8186e-04 eta 0:07:23
epoch [116/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.3738 (0.3152) acc 90.6250 (92.5000) lr 7.8186e-04 eta 0:07:14
epoch [116/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2749 (0.3037) acc 93.7500 (92.8750) lr 7.8186e-04 eta 0:07:07
epoch [117/200] batch [5/51] time 0.088 (0.197) data 0.000 (0.109) loss 0.3848 (0.2573) acc 87.5000 (94.3750) lr 7.6655e-04 eta 0:14:01
epoch [117/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.054) loss 0.4028 (0.2487) acc 84.3750 (93.7500) lr 7.6655e-04 eta 0:10:05
epoch [117/200] batch [15/51] time 0.087 (0.123) data 0.000 (0.036) loss 0.2130 (0.2511) acc 93.7500 (93.9583) lr 7.6655e-04 eta 0:08:47
epoch [117/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2188 (0.2519) acc 96.8750 (94.2188) lr 7.6655e-04 eta 0:08:07
epoch [117/200] batch [25/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.2355 (0.2587) acc 93.7500 (94.3750) lr 7.6655e-04 eta 0:07:43
epoch [117/200] batch [30/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.4915 (0.2883) acc 84.3750 (93.4375) lr 7.6655e-04 eta 0:07:27
epoch [117/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2487 (0.2929) acc 96.8750 (93.4821) lr 7.6655e-04 eta 0:07:15
epoch [117/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1805 (0.2934) acc 96.8750 (93.4375) lr 7.6655e-04 eta 0:07:06
epoch [117/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.1394 (0.2920) acc 93.7500 (92.9861) lr 7.6655e-04 eta 0:06:58
epoch [117/200] batch [50/51] time 0.088 (0.098) data 0.000 (0.011) loss 0.1632 (0.2890) acc 96.8750 (92.9375) lr 7.6655e-04 eta 0:06:52
epoch [118/200] batch [5/51] time 0.088 (0.213) data 0.000 (0.125) loss 0.3367 (0.3721) acc 93.7500 (90.6250) lr 7.5131e-04 eta 0:14:59
epoch [118/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.2185 (0.3155) acc 96.8750 (91.5625) lr 7.5131e-04 eta 0:10:32
epoch [118/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.1743 (0.2907) acc 93.7500 (91.8750) lr 7.5131e-04 eta 0:09:03
epoch [118/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.032) loss 0.1522 (0.3094) acc 100.0000 (91.5625) lr 7.5131e-04 eta 0:08:18
epoch [118/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.4307 (0.3361) acc 87.5000 (91.0000) lr 7.5131e-04 eta 0:07:51
epoch [118/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2717 (0.3255) acc 96.8750 (91.6667) lr 7.5131e-04 eta 0:07:33
epoch [118/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3462 (0.3176) acc 90.6250 (91.8750) lr 7.5131e-04 eta 0:07:20
epoch [118/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.4353 (0.3101) acc 87.5000 (92.1094) lr 7.5131e-04 eta 0:07:09
epoch [118/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4158 (0.3067) acc 90.6250 (92.2917) lr 7.5131e-04 eta 0:07:01
epoch [118/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1475 (0.3077) acc 96.8750 (92.5000) lr 7.5131e-04 eta 0:06:55
epoch [119/200] batch [5/51] time 0.087 (0.199) data 0.001 (0.112) loss 0.2671 (0.3025) acc 96.8750 (93.7500) lr 7.3613e-04 eta 0:13:53
epoch [119/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.3940 (0.3235) acc 93.7500 (93.4375) lr 7.3613e-04 eta 0:09:58
epoch [119/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2255 (0.3110) acc 96.8750 (93.7500) lr 7.3613e-04 eta 0:08:38
epoch [119/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4612 (0.3259) acc 87.5000 (93.1250) lr 7.3613e-04 eta 0:07:59
epoch [119/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1898 (0.3162) acc 96.8750 (93.2500) lr 7.3613e-04 eta 0:07:35
epoch [119/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3650 (0.3194) acc 93.7500 (93.1250) lr 7.3613e-04 eta 0:07:19
epoch [119/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.5928 (0.3280) acc 84.3750 (92.5000) lr 7.3613e-04 eta 0:07:07
epoch [119/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5879 (0.3203) acc 81.2500 (92.5781) lr 7.3613e-04 eta 0:06:58
epoch [119/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.5293 (0.3297) acc 84.3750 (92.4306) lr 7.3613e-04 eta 0:06:51
epoch [119/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.1615 (0.3228) acc 96.8750 (92.6875) lr 7.3613e-04 eta 0:06:44
epoch [120/200] batch [5/51] time 0.088 (0.225) data 0.000 (0.137) loss 0.3235 (0.2217) acc 87.5000 (93.1250) lr 7.2101e-04 eta 0:15:29
epoch [120/200] batch [10/51] time 0.088 (0.156) data 0.000 (0.068) loss 0.2150 (0.2526) acc 96.8750 (93.1250) lr 7.2101e-04 eta 0:10:44
epoch [120/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.1567 (0.2729) acc 93.7500 (92.0833) lr 7.2101e-04 eta 0:09:08
epoch [120/200] batch [20/51] time 0.088 (0.122) data 0.000 (0.034) loss 0.3145 (0.2686) acc 93.7500 (92.6562) lr 7.2101e-04 eta 0:08:20
epoch [120/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3901 (0.2855) acc 90.6250 (92.2500) lr 7.2101e-04 eta 0:07:51
epoch [120/200] batch [30/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.3440 (0.2873) acc 90.6250 (92.3958) lr 7.2101e-04 eta 0:07:31
epoch [120/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1549 (0.2815) acc 96.8750 (92.8571) lr 7.2101e-04 eta 0:07:17
epoch [120/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.3184 (0.2881) acc 90.6250 (92.6562) lr 7.2101e-04 eta 0:07:06
epoch [120/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.7280 (0.3084) acc 81.2500 (92.0833) lr 7.2101e-04 eta 0:06:57
epoch [120/200] batch [50/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.3115 (0.2981) acc 93.7500 (92.5000) lr 7.2101e-04 eta 0:06:50
epoch [121/200] batch [5/51] time 0.087 (0.216) data 0.000 (0.128) loss 0.2014 (0.2543) acc 96.8750 (93.1250) lr 7.0596e-04 eta 0:14:38
epoch [121/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.1876 (0.2546) acc 96.8750 (94.6875) lr 7.0596e-04 eta 0:10:16
epoch [121/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.1603 (0.2433) acc 96.8750 (95.0000) lr 7.0596e-04 eta 0:08:48
epoch [121/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.3408 (0.2612) acc 87.5000 (93.9062) lr 7.0596e-04 eta 0:08:04
epoch [121/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2939 (0.2653) acc 93.7500 (93.8750) lr 7.0596e-04 eta 0:07:37
epoch [121/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4236 (0.2721) acc 81.2500 (93.1250) lr 7.0596e-04 eta 0:07:19
epoch [121/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.018) loss 0.2235 (0.2826) acc 100.0000 (92.9464) lr 7.0596e-04 eta 0:07:06
epoch [121/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.7017 (0.2877) acc 81.2500 (92.7344) lr 7.0596e-04 eta 0:06:56
epoch [121/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4578 (0.2961) acc 90.6250 (92.7083) lr 7.0596e-04 eta 0:06:48
epoch [121/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3923 (0.3023) acc 90.6250 (92.5625) lr 7.0596e-04 eta 0:06:41
epoch [122/200] batch [5/51] time 0.088 (0.218) data 0.000 (0.130) loss 0.4111 (0.2472) acc 87.5000 (93.7500) lr 6.9098e-04 eta 0:14:37
epoch [122/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.065) loss 0.5884 (0.3067) acc 87.5000 (92.5000) lr 6.9098e-04 eta 0:10:13
epoch [122/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.1675 (0.2851) acc 96.8750 (93.1250) lr 6.9098e-04 eta 0:08:44
epoch [122/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.4634 (0.2985) acc 87.5000 (92.6562) lr 6.9098e-04 eta 0:08:00
epoch [122/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.3477 (0.2855) acc 87.5000 (92.8750) lr 6.9098e-04 eta 0:07:33
epoch [122/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2384 (0.2682) acc 96.8750 (93.4375) lr 6.9098e-04 eta 0:07:15
epoch [122/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1246 (0.2736) acc 96.8750 (93.3929) lr 6.9098e-04 eta 0:07:02
epoch [122/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.4290 (0.2958) acc 84.3750 (92.5781) lr 6.9098e-04 eta 0:06:51
epoch [122/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.3501 (0.2945) acc 84.3750 (92.4306) lr 6.9098e-04 eta 0:06:43
epoch [122/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.2546 (0.3015) acc 93.7500 (92.3750) lr 6.9098e-04 eta 0:06:36
epoch [123/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.5293 (0.3757) acc 84.3750 (90.6250) lr 6.7608e-04 eta 0:13:04
epoch [123/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.1809 (0.2739) acc 100.0000 (93.4375) lr 6.7608e-04 eta 0:09:24
epoch [123/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.4077 (0.3073) acc 87.5000 (92.5000) lr 6.7608e-04 eta 0:08:11
epoch [123/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.2974 (0.3041) acc 90.6250 (92.6562) lr 6.7608e-04 eta 0:07:33
epoch [123/200] batch [25/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.4729 (0.3000) acc 90.6250 (93.0000) lr 6.7608e-04 eta 0:07:11
epoch [123/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3857 (0.3158) acc 90.6250 (92.3958) lr 6.7608e-04 eta 0:06:56
epoch [123/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.5303 (0.3082) acc 81.2500 (92.5000) lr 6.7608e-04 eta 0:06:45
epoch [123/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2668 (0.3052) acc 93.7500 (92.7344) lr 6.7608e-04 eta 0:06:37
epoch [123/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.0814 (0.3097) acc 100.0000 (92.4306) lr 6.7608e-04 eta 0:06:30
epoch [123/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1511 (0.3063) acc 96.8750 (92.5000) lr 6.7608e-04 eta 0:06:24
epoch [124/200] batch [5/51] time 0.086 (0.216) data 0.000 (0.129) loss 0.2666 (0.3260) acc 96.8750 (93.1250) lr 6.6126e-04 eta 0:14:06
epoch [124/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.064) loss 0.3589 (0.3241) acc 90.6250 (92.8125) lr 6.6126e-04 eta 0:09:53
epoch [124/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.1556 (0.3065) acc 100.0000 (93.1250) lr 6.6126e-04 eta 0:08:28
epoch [124/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.1443 (0.2790) acc 100.0000 (93.9062) lr 6.6126e-04 eta 0:07:45
epoch [124/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2133 (0.2980) acc 100.0000 (93.1250) lr 6.6126e-04 eta 0:07:20
epoch [124/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4216 (0.3032) acc 81.2500 (92.8125) lr 6.6126e-04 eta 0:07:02
epoch [124/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.2939 (0.3012) acc 93.7500 (92.9464) lr 6.6126e-04 eta 0:06:50
epoch [124/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2441 (0.2960) acc 96.8750 (93.1250) lr 6.6126e-04 eta 0:06:40
epoch [124/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4084 (0.2922) acc 87.5000 (93.1944) lr 6.6126e-04 eta 0:06:32
epoch [124/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1794 (0.2971) acc 93.7500 (93.0000) lr 6.6126e-04 eta 0:06:26
epoch [125/200] batch [5/51] time 0.087 (0.225) data 0.000 (0.138) loss 0.2527 (0.2487) acc 93.7500 (93.7500) lr 6.4653e-04 eta 0:14:31
epoch [125/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.4160 (0.2766) acc 90.6250 (93.7500) lr 6.4653e-04 eta 0:10:04
epoch [125/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.1691 (0.2798) acc 96.8750 (93.9583) lr 6.4653e-04 eta 0:08:34
epoch [125/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.0566 (0.2663) acc 100.0000 (94.3750) lr 6.4653e-04 eta 0:07:49
epoch [125/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4270 (0.2898) acc 93.7500 (93.7500) lr 6.4653e-04 eta 0:07:22
epoch [125/200] batch [30/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.2341 (0.2893) acc 93.7500 (93.8542) lr 6.4653e-04 eta 0:07:03
epoch [125/200] batch [35/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.2856 (0.2898) acc 93.7500 (93.8393) lr 6.4653e-04 eta 0:06:50
epoch [125/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.4050 (0.2897) acc 93.7500 (93.9062) lr 6.4653e-04 eta 0:06:40
epoch [125/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.1470 (0.2867) acc 100.0000 (94.0972) lr 6.4653e-04 eta 0:06:31
epoch [125/200] batch [50/51] time 0.088 (0.101) data 0.000 (0.014) loss 0.2981 (0.2881) acc 90.6250 (93.8125) lr 6.4653e-04 eta 0:06:25
epoch [126/200] batch [5/51] time 0.088 (0.214) data 0.000 (0.127) loss 0.4067 (0.2784) acc 96.8750 (95.6250) lr 6.3188e-04 eta 0:13:37
epoch [126/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.063) loss 0.3884 (0.2766) acc 84.3750 (93.4375) lr 6.3188e-04 eta 0:09:34
epoch [126/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.1862 (0.2977) acc 90.6250 (92.9167) lr 6.3188e-04 eta 0:08:12
epoch [126/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.2512 (0.2990) acc 93.7500 (92.6562) lr 6.3188e-04 eta 0:07:31
epoch [126/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3132 (0.2956) acc 96.8750 (92.8750) lr 6.3188e-04 eta 0:07:06
epoch [126/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2666 (0.2921) acc 96.8750 (92.7083) lr 6.3188e-04 eta 0:06:50
epoch [126/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.2198 (0.2916) acc 93.7500 (92.8571) lr 6.3188e-04 eta 0:06:38
epoch [126/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2622 (0.3011) acc 93.7500 (92.6562) lr 6.3188e-04 eta 0:06:28
epoch [126/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4951 (0.3054) acc 90.6250 (92.5694) lr 6.3188e-04 eta 0:06:21
epoch [126/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4658 (0.3024) acc 87.5000 (92.6250) lr 6.3188e-04 eta 0:06:15
epoch [127/200] batch [5/51] time 0.089 (0.203) data 0.000 (0.114) loss 0.2385 (0.3215) acc 93.7500 (93.1250) lr 6.1732e-04 eta 0:12:43
epoch [127/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.3352 (0.3260) acc 87.5000 (92.1875) lr 6.1732e-04 eta 0:09:07
epoch [127/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.038) loss 0.1798 (0.3153) acc 93.7500 (91.4583) lr 6.1732e-04 eta 0:07:54
epoch [127/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2089 (0.2721) acc 96.8750 (93.1250) lr 6.1732e-04 eta 0:07:17
epoch [127/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.023) loss 0.8540 (0.3049) acc 81.2500 (92.6250) lr 6.1732e-04 eta 0:06:54
epoch [127/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.019) loss 0.2747 (0.3007) acc 90.6250 (92.5000) lr 6.1732e-04 eta 0:06:39
epoch [127/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.5562 (0.3001) acc 87.5000 (92.5893) lr 6.1732e-04 eta 0:06:28
epoch [127/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.014) loss 0.3198 (0.2974) acc 93.7500 (92.9688) lr 6.1732e-04 eta 0:06:20
epoch [127/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2603 (0.3100) acc 93.7500 (92.5000) lr 6.1732e-04 eta 0:06:13
epoch [127/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1263 (0.3106) acc 96.8750 (92.6250) lr 6.1732e-04 eta 0:06:07
epoch [128/200] batch [5/51] time 0.088 (0.196) data 0.000 (0.108) loss 0.3857 (0.3604) acc 90.6250 (91.2500) lr 6.0285e-04 eta 0:12:07
epoch [128/200] batch [10/51] time 0.088 (0.141) data 0.000 (0.054) loss 0.4587 (0.3636) acc 87.5000 (90.6250) lr 6.0285e-04 eta 0:08:44
epoch [128/200] batch [15/51] time 0.087 (0.123) data 0.000 (0.036) loss 0.3608 (0.3317) acc 90.6250 (91.4583) lr 6.0285e-04 eta 0:07:37
epoch [128/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2355 (0.3119) acc 87.5000 (91.5625) lr 6.0285e-04 eta 0:07:03
epoch [128/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1387 (0.3020) acc 100.0000 (91.8750) lr 6.0285e-04 eta 0:06:42
epoch [128/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.5010 (0.3110) acc 93.7500 (91.9792) lr 6.0285e-04 eta 0:06:28
epoch [128/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.5278 (0.3268) acc 87.5000 (91.7857) lr 6.0285e-04 eta 0:06:18
epoch [128/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3635 (0.3276) acc 90.6250 (91.6406) lr 6.0285e-04 eta 0:06:10
epoch [128/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1642 (0.3145) acc 96.8750 (92.2222) lr 6.0285e-04 eta 0:06:04
epoch [128/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2642 (0.3087) acc 93.7500 (92.3125) lr 6.0285e-04 eta 0:05:58
epoch [129/200] batch [5/51] time 0.087 (0.203) data 0.000 (0.115) loss 0.3789 (0.3696) acc 90.6250 (91.2500) lr 5.8849e-04 eta 0:12:23
epoch [129/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.1890 (0.3308) acc 96.8750 (91.2500) lr 5.8849e-04 eta 0:08:50
epoch [129/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.039) loss 0.2059 (0.3156) acc 93.7500 (92.0833) lr 5.8849e-04 eta 0:07:38
epoch [129/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.4243 (0.3164) acc 87.5000 (92.0312) lr 5.8849e-04 eta 0:07:02
epoch [129/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1692 (0.3036) acc 96.8750 (92.1250) lr 5.8849e-04 eta 0:06:41
epoch [129/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.4683 (0.3014) acc 90.6250 (92.3958) lr 5.8849e-04 eta 0:06:26
epoch [129/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.017) loss 0.2881 (0.3028) acc 96.8750 (92.6786) lr 5.8849e-04 eta 0:06:16
epoch [129/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3848 (0.3006) acc 87.5000 (92.7344) lr 5.8849e-04 eta 0:06:08
epoch [129/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3013 (0.3052) acc 93.7500 (92.6389) lr 5.8849e-04 eta 0:06:01
epoch [129/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3406 (0.3030) acc 93.7500 (92.6250) lr 5.8849e-04 eta 0:05:56
epoch [130/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.1033 (0.3969) acc 100.0000 (89.3750) lr 5.7422e-04 eta 0:12:03
epoch [130/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.2798 (0.3620) acc 93.7500 (90.9375) lr 5.7422e-04 eta 0:08:38
epoch [130/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.037) loss 0.3606 (0.3312) acc 90.6250 (91.4583) lr 5.7422e-04 eta 0:07:29
epoch [130/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2664 (0.3156) acc 87.5000 (91.7188) lr 5.7422e-04 eta 0:06:55
epoch [130/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1492 (0.3049) acc 96.8750 (91.6250) lr 5.7422e-04 eta 0:06:34
epoch [130/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1404 (0.2975) acc 96.8750 (91.9792) lr 5.7422e-04 eta 0:06:20
epoch [130/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2358 (0.2961) acc 96.8750 (91.9643) lr 5.7422e-04 eta 0:06:10
epoch [130/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3511 (0.2958) acc 87.5000 (92.1094) lr 5.7422e-04 eta 0:06:02
epoch [130/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2144 (0.2956) acc 93.7500 (91.9444) lr 5.7422e-04 eta 0:05:56
epoch [130/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2083 (0.2943) acc 96.8750 (92.1250) lr 5.7422e-04 eta 0:05:50
epoch [131/200] batch [5/51] time 0.089 (0.201) data 0.000 (0.112) loss 0.2185 (0.2929) acc 93.7500 (91.8750) lr 5.6006e-04 eta 0:11:54
epoch [131/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.056) loss 0.1982 (0.3140) acc 96.8750 (91.8750) lr 5.6006e-04 eta 0:08:32
epoch [131/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.037) loss 0.6870 (0.3428) acc 84.3750 (91.0417) lr 5.6006e-04 eta 0:07:24
epoch [131/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.2065 (0.3141) acc 96.8750 (92.0312) lr 5.6006e-04 eta 0:06:50
epoch [131/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.0778 (0.3248) acc 100.0000 (92.0000) lr 5.6006e-04 eta 0:06:29
epoch [131/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.0653 (0.3044) acc 100.0000 (92.6042) lr 5.6006e-04 eta 0:06:15
epoch [131/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.016) loss 0.2450 (0.3046) acc 90.6250 (92.5000) lr 5.6006e-04 eta 0:06:05
epoch [131/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2734 (0.3050) acc 90.6250 (92.5000) lr 5.6006e-04 eta 0:05:57
epoch [131/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2808 (0.3072) acc 93.7500 (92.2917) lr 5.6006e-04 eta 0:05:51
epoch [131/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3303 (0.3063) acc 93.7500 (92.3750) lr 5.6006e-04 eta 0:05:46
epoch [132/200] batch [5/51] time 0.087 (0.207) data 0.000 (0.119) loss 0.4324 (0.2486) acc 90.6250 (94.3750) lr 5.4601e-04 eta 0:12:07
epoch [132/200] batch [10/51] time 0.086 (0.147) data 0.000 (0.060) loss 0.3557 (0.2587) acc 87.5000 (93.4375) lr 5.4601e-04 eta 0:08:35
epoch [132/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.3320 (0.2579) acc 93.7500 (93.5417) lr 5.4601e-04 eta 0:07:24
epoch [132/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.2484 (0.2669) acc 93.7500 (93.1250) lr 5.4601e-04 eta 0:06:48
epoch [132/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1864 (0.2512) acc 93.7500 (94.0000) lr 5.4601e-04 eta 0:06:27
epoch [132/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2390 (0.2697) acc 96.8750 (93.6458) lr 5.4601e-04 eta 0:06:12
epoch [132/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1881 (0.2625) acc 93.7500 (93.7500) lr 5.4601e-04 eta 0:06:02
epoch [132/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1359 (0.2620) acc 100.0000 (93.9062) lr 5.4601e-04 eta 0:05:53
epoch [132/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3640 (0.2775) acc 90.6250 (93.3333) lr 5.4601e-04 eta 0:05:47
epoch [132/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2637 (0.2820) acc 96.8750 (93.3750) lr 5.4601e-04 eta 0:05:41
epoch [133/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.112) loss 0.4390 (0.3385) acc 93.7500 (91.2500) lr 5.3207e-04 eta 0:11:35
epoch [133/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.3838 (0.3043) acc 93.7500 (92.1875) lr 5.3207e-04 eta 0:08:18
epoch [133/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.1422 (0.2884) acc 100.0000 (92.2917) lr 5.3207e-04 eta 0:07:11
epoch [133/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.2012 (0.2880) acc 100.0000 (92.3438) lr 5.3207e-04 eta 0:06:38
epoch [133/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1130 (0.2605) acc 100.0000 (93.6250) lr 5.3207e-04 eta 0:06:17
epoch [133/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1571 (0.2621) acc 100.0000 (93.8542) lr 5.3207e-04 eta 0:06:04
epoch [133/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3167 (0.2836) acc 90.6250 (92.7679) lr 5.3207e-04 eta 0:05:54
epoch [133/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3794 (0.2832) acc 93.7500 (92.8125) lr 5.3207e-04 eta 0:05:46
epoch [133/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3464 (0.2814) acc 90.6250 (92.8472) lr 5.3207e-04 eta 0:05:40
epoch [133/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3113 (0.2805) acc 90.6250 (92.9375) lr 5.3207e-04 eta 0:05:35
epoch [134/200] batch [5/51] time 0.088 (0.224) data 0.000 (0.136) loss 0.2969 (0.2716) acc 96.8750 (94.3750) lr 5.1825e-04 eta 0:12:43
epoch [134/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.068) loss 0.1588 (0.2817) acc 100.0000 (94.0625) lr 5.1825e-04 eta 0:08:50
epoch [134/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.1991 (0.2838) acc 93.7500 (93.5417) lr 5.1825e-04 eta 0:07:32
epoch [134/200] batch [20/51] time 0.088 (0.122) data 0.000 (0.034) loss 0.3853 (0.2743) acc 90.6250 (93.9062) lr 5.1825e-04 eta 0:06:53
epoch [134/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.027) loss 0.6597 (0.2840) acc 87.5000 (93.5000) lr 5.1825e-04 eta 0:06:29
epoch [134/200] batch [30/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.3093 (0.2805) acc 90.6250 (93.4375) lr 5.1825e-04 eta 0:06:13
epoch [134/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2878 (0.2823) acc 90.6250 (93.2143) lr 5.1825e-04 eta 0:06:01
epoch [134/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3242 (0.2799) acc 90.6250 (93.3594) lr 5.1825e-04 eta 0:05:52
epoch [134/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.0690 (0.2683) acc 100.0000 (93.8194) lr 5.1825e-04 eta 0:05:44
epoch [134/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1676 (0.2620) acc 93.7500 (93.8125) lr 5.1825e-04 eta 0:05:38
epoch [135/200] batch [5/51] time 0.088 (0.222) data 0.000 (0.134) loss 0.3708 (0.3250) acc 90.6250 (92.5000) lr 5.0454e-04 eta 0:12:25
epoch [135/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.067) loss 0.2111 (0.3108) acc 96.8750 (92.5000) lr 5.0454e-04 eta 0:08:38
epoch [135/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.3110 (0.2773) acc 87.5000 (93.7500) lr 5.0454e-04 eta 0:07:22
epoch [135/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.0991 (0.2587) acc 100.0000 (94.0625) lr 5.0454e-04 eta 0:06:44
epoch [135/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.0931 (0.2359) acc 100.0000 (95.0000) lr 5.0454e-04 eta 0:06:21
epoch [135/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.1917 (0.2316) acc 96.8750 (95.0000) lr 5.0454e-04 eta 0:06:05
epoch [135/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.019) loss 0.2651 (0.2436) acc 93.7500 (94.9107) lr 5.0454e-04 eta 0:05:54
epoch [135/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1840 (0.2545) acc 100.0000 (94.5312) lr 5.0454e-04 eta 0:05:45
epoch [135/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1122 (0.2604) acc 100.0000 (94.3056) lr 5.0454e-04 eta 0:05:38
epoch [135/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.5068 (0.2646) acc 90.6250 (94.1875) lr 5.0454e-04 eta 0:05:32
epoch [136/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.130) loss 0.3867 (0.4697) acc 90.6250 (90.6250) lr 4.9096e-04 eta 0:11:58
epoch [136/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.6265 (0.4206) acc 84.3750 (90.3125) lr 4.9096e-04 eta 0:08:22
epoch [136/200] batch [15/51] time 0.086 (0.130) data 0.000 (0.043) loss 0.1759 (0.3619) acc 93.7500 (91.8750) lr 4.9096e-04 eta 0:07:09
epoch [136/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.033) loss 0.3489 (0.3453) acc 93.7500 (92.3438) lr 4.9096e-04 eta 0:06:33
epoch [136/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2427 (0.3486) acc 96.8750 (91.8750) lr 4.9096e-04 eta 0:06:11
epoch [136/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3777 (0.3434) acc 93.7500 (92.0833) lr 4.9096e-04 eta 0:05:56
epoch [136/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2330 (0.3251) acc 93.7500 (92.4107) lr 4.9096e-04 eta 0:05:46
epoch [136/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.2656 (0.3122) acc 96.8750 (92.7344) lr 4.9096e-04 eta 0:05:38
epoch [136/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.0801 (0.3039) acc 100.0000 (92.9861) lr 4.9096e-04 eta 0:05:31
epoch [136/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.1597 (0.3009) acc 93.7500 (93.0625) lr 4.9096e-04 eta 0:05:25
epoch [137/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.1508 (0.2969) acc 100.0000 (92.5000) lr 4.7750e-04 eta 0:10:52
epoch [137/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.4939 (0.3212) acc 93.7500 (93.4375) lr 4.7750e-04 eta 0:07:47
epoch [137/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.2417 (0.3261) acc 93.7500 (92.9167) lr 4.7750e-04 eta 0:06:45
epoch [137/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.5283 (0.3239) acc 87.5000 (92.6562) lr 4.7750e-04 eta 0:06:14
epoch [137/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4580 (0.3257) acc 90.6250 (92.7500) lr 4.7750e-04 eta 0:05:55
epoch [137/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.1044 (0.3304) acc 96.8750 (91.7708) lr 4.7750e-04 eta 0:05:42
epoch [137/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2241 (0.3194) acc 90.6250 (92.2321) lr 4.7750e-04 eta 0:05:33
epoch [137/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5464 (0.3358) acc 84.3750 (91.8750) lr 4.7750e-04 eta 0:05:26
epoch [137/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2612 (0.3300) acc 90.6250 (91.8750) lr 4.7750e-04 eta 0:05:20
epoch [137/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3892 (0.3259) acc 93.7500 (92.0625) lr 4.7750e-04 eta 0:05:15
epoch [138/200] batch [5/51] time 0.089 (0.208) data 0.000 (0.120) loss 0.3584 (0.2929) acc 90.6250 (94.3750) lr 4.6417e-04 eta 0:11:07
epoch [138/200] batch [10/51] time 0.088 (0.148) data 0.000 (0.060) loss 0.1854 (0.3753) acc 93.7500 (90.9375) lr 4.6417e-04 eta 0:07:52
epoch [138/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.3303 (0.3251) acc 93.7500 (92.2917) lr 4.6417e-04 eta 0:06:47
epoch [138/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3835 (0.3410) acc 87.5000 (91.7188) lr 4.6417e-04 eta 0:06:14
epoch [138/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.2927 (0.3164) acc 93.7500 (92.6250) lr 4.6417e-04 eta 0:05:54
epoch [138/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2988 (0.3170) acc 93.7500 (92.7083) lr 4.6417e-04 eta 0:05:41
epoch [138/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2057 (0.3029) acc 100.0000 (93.2143) lr 4.6417e-04 eta 0:05:31
epoch [138/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3777 (0.3084) acc 90.6250 (93.1250) lr 4.6417e-04 eta 0:05:23
epoch [138/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4011 (0.3021) acc 90.6250 (93.1944) lr 4.6417e-04 eta 0:05:17
epoch [138/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1427 (0.3013) acc 96.8750 (93.2500) lr 4.6417e-04 eta 0:05:12
epoch [139/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.113) loss 0.3167 (0.3282) acc 93.7500 (92.5000) lr 4.5098e-04 eta 0:10:35
epoch [139/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.2859 (0.3303) acc 93.7500 (91.5625) lr 4.5098e-04 eta 0:07:34
epoch [139/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.2788 (0.2976) acc 90.6250 (92.5000) lr 4.5098e-04 eta 0:06:33
epoch [139/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.3948 (0.3234) acc 90.6250 (91.7188) lr 4.5098e-04 eta 0:06:03
epoch [139/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2522 (0.3300) acc 93.7500 (91.6250) lr 4.5098e-04 eta 0:05:44
epoch [139/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1342 (0.3182) acc 96.8750 (92.0833) lr 4.5098e-04 eta 0:05:32
epoch [139/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.0886 (0.3216) acc 96.8750 (92.2321) lr 4.5098e-04 eta 0:05:23
epoch [139/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2292 (0.3095) acc 96.8750 (92.5000) lr 4.5098e-04 eta 0:05:16
epoch [139/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2037 (0.3012) acc 96.8750 (92.7083) lr 4.5098e-04 eta 0:05:10
epoch [139/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1711 (0.3114) acc 96.8750 (92.5625) lr 4.5098e-04 eta 0:05:05
epoch [140/200] batch [5/51] time 0.087 (0.216) data 0.000 (0.129) loss 0.3384 (0.2311) acc 90.6250 (94.3750) lr 4.3792e-04 eta 0:11:11
epoch [140/200] batch [10/51] time 0.088 (0.152) data 0.000 (0.065) loss 0.3225 (0.2590) acc 93.7500 (93.7500) lr 4.3792e-04 eta 0:07:50
epoch [140/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.3679 (0.2697) acc 87.5000 (93.5417) lr 4.3792e-04 eta 0:06:43
epoch [140/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3257 (0.2705) acc 93.7500 (93.9062) lr 4.3792e-04 eta 0:06:09
epoch [140/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.1478 (0.2745) acc 96.8750 (94.0000) lr 4.3792e-04 eta 0:05:48
epoch [140/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3655 (0.2845) acc 90.6250 (93.5417) lr 4.3792e-04 eta 0:05:34
epoch [140/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.4663 (0.2902) acc 87.5000 (93.3036) lr 4.3792e-04 eta 0:05:24
epoch [140/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.2686 (0.2977) acc 93.7500 (92.9688) lr 4.3792e-04 eta 0:05:16
epoch [140/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3303 (0.2952) acc 93.7500 (92.7778) lr 4.3792e-04 eta 0:05:10
epoch [140/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3782 (0.2986) acc 93.7500 (92.8125) lr 4.3792e-04 eta 0:05:05
epoch [141/200] batch [5/51] time 0.088 (0.206) data 0.000 (0.117) loss 0.4780 (0.3580) acc 93.7500 (92.5000) lr 4.2499e-04 eta 0:10:28
epoch [141/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.2380 (0.2867) acc 93.7500 (94.0625) lr 4.2499e-04 eta 0:07:28
epoch [141/200] batch [15/51] time 0.088 (0.127) data 0.000 (0.039) loss 0.2228 (0.2884) acc 93.7500 (93.3333) lr 4.2499e-04 eta 0:06:27
epoch [141/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.030) loss 0.3022 (0.2903) acc 93.7500 (93.4375) lr 4.2499e-04 eta 0:05:56
epoch [141/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.2605 (0.2946) acc 93.7500 (93.3750) lr 4.2499e-04 eta 0:05:37
epoch [141/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2273 (0.2967) acc 96.8750 (93.3333) lr 4.2499e-04 eta 0:05:25
epoch [141/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.017) loss 0.1904 (0.2880) acc 96.8750 (93.4821) lr 4.2499e-04 eta 0:05:16
epoch [141/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5522 (0.2931) acc 87.5000 (93.3594) lr 4.2499e-04 eta 0:05:08
epoch [141/200] batch [45/51] time 0.087 (0.100) data 0.000 (0.013) loss 0.3386 (0.2891) acc 90.6250 (93.4028) lr 4.2499e-04 eta 0:05:02
epoch [141/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3745 (0.2923) acc 87.5000 (93.2500) lr 4.2499e-04 eta 0:04:58
epoch [142/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.1785 (0.2208) acc 100.0000 (96.2500) lr 4.1221e-04 eta 0:10:00
epoch [142/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.056) loss 0.2007 (0.2436) acc 96.8750 (94.6875) lr 4.1221e-04 eta 0:07:09
epoch [142/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.037) loss 0.5034 (0.3126) acc 84.3750 (92.5000) lr 4.1221e-04 eta 0:06:12
epoch [142/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2485 (0.2932) acc 93.7500 (92.9688) lr 4.1221e-04 eta 0:05:44
epoch [142/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4065 (0.2994) acc 96.8750 (93.0000) lr 4.1221e-04 eta 0:05:26
epoch [142/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2008 (0.2797) acc 96.8750 (93.5417) lr 4.1221e-04 eta 0:05:15
epoch [142/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2568 (0.2723) acc 93.7500 (93.4821) lr 4.1221e-04 eta 0:05:06
epoch [142/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3845 (0.2844) acc 87.5000 (93.2812) lr 4.1221e-04 eta 0:04:59
epoch [142/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2106 (0.2867) acc 96.8750 (93.4028) lr 4.1221e-04 eta 0:04:54
epoch [142/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2664 (0.2979) acc 96.8750 (93.4375) lr 4.1221e-04 eta 0:04:49
epoch [143/200] batch [5/51] time 0.087 (0.206) data 0.000 (0.118) loss 0.5063 (0.3830) acc 84.3750 (88.7500) lr 3.9958e-04 eta 0:10:08
epoch [143/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.1332 (0.3197) acc 96.8750 (90.9375) lr 3.9958e-04 eta 0:07:11
epoch [143/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.3181 (0.3410) acc 87.5000 (90.2083) lr 3.9958e-04 eta 0:06:12
epoch [143/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2571 (0.3126) acc 96.8750 (91.2500) lr 3.9958e-04 eta 0:05:43
epoch [143/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1879 (0.3152) acc 96.8750 (91.3750) lr 3.9958e-04 eta 0:05:24
epoch [143/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.020) loss 0.2024 (0.3014) acc 96.8750 (91.9792) lr 3.9958e-04 eta 0:05:12
epoch [143/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2759 (0.3012) acc 93.7500 (91.9643) lr 3.9958e-04 eta 0:05:03
epoch [143/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2219 (0.2901) acc 93.7500 (92.5000) lr 3.9958e-04 eta 0:04:57
epoch [143/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2212 (0.2930) acc 93.7500 (92.7778) lr 3.9958e-04 eta 0:04:51
epoch [143/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4868 (0.2982) acc 84.3750 (92.5625) lr 3.9958e-04 eta 0:04:46
epoch [144/200] batch [5/51] time 0.087 (0.216) data 0.000 (0.129) loss 0.3818 (0.3996) acc 90.6250 (90.0000) lr 3.8709e-04 eta 0:10:26
epoch [144/200] batch [10/51] time 0.086 (0.151) data 0.000 (0.064) loss 0.1178 (0.3415) acc 96.8750 (91.8750) lr 3.8709e-04 eta 0:07:18
epoch [144/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.1604 (0.3478) acc 96.8750 (92.0833) lr 3.8709e-04 eta 0:06:16
epoch [144/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.3630 (0.3446) acc 84.3750 (91.7188) lr 3.8709e-04 eta 0:05:44
epoch [144/200] batch [25/51] time 0.088 (0.113) data 0.000 (0.026) loss 0.3701 (0.3438) acc 90.6250 (91.5000) lr 3.8709e-04 eta 0:05:25
epoch [144/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1219 (0.3134) acc 100.0000 (92.6042) lr 3.8709e-04 eta 0:05:12
epoch [144/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1418 (0.3075) acc 100.0000 (92.5893) lr 3.8709e-04 eta 0:05:03
epoch [144/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1639 (0.3027) acc 96.8750 (92.8125) lr 3.8709e-04 eta 0:04:55
epoch [144/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1147 (0.3113) acc 96.8750 (92.5000) lr 3.8709e-04 eta 0:04:49
epoch [144/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3503 (0.3145) acc 93.7500 (92.5000) lr 3.8709e-04 eta 0:04:44
epoch [145/200] batch [5/51] time 0.088 (0.200) data 0.000 (0.112) loss 0.2832 (0.2214) acc 93.7500 (96.2500) lr 3.7476e-04 eta 0:09:29
epoch [145/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.2245 (0.3033) acc 96.8750 (93.7500) lr 3.7476e-04 eta 0:06:47
epoch [145/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.4775 (0.3055) acc 93.7500 (93.9583) lr 3.7476e-04 eta 0:05:53
epoch [145/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.1449 (0.3047) acc 93.7500 (94.0625) lr 3.7476e-04 eta 0:05:26
epoch [145/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.4102 (0.3174) acc 84.3750 (93.1250) lr 3.7476e-04 eta 0:05:09
epoch [145/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2878 (0.3152) acc 96.8750 (93.3333) lr 3.7476e-04 eta 0:04:58
epoch [145/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2394 (0.3033) acc 93.7500 (93.5714) lr 3.7476e-04 eta 0:04:50
epoch [145/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5078 (0.3051) acc 84.3750 (93.4375) lr 3.7476e-04 eta 0:04:43
epoch [145/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2295 (0.3070) acc 96.8750 (93.6111) lr 3.7476e-04 eta 0:04:38
epoch [145/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2219 (0.3061) acc 93.7500 (93.5000) lr 3.7476e-04 eta 0:04:34
epoch [146/200] batch [5/51] time 0.087 (0.215) data 0.000 (0.127) loss 0.2384 (0.2242) acc 93.7500 (93.7500) lr 3.6258e-04 eta 0:10:02
epoch [146/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.1450 (0.2234) acc 100.0000 (94.6875) lr 3.6258e-04 eta 0:07:02
epoch [146/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.2189 (0.2411) acc 93.7500 (93.5417) lr 3.6258e-04 eta 0:06:01
epoch [146/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.1327 (0.2495) acc 100.0000 (94.0625) lr 3.6258e-04 eta 0:05:31
epoch [146/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.026) loss 0.3081 (0.2517) acc 93.7500 (94.3750) lr 3.6258e-04 eta 0:05:12
epoch [146/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.4875 (0.2653) acc 87.5000 (94.0625) lr 3.6258e-04 eta 0:05:00
epoch [146/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3577 (0.2734) acc 93.7500 (94.0179) lr 3.6258e-04 eta 0:04:51
epoch [146/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2212 (0.2694) acc 93.7500 (93.9062) lr 3.6258e-04 eta 0:04:44
epoch [146/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2661 (0.2638) acc 90.6250 (94.0278) lr 3.6258e-04 eta 0:04:38
epoch [146/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3748 (0.2695) acc 93.7500 (93.8125) lr 3.6258e-04 eta 0:04:33
epoch [147/200] batch [5/51] time 0.087 (0.225) data 0.000 (0.137) loss 0.5093 (0.3285) acc 90.6250 (91.2500) lr 3.5055e-04 eta 0:10:17
epoch [147/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.2274 (0.3281) acc 96.8750 (91.8750) lr 3.5055e-04 eta 0:07:07
epoch [147/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.5151 (0.3288) acc 90.6250 (92.2917) lr 3.5055e-04 eta 0:06:03
epoch [147/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.035) loss 0.1589 (0.3109) acc 93.7500 (92.3438) lr 3.5055e-04 eta 0:05:31
epoch [147/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.1653 (0.3013) acc 96.8750 (92.5000) lr 3.5055e-04 eta 0:05:12
epoch [147/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2786 (0.3054) acc 87.5000 (91.9792) lr 3.5055e-04 eta 0:04:59
epoch [147/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2152 (0.3050) acc 93.7500 (91.9643) lr 3.5055e-04 eta 0:04:50
epoch [147/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2382 (0.3043) acc 96.8750 (92.1094) lr 3.5055e-04 eta 0:04:42
epoch [147/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5938 (0.3091) acc 93.7500 (92.2222) lr 3.5055e-04 eta 0:04:36
epoch [147/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1987 (0.3007) acc 96.8750 (92.4375) lr 3.5055e-04 eta 0:04:32
epoch [148/200] batch [5/51] time 0.089 (0.200) data 0.000 (0.111) loss 0.2102 (0.2816) acc 93.7500 (93.7500) lr 3.3869e-04 eta 0:08:58
epoch [148/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.1511 (0.2715) acc 96.8750 (95.0000) lr 3.3869e-04 eta 0:06:26
epoch [148/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.037) loss 0.3303 (0.2817) acc 93.7500 (94.5833) lr 3.3869e-04 eta 0:05:35
epoch [148/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.4915 (0.3023) acc 87.5000 (93.7500) lr 3.3869e-04 eta 0:05:09
epoch [148/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.3281 (0.3023) acc 96.8750 (94.0000) lr 3.3869e-04 eta 0:04:54
epoch [148/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.1472 (0.3011) acc 93.7500 (93.5417) lr 3.3869e-04 eta 0:04:43
epoch [148/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.1478 (0.2870) acc 96.8750 (93.9286) lr 3.3869e-04 eta 0:04:36
epoch [148/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4631 (0.2907) acc 87.5000 (93.6719) lr 3.3869e-04 eta 0:04:29
epoch [148/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3271 (0.2995) acc 90.6250 (93.2639) lr 3.3869e-04 eta 0:04:24
epoch [148/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2524 (0.2994) acc 96.8750 (93.2500) lr 3.3869e-04 eta 0:04:20
epoch [149/200] batch [5/51] time 0.087 (0.220) data 0.000 (0.133) loss 0.5684 (0.3532) acc 84.3750 (90.0000) lr 3.2699e-04 eta 0:09:42
epoch [149/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.3679 (0.3342) acc 87.5000 (90.9375) lr 3.2699e-04 eta 0:06:45
epoch [149/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.045) loss 0.4023 (0.3104) acc 87.5000 (91.2500) lr 3.2699e-04 eta 0:05:46
epoch [149/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3325 (0.3103) acc 93.7500 (91.5625) lr 3.2699e-04 eta 0:05:16
epoch [149/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2695 (0.3017) acc 100.0000 (91.8750) lr 3.2699e-04 eta 0:04:58
epoch [149/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.3340 (0.2902) acc 90.6250 (92.2917) lr 3.2699e-04 eta 0:04:46
epoch [149/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3738 (0.2950) acc 90.6250 (92.2321) lr 3.2699e-04 eta 0:04:37
epoch [149/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.4587 (0.3015) acc 93.7500 (92.4219) lr 3.2699e-04 eta 0:04:30
epoch [149/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3943 (0.3013) acc 93.7500 (92.5000) lr 3.2699e-04 eta 0:04:25
epoch [149/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3323 (0.2979) acc 93.7500 (92.6875) lr 3.2699e-04 eta 0:04:20
epoch [150/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.113) loss 0.2135 (0.2499) acc 96.8750 (95.0000) lr 3.1545e-04 eta 0:08:44
epoch [150/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.4343 (0.2904) acc 84.3750 (92.5000) lr 3.1545e-04 eta 0:06:14
epoch [150/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.6855 (0.3056) acc 90.6250 (92.9167) lr 3.1545e-04 eta 0:05:24
epoch [150/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.2195 (0.3053) acc 93.7500 (93.2812) lr 3.1545e-04 eta 0:04:58
epoch [150/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1528 (0.3036) acc 96.8750 (93.1250) lr 3.1545e-04 eta 0:04:43
epoch [150/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1372 (0.2877) acc 96.8750 (93.5417) lr 3.1545e-04 eta 0:04:33
epoch [150/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.016) loss 0.2690 (0.2974) acc 93.7500 (93.3929) lr 3.1545e-04 eta 0:04:25
epoch [150/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2747 (0.2997) acc 90.6250 (93.0469) lr 3.1545e-04 eta 0:04:19
epoch [150/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1711 (0.3006) acc 96.8750 (92.9167) lr 3.1545e-04 eta 0:04:14
epoch [150/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.2114 (0.2972) acc 90.6250 (92.6875) lr 3.1545e-04 eta 0:04:10
epoch [151/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.126) loss 0.1276 (0.1591) acc 96.8750 (96.2500) lr 3.0409e-04 eta 0:09:02
epoch [151/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.4536 (0.2355) acc 84.3750 (94.0625) lr 3.0409e-04 eta 0:06:21
epoch [151/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.5645 (0.2620) acc 84.3750 (93.5417) lr 3.0409e-04 eta 0:05:26
epoch [151/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.032) loss 0.2549 (0.2755) acc 100.0000 (93.1250) lr 3.0409e-04 eta 0:04:59
epoch [151/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1938 (0.2689) acc 93.7500 (93.6250) lr 3.0409e-04 eta 0:04:43
epoch [151/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2119 (0.2758) acc 93.7500 (93.1250) lr 3.0409e-04 eta 0:04:32
epoch [151/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.4460 (0.2981) acc 87.5000 (92.4107) lr 3.0409e-04 eta 0:04:24
epoch [151/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2727 (0.2941) acc 90.6250 (92.5000) lr 3.0409e-04 eta 0:04:17
epoch [151/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5669 (0.2980) acc 81.2500 (92.2917) lr 3.0409e-04 eta 0:04:12
epoch [151/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3369 (0.3012) acc 93.7500 (92.4375) lr 3.0409e-04 eta 0:04:08
epoch [152/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.115) loss 0.4534 (0.3351) acc 84.3750 (90.6250) lr 2.9289e-04 eta 0:08:28
epoch [152/200] batch [10/51] time 0.085 (0.145) data 0.000 (0.058) loss 0.4351 (0.2978) acc 90.6250 (91.5625) lr 2.9289e-04 eta 0:06:01
epoch [152/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.039) loss 0.4465 (0.3323) acc 93.7500 (91.6667) lr 2.9289e-04 eta 0:05:12
epoch [152/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.029) loss 0.2710 (0.3119) acc 93.7500 (92.5000) lr 2.9289e-04 eta 0:04:47
epoch [152/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4509 (0.3076) acc 87.5000 (92.5000) lr 2.9289e-04 eta 0:04:32
epoch [152/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3879 (0.3145) acc 90.6250 (92.2917) lr 2.9289e-04 eta 0:04:22
epoch [152/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.1351 (0.2990) acc 96.8750 (92.6786) lr 2.9289e-04 eta 0:04:15
epoch [152/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2109 (0.2859) acc 96.8750 (93.2031) lr 2.9289e-04 eta 0:04:09
epoch [152/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1411 (0.2774) acc 93.7500 (93.3333) lr 2.9289e-04 eta 0:04:05
epoch [152/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2139 (0.2841) acc 96.8750 (93.1875) lr 2.9289e-04 eta 0:04:01
epoch [153/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.5195 (0.3629) acc 90.6250 (90.6250) lr 2.8187e-04 eta 0:08:12
epoch [153/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.3528 (0.3554) acc 90.6250 (90.6250) lr 2.8187e-04 eta 0:05:52
epoch [153/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.3083 (0.3337) acc 93.7500 (91.6667) lr 2.8187e-04 eta 0:05:05
epoch [153/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.4958 (0.3416) acc 84.3750 (91.2500) lr 2.8187e-04 eta 0:04:41
epoch [153/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3538 (0.3125) acc 90.6250 (92.0000) lr 2.8187e-04 eta 0:04:26
epoch [153/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2401 (0.3044) acc 93.7500 (92.5000) lr 2.8187e-04 eta 0:04:16
epoch [153/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.016) loss 0.4578 (0.3125) acc 90.6250 (92.4107) lr 2.8187e-04 eta 0:04:09
epoch [153/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3428 (0.3256) acc 90.6250 (92.1875) lr 2.8187e-04 eta 0:04:04
epoch [153/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4163 (0.3282) acc 87.5000 (92.1528) lr 2.8187e-04 eta 0:03:59
epoch [153/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1177 (0.3136) acc 100.0000 (92.5625) lr 2.8187e-04 eta 0:03:56
epoch [154/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.2952 (0.2827) acc 96.8750 (92.5000) lr 2.7103e-04 eta 0:08:08
epoch [154/200] batch [10/51] time 0.086 (0.146) data 0.000 (0.058) loss 0.1725 (0.3278) acc 96.8750 (91.5625) lr 2.7103e-04 eta 0:05:48
epoch [154/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.039) loss 0.3831 (0.3223) acc 90.6250 (91.6667) lr 2.7103e-04 eta 0:05:00
epoch [154/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2708 (0.3089) acc 90.6250 (92.1875) lr 2.7103e-04 eta 0:04:36
epoch [154/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.023) loss 0.1887 (0.3048) acc 93.7500 (92.2500) lr 2.7103e-04 eta 0:04:22
epoch [154/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4805 (0.3230) acc 90.6250 (91.8750) lr 2.7103e-04 eta 0:04:12
epoch [154/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3250 (0.3156) acc 90.6250 (91.8750) lr 2.7103e-04 eta 0:04:05
epoch [154/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2227 (0.3126) acc 93.7500 (92.1875) lr 2.7103e-04 eta 0:03:59
epoch [154/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3279 (0.3032) acc 93.7500 (92.5000) lr 2.7103e-04 eta 0:03:55
epoch [154/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3367 (0.3048) acc 90.6250 (92.5000) lr 2.7103e-04 eta 0:03:51
epoch [155/200] batch [5/51] time 0.088 (0.214) data 0.000 (0.126) loss 0.0865 (0.1903) acc 100.0000 (95.6250) lr 2.6037e-04 eta 0:08:21
epoch [155/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.063) loss 0.2712 (0.2592) acc 96.8750 (94.0625) lr 2.6037e-04 eta 0:05:52
epoch [155/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.042) loss 0.2000 (0.2808) acc 93.7500 (93.9583) lr 2.6037e-04 eta 0:05:01
epoch [155/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.1515 (0.2755) acc 96.8750 (93.7500) lr 2.6037e-04 eta 0:04:36
epoch [155/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.025) loss 0.1464 (0.2755) acc 96.8750 (93.5000) lr 2.6037e-04 eta 0:04:21
epoch [155/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3008 (0.2860) acc 93.7500 (92.9167) lr 2.6037e-04 eta 0:04:10
epoch [155/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.3298 (0.2907) acc 87.5000 (92.6786) lr 2.6037e-04 eta 0:04:03
epoch [155/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1858 (0.2876) acc 93.7500 (92.9688) lr 2.6037e-04 eta 0:03:57
epoch [155/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1842 (0.2818) acc 96.8750 (93.2639) lr 2.6037e-04 eta 0:03:52
epoch [155/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1473 (0.2844) acc 93.7500 (93.0000) lr 2.6037e-04 eta 0:03:48
epoch [156/200] batch [5/51] time 0.088 (0.200) data 0.000 (0.112) loss 0.2289 (0.3156) acc 93.7500 (93.1250) lr 2.4989e-04 eta 0:07:38
epoch [156/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.4043 (0.3189) acc 87.5000 (92.5000) lr 2.4989e-04 eta 0:05:28
epoch [156/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.2856 (0.3181) acc 87.5000 (92.5000) lr 2.4989e-04 eta 0:04:44
epoch [156/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2068 (0.3249) acc 96.8750 (91.8750) lr 2.4989e-04 eta 0:04:22
epoch [156/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3325 (0.3135) acc 96.8750 (92.3750) lr 2.4989e-04 eta 0:04:08
epoch [156/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4153 (0.3087) acc 87.5000 (92.3958) lr 2.4989e-04 eta 0:03:59
epoch [156/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2015 (0.3093) acc 100.0000 (92.5893) lr 2.4989e-04 eta 0:03:53
epoch [156/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1053 (0.2926) acc 96.8750 (93.1250) lr 2.4989e-04 eta 0:03:48
epoch [156/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2434 (0.2857) acc 96.8750 (93.4028) lr 2.4989e-04 eta 0:03:43
epoch [156/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3306 (0.2790) acc 90.6250 (93.5625) lr 2.4989e-04 eta 0:03:40
epoch [157/200] batch [5/51] time 0.088 (0.198) data 0.000 (0.109) loss 0.4302 (0.2944) acc 90.6250 (93.7500) lr 2.3959e-04 eta 0:07:22
epoch [157/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.055) loss 0.2073 (0.3000) acc 96.8750 (92.8125) lr 2.3959e-04 eta 0:05:18
epoch [157/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2450 (0.3148) acc 93.7500 (92.2917) lr 2.3959e-04 eta 0:04:37
epoch [157/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.3257 (0.3063) acc 90.6250 (92.5000) lr 2.3959e-04 eta 0:04:15
epoch [157/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.022) loss 0.6123 (0.3265) acc 84.3750 (91.8750) lr 2.3959e-04 eta 0:04:03
epoch [157/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.018) loss 0.1680 (0.3119) acc 96.8750 (92.3958) lr 2.3959e-04 eta 0:03:54
epoch [157/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2781 (0.2989) acc 90.6250 (92.5000) lr 2.3959e-04 eta 0:03:48
epoch [157/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2255 (0.2898) acc 96.8750 (92.8906) lr 2.3959e-04 eta 0:03:42
epoch [157/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2578 (0.2871) acc 93.7500 (93.0556) lr 2.3959e-04 eta 0:03:38
epoch [157/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4678 (0.2896) acc 90.6250 (92.9375) lr 2.3959e-04 eta 0:03:35
epoch [158/200] batch [5/51] time 0.088 (0.198) data 0.000 (0.111) loss 0.1310 (0.2953) acc 96.8750 (94.3750) lr 2.2949e-04 eta 0:07:14
epoch [158/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.5068 (0.3053) acc 87.5000 (93.1250) lr 2.2949e-04 eta 0:05:11
epoch [158/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.4370 (0.2999) acc 87.5000 (93.7500) lr 2.2949e-04 eta 0:04:30
epoch [158/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2023 (0.3232) acc 93.7500 (92.9688) lr 2.2949e-04 eta 0:04:09
epoch [158/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3408 (0.3095) acc 84.3750 (93.1250) lr 2.2949e-04 eta 0:03:56
epoch [158/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.4575 (0.3174) acc 90.6250 (92.5000) lr 2.2949e-04 eta 0:03:48
epoch [158/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.5415 (0.3158) acc 84.3750 (92.4107) lr 2.2949e-04 eta 0:03:41
epoch [158/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2368 (0.3087) acc 96.8750 (92.7344) lr 2.2949e-04 eta 0:03:36
epoch [158/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4700 (0.3134) acc 87.5000 (92.7083) lr 2.2949e-04 eta 0:03:32
epoch [158/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2783 (0.3103) acc 93.7500 (92.8125) lr 2.2949e-04 eta 0:03:29
epoch [159/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.1376 (0.2740) acc 100.0000 (94.3750) lr 2.1957e-04 eta 0:07:07
epoch [159/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.3110 (0.2538) acc 93.7500 (94.6875) lr 2.1957e-04 eta 0:05:06
epoch [159/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.2292 (0.2460) acc 96.8750 (94.7917) lr 2.1957e-04 eta 0:04:24
epoch [159/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3130 (0.2659) acc 96.8750 (94.5312) lr 2.1957e-04 eta 0:04:04
epoch [159/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3955 (0.2743) acc 90.6250 (94.1250) lr 2.1957e-04 eta 0:03:51
epoch [159/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1356 (0.2667) acc 96.8750 (94.2708) lr 2.1957e-04 eta 0:03:43
epoch [159/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.1458 (0.2586) acc 100.0000 (94.5536) lr 2.1957e-04 eta 0:03:37
epoch [159/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2986 (0.2820) acc 93.7500 (94.1406) lr 2.1957e-04 eta 0:03:32
epoch [159/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3477 (0.2786) acc 93.7500 (94.1667) lr 2.1957e-04 eta 0:03:28
epoch [159/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2734 (0.2804) acc 90.6250 (93.9375) lr 2.1957e-04 eta 0:03:25
epoch [160/200] batch [5/51] time 0.088 (0.208) data 0.000 (0.119) loss 0.3140 (0.2225) acc 93.7500 (95.6250) lr 2.0984e-04 eta 0:07:14
epoch [160/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.1769 (0.2479) acc 93.7500 (95.6250) lr 2.0984e-04 eta 0:05:07
epoch [160/200] batch [15/51] time 0.088 (0.128) data 0.000 (0.040) loss 0.1829 (0.2415) acc 96.8750 (95.4167) lr 2.0984e-04 eta 0:04:25
epoch [160/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3450 (0.2693) acc 84.3750 (93.7500) lr 2.0984e-04 eta 0:04:03
epoch [160/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.4177 (0.2776) acc 90.6250 (93.6250) lr 2.0984e-04 eta 0:03:49
epoch [160/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1791 (0.2719) acc 93.7500 (93.6458) lr 2.0984e-04 eta 0:03:40
epoch [160/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3157 (0.2716) acc 90.6250 (93.6607) lr 2.0984e-04 eta 0:03:34
epoch [160/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3752 (0.2820) acc 90.6250 (93.4375) lr 2.0984e-04 eta 0:03:29
epoch [160/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4146 (0.2928) acc 90.6250 (93.1250) lr 2.0984e-04 eta 0:03:25
epoch [160/200] batch [50/51] time 0.088 (0.099) data 0.000 (0.012) loss 0.4651 (0.2904) acc 87.5000 (93.3125) lr 2.0984e-04 eta 0:03:21
epoch [161/200] batch [5/51] time 0.089 (0.218) data 0.000 (0.129) loss 0.2627 (0.2126) acc 93.7500 (95.0000) lr 2.0032e-04 eta 0:07:22
epoch [161/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.065) loss 0.1624 (0.2175) acc 100.0000 (95.3125) lr 2.0032e-04 eta 0:05:09
epoch [161/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.043) loss 0.3591 (0.2352) acc 87.5000 (94.7917) lr 2.0032e-04 eta 0:04:24
epoch [161/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.032) loss 0.5527 (0.2717) acc 78.1250 (93.1250) lr 2.0032e-04 eta 0:04:01
epoch [161/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.1610 (0.2708) acc 93.7500 (93.0000) lr 2.0032e-04 eta 0:03:47
epoch [161/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.4395 (0.2748) acc 87.5000 (93.0208) lr 2.0032e-04 eta 0:03:38
epoch [161/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.1613 (0.2688) acc 96.8750 (93.1250) lr 2.0032e-04 eta 0:03:31
epoch [161/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1638 (0.2686) acc 93.7500 (92.9688) lr 2.0032e-04 eta 0:03:26
epoch [161/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1364 (0.2732) acc 100.0000 (92.9861) lr 2.0032e-04 eta 0:03:21
epoch [161/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.1323 (0.2745) acc 100.0000 (93.1875) lr 2.0032e-04 eta 0:03:18
epoch [162/200] batch [5/51] time 0.088 (0.213) data 0.000 (0.125) loss 0.1813 (0.3583) acc 96.8750 (90.6250) lr 1.9098e-04 eta 0:07:02
epoch [162/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.2825 (0.3135) acc 93.7500 (91.8750) lr 1.9098e-04 eta 0:04:56
epoch [162/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.2045 (0.3446) acc 93.7500 (90.8333) lr 1.9098e-04 eta 0:04:14
epoch [162/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.3831 (0.3364) acc 87.5000 (90.9375) lr 1.9098e-04 eta 0:03:53
epoch [162/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.6846 (0.3282) acc 78.1250 (91.6250) lr 1.9098e-04 eta 0:03:40
epoch [162/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.5293 (0.3318) acc 87.5000 (91.5625) lr 1.9098e-04 eta 0:03:31
epoch [162/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.2803 (0.3185) acc 93.7500 (92.2321) lr 1.9098e-04 eta 0:03:25
epoch [162/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4370 (0.3238) acc 87.5000 (91.9531) lr 1.9098e-04 eta 0:03:20
epoch [162/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2576 (0.3231) acc 96.8750 (92.2222) lr 1.9098e-04 eta 0:03:16
epoch [162/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3301 (0.3167) acc 93.7500 (92.3750) lr 1.9098e-04 eta 0:03:12
epoch [163/200] batch [5/51] time 0.088 (0.218) data 0.000 (0.129) loss 0.2991 (0.3284) acc 93.7500 (92.5000) lr 1.8185e-04 eta 0:07:00
epoch [163/200] batch [10/51] time 0.088 (0.153) data 0.000 (0.065) loss 0.7314 (0.3878) acc 87.5000 (92.5000) lr 1.8185e-04 eta 0:04:54
epoch [163/200] batch [15/51] time 0.088 (0.131) data 0.000 (0.043) loss 0.5439 (0.3825) acc 87.5000 (91.8750) lr 1.8185e-04 eta 0:04:11
epoch [163/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.032) loss 0.1724 (0.3377) acc 93.7500 (92.8125) lr 1.8185e-04 eta 0:03:50
epoch [163/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.026) loss 0.1648 (0.3222) acc 100.0000 (93.2500) lr 1.8185e-04 eta 0:03:37
epoch [163/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2456 (0.3151) acc 93.7500 (93.3333) lr 1.8185e-04 eta 0:03:28
epoch [163/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.3340 (0.3050) acc 90.6250 (93.4821) lr 1.8185e-04 eta 0:03:21
epoch [163/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.016) loss 0.4500 (0.3072) acc 81.2500 (93.0469) lr 1.8185e-04 eta 0:03:16
epoch [163/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4111 (0.3041) acc 87.5000 (93.1250) lr 1.8185e-04 eta 0:03:12
epoch [163/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1881 (0.3058) acc 96.8750 (92.9375) lr 1.8185e-04 eta 0:03:08
epoch [164/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.2561 (0.2328) acc 96.8750 (95.6250) lr 1.7292e-04 eta 0:06:23
epoch [164/200] batch [10/51] time 0.088 (0.146) data 0.000 (0.058) loss 0.4148 (0.3048) acc 84.3750 (93.1250) lr 1.7292e-04 eta 0:04:33
epoch [164/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.1677 (0.2816) acc 93.7500 (93.9583) lr 1.7292e-04 eta 0:03:56
epoch [164/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2476 (0.2817) acc 93.7500 (93.5938) lr 1.7292e-04 eta 0:03:37
epoch [164/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4138 (0.3085) acc 93.7500 (92.8750) lr 1.7292e-04 eta 0:03:25
epoch [164/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4792 (0.3183) acc 87.5000 (92.6042) lr 1.7292e-04 eta 0:03:17
epoch [164/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2646 (0.3150) acc 93.7500 (92.7679) lr 1.7292e-04 eta 0:03:12
epoch [164/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3296 (0.3079) acc 90.6250 (92.8906) lr 1.7292e-04 eta 0:03:07
epoch [164/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.1324 (0.3070) acc 100.0000 (93.0556) lr 1.7292e-04 eta 0:03:03
epoch [164/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2842 (0.3020) acc 93.7500 (93.0000) lr 1.7292e-04 eta 0:03:00
epoch [165/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.1957 (0.2835) acc 96.8750 (93.1250) lr 1.6419e-04 eta 0:06:05
epoch [165/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.1039 (0.3186) acc 100.0000 (93.1250) lr 1.6419e-04 eta 0:04:22
epoch [165/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.037) loss 0.3059 (0.3290) acc 96.8750 (92.5000) lr 1.6419e-04 eta 0:03:47
epoch [165/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.2330 (0.3176) acc 96.8750 (92.5000) lr 1.6419e-04 eta 0:03:29
epoch [165/200] batch [25/51] time 0.089 (0.110) data 0.000 (0.023) loss 0.2986 (0.3226) acc 93.7500 (92.6250) lr 1.6419e-04 eta 0:03:18
epoch [165/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1582 (0.3077) acc 96.8750 (92.9167) lr 1.6419e-04 eta 0:03:11
epoch [165/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.016) loss 0.2477 (0.3144) acc 93.7500 (92.7679) lr 1.6419e-04 eta 0:03:06
epoch [165/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2849 (0.2989) acc 93.7500 (93.1250) lr 1.6419e-04 eta 0:03:02
epoch [165/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2042 (0.2911) acc 93.7500 (93.3333) lr 1.6419e-04 eta 0:02:58
epoch [165/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2981 (0.2926) acc 93.7500 (93.1250) lr 1.6419e-04 eta 0:02:55
epoch [166/200] batch [5/51] time 0.088 (0.199) data 0.000 (0.111) loss 0.2026 (0.2316) acc 96.8750 (95.0000) lr 1.5567e-04 eta 0:05:54
epoch [166/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.5361 (0.2716) acc 81.2500 (93.4375) lr 1.5567e-04 eta 0:04:14
epoch [166/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2659 (0.2811) acc 90.6250 (92.7083) lr 1.5567e-04 eta 0:03:40
epoch [166/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.0809 (0.2786) acc 100.0000 (93.5938) lr 1.5567e-04 eta 0:03:23
epoch [166/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.2101 (0.2861) acc 96.8750 (93.0000) lr 1.5567e-04 eta 0:03:12
epoch [166/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1570 (0.2756) acc 100.0000 (93.1250) lr 1.5567e-04 eta 0:03:05
epoch [166/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1742 (0.2707) acc 96.8750 (93.3036) lr 1.5567e-04 eta 0:03:00
epoch [166/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3123 (0.2709) acc 93.7500 (93.2031) lr 1.5567e-04 eta 0:02:56
epoch [166/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1593 (0.2699) acc 100.0000 (93.4028) lr 1.5567e-04 eta 0:02:53
epoch [166/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2102 (0.2645) acc 96.8750 (93.5625) lr 1.5567e-04 eta 0:02:50
epoch [167/200] batch [5/51] time 0.087 (0.220) data 0.000 (0.133) loss 0.3616 (0.3202) acc 90.6250 (92.5000) lr 1.4736e-04 eta 0:06:19
epoch [167/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.067) loss 0.2485 (0.2535) acc 93.7500 (94.3750) lr 1.4736e-04 eta 0:04:23
epoch [167/200] batch [15/51] time 0.086 (0.131) data 0.000 (0.044) loss 0.5713 (0.2934) acc 87.5000 (93.3333) lr 1.4736e-04 eta 0:03:45
epoch [167/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.1600 (0.2836) acc 96.8750 (93.7500) lr 1.4736e-04 eta 0:03:25
epoch [167/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.4526 (0.2904) acc 87.5000 (93.5000) lr 1.4736e-04 eta 0:03:13
epoch [167/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2435 (0.3022) acc 90.6250 (92.7083) lr 1.4736e-04 eta 0:03:05
epoch [167/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1943 (0.2938) acc 93.7500 (92.9464) lr 1.4736e-04 eta 0:02:59
epoch [167/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.1680 (0.2867) acc 100.0000 (92.9688) lr 1.4736e-04 eta 0:02:54
epoch [167/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4102 (0.2923) acc 87.5000 (92.8472) lr 1.4736e-04 eta 0:02:51
epoch [167/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1324 (0.2875) acc 96.8750 (92.9375) lr 1.4736e-04 eta 0:02:48
epoch [168/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.113) loss 0.1381 (0.2101) acc 100.0000 (97.5000) lr 1.3926e-04 eta 0:05:36
epoch [168/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.2505 (0.2053) acc 96.8750 (96.2500) lr 1.3926e-04 eta 0:04:00
epoch [168/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.4082 (0.2187) acc 93.7500 (95.6250) lr 1.3926e-04 eta 0:03:28
epoch [168/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.3098 (0.2442) acc 93.7500 (94.5312) lr 1.3926e-04 eta 0:03:12
epoch [168/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2087 (0.2514) acc 96.8750 (94.7500) lr 1.3926e-04 eta 0:03:02
epoch [168/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1803 (0.2652) acc 96.8750 (94.6875) lr 1.3926e-04 eta 0:02:55
epoch [168/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2900 (0.2635) acc 90.6250 (94.1964) lr 1.3926e-04 eta 0:02:50
epoch [168/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3232 (0.2622) acc 93.7500 (94.1406) lr 1.3926e-04 eta 0:02:46
epoch [168/200] batch [45/51] time 0.087 (0.100) data 0.000 (0.013) loss 0.3750 (0.2659) acc 90.6250 (94.0278) lr 1.3926e-04 eta 0:02:43
epoch [168/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1766 (0.2663) acc 90.6250 (93.8125) lr 1.3926e-04 eta 0:02:40
epoch [169/200] batch [5/51] time 0.088 (0.199) data 0.000 (0.110) loss 0.2747 (0.2341) acc 93.7500 (95.0000) lr 1.3137e-04 eta 0:05:23
epoch [169/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.055) loss 0.2246 (0.2896) acc 96.8750 (93.4375) lr 1.3137e-04 eta 0:03:52
epoch [169/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.037) loss 0.5454 (0.2914) acc 90.6250 (93.9583) lr 1.3137e-04 eta 0:03:21
epoch [169/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.1722 (0.2715) acc 96.8750 (94.3750) lr 1.3137e-04 eta 0:03:05
epoch [169/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.3005 (0.2658) acc 93.7500 (94.5000) lr 1.3137e-04 eta 0:02:56
epoch [169/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.2036 (0.2769) acc 96.8750 (94.1667) lr 1.3137e-04 eta 0:02:49
epoch [169/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.5371 (0.2791) acc 87.5000 (94.0179) lr 1.3137e-04 eta 0:02:45
epoch [169/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2190 (0.2806) acc 90.6250 (93.6719) lr 1.3137e-04 eta 0:02:41
epoch [169/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4985 (0.2793) acc 87.5000 (93.5417) lr 1.3137e-04 eta 0:02:37
epoch [169/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1088 (0.2695) acc 100.0000 (93.8750) lr 1.3137e-04 eta 0:02:35
epoch [170/200] batch [5/51] time 0.087 (0.219) data 0.000 (0.132) loss 0.4163 (0.3548) acc 93.7500 (93.1250) lr 1.2369e-04 eta 0:05:45
epoch [170/200] batch [10/51] time 0.088 (0.153) data 0.000 (0.066) loss 0.4910 (0.3114) acc 84.3750 (93.1250) lr 1.2369e-04 eta 0:04:00
epoch [170/200] batch [15/51] time 0.086 (0.131) data 0.000 (0.044) loss 0.5703 (0.3200) acc 87.5000 (92.2917) lr 1.2369e-04 eta 0:03:25
epoch [170/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.0895 (0.3072) acc 100.0000 (92.9688) lr 1.2369e-04 eta 0:03:07
epoch [170/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.4395 (0.3089) acc 90.6250 (93.2500) lr 1.2369e-04 eta 0:02:55
epoch [170/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.3035 (0.3130) acc 87.5000 (92.8125) lr 1.2369e-04 eta 0:02:48
epoch [170/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2744 (0.3070) acc 90.6250 (92.7679) lr 1.2369e-04 eta 0:02:43
epoch [170/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.2546 (0.3041) acc 93.7500 (92.7344) lr 1.2369e-04 eta 0:02:38
epoch [170/200] batch [45/51] time 0.089 (0.101) data 0.000 (0.015) loss 0.1301 (0.2962) acc 96.8750 (92.7778) lr 1.2369e-04 eta 0:02:35
epoch [170/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.2878 (0.2983) acc 90.6250 (92.5625) lr 1.2369e-04 eta 0:02:32
epoch [171/200] batch [5/51] time 0.088 (0.197) data 0.000 (0.109) loss 0.2932 (0.2771) acc 96.8750 (96.8750) lr 1.1623e-04 eta 0:05:00
epoch [171/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.3228 (0.2607) acc 93.7500 (96.5625) lr 1.1623e-04 eta 0:03:35
epoch [171/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.1868 (0.2258) acc 96.8750 (96.8750) lr 1.1623e-04 eta 0:03:07
epoch [171/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.2815 (0.2386) acc 96.8750 (96.0938) lr 1.1623e-04 eta 0:02:52
epoch [171/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3064 (0.2541) acc 90.6250 (95.5000) lr 1.1623e-04 eta 0:02:43
epoch [171/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1656 (0.2495) acc 100.0000 (95.4167) lr 1.1623e-04 eta 0:02:37
epoch [171/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1552 (0.2612) acc 93.7500 (95.0000) lr 1.1623e-04 eta 0:02:33
epoch [171/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2045 (0.2669) acc 93.7500 (94.8438) lr 1.1623e-04 eta 0:02:29
epoch [171/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.3398 (0.2696) acc 90.6250 (94.7917) lr 1.1623e-04 eta 0:02:27
epoch [171/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4880 (0.2730) acc 90.6250 (94.6250) lr 1.1623e-04 eta 0:02:24
epoch [172/200] batch [5/51] time 0.087 (0.208) data 0.000 (0.121) loss 0.3218 (0.3093) acc 90.6250 (92.5000) lr 1.0899e-04 eta 0:05:07
epoch [172/200] batch [10/51] time 0.086 (0.148) data 0.000 (0.061) loss 0.2031 (0.2969) acc 93.7500 (92.5000) lr 1.0899e-04 eta 0:03:36
epoch [172/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.041) loss 0.2268 (0.2690) acc 96.8750 (93.3333) lr 1.0899e-04 eta 0:03:06
epoch [172/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.2057 (0.2650) acc 96.8750 (93.5938) lr 1.0899e-04 eta 0:02:50
epoch [172/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1065 (0.2515) acc 100.0000 (94.2500) lr 1.0899e-04 eta 0:02:41
epoch [172/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1737 (0.2496) acc 96.8750 (94.0625) lr 1.0899e-04 eta 0:02:34
epoch [172/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1559 (0.2452) acc 93.7500 (94.1964) lr 1.0899e-04 eta 0:02:30
epoch [172/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1108 (0.2470) acc 100.0000 (94.1406) lr 1.0899e-04 eta 0:02:26
epoch [172/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.5303 (0.2651) acc 81.2500 (93.8194) lr 1.0899e-04 eta 0:02:23
epoch [172/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3313 (0.2750) acc 90.6250 (93.4375) lr 1.0899e-04 eta 0:02:20
epoch [173/200] batch [5/51] time 0.088 (0.209) data 0.000 (0.120) loss 0.2986 (0.3333) acc 93.7500 (93.1250) lr 1.0197e-04 eta 0:04:56
epoch [173/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.3765 (0.3088) acc 87.5000 (92.5000) lr 1.0197e-04 eta 0:03:29
epoch [173/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.040) loss 0.2454 (0.3342) acc 100.0000 (92.9167) lr 1.0197e-04 eta 0:03:00
epoch [173/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2520 (0.3070) acc 90.6250 (93.4375) lr 1.0197e-04 eta 0:02:45
epoch [173/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4639 (0.3172) acc 93.7500 (93.5000) lr 1.0197e-04 eta 0:02:36
epoch [173/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.2386 (0.3069) acc 93.7500 (93.3333) lr 1.0197e-04 eta 0:02:30
epoch [173/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2974 (0.3114) acc 93.7500 (93.0357) lr 1.0197e-04 eta 0:02:25
epoch [173/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.0643 (0.3154) acc 100.0000 (92.8906) lr 1.0197e-04 eta 0:02:21
epoch [173/200] batch [45/51] time 0.087 (0.100) data 0.000 (0.014) loss 0.1768 (0.3138) acc 96.8750 (93.0556) lr 1.0197e-04 eta 0:02:18
epoch [173/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2114 (0.3049) acc 90.6250 (93.2500) lr 1.0197e-04 eta 0:02:16
epoch [174/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.3438 (0.3921) acc 93.7500 (89.3750) lr 9.5173e-05 eta 0:04:31
epoch [174/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.2147 (0.3289) acc 93.7500 (91.5625) lr 9.5173e-05 eta 0:03:14
epoch [174/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.1986 (0.3004) acc 93.7500 (92.7083) lr 9.5173e-05 eta 0:02:48
epoch [174/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.1847 (0.2868) acc 93.7500 (92.9688) lr 9.5173e-05 eta 0:02:35
epoch [174/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1956 (0.2856) acc 96.8750 (93.1250) lr 9.5173e-05 eta 0:02:27
epoch [174/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.4509 (0.3005) acc 87.5000 (92.9167) lr 9.5173e-05 eta 0:02:22
epoch [174/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3933 (0.2983) acc 93.7500 (93.0357) lr 9.5173e-05 eta 0:02:18
epoch [174/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3276 (0.2925) acc 90.6250 (93.2812) lr 9.5173e-05 eta 0:02:14
epoch [174/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.0918 (0.2832) acc 96.8750 (93.6806) lr 9.5173e-05 eta 0:02:12
epoch [174/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4336 (0.2861) acc 90.6250 (93.6250) lr 9.5173e-05 eta 0:02:10
epoch [175/200] batch [5/51] time 0.087 (0.208) data 0.000 (0.122) loss 0.3391 (0.2909) acc 87.5000 (93.1250) lr 8.8597e-05 eta 0:04:35
epoch [175/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.1981 (0.2616) acc 96.8750 (94.0625) lr 8.8597e-05 eta 0:03:14
epoch [175/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.041) loss 0.1685 (0.2701) acc 96.8750 (93.3333) lr 8.8597e-05 eta 0:02:47
epoch [175/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.031) loss 0.5352 (0.2886) acc 84.3750 (92.9688) lr 8.8597e-05 eta 0:02:33
epoch [175/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3831 (0.2939) acc 87.5000 (92.8750) lr 8.8597e-05 eta 0:02:24
epoch [175/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1781 (0.2751) acc 96.8750 (93.3333) lr 8.8597e-05 eta 0:02:19
epoch [175/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.1287 (0.2658) acc 96.8750 (93.5714) lr 8.8597e-05 eta 0:02:14
epoch [175/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3691 (0.2601) acc 90.6250 (93.7500) lr 8.8597e-05 eta 0:02:11
epoch [175/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1851 (0.2604) acc 96.8750 (93.6806) lr 8.8597e-05 eta 0:02:08
epoch [175/200] batch [50/51] time 0.087 (0.099) data 0.000 (0.012) loss 0.5352 (0.2712) acc 90.6250 (93.3750) lr 8.8597e-05 eta 0:02:06
epoch [176/200] batch [5/51] time 0.088 (0.200) data 0.000 (0.112) loss 0.1315 (0.3262) acc 100.0000 (93.7500) lr 8.2245e-05 eta 0:04:14
epoch [176/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.056) loss 0.1372 (0.2828) acc 96.8750 (94.0625) lr 8.2245e-05 eta 0:03:01
epoch [176/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.037) loss 0.1880 (0.2676) acc 96.8750 (94.7917) lr 8.2245e-05 eta 0:02:37
epoch [176/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2162 (0.2717) acc 90.6250 (94.0625) lr 8.2245e-05 eta 0:02:24
epoch [176/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2678 (0.2713) acc 90.6250 (93.8750) lr 8.2245e-05 eta 0:02:17
epoch [176/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.5698 (0.2786) acc 84.3750 (93.7500) lr 8.2245e-05 eta 0:02:11
epoch [176/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2803 (0.2786) acc 93.7500 (93.8393) lr 8.2245e-05 eta 0:02:07
epoch [176/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3091 (0.2843) acc 90.6250 (93.4375) lr 8.2245e-05 eta 0:02:04
epoch [176/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1609 (0.2746) acc 96.8750 (93.8194) lr 8.2245e-05 eta 0:02:02
epoch [176/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1232 (0.2752) acc 100.0000 (93.9375) lr 8.2245e-05 eta 0:02:00
epoch [177/200] batch [5/51] time 0.090 (0.204) data 0.000 (0.116) loss 0.2189 (0.2951) acc 93.7500 (90.0000) lr 7.6120e-05 eta 0:04:09
epoch [177/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.5088 (0.2984) acc 84.3750 (91.2500) lr 7.6120e-05 eta 0:02:56
epoch [177/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.039) loss 0.3982 (0.3228) acc 90.6250 (90.8333) lr 7.6120e-05 eta 0:02:32
epoch [177/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.029) loss 0.4299 (0.2987) acc 90.6250 (92.0312) lr 7.6120e-05 eta 0:02:20
epoch [177/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.023) loss 0.1646 (0.2857) acc 96.8750 (92.6250) lr 7.6120e-05 eta 0:02:12
epoch [177/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3782 (0.2925) acc 93.7500 (92.6042) lr 7.6120e-05 eta 0:02:07
epoch [177/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2101 (0.2933) acc 96.8750 (92.5000) lr 7.6120e-05 eta 0:02:03
epoch [177/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1858 (0.2799) acc 93.7500 (92.8125) lr 7.6120e-05 eta 0:02:00
epoch [177/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1058 (0.2700) acc 96.8750 (92.9861) lr 7.6120e-05 eta 0:01:57
epoch [177/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3188 (0.2621) acc 93.7500 (93.3125) lr 7.6120e-05 eta 0:01:55
epoch [178/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.114) loss 0.2998 (0.2502) acc 93.7500 (94.3750) lr 7.0224e-05 eta 0:03:55
epoch [178/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.057) loss 0.2136 (0.2744) acc 96.8750 (94.6875) lr 7.0224e-05 eta 0:02:48
epoch [178/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.1807 (0.2810) acc 100.0000 (94.1667) lr 7.0224e-05 eta 0:02:25
epoch [178/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.029) loss 0.4707 (0.2768) acc 87.5000 (94.3750) lr 7.0224e-05 eta 0:02:13
epoch [178/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.2404 (0.2779) acc 93.7500 (94.5000) lr 7.0224e-05 eta 0:02:06
epoch [178/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1628 (0.2815) acc 93.7500 (94.1667) lr 7.0224e-05 eta 0:02:01
epoch [178/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.0980 (0.2778) acc 100.0000 (94.1071) lr 7.0224e-05 eta 0:01:57
epoch [178/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1414 (0.2655) acc 96.8750 (94.4531) lr 7.0224e-05 eta 0:01:54
epoch [178/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1387 (0.2578) acc 100.0000 (94.6528) lr 7.0224e-05 eta 0:01:52
epoch [178/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1445 (0.2546) acc 96.8750 (94.6250) lr 7.0224e-05 eta 0:01:50
epoch [179/200] batch [5/51] time 0.086 (0.218) data 0.000 (0.131) loss 0.4626 (0.2949) acc 93.7500 (93.1250) lr 6.4556e-05 eta 0:04:03
epoch [179/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.0997 (0.2822) acc 100.0000 (93.1250) lr 6.4556e-05 eta 0:02:49
epoch [179/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.3208 (0.2805) acc 93.7500 (93.7500) lr 6.4556e-05 eta 0:02:24
epoch [179/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3987 (0.2693) acc 90.6250 (93.9062) lr 6.4556e-05 eta 0:02:11
epoch [179/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2639 (0.2566) acc 93.7500 (94.2500) lr 6.4556e-05 eta 0:02:04
epoch [179/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2076 (0.2695) acc 96.8750 (93.7500) lr 6.4556e-05 eta 0:01:58
epoch [179/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2434 (0.2689) acc 93.7500 (93.8393) lr 6.4556e-05 eta 0:01:54
epoch [179/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.2393 (0.2685) acc 96.8750 (94.0625) lr 6.4556e-05 eta 0:01:51
epoch [179/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4541 (0.2791) acc 81.2500 (93.6806) lr 6.4556e-05 eta 0:01:49
epoch [179/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2147 (0.2726) acc 96.8750 (93.8125) lr 6.4556e-05 eta 0:01:46
epoch [180/200] batch [5/51] time 0.088 (0.223) data 0.000 (0.135) loss 0.2104 (0.2670) acc 96.8750 (93.7500) lr 5.9119e-05 eta 0:03:57
epoch [180/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.4143 (0.2866) acc 87.5000 (93.1250) lr 5.9119e-05 eta 0:02:44
epoch [180/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.1770 (0.2801) acc 96.8750 (93.9583) lr 5.9119e-05 eta 0:02:19
epoch [180/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.2908 (0.2715) acc 90.6250 (94.5312) lr 5.9119e-05 eta 0:02:07
epoch [180/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2627 (0.3020) acc 93.7500 (93.3750) lr 5.9119e-05 eta 0:01:59
epoch [180/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1598 (0.3007) acc 96.8750 (93.6458) lr 5.9119e-05 eta 0:01:54
epoch [180/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.1135 (0.2924) acc 100.0000 (93.9286) lr 5.9119e-05 eta 0:01:50
epoch [180/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1683 (0.2803) acc 96.8750 (94.2188) lr 5.9119e-05 eta 0:01:47
epoch [180/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1173 (0.2805) acc 96.8750 (94.0972) lr 5.9119e-05 eta 0:01:44
epoch [180/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2279 (0.2757) acc 93.7500 (94.0000) lr 5.9119e-05 eta 0:01:42
epoch [181/200] batch [5/51] time 0.087 (0.215) data 0.000 (0.128) loss 0.4148 (0.2732) acc 90.6250 (93.7500) lr 5.3915e-05 eta 0:03:38
epoch [181/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.2274 (0.2528) acc 96.8750 (94.3750) lr 5.3915e-05 eta 0:02:32
epoch [181/200] batch [15/51] time 0.086 (0.129) data 0.000 (0.043) loss 0.2444 (0.2477) acc 90.6250 (94.3750) lr 5.3915e-05 eta 0:02:10
epoch [181/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.3047 (0.2571) acc 93.7500 (94.5312) lr 5.3915e-05 eta 0:01:58
epoch [181/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.026) loss 0.1533 (0.2653) acc 96.8750 (94.2500) lr 5.3915e-05 eta 0:01:51
epoch [181/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.021) loss 0.1937 (0.2678) acc 96.8750 (94.3750) lr 5.3915e-05 eta 0:01:46
epoch [181/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.1366 (0.2711) acc 100.0000 (94.1964) lr 5.3915e-05 eta 0:01:43
epoch [181/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2072 (0.2673) acc 93.7500 (94.2188) lr 5.3915e-05 eta 0:01:40
epoch [181/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2000 (0.2724) acc 93.7500 (93.8889) lr 5.3915e-05 eta 0:01:38
epoch [181/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1589 (0.2687) acc 100.0000 (94.1875) lr 5.3915e-05 eta 0:01:36
epoch [182/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.118) loss 0.4460 (0.3471) acc 90.6250 (91.8750) lr 4.8943e-05 eta 0:03:18
epoch [182/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.1311 (0.2697) acc 100.0000 (94.0625) lr 4.8943e-05 eta 0:02:20
epoch [182/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.2134 (0.2762) acc 96.8750 (93.9583) lr 4.8943e-05 eta 0:02:00
epoch [182/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2869 (0.2669) acc 93.7500 (94.0625) lr 4.8943e-05 eta 0:01:50
epoch [182/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1138 (0.2471) acc 96.8750 (94.6250) lr 4.8943e-05 eta 0:01:44
epoch [182/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.2539 (0.2657) acc 90.6250 (93.7500) lr 4.8943e-05 eta 0:01:40
epoch [182/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.3523 (0.2651) acc 96.8750 (93.8393) lr 4.8943e-05 eta 0:01:37
epoch [182/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1611 (0.2604) acc 93.7500 (93.8281) lr 4.8943e-05 eta 0:01:34
epoch [182/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2500 (0.2622) acc 96.8750 (93.8194) lr 4.8943e-05 eta 0:01:32
epoch [182/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2242 (0.2674) acc 96.8750 (93.7500) lr 4.8943e-05 eta 0:01:30
epoch [183/200] batch [5/51] time 0.089 (0.201) data 0.000 (0.112) loss 0.2178 (0.2541) acc 96.8750 (95.0000) lr 4.4207e-05 eta 0:03:03
epoch [183/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.056) loss 0.3674 (0.2558) acc 90.6250 (94.6875) lr 4.4207e-05 eta 0:02:11
epoch [183/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.1847 (0.2349) acc 96.8750 (95.2083) lr 4.4207e-05 eta 0:01:53
epoch [183/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.028) loss 0.2458 (0.2442) acc 96.8750 (95.0000) lr 4.4207e-05 eta 0:01:44
epoch [183/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1412 (0.2565) acc 100.0000 (94.3750) lr 4.4207e-05 eta 0:01:38
epoch [183/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2595 (0.2589) acc 90.6250 (94.1667) lr 4.4207e-05 eta 0:01:34
epoch [183/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.016) loss 0.3127 (0.2591) acc 90.6250 (93.8393) lr 4.4207e-05 eta 0:01:31
epoch [183/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1708 (0.2661) acc 96.8750 (93.4375) lr 4.4207e-05 eta 0:01:28
epoch [183/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1935 (0.2691) acc 96.8750 (93.2639) lr 4.4207e-05 eta 0:01:26
epoch [183/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1915 (0.2630) acc 96.8750 (93.4375) lr 4.4207e-05 eta 0:01:25
epoch [184/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.117) loss 0.2009 (0.2281) acc 96.8750 (96.2500) lr 3.9706e-05 eta 0:02:56
epoch [184/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.1887 (0.2172) acc 96.8750 (96.8750) lr 3.9706e-05 eta 0:02:05
epoch [184/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.0941 (0.2448) acc 100.0000 (95.4167) lr 3.9706e-05 eta 0:01:47
epoch [184/200] batch [20/51] time 0.091 (0.117) data 0.000 (0.030) loss 0.2510 (0.2470) acc 96.8750 (95.0000) lr 3.9706e-05 eta 0:01:39
epoch [184/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.1566 (0.2666) acc 96.8750 (94.5000) lr 3.9706e-05 eta 0:01:33
epoch [184/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3918 (0.2746) acc 90.6250 (94.3750) lr 3.9706e-05 eta 0:01:29
epoch [184/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2479 (0.2763) acc 96.8750 (94.1964) lr 3.9706e-05 eta 0:01:26
epoch [184/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3469 (0.2810) acc 90.6250 (93.9062) lr 3.9706e-05 eta 0:01:24
epoch [184/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3228 (0.2898) acc 93.7500 (93.6806) lr 3.9706e-05 eta 0:01:22
epoch [184/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3030 (0.2973) acc 90.6250 (93.3750) lr 3.9706e-05 eta 0:01:20
epoch [185/200] batch [5/51] time 0.088 (0.205) data 0.000 (0.117) loss 0.3352 (0.2510) acc 93.7500 (95.0000) lr 3.5443e-05 eta 0:02:46
epoch [185/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.0834 (0.2499) acc 100.0000 (95.3125) lr 3.5443e-05 eta 0:01:57
epoch [185/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.1604 (0.2481) acc 93.7500 (94.5833) lr 3.5443e-05 eta 0:01:41
epoch [185/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.0435 (0.2319) acc 100.0000 (94.8438) lr 3.5443e-05 eta 0:01:32
epoch [185/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4233 (0.2369) acc 93.7500 (95.1250) lr 3.5443e-05 eta 0:01:27
epoch [185/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4021 (0.2462) acc 90.6250 (94.7917) lr 3.5443e-05 eta 0:01:23
epoch [185/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2010 (0.2433) acc 93.7500 (94.6429) lr 3.5443e-05 eta 0:01:21
epoch [185/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2147 (0.2490) acc 93.7500 (94.3750) lr 3.5443e-05 eta 0:01:18
epoch [185/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.2903 (0.2534) acc 87.5000 (94.3056) lr 3.5443e-05 eta 0:01:16
epoch [185/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3010 (0.2531) acc 93.7500 (94.3750) lr 3.5443e-05 eta 0:01:15
epoch [186/200] batch [5/51] time 0.088 (0.208) data 0.000 (0.120) loss 0.2839 (0.2695) acc 93.7500 (93.7500) lr 3.1417e-05 eta 0:02:38
epoch [186/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.2068 (0.2623) acc 93.7500 (93.7500) lr 3.1417e-05 eta 0:01:51
epoch [186/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.4365 (0.3099) acc 87.5000 (91.6667) lr 3.1417e-05 eta 0:01:35
epoch [186/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3367 (0.3149) acc 87.5000 (91.7188) lr 3.1417e-05 eta 0:01:27
epoch [186/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1931 (0.2931) acc 93.7500 (92.2500) lr 3.1417e-05 eta 0:01:22
epoch [186/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2612 (0.2954) acc 90.6250 (91.9792) lr 3.1417e-05 eta 0:01:18
epoch [186/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.5356 (0.2974) acc 87.5000 (92.1429) lr 3.1417e-05 eta 0:01:16
epoch [186/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1819 (0.2967) acc 96.8750 (92.3438) lr 3.1417e-05 eta 0:01:13
epoch [186/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2930 (0.2969) acc 96.8750 (92.5000) lr 3.1417e-05 eta 0:01:12
epoch [186/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3826 (0.2926) acc 90.6250 (92.6875) lr 3.1417e-05 eta 0:01:10
epoch [187/200] batch [5/51] time 0.088 (0.207) data 0.000 (0.120) loss 0.2822 (0.2984) acc 93.7500 (93.7500) lr 2.7630e-05 eta 0:02:26
epoch [187/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.4666 (0.2613) acc 90.6250 (94.3750) lr 2.7630e-05 eta 0:01:43
epoch [187/200] batch [15/51] time 0.088 (0.127) data 0.000 (0.040) loss 0.0934 (0.2515) acc 100.0000 (94.3750) lr 2.7630e-05 eta 0:01:28
epoch [187/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.1631 (0.2563) acc 100.0000 (94.2188) lr 2.7630e-05 eta 0:01:21
epoch [187/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4329 (0.2762) acc 90.6250 (93.8750) lr 2.7630e-05 eta 0:01:16
epoch [187/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3552 (0.2957) acc 93.7500 (93.7500) lr 2.7630e-05 eta 0:01:13
epoch [187/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.017) loss 0.2101 (0.2795) acc 96.8750 (94.2857) lr 2.7630e-05 eta 0:01:10
epoch [187/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2280 (0.2682) acc 93.7500 (94.6094) lr 2.7630e-05 eta 0:01:08
epoch [187/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2252 (0.2751) acc 93.7500 (94.0278) lr 2.7630e-05 eta 0:01:07
epoch [187/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3411 (0.2751) acc 90.6250 (93.8125) lr 2.7630e-05 eta 0:01:05
epoch [188/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.111) loss 0.2725 (0.2407) acc 93.7500 (93.7500) lr 2.4083e-05 eta 0:02:11
epoch [188/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.2739 (0.2488) acc 93.7500 (93.7500) lr 2.4083e-05 eta 0:01:33
epoch [188/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.2478 (0.2648) acc 96.8750 (93.9583) lr 2.4083e-05 eta 0:01:20
epoch [188/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4062 (0.2667) acc 90.6250 (93.4375) lr 2.4083e-05 eta 0:01:13
epoch [188/200] batch [25/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.1823 (0.2522) acc 96.8750 (94.1250) lr 2.4083e-05 eta 0:01:09
epoch [188/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1827 (0.2547) acc 96.8750 (94.0625) lr 2.4083e-05 eta 0:01:06
epoch [188/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2083 (0.2529) acc 96.8750 (93.8393) lr 2.4083e-05 eta 0:01:04
epoch [188/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1384 (0.2584) acc 100.0000 (93.9062) lr 2.4083e-05 eta 0:01:02
epoch [188/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.0739 (0.2502) acc 100.0000 (94.2361) lr 2.4083e-05 eta 0:01:01
epoch [188/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1414 (0.2436) acc 100.0000 (94.5000) lr 2.4083e-05 eta 0:00:59
epoch [189/200] batch [5/51] time 0.088 (0.205) data 0.000 (0.117) loss 0.3108 (0.3073) acc 93.7500 (93.1250) lr 2.0777e-05 eta 0:02:04
epoch [189/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.4175 (0.3488) acc 87.5000 (90.9375) lr 2.0777e-05 eta 0:01:28
epoch [189/200] batch [15/51] time 0.088 (0.127) data 0.000 (0.039) loss 0.1241 (0.3117) acc 96.8750 (91.8750) lr 2.0777e-05 eta 0:01:15
epoch [189/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.029) loss 0.2849 (0.3077) acc 93.7500 (92.1875) lr 2.0777e-05 eta 0:01:09
epoch [189/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1719 (0.2856) acc 96.8750 (92.8750) lr 2.0777e-05 eta 0:01:05
epoch [189/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2815 (0.2856) acc 93.7500 (92.9167) lr 2.0777e-05 eta 0:01:02
epoch [189/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2284 (0.2761) acc 96.8750 (93.4821) lr 2.0777e-05 eta 0:01:00
epoch [189/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3386 (0.2702) acc 96.8750 (93.8281) lr 2.0777e-05 eta 0:00:58
epoch [189/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1285 (0.2661) acc 100.0000 (93.8889) lr 2.0777e-05 eta 0:00:56
epoch [189/200] batch [50/51] time 0.087 (0.099) data 0.000 (0.012) loss 0.3455 (0.2705) acc 90.6250 (93.5625) lr 2.0777e-05 eta 0:00:55
epoch [190/200] batch [5/51] time 0.088 (0.206) data 0.000 (0.117) loss 0.3167 (0.2727) acc 93.7500 (91.8750) lr 1.7713e-05 eta 0:01:54
epoch [190/200] batch [10/51] time 0.088 (0.147) data 0.000 (0.059) loss 0.1936 (0.2967) acc 96.8750 (91.5625) lr 1.7713e-05 eta 0:01:20
epoch [190/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.1969 (0.2903) acc 93.7500 (92.5000) lr 1.7713e-05 eta 0:01:09
epoch [190/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2129 (0.2860) acc 96.8750 (92.9688) lr 1.7713e-05 eta 0:01:03
epoch [190/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3030 (0.2970) acc 90.6250 (92.3750) lr 1.7713e-05 eta 0:00:59
epoch [190/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2131 (0.2841) acc 93.7500 (92.9167) lr 1.7713e-05 eta 0:00:56
epoch [190/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1722 (0.2777) acc 96.8750 (93.0357) lr 1.7713e-05 eta 0:00:54
epoch [190/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3452 (0.2817) acc 93.7500 (92.6562) lr 1.7713e-05 eta 0:00:53
epoch [190/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2751 (0.2825) acc 87.5000 (92.6389) lr 1.7713e-05 eta 0:00:51
epoch [190/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2561 (0.2792) acc 96.8750 (92.9375) lr 1.7713e-05 eta 0:00:50
epoch [191/200] batch [5/51] time 0.087 (0.208) data 0.000 (0.120) loss 0.5010 (0.2497) acc 93.7500 (96.2500) lr 1.4891e-05 eta 0:01:45
epoch [191/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.1576 (0.2792) acc 96.8750 (93.7500) lr 1.4891e-05 eta 0:01:13
epoch [191/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.2161 (0.2702) acc 93.7500 (93.7500) lr 1.4891e-05 eta 0:01:03
epoch [191/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3022 (0.2544) acc 93.7500 (94.3750) lr 1.4891e-05 eta 0:00:57
epoch [191/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1346 (0.2520) acc 100.0000 (94.1250) lr 1.4891e-05 eta 0:00:53
epoch [191/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1182 (0.2508) acc 96.8750 (94.1667) lr 1.4891e-05 eta 0:00:51
epoch [191/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.0938 (0.2474) acc 100.0000 (94.1071) lr 1.4891e-05 eta 0:00:49
epoch [191/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2041 (0.2470) acc 96.8750 (94.2188) lr 1.4891e-05 eta 0:00:47
epoch [191/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2559 (0.2559) acc 93.7500 (93.9583) lr 1.4891e-05 eta 0:00:46
epoch [191/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4541 (0.2645) acc 90.6250 (93.7500) lr 1.4891e-05 eta 0:00:45
epoch [192/200] batch [5/51] time 0.088 (0.222) data 0.000 (0.135) loss 0.1448 (0.2676) acc 100.0000 (94.3750) lr 1.2312e-05 eta 0:01:40
epoch [192/200] batch [10/51] time 0.086 (0.154) data 0.000 (0.068) loss 0.3782 (0.2677) acc 90.6250 (93.4375) lr 1.2312e-05 eta 0:01:09
epoch [192/200] batch [15/51] time 0.086 (0.132) data 0.000 (0.045) loss 0.2141 (0.2677) acc 96.8750 (93.7500) lr 1.2312e-05 eta 0:00:58
epoch [192/200] batch [20/51] time 0.088 (0.121) data 0.000 (0.034) loss 0.3831 (0.2641) acc 87.5000 (94.0625) lr 1.2312e-05 eta 0:00:53
epoch [192/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.1929 (0.2547) acc 96.8750 (94.3750) lr 1.2312e-05 eta 0:00:49
epoch [192/200] batch [30/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.2986 (0.2736) acc 93.7500 (93.7500) lr 1.2312e-05 eta 0:00:47
epoch [192/200] batch [35/51] time 0.088 (0.107) data 0.000 (0.019) loss 0.4773 (0.2860) acc 84.3750 (93.3036) lr 1.2312e-05 eta 0:00:45
epoch [192/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2458 (0.2780) acc 90.6250 (93.5156) lr 1.2312e-05 eta 0:00:43
epoch [192/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2313 (0.2785) acc 96.8750 (93.4028) lr 1.2312e-05 eta 0:00:42
epoch [192/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2087 (0.2792) acc 90.6250 (93.1250) lr 1.2312e-05 eta 0:00:41
epoch [193/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.1043 (0.2385) acc 100.0000 (95.0000) lr 9.9763e-06 eta 0:01:20
epoch [193/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.2590 (0.2853) acc 90.6250 (93.1250) lr 9.9763e-06 eta 0:00:57
epoch [193/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.038) loss 0.3115 (0.2763) acc 90.6250 (93.5417) lr 9.9763e-06 eta 0:00:49
epoch [193/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.028) loss 0.2329 (0.2839) acc 93.7500 (93.2812) lr 9.9763e-06 eta 0:00:44
epoch [193/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.2898 (0.2811) acc 93.7500 (93.3750) lr 9.9763e-06 eta 0:00:41
epoch [193/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3459 (0.2770) acc 90.6250 (93.4375) lr 9.9763e-06 eta 0:00:39
epoch [193/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.1755 (0.2623) acc 96.8750 (93.6607) lr 9.9763e-06 eta 0:00:38
epoch [193/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2729 (0.2630) acc 93.7500 (93.8281) lr 9.9763e-06 eta 0:00:37
epoch [193/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3328 (0.2645) acc 96.8750 (94.0278) lr 9.9763e-06 eta 0:00:36
epoch [193/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4807 (0.2640) acc 93.7500 (94.1250) lr 9.9763e-06 eta 0:00:35
epoch [194/200] batch [5/51] time 0.088 (0.197) data 0.000 (0.109) loss 0.2003 (0.2551) acc 93.7500 (94.3750) lr 7.8853e-06 eta 0:01:09
epoch [194/200] batch [10/51] time 0.088 (0.142) data 0.001 (0.055) loss 0.1708 (0.2649) acc 96.8750 (94.0625) lr 7.8853e-06 eta 0:00:49
epoch [194/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2261 (0.2656) acc 96.8750 (93.7500) lr 7.8853e-06 eta 0:00:42
epoch [194/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.027) loss 0.3232 (0.2784) acc 90.6250 (93.1250) lr 7.8853e-06 eta 0:00:38
epoch [194/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2185 (0.2830) acc 93.7500 (93.1250) lr 7.8853e-06 eta 0:00:36
epoch [194/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.3386 (0.2804) acc 87.5000 (93.3333) lr 7.8853e-06 eta 0:00:34
epoch [194/200] batch [35/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.3633 (0.2785) acc 90.6250 (93.3036) lr 7.8853e-06 eta 0:00:32
epoch [194/200] batch [40/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.3601 (0.2782) acc 93.7500 (93.4375) lr 7.8853e-06 eta 0:00:31
epoch [194/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4688 (0.2814) acc 90.6250 (93.4722) lr 7.8853e-06 eta 0:00:30
epoch [194/200] batch [50/51] time 0.086 (0.097) data 0.000 (0.011) loss 0.2651 (0.2756) acc 96.8750 (93.6875) lr 7.8853e-06 eta 0:00:29
epoch [195/200] batch [5/51] time 0.088 (0.223) data 0.000 (0.135) loss 0.2095 (0.3555) acc 93.7500 (91.8750) lr 6.0390e-06 eta 0:01:06
epoch [195/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.1377 (0.3006) acc 96.8750 (92.8125) lr 6.0390e-06 eta 0:00:45
epoch [195/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.2220 (0.2972) acc 93.7500 (92.9167) lr 6.0390e-06 eta 0:00:38
epoch [195/200] batch [20/51] time 0.088 (0.121) data 0.000 (0.034) loss 0.2434 (0.3004) acc 93.7500 (92.9688) lr 6.0390e-06 eta 0:00:34
epoch [195/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.6152 (0.3088) acc 81.2500 (92.5000) lr 6.0390e-06 eta 0:00:32
epoch [195/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.1642 (0.3046) acc 96.8750 (92.6042) lr 6.0390e-06 eta 0:00:30
epoch [195/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.3406 (0.3022) acc 96.8750 (92.6786) lr 6.0390e-06 eta 0:00:28
epoch [195/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2659 (0.2968) acc 93.7500 (92.6562) lr 6.0390e-06 eta 0:00:27
epoch [195/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2499 (0.2899) acc 96.8750 (93.0556) lr 6.0390e-06 eta 0:00:26
epoch [195/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2068 (0.3011) acc 96.8750 (92.9375) lr 6.0390e-06 eta 0:00:25
epoch [196/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.130) loss 0.2969 (0.2734) acc 93.7500 (93.7500) lr 4.4380e-06 eta 0:00:54
epoch [196/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.1164 (0.2681) acc 96.8750 (94.0625) lr 4.4380e-06 eta 0:00:37
epoch [196/200] batch [15/51] time 0.086 (0.130) data 0.000 (0.043) loss 0.2905 (0.2727) acc 90.6250 (93.9583) lr 4.4380e-06 eta 0:00:31
epoch [196/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.033) loss 0.2729 (0.2727) acc 93.7500 (93.9062) lr 4.4380e-06 eta 0:00:27
epoch [196/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.5361 (0.2884) acc 87.5000 (93.2500) lr 4.4380e-06 eta 0:00:25
epoch [196/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.022) loss 0.2681 (0.2800) acc 96.8750 (93.9583) lr 4.4380e-06 eta 0:00:24
epoch [196/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.0829 (0.2839) acc 100.0000 (93.8393) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3352 (0.2868) acc 93.7500 (93.6719) lr 4.4380e-06 eta 0:00:22
epoch [196/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4553 (0.2919) acc 87.5000 (93.5417) lr 4.4380e-06 eta 0:00:21
epoch [196/200] batch [50/51] time 0.087 (0.099) data 0.000 (0.013) loss 0.4763 (0.2970) acc 81.2500 (93.2500) lr 4.4380e-06 eta 0:00:20
epoch [197/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.111) loss 0.1254 (0.1877) acc 96.8750 (95.0000) lr 3.0827e-06 eta 0:00:39
epoch [197/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.2346 (0.2153) acc 93.7500 (95.0000) lr 3.0827e-06 eta 0:00:27
epoch [197/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.2881 (0.2439) acc 93.7500 (94.5833) lr 3.0827e-06 eta 0:00:23
epoch [197/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4409 (0.2793) acc 90.6250 (93.5938) lr 3.0827e-06 eta 0:00:21
epoch [197/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2683 (0.2715) acc 93.7500 (94.0000) lr 3.0827e-06 eta 0:00:19
epoch [197/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.0793 (0.2649) acc 100.0000 (94.2708) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1930 (0.2674) acc 93.7500 (94.1071) lr 3.0827e-06 eta 0:00:17
epoch [197/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3284 (0.2745) acc 90.6250 (93.9062) lr 3.0827e-06 eta 0:00:16
epoch [197/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2235 (0.2672) acc 93.7500 (94.0278) lr 3.0827e-06 eta 0:00:15
epoch [197/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1647 (0.2617) acc 96.8750 (94.3125) lr 3.0827e-06 eta 0:00:15
epoch [198/200] batch [5/51] time 0.087 (0.214) data 0.000 (0.126) loss 0.3906 (0.2927) acc 87.5000 (93.1250) lr 1.9733e-06 eta 0:00:31
epoch [198/200] batch [10/51] time 0.086 (0.150) data 0.000 (0.063) loss 0.2849 (0.2663) acc 93.7500 (94.0625) lr 1.9733e-06 eta 0:00:21
epoch [198/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.1959 (0.2829) acc 96.8750 (93.7500) lr 1.9733e-06 eta 0:00:17
epoch [198/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.032) loss 0.1478 (0.2756) acc 100.0000 (93.9062) lr 1.9733e-06 eta 0:00:15
epoch [198/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.3936 (0.2814) acc 90.6250 (93.7500) lr 1.9733e-06 eta 0:00:14
epoch [198/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.021) loss 0.4983 (0.2965) acc 81.2500 (93.1250) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.4185 (0.2884) acc 87.5000 (93.3036) lr 1.9733e-06 eta 0:00:12
epoch [198/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2554 (0.2902) acc 93.7500 (93.2812) lr 1.9733e-06 eta 0:00:11
epoch [198/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1697 (0.2828) acc 90.6250 (93.4028) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3955 (0.2861) acc 84.3750 (93.1875) lr 1.9733e-06 eta 0:00:10
epoch [199/200] batch [5/51] time 0.087 (0.207) data 0.000 (0.119) loss 0.1841 (0.2385) acc 96.8750 (93.7500) lr 1.1101e-06 eta 0:00:20
epoch [199/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.1628 (0.2531) acc 96.8750 (94.0625) lr 1.1101e-06 eta 0:00:13
epoch [199/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.3115 (0.2868) acc 93.7500 (92.9167) lr 1.1101e-06 eta 0:00:11
epoch [199/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.2137 (0.2829) acc 93.7500 (93.1250) lr 1.1101e-06 eta 0:00:09
epoch [199/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1858 (0.2779) acc 93.7500 (93.3750) lr 1.1101e-06 eta 0:00:08
epoch [199/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.2081 (0.2869) acc 96.8750 (93.3333) lr 1.1101e-06 eta 0:00:07
epoch [199/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2708 (0.2916) acc 93.7500 (93.3036) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.2426 (0.2757) acc 87.5000 (93.5156) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4390 (0.2782) acc 90.6250 (93.3333) lr 1.1101e-06 eta 0:00:05
epoch [199/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3271 (0.2780) acc 93.7500 (93.4375) lr 1.1101e-06 eta 0:00:05
epoch [200/200] batch [5/51] time 0.089 (0.200) data 0.000 (0.111) loss 0.3977 (0.3593) acc 90.6250 (92.5000) lr 4.9344e-07 eta 0:00:09
epoch [200/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.3035 (0.3704) acc 90.6250 (90.6250) lr 4.9344e-07 eta 0:00:05
epoch [200/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.037) loss 0.5371 (0.4000) acc 87.5000 (90.0000) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2676 (0.3631) acc 90.6250 (91.5625) lr 4.9344e-07 eta 0:00:03
epoch [200/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.1886 (0.3575) acc 96.8750 (91.5000) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.2861 (0.3473) acc 93.7500 (91.8750) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3113 (0.3301) acc 87.5000 (92.2321) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.0933 (0.3168) acc 100.0000 (92.7344) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3274 (0.3172) acc 87.5000 (92.6389) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4609 (0.3150) acc 90.6250 (92.6250) lr 4.9344e-07 eta 0:00:00
Checkpoint saved to output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:01<00:46,  1.96s/it]  8%|▊         | 2/25 [00:02<00:20,  1.14it/s] 12%|█▏        | 3/25 [00:02<00:11,  1.87it/s] 16%|█▌        | 4/25 [00:02<00:07,  2.69it/s] 20%|██        | 5/25 [00:02<00:05,  3.55it/s] 24%|██▍       | 6/25 [00:02<00:04,  4.39it/s] 28%|██▊       | 7/25 [00:02<00:03,  5.17it/s] 32%|███▏      | 8/25 [00:02<00:02,  5.84it/s] 36%|███▌      | 9/25 [00:03<00:02,  5.39it/s] 40%|████      | 10/25 [00:03<00:02,  6.02it/s] 44%|████▍     | 11/25 [00:03<00:02,  6.54it/s] 48%|████▊     | 12/25 [00:03<00:01,  6.95it/s] 52%|█████▏    | 13/25 [00:03<00:01,  7.24it/s] 56%|█████▌    | 14/25 [00:03<00:01,  7.49it/s] 60%|██████    | 15/25 [00:03<00:01,  7.66it/s] 64%|██████▍   | 16/25 [00:03<00:01,  7.79it/s] 68%|██████▊   | 17/25 [00:04<00:02,  3.96it/s] 72%|███████▏  | 18/25 [00:04<00:01,  4.69it/s] 76%|███████▌  | 19/25 [00:04<00:01,  5.38it/s] 80%|████████  | 20/25 [00:04<00:00,  6.00it/s] 84%|████████▍ | 21/25 [00:04<00:00,  6.52it/s] 88%|████████▊ | 22/25 [00:05<00:00,  6.95it/s] 92%|█████████▏| 23/25 [00:05<00:00,  7.27it/s] 96%|█████████▌| 24/25 [00:05<00:00,  7.52it/s]100%|██████████| 25/25 [00:05<00:00,  4.56it/s]
=> result
* total: 2,463
* correct: 2,370
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.0%
Elapsed: 0:17:12
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_train.sh oxford_flowers 2 0 vit_b16_ctxv1 16 CoOp
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_2.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/200] batch [5/51] time 0.086 (0.594) data 0.000 (0.194) loss 2.0781 (2.2289) acc 50.0000 (54.3750) lr 1.0000e-05 eta 1:40:57
epoch [1/200] batch [10/51] time 0.087 (0.340) data 0.000 (0.097) loss 3.0078 (2.1771) acc 46.8750 (60.0000) lr 1.0000e-05 eta 0:57:47
epoch [1/200] batch [15/51] time 0.086 (0.255) data 0.000 (0.065) loss 3.3105 (2.2367) acc 53.1250 (57.2917) lr 1.0000e-05 eta 0:43:22
epoch [1/200] batch [20/51] time 0.086 (0.213) data 0.000 (0.049) loss 1.0732 (2.1609) acc 75.0000 (57.6562) lr 1.0000e-05 eta 0:36:10
epoch [1/200] batch [25/51] time 0.087 (0.188) data 0.000 (0.039) loss 1.8340 (2.0912) acc 56.2500 (57.6250) lr 1.0000e-05 eta 0:31:50
epoch [1/200] batch [30/51] time 0.086 (0.171) data 0.000 (0.033) loss 0.9668 (2.0731) acc 78.1250 (59.5833) lr 1.0000e-05 eta 0:28:58
epoch [1/200] batch [35/51] time 0.087 (0.159) data 0.000 (0.028) loss 1.9873 (2.0228) acc 71.8750 (60.0000) lr 1.0000e-05 eta 0:26:55
epoch [1/200] batch [40/51] time 0.085 (0.150) data 0.000 (0.025) loss 1.4150 (2.0120) acc 59.3750 (59.9219) lr 1.0000e-05 eta 0:25:22
epoch [1/200] batch [45/51] time 0.085 (0.143) data 0.000 (0.022) loss 1.1826 (1.9930) acc 65.6250 (59.7917) lr 1.0000e-05 eta 0:24:09
epoch [1/200] batch [50/51] time 0.086 (0.137) data 0.000 (0.020) loss 2.6855 (2.0223) acc 56.2500 (59.4375) lr 1.0000e-05 eta 0:23:10
epoch [2/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.111) loss 1.9043 (1.8412) acc 56.2500 (63.1250) lr 2.0000e-03 eta 0:33:37
epoch [2/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 1.3496 (1.7979) acc 56.2500 (61.8750) lr 2.0000e-03 eta 0:24:07
epoch [2/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 1.5449 (1.6616) acc 68.7500 (63.3333) lr 2.0000e-03 eta 0:20:58
epoch [2/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.028) loss 1.1426 (1.5966) acc 59.3750 (63.5938) lr 2.0000e-03 eta 0:19:22
epoch [2/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 1.4668 (1.5670) acc 62.5000 (63.8750) lr 2.0000e-03 eta 0:18:25
epoch [2/200] batch [30/51] time 0.089 (0.105) data 0.000 (0.019) loss 1.8643 (1.5523) acc 43.7500 (63.3333) lr 2.0000e-03 eta 0:17:47
epoch [2/200] batch [35/51] time 0.086 (0.103) data 0.000 (0.016) loss 1.6611 (1.5437) acc 65.6250 (63.3929) lr 2.0000e-03 eta 0:17:19
epoch [2/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 1.3984 (1.5040) acc 59.3750 (63.6719) lr 2.0000e-03 eta 0:16:58
epoch [2/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.9531 (1.4704) acc 75.0000 (64.4444) lr 2.0000e-03 eta 0:16:40
epoch [2/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 1.3301 (1.4566) acc 65.6250 (64.9375) lr 2.0000e-03 eta 0:16:26
epoch [3/200] batch [5/51] time 0.087 (0.216) data 0.000 (0.128) loss 1.3740 (1.0687) acc 65.6250 (70.6250) lr 1.9999e-03 eta 0:36:24
epoch [3/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.064) loss 0.9990 (1.0792) acc 65.6250 (69.6875) lr 1.9999e-03 eta 0:25:31
epoch [3/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 1.2236 (1.1094) acc 62.5000 (69.1667) lr 1.9999e-03 eta 0:21:53
epoch [3/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 1.3818 (1.0719) acc 65.6250 (70.3125) lr 1.9999e-03 eta 0:20:03
epoch [3/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 1.4326 (1.1109) acc 65.6250 (70.7500) lr 1.9999e-03 eta 0:18:58
epoch [3/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.6045 (1.1117) acc 87.5000 (70.4167) lr 1.9999e-03 eta 0:18:14
epoch [3/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.9443 (1.1072) acc 71.8750 (70.6250) lr 1.9999e-03 eta 0:17:42
epoch [3/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 1.3262 (1.1072) acc 71.8750 (70.7812) lr 1.9999e-03 eta 0:17:17
epoch [3/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.8291 (1.0947) acc 75.0000 (70.8333) lr 1.9999e-03 eta 0:16:57
epoch [3/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 1.0889 (1.0843) acc 75.0000 (70.7500) lr 1.9999e-03 eta 0:16:41
epoch [4/200] batch [5/51] time 0.087 (0.219) data 0.000 (0.131) loss 0.6353 (0.7625) acc 81.2500 (76.8750) lr 1.9995e-03 eta 0:36:34
epoch [4/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.5586 (0.7883) acc 84.3750 (78.1250) lr 1.9995e-03 eta 0:25:30
epoch [4/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.044) loss 1.0889 (0.9023) acc 71.8750 (75.2083) lr 1.9995e-03 eta 0:21:48
epoch [4/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 1.3916 (0.9021) acc 62.5000 (75.1562) lr 1.9995e-03 eta 0:19:58
epoch [4/200] batch [25/51] time 0.088 (0.113) data 0.000 (0.027) loss 0.6890 (0.8825) acc 78.1250 (75.5000) lr 1.9995e-03 eta 0:18:52
epoch [4/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 1.5029 (0.9373) acc 65.6250 (73.9583) lr 1.9995e-03 eta 0:18:08
epoch [4/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 1.0811 (0.9321) acc 71.8750 (74.1071) lr 1.9995e-03 eta 0:17:37
epoch [4/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.8057 (0.9374) acc 78.1250 (73.8281) lr 1.9995e-03 eta 0:17:11
epoch [4/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.9146 (0.9340) acc 75.0000 (74.2361) lr 1.9995e-03 eta 0:16:51
epoch [4/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 1.2031 (0.9461) acc 59.3750 (73.5625) lr 1.9995e-03 eta 0:16:34
epoch [5/200] batch [5/51] time 0.089 (0.200) data 0.000 (0.112) loss 1.0596 (0.8338) acc 71.8750 (76.8750) lr 1.9989e-03 eta 0:33:14
epoch [5/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.9790 (0.8594) acc 75.0000 (76.8750) lr 1.9989e-03 eta 0:23:47
epoch [5/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 1.2539 (0.8670) acc 56.2500 (76.2500) lr 1.9989e-03 eta 0:20:39
epoch [5/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.028) loss 0.8149 (0.8469) acc 84.3750 (77.3438) lr 1.9989e-03 eta 0:19:04
epoch [5/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.4458 (0.8201) acc 90.6250 (78.3750) lr 1.9989e-03 eta 0:18:07
epoch [5/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.6968 (0.8159) acc 84.3750 (78.5417) lr 1.9989e-03 eta 0:17:29
epoch [5/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4189 (0.7884) acc 90.6250 (79.2857) lr 1.9989e-03 eta 0:17:02
epoch [5/200] batch [40/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.7671 (0.7780) acc 78.1250 (79.5312) lr 1.9989e-03 eta 0:16:40
epoch [5/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.7334 (0.7718) acc 68.7500 (79.5139) lr 1.9989e-03 eta 0:16:22
epoch [5/200] batch [50/51] time 0.087 (0.097) data 0.000 (0.011) loss 0.5669 (0.7767) acc 81.2500 (79.1875) lr 1.9989e-03 eta 0:16:09
epoch [6/200] batch [5/51] time 0.087 (0.209) data 0.000 (0.121) loss 0.5122 (0.6859) acc 90.6250 (81.2500) lr 1.9980e-03 eta 0:34:32
epoch [6/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.7910 (0.7435) acc 78.1250 (81.5625) lr 1.9980e-03 eta 0:24:25
epoch [6/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.041) loss 0.8994 (0.7236) acc 81.2500 (81.6667) lr 1.9980e-03 eta 0:21:00
epoch [6/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.8027 (0.7238) acc 78.1250 (81.5625) lr 1.9980e-03 eta 0:19:19
epoch [6/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 1.0645 (0.7564) acc 62.5000 (79.7500) lr 1.9980e-03 eta 0:18:18
epoch [6/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.020) loss 0.6758 (0.7284) acc 84.3750 (80.4167) lr 1.9980e-03 eta 0:17:37
epoch [6/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.7324 (0.7285) acc 84.3750 (80.3571) lr 1.9980e-03 eta 0:17:09
epoch [6/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.6108 (0.7050) acc 81.2500 (81.0156) lr 1.9980e-03 eta 0:16:46
epoch [6/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4795 (0.7012) acc 87.5000 (81.2500) lr 1.9980e-03 eta 0:16:28
epoch [6/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.5762 (0.6892) acc 78.1250 (81.3125) lr 1.9980e-03 eta 0:16:13
epoch [7/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.115) loss 0.3770 (0.7169) acc 90.6250 (85.6250) lr 1.9969e-03 eta 0:33:35
epoch [7/200] batch [10/51] time 0.086 (0.145) data 0.000 (0.058) loss 0.6284 (0.6685) acc 84.3750 (86.2500) lr 1.9969e-03 eta 0:23:55
epoch [7/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.5229 (0.6467) acc 93.7500 (85.4167) lr 1.9969e-03 eta 0:20:42
epoch [7/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.7144 (0.6582) acc 81.2500 (84.3750) lr 1.9969e-03 eta 0:19:04
epoch [7/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.6367 (0.6377) acc 84.3750 (85.3750) lr 1.9969e-03 eta 0:18:06
epoch [7/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.9243 (0.6295) acc 68.7500 (85.1042) lr 1.9969e-03 eta 0:17:28
epoch [7/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.5796 (0.6285) acc 84.3750 (84.7321) lr 1.9969e-03 eta 0:17:00
epoch [7/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.6489 (0.6271) acc 81.2500 (84.4531) lr 1.9969e-03 eta 0:16:38
epoch [7/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.6499 (0.6321) acc 75.0000 (84.0278) lr 1.9969e-03 eta 0:16:21
epoch [7/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.6670 (0.6419) acc 84.3750 (84.1250) lr 1.9969e-03 eta 0:16:07
epoch [8/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.115) loss 0.4431 (0.5187) acc 78.1250 (86.2500) lr 1.9956e-03 eta 0:33:17
epoch [8/200] batch [10/51] time 0.088 (0.145) data 0.000 (0.058) loss 0.3364 (0.6047) acc 93.7500 (85.6250) lr 1.9956e-03 eta 0:23:49
epoch [8/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.6279 (0.6177) acc 78.1250 (84.5833) lr 1.9956e-03 eta 0:20:37
epoch [8/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.3691 (0.6097) acc 90.6250 (84.5312) lr 1.9956e-03 eta 0:18:59
epoch [8/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.6655 (0.6368) acc 78.1250 (83.5000) lr 1.9956e-03 eta 0:18:00
epoch [8/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.4531 (0.6485) acc 90.6250 (83.2292) lr 1.9956e-03 eta 0:17:21
epoch [8/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.017) loss 0.6460 (0.6220) acc 81.2500 (84.1964) lr 1.9956e-03 eta 0:16:53
epoch [8/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.4944 (0.6453) acc 84.3750 (83.4375) lr 1.9956e-03 eta 0:16:31
epoch [8/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.8696 (0.6356) acc 84.3750 (83.7500) lr 1.9956e-03 eta 0:16:14
epoch [8/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.5312 (0.6189) acc 81.2500 (84.1250) lr 1.9956e-03 eta 0:16:00
epoch [9/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.124) loss 0.5566 (0.6975) acc 81.2500 (78.1250) lr 1.9940e-03 eta 0:34:28
epoch [9/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.3716 (0.6276) acc 87.5000 (82.5000) lr 1.9940e-03 eta 0:24:18
epoch [9/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.5215 (0.5899) acc 81.2500 (83.5417) lr 1.9940e-03 eta 0:20:55
epoch [9/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.8726 (0.5915) acc 81.2500 (84.0625) lr 1.9940e-03 eta 0:19:14
epoch [9/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.9219 (0.5938) acc 68.7500 (83.6250) lr 1.9940e-03 eta 0:18:11
epoch [9/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.6426 (0.5912) acc 78.1250 (84.0625) lr 1.9940e-03 eta 0:17:31
epoch [9/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.5098 (0.5967) acc 90.6250 (84.2857) lr 1.9940e-03 eta 0:17:01
epoch [9/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.7339 (0.5993) acc 81.2500 (83.9062) lr 1.9940e-03 eta 0:16:37
epoch [9/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.6821 (0.6023) acc 84.3750 (83.8194) lr 1.9940e-03 eta 0:16:19
epoch [9/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.5078 (0.5913) acc 81.2500 (84.0625) lr 1.9940e-03 eta 0:16:04
epoch [10/200] batch [5/51] time 0.087 (0.221) data 0.000 (0.134) loss 0.2034 (0.4138) acc 100.0000 (89.3750) lr 1.9921e-03 eta 0:35:54
epoch [10/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.7383 (0.5797) acc 81.2500 (85.3125) lr 1.9921e-03 eta 0:24:58
epoch [10/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.5044 (0.5500) acc 81.2500 (86.2500) lr 1.9921e-03 eta 0:21:18
epoch [10/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.034) loss 0.7915 (0.5816) acc 68.7500 (85.4688) lr 1.9921e-03 eta 0:19:29
epoch [10/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.5259 (0.5816) acc 81.2500 (85.3750) lr 1.9921e-03 eta 0:18:22
epoch [10/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.8218 (0.5959) acc 68.7500 (84.2708) lr 1.9921e-03 eta 0:17:39
epoch [10/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.5532 (0.5776) acc 93.7500 (85.1786) lr 1.9921e-03 eta 0:17:07
epoch [10/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.9121 (0.5751) acc 71.8750 (85.3125) lr 1.9921e-03 eta 0:16:43
epoch [10/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4077 (0.5724) acc 87.5000 (85.2083) lr 1.9921e-03 eta 0:16:23
epoch [10/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.6025 (0.5650) acc 78.1250 (84.9375) lr 1.9921e-03 eta 0:16:07
epoch [11/200] batch [5/51] time 0.087 (0.215) data 0.000 (0.127) loss 1.0068 (0.8028) acc 75.0000 (80.6250) lr 1.9900e-03 eta 0:34:41
epoch [11/200] batch [10/51] time 0.088 (0.151) data 0.000 (0.064) loss 0.5552 (0.5918) acc 87.5000 (85.9375) lr 1.9900e-03 eta 0:24:23
epoch [11/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.6987 (0.6398) acc 78.1250 (83.1250) lr 1.9900e-03 eta 0:20:56
epoch [11/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.9097 (0.6354) acc 71.8750 (83.2812) lr 1.9900e-03 eta 0:19:13
epoch [11/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.3066 (0.6162) acc 96.8750 (83.8750) lr 1.9900e-03 eta 0:18:10
epoch [11/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.021) loss 0.3784 (0.5982) acc 87.5000 (84.3750) lr 1.9900e-03 eta 0:17:28
epoch [11/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.018) loss 0.4854 (0.5777) acc 90.6250 (85.0893) lr 1.9900e-03 eta 0:16:58
epoch [11/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.6050 (0.5733) acc 75.0000 (85.3906) lr 1.9900e-03 eta 0:16:35
epoch [11/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4690 (0.5573) acc 84.3750 (85.6944) lr 1.9900e-03 eta 0:16:15
epoch [11/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3899 (0.5575) acc 90.6250 (85.7500) lr 1.9900e-03 eta 0:16:00
epoch [12/200] batch [5/51] time 0.088 (0.222) data 0.000 (0.135) loss 0.3914 (0.5408) acc 90.6250 (86.8750) lr 1.9877e-03 eta 0:35:39
epoch [12/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.067) loss 0.7539 (0.5428) acc 81.2500 (87.1875) lr 1.9877e-03 eta 0:24:49
epoch [12/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.5200 (0.5590) acc 81.2500 (86.4583) lr 1.9877e-03 eta 0:21:10
epoch [12/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.2476 (0.5329) acc 96.8750 (87.3438) lr 1.9877e-03 eta 0:19:21
epoch [12/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.5898 (0.5409) acc 84.3750 (86.6250) lr 1.9877e-03 eta 0:18:15
epoch [12/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.3464 (0.5204) acc 90.6250 (87.0833) lr 1.9877e-03 eta 0:17:31
epoch [12/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.6172 (0.5269) acc 84.3750 (86.9643) lr 1.9877e-03 eta 0:17:00
epoch [12/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.6992 (0.5215) acc 90.6250 (87.2656) lr 1.9877e-03 eta 0:16:35
epoch [12/200] batch [45/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.5771 (0.5210) acc 84.3750 (86.8056) lr 1.9877e-03 eta 0:16:15
epoch [12/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.5420 (0.5121) acc 81.2500 (86.8125) lr 1.9877e-03 eta 0:15:59
epoch [13/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.111) loss 0.5669 (0.4571) acc 84.3750 (88.1250) lr 1.9851e-03 eta 0:31:48
epoch [13/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.3333 (0.4551) acc 93.7500 (88.4375) lr 1.9851e-03 eta 0:22:49
epoch [13/200] batch [15/51] time 0.085 (0.124) data 0.000 (0.037) loss 0.2444 (0.4457) acc 100.0000 (89.5833) lr 1.9851e-03 eta 0:19:48
epoch [13/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.5786 (0.4828) acc 90.6250 (88.5938) lr 1.9851e-03 eta 0:18:18
epoch [13/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4094 (0.4763) acc 84.3750 (88.0000) lr 1.9851e-03 eta 0:17:24
epoch [13/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.5781 (0.4942) acc 81.2500 (87.2917) lr 1.9851e-03 eta 0:16:48
epoch [13/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.7925 (0.5077) acc 87.5000 (86.9643) lr 1.9851e-03 eta 0:16:22
epoch [13/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.7632 (0.5090) acc 78.1250 (87.1094) lr 1.9851e-03 eta 0:16:02
epoch [13/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.8779 (0.5140) acc 81.2500 (87.3611) lr 1.9851e-03 eta 0:15:45
epoch [13/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4910 (0.5091) acc 84.3750 (87.3125) lr 1.9851e-03 eta 0:15:32
epoch [14/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.129) loss 0.3730 (0.4561) acc 90.6250 (86.2500) lr 1.9823e-03 eta 0:34:25
epoch [14/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.5200 (0.4555) acc 84.3750 (88.1250) lr 1.9823e-03 eta 0:24:04
epoch [14/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.7012 (0.4709) acc 81.2500 (87.2917) lr 1.9823e-03 eta 0:20:37
epoch [14/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.4915 (0.4869) acc 90.6250 (87.3438) lr 1.9823e-03 eta 0:18:53
epoch [14/200] batch [25/51] time 0.088 (0.113) data 0.000 (0.026) loss 0.5859 (0.4875) acc 81.2500 (87.0000) lr 1.9823e-03 eta 0:17:51
epoch [14/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.022) loss 0.4241 (0.4881) acc 93.7500 (86.9792) lr 1.9823e-03 eta 0:17:11
epoch [14/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.019) loss 0.2264 (0.4721) acc 93.7500 (87.5000) lr 1.9823e-03 eta 0:16:42
epoch [14/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.5430 (0.4712) acc 84.3750 (87.5000) lr 1.9823e-03 eta 0:16:18
epoch [14/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.6909 (0.4697) acc 81.2500 (87.7083) lr 1.9823e-03 eta 0:15:59
epoch [14/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5435 (0.4816) acc 87.5000 (87.5000) lr 1.9823e-03 eta 0:15:44
epoch [15/200] batch [5/51] time 0.088 (0.200) data 0.000 (0.112) loss 0.6875 (0.6421) acc 81.2500 (79.3750) lr 1.9792e-03 eta 0:31:38
epoch [15/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.4448 (0.5291) acc 87.5000 (84.6875) lr 1.9792e-03 eta 0:22:41
epoch [15/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.037) loss 0.4395 (0.5912) acc 93.7500 (84.3750) lr 1.9792e-03 eta 0:19:41
epoch [15/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.5317 (0.5507) acc 78.1250 (85.0000) lr 1.9792e-03 eta 0:18:10
epoch [15/200] batch [25/51] time 0.089 (0.110) data 0.000 (0.023) loss 0.2275 (0.5106) acc 96.8750 (86.7500) lr 1.9792e-03 eta 0:17:16
epoch [15/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2375 (0.5040) acc 96.8750 (86.7708) lr 1.9792e-03 eta 0:16:40
epoch [15/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.5229 (0.4958) acc 90.6250 (87.1429) lr 1.9792e-03 eta 0:16:14
epoch [15/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.7886 (0.5097) acc 75.0000 (86.7188) lr 1.9792e-03 eta 0:15:54
epoch [15/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.5732 (0.5192) acc 87.5000 (86.4583) lr 1.9792e-03 eta 0:15:38
epoch [15/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.7188 (0.5225) acc 81.2500 (86.3750) lr 1.9792e-03 eta 0:15:24
epoch [16/200] batch [5/51] time 0.087 (0.218) data 0.000 (0.131) loss 0.5977 (0.4261) acc 84.3750 (86.8750) lr 1.9759e-03 eta 0:34:19
epoch [16/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.8481 (0.4534) acc 81.2500 (87.1875) lr 1.9759e-03 eta 0:23:57
epoch [16/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.2419 (0.5143) acc 93.7500 (86.2500) lr 1.9759e-03 eta 0:20:31
epoch [16/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.5400 (0.5464) acc 84.3750 (85.6250) lr 1.9759e-03 eta 0:18:46
epoch [16/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.5210 (0.5495) acc 90.6250 (86.0000) lr 1.9759e-03 eta 0:17:44
epoch [16/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3818 (0.5431) acc 90.6250 (86.2500) lr 1.9759e-03 eta 0:17:02
epoch [16/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4473 (0.5404) acc 84.3750 (86.1607) lr 1.9759e-03 eta 0:16:33
epoch [16/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.2372 (0.5262) acc 96.8750 (86.7969) lr 1.9759e-03 eta 0:16:09
epoch [16/200] batch [45/51] time 0.087 (0.101) data 0.000 (0.015) loss 0.4888 (0.5159) acc 87.5000 (87.1528) lr 1.9759e-03 eta 0:15:51
epoch [16/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5298 (0.5085) acc 87.5000 (87.3750) lr 1.9759e-03 eta 0:15:36
epoch [17/200] batch [5/51] time 0.087 (0.227) data 0.000 (0.140) loss 0.3367 (0.4915) acc 93.7500 (90.6250) lr 1.9724e-03 eta 0:35:25
epoch [17/200] batch [10/51] time 0.085 (0.156) data 0.000 (0.070) loss 0.7759 (0.5077) acc 81.2500 (87.8125) lr 1.9724e-03 eta 0:24:24
epoch [17/200] batch [15/51] time 0.086 (0.133) data 0.000 (0.047) loss 0.2156 (0.4686) acc 93.7500 (88.1250) lr 1.9724e-03 eta 0:20:43
epoch [17/200] batch [20/51] time 0.086 (0.121) data 0.000 (0.035) loss 0.6479 (0.4667) acc 81.2500 (87.9688) lr 1.9724e-03 eta 0:18:52
epoch [17/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.028) loss 0.3425 (0.4807) acc 90.6250 (87.1250) lr 1.9724e-03 eta 0:17:46
epoch [17/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.023) loss 0.4854 (0.4739) acc 90.6250 (87.7083) lr 1.9724e-03 eta 0:17:02
epoch [17/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.020) loss 0.4092 (0.4704) acc 90.6250 (88.2143) lr 1.9724e-03 eta 0:16:30
epoch [17/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.018) loss 0.3887 (0.4807) acc 87.5000 (87.9688) lr 1.9724e-03 eta 0:16:06
epoch [17/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.016) loss 0.4182 (0.4789) acc 90.6250 (87.9861) lr 1.9724e-03 eta 0:15:47
epoch [17/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.5439 (0.4782) acc 81.2500 (87.8125) lr 1.9724e-03 eta 0:15:31
epoch [18/200] batch [5/51] time 0.086 (0.222) data 0.000 (0.135) loss 0.8765 (0.5371) acc 78.1250 (85.0000) lr 1.9686e-03 eta 0:34:32
epoch [18/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.4302 (0.4469) acc 93.7500 (88.4375) lr 1.9686e-03 eta 0:24:01
epoch [18/200] batch [15/51] time 0.086 (0.132) data 0.000 (0.045) loss 0.4788 (0.4997) acc 87.5000 (86.8750) lr 1.9686e-03 eta 0:20:29
epoch [18/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.5444 (0.4902) acc 81.2500 (87.1875) lr 1.9686e-03 eta 0:18:42
epoch [18/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.5781 (0.4825) acc 78.1250 (87.1250) lr 1.9686e-03 eta 0:17:38
epoch [18/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.5732 (0.4878) acc 87.5000 (87.2917) lr 1.9686e-03 eta 0:16:55
epoch [18/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.2317 (0.4676) acc 96.8750 (87.8571) lr 1.9686e-03 eta 0:16:25
epoch [18/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.4360 (0.4688) acc 90.6250 (88.0469) lr 1.9686e-03 eta 0:16:01
epoch [18/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.6533 (0.4865) acc 81.2500 (87.2917) lr 1.9686e-03 eta 0:15:42
epoch [18/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2196 (0.4868) acc 100.0000 (87.3750) lr 1.9686e-03 eta 0:15:27
epoch [19/200] batch [5/51] time 0.087 (0.203) data 0.000 (0.115) loss 0.5054 (0.3864) acc 87.5000 (92.5000) lr 1.9646e-03 eta 0:31:26
epoch [19/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.3035 (0.3750) acc 96.8750 (91.8750) lr 1.9646e-03 eta 0:22:24
epoch [19/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.039) loss 0.4158 (0.3823) acc 93.7500 (91.6667) lr 1.9646e-03 eta 0:19:22
epoch [19/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.4297 (0.3854) acc 93.7500 (91.2500) lr 1.9646e-03 eta 0:17:52
epoch [19/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.5239 (0.3874) acc 87.5000 (91.2500) lr 1.9646e-03 eta 0:16:56
epoch [19/200] batch [30/51] time 0.085 (0.106) data 0.000 (0.019) loss 0.5371 (0.3981) acc 90.6250 (90.5208) lr 1.9646e-03 eta 0:16:20
epoch [19/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.017) loss 0.6797 (0.4222) acc 84.3750 (89.6429) lr 1.9646e-03 eta 0:15:53
epoch [19/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.5049 (0.4400) acc 84.3750 (89.2188) lr 1.9646e-03 eta 0:15:32
epoch [19/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.7661 (0.4386) acc 84.3750 (89.0972) lr 1.9646e-03 eta 0:15:16
epoch [19/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.3396 (0.4411) acc 87.5000 (88.9375) lr 1.9646e-03 eta 0:15:03
epoch [20/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.111) loss 0.3901 (0.4420) acc 93.7500 (88.7500) lr 1.9603e-03 eta 0:30:35
epoch [20/200] batch [10/51] time 0.086 (0.143) data 0.000 (0.055) loss 0.5425 (0.4319) acc 90.6250 (87.5000) lr 1.9603e-03 eta 0:21:56
epoch [20/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.3000 (0.4120) acc 93.7500 (89.3750) lr 1.9603e-03 eta 0:19:04
epoch [20/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.6240 (0.4317) acc 90.6250 (89.2188) lr 1.9603e-03 eta 0:17:37
epoch [20/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4526 (0.4424) acc 87.5000 (88.8750) lr 1.9603e-03 eta 0:16:45
epoch [20/200] batch [30/51] time 0.088 (0.105) data 0.000 (0.019) loss 0.4919 (0.4462) acc 87.5000 (88.9583) lr 1.9603e-03 eta 0:16:10
epoch [20/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3982 (0.4465) acc 87.5000 (89.0179) lr 1.9603e-03 eta 0:15:46
epoch [20/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.3115 (0.4421) acc 93.7500 (88.9844) lr 1.9603e-03 eta 0:15:26
epoch [20/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5918 (0.4469) acc 84.3750 (88.7500) lr 1.9603e-03 eta 0:15:10
epoch [20/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1422 (0.4471) acc 100.0000 (88.8750) lr 1.9603e-03 eta 0:14:57
epoch [21/200] batch [5/51] time 0.087 (0.206) data 0.000 (0.118) loss 0.4780 (0.4618) acc 84.3750 (88.7500) lr 1.9558e-03 eta 0:31:27
epoch [21/200] batch [10/51] time 0.089 (0.147) data 0.000 (0.059) loss 0.2820 (0.4904) acc 87.5000 (86.8750) lr 1.9558e-03 eta 0:22:25
epoch [21/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.4146 (0.4416) acc 90.6250 (88.9583) lr 1.9558e-03 eta 0:19:21
epoch [21/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.4871 (0.4497) acc 87.5000 (88.9062) lr 1.9558e-03 eta 0:17:50
epoch [21/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.5845 (0.4602) acc 87.5000 (88.7500) lr 1.9558e-03 eta 0:16:54
epoch [21/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.020) loss 0.2183 (0.4456) acc 96.8750 (89.0625) lr 1.9558e-03 eta 0:16:17
epoch [21/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.5796 (0.4480) acc 87.5000 (89.1071) lr 1.9558e-03 eta 0:15:51
epoch [21/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4988 (0.4450) acc 87.5000 (89.0625) lr 1.9558e-03 eta 0:15:30
epoch [21/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4805 (0.4458) acc 84.3750 (88.8889) lr 1.9558e-03 eta 0:15:14
epoch [21/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.6685 (0.4528) acc 75.0000 (88.5625) lr 1.9558e-03 eta 0:15:00
epoch [22/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.114) loss 0.1770 (0.3078) acc 96.8750 (91.8750) lr 1.9511e-03 eta 0:30:39
epoch [22/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.4238 (0.4016) acc 90.6250 (89.6875) lr 1.9511e-03 eta 0:21:53
epoch [22/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.3948 (0.4496) acc 87.5000 (87.7083) lr 1.9511e-03 eta 0:18:58
epoch [22/200] batch [20/51] time 0.089 (0.115) data 0.000 (0.029) loss 0.2355 (0.4126) acc 100.0000 (89.3750) lr 1.9511e-03 eta 0:17:32
epoch [22/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.5024 (0.4170) acc 84.3750 (89.1250) lr 1.9511e-03 eta 0:16:39
epoch [22/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.5396 (0.4349) acc 87.5000 (88.4375) lr 1.9511e-03 eta 0:16:04
epoch [22/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.017) loss 0.9253 (0.4463) acc 81.2500 (88.5714) lr 1.9511e-03 eta 0:15:39
epoch [22/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4182 (0.4489) acc 90.6250 (88.5156) lr 1.9511e-03 eta 0:15:19
epoch [22/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.6592 (0.4550) acc 84.3750 (88.4028) lr 1.9511e-03 eta 0:15:03
epoch [22/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2318 (0.4540) acc 93.7500 (88.4375) lr 1.9511e-03 eta 0:14:50
epoch [23/200] batch [5/51] time 0.087 (0.215) data 0.000 (0.128) loss 0.4412 (0.4572) acc 84.3750 (87.5000) lr 1.9461e-03 eta 0:32:29
epoch [23/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.5654 (0.5018) acc 87.5000 (87.8125) lr 1.9461e-03 eta 0:22:49
epoch [23/200] batch [15/51] time 0.086 (0.130) data 0.000 (0.043) loss 0.5239 (0.4682) acc 90.6250 (88.5417) lr 1.9461e-03 eta 0:19:33
epoch [23/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.6157 (0.4725) acc 81.2500 (88.5938) lr 1.9461e-03 eta 0:17:56
epoch [23/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.026) loss 0.3667 (0.4783) acc 90.6250 (88.7500) lr 1.9461e-03 eta 0:16:57
epoch [23/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.021) loss 0.5630 (0.4741) acc 78.1250 (88.4375) lr 1.9461e-03 eta 0:16:17
epoch [23/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.3149 (0.4826) acc 87.5000 (88.2143) lr 1.9461e-03 eta 0:15:49
epoch [23/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4646 (0.4774) acc 87.5000 (88.2812) lr 1.9461e-03 eta 0:15:27
epoch [23/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5625 (0.4742) acc 90.6250 (88.2639) lr 1.9461e-03 eta 0:15:10
epoch [23/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.6509 (0.4743) acc 78.1250 (87.9375) lr 1.9461e-03 eta 0:14:56
epoch [24/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.5884 (0.5158) acc 81.2500 (89.3750) lr 1.9409e-03 eta 0:29:45
epoch [24/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.2791 (0.4437) acc 93.7500 (89.3750) lr 1.9409e-03 eta 0:21:24
epoch [24/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.2340 (0.4505) acc 93.7500 (88.9583) lr 1.9409e-03 eta 0:18:34
epoch [24/200] batch [20/51] time 0.086 (0.114) data 0.000 (0.028) loss 0.5938 (0.4497) acc 84.3750 (88.5938) lr 1.9409e-03 eta 0:17:10
epoch [24/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4736 (0.4328) acc 84.3750 (89.0000) lr 1.9409e-03 eta 0:16:19
epoch [24/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.3164 (0.4229) acc 100.0000 (89.6875) lr 1.9409e-03 eta 0:15:45
epoch [24/200] batch [35/51] time 0.087 (0.102) data 0.000 (0.016) loss 0.2747 (0.4158) acc 96.8750 (90.0000) lr 1.9409e-03 eta 0:15:21
epoch [24/200] batch [40/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.3423 (0.4237) acc 90.6250 (89.2188) lr 1.9409e-03 eta 0:15:01
epoch [24/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.2974 (0.4144) acc 90.6250 (89.3750) lr 1.9409e-03 eta 0:14:46
epoch [24/200] batch [50/51] time 0.085 (0.097) data 0.000 (0.011) loss 0.3953 (0.4110) acc 93.7500 (89.4375) lr 1.9409e-03 eta 0:14:34
epoch [25/200] batch [5/51] time 0.088 (0.206) data 0.000 (0.118) loss 0.2361 (0.2974) acc 93.7500 (93.1250) lr 1.9354e-03 eta 0:30:47
epoch [25/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.2673 (0.3673) acc 96.8750 (90.6250) lr 1.9354e-03 eta 0:21:56
epoch [25/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.2145 (0.3905) acc 93.7500 (89.1667) lr 1.9354e-03 eta 0:18:57
epoch [25/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2671 (0.3958) acc 93.7500 (89.5312) lr 1.9354e-03 eta 0:17:27
epoch [25/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.6621 (0.4054) acc 84.3750 (89.5000) lr 1.9354e-03 eta 0:16:33
epoch [25/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.5933 (0.4146) acc 87.5000 (89.4792) lr 1.9354e-03 eta 0:15:57
epoch [25/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.2336 (0.3968) acc 96.8750 (89.8214) lr 1.9354e-03 eta 0:15:31
epoch [25/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4807 (0.4120) acc 87.5000 (89.2969) lr 1.9354e-03 eta 0:15:10
epoch [25/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4990 (0.4254) acc 81.2500 (89.0278) lr 1.9354e-03 eta 0:14:54
epoch [25/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2427 (0.4203) acc 90.6250 (89.3750) lr 1.9354e-03 eta 0:14:41
epoch [26/200] batch [5/51] time 0.087 (0.216) data 0.000 (0.128) loss 0.5713 (0.4741) acc 81.2500 (86.8750) lr 1.9298e-03 eta 0:32:03
epoch [26/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.3948 (0.3861) acc 87.5000 (89.6875) lr 1.9298e-03 eta 0:22:29
epoch [26/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.4429 (0.3995) acc 87.5000 (90.4167) lr 1.9298e-03 eta 0:19:15
epoch [26/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.3147 (0.4073) acc 90.6250 (90.6250) lr 1.9298e-03 eta 0:17:40
epoch [26/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.3149 (0.4278) acc 96.8750 (90.3750) lr 1.9298e-03 eta 0:16:42
epoch [26/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.022) loss 0.4795 (0.4430) acc 87.5000 (89.7917) lr 1.9298e-03 eta 0:16:03
epoch [26/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.8042 (0.4545) acc 78.1250 (89.1071) lr 1.9298e-03 eta 0:15:36
epoch [26/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.6313 (0.4486) acc 84.3750 (89.2188) lr 1.9298e-03 eta 0:15:14
epoch [26/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3521 (0.4450) acc 90.6250 (89.3056) lr 1.9298e-03 eta 0:14:56
epoch [26/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3464 (0.4294) acc 90.6250 (89.6250) lr 1.9298e-03 eta 0:14:42
epoch [27/200] batch [5/51] time 0.088 (0.220) data 0.000 (0.133) loss 0.1929 (0.4117) acc 93.7500 (91.2500) lr 1.9239e-03 eta 0:32:33
epoch [27/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.066) loss 0.7900 (0.4917) acc 84.3750 (89.3750) lr 1.9239e-03 eta 0:22:41
epoch [27/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.2737 (0.4300) acc 90.6250 (90.4167) lr 1.9239e-03 eta 0:19:24
epoch [27/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.4421 (0.4333) acc 87.5000 (89.6875) lr 1.9239e-03 eta 0:17:44
epoch [27/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3657 (0.4195) acc 93.7500 (90.1250) lr 1.9239e-03 eta 0:16:45
epoch [27/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3481 (0.4126) acc 96.8750 (90.3125) lr 1.9239e-03 eta 0:16:05
epoch [27/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.3018 (0.4205) acc 90.6250 (90.0893) lr 1.9239e-03 eta 0:15:36
epoch [27/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.3403 (0.4171) acc 90.6250 (89.7656) lr 1.9239e-03 eta 0:15:13
epoch [27/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.5181 (0.4226) acc 78.1250 (89.3056) lr 1.9239e-03 eta 0:14:55
epoch [27/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.7256 (0.4191) acc 84.3750 (89.3750) lr 1.9239e-03 eta 0:14:41
epoch [28/200] batch [5/51] time 0.088 (0.200) data 0.001 (0.112) loss 0.3809 (0.3879) acc 90.6250 (89.3750) lr 1.9178e-03 eta 0:29:22
epoch [28/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.2815 (0.3762) acc 93.7500 (90.0000) lr 1.9178e-03 eta 0:21:05
epoch [28/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.6416 (0.3779) acc 81.2500 (89.3750) lr 1.9178e-03 eta 0:18:17
epoch [28/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3469 (0.3844) acc 90.6250 (89.2188) lr 1.9178e-03 eta 0:16:54
epoch [28/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3870 (0.3949) acc 90.6250 (89.1250) lr 1.9178e-03 eta 0:16:04
epoch [28/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3132 (0.3855) acc 96.8750 (89.5833) lr 1.9178e-03 eta 0:15:31
epoch [28/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.6982 (0.3922) acc 84.3750 (89.1964) lr 1.9178e-03 eta 0:15:07
epoch [28/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3838 (0.3925) acc 84.3750 (89.3750) lr 1.9178e-03 eta 0:14:48
epoch [28/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.5078 (0.3879) acc 90.6250 (89.4444) lr 1.9178e-03 eta 0:14:32
epoch [28/200] batch [50/51] time 0.087 (0.098) data 0.000 (0.011) loss 0.3779 (0.3992) acc 84.3750 (89.1875) lr 1.9178e-03 eta 0:14:20
epoch [29/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.123) loss 0.2452 (0.3456) acc 90.6250 (91.2500) lr 1.9114e-03 eta 0:30:50
epoch [29/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.3042 (0.4307) acc 96.8750 (90.9375) lr 1.9114e-03 eta 0:21:44
epoch [29/200] batch [15/51] time 0.088 (0.128) data 0.000 (0.041) loss 0.6055 (0.4145) acc 84.3750 (90.6250) lr 1.9114e-03 eta 0:18:44
epoch [29/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.3298 (0.4083) acc 90.6250 (90.6250) lr 1.9114e-03 eta 0:17:13
epoch [29/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2830 (0.4011) acc 90.6250 (90.2500) lr 1.9114e-03 eta 0:16:19
epoch [29/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.021) loss 0.2573 (0.3738) acc 93.7500 (90.7292) lr 1.9114e-03 eta 0:15:42
epoch [29/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.3286 (0.3826) acc 90.6250 (90.3571) lr 1.9114e-03 eta 0:15:16
epoch [29/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.6362 (0.3951) acc 87.5000 (90.1562) lr 1.9114e-03 eta 0:14:55
epoch [29/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2830 (0.3869) acc 96.8750 (90.6250) lr 1.9114e-03 eta 0:14:38
epoch [29/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3933 (0.3897) acc 87.5000 (90.5000) lr 1.9114e-03 eta 0:14:25
epoch [30/200] batch [5/51] time 0.089 (0.202) data 0.000 (0.114) loss 0.3018 (0.4792) acc 93.7500 (88.7500) lr 1.9048e-03 eta 0:29:23
epoch [30/200] batch [10/51] time 0.086 (0.145) data 0.000 (0.057) loss 0.4026 (0.4077) acc 93.7500 (90.0000) lr 1.9048e-03 eta 0:20:59
epoch [30/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.7065 (0.4125) acc 87.5000 (89.5833) lr 1.9048e-03 eta 0:18:11
epoch [30/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2839 (0.4108) acc 96.8750 (89.3750) lr 1.9048e-03 eta 0:16:47
epoch [30/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.5439 (0.3991) acc 87.5000 (89.8750) lr 1.9048e-03 eta 0:15:57
epoch [30/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4248 (0.3927) acc 90.6250 (90.2083) lr 1.9048e-03 eta 0:15:23
epoch [30/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.016) loss 0.4597 (0.4227) acc 84.3750 (89.0179) lr 1.9048e-03 eta 0:15:00
epoch [30/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2448 (0.4177) acc 93.7500 (89.4531) lr 1.9048e-03 eta 0:14:40
epoch [30/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3613 (0.4108) acc 90.6250 (89.5833) lr 1.9048e-03 eta 0:14:24
epoch [30/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.5010 (0.4057) acc 84.3750 (89.5625) lr 1.9048e-03 eta 0:14:12
epoch [31/200] batch [5/51] time 0.088 (0.228) data 0.000 (0.141) loss 0.3379 (0.5977) acc 90.6250 (86.2500) lr 1.8980e-03 eta 0:32:59
epoch [31/200] batch [10/51] time 0.087 (0.158) data 0.000 (0.071) loss 0.3376 (0.4969) acc 93.7500 (88.1250) lr 1.8980e-03 eta 0:22:46
epoch [31/200] batch [15/51] time 0.087 (0.134) data 0.000 (0.047) loss 0.2273 (0.4958) acc 93.7500 (88.3333) lr 1.8980e-03 eta 0:19:20
epoch [31/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.4194 (0.4771) acc 90.6250 (88.9062) lr 1.8980e-03 eta 0:17:37
epoch [31/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.0909 (0.4369) acc 100.0000 (90.1250) lr 1.8980e-03 eta 0:16:35
epoch [31/200] batch [30/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.3667 (0.4239) acc 93.7500 (90.2083) lr 1.8980e-03 eta 0:15:55
epoch [31/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4355 (0.4293) acc 87.5000 (89.8214) lr 1.8980e-03 eta 0:15:25
epoch [31/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.6431 (0.4276) acc 81.2500 (89.7656) lr 1.8980e-03 eta 0:15:01
epoch [31/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.5640 (0.4201) acc 87.5000 (89.8611) lr 1.8980e-03 eta 0:14:43
epoch [31/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3562 (0.4135) acc 93.7500 (90.2500) lr 1.8980e-03 eta 0:14:28
epoch [32/200] batch [5/51] time 0.087 (0.207) data 0.000 (0.118) loss 0.2297 (0.3695) acc 96.8750 (90.0000) lr 1.8910e-03 eta 0:29:40
epoch [32/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.2849 (0.3607) acc 93.7500 (90.6250) lr 1.8910e-03 eta 0:21:05
epoch [32/200] batch [15/51] time 0.088 (0.127) data 0.000 (0.040) loss 0.3999 (0.3502) acc 96.8750 (91.8750) lr 1.8910e-03 eta 0:18:12
epoch [32/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.4714 (0.3658) acc 90.6250 (91.5625) lr 1.8910e-03 eta 0:16:46
epoch [32/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.3250 (0.3788) acc 96.8750 (91.2500) lr 1.8910e-03 eta 0:15:56
epoch [32/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2988 (0.3736) acc 90.6250 (91.1458) lr 1.8910e-03 eta 0:15:21
epoch [32/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.4927 (0.3837) acc 93.7500 (90.8036) lr 1.8910e-03 eta 0:14:56
epoch [32/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4724 (0.4072) acc 84.3750 (90.1562) lr 1.8910e-03 eta 0:14:36
epoch [32/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5420 (0.4009) acc 84.3750 (90.2083) lr 1.8910e-03 eta 0:14:21
epoch [32/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3616 (0.3974) acc 90.6250 (90.3125) lr 1.8910e-03 eta 0:14:08
epoch [33/200] batch [5/51] time 0.090 (0.215) data 0.000 (0.126) loss 0.3594 (0.2757) acc 90.6250 (94.3750) lr 1.8838e-03 eta 0:30:44
epoch [33/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.063) loss 0.1808 (0.3627) acc 96.8750 (91.8750) lr 1.8838e-03 eta 0:21:36
epoch [33/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.042) loss 0.2311 (0.3776) acc 90.6250 (90.6250) lr 1.8838e-03 eta 0:18:33
epoch [33/200] batch [20/51] time 0.088 (0.120) data 0.000 (0.032) loss 0.4490 (0.3778) acc 90.6250 (90.6250) lr 1.8838e-03 eta 0:17:01
epoch [33/200] batch [25/51] time 0.088 (0.113) data 0.000 (0.025) loss 0.3997 (0.3891) acc 87.5000 (90.2500) lr 1.8838e-03 eta 0:16:06
epoch [33/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.021) loss 0.5903 (0.4106) acc 81.2500 (89.4792) lr 1.8838e-03 eta 0:15:28
epoch [33/200] batch [35/51] time 0.085 (0.106) data 0.000 (0.018) loss 0.3218 (0.4122) acc 90.6250 (89.7321) lr 1.8838e-03 eta 0:15:00
epoch [33/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1832 (0.4026) acc 90.6250 (90.0781) lr 1.8838e-03 eta 0:14:38
epoch [33/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.6763 (0.4089) acc 81.2500 (89.7917) lr 1.8838e-03 eta 0:14:21
epoch [33/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.8823 (0.4180) acc 78.1250 (89.6250) lr 1.8838e-03 eta 0:14:07
epoch [34/200] batch [5/51] time 0.087 (0.209) data 0.000 (0.121) loss 0.4333 (0.3249) acc 90.6250 (91.8750) lr 1.8763e-03 eta 0:29:38
epoch [34/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.1948 (0.3644) acc 93.7500 (92.1875) lr 1.8763e-03 eta 0:20:58
epoch [34/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.4785 (0.3795) acc 87.5000 (90.8333) lr 1.8763e-03 eta 0:18:05
epoch [34/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.030) loss 0.2356 (0.3935) acc 96.8750 (90.1562) lr 1.8763e-03 eta 0:16:38
epoch [34/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.024) loss 0.4087 (0.3958) acc 84.3750 (90.1250) lr 1.8763e-03 eta 0:15:47
epoch [34/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.020) loss 0.5923 (0.4078) acc 84.3750 (89.6875) lr 1.8763e-03 eta 0:15:12
epoch [34/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.7881 (0.4066) acc 78.1250 (89.6429) lr 1.8763e-03 eta 0:14:48
epoch [34/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.7046 (0.3950) acc 84.3750 (90.3125) lr 1.8763e-03 eta 0:14:28
epoch [34/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5288 (0.4060) acc 87.5000 (89.8611) lr 1.8763e-03 eta 0:14:12
epoch [34/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3967 (0.4131) acc 93.7500 (89.6875) lr 1.8763e-03 eta 0:13:59
epoch [35/200] batch [5/51] time 0.089 (0.206) data 0.000 (0.117) loss 0.4426 (0.2832) acc 87.5000 (93.7500) lr 1.8686e-03 eta 0:29:00
epoch [35/200] batch [10/51] time 0.088 (0.147) data 0.000 (0.059) loss 0.5215 (0.3287) acc 78.1250 (91.8750) lr 1.8686e-03 eta 0:20:40
epoch [35/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.2947 (0.3375) acc 93.7500 (91.2500) lr 1.8686e-03 eta 0:17:52
epoch [35/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.029) loss 0.3137 (0.3505) acc 90.6250 (90.1562) lr 1.8686e-03 eta 0:16:27
epoch [35/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.2382 (0.3588) acc 93.7500 (90.2500) lr 1.8686e-03 eta 0:15:37
epoch [35/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2052 (0.3811) acc 93.7500 (89.6875) lr 1.8686e-03 eta 0:15:03
epoch [35/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.5596 (0.4039) acc 81.2500 (89.2857) lr 1.8686e-03 eta 0:14:39
epoch [35/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2683 (0.4038) acc 93.7500 (89.6094) lr 1.8686e-03 eta 0:14:19
epoch [35/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3586 (0.3941) acc 87.5000 (89.8611) lr 1.8686e-03 eta 0:14:04
epoch [35/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5205 (0.3985) acc 87.5000 (89.8125) lr 1.8686e-03 eta 0:13:51
epoch [36/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.111) loss 0.2448 (0.4946) acc 96.8750 (89.3750) lr 1.8607e-03 eta 0:27:56
epoch [36/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.5630 (0.4675) acc 78.1250 (88.4375) lr 1.8607e-03 eta 0:20:04
epoch [36/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.037) loss 0.2302 (0.4364) acc 100.0000 (89.3750) lr 1.8607e-03 eta 0:17:26
epoch [36/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.6167 (0.4367) acc 84.3750 (89.0625) lr 1.8607e-03 eta 0:16:07
epoch [36/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.6284 (0.4318) acc 81.2500 (89.0000) lr 1.8607e-03 eta 0:15:18
epoch [36/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.6045 (0.4182) acc 90.6250 (89.7917) lr 1.8607e-03 eta 0:14:46
epoch [36/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4519 (0.4356) acc 84.3750 (89.0179) lr 1.8607e-03 eta 0:14:23
epoch [36/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1929 (0.4345) acc 96.8750 (89.1406) lr 1.8607e-03 eta 0:14:05
epoch [36/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3257 (0.4316) acc 90.6250 (89.0278) lr 1.8607e-03 eta 0:13:50
epoch [36/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3809 (0.4270) acc 87.5000 (89.1250) lr 1.8607e-03 eta 0:13:38
epoch [37/200] batch [5/51] time 0.086 (0.218) data 0.000 (0.131) loss 0.2133 (0.2975) acc 90.6250 (93.1250) lr 1.8526e-03 eta 0:30:23
epoch [37/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.2471 (0.3025) acc 93.7500 (93.4375) lr 1.8526e-03 eta 0:21:14
epoch [37/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.4690 (0.3019) acc 84.3750 (93.3333) lr 1.8526e-03 eta 0:18:09
epoch [37/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.1903 (0.3034) acc 90.6250 (92.9688) lr 1.8526e-03 eta 0:16:38
epoch [37/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.3867 (0.3480) acc 87.5000 (91.3750) lr 1.8526e-03 eta 0:15:42
epoch [37/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.5146 (0.3511) acc 90.6250 (91.2500) lr 1.8526e-03 eta 0:15:04
epoch [37/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.2910 (0.3496) acc 87.5000 (91.0714) lr 1.8526e-03 eta 0:14:38
epoch [37/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.4060 (0.3507) acc 90.6250 (91.0938) lr 1.8526e-03 eta 0:14:17
epoch [37/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3132 (0.3491) acc 96.8750 (91.1806) lr 1.8526e-03 eta 0:14:00
epoch [37/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3494 (0.3719) acc 93.7500 (90.7500) lr 1.8526e-03 eta 0:13:47
epoch [38/200] batch [5/51] time 0.086 (0.222) data 0.000 (0.135) loss 0.3540 (0.3096) acc 93.7500 (93.1250) lr 1.8443e-03 eta 0:30:42
epoch [38/200] batch [10/51] time 0.086 (0.154) data 0.000 (0.068) loss 0.3875 (0.3824) acc 87.5000 (91.2500) lr 1.8443e-03 eta 0:21:20
epoch [38/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.3748 (0.3795) acc 87.5000 (91.0417) lr 1.8443e-03 eta 0:18:14
epoch [38/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.034) loss 0.4265 (0.3739) acc 93.7500 (91.7188) lr 1.8443e-03 eta 0:16:39
epoch [38/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.1871 (0.3780) acc 96.8750 (91.6250) lr 1.8443e-03 eta 0:15:42
epoch [38/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.3467 (0.3866) acc 90.6250 (91.0417) lr 1.8443e-03 eta 0:15:04
epoch [38/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.2913 (0.3839) acc 93.7500 (90.9821) lr 1.8443e-03 eta 0:14:37
epoch [38/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.5068 (0.3897) acc 81.2500 (90.5469) lr 1.8443e-03 eta 0:14:16
epoch [38/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2917 (0.3819) acc 93.7500 (91.0417) lr 1.8443e-03 eta 0:13:59
epoch [38/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1829 (0.3837) acc 100.0000 (91.0000) lr 1.8443e-03 eta 0:13:45
epoch [39/200] batch [5/51] time 0.088 (0.198) data 0.000 (0.110) loss 0.2433 (0.5346) acc 96.8750 (86.8750) lr 1.8358e-03 eta 0:27:12
epoch [39/200] batch [10/51] time 0.088 (0.142) data 0.000 (0.055) loss 0.4680 (0.4629) acc 87.5000 (89.0625) lr 1.8358e-03 eta 0:19:34
epoch [39/200] batch [15/51] time 0.088 (0.124) data 0.000 (0.037) loss 0.4832 (0.4658) acc 90.6250 (88.1250) lr 1.8358e-03 eta 0:17:03
epoch [39/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.1028 (0.4172) acc 100.0000 (89.6875) lr 1.8358e-03 eta 0:15:46
epoch [39/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2976 (0.4035) acc 93.7500 (90.2500) lr 1.8358e-03 eta 0:15:00
epoch [39/200] batch [30/51] time 0.089 (0.106) data 0.000 (0.019) loss 0.3838 (0.3949) acc 90.6250 (90.3125) lr 1.8358e-03 eta 0:14:30
epoch [39/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.6870 (0.3957) acc 87.5000 (90.4464) lr 1.8358e-03 eta 0:14:08
epoch [39/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1255 (0.3842) acc 100.0000 (90.7812) lr 1.8358e-03 eta 0:13:50
epoch [39/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3669 (0.3821) acc 93.7500 (90.9722) lr 1.8358e-03 eta 0:13:35
epoch [39/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2634 (0.3882) acc 93.7500 (90.6250) lr 1.8358e-03 eta 0:13:24
epoch [40/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.2676 (0.3124) acc 96.8750 (94.3750) lr 1.8271e-03 eta 0:27:31
epoch [40/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.1343 (0.3529) acc 96.8750 (92.8125) lr 1.8271e-03 eta 0:19:43
epoch [40/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.5342 (0.3654) acc 87.5000 (92.7083) lr 1.8271e-03 eta 0:17:06
epoch [40/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.3928 (0.3632) acc 90.6250 (92.5000) lr 1.8271e-03 eta 0:15:47
epoch [40/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.5410 (0.3742) acc 81.2500 (91.3750) lr 1.8271e-03 eta 0:14:59
epoch [40/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4873 (0.3765) acc 87.5000 (91.0417) lr 1.8271e-03 eta 0:14:27
epoch [40/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.3411 (0.3626) acc 96.8750 (91.6071) lr 1.8271e-03 eta 0:14:04
epoch [40/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2273 (0.3773) acc 96.8750 (90.9375) lr 1.8271e-03 eta 0:13:46
epoch [40/200] batch [45/51] time 0.087 (0.100) data 0.000 (0.013) loss 0.6436 (0.3930) acc 81.2500 (90.1389) lr 1.8271e-03 eta 0:13:32
epoch [40/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4668 (0.3925) acc 84.3750 (90.1250) lr 1.8271e-03 eta 0:13:21
epoch [41/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.3982 (0.3709) acc 93.7500 (91.8750) lr 1.8181e-03 eta 0:27:17
epoch [41/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.5625 (0.3537) acc 87.5000 (91.5625) lr 1.8181e-03 eta 0:19:32
epoch [41/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.2705 (0.3365) acc 90.6250 (92.0833) lr 1.8181e-03 eta 0:16:56
epoch [41/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.4497 (0.3608) acc 93.7500 (91.7188) lr 1.8181e-03 eta 0:15:39
epoch [41/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3843 (0.3572) acc 90.6250 (91.6250) lr 1.8181e-03 eta 0:14:53
epoch [41/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2190 (0.3439) acc 96.8750 (91.9792) lr 1.8181e-03 eta 0:14:22
epoch [41/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.5376 (0.3420) acc 84.3750 (91.9643) lr 1.8181e-03 eta 0:14:00
epoch [41/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4556 (0.3457) acc 90.6250 (92.0312) lr 1.8181e-03 eta 0:13:42
epoch [41/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5386 (0.3444) acc 87.5000 (92.0139) lr 1.8181e-03 eta 0:13:28
epoch [41/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1998 (0.3434) acc 96.8750 (92.1250) lr 1.8181e-03 eta 0:13:16
epoch [42/200] batch [5/51] time 0.088 (0.209) data 0.000 (0.120) loss 0.2119 (0.2770) acc 96.8750 (94.3750) lr 1.8090e-03 eta 0:28:11
epoch [42/200] batch [10/51] time 0.088 (0.148) data 0.000 (0.060) loss 0.1749 (0.3177) acc 100.0000 (92.5000) lr 1.8090e-03 eta 0:19:59
epoch [42/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.040) loss 0.5879 (0.3413) acc 81.2500 (91.2500) lr 1.8090e-03 eta 0:17:14
epoch [42/200] batch [20/51] time 0.088 (0.118) data 0.000 (0.030) loss 0.2272 (0.3377) acc 90.6250 (91.2500) lr 1.8090e-03 eta 0:15:51
epoch [42/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.024) loss 0.6313 (0.3446) acc 87.5000 (91.0000) lr 1.8090e-03 eta 0:15:02
epoch [42/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.020) loss 0.3643 (0.3718) acc 90.6250 (90.3125) lr 1.8090e-03 eta 0:14:29
epoch [42/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.017) loss 0.7500 (0.3934) acc 84.3750 (89.8214) lr 1.8090e-03 eta 0:14:06
epoch [42/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.015) loss 0.5454 (0.4081) acc 84.3750 (89.5312) lr 1.8090e-03 eta 0:13:47
epoch [42/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5947 (0.4148) acc 81.2500 (89.1667) lr 1.8090e-03 eta 0:13:32
epoch [42/200] batch [50/51] time 0.087 (0.099) data 0.000 (0.012) loss 0.3872 (0.4129) acc 87.5000 (89.0625) lr 1.8090e-03 eta 0:13:19
epoch [43/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.3413 (0.3505) acc 90.6250 (91.2500) lr 1.7997e-03 eta 0:27:21
epoch [43/200] batch [10/51] time 0.088 (0.146) data 0.000 (0.058) loss 0.3909 (0.3325) acc 93.7500 (92.8125) lr 1.7997e-03 eta 0:19:31
epoch [43/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.039) loss 0.5425 (0.3308) acc 75.0000 (92.0833) lr 1.7997e-03 eta 0:16:53
epoch [43/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.5547 (0.4014) acc 90.6250 (90.1562) lr 1.7997e-03 eta 0:15:33
epoch [43/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2386 (0.3759) acc 93.7500 (90.7500) lr 1.7997e-03 eta 0:14:46
epoch [43/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4219 (0.3787) acc 87.5000 (90.4167) lr 1.7997e-03 eta 0:14:13
epoch [43/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.5063 (0.3812) acc 87.5000 (90.3571) lr 1.7997e-03 eta 0:13:51
epoch [43/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2883 (0.3875) acc 96.8750 (90.1562) lr 1.7997e-03 eta 0:13:33
epoch [43/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4880 (0.3894) acc 87.5000 (90.1389) lr 1.7997e-03 eta 0:13:18
epoch [43/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3521 (0.3905) acc 87.5000 (89.9375) lr 1.7997e-03 eta 0:13:07
epoch [44/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.4150 (0.4324) acc 90.6250 (90.6250) lr 1.7902e-03 eta 0:26:38
epoch [44/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.056) loss 0.4207 (0.3491) acc 90.6250 (91.2500) lr 1.7902e-03 eta 0:19:06
epoch [44/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.038) loss 0.1893 (0.3791) acc 93.7500 (90.2083) lr 1.7902e-03 eta 0:16:34
epoch [44/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3308 (0.3923) acc 90.6250 (89.5312) lr 1.7902e-03 eta 0:15:18
epoch [44/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2344 (0.3735) acc 96.8750 (89.8750) lr 1.7902e-03 eta 0:14:35
epoch [44/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.6509 (0.3722) acc 81.2500 (90.1042) lr 1.7902e-03 eta 0:14:04
epoch [44/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3984 (0.3799) acc 90.6250 (89.6429) lr 1.7902e-03 eta 0:13:42
epoch [44/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.6860 (0.3887) acc 84.3750 (89.6875) lr 1.7902e-03 eta 0:13:25
epoch [44/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4768 (0.3851) acc 84.3750 (89.7917) lr 1.7902e-03 eta 0:13:11
epoch [44/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1307 (0.3772) acc 96.8750 (90.1875) lr 1.7902e-03 eta 0:13:00
epoch [45/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.5303 (0.4795) acc 93.7500 (89.3750) lr 1.7804e-03 eta 0:27:04
epoch [45/200] batch [10/51] time 0.086 (0.146) data 0.000 (0.058) loss 0.5454 (0.4487) acc 87.5000 (90.3125) lr 1.7804e-03 eta 0:19:16
epoch [45/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.3303 (0.4399) acc 87.5000 (89.1667) lr 1.7804e-03 eta 0:16:40
epoch [45/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.5728 (0.4435) acc 84.3750 (88.4375) lr 1.7804e-03 eta 0:15:22
epoch [45/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3259 (0.4198) acc 90.6250 (89.1250) lr 1.7804e-03 eta 0:14:35
epoch [45/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.3147 (0.4048) acc 90.6250 (89.5833) lr 1.7804e-03 eta 0:14:04
epoch [45/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2954 (0.4047) acc 93.7500 (89.5536) lr 1.7804e-03 eta 0:13:41
epoch [45/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2871 (0.3971) acc 93.7500 (90.0000) lr 1.7804e-03 eta 0:13:23
epoch [45/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3662 (0.3938) acc 93.7500 (90.3472) lr 1.7804e-03 eta 0:13:09
epoch [45/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3340 (0.3868) acc 93.7500 (90.7500) lr 1.7804e-03 eta 0:12:57
epoch [46/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.134) loss 0.4719 (0.3220) acc 87.5000 (93.7500) lr 1.7705e-03 eta 0:29:11
epoch [46/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.4758 (0.3229) acc 84.3750 (92.8125) lr 1.7705e-03 eta 0:20:18
epoch [46/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.4966 (0.3757) acc 87.5000 (91.4583) lr 1.7705e-03 eta 0:17:20
epoch [46/200] batch [20/51] time 0.086 (0.121) data 0.000 (0.034) loss 0.4021 (0.3903) acc 93.7500 (91.0938) lr 1.7705e-03 eta 0:15:50
epoch [46/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.1821 (0.3696) acc 96.8750 (91.5000) lr 1.7705e-03 eta 0:14:57
epoch [46/200] batch [30/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.3027 (0.3671) acc 90.6250 (91.4583) lr 1.7705e-03 eta 0:14:22
epoch [46/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.2681 (0.3714) acc 96.8750 (91.5179) lr 1.7705e-03 eta 0:13:57
epoch [46/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3059 (0.3691) acc 90.6250 (91.4062) lr 1.7705e-03 eta 0:13:36
epoch [46/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1986 (0.3694) acc 96.8750 (91.2500) lr 1.7705e-03 eta 0:13:20
epoch [46/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3020 (0.3656) acc 93.7500 (91.3125) lr 1.7705e-03 eta 0:13:07
epoch [47/200] batch [5/51] time 0.089 (0.201) data 0.000 (0.111) loss 0.4290 (0.3305) acc 90.6250 (90.0000) lr 1.7604e-03 eta 0:26:14
epoch [47/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.056) loss 0.7427 (0.3962) acc 71.8750 (88.7500) lr 1.7604e-03 eta 0:18:49
epoch [47/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.037) loss 0.2871 (0.3755) acc 93.7500 (89.7917) lr 1.7604e-03 eta 0:16:20
epoch [47/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.3770 (0.3773) acc 90.6250 (90.3125) lr 1.7604e-03 eta 0:15:05
epoch [47/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.3572 (0.3724) acc 93.7500 (91.0000) lr 1.7604e-03 eta 0:14:19
epoch [47/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3806 (0.3867) acc 93.7500 (90.6250) lr 1.7604e-03 eta 0:13:50
epoch [47/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.4951 (0.3805) acc 84.3750 (90.5357) lr 1.7604e-03 eta 0:13:28
epoch [47/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2668 (0.3715) acc 90.6250 (90.5469) lr 1.7604e-03 eta 0:13:10
epoch [47/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3308 (0.3605) acc 96.8750 (90.9722) lr 1.7604e-03 eta 0:12:57
epoch [47/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3079 (0.3611) acc 93.7500 (90.8750) lr 1.7604e-03 eta 0:12:46
epoch [48/200] batch [5/51] time 0.086 (0.201) data 0.000 (0.113) loss 0.6650 (0.4348) acc 81.2500 (85.6250) lr 1.7501e-03 eta 0:26:07
epoch [48/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.5923 (0.3812) acc 84.3750 (89.3750) lr 1.7501e-03 eta 0:18:44
epoch [48/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.038) loss 0.4551 (0.3970) acc 90.6250 (89.5833) lr 1.7501e-03 eta 0:16:14
epoch [48/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.028) loss 0.6504 (0.4139) acc 84.3750 (89.5312) lr 1.7501e-03 eta 0:14:59
epoch [48/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2510 (0.3990) acc 96.8750 (89.5000) lr 1.7501e-03 eta 0:14:14
epoch [48/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3232 (0.3744) acc 90.6250 (90.4167) lr 1.7501e-03 eta 0:13:43
epoch [48/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3628 (0.3748) acc 93.7500 (90.7143) lr 1.7501e-03 eta 0:13:22
epoch [48/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2771 (0.3587) acc 90.6250 (90.9375) lr 1.7501e-03 eta 0:13:05
epoch [48/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1965 (0.3550) acc 96.8750 (90.9028) lr 1.7501e-03 eta 0:12:51
epoch [48/200] batch [50/51] time 0.087 (0.098) data 0.000 (0.012) loss 0.4231 (0.3632) acc 96.8750 (90.8750) lr 1.7501e-03 eta 0:12:40
epoch [49/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.3274 (0.3171) acc 87.5000 (91.8750) lr 1.7396e-03 eta 0:26:18
epoch [49/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.4866 (0.3722) acc 90.6250 (91.8750) lr 1.7396e-03 eta 0:18:44
epoch [49/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.0904 (0.3320) acc 100.0000 (93.1250) lr 1.7396e-03 eta 0:16:12
epoch [49/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3992 (0.3346) acc 87.5000 (92.3438) lr 1.7396e-03 eta 0:14:56
epoch [49/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5811 (0.3524) acc 84.3750 (92.1250) lr 1.7396e-03 eta 0:14:10
epoch [49/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.4580 (0.3499) acc 84.3750 (91.6667) lr 1.7396e-03 eta 0:13:39
epoch [49/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.017) loss 0.2981 (0.3460) acc 93.7500 (91.7857) lr 1.7396e-03 eta 0:13:17
epoch [49/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.6343 (0.3530) acc 84.3750 (91.6406) lr 1.7396e-03 eta 0:13:00
epoch [49/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.6392 (0.3536) acc 84.3750 (91.5972) lr 1.7396e-03 eta 0:12:47
epoch [49/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.4138 (0.3521) acc 90.6250 (91.6250) lr 1.7396e-03 eta 0:12:36
epoch [50/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.2076 (0.2907) acc 93.7500 (93.7500) lr 1.7290e-03 eta 0:25:41
epoch [50/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.4382 (0.3443) acc 90.6250 (92.1875) lr 1.7290e-03 eta 0:18:23
epoch [50/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.1908 (0.3537) acc 93.7500 (91.0417) lr 1.7290e-03 eta 0:15:58
epoch [50/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3267 (0.3495) acc 90.6250 (91.2500) lr 1.7290e-03 eta 0:14:45
epoch [50/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3572 (0.3789) acc 93.7500 (91.0000) lr 1.7290e-03 eta 0:14:01
epoch [50/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4539 (0.3759) acc 84.3750 (90.7292) lr 1.7290e-03 eta 0:13:32
epoch [50/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4458 (0.3833) acc 87.5000 (90.7143) lr 1.7290e-03 eta 0:13:11
epoch [50/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2810 (0.3841) acc 93.7500 (90.7031) lr 1.7290e-03 eta 0:12:55
epoch [50/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2905 (0.3777) acc 93.7500 (90.6250) lr 1.7290e-03 eta 0:12:42
epoch [50/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4458 (0.3708) acc 87.5000 (90.8750) lr 1.7290e-03 eta 0:12:31
epoch [51/200] batch [5/51] time 0.088 (0.197) data 0.000 (0.109) loss 0.3623 (0.4334) acc 87.5000 (88.7500) lr 1.7181e-03 eta 0:25:07
epoch [51/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.0894 (0.3906) acc 100.0000 (91.2500) lr 1.7181e-03 eta 0:18:06
epoch [51/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.036) loss 0.3538 (0.4024) acc 90.6250 (90.4167) lr 1.7181e-03 eta 0:15:45
epoch [51/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.027) loss 0.6553 (0.3980) acc 90.6250 (90.9375) lr 1.7181e-03 eta 0:14:34
epoch [51/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4753 (0.3871) acc 87.5000 (91.5000) lr 1.7181e-03 eta 0:13:51
epoch [51/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.4958 (0.4049) acc 87.5000 (91.0417) lr 1.7181e-03 eta 0:13:22
epoch [51/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.1309 (0.3856) acc 96.8750 (91.6071) lr 1.7181e-03 eta 0:13:02
epoch [51/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3743 (0.3809) acc 90.6250 (91.7969) lr 1.7181e-03 eta 0:12:46
epoch [51/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3381 (0.3817) acc 93.7500 (91.5278) lr 1.7181e-03 eta 0:12:33
epoch [51/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2622 (0.3833) acc 93.7500 (91.4375) lr 1.7181e-03 eta 0:12:22
epoch [52/200] batch [5/51] time 0.087 (0.221) data 0.000 (0.134) loss 0.1853 (0.4147) acc 93.7500 (87.5000) lr 1.7071e-03 eta 0:27:59
epoch [52/200] batch [10/51] time 0.086 (0.154) data 0.000 (0.067) loss 0.3940 (0.4196) acc 87.5000 (89.0625) lr 1.7071e-03 eta 0:19:29
epoch [52/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.5425 (0.4387) acc 81.2500 (88.7500) lr 1.7071e-03 eta 0:16:37
epoch [52/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.034) loss 0.3054 (0.4408) acc 93.7500 (89.0625) lr 1.7071e-03 eta 0:15:12
epoch [52/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2957 (0.4145) acc 90.6250 (89.5000) lr 1.7071e-03 eta 0:14:21
epoch [52/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.5376 (0.4169) acc 84.3750 (89.4792) lr 1.7071e-03 eta 0:13:46
epoch [52/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.2285 (0.4231) acc 93.7500 (88.7500) lr 1.7071e-03 eta 0:13:22
epoch [52/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3599 (0.4137) acc 93.7500 (88.9062) lr 1.7071e-03 eta 0:13:02
epoch [52/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5361 (0.4080) acc 81.2500 (88.8194) lr 1.7071e-03 eta 0:12:47
epoch [52/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3066 (0.4005) acc 90.6250 (88.9375) lr 1.7071e-03 eta 0:12:34
epoch [53/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.6260 (0.4216) acc 87.5000 (91.2500) lr 1.6959e-03 eta 0:24:56
epoch [53/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.2125 (0.3804) acc 96.8750 (93.1250) lr 1.6959e-03 eta 0:17:55
epoch [53/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2917 (0.3627) acc 96.8750 (92.5000) lr 1.6959e-03 eta 0:15:34
epoch [53/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3335 (0.3527) acc 93.7500 (92.6562) lr 1.6959e-03 eta 0:14:23
epoch [53/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2817 (0.3450) acc 96.8750 (92.7500) lr 1.6959e-03 eta 0:13:42
epoch [53/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.2144 (0.3431) acc 93.7500 (92.9167) lr 1.6959e-03 eta 0:13:13
epoch [53/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2139 (0.3312) acc 93.7500 (92.8571) lr 1.6959e-03 eta 0:12:53
epoch [53/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3567 (0.3411) acc 87.5000 (92.1094) lr 1.6959e-03 eta 0:12:36
epoch [53/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.2634 (0.3437) acc 90.6250 (91.8056) lr 1.6959e-03 eta 0:12:23
epoch [53/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4253 (0.3496) acc 93.7500 (91.5000) lr 1.6959e-03 eta 0:12:13
epoch [54/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.129) loss 0.5801 (0.3999) acc 87.5000 (87.5000) lr 1.6845e-03 eta 0:27:03
epoch [54/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.6982 (0.3951) acc 84.3750 (88.7500) lr 1.6845e-03 eta 0:18:57
epoch [54/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.2346 (0.4022) acc 96.8750 (89.7917) lr 1.6845e-03 eta 0:16:15
epoch [54/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.4753 (0.4042) acc 90.6250 (90.3125) lr 1.6845e-03 eta 0:14:55
epoch [54/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.1932 (0.3921) acc 96.8750 (90.2500) lr 1.6845e-03 eta 0:14:05
epoch [54/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2776 (0.3744) acc 93.7500 (90.8333) lr 1.6845e-03 eta 0:13:32
epoch [54/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.3196 (0.3718) acc 90.6250 (90.7143) lr 1.6845e-03 eta 0:13:09
epoch [54/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2610 (0.3628) acc 93.7500 (91.0156) lr 1.6845e-03 eta 0:12:50
epoch [54/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3713 (0.3723) acc 87.5000 (90.4167) lr 1.6845e-03 eta 0:12:35
epoch [54/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2705 (0.3656) acc 96.8750 (90.6250) lr 1.6845e-03 eta 0:12:23
epoch [55/200] batch [5/51] time 0.088 (0.210) data 0.000 (0.122) loss 0.1711 (0.2518) acc 100.0000 (93.7500) lr 1.6730e-03 eta 0:26:04
epoch [55/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.1904 (0.2927) acc 96.8750 (92.5000) lr 1.6730e-03 eta 0:18:23
epoch [55/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.4658 (0.3104) acc 87.5000 (92.5000) lr 1.6730e-03 eta 0:15:49
epoch [55/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.7549 (0.3363) acc 84.3750 (91.5625) lr 1.6730e-03 eta 0:14:32
epoch [55/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.025) loss 0.6431 (0.3557) acc 84.3750 (91.1250) lr 1.6730e-03 eta 0:13:45
epoch [55/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.021) loss 0.0757 (0.3494) acc 100.0000 (91.1458) lr 1.6730e-03 eta 0:13:14
epoch [55/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.4475 (0.3598) acc 90.6250 (90.9821) lr 1.6730e-03 eta 0:12:52
epoch [55/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.1760 (0.3457) acc 96.8750 (91.3281) lr 1.6730e-03 eta 0:12:35
epoch [55/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1775 (0.3510) acc 96.8750 (91.3889) lr 1.6730e-03 eta 0:12:21
epoch [55/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3042 (0.3591) acc 96.8750 (91.3125) lr 1.6730e-03 eta 0:12:10
epoch [56/200] batch [5/51] time 0.090 (0.207) data 0.000 (0.119) loss 0.2844 (0.4273) acc 93.7500 (90.6250) lr 1.6613e-03 eta 0:25:33
epoch [56/200] batch [10/51] time 0.088 (0.148) data 0.000 (0.060) loss 0.2993 (0.4290) acc 96.8750 (90.6250) lr 1.6613e-03 eta 0:18:10
epoch [56/200] batch [15/51] time 0.088 (0.128) data 0.000 (0.040) loss 0.2141 (0.3641) acc 96.8750 (91.8750) lr 1.6613e-03 eta 0:15:42
epoch [56/200] batch [20/51] time 0.088 (0.118) data 0.000 (0.030) loss 0.0708 (0.3274) acc 100.0000 (92.5000) lr 1.6613e-03 eta 0:14:27
epoch [56/200] batch [25/51] time 0.088 (0.112) data 0.000 (0.024) loss 0.2391 (0.3358) acc 93.7500 (92.0000) lr 1.6613e-03 eta 0:13:43
epoch [56/200] batch [30/51] time 0.089 (0.108) data 0.000 (0.020) loss 0.2048 (0.3349) acc 100.0000 (92.2917) lr 1.6613e-03 eta 0:13:13
epoch [56/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.017) loss 0.3152 (0.3292) acc 87.5000 (92.4107) lr 1.6613e-03 eta 0:12:51
epoch [56/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.015) loss 0.6138 (0.3373) acc 84.3750 (92.1875) lr 1.6613e-03 eta 0:12:34
epoch [56/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.013) loss 0.1875 (0.3316) acc 96.8750 (92.2917) lr 1.6613e-03 eta 0:12:20
epoch [56/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3840 (0.3349) acc 90.6250 (92.2500) lr 1.6613e-03 eta 0:12:08
epoch [57/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.4399 (0.3918) acc 87.5000 (90.6250) lr 1.6494e-03 eta 0:24:34
epoch [57/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.3794 (0.3420) acc 90.6250 (90.9375) lr 1.6494e-03 eta 0:17:37
epoch [57/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.2529 (0.3652) acc 93.7500 (91.2500) lr 1.6494e-03 eta 0:15:17
epoch [57/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.5439 (0.3732) acc 93.7500 (90.9375) lr 1.6494e-03 eta 0:14:06
epoch [57/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.5679 (0.3772) acc 90.6250 (91.0000) lr 1.6494e-03 eta 0:13:24
epoch [57/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.8999 (0.3892) acc 81.2500 (90.8333) lr 1.6494e-03 eta 0:12:56
epoch [57/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4019 (0.3940) acc 87.5000 (90.5357) lr 1.6494e-03 eta 0:12:36
epoch [57/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1544 (0.3905) acc 100.0000 (90.7812) lr 1.6494e-03 eta 0:12:20
epoch [57/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1711 (0.3811) acc 96.8750 (91.1111) lr 1.6494e-03 eta 0:12:07
epoch [57/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1460 (0.3742) acc 96.8750 (91.2500) lr 1.6494e-03 eta 0:11:56
epoch [58/200] batch [5/51] time 0.087 (0.221) data 0.000 (0.135) loss 0.4658 (0.3045) acc 90.6250 (92.5000) lr 1.6374e-03 eta 0:26:54
epoch [58/200] batch [10/51] time 0.088 (0.154) data 0.000 (0.067) loss 0.3535 (0.2644) acc 87.5000 (94.0625) lr 1.6374e-03 eta 0:18:44
epoch [58/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.2119 (0.2832) acc 96.8750 (93.7500) lr 1.6374e-03 eta 0:16:00
epoch [58/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.6099 (0.3037) acc 84.3750 (92.9688) lr 1.6374e-03 eta 0:14:38
epoch [58/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.4702 (0.3072) acc 87.5000 (92.7500) lr 1.6374e-03 eta 0:13:49
epoch [58/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3181 (0.3110) acc 96.8750 (92.7083) lr 1.6374e-03 eta 0:13:15
epoch [58/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.2642 (0.3253) acc 93.7500 (92.0536) lr 1.6374e-03 eta 0:12:51
epoch [58/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.2905 (0.3350) acc 93.7500 (91.7969) lr 1.6374e-03 eta 0:12:32
epoch [58/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1843 (0.3338) acc 96.8750 (91.6667) lr 1.6374e-03 eta 0:12:17
epoch [58/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.7427 (0.3446) acc 81.2500 (91.3750) lr 1.6374e-03 eta 0:12:05
epoch [59/200] batch [5/51] time 0.087 (0.218) data 0.000 (0.131) loss 0.4441 (0.3813) acc 90.6250 (90.6250) lr 1.6252e-03 eta 0:26:20
epoch [59/200] batch [10/51] time 0.088 (0.153) data 0.000 (0.065) loss 0.9033 (0.4016) acc 81.2500 (90.9375) lr 1.6252e-03 eta 0:18:25
epoch [59/200] batch [15/51] time 0.088 (0.131) data 0.000 (0.044) loss 0.4663 (0.3688) acc 87.5000 (91.0417) lr 1.6252e-03 eta 0:15:46
epoch [59/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.2568 (0.3398) acc 93.7500 (91.7188) lr 1.6252e-03 eta 0:14:27
epoch [59/200] batch [25/51] time 0.089 (0.114) data 0.000 (0.026) loss 0.3254 (0.3413) acc 87.5000 (91.5000) lr 1.6252e-03 eta 0:13:39
epoch [59/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4482 (0.3599) acc 87.5000 (90.9375) lr 1.6252e-03 eta 0:13:07
epoch [59/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2983 (0.3637) acc 93.7500 (90.8036) lr 1.6252e-03 eta 0:12:44
epoch [59/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.5107 (0.3646) acc 90.6250 (90.7031) lr 1.6252e-03 eta 0:12:26
epoch [59/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2411 (0.3648) acc 93.7500 (90.6250) lr 1.6252e-03 eta 0:12:11
epoch [59/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3074 (0.3666) acc 93.7500 (90.6250) lr 1.6252e-03 eta 0:11:59
epoch [60/200] batch [5/51] time 0.088 (0.207) data 0.000 (0.119) loss 0.4895 (0.3893) acc 87.5000 (90.6250) lr 1.6129e-03 eta 0:24:48
epoch [60/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.4639 (0.3801) acc 87.5000 (90.6250) lr 1.6129e-03 eta 0:17:35
epoch [60/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.3662 (0.3413) acc 84.3750 (91.4583) lr 1.6129e-03 eta 0:15:11
epoch [60/200] batch [20/51] time 0.089 (0.117) data 0.000 (0.030) loss 0.3867 (0.3540) acc 90.6250 (91.5625) lr 1.6129e-03 eta 0:13:59
epoch [60/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1545 (0.3477) acc 96.8750 (91.2500) lr 1.6129e-03 eta 0:13:15
epoch [60/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2908 (0.3280) acc 90.6250 (91.6667) lr 1.6129e-03 eta 0:12:45
epoch [60/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3489 (0.3227) acc 93.7500 (92.0536) lr 1.6129e-03 eta 0:12:25
epoch [60/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3044 (0.3280) acc 90.6250 (91.6406) lr 1.6129e-03 eta 0:12:08
epoch [60/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.8740 (0.3448) acc 81.2500 (91.3889) lr 1.6129e-03 eta 0:11:55
epoch [60/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.6694 (0.3488) acc 78.1250 (91.0000) lr 1.6129e-03 eta 0:11:44
epoch [61/200] batch [5/51] time 0.088 (0.201) data 0.001 (0.113) loss 0.4500 (0.3775) acc 81.2500 (90.0000) lr 1.6004e-03 eta 0:23:54
epoch [61/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.4692 (0.3277) acc 90.6250 (91.5625) lr 1.6004e-03 eta 0:17:04
epoch [61/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.3506 (0.3776) acc 90.6250 (90.2083) lr 1.6004e-03 eta 0:14:49
epoch [61/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.029) loss 0.2388 (0.3503) acc 93.7500 (91.2500) lr 1.6004e-03 eta 0:13:42
epoch [61/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4011 (0.3514) acc 87.5000 (91.1250) lr 1.6004e-03 eta 0:13:01
epoch [61/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3752 (0.3375) acc 90.6250 (91.7708) lr 1.6004e-03 eta 0:12:34
epoch [61/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1361 (0.3324) acc 96.8750 (91.7857) lr 1.6004e-03 eta 0:12:14
epoch [61/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1890 (0.3191) acc 96.8750 (92.2656) lr 1.6004e-03 eta 0:11:58
epoch [61/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.3230 (0.3161) acc 90.6250 (92.2917) lr 1.6004e-03 eta 0:11:45
epoch [61/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3450 (0.3156) acc 90.6250 (92.3125) lr 1.6004e-03 eta 0:11:35
epoch [62/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.125) loss 0.3213 (0.3512) acc 90.6250 (91.8750) lr 1.5878e-03 eta 0:25:08
epoch [62/200] batch [10/51] time 0.088 (0.150) data 0.000 (0.063) loss 0.1920 (0.3387) acc 96.8750 (91.8750) lr 1.5878e-03 eta 0:17:43
epoch [62/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.3015 (0.3571) acc 96.8750 (91.2500) lr 1.5878e-03 eta 0:15:14
epoch [62/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.031) loss 0.2239 (0.3334) acc 93.7500 (91.4062) lr 1.5878e-03 eta 0:13:59
epoch [62/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.025) loss 0.4824 (0.3209) acc 81.2500 (91.7500) lr 1.5878e-03 eta 0:13:14
epoch [62/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.4839 (0.3276) acc 84.3750 (91.5625) lr 1.5878e-03 eta 0:12:43
epoch [62/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.5415 (0.3306) acc 90.6250 (91.6071) lr 1.5878e-03 eta 0:12:21
epoch [62/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2734 (0.3346) acc 90.6250 (91.3281) lr 1.5878e-03 eta 0:12:04
epoch [62/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4873 (0.3470) acc 87.5000 (91.0417) lr 1.5878e-03 eta 0:11:51
epoch [62/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2015 (0.3482) acc 96.8750 (91.1250) lr 1.5878e-03 eta 0:11:40
epoch [63/200] batch [5/51] time 0.087 (0.196) data 0.000 (0.109) loss 0.5879 (0.3682) acc 78.1250 (88.7500) lr 1.5750e-03 eta 0:23:01
epoch [63/200] batch [10/51] time 0.086 (0.142) data 0.000 (0.055) loss 0.4087 (0.3604) acc 87.5000 (90.3125) lr 1.5750e-03 eta 0:16:35
epoch [63/200] batch [15/51] time 0.087 (0.123) data 0.000 (0.037) loss 0.3083 (0.3656) acc 90.6250 (90.2083) lr 1.5750e-03 eta 0:14:25
epoch [63/200] batch [20/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.1892 (0.3650) acc 100.0000 (91.0938) lr 1.5750e-03 eta 0:13:20
epoch [63/200] batch [25/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.3042 (0.3603) acc 93.7500 (91.1250) lr 1.5750e-03 eta 0:12:41
epoch [63/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.5366 (0.3686) acc 87.5000 (90.8333) lr 1.5750e-03 eta 0:12:14
epoch [63/200] batch [35/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.4451 (0.3615) acc 90.6250 (90.8929) lr 1.5750e-03 eta 0:11:56
epoch [63/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2397 (0.3518) acc 96.8750 (91.0938) lr 1.5750e-03 eta 0:11:41
epoch [63/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1076 (0.3495) acc 96.8750 (90.9722) lr 1.5750e-03 eta 0:11:29
epoch [63/200] batch [50/51] time 0.085 (0.097) data 0.000 (0.011) loss 0.6616 (0.3601) acc 84.3750 (90.7500) lr 1.5750e-03 eta 0:11:19
epoch [64/200] batch [5/51] time 0.086 (0.220) data 0.000 (0.133) loss 0.2908 (0.3838) acc 96.8750 (93.1250) lr 1.5621e-03 eta 0:25:35
epoch [64/200] batch [10/51] time 0.086 (0.153) data 0.000 (0.067) loss 0.4683 (0.3748) acc 87.5000 (92.5000) lr 1.5621e-03 eta 0:17:49
epoch [64/200] batch [15/51] time 0.088 (0.131) data 0.000 (0.045) loss 0.1935 (0.3682) acc 96.8750 (92.2917) lr 1.5621e-03 eta 0:15:14
epoch [64/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.3755 (0.3591) acc 93.7500 (92.1875) lr 1.5621e-03 eta 0:13:55
epoch [64/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.027) loss 0.3027 (0.3336) acc 96.8750 (93.0000) lr 1.5621e-03 eta 0:13:08
epoch [64/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1824 (0.3332) acc 96.8750 (93.0208) lr 1.5621e-03 eta 0:12:36
epoch [64/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2849 (0.3211) acc 96.8750 (93.3036) lr 1.5621e-03 eta 0:12:13
epoch [64/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.4651 (0.3324) acc 87.5000 (92.7344) lr 1.5621e-03 eta 0:11:56
epoch [64/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3611 (0.3250) acc 84.3750 (92.7778) lr 1.5621e-03 eta 0:11:42
epoch [64/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1726 (0.3216) acc 93.7500 (92.5000) lr 1.5621e-03 eta 0:11:31
epoch [65/200] batch [5/51] time 0.087 (0.224) data 0.000 (0.137) loss 0.1765 (0.2601) acc 96.8750 (93.7500) lr 1.5490e-03 eta 0:25:54
epoch [65/200] batch [10/51] time 0.086 (0.156) data 0.000 (0.069) loss 0.4648 (0.3426) acc 93.7500 (91.5625) lr 1.5490e-03 eta 0:17:57
epoch [65/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.0859 (0.3079) acc 100.0000 (92.9167) lr 1.5490e-03 eta 0:15:17
epoch [65/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.5811 (0.3285) acc 90.6250 (92.1875) lr 1.5490e-03 eta 0:13:56
epoch [65/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.028) loss 0.3555 (0.3418) acc 84.3750 (91.6250) lr 1.5490e-03 eta 0:13:08
epoch [65/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.023) loss 0.6021 (0.3536) acc 87.5000 (91.2500) lr 1.5490e-03 eta 0:12:35
epoch [65/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.020) loss 0.4734 (0.3752) acc 90.6250 (91.0714) lr 1.5490e-03 eta 0:12:11
epoch [65/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2407 (0.3659) acc 96.8750 (91.4062) lr 1.5490e-03 eta 0:11:53
epoch [65/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2217 (0.3693) acc 96.8750 (91.3194) lr 1.5490e-03 eta 0:11:39
epoch [65/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3416 (0.3668) acc 90.6250 (91.1875) lr 1.5490e-03 eta 0:11:28
epoch [66/200] batch [5/51] time 0.087 (0.221) data 0.000 (0.133) loss 0.0488 (0.3238) acc 100.0000 (91.2500) lr 1.5358e-03 eta 0:25:17
epoch [66/200] batch [10/51] time 0.088 (0.154) data 0.000 (0.067) loss 0.3311 (0.3597) acc 96.8750 (91.8750) lr 1.5358e-03 eta 0:17:39
epoch [66/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.3113 (0.3572) acc 93.7500 (91.0417) lr 1.5358e-03 eta 0:15:04
epoch [66/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.4395 (0.3412) acc 93.7500 (92.1875) lr 1.5358e-03 eta 0:13:47
epoch [66/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.4709 (0.3537) acc 87.5000 (92.2500) lr 1.5358e-03 eta 0:13:00
epoch [66/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.1910 (0.3561) acc 96.8750 (91.9792) lr 1.5358e-03 eta 0:12:29
epoch [66/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1680 (0.3350) acc 93.7500 (92.4107) lr 1.5358e-03 eta 0:12:07
epoch [66/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3096 (0.3373) acc 96.8750 (92.2656) lr 1.5358e-03 eta 0:11:50
epoch [66/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3616 (0.3291) acc 87.5000 (92.2917) lr 1.5358e-03 eta 0:11:36
epoch [66/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3889 (0.3281) acc 90.6250 (92.3750) lr 1.5358e-03 eta 0:11:24
epoch [67/200] batch [5/51] time 0.088 (0.209) data 0.000 (0.121) loss 0.0800 (0.2421) acc 100.0000 (96.2500) lr 1.5225e-03 eta 0:23:45
epoch [67/200] batch [10/51] time 0.088 (0.148) data 0.000 (0.061) loss 0.4824 (0.3186) acc 90.6250 (93.4375) lr 1.5225e-03 eta 0:16:50
epoch [67/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.3984 (0.3324) acc 90.6250 (93.3333) lr 1.5225e-03 eta 0:14:30
epoch [67/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.1455 (0.3210) acc 96.8750 (93.1250) lr 1.5225e-03 eta 0:13:20
epoch [67/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.3882 (0.3333) acc 84.3750 (92.2500) lr 1.5225e-03 eta 0:12:38
epoch [67/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3860 (0.3430) acc 87.5000 (91.6667) lr 1.5225e-03 eta 0:12:10
epoch [67/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.1921 (0.3405) acc 96.8750 (91.6071) lr 1.5225e-03 eta 0:11:50
epoch [67/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5400 (0.3561) acc 90.6250 (91.1719) lr 1.5225e-03 eta 0:11:34
epoch [67/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2878 (0.3454) acc 96.8750 (91.7361) lr 1.5225e-03 eta 0:11:21
epoch [67/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3481 (0.3402) acc 90.6250 (91.5625) lr 1.5225e-03 eta 0:11:11
epoch [68/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.135) loss 0.2216 (0.3815) acc 93.7500 (91.2500) lr 1.5090e-03 eta 0:25:06
epoch [68/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.1515 (0.3335) acc 93.7500 (92.1875) lr 1.5090e-03 eta 0:17:26
epoch [68/200] batch [15/51] time 0.086 (0.132) data 0.000 (0.045) loss 0.4453 (0.3329) acc 90.6250 (92.2917) lr 1.5090e-03 eta 0:14:51
epoch [68/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.034) loss 0.3252 (0.3358) acc 93.7500 (92.1875) lr 1.5090e-03 eta 0:13:34
epoch [68/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.5020 (0.3363) acc 87.5000 (92.2500) lr 1.5090e-03 eta 0:12:48
epoch [68/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.023) loss 0.3730 (0.3392) acc 87.5000 (92.1875) lr 1.5090e-03 eta 0:12:16
epoch [68/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.4238 (0.3272) acc 90.6250 (92.4107) lr 1.5090e-03 eta 0:11:54
epoch [68/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.4236 (0.3374) acc 81.2500 (91.6406) lr 1.5090e-03 eta 0:11:37
epoch [68/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.6172 (0.3430) acc 87.5000 (91.3889) lr 1.5090e-03 eta 0:11:23
epoch [68/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3477 (0.3376) acc 93.7500 (91.5000) lr 1.5090e-03 eta 0:11:12
epoch [69/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.111) loss 0.2368 (0.3514) acc 90.6250 (91.8750) lr 1.4955e-03 eta 0:22:26
epoch [69/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.056) loss 0.2993 (0.3046) acc 93.7500 (92.8125) lr 1.4955e-03 eta 0:16:07
epoch [69/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.037) loss 0.1788 (0.3109) acc 96.8750 (92.2917) lr 1.4955e-03 eta 0:13:59
epoch [69/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3699 (0.2983) acc 93.7500 (93.1250) lr 1.4955e-03 eta 0:12:55
epoch [69/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.1880 (0.3011) acc 96.8750 (92.7500) lr 1.4955e-03 eta 0:12:16
epoch [69/200] batch [30/51] time 0.091 (0.106) data 0.000 (0.019) loss 0.2673 (0.2980) acc 93.7500 (92.9167) lr 1.4955e-03 eta 0:11:51
epoch [69/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3037 (0.3112) acc 90.6250 (92.4107) lr 1.4955e-03 eta 0:11:32
epoch [69/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2661 (0.3303) acc 93.7500 (92.2656) lr 1.4955e-03 eta 0:11:17
epoch [69/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.3608 (0.3226) acc 87.5000 (92.0833) lr 1.4955e-03 eta 0:11:05
epoch [69/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2382 (0.3245) acc 93.7500 (92.0000) lr 1.4955e-03 eta 0:10:55
epoch [70/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.125) loss 0.3860 (0.1994) acc 90.6250 (96.2500) lr 1.4818e-03 eta 0:23:40
epoch [70/200] batch [10/51] time 0.088 (0.150) data 0.000 (0.062) loss 0.2339 (0.2689) acc 93.7500 (94.6875) lr 1.4818e-03 eta 0:16:41
epoch [70/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.4077 (0.2895) acc 87.5000 (93.3333) lr 1.4818e-03 eta 0:14:20
epoch [70/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.031) loss 0.7036 (0.3043) acc 84.3750 (92.8125) lr 1.4818e-03 eta 0:13:10
epoch [70/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1317 (0.2913) acc 100.0000 (93.3750) lr 1.4818e-03 eta 0:12:27
epoch [70/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.4116 (0.2989) acc 90.6250 (93.1250) lr 1.4818e-03 eta 0:11:59
epoch [70/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3738 (0.2973) acc 93.7500 (93.3036) lr 1.4818e-03 eta 0:11:39
epoch [70/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3071 (0.3053) acc 93.7500 (93.2031) lr 1.4818e-03 eta 0:11:23
epoch [70/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3354 (0.3132) acc 93.7500 (92.9167) lr 1.4818e-03 eta 0:11:10
epoch [70/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3723 (0.3216) acc 90.6250 (92.7500) lr 1.4818e-03 eta 0:11:00
epoch [71/200] batch [5/51] time 0.086 (0.221) data 0.000 (0.134) loss 0.4263 (0.3151) acc 87.5000 (91.8750) lr 1.4679e-03 eta 0:24:22
epoch [71/200] batch [10/51] time 0.086 (0.154) data 0.000 (0.067) loss 0.4333 (0.2994) acc 93.7500 (92.8125) lr 1.4679e-03 eta 0:16:58
epoch [71/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.045) loss 0.2467 (0.2959) acc 90.6250 (92.5000) lr 1.4679e-03 eta 0:14:29
epoch [71/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.034) loss 0.2983 (0.3122) acc 96.8750 (92.5000) lr 1.4679e-03 eta 0:13:16
epoch [71/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3979 (0.3202) acc 90.6250 (92.3750) lr 1.4679e-03 eta 0:12:31
epoch [71/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.1962 (0.3103) acc 96.8750 (92.7083) lr 1.4679e-03 eta 0:12:02
epoch [71/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.4316 (0.3144) acc 87.5000 (92.5893) lr 1.4679e-03 eta 0:11:40
epoch [71/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.6753 (0.3156) acc 84.3750 (92.5781) lr 1.4679e-03 eta 0:11:23
epoch [71/200] batch [45/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.4355 (0.3184) acc 81.2500 (92.2917) lr 1.4679e-03 eta 0:11:09
epoch [71/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2712 (0.3197) acc 93.7500 (92.1875) lr 1.4679e-03 eta 0:10:58
epoch [72/200] batch [5/51] time 0.087 (0.220) data 0.000 (0.133) loss 0.3459 (0.2805) acc 90.6250 (92.5000) lr 1.4540e-03 eta 0:24:04
epoch [72/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.067) loss 0.1733 (0.2826) acc 96.8750 (91.8750) lr 1.4540e-03 eta 0:16:47
epoch [72/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.1170 (0.3193) acc 100.0000 (92.0833) lr 1.4540e-03 eta 0:14:20
epoch [72/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.1176 (0.3105) acc 96.8750 (92.3438) lr 1.4540e-03 eta 0:13:07
epoch [72/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.2452 (0.2866) acc 96.8750 (93.2500) lr 1.4540e-03 eta 0:12:23
epoch [72/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.2198 (0.2995) acc 93.7500 (92.6042) lr 1.4540e-03 eta 0:11:53
epoch [72/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.0808 (0.2973) acc 100.0000 (92.6786) lr 1.4540e-03 eta 0:11:32
epoch [72/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.6177 (0.3094) acc 84.3750 (92.5000) lr 1.4540e-03 eta 0:11:15
epoch [72/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4695 (0.3187) acc 93.7500 (92.4306) lr 1.4540e-03 eta 0:11:02
epoch [72/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4084 (0.3199) acc 87.5000 (92.3750) lr 1.4540e-03 eta 0:10:51
epoch [73/200] batch [5/51] time 0.088 (0.200) data 0.000 (0.111) loss 0.3945 (0.3285) acc 90.6250 (90.6250) lr 1.4399e-03 eta 0:21:46
epoch [73/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.056) loss 0.7583 (0.4208) acc 78.1250 (89.3750) lr 1.4399e-03 eta 0:15:36
epoch [73/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.037) loss 0.3293 (0.3637) acc 93.7500 (90.6250) lr 1.4399e-03 eta 0:13:33
epoch [73/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4082 (0.3675) acc 93.7500 (90.4688) lr 1.4399e-03 eta 0:12:30
epoch [73/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.1771 (0.3579) acc 93.7500 (90.7500) lr 1.4399e-03 eta 0:11:54
epoch [73/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2703 (0.3499) acc 96.8750 (90.9375) lr 1.4399e-03 eta 0:11:28
epoch [73/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2324 (0.3362) acc 93.7500 (91.2500) lr 1.4399e-03 eta 0:11:10
epoch [73/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2666 (0.3373) acc 96.8750 (91.3281) lr 1.4399e-03 eta 0:10:56
epoch [73/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.6978 (0.3400) acc 84.3750 (91.3889) lr 1.4399e-03 eta 0:10:44
epoch [73/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1956 (0.3409) acc 96.8750 (91.5000) lr 1.4399e-03 eta 0:10:35
epoch [74/200] batch [5/51] time 0.087 (0.214) data 0.000 (0.126) loss 0.2001 (0.3175) acc 96.8750 (93.1250) lr 1.4258e-03 eta 0:23:05
epoch [74/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.2068 (0.2913) acc 96.8750 (92.8125) lr 1.4258e-03 eta 0:16:11
epoch [74/200] batch [15/51] time 0.086 (0.129) data 0.000 (0.042) loss 0.4287 (0.3117) acc 81.2500 (91.6667) lr 1.4258e-03 eta 0:13:54
epoch [74/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.1447 (0.3103) acc 93.7500 (91.8750) lr 1.4258e-03 eta 0:12:45
epoch [74/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.4988 (0.3061) acc 87.5000 (91.7500) lr 1.4258e-03 eta 0:12:03
epoch [74/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.021) loss 0.3833 (0.3173) acc 93.7500 (91.8750) lr 1.4258e-03 eta 0:11:35
epoch [74/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.2852 (0.3221) acc 90.6250 (91.5179) lr 1.4258e-03 eta 0:11:15
epoch [74/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1219 (0.3216) acc 96.8750 (91.3281) lr 1.4258e-03 eta 0:11:00
epoch [74/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3877 (0.3302) acc 87.5000 (91.3194) lr 1.4258e-03 eta 0:10:47
epoch [74/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.6353 (0.3450) acc 84.3750 (91.3125) lr 1.4258e-03 eta 0:10:38
epoch [75/200] batch [5/51] time 0.087 (0.223) data 0.000 (0.136) loss 0.3015 (0.3114) acc 93.7500 (93.1250) lr 1.4115e-03 eta 0:23:53
epoch [75/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.2092 (0.3073) acc 93.7500 (93.7500) lr 1.4115e-03 eta 0:16:36
epoch [75/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.046) loss 0.4292 (0.3004) acc 84.3750 (92.7083) lr 1.4115e-03 eta 0:14:09
epoch [75/200] batch [20/51] time 0.086 (0.121) data 0.000 (0.034) loss 0.4995 (0.3086) acc 84.3750 (92.6562) lr 1.4115e-03 eta 0:12:55
epoch [75/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2576 (0.3211) acc 90.6250 (92.1250) lr 1.4115e-03 eta 0:12:11
epoch [75/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3540 (0.3283) acc 87.5000 (92.1875) lr 1.4115e-03 eta 0:11:41
epoch [75/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.020) loss 0.4473 (0.3336) acc 90.6250 (91.8750) lr 1.4115e-03 eta 0:11:20
epoch [75/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.5171 (0.3612) acc 90.6250 (91.3281) lr 1.4115e-03 eta 0:11:03
epoch [75/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2903 (0.3491) acc 93.7500 (91.6667) lr 1.4115e-03 eta 0:10:50
epoch [75/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3552 (0.3614) acc 93.7500 (91.2500) lr 1.4115e-03 eta 0:10:39
epoch [76/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.2190 (0.3358) acc 93.7500 (91.8750) lr 1.3971e-03 eta 0:21:22
epoch [76/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.057) loss 0.1913 (0.3389) acc 96.8750 (92.5000) lr 1.3971e-03 eta 0:15:17
epoch [76/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.7510 (0.3988) acc 81.2500 (90.2083) lr 1.3971e-03 eta 0:13:16
epoch [76/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.4609 (0.3897) acc 93.7500 (91.0938) lr 1.3971e-03 eta 0:12:15
epoch [76/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3740 (0.3911) acc 96.8750 (91.6250) lr 1.3971e-03 eta 0:11:38
epoch [76/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3794 (0.3786) acc 90.6250 (91.7708) lr 1.3971e-03 eta 0:11:13
epoch [76/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.016) loss 0.3643 (0.3867) acc 87.5000 (91.1607) lr 1.3971e-03 eta 0:10:56
epoch [76/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4021 (0.3985) acc 87.5000 (90.5469) lr 1.3971e-03 eta 0:10:42
epoch [76/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3169 (0.3859) acc 96.8750 (90.7639) lr 1.3971e-03 eta 0:10:31
epoch [76/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3538 (0.3753) acc 90.6250 (91.1250) lr 1.3971e-03 eta 0:10:21
epoch [77/200] batch [5/51] time 0.086 (0.212) data 0.000 (0.125) loss 0.4048 (0.3318) acc 87.5000 (91.2500) lr 1.3827e-03 eta 0:22:20
epoch [77/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.062) loss 0.2230 (0.3230) acc 93.7500 (91.2500) lr 1.3827e-03 eta 0:15:44
epoch [77/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.042) loss 0.1160 (0.3117) acc 96.8750 (91.8750) lr 1.3827e-03 eta 0:13:30
epoch [77/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.4421 (0.3043) acc 87.5000 (92.3438) lr 1.3827e-03 eta 0:12:23
epoch [77/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3359 (0.3040) acc 93.7500 (92.5000) lr 1.3827e-03 eta 0:11:43
epoch [77/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.021) loss 0.5264 (0.3132) acc 87.5000 (92.2917) lr 1.3827e-03 eta 0:11:16
epoch [77/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.3042 (0.3178) acc 90.6250 (92.3214) lr 1.3827e-03 eta 0:10:56
epoch [77/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.3770 (0.3210) acc 87.5000 (92.4219) lr 1.3827e-03 eta 0:10:41
epoch [77/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2109 (0.3204) acc 93.7500 (92.2917) lr 1.3827e-03 eta 0:10:29
epoch [77/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.3066 (0.3245) acc 90.6250 (92.1250) lr 1.3827e-03 eta 0:10:19
epoch [78/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.124) loss 0.1956 (0.3013) acc 93.7500 (93.1250) lr 1.3681e-03 eta 0:22:13
epoch [78/200] batch [10/51] time 0.088 (0.150) data 0.000 (0.062) loss 0.2637 (0.3394) acc 96.8750 (91.5625) lr 1.3681e-03 eta 0:15:39
epoch [78/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.1332 (0.3554) acc 100.0000 (91.0417) lr 1.3681e-03 eta 0:13:27
epoch [78/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.031) loss 0.3176 (0.3579) acc 84.3750 (90.1562) lr 1.3681e-03 eta 0:12:22
epoch [78/200] batch [25/51] time 0.088 (0.112) data 0.000 (0.025) loss 0.1678 (0.3462) acc 96.8750 (90.5000) lr 1.3681e-03 eta 0:11:42
epoch [78/200] batch [30/51] time 0.089 (0.108) data 0.000 (0.021) loss 0.2227 (0.3488) acc 96.8750 (90.8333) lr 1.3681e-03 eta 0:11:16
epoch [78/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.3062 (0.3443) acc 93.7500 (90.8036) lr 1.3681e-03 eta 0:10:56
epoch [78/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3279 (0.3416) acc 93.7500 (91.1719) lr 1.3681e-03 eta 0:10:41
epoch [78/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4600 (0.3601) acc 90.6250 (90.9028) lr 1.3681e-03 eta 0:10:28
epoch [78/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.7544 (0.3584) acc 75.0000 (90.9375) lr 1.3681e-03 eta 0:10:18
epoch [79/200] batch [5/51] time 0.088 (0.202) data 0.000 (0.114) loss 0.3679 (0.3551) acc 96.8750 (92.5000) lr 1.3535e-03 eta 0:20:55
epoch [79/200] batch [10/51] time 0.088 (0.145) data 0.000 (0.057) loss 0.2334 (0.3091) acc 96.8750 (93.4375) lr 1.3535e-03 eta 0:14:59
epoch [79/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.3413 (0.3676) acc 93.7500 (92.0833) lr 1.3535e-03 eta 0:12:59
epoch [79/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2303 (0.3264) acc 93.7500 (93.2812) lr 1.3535e-03 eta 0:11:58
epoch [79/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.2617 (0.3108) acc 93.7500 (93.6250) lr 1.3535e-03 eta 0:11:22
epoch [79/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1644 (0.3016) acc 93.7500 (93.5417) lr 1.3535e-03 eta 0:10:59
epoch [79/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2891 (0.3081) acc 93.7500 (93.3929) lr 1.3535e-03 eta 0:10:41
epoch [79/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2356 (0.3068) acc 93.7500 (93.2031) lr 1.3535e-03 eta 0:10:27
epoch [79/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5200 (0.3244) acc 90.6250 (92.9861) lr 1.3535e-03 eta 0:10:15
epoch [79/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2130 (0.3221) acc 96.8750 (92.9375) lr 1.3535e-03 eta 0:10:06
epoch [80/200] batch [5/51] time 0.087 (0.208) data 0.000 (0.121) loss 0.2228 (0.2559) acc 93.7500 (93.1250) lr 1.3387e-03 eta 0:21:25
epoch [80/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.3577 (0.3239) acc 93.7500 (91.8750) lr 1.3387e-03 eta 0:15:09
epoch [80/200] batch [15/51] time 0.085 (0.127) data 0.000 (0.040) loss 0.4053 (0.3410) acc 96.8750 (91.6667) lr 1.3387e-03 eta 0:13:02
epoch [80/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3469 (0.3457) acc 93.7500 (91.5625) lr 1.3387e-03 eta 0:12:00
epoch [80/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1217 (0.3388) acc 100.0000 (91.8750) lr 1.3387e-03 eta 0:11:22
epoch [80/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3826 (0.3320) acc 90.6250 (91.9792) lr 1.3387e-03 eta 0:10:57
epoch [80/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.7065 (0.3448) acc 81.2500 (91.6964) lr 1.3387e-03 eta 0:10:39
epoch [80/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2676 (0.3512) acc 90.6250 (91.3281) lr 1.3387e-03 eta 0:10:25
epoch [80/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.0616 (0.3427) acc 100.0000 (91.4583) lr 1.3387e-03 eta 0:10:13
epoch [80/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1759 (0.3424) acc 100.0000 (91.3750) lr 1.3387e-03 eta 0:10:04
epoch [81/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.3464 (0.3334) acc 93.7500 (93.7500) lr 1.3239e-03 eta 0:20:24
epoch [81/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.2974 (0.3345) acc 93.7500 (92.8125) lr 1.3239e-03 eta 0:14:37
epoch [81/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.037) loss 0.3586 (0.3434) acc 90.6250 (92.5000) lr 1.3239e-03 eta 0:12:42
epoch [81/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.5532 (0.3264) acc 87.5000 (92.5000) lr 1.3239e-03 eta 0:11:44
epoch [81/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3193 (0.3305) acc 87.5000 (92.1250) lr 1.3239e-03 eta 0:11:08
epoch [81/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4734 (0.3261) acc 87.5000 (92.0833) lr 1.3239e-03 eta 0:10:45
epoch [81/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2169 (0.3233) acc 96.8750 (91.7857) lr 1.3239e-03 eta 0:10:28
epoch [81/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2573 (0.3273) acc 96.8750 (91.5625) lr 1.3239e-03 eta 0:10:14
epoch [81/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.2627 (0.3272) acc 93.7500 (91.8056) lr 1.3239e-03 eta 0:10:03
epoch [81/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.5557 (0.3311) acc 87.5000 (91.5625) lr 1.3239e-03 eta 0:09:54
epoch [82/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.3433 (0.2788) acc 93.7500 (93.1250) lr 1.3090e-03 eta 0:19:57
epoch [82/200] batch [10/51] time 0.086 (0.143) data 0.000 (0.055) loss 0.3098 (0.3255) acc 96.8750 (92.8125) lr 1.3090e-03 eta 0:14:23
epoch [82/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2854 (0.2893) acc 93.7500 (93.3333) lr 1.3090e-03 eta 0:12:31
epoch [82/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.1604 (0.2873) acc 93.7500 (93.4375) lr 1.3090e-03 eta 0:11:33
epoch [82/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1531 (0.2725) acc 100.0000 (93.8750) lr 1.3090e-03 eta 0:10:59
epoch [82/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.018) loss 0.2988 (0.2632) acc 87.5000 (94.0625) lr 1.3090e-03 eta 0:10:37
epoch [82/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3042 (0.2760) acc 96.8750 (93.7500) lr 1.3090e-03 eta 0:10:20
epoch [82/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2900 (0.2834) acc 93.7500 (93.4375) lr 1.3090e-03 eta 0:10:07
epoch [82/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3176 (0.2835) acc 90.6250 (93.4722) lr 1.3090e-03 eta 0:09:56
epoch [82/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2261 (0.2948) acc 96.8750 (93.0625) lr 1.3090e-03 eta 0:09:48
epoch [83/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.124) loss 0.1626 (0.1754) acc 96.8750 (96.2500) lr 1.2940e-03 eta 0:21:11
epoch [83/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.2455 (0.2526) acc 96.8750 (95.0000) lr 1.2940e-03 eta 0:14:56
epoch [83/200] batch [15/51] time 0.088 (0.128) data 0.000 (0.041) loss 0.2781 (0.2898) acc 90.6250 (92.9167) lr 1.2940e-03 eta 0:12:51
epoch [83/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.2371 (0.2937) acc 93.7500 (92.8125) lr 1.2940e-03 eta 0:11:48
epoch [83/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3516 (0.3020) acc 90.6250 (92.6250) lr 1.2940e-03 eta 0:11:11
epoch [83/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2081 (0.3007) acc 96.8750 (92.8125) lr 1.2940e-03 eta 0:10:45
epoch [83/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.2111 (0.3033) acc 93.7500 (92.5893) lr 1.2940e-03 eta 0:10:27
epoch [83/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2939 (0.3087) acc 90.6250 (92.4219) lr 1.2940e-03 eta 0:10:13
epoch [83/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2764 (0.2993) acc 93.7500 (92.7778) lr 1.2940e-03 eta 0:10:01
epoch [83/200] batch [50/51] time 0.087 (0.099) data 0.000 (0.013) loss 0.3867 (0.3076) acc 87.5000 (92.6250) lr 1.2940e-03 eta 0:09:52
epoch [84/200] batch [5/51] time 0.089 (0.207) data 0.000 (0.119) loss 0.3877 (0.4147) acc 87.5000 (90.0000) lr 1.2790e-03 eta 0:20:32
epoch [84/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.3000 (0.3576) acc 93.7500 (91.2500) lr 1.2790e-03 eta 0:14:33
epoch [84/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.2169 (0.3133) acc 96.8750 (92.7083) lr 1.2790e-03 eta 0:12:34
epoch [84/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3635 (0.3071) acc 87.5000 (92.5000) lr 1.2790e-03 eta 0:11:35
epoch [84/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4749 (0.3230) acc 78.1250 (91.5000) lr 1.2790e-03 eta 0:10:59
epoch [84/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4465 (0.3366) acc 87.5000 (91.4583) lr 1.2790e-03 eta 0:10:35
epoch [84/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2260 (0.3213) acc 96.8750 (91.8750) lr 1.2790e-03 eta 0:10:17
epoch [84/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3076 (0.3206) acc 90.6250 (91.8750) lr 1.2790e-03 eta 0:10:04
epoch [84/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4065 (0.3284) acc 96.8750 (91.8056) lr 1.2790e-03 eta 0:09:53
epoch [84/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4963 (0.3310) acc 87.5000 (91.5625) lr 1.2790e-03 eta 0:09:44
epoch [85/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.115) loss 0.2239 (0.3381) acc 90.6250 (89.3750) lr 1.2639e-03 eta 0:19:56
epoch [85/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.4172 (0.3493) acc 84.3750 (89.6875) lr 1.2639e-03 eta 0:14:13
epoch [85/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.038) loss 0.2052 (0.3235) acc 96.8750 (91.2500) lr 1.2639e-03 eta 0:12:19
epoch [85/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.6191 (0.3232) acc 84.3750 (91.5625) lr 1.2639e-03 eta 0:11:21
epoch [85/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5322 (0.3143) acc 87.5000 (92.1250) lr 1.2639e-03 eta 0:10:46
epoch [85/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1426 (0.3366) acc 96.8750 (91.8750) lr 1.2639e-03 eta 0:10:23
epoch [85/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.017) loss 0.0905 (0.3169) acc 100.0000 (92.4107) lr 1.2639e-03 eta 0:10:06
epoch [85/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.2498 (0.3147) acc 96.8750 (92.5781) lr 1.2639e-03 eta 0:09:54
epoch [85/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.1378 (0.3091) acc 96.8750 (92.7778) lr 1.2639e-03 eta 0:09:43
epoch [85/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.3152 (0.3111) acc 90.6250 (92.6875) lr 1.2639e-03 eta 0:09:34
epoch [86/200] batch [5/51] time 0.086 (0.208) data 0.000 (0.120) loss 0.2764 (0.2849) acc 93.7500 (96.2500) lr 1.2487e-03 eta 0:20:17
epoch [86/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.1820 (0.2727) acc 96.8750 (95.0000) lr 1.2487e-03 eta 0:14:22
epoch [86/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.1268 (0.3057) acc 96.8750 (93.1250) lr 1.2487e-03 eta 0:12:23
epoch [86/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.2710 (0.3199) acc 93.7500 (92.5000) lr 1.2487e-03 eta 0:11:24
epoch [86/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1709 (0.3008) acc 96.8750 (92.8750) lr 1.2487e-03 eta 0:10:48
epoch [86/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2405 (0.3151) acc 96.8750 (92.6042) lr 1.2487e-03 eta 0:10:24
epoch [86/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3352 (0.3248) acc 96.8750 (92.5893) lr 1.2487e-03 eta 0:10:06
epoch [86/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3606 (0.3204) acc 93.7500 (92.8906) lr 1.2487e-03 eta 0:09:53
epoch [86/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2480 (0.3212) acc 93.7500 (92.9167) lr 1.2487e-03 eta 0:09:42
epoch [86/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1947 (0.3095) acc 93.7500 (93.2500) lr 1.2487e-03 eta 0:09:33
epoch [87/200] batch [5/51] time 0.086 (0.218) data 0.000 (0.131) loss 0.2607 (0.2825) acc 93.7500 (93.7500) lr 1.2334e-03 eta 0:21:08
epoch [87/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.3621 (0.3279) acc 93.7500 (93.1250) lr 1.2334e-03 eta 0:14:46
epoch [87/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.1855 (0.3366) acc 93.7500 (92.7083) lr 1.2334e-03 eta 0:12:37
epoch [87/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3572 (0.3351) acc 93.7500 (93.1250) lr 1.2334e-03 eta 0:11:33
epoch [87/200] batch [25/51] time 0.088 (0.113) data 0.000 (0.026) loss 0.2627 (0.3216) acc 90.6250 (93.1250) lr 1.2334e-03 eta 0:10:55
epoch [87/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2566 (0.3267) acc 93.7500 (93.0208) lr 1.2334e-03 eta 0:10:30
epoch [87/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2081 (0.3273) acc 96.8750 (93.1250) lr 1.2334e-03 eta 0:10:11
epoch [87/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.3840 (0.3373) acc 96.8750 (92.6562) lr 1.2334e-03 eta 0:09:57
epoch [87/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1519 (0.3382) acc 96.8750 (92.6389) lr 1.2334e-03 eta 0:09:45
epoch [87/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.3833 (0.3344) acc 84.3750 (92.5000) lr 1.2334e-03 eta 0:09:35
epoch [88/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.129) loss 0.3345 (0.3536) acc 93.7500 (93.7500) lr 1.2181e-03 eta 0:20:47
epoch [88/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.2856 (0.3112) acc 93.7500 (93.4375) lr 1.2181e-03 eta 0:14:33
epoch [88/200] batch [15/51] time 0.088 (0.130) data 0.000 (0.043) loss 0.2593 (0.2904) acc 96.8750 (93.9583) lr 1.2181e-03 eta 0:12:27
epoch [88/200] batch [20/51] time 0.089 (0.119) data 0.000 (0.032) loss 0.3000 (0.2788) acc 93.7500 (93.9062) lr 1.2181e-03 eta 0:11:25
epoch [88/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.3450 (0.2829) acc 93.7500 (94.1250) lr 1.2181e-03 eta 0:10:47
epoch [88/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3118 (0.2841) acc 93.7500 (94.0625) lr 1.2181e-03 eta 0:10:22
epoch [88/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.3862 (0.2938) acc 87.5000 (93.7500) lr 1.2181e-03 eta 0:10:03
epoch [88/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.1447 (0.2974) acc 96.8750 (93.4375) lr 1.2181e-03 eta 0:09:49
epoch [88/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1681 (0.2935) acc 96.8750 (93.6111) lr 1.2181e-03 eta 0:09:37
epoch [88/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5210 (0.2961) acc 84.3750 (93.3125) lr 1.2181e-03 eta 0:09:28
epoch [89/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.114) loss 0.7886 (0.4329) acc 84.3750 (90.0000) lr 1.2028e-03 eta 0:19:08
epoch [89/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.3645 (0.3739) acc 87.5000 (91.2500) lr 1.2028e-03 eta 0:13:42
epoch [89/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.1987 (0.3458) acc 93.7500 (92.0833) lr 1.2028e-03 eta 0:11:53
epoch [89/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3042 (0.3266) acc 93.7500 (92.9688) lr 1.2028e-03 eta 0:10:58
epoch [89/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.3000 (0.3083) acc 93.7500 (93.2500) lr 1.2028e-03 eta 0:10:25
epoch [89/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.1897 (0.3166) acc 96.8750 (93.1250) lr 1.2028e-03 eta 0:10:02
epoch [89/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3049 (0.3158) acc 90.6250 (93.0357) lr 1.2028e-03 eta 0:09:46
epoch [89/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.3699 (0.3152) acc 90.6250 (92.9688) lr 1.2028e-03 eta 0:09:33
epoch [89/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2467 (0.3255) acc 93.7500 (92.8472) lr 1.2028e-03 eta 0:09:23
epoch [89/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.5063 (0.3255) acc 84.3750 (92.6250) lr 1.2028e-03 eta 0:09:15
epoch [90/200] batch [5/51] time 0.089 (0.199) data 0.001 (0.111) loss 0.3716 (0.3320) acc 90.6250 (90.0000) lr 1.1874e-03 eta 0:18:42
epoch [90/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.5420 (0.3624) acc 81.2500 (89.3750) lr 1.1874e-03 eta 0:13:26
epoch [90/200] batch [15/51] time 0.088 (0.124) data 0.000 (0.037) loss 0.3916 (0.3413) acc 84.3750 (90.2083) lr 1.1874e-03 eta 0:11:41
epoch [90/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2605 (0.3519) acc 93.7500 (90.6250) lr 1.1874e-03 eta 0:10:48
epoch [90/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3564 (0.3647) acc 84.3750 (90.5000) lr 1.1874e-03 eta 0:10:16
epoch [90/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3914 (0.3612) acc 90.6250 (90.5208) lr 1.1874e-03 eta 0:09:55
epoch [90/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3391 (0.3556) acc 87.5000 (90.6250) lr 1.1874e-03 eta 0:09:39
epoch [90/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3306 (0.3453) acc 87.5000 (90.8594) lr 1.1874e-03 eta 0:09:27
epoch [90/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.5195 (0.3347) acc 87.5000 (91.1806) lr 1.1874e-03 eta 0:09:17
epoch [90/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1969 (0.3357) acc 96.8750 (91.1875) lr 1.1874e-03 eta 0:09:09
epoch [91/200] batch [5/51] time 0.086 (0.216) data 0.000 (0.129) loss 0.4578 (0.3451) acc 93.7500 (94.3750) lr 1.1719e-03 eta 0:20:09
epoch [91/200] batch [10/51] time 0.086 (0.151) data 0.000 (0.065) loss 0.4229 (0.3640) acc 84.3750 (91.5625) lr 1.1719e-03 eta 0:14:07
epoch [91/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.2517 (0.3516) acc 90.6250 (90.4167) lr 1.1719e-03 eta 0:12:05
epoch [91/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.6011 (0.3618) acc 87.5000 (90.9375) lr 1.1719e-03 eta 0:11:05
epoch [91/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2783 (0.3494) acc 93.7500 (91.5000) lr 1.1719e-03 eta 0:10:29
epoch [91/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.022) loss 0.4663 (0.3572) acc 87.5000 (91.4583) lr 1.1719e-03 eta 0:10:04
epoch [91/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.4614 (0.3489) acc 90.6250 (91.5179) lr 1.1719e-03 eta 0:09:47
epoch [91/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1777 (0.3456) acc 93.7500 (91.5625) lr 1.1719e-03 eta 0:09:33
epoch [91/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.6890 (0.3469) acc 81.2500 (91.6667) lr 1.1719e-03 eta 0:09:22
epoch [91/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2703 (0.3403) acc 96.8750 (92.0000) lr 1.1719e-03 eta 0:09:13
epoch [92/200] batch [5/51] time 0.088 (0.211) data 0.000 (0.123) loss 0.3403 (0.2082) acc 87.5000 (96.2500) lr 1.1564e-03 eta 0:19:32
epoch [92/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.1133 (0.2317) acc 96.8750 (95.3125) lr 1.1564e-03 eta 0:13:46
epoch [92/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.1948 (0.2488) acc 96.8750 (94.3750) lr 1.1564e-03 eta 0:11:50
epoch [92/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.2776 (0.2680) acc 93.7500 (93.9062) lr 1.1564e-03 eta 0:10:53
epoch [92/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3914 (0.2764) acc 87.5000 (93.5000) lr 1.1564e-03 eta 0:10:18
epoch [92/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.8062 (0.2951) acc 78.1250 (92.8125) lr 1.1564e-03 eta 0:09:55
epoch [92/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.2612 (0.2929) acc 93.7500 (92.9464) lr 1.1564e-03 eta 0:09:38
epoch [92/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2378 (0.2846) acc 93.7500 (93.1250) lr 1.1564e-03 eta 0:09:25
epoch [92/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2554 (0.2956) acc 93.7500 (92.8472) lr 1.1564e-03 eta 0:09:14
epoch [92/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.6636 (0.3068) acc 87.5000 (92.6875) lr 1.1564e-03 eta 0:09:06
epoch [93/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.2097 (0.3075) acc 93.7500 (91.2500) lr 1.1409e-03 eta 0:18:40
epoch [93/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.4373 (0.3151) acc 87.5000 (91.5625) lr 1.1409e-03 eta 0:13:19
epoch [93/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.039) loss 0.2595 (0.2903) acc 93.7500 (92.9167) lr 1.1409e-03 eta 0:11:31
epoch [93/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2837 (0.2733) acc 90.6250 (93.1250) lr 1.1409e-03 eta 0:10:37
epoch [93/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2668 (0.2641) acc 96.8750 (93.6250) lr 1.1409e-03 eta 0:10:05
epoch [93/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.1660 (0.2701) acc 96.8750 (93.6458) lr 1.1409e-03 eta 0:09:43
epoch [93/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.4172 (0.2878) acc 90.6250 (93.1250) lr 1.1409e-03 eta 0:09:27
epoch [93/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1912 (0.2831) acc 93.7500 (93.2812) lr 1.1409e-03 eta 0:09:15
epoch [93/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2971 (0.2747) acc 96.8750 (93.5417) lr 1.1409e-03 eta 0:09:05
epoch [93/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3618 (0.2724) acc 93.7500 (93.6250) lr 1.1409e-03 eta 0:08:57
epoch [94/200] batch [5/51] time 0.086 (0.225) data 0.000 (0.138) loss 0.2522 (0.3206) acc 96.8750 (93.1250) lr 1.1253e-03 eta 0:20:24
epoch [94/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.1392 (0.3249) acc 100.0000 (92.5000) lr 1.1253e-03 eta 0:14:08
epoch [94/200] batch [15/51] time 0.086 (0.133) data 0.000 (0.046) loss 0.1423 (0.3213) acc 96.8750 (92.5000) lr 1.1253e-03 eta 0:12:01
epoch [94/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.035) loss 0.5244 (0.3449) acc 84.3750 (91.4062) lr 1.1253e-03 eta 0:10:58
epoch [94/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.2063 (0.3148) acc 93.7500 (92.3750) lr 1.1253e-03 eta 0:10:20
epoch [94/200] batch [30/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.2474 (0.3084) acc 93.7500 (92.6042) lr 1.1253e-03 eta 0:09:54
epoch [94/200] batch [35/51] time 0.091 (0.106) data 0.000 (0.020) loss 0.3079 (0.3056) acc 93.7500 (92.8571) lr 1.1253e-03 eta 0:09:37
epoch [94/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.5024 (0.3137) acc 90.6250 (92.6562) lr 1.1253e-03 eta 0:09:22
epoch [94/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3606 (0.3198) acc 87.5000 (92.3611) lr 1.1253e-03 eta 0:09:11
epoch [94/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2766 (0.3218) acc 93.7500 (92.3125) lr 1.1253e-03 eta 0:09:01
epoch [95/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.123) loss 0.2122 (0.2639) acc 100.0000 (94.3750) lr 1.1097e-03 eta 0:18:57
epoch [95/200] batch [10/51] time 0.088 (0.149) data 0.000 (0.062) loss 0.3093 (0.2500) acc 96.8750 (94.3750) lr 1.1097e-03 eta 0:13:24
epoch [95/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.3132 (0.3037) acc 96.8750 (93.1250) lr 1.1097e-03 eta 0:11:31
epoch [95/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.3416 (0.3167) acc 93.7500 (92.8125) lr 1.1097e-03 eta 0:10:35
epoch [95/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.5093 (0.3145) acc 90.6250 (93.1250) lr 1.1097e-03 eta 0:10:01
epoch [95/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3247 (0.3254) acc 90.6250 (92.8125) lr 1.1097e-03 eta 0:09:38
epoch [95/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3328 (0.3193) acc 93.7500 (92.9464) lr 1.1097e-03 eta 0:09:22
epoch [95/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.3752 (0.3207) acc 87.5000 (92.8125) lr 1.1097e-03 eta 0:09:09
epoch [95/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5259 (0.3235) acc 90.6250 (92.6389) lr 1.1097e-03 eta 0:08:59
epoch [95/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5908 (0.3298) acc 84.3750 (92.4375) lr 1.1097e-03 eta 0:08:51
epoch [96/200] batch [5/51] time 0.086 (0.202) data 0.001 (0.114) loss 0.3655 (0.2302) acc 87.5000 (93.7500) lr 1.0941e-03 eta 0:18:00
epoch [96/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.057) loss 0.1859 (0.2263) acc 96.8750 (94.0625) lr 1.0941e-03 eta 0:12:52
epoch [96/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.1270 (0.2523) acc 96.8750 (93.3333) lr 1.0941e-03 eta 0:11:09
epoch [96/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.029) loss 0.2473 (0.2937) acc 93.7500 (92.8125) lr 1.0941e-03 eta 0:10:17
epoch [96/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3867 (0.3103) acc 90.6250 (93.0000) lr 1.0941e-03 eta 0:09:47
epoch [96/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4277 (0.3160) acc 93.7500 (92.8125) lr 1.0941e-03 eta 0:09:26
epoch [96/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1949 (0.3022) acc 96.8750 (93.2143) lr 1.0941e-03 eta 0:09:10
epoch [96/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.6714 (0.3085) acc 84.3750 (92.8906) lr 1.0941e-03 eta 0:08:58
epoch [96/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4797 (0.3176) acc 87.5000 (92.5000) lr 1.0941e-03 eta 0:08:49
epoch [96/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.6377 (0.3196) acc 84.3750 (92.3750) lr 1.0941e-03 eta 0:08:41
epoch [97/200] batch [5/51] time 0.086 (0.214) data 0.000 (0.126) loss 0.2275 (0.2694) acc 96.8750 (93.1250) lr 1.0785e-03 eta 0:18:51
epoch [97/200] batch [10/51] time 0.088 (0.150) data 0.000 (0.063) loss 0.3269 (0.2674) acc 87.5000 (92.5000) lr 1.0785e-03 eta 0:13:14
epoch [97/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.1677 (0.2896) acc 100.0000 (92.2917) lr 1.0785e-03 eta 0:11:22
epoch [97/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.032) loss 0.2124 (0.2867) acc 96.8750 (92.8125) lr 1.0785e-03 eta 0:10:25
epoch [97/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3218 (0.2809) acc 90.6250 (93.0000) lr 1.0785e-03 eta 0:09:51
epoch [97/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2484 (0.2706) acc 90.6250 (93.3333) lr 1.0785e-03 eta 0:09:29
epoch [97/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3057 (0.2658) acc 90.6250 (93.5714) lr 1.0785e-03 eta 0:09:12
epoch [97/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2097 (0.2775) acc 96.8750 (93.3594) lr 1.0785e-03 eta 0:09:00
epoch [97/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3025 (0.2884) acc 90.6250 (93.0556) lr 1.0785e-03 eta 0:08:49
epoch [97/200] batch [50/51] time 0.088 (0.099) data 0.000 (0.013) loss 0.2089 (0.2997) acc 93.7500 (92.8125) lr 1.0785e-03 eta 0:08:41
epoch [98/200] batch [5/51] time 0.088 (0.208) data 0.000 (0.120) loss 0.1377 (0.2363) acc 96.8750 (95.0000) lr 1.0628e-03 eta 0:18:13
epoch [98/200] batch [10/51] time 0.088 (0.148) data 0.000 (0.060) loss 0.4160 (0.2829) acc 87.5000 (93.7500) lr 1.0628e-03 eta 0:12:57
epoch [98/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.040) loss 0.3740 (0.2872) acc 84.3750 (92.5000) lr 1.0628e-03 eta 0:11:09
epoch [98/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.2981 (0.3021) acc 90.6250 (92.3438) lr 1.0628e-03 eta 0:10:14
epoch [98/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4163 (0.3052) acc 87.5000 (92.5000) lr 1.0628e-03 eta 0:09:41
epoch [98/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1487 (0.3031) acc 96.8750 (92.1875) lr 1.0628e-03 eta 0:09:19
epoch [98/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2286 (0.3050) acc 96.8750 (92.4107) lr 1.0628e-03 eta 0:09:04
epoch [98/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2175 (0.3110) acc 93.7500 (92.3438) lr 1.0628e-03 eta 0:08:51
epoch [98/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3911 (0.3135) acc 93.7500 (92.4306) lr 1.0628e-03 eta 0:08:41
epoch [98/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1752 (0.3014) acc 96.8750 (92.7500) lr 1.0628e-03 eta 0:08:33
epoch [99/200] batch [5/51] time 0.087 (0.219) data 0.000 (0.132) loss 0.2079 (0.2815) acc 93.7500 (93.1250) lr 1.0471e-03 eta 0:18:57
epoch [99/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.2610 (0.2515) acc 96.8750 (94.6875) lr 1.0471e-03 eta 0:13:13
epoch [99/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.2200 (0.2856) acc 90.6250 (92.7083) lr 1.0471e-03 eta 0:11:18
epoch [99/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.2593 (0.2884) acc 96.8750 (93.1250) lr 1.0471e-03 eta 0:10:20
epoch [99/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.2491 (0.3063) acc 93.7500 (92.8750) lr 1.0471e-03 eta 0:09:45
epoch [99/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1437 (0.3106) acc 100.0000 (93.0208) lr 1.0471e-03 eta 0:09:22
epoch [99/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.2896 (0.3071) acc 93.7500 (93.1250) lr 1.0471e-03 eta 0:09:06
epoch [99/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.5762 (0.3119) acc 90.6250 (92.9688) lr 1.0471e-03 eta 0:08:52
epoch [99/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4688 (0.3137) acc 93.7500 (93.1250) lr 1.0471e-03 eta 0:08:42
epoch [99/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3201 (0.3130) acc 87.5000 (93.0000) lr 1.0471e-03 eta 0:08:33
epoch [100/200] batch [5/51] time 0.087 (0.224) data 0.000 (0.136) loss 0.2971 (0.2346) acc 96.8750 (96.2500) lr 1.0314e-03 eta 0:19:10
epoch [100/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.1860 (0.1972) acc 96.8750 (96.2500) lr 1.0314e-03 eta 0:13:19
epoch [100/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.4470 (0.2560) acc 84.3750 (94.3750) lr 1.0314e-03 eta 0:11:21
epoch [100/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.1980 (0.2735) acc 96.8750 (93.5938) lr 1.0314e-03 eta 0:10:22
epoch [100/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2296 (0.2621) acc 93.7500 (93.7500) lr 1.0314e-03 eta 0:09:46
epoch [100/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2456 (0.2822) acc 93.7500 (93.3333) lr 1.0314e-03 eta 0:09:22
epoch [100/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4314 (0.2747) acc 87.5000 (93.5714) lr 1.0314e-03 eta 0:09:05
epoch [100/200] batch [40/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.4033 (0.2779) acc 96.8750 (93.4375) lr 1.0314e-03 eta 0:08:52
epoch [100/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2400 (0.2866) acc 96.8750 (93.1250) lr 1.0314e-03 eta 0:08:41
epoch [100/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2015 (0.2968) acc 93.7500 (92.5625) lr 1.0314e-03 eta 0:08:32
epoch [101/200] batch [5/51] time 0.088 (0.207) data 0.000 (0.119) loss 0.4377 (0.2434) acc 90.6250 (95.0000) lr 1.0157e-03 eta 0:17:34
epoch [101/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.1881 (0.3115) acc 96.8750 (92.8125) lr 1.0157e-03 eta 0:12:28
epoch [101/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.3008 (0.3096) acc 93.7500 (92.9167) lr 1.0157e-03 eta 0:10:46
epoch [101/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.030) loss 0.3264 (0.3075) acc 87.5000 (92.6562) lr 1.0157e-03 eta 0:09:54
epoch [101/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.2126 (0.3068) acc 93.7500 (92.6250) lr 1.0157e-03 eta 0:09:23
epoch [101/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3032 (0.3076) acc 96.8750 (92.8125) lr 1.0157e-03 eta 0:09:02
epoch [101/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1569 (0.3036) acc 100.0000 (93.1250) lr 1.0157e-03 eta 0:08:47
epoch [101/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1257 (0.3007) acc 100.0000 (93.3594) lr 1.0157e-03 eta 0:08:35
epoch [101/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2236 (0.3038) acc 93.7500 (93.2639) lr 1.0157e-03 eta 0:08:26
epoch [101/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3289 (0.3009) acc 93.7500 (93.3125) lr 1.0157e-03 eta 0:08:18
epoch [102/200] batch [5/51] time 0.086 (0.225) data 0.000 (0.137) loss 0.5117 (0.3695) acc 84.3750 (91.2500) lr 1.0000e-03 eta 0:18:52
epoch [102/200] batch [10/51] time 0.086 (0.156) data 0.000 (0.069) loss 0.3894 (0.2996) acc 90.6250 (93.1250) lr 1.0000e-03 eta 0:13:03
epoch [102/200] batch [15/51] time 0.086 (0.132) data 0.000 (0.046) loss 0.6191 (0.3181) acc 81.2500 (92.5000) lr 1.0000e-03 eta 0:11:06
epoch [102/200] batch [20/51] time 0.086 (0.121) data 0.000 (0.035) loss 0.6987 (0.3761) acc 87.5000 (91.8750) lr 1.0000e-03 eta 0:10:08
epoch [102/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.028) loss 0.3477 (0.3567) acc 90.6250 (92.0000) lr 1.0000e-03 eta 0:09:32
epoch [102/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.023) loss 0.2629 (0.3382) acc 93.7500 (92.2917) lr 1.0000e-03 eta 0:09:08
epoch [102/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.020) loss 0.1207 (0.3194) acc 100.0000 (93.0357) lr 1.0000e-03 eta 0:08:52
epoch [102/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2671 (0.3084) acc 93.7500 (93.2812) lr 1.0000e-03 eta 0:08:39
epoch [102/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1340 (0.3094) acc 100.0000 (93.2639) lr 1.0000e-03 eta 0:08:28
epoch [102/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2974 (0.3106) acc 96.8750 (93.3125) lr 1.0000e-03 eta 0:08:20
epoch [103/200] batch [5/51] time 0.088 (0.210) data 0.000 (0.121) loss 0.3948 (0.3281) acc 90.6250 (91.2500) lr 9.8429e-04 eta 0:17:28
epoch [103/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.061) loss 0.2003 (0.3098) acc 96.8750 (92.5000) lr 9.8429e-04 eta 0:12:21
epoch [103/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.4675 (0.3019) acc 87.5000 (92.0833) lr 9.8429e-04 eta 0:10:38
epoch [103/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.2878 (0.2874) acc 93.7500 (92.8125) lr 9.8429e-04 eta 0:09:46
epoch [103/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.4321 (0.3114) acc 87.5000 (91.8750) lr 9.8429e-04 eta 0:09:15
epoch [103/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.020) loss 0.3643 (0.3258) acc 96.8750 (91.9792) lr 9.8429e-04 eta 0:08:54
epoch [103/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.0937 (0.3211) acc 96.8750 (91.6964) lr 9.8429e-04 eta 0:08:39
epoch [103/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3254 (0.3168) acc 90.6250 (91.7969) lr 9.8429e-04 eta 0:08:27
epoch [103/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1096 (0.3189) acc 100.0000 (91.9444) lr 9.8429e-04 eta 0:08:17
epoch [103/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1541 (0.3136) acc 100.0000 (92.2500) lr 9.8429e-04 eta 0:08:10
epoch [104/200] batch [5/51] time 0.088 (0.199) data 0.000 (0.110) loss 0.1064 (0.1696) acc 100.0000 (97.5000) lr 9.6859e-04 eta 0:16:23
epoch [104/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.055) loss 0.5356 (0.2144) acc 90.6250 (96.5625) lr 9.6859e-04 eta 0:11:46
epoch [104/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.3010 (0.2722) acc 93.7500 (95.0000) lr 9.6859e-04 eta 0:10:13
epoch [104/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2832 (0.2973) acc 90.6250 (93.7500) lr 9.6859e-04 eta 0:09:26
epoch [104/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3186 (0.2995) acc 90.6250 (93.3750) lr 9.6859e-04 eta 0:08:58
epoch [104/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2499 (0.2924) acc 87.5000 (93.1250) lr 9.6859e-04 eta 0:08:39
epoch [104/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3799 (0.2940) acc 87.5000 (92.9464) lr 9.6859e-04 eta 0:08:25
epoch [104/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3901 (0.3006) acc 90.6250 (92.8125) lr 9.6859e-04 eta 0:08:14
epoch [104/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5435 (0.3053) acc 81.2500 (92.5000) lr 9.6859e-04 eta 0:08:06
epoch [104/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2380 (0.3067) acc 90.6250 (92.4375) lr 9.6859e-04 eta 0:07:59
epoch [105/200] batch [5/51] time 0.086 (0.207) data 0.000 (0.120) loss 0.0974 (0.2072) acc 100.0000 (95.0000) lr 9.5289e-04 eta 0:16:51
epoch [105/200] batch [10/51] time 0.086 (0.147) data 0.000 (0.060) loss 0.1423 (0.2523) acc 96.8750 (94.0625) lr 9.5289e-04 eta 0:11:56
epoch [105/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.3240 (0.2441) acc 90.6250 (94.3750) lr 9.5289e-04 eta 0:10:18
epoch [105/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.1575 (0.2621) acc 96.8750 (93.9062) lr 9.5289e-04 eta 0:09:29
epoch [105/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.2324 (0.2705) acc 90.6250 (93.2500) lr 9.5289e-04 eta 0:08:59
epoch [105/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3782 (0.2852) acc 90.6250 (92.9167) lr 9.5289e-04 eta 0:08:39
epoch [105/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.0994 (0.2860) acc 100.0000 (93.0357) lr 9.5289e-04 eta 0:08:24
epoch [105/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2354 (0.2841) acc 93.7500 (93.2812) lr 9.5289e-04 eta 0:08:13
epoch [105/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2390 (0.2857) acc 96.8750 (93.4028) lr 9.5289e-04 eta 0:08:04
epoch [105/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2639 (0.2806) acc 93.7500 (93.5000) lr 9.5289e-04 eta 0:07:57
epoch [106/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.114) loss 0.6016 (0.4843) acc 87.5000 (86.8750) lr 9.3721e-04 eta 0:16:16
epoch [106/200] batch [10/51] time 0.088 (0.145) data 0.000 (0.057) loss 0.3259 (0.4101) acc 96.8750 (90.0000) lr 9.3721e-04 eta 0:11:39
epoch [106/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.1953 (0.3752) acc 90.6250 (91.2500) lr 9.3721e-04 eta 0:10:06
epoch [106/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3506 (0.3458) acc 87.5000 (91.4062) lr 9.3721e-04 eta 0:09:19
epoch [106/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.2136 (0.3425) acc 93.7500 (91.2500) lr 9.3721e-04 eta 0:08:51
epoch [106/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3418 (0.3246) acc 87.5000 (91.6667) lr 9.3721e-04 eta 0:08:32
epoch [106/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3547 (0.3190) acc 93.7500 (92.3214) lr 9.3721e-04 eta 0:08:18
epoch [106/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2769 (0.3159) acc 93.7500 (92.4219) lr 9.3721e-04 eta 0:08:07
epoch [106/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4197 (0.3185) acc 87.5000 (92.5694) lr 9.3721e-04 eta 0:07:58
epoch [106/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3499 (0.3177) acc 90.6250 (92.3750) lr 9.3721e-04 eta 0:07:51
epoch [107/200] batch [5/51] time 0.086 (0.214) data 0.000 (0.126) loss 0.3101 (0.2943) acc 87.5000 (92.5000) lr 9.2154e-04 eta 0:17:03
epoch [107/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.3398 (0.2999) acc 93.7500 (93.7500) lr 9.2154e-04 eta 0:11:58
epoch [107/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.1052 (0.3048) acc 100.0000 (93.7500) lr 9.2154e-04 eta 0:10:15
epoch [107/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.032) loss 0.4380 (0.3291) acc 87.5000 (92.8125) lr 9.2154e-04 eta 0:09:25
epoch [107/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1726 (0.3391) acc 96.8750 (92.6250) lr 9.2154e-04 eta 0:08:54
epoch [107/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3677 (0.3238) acc 87.5000 (93.0208) lr 9.2154e-04 eta 0:08:33
epoch [107/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.3860 (0.3227) acc 90.6250 (93.1250) lr 9.2154e-04 eta 0:08:18
epoch [107/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.1609 (0.3200) acc 100.0000 (93.1250) lr 9.2154e-04 eta 0:08:07
epoch [107/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3313 (0.3122) acc 93.7500 (93.3333) lr 9.2154e-04 eta 0:07:57
epoch [107/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.2876 (0.3071) acc 90.6250 (93.3125) lr 9.2154e-04 eta 0:07:50
epoch [108/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.113) loss 0.1206 (0.2694) acc 100.0000 (96.2500) lr 9.0589e-04 eta 0:15:52
epoch [108/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.1627 (0.2782) acc 100.0000 (94.0625) lr 9.0589e-04 eta 0:11:23
epoch [108/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.038) loss 0.1074 (0.2738) acc 100.0000 (94.1667) lr 9.0589e-04 eta 0:09:52
epoch [108/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.2549 (0.2660) acc 93.7500 (94.3750) lr 9.0589e-04 eta 0:09:06
epoch [108/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.1842 (0.3103) acc 96.8750 (93.1250) lr 9.0589e-04 eta 0:08:39
epoch [108/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1344 (0.2959) acc 100.0000 (93.1250) lr 9.0589e-04 eta 0:08:20
epoch [108/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4260 (0.2858) acc 90.6250 (93.3036) lr 9.0589e-04 eta 0:08:07
epoch [108/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.3909 (0.3018) acc 87.5000 (92.9688) lr 9.0589e-04 eta 0:07:56
epoch [108/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3889 (0.3118) acc 93.7500 (92.5000) lr 9.0589e-04 eta 0:07:47
epoch [108/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3777 (0.3152) acc 93.7500 (92.3750) lr 9.0589e-04 eta 0:07:40
epoch [109/200] batch [5/51] time 0.086 (0.225) data 0.000 (0.138) loss 0.3169 (0.2929) acc 90.6250 (92.5000) lr 8.9027e-04 eta 0:17:35
epoch [109/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.4277 (0.3020) acc 87.5000 (91.5625) lr 8.9027e-04 eta 0:12:10
epoch [109/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.3472 (0.2858) acc 93.7500 (92.7083) lr 8.9027e-04 eta 0:10:21
epoch [109/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.035) loss 0.5479 (0.3246) acc 87.5000 (91.5625) lr 8.9027e-04 eta 0:09:27
epoch [109/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3354 (0.3284) acc 90.6250 (92.0000) lr 8.9027e-04 eta 0:08:54
epoch [109/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2998 (0.3151) acc 90.6250 (92.2917) lr 8.9027e-04 eta 0:08:32
epoch [109/200] batch [35/51] time 0.086 (0.107) data 0.000 (0.020) loss 0.1184 (0.3013) acc 96.8750 (92.5000) lr 8.9027e-04 eta 0:08:16
epoch [109/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.1802 (0.3000) acc 96.8750 (92.5781) lr 8.9027e-04 eta 0:08:03
epoch [109/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.3870 (0.3097) acc 96.8750 (92.6389) lr 8.9027e-04 eta 0:07:53
epoch [109/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1162 (0.3120) acc 96.8750 (92.3750) lr 8.9027e-04 eta 0:07:46
epoch [110/200] batch [5/51] time 0.088 (0.202) data 0.000 (0.114) loss 0.1582 (0.2769) acc 96.8750 (92.5000) lr 8.7467e-04 eta 0:15:35
epoch [110/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.3125 (0.2831) acc 90.6250 (91.5625) lr 8.7467e-04 eta 0:11:08
epoch [110/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.0873 (0.2737) acc 100.0000 (92.7083) lr 8.7467e-04 eta 0:09:39
epoch [110/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.1628 (0.2790) acc 93.7500 (92.1875) lr 8.7467e-04 eta 0:08:54
epoch [110/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.1924 (0.2772) acc 93.7500 (92.2500) lr 8.7467e-04 eta 0:08:27
epoch [110/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.2058 (0.2766) acc 100.0000 (92.6042) lr 8.7467e-04 eta 0:08:09
epoch [110/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2029 (0.2743) acc 96.8750 (92.7679) lr 8.7467e-04 eta 0:07:56
epoch [110/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.1017 (0.2827) acc 100.0000 (92.5781) lr 8.7467e-04 eta 0:07:46
epoch [110/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1658 (0.2850) acc 96.8750 (92.6389) lr 8.7467e-04 eta 0:07:38
epoch [110/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.4231 (0.2855) acc 93.7500 (92.8125) lr 8.7467e-04 eta 0:07:31
epoch [111/200] batch [5/51] time 0.088 (0.194) data 0.000 (0.106) loss 0.5259 (0.2977) acc 84.3750 (93.7500) lr 8.5910e-04 eta 0:14:50
epoch [111/200] batch [10/51] time 0.087 (0.141) data 0.000 (0.053) loss 0.3323 (0.2960) acc 96.8750 (93.4375) lr 8.5910e-04 eta 0:10:44
epoch [111/200] batch [15/51] time 0.087 (0.123) data 0.000 (0.036) loss 0.4729 (0.3460) acc 90.6250 (92.5000) lr 8.5910e-04 eta 0:09:21
epoch [111/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.1990 (0.3310) acc 96.8750 (92.9688) lr 8.5910e-04 eta 0:08:40
epoch [111/200] batch [25/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.1595 (0.3208) acc 93.7500 (92.8750) lr 8.5910e-04 eta 0:08:15
epoch [111/200] batch [30/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.4043 (0.3206) acc 87.5000 (92.3958) lr 8.5910e-04 eta 0:07:58
epoch [111/200] batch [35/51] time 0.089 (0.103) data 0.000 (0.015) loss 0.1438 (0.3173) acc 100.0000 (92.5893) lr 8.5910e-04 eta 0:07:46
epoch [111/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2900 (0.3241) acc 93.7500 (92.3438) lr 8.5910e-04 eta 0:07:37
epoch [111/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2573 (0.3199) acc 93.7500 (92.3611) lr 8.5910e-04 eta 0:07:29
epoch [111/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3540 (0.3178) acc 96.8750 (92.5000) lr 8.5910e-04 eta 0:07:23
epoch [112/200] batch [5/51] time 0.088 (0.210) data 0.001 (0.121) loss 0.1589 (0.2500) acc 96.8750 (93.7500) lr 8.4357e-04 eta 0:15:52
epoch [112/200] batch [10/51] time 0.088 (0.149) data 0.000 (0.061) loss 0.2120 (0.2928) acc 90.6250 (91.2500) lr 8.4357e-04 eta 0:11:13
epoch [112/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.3611 (0.3126) acc 93.7500 (92.0833) lr 8.4357e-04 eta 0:09:39
epoch [112/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.6494 (0.3209) acc 87.5000 (92.3438) lr 8.4357e-04 eta 0:08:52
epoch [112/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.024) loss 0.8174 (0.3592) acc 81.2500 (91.5000) lr 8.4357e-04 eta 0:08:24
epoch [112/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.020) loss 0.3538 (0.3366) acc 90.6250 (92.1875) lr 8.4357e-04 eta 0:08:05
epoch [112/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.6538 (0.3414) acc 87.5000 (92.0536) lr 8.4357e-04 eta 0:07:51
epoch [112/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.0848 (0.3430) acc 100.0000 (91.9531) lr 8.4357e-04 eta 0:07:40
epoch [112/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1879 (0.3318) acc 90.6250 (92.0139) lr 8.4357e-04 eta 0:07:32
epoch [112/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5542 (0.3280) acc 87.5000 (92.1875) lr 8.4357e-04 eta 0:07:25
epoch [113/200] batch [5/51] time 0.087 (0.215) data 0.000 (0.128) loss 0.4182 (0.5165) acc 93.7500 (90.0000) lr 8.2807e-04 eta 0:16:04
epoch [113/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.2333 (0.3552) acc 93.7500 (93.1250) lr 8.2807e-04 eta 0:11:15
epoch [113/200] batch [15/51] time 0.086 (0.129) data 0.000 (0.043) loss 0.3870 (0.3380) acc 90.6250 (93.5417) lr 8.2807e-04 eta 0:09:38
epoch [113/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.2477 (0.3377) acc 93.7500 (93.1250) lr 8.2807e-04 eta 0:08:50
epoch [113/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.026) loss 0.3250 (0.3302) acc 93.7500 (93.1250) lr 8.2807e-04 eta 0:08:21
epoch [113/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.022) loss 0.0706 (0.3274) acc 100.0000 (93.1250) lr 8.2807e-04 eta 0:08:02
epoch [113/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1554 (0.3317) acc 96.8750 (93.1250) lr 8.2807e-04 eta 0:07:48
epoch [113/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2942 (0.3361) acc 87.5000 (92.6562) lr 8.2807e-04 eta 0:07:36
epoch [113/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1272 (0.3251) acc 96.8750 (92.8472) lr 8.2807e-04 eta 0:07:28
epoch [113/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3420 (0.3259) acc 93.7500 (92.8125) lr 8.2807e-04 eta 0:07:20
epoch [114/200] batch [5/51] time 0.087 (0.210) data 0.000 (0.122) loss 0.3870 (0.2677) acc 90.6250 (93.1250) lr 8.1262e-04 eta 0:15:29
epoch [114/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.1525 (0.2169) acc 100.0000 (94.3750) lr 8.1262e-04 eta 0:10:56
epoch [114/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.4304 (0.2422) acc 87.5000 (93.9583) lr 8.1262e-04 eta 0:09:24
epoch [114/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.031) loss 0.1781 (0.2556) acc 93.7500 (93.7500) lr 8.1262e-04 eta 0:08:38
epoch [114/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.025) loss 0.2617 (0.2821) acc 93.7500 (93.1250) lr 8.1262e-04 eta 0:08:11
epoch [114/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.020) loss 0.3774 (0.3119) acc 93.7500 (92.6042) lr 8.1262e-04 eta 0:07:52
epoch [114/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.1417 (0.3111) acc 93.7500 (92.6786) lr 8.1262e-04 eta 0:07:38
epoch [114/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.4402 (0.3173) acc 87.5000 (92.5000) lr 8.1262e-04 eta 0:07:28
epoch [114/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2000 (0.3231) acc 96.8750 (92.7083) lr 8.1262e-04 eta 0:07:19
epoch [114/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2017 (0.3242) acc 93.7500 (92.6875) lr 8.1262e-04 eta 0:07:12
epoch [115/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.124) loss 0.2878 (0.2286) acc 90.6250 (92.5000) lr 7.9721e-04 eta 0:15:30
epoch [115/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.062) loss 0.4573 (0.3017) acc 90.6250 (92.1875) lr 7.9721e-04 eta 0:10:56
epoch [115/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.4207 (0.2688) acc 87.5000 (93.3333) lr 7.9721e-04 eta 0:09:24
epoch [115/200] batch [20/51] time 0.088 (0.119) data 0.000 (0.031) loss 0.1218 (0.2893) acc 100.0000 (92.8125) lr 7.9721e-04 eta 0:08:38
epoch [115/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.3147 (0.3041) acc 93.7500 (92.2500) lr 7.9721e-04 eta 0:08:09
epoch [115/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.4492 (0.3105) acc 87.5000 (92.1875) lr 7.9721e-04 eta 0:07:50
epoch [115/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.1870 (0.3070) acc 90.6250 (92.1429) lr 7.9721e-04 eta 0:07:37
epoch [115/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2937 (0.3012) acc 96.8750 (92.5000) lr 7.9721e-04 eta 0:07:26
epoch [115/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3582 (0.3122) acc 93.7500 (92.4306) lr 7.9721e-04 eta 0:07:17
epoch [115/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2396 (0.3084) acc 100.0000 (92.8125) lr 7.9721e-04 eta 0:07:10
epoch [116/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.124) loss 0.3281 (0.3401) acc 90.6250 (91.2500) lr 7.8186e-04 eta 0:15:16
epoch [116/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.062) loss 0.1379 (0.3294) acc 100.0000 (91.5625) lr 7.8186e-04 eta 0:10:47
epoch [116/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.3936 (0.3267) acc 84.3750 (91.4583) lr 7.8186e-04 eta 0:09:16
epoch [116/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.1667 (0.3093) acc 96.8750 (91.5625) lr 7.8186e-04 eta 0:08:31
epoch [116/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2957 (0.3141) acc 93.7500 (92.0000) lr 7.8186e-04 eta 0:08:03
epoch [116/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.021) loss 0.6719 (0.3165) acc 78.1250 (92.1875) lr 7.8186e-04 eta 0:07:45
epoch [116/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.2466 (0.3057) acc 93.7500 (92.5893) lr 7.8186e-04 eta 0:07:31
epoch [116/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2517 (0.3048) acc 93.7500 (92.8125) lr 7.8186e-04 eta 0:07:21
epoch [116/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3689 (0.3055) acc 87.5000 (92.6389) lr 7.8186e-04 eta 0:07:12
epoch [116/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2544 (0.3160) acc 93.7500 (92.3125) lr 7.8186e-04 eta 0:07:05
epoch [117/200] batch [5/51] time 0.088 (0.204) data 0.000 (0.116) loss 0.2334 (0.2442) acc 93.7500 (93.7500) lr 7.6655e-04 eta 0:14:32
epoch [117/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.5210 (0.3884) acc 90.6250 (92.5000) lr 7.6655e-04 eta 0:10:21
epoch [117/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.039) loss 0.2671 (0.3372) acc 96.8750 (93.5417) lr 7.6655e-04 eta 0:08:57
epoch [117/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.1588 (0.3110) acc 96.8750 (93.5938) lr 7.6655e-04 eta 0:08:15
epoch [117/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2068 (0.2966) acc 90.6250 (93.8750) lr 7.6655e-04 eta 0:07:49
epoch [117/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.020) loss 0.1899 (0.2910) acc 96.8750 (94.1667) lr 7.6655e-04 eta 0:07:32
epoch [117/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3850 (0.2850) acc 93.7500 (93.9286) lr 7.6655e-04 eta 0:07:20
epoch [117/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3621 (0.2932) acc 84.3750 (93.2812) lr 7.6655e-04 eta 0:07:10
epoch [117/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3728 (0.2937) acc 93.7500 (93.2639) lr 7.6655e-04 eta 0:07:02
epoch [117/200] batch [50/51] time 0.088 (0.098) data 0.000 (0.012) loss 0.2009 (0.2898) acc 96.8750 (93.4375) lr 7.6655e-04 eta 0:06:56
epoch [118/200] batch [5/51] time 0.087 (0.225) data 0.000 (0.137) loss 0.2389 (0.2092) acc 90.6250 (94.3750) lr 7.5131e-04 eta 0:15:51
epoch [118/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.2766 (0.2863) acc 93.7500 (94.0625) lr 7.5131e-04 eta 0:10:59
epoch [118/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.1418 (0.2788) acc 96.8750 (93.9583) lr 7.5131e-04 eta 0:09:21
epoch [118/200] batch [20/51] time 0.088 (0.122) data 0.000 (0.034) loss 0.2153 (0.3085) acc 93.7500 (92.8125) lr 7.5131e-04 eta 0:08:33
epoch [118/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.1155 (0.2973) acc 96.8750 (93.1250) lr 7.5131e-04 eta 0:08:03
epoch [118/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1445 (0.2903) acc 100.0000 (93.6458) lr 7.5131e-04 eta 0:07:43
epoch [118/200] batch [35/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.2385 (0.2975) acc 96.8750 (93.4821) lr 7.5131e-04 eta 0:07:29
epoch [118/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2157 (0.2982) acc 96.8750 (93.2812) lr 7.5131e-04 eta 0:07:18
epoch [118/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3406 (0.2980) acc 90.6250 (93.0556) lr 7.5131e-04 eta 0:07:08
epoch [118/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2671 (0.3018) acc 96.8750 (92.7500) lr 7.5131e-04 eta 0:07:01
epoch [119/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.1171 (0.2856) acc 100.0000 (92.5000) lr 7.3613e-04 eta 0:13:45
epoch [119/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.1967 (0.2646) acc 96.8750 (93.4375) lr 7.3613e-04 eta 0:09:54
epoch [119/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.1989 (0.2425) acc 93.7500 (93.9583) lr 7.3613e-04 eta 0:08:36
epoch [119/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2566 (0.2974) acc 96.8750 (92.8125) lr 7.3613e-04 eta 0:07:57
epoch [119/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1705 (0.2946) acc 96.8750 (92.3750) lr 7.3613e-04 eta 0:07:33
epoch [119/200] batch [30/51] time 0.088 (0.105) data 0.000 (0.019) loss 0.3867 (0.3122) acc 96.8750 (92.3958) lr 7.3613e-04 eta 0:07:17
epoch [119/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3066 (0.3043) acc 93.7500 (92.9464) lr 7.3613e-04 eta 0:07:06
epoch [119/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2627 (0.3003) acc 93.7500 (93.0469) lr 7.3613e-04 eta 0:06:57
epoch [119/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.0970 (0.3008) acc 100.0000 (93.1250) lr 7.3613e-04 eta 0:06:49
epoch [119/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2771 (0.3035) acc 90.6250 (92.7500) lr 7.3613e-04 eta 0:06:43
epoch [120/200] batch [5/51] time 0.088 (0.205) data 0.000 (0.117) loss 0.1901 (0.2911) acc 93.7500 (93.1250) lr 7.2101e-04 eta 0:14:05
epoch [120/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.1198 (0.2670) acc 96.8750 (94.0625) lr 7.2101e-04 eta 0:10:02
epoch [120/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.2062 (0.2906) acc 96.8750 (93.9583) lr 7.2101e-04 eta 0:08:40
epoch [120/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3396 (0.2872) acc 87.5000 (93.5938) lr 7.2101e-04 eta 0:07:59
epoch [120/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.6372 (0.3030) acc 87.5000 (93.7500) lr 7.2101e-04 eta 0:07:34
epoch [120/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.5088 (0.3017) acc 84.3750 (93.4375) lr 7.2101e-04 eta 0:07:17
epoch [120/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.4456 (0.3196) acc 87.5000 (92.7679) lr 7.2101e-04 eta 0:07:05
epoch [120/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.5410 (0.3189) acc 87.5000 (92.6562) lr 7.2101e-04 eta 0:06:55
epoch [120/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1824 (0.3094) acc 96.8750 (92.7778) lr 7.2101e-04 eta 0:06:48
epoch [120/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2959 (0.3036) acc 96.8750 (93.0625) lr 7.2101e-04 eta 0:06:41
epoch [121/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.113) loss 0.6519 (0.3402) acc 87.5000 (92.5000) lr 7.0596e-04 eta 0:13:41
epoch [121/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.4944 (0.4005) acc 87.5000 (90.3125) lr 7.0596e-04 eta 0:09:47
epoch [121/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.038) loss 0.2001 (0.3624) acc 96.8750 (91.2500) lr 7.0596e-04 eta 0:08:29
epoch [121/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3044 (0.3530) acc 87.5000 (91.0938) lr 7.0596e-04 eta 0:07:50
epoch [121/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.2424 (0.3424) acc 90.6250 (90.8750) lr 7.0596e-04 eta 0:07:26
epoch [121/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3853 (0.3413) acc 87.5000 (91.0417) lr 7.0596e-04 eta 0:07:10
epoch [121/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.016) loss 0.0949 (0.3304) acc 100.0000 (91.5179) lr 7.0596e-04 eta 0:06:59
epoch [121/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3323 (0.3179) acc 96.8750 (92.1094) lr 7.0596e-04 eta 0:06:49
epoch [121/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4141 (0.3208) acc 84.3750 (92.0833) lr 7.0596e-04 eta 0:06:42
epoch [121/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3555 (0.3154) acc 93.7500 (92.3750) lr 7.0596e-04 eta 0:06:36
epoch [122/200] batch [5/51] time 0.086 (0.210) data 0.000 (0.122) loss 0.2290 (0.2057) acc 93.7500 (93.7500) lr 6.9098e-04 eta 0:14:03
epoch [122/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.3992 (0.2081) acc 87.5000 (94.6875) lr 6.9098e-04 eta 0:09:56
epoch [122/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.1487 (0.2389) acc 93.7500 (93.9583) lr 6.9098e-04 eta 0:08:33
epoch [122/200] batch [20/51] time 0.088 (0.118) data 0.000 (0.031) loss 0.1920 (0.2618) acc 93.7500 (93.1250) lr 6.9098e-04 eta 0:07:52
epoch [122/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1039 (0.2563) acc 96.8750 (93.3750) lr 6.9098e-04 eta 0:07:26
epoch [122/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.1969 (0.2726) acc 96.8750 (93.1250) lr 6.9098e-04 eta 0:07:09
epoch [122/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.1879 (0.2715) acc 96.8750 (93.4821) lr 6.9098e-04 eta 0:06:57
epoch [122/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.6084 (0.2824) acc 84.3750 (93.4375) lr 6.9098e-04 eta 0:06:47
epoch [122/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.6709 (0.2876) acc 78.1250 (93.1250) lr 6.9098e-04 eta 0:06:39
epoch [122/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1785 (0.2777) acc 100.0000 (93.5625) lr 6.9098e-04 eta 0:06:33
epoch [123/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.123) loss 0.3391 (0.3140) acc 90.6250 (92.5000) lr 6.7608e-04 eta 0:13:56
epoch [123/200] batch [10/51] time 0.088 (0.149) data 0.000 (0.061) loss 0.3074 (0.2741) acc 90.6250 (93.1250) lr 6.7608e-04 eta 0:09:51
epoch [123/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.1436 (0.2712) acc 96.8750 (93.1250) lr 6.7608e-04 eta 0:08:28
epoch [123/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.4067 (0.2618) acc 81.2500 (93.2812) lr 6.7608e-04 eta 0:07:47
epoch [123/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2389 (0.2508) acc 96.8750 (93.7500) lr 6.7608e-04 eta 0:07:22
epoch [123/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2201 (0.2615) acc 90.6250 (93.1250) lr 6.7608e-04 eta 0:07:05
epoch [123/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.3391 (0.2699) acc 87.5000 (92.9464) lr 6.7608e-04 eta 0:06:53
epoch [123/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.1830 (0.2832) acc 100.0000 (92.5781) lr 6.7608e-04 eta 0:06:43
epoch [123/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3181 (0.2830) acc 90.6250 (92.9861) lr 6.7608e-04 eta 0:06:35
epoch [123/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3501 (0.2769) acc 90.6250 (93.2500) lr 6.7608e-04 eta 0:06:29
epoch [124/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.1749 (0.2254) acc 96.8750 (95.0000) lr 6.6126e-04 eta 0:13:19
epoch [124/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.3389 (0.2321) acc 87.5000 (93.7500) lr 6.6126e-04 eta 0:09:29
epoch [124/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.2351 (0.2983) acc 96.8750 (92.9167) lr 6.6126e-04 eta 0:08:12
epoch [124/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.2357 (0.3052) acc 93.7500 (93.1250) lr 6.6126e-04 eta 0:07:33
epoch [124/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3147 (0.3059) acc 93.7500 (93.1250) lr 6.6126e-04 eta 0:07:10
epoch [124/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1475 (0.2989) acc 100.0000 (93.4375) lr 6.6126e-04 eta 0:06:54
epoch [124/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1458 (0.2907) acc 96.8750 (93.5714) lr 6.6126e-04 eta 0:06:43
epoch [124/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2283 (0.2907) acc 93.7500 (93.4375) lr 6.6126e-04 eta 0:06:34
epoch [124/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.2113 (0.2855) acc 96.8750 (93.4028) lr 6.6126e-04 eta 0:06:26
epoch [124/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2676 (0.2958) acc 90.6250 (93.1250) lr 6.6126e-04 eta 0:06:20
epoch [125/200] batch [5/51] time 0.088 (0.195) data 0.000 (0.107) loss 0.3257 (0.3493) acc 90.6250 (90.0000) lr 6.4653e-04 eta 0:12:35
epoch [125/200] batch [10/51] time 0.087 (0.141) data 0.000 (0.054) loss 0.2510 (0.3550) acc 96.8750 (89.6875) lr 6.4653e-04 eta 0:09:05
epoch [125/200] batch [15/51] time 0.087 (0.123) data 0.000 (0.036) loss 0.2468 (0.3230) acc 90.6250 (90.6250) lr 6.4653e-04 eta 0:07:55
epoch [125/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3506 (0.3112) acc 93.7500 (91.5625) lr 6.4653e-04 eta 0:07:19
epoch [125/200] batch [25/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.4570 (0.3000) acc 87.5000 (92.1250) lr 6.4653e-04 eta 0:06:59
epoch [125/200] batch [30/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.1970 (0.3062) acc 93.7500 (91.7708) lr 6.4653e-04 eta 0:06:44
epoch [125/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2257 (0.3010) acc 93.7500 (91.7857) lr 6.4653e-04 eta 0:06:34
epoch [125/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3459 (0.2958) acc 96.8750 (92.1094) lr 6.4653e-04 eta 0:06:26
epoch [125/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4773 (0.3102) acc 90.6250 (91.7361) lr 6.4653e-04 eta 0:06:19
epoch [125/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3101 (0.3105) acc 93.7500 (91.8750) lr 6.4653e-04 eta 0:06:13
epoch [126/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.129) loss 0.2634 (0.2963) acc 93.7500 (92.5000) lr 6.3188e-04 eta 0:13:47
epoch [126/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.6289 (0.3714) acc 81.2500 (91.2500) lr 6.3188e-04 eta 0:09:39
epoch [126/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.1907 (0.3294) acc 96.8750 (92.0833) lr 6.3188e-04 eta 0:08:16
epoch [126/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.3716 (0.3248) acc 93.7500 (92.3438) lr 6.3188e-04 eta 0:07:34
epoch [126/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.5288 (0.3279) acc 81.2500 (92.2500) lr 6.3188e-04 eta 0:07:09
epoch [126/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.5732 (0.3430) acc 84.3750 (92.0833) lr 6.3188e-04 eta 0:06:52
epoch [126/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1853 (0.3320) acc 93.7500 (92.5000) lr 6.3188e-04 eta 0:06:40
epoch [126/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4543 (0.3262) acc 87.5000 (92.6562) lr 6.3188e-04 eta 0:06:30
epoch [126/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3235 (0.3291) acc 90.6250 (92.2222) lr 6.3188e-04 eta 0:06:23
epoch [126/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2610 (0.3333) acc 96.8750 (92.1250) lr 6.3188e-04 eta 0:06:16
epoch [127/200] batch [5/51] time 0.088 (0.211) data 0.000 (0.124) loss 0.1272 (0.2528) acc 96.8750 (94.3750) lr 6.1732e-04 eta 0:13:15
epoch [127/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 0.2069 (0.2338) acc 96.8750 (95.0000) lr 6.1732e-04 eta 0:09:22
epoch [127/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.041) loss 0.2576 (0.2352) acc 96.8750 (94.7917) lr 6.1732e-04 eta 0:08:03
epoch [127/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.3694 (0.2538) acc 87.5000 (94.0625) lr 6.1732e-04 eta 0:07:23
epoch [127/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1975 (0.2632) acc 90.6250 (93.7500) lr 6.1732e-04 eta 0:06:59
epoch [127/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.1576 (0.2510) acc 100.0000 (94.4792) lr 6.1732e-04 eta 0:06:43
epoch [127/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1868 (0.2471) acc 96.8750 (94.6429) lr 6.1732e-04 eta 0:06:31
epoch [127/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2573 (0.2628) acc 96.8750 (94.1406) lr 6.1732e-04 eta 0:06:22
epoch [127/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2600 (0.2723) acc 93.7500 (94.0278) lr 6.1732e-04 eta 0:06:14
epoch [127/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4365 (0.2825) acc 90.6250 (93.8125) lr 6.1732e-04 eta 0:06:08
epoch [128/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.111) loss 0.1765 (0.2731) acc 93.7500 (91.8750) lr 6.0285e-04 eta 0:12:21
epoch [128/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.056) loss 0.4851 (0.3115) acc 87.5000 (91.5625) lr 6.0285e-04 eta 0:08:51
epoch [128/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.3435 (0.3038) acc 93.7500 (92.5000) lr 6.0285e-04 eta 0:07:40
epoch [128/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.028) loss 0.1033 (0.2907) acc 100.0000 (93.2812) lr 6.0285e-04 eta 0:07:05
epoch [128/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3362 (0.2982) acc 90.6250 (92.8750) lr 6.0285e-04 eta 0:06:44
epoch [128/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1824 (0.3073) acc 96.8750 (92.3958) lr 6.0285e-04 eta 0:06:29
epoch [128/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3914 (0.2968) acc 87.5000 (92.6786) lr 6.0285e-04 eta 0:06:19
epoch [128/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.2261 (0.2973) acc 96.8750 (92.8125) lr 6.0285e-04 eta 0:06:11
epoch [128/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.0723 (0.3023) acc 100.0000 (92.7083) lr 6.0285e-04 eta 0:06:04
epoch [128/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.2734 (0.2955) acc 96.8750 (92.8750) lr 6.0285e-04 eta 0:05:59
epoch [129/200] batch [5/51] time 0.088 (0.223) data 0.000 (0.135) loss 0.5474 (0.2133) acc 81.2500 (93.7500) lr 5.8849e-04 eta 0:13:37
epoch [129/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.3467 (0.2421) acc 90.6250 (93.1250) lr 5.8849e-04 eta 0:09:26
epoch [129/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.4048 (0.2373) acc 90.6250 (94.1667) lr 5.8849e-04 eta 0:08:03
epoch [129/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.1132 (0.2428) acc 96.8750 (94.2188) lr 5.8849e-04 eta 0:07:21
epoch [129/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2834 (0.2541) acc 90.6250 (94.0000) lr 5.8849e-04 eta 0:06:56
epoch [129/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2073 (0.2561) acc 93.7500 (93.8542) lr 5.8849e-04 eta 0:06:39
epoch [129/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.5088 (0.2688) acc 87.5000 (93.3929) lr 5.8849e-04 eta 0:06:27
epoch [129/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2245 (0.2632) acc 96.8750 (93.6719) lr 5.8849e-04 eta 0:06:17
epoch [129/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4590 (0.2705) acc 87.5000 (93.5417) lr 5.8849e-04 eta 0:06:09
epoch [129/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3496 (0.2802) acc 96.8750 (93.5625) lr 5.8849e-04 eta 0:06:03
epoch [130/200] batch [5/51] time 0.087 (0.207) data 0.000 (0.119) loss 0.2676 (0.1879) acc 93.7500 (96.2500) lr 5.7422e-04 eta 0:12:28
epoch [130/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.1638 (0.2193) acc 96.8750 (95.9375) lr 5.7422e-04 eta 0:08:50
epoch [130/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.2727 (0.2267) acc 93.7500 (95.2083) lr 5.7422e-04 eta 0:07:37
epoch [130/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.2114 (0.2147) acc 93.7500 (95.6250) lr 5.7422e-04 eta 0:06:59
epoch [130/200] batch [25/51] time 0.089 (0.111) data 0.000 (0.024) loss 0.4526 (0.2266) acc 93.7500 (95.5000) lr 5.7422e-04 eta 0:06:38
epoch [130/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.5806 (0.2462) acc 84.3750 (94.8958) lr 5.7422e-04 eta 0:06:23
epoch [130/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1334 (0.2422) acc 96.8750 (94.8214) lr 5.7422e-04 eta 0:06:12
epoch [130/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5615 (0.2597) acc 90.6250 (94.4531) lr 5.7422e-04 eta 0:06:03
epoch [130/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3533 (0.2625) acc 96.8750 (94.5139) lr 5.7422e-04 eta 0:05:56
epoch [130/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.5786 (0.2613) acc 81.2500 (94.5000) lr 5.7422e-04 eta 0:05:51
epoch [131/200] batch [5/51] time 0.086 (0.208) data 0.000 (0.121) loss 0.0799 (0.1834) acc 100.0000 (96.8750) lr 5.6006e-04 eta 0:12:21
epoch [131/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.061) loss 0.3135 (0.2636) acc 96.8750 (95.3125) lr 5.6006e-04 eta 0:08:44
epoch [131/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.2925 (0.2454) acc 90.6250 (95.0000) lr 5.6006e-04 eta 0:07:31
epoch [131/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2861 (0.2516) acc 90.6250 (94.3750) lr 5.6006e-04 eta 0:06:56
epoch [131/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.0991 (0.2665) acc 100.0000 (93.8750) lr 5.6006e-04 eta 0:06:34
epoch [131/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2411 (0.2620) acc 100.0000 (93.9583) lr 5.6006e-04 eta 0:06:19
epoch [131/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.1672 (0.2810) acc 96.8750 (93.5714) lr 5.6006e-04 eta 0:06:08
epoch [131/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.3066 (0.2821) acc 96.8750 (93.3594) lr 5.6006e-04 eta 0:05:59
epoch [131/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2294 (0.2807) acc 93.7500 (93.1250) lr 5.6006e-04 eta 0:05:52
epoch [131/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.1578 (0.2868) acc 96.8750 (93.1250) lr 5.6006e-04 eta 0:05:46
epoch [132/200] batch [5/51] time 0.086 (0.219) data 0.000 (0.132) loss 0.4487 (0.3028) acc 90.6250 (93.1250) lr 5.4601e-04 eta 0:12:49
epoch [132/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.2871 (0.3049) acc 96.8750 (93.4375) lr 5.4601e-04 eta 0:08:57
epoch [132/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.2732 (0.3253) acc 93.7500 (92.5000) lr 5.4601e-04 eta 0:07:39
epoch [132/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3457 (0.3297) acc 93.7500 (92.8125) lr 5.4601e-04 eta 0:06:59
epoch [132/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.2181 (0.3008) acc 90.6250 (93.1250) lr 5.4601e-04 eta 0:06:36
epoch [132/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2109 (0.3008) acc 93.7500 (93.1250) lr 5.4601e-04 eta 0:06:19
epoch [132/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.3149 (0.2966) acc 87.5000 (92.9464) lr 5.4601e-04 eta 0:06:08
epoch [132/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.2250 (0.2888) acc 96.8750 (93.1250) lr 5.4601e-04 eta 0:05:59
epoch [132/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1323 (0.2778) acc 96.8750 (93.1944) lr 5.4601e-04 eta 0:05:51
epoch [132/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3628 (0.2700) acc 90.6250 (93.5000) lr 5.4601e-04 eta 0:05:45
epoch [133/200] batch [5/51] time 0.088 (0.199) data 0.000 (0.110) loss 0.1492 (0.2387) acc 100.0000 (94.3750) lr 5.3207e-04 eta 0:11:27
epoch [133/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.055) loss 0.1823 (0.2279) acc 93.7500 (94.3750) lr 5.3207e-04 eta 0:08:14
epoch [133/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2458 (0.2494) acc 93.7500 (94.1667) lr 5.3207e-04 eta 0:07:09
epoch [133/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.1935 (0.2881) acc 93.7500 (93.1250) lr 5.3207e-04 eta 0:06:37
epoch [133/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.4382 (0.2908) acc 87.5000 (93.0000) lr 5.3207e-04 eta 0:06:17
epoch [133/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1931 (0.2906) acc 93.7500 (92.8125) lr 5.3207e-04 eta 0:06:04
epoch [133/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.1879 (0.2942) acc 96.8750 (93.0357) lr 5.3207e-04 eta 0:05:54
epoch [133/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4534 (0.3001) acc 93.7500 (92.8125) lr 5.3207e-04 eta 0:05:46
epoch [133/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.012) loss 0.3518 (0.3083) acc 90.6250 (92.6389) lr 5.3207e-04 eta 0:05:40
epoch [133/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2537 (0.3013) acc 93.7500 (92.6250) lr 5.3207e-04 eta 0:05:35
epoch [134/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.2203 (0.2203) acc 90.6250 (95.6250) lr 5.1825e-04 eta 0:11:37
epoch [134/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.1864 (0.2703) acc 96.8750 (94.0625) lr 5.1825e-04 eta 0:08:16
epoch [134/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.3987 (0.2638) acc 90.6250 (93.9583) lr 5.1825e-04 eta 0:07:09
epoch [134/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.1475 (0.2454) acc 96.8750 (94.0625) lr 5.1825e-04 eta 0:06:35
epoch [134/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.023) loss 0.4019 (0.2413) acc 90.6250 (94.6250) lr 5.1825e-04 eta 0:06:14
epoch [134/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3530 (0.2616) acc 90.6250 (94.0625) lr 5.1825e-04 eta 0:06:01
epoch [134/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.2239 (0.2539) acc 96.8750 (94.3750) lr 5.1825e-04 eta 0:05:51
epoch [134/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1793 (0.2557) acc 100.0000 (94.5312) lr 5.1825e-04 eta 0:05:43
epoch [134/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2281 (0.2601) acc 96.8750 (94.5833) lr 5.1825e-04 eta 0:05:36
epoch [134/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.8101 (0.2716) acc 84.3750 (94.4375) lr 5.1825e-04 eta 0:05:31
epoch [135/200] batch [5/51] time 0.088 (0.205) data 0.000 (0.117) loss 0.1829 (0.4360) acc 96.8750 (92.5000) lr 5.0454e-04 eta 0:11:29
epoch [135/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.2174 (0.3282) acc 93.7500 (94.3750) lr 5.0454e-04 eta 0:08:10
epoch [135/200] batch [15/51] time 0.088 (0.127) data 0.000 (0.039) loss 0.3599 (0.3465) acc 93.7500 (92.2917) lr 5.0454e-04 eta 0:07:04
epoch [135/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.029) loss 0.5493 (0.3391) acc 90.6250 (92.8125) lr 5.0454e-04 eta 0:06:30
epoch [135/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.1396 (0.3158) acc 100.0000 (93.3750) lr 5.0454e-04 eta 0:06:09
epoch [135/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3538 (0.3172) acc 87.5000 (93.2292) lr 5.0454e-04 eta 0:05:55
epoch [135/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2429 (0.3074) acc 90.6250 (92.9464) lr 5.0454e-04 eta 0:05:45
epoch [135/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3489 (0.3062) acc 93.7500 (92.9688) lr 5.0454e-04 eta 0:05:38
epoch [135/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.4658 (0.3054) acc 90.6250 (92.7778) lr 5.0454e-04 eta 0:05:31
epoch [135/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2228 (0.2970) acc 93.7500 (92.8750) lr 5.0454e-04 eta 0:05:26
epoch [136/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.114) loss 0.3535 (0.2584) acc 87.5000 (91.2500) lr 4.9096e-04 eta 0:11:05
epoch [136/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.4260 (0.2636) acc 87.5000 (92.8125) lr 4.9096e-04 eta 0:07:55
epoch [136/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.2410 (0.2712) acc 90.6250 (93.1250) lr 4.9096e-04 eta 0:06:52
epoch [136/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.029) loss 0.2734 (0.2552) acc 96.8750 (93.7500) lr 4.9096e-04 eta 0:06:19
epoch [136/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2515 (0.2632) acc 96.8750 (93.7500) lr 4.9096e-04 eta 0:06:00
epoch [136/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1604 (0.2587) acc 100.0000 (93.8542) lr 4.9096e-04 eta 0:05:47
epoch [136/200] batch [35/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3005 (0.2735) acc 96.8750 (93.8393) lr 4.9096e-04 eta 0:05:37
epoch [136/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1470 (0.2685) acc 100.0000 (94.2188) lr 4.9096e-04 eta 0:05:30
epoch [136/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3328 (0.2783) acc 90.6250 (93.8194) lr 4.9096e-04 eta 0:05:24
epoch [136/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1543 (0.2723) acc 100.0000 (94.0000) lr 4.9096e-04 eta 0:05:19
epoch [137/200] batch [5/51] time 0.087 (0.215) data 0.000 (0.128) loss 0.2020 (0.2594) acc 93.7500 (94.3750) lr 4.7750e-04 eta 0:11:41
epoch [137/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.1979 (0.2674) acc 100.0000 (94.6875) lr 4.7750e-04 eta 0:08:11
epoch [137/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.4895 (0.3001) acc 87.5000 (94.1667) lr 4.7750e-04 eta 0:07:01
epoch [137/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.2152 (0.3125) acc 96.8750 (93.5938) lr 4.7750e-04 eta 0:06:25
epoch [137/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.3293 (0.3186) acc 90.6250 (93.6250) lr 4.7750e-04 eta 0:06:04
epoch [137/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.022) loss 0.4995 (0.3285) acc 87.5000 (93.2292) lr 4.7750e-04 eta 0:05:50
epoch [137/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3972 (0.3392) acc 84.3750 (92.5893) lr 4.7750e-04 eta 0:05:40
epoch [137/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4946 (0.3491) acc 84.3750 (92.2656) lr 4.7750e-04 eta 0:05:31
epoch [137/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2074 (0.3370) acc 93.7500 (92.6389) lr 4.7750e-04 eta 0:05:25
epoch [137/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.2253 (0.3232) acc 93.7500 (93.0000) lr 4.7750e-04 eta 0:05:19
epoch [138/200] batch [5/51] time 0.088 (0.209) data 0.000 (0.121) loss 0.2781 (0.2837) acc 93.7500 (93.7500) lr 4.6417e-04 eta 0:11:09
epoch [138/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.1973 (0.2418) acc 93.7500 (94.0625) lr 4.6417e-04 eta 0:07:54
epoch [138/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.040) loss 0.1925 (0.2306) acc 96.8750 (94.5833) lr 4.6417e-04 eta 0:06:48
epoch [138/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.030) loss 0.0952 (0.2805) acc 100.0000 (93.9062) lr 4.6417e-04 eta 0:06:15
epoch [138/200] batch [25/51] time 0.090 (0.112) data 0.000 (0.024) loss 0.7798 (0.3085) acc 84.3750 (93.1250) lr 4.6417e-04 eta 0:05:55
epoch [138/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.020) loss 0.3162 (0.3097) acc 93.7500 (93.1250) lr 4.6417e-04 eta 0:05:42
epoch [138/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.017) loss 0.1636 (0.3034) acc 93.7500 (92.8571) lr 4.6417e-04 eta 0:05:32
epoch [138/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2852 (0.3024) acc 96.8750 (92.9688) lr 4.6417e-04 eta 0:05:24
epoch [138/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2517 (0.3066) acc 87.5000 (92.7083) lr 4.6417e-04 eta 0:05:18
epoch [138/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2456 (0.3036) acc 93.7500 (92.8750) lr 4.6417e-04 eta 0:05:13
epoch [139/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.130) loss 0.3525 (0.2604) acc 87.5000 (93.7500) lr 4.5098e-04 eta 0:11:25
epoch [139/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.4209 (0.3000) acc 90.6250 (93.1250) lr 4.5098e-04 eta 0:07:58
epoch [139/200] batch [15/51] time 0.086 (0.130) data 0.000 (0.043) loss 0.1023 (0.2632) acc 100.0000 (93.9583) lr 4.5098e-04 eta 0:06:49
epoch [139/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.033) loss 0.1832 (0.2695) acc 96.8750 (94.2188) lr 4.5098e-04 eta 0:06:14
epoch [139/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.026) loss 0.1803 (0.2679) acc 96.8750 (93.7500) lr 4.5098e-04 eta 0:05:53
epoch [139/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.022) loss 0.3936 (0.2799) acc 96.8750 (93.9583) lr 4.5098e-04 eta 0:05:38
epoch [139/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.1333 (0.2755) acc 96.8750 (94.0179) lr 4.5098e-04 eta 0:05:28
epoch [139/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.2463 (0.2759) acc 93.7500 (94.0625) lr 4.5098e-04 eta 0:05:20
epoch [139/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.4685 (0.2753) acc 84.3750 (93.8889) lr 4.5098e-04 eta 0:05:14
epoch [139/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.2303 (0.2753) acc 93.7500 (94.0625) lr 4.5098e-04 eta 0:05:09
epoch [140/200] batch [5/51] time 0.088 (0.208) data 0.000 (0.120) loss 0.0820 (0.2670) acc 100.0000 (95.0000) lr 4.3792e-04 eta 0:10:46
epoch [140/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.2092 (0.2505) acc 96.8750 (94.3750) lr 4.3792e-04 eta 0:07:37
epoch [140/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.040) loss 0.3186 (0.2673) acc 93.7500 (93.9583) lr 4.3792e-04 eta 0:06:34
epoch [140/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3083 (0.2767) acc 96.8750 (93.7500) lr 4.3792e-04 eta 0:06:02
epoch [140/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.2622 (0.2929) acc 96.8750 (93.3750) lr 4.3792e-04 eta 0:05:43
epoch [140/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1738 (0.2934) acc 96.8750 (93.3333) lr 4.3792e-04 eta 0:05:30
epoch [140/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1962 (0.2872) acc 96.8750 (93.6607) lr 4.3792e-04 eta 0:05:21
epoch [140/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2227 (0.2922) acc 93.7500 (93.3594) lr 4.3792e-04 eta 0:05:13
epoch [140/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1003 (0.2849) acc 100.0000 (93.7500) lr 4.3792e-04 eta 0:05:07
epoch [140/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1203 (0.2844) acc 100.0000 (93.8125) lr 4.3792e-04 eta 0:05:03
epoch [141/200] batch [5/51] time 0.086 (0.214) data 0.000 (0.127) loss 0.6235 (0.3872) acc 81.2500 (90.6250) lr 4.2499e-04 eta 0:10:53
epoch [141/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.064) loss 0.3279 (0.3350) acc 90.6250 (91.8750) lr 4.2499e-04 eta 0:07:38
epoch [141/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.043) loss 0.2426 (0.3001) acc 93.7500 (93.1250) lr 4.2499e-04 eta 0:06:33
epoch [141/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.0916 (0.3129) acc 100.0000 (92.5000) lr 4.2499e-04 eta 0:06:00
epoch [141/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.026) loss 0.1261 (0.3115) acc 96.8750 (92.6250) lr 4.2499e-04 eta 0:05:40
epoch [141/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.1594 (0.3006) acc 93.7500 (92.6042) lr 4.2499e-04 eta 0:05:27
epoch [141/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.2722 (0.2875) acc 93.7500 (93.0357) lr 4.2499e-04 eta 0:05:17
epoch [141/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1078 (0.2747) acc 100.0000 (93.6719) lr 4.2499e-04 eta 0:05:09
epoch [141/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.4453 (0.2705) acc 90.6250 (93.6806) lr 4.2499e-04 eta 0:05:03
epoch [141/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3887 (0.2735) acc 90.6250 (93.5625) lr 4.2499e-04 eta 0:04:58
epoch [142/200] batch [5/51] time 0.088 (0.208) data 0.000 (0.120) loss 0.4705 (0.2558) acc 81.2500 (91.8750) lr 4.1221e-04 eta 0:10:25
epoch [142/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.5347 (0.2943) acc 84.3750 (92.1875) lr 4.1221e-04 eta 0:07:22
epoch [142/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.3696 (0.3070) acc 87.5000 (92.2917) lr 4.1221e-04 eta 0:06:21
epoch [142/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.1349 (0.3028) acc 100.0000 (92.6562) lr 4.1221e-04 eta 0:05:50
epoch [142/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.2617 (0.2855) acc 93.7500 (93.2500) lr 4.1221e-04 eta 0:05:31
epoch [142/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4253 (0.2847) acc 87.5000 (93.6458) lr 4.1221e-04 eta 0:05:19
epoch [142/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.4324 (0.2814) acc 87.5000 (93.3929) lr 4.1221e-04 eta 0:05:10
epoch [142/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2520 (0.2806) acc 93.7500 (93.1250) lr 4.1221e-04 eta 0:05:02
epoch [142/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1725 (0.2672) acc 96.8750 (93.6111) lr 4.1221e-04 eta 0:04:57
epoch [142/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1375 (0.2688) acc 96.8750 (93.6875) lr 4.1221e-04 eta 0:04:52
epoch [143/200] batch [5/51] time 0.087 (0.214) data 0.000 (0.126) loss 0.3352 (0.3800) acc 87.5000 (89.3750) lr 3.9958e-04 eta 0:10:30
epoch [143/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.2515 (0.3130) acc 90.6250 (91.8750) lr 3.9958e-04 eta 0:07:23
epoch [143/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.1934 (0.3042) acc 96.8750 (93.1250) lr 3.9958e-04 eta 0:06:20
epoch [143/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.1099 (0.3108) acc 100.0000 (92.8125) lr 3.9958e-04 eta 0:05:48
epoch [143/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3403 (0.3015) acc 93.7500 (93.1250) lr 3.9958e-04 eta 0:05:29
epoch [143/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2642 (0.3053) acc 96.8750 (93.2292) lr 3.9958e-04 eta 0:05:15
epoch [143/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3157 (0.3002) acc 93.7500 (93.3036) lr 3.9958e-04 eta 0:05:06
epoch [143/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.5205 (0.3034) acc 90.6250 (93.2031) lr 3.9958e-04 eta 0:04:59
epoch [143/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2323 (0.2968) acc 93.7500 (93.4722) lr 3.9958e-04 eta 0:04:53
epoch [143/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1112 (0.3005) acc 100.0000 (93.4375) lr 3.9958e-04 eta 0:04:48
epoch [144/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.118) loss 0.1744 (0.3181) acc 96.8750 (93.1250) lr 3.8709e-04 eta 0:09:54
epoch [144/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.2539 (0.2531) acc 93.7500 (94.6875) lr 3.8709e-04 eta 0:07:02
epoch [144/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.4153 (0.2597) acc 90.6250 (94.7917) lr 3.8709e-04 eta 0:06:04
epoch [144/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.030) loss 0.1015 (0.2688) acc 96.8750 (94.3750) lr 3.8709e-04 eta 0:05:36
epoch [144/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.1737 (0.2613) acc 96.8750 (94.7500) lr 3.8709e-04 eta 0:05:18
epoch [144/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.2566 (0.2506) acc 90.6250 (95.0000) lr 3.8709e-04 eta 0:05:06
epoch [144/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3718 (0.2434) acc 93.7500 (95.2679) lr 3.8709e-04 eta 0:04:57
epoch [144/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2715 (0.2498) acc 93.7500 (95.0000) lr 3.8709e-04 eta 0:04:50
epoch [144/200] batch [45/51] time 0.087 (0.100) data 0.000 (0.013) loss 0.1570 (0.2566) acc 96.8750 (94.7222) lr 3.8709e-04 eta 0:04:45
epoch [144/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1095 (0.2634) acc 100.0000 (94.3750) lr 3.8709e-04 eta 0:04:40
epoch [145/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.125) loss 0.6953 (0.3668) acc 78.1250 (90.0000) lr 3.7476e-04 eta 0:10:04
epoch [145/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.063) loss 0.1569 (0.2944) acc 96.8750 (92.8125) lr 3.7476e-04 eta 0:07:05
epoch [145/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.1460 (0.2713) acc 100.0000 (94.3750) lr 3.7476e-04 eta 0:06:05
epoch [145/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.3774 (0.2811) acc 90.6250 (94.0625) lr 3.7476e-04 eta 0:05:35
epoch [145/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2455 (0.2831) acc 93.7500 (93.6250) lr 3.7476e-04 eta 0:05:17
epoch [145/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.021) loss 0.5215 (0.2790) acc 90.6250 (93.9583) lr 3.7476e-04 eta 0:05:04
epoch [145/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.1891 (0.2768) acc 96.8750 (93.7500) lr 3.7476e-04 eta 0:04:55
epoch [145/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.3005 (0.2836) acc 93.7500 (93.4375) lr 3.7476e-04 eta 0:04:48
epoch [145/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.2466 (0.2830) acc 96.8750 (93.4028) lr 3.7476e-04 eta 0:04:42
epoch [145/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.3071 (0.2875) acc 93.7500 (93.4375) lr 3.7476e-04 eta 0:04:37
epoch [146/200] batch [5/51] time 0.087 (0.224) data 0.000 (0.136) loss 0.6265 (0.4161) acc 84.3750 (89.3750) lr 3.6258e-04 eta 0:10:26
epoch [146/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.3000 (0.3050) acc 90.6250 (92.1875) lr 3.6258e-04 eta 0:07:14
epoch [146/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.1689 (0.2929) acc 96.8750 (92.0833) lr 3.6258e-04 eta 0:06:09
epoch [146/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.4805 (0.2937) acc 87.5000 (92.1875) lr 3.6258e-04 eta 0:05:37
epoch [146/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.3037 (0.2920) acc 90.6250 (92.2500) lr 3.6258e-04 eta 0:05:17
epoch [146/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3398 (0.2877) acc 96.8750 (92.5000) lr 3.6258e-04 eta 0:05:04
epoch [146/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.3020 (0.2938) acc 93.7500 (92.2321) lr 3.6258e-04 eta 0:04:54
epoch [146/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3604 (0.2926) acc 93.7500 (92.5000) lr 3.6258e-04 eta 0:04:47
epoch [146/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3022 (0.2929) acc 90.6250 (92.6389) lr 3.6258e-04 eta 0:04:41
epoch [146/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2181 (0.2868) acc 93.7500 (92.8125) lr 3.6258e-04 eta 0:04:36
epoch [147/200] batch [5/51] time 0.087 (0.209) data 0.000 (0.121) loss 0.2408 (0.1830) acc 96.8750 (96.8750) lr 3.5055e-04 eta 0:09:34
epoch [147/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.1787 (0.1953) acc 96.8750 (95.9375) lr 3.5055e-04 eta 0:06:45
epoch [147/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.041) loss 0.3271 (0.2319) acc 96.8750 (95.8333) lr 3.5055e-04 eta 0:05:49
epoch [147/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.0494 (0.2470) acc 100.0000 (95.0000) lr 3.5055e-04 eta 0:05:20
epoch [147/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4722 (0.2645) acc 90.6250 (94.3750) lr 3.5055e-04 eta 0:05:03
epoch [147/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2876 (0.2670) acc 93.7500 (94.2708) lr 3.5055e-04 eta 0:04:51
epoch [147/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.3301 (0.2630) acc 87.5000 (93.9286) lr 3.5055e-04 eta 0:04:43
epoch [147/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2629 (0.2598) acc 90.6250 (93.9062) lr 3.5055e-04 eta 0:04:36
epoch [147/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2556 (0.2545) acc 90.6250 (94.0972) lr 3.5055e-04 eta 0:04:31
epoch [147/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2019 (0.2577) acc 96.8750 (93.9375) lr 3.5055e-04 eta 0:04:26
epoch [148/200] batch [5/51] time 0.089 (0.206) data 0.000 (0.118) loss 0.3306 (0.2859) acc 93.7500 (94.3750) lr 3.3869e-04 eta 0:09:16
epoch [148/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.5073 (0.3054) acc 93.7500 (94.0625) lr 3.3869e-04 eta 0:06:35
epoch [148/200] batch [15/51] time 0.088 (0.127) data 0.000 (0.040) loss 0.0959 (0.3130) acc 100.0000 (93.9583) lr 3.3869e-04 eta 0:05:41
epoch [148/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.030) loss 0.2947 (0.3156) acc 93.7500 (93.2812) lr 3.3869e-04 eta 0:05:14
epoch [148/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.2727 (0.3174) acc 90.6250 (92.6250) lr 3.3869e-04 eta 0:04:58
epoch [148/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.0622 (0.3005) acc 100.0000 (93.0208) lr 3.3869e-04 eta 0:04:46
epoch [148/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.4932 (0.2974) acc 84.3750 (93.0357) lr 3.3869e-04 eta 0:04:38
epoch [148/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3459 (0.3075) acc 90.6250 (92.8125) lr 3.3869e-04 eta 0:04:32
epoch [148/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5586 (0.3106) acc 84.3750 (92.4306) lr 3.3869e-04 eta 0:04:27
epoch [148/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2908 (0.3079) acc 93.7500 (92.5625) lr 3.3869e-04 eta 0:04:22
epoch [149/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.113) loss 0.2051 (0.3322) acc 93.7500 (93.1250) lr 3.2699e-04 eta 0:08:53
epoch [149/200] batch [10/51] time 0.086 (0.145) data 0.000 (0.057) loss 0.3430 (0.3115) acc 93.7500 (93.7500) lr 3.2699e-04 eta 0:06:22
epoch [149/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.3181 (0.3023) acc 93.7500 (94.1667) lr 3.2699e-04 eta 0:05:30
epoch [149/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.028) loss 0.2632 (0.2970) acc 87.5000 (93.2812) lr 3.2699e-04 eta 0:05:04
epoch [149/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.4895 (0.3085) acc 87.5000 (93.1250) lr 3.2699e-04 eta 0:04:48
epoch [149/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4851 (0.3140) acc 90.6250 (93.1250) lr 3.2699e-04 eta 0:04:37
epoch [149/200] batch [35/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2480 (0.3015) acc 90.6250 (93.1250) lr 3.2699e-04 eta 0:04:29
epoch [149/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1962 (0.3027) acc 96.8750 (92.9688) lr 3.2699e-04 eta 0:04:23
epoch [149/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2368 (0.2921) acc 93.7500 (93.1944) lr 3.2699e-04 eta 0:04:18
epoch [149/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.1813 (0.3004) acc 96.8750 (93.0625) lr 3.2699e-04 eta 0:04:14
epoch [150/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.123) loss 0.4495 (0.2947) acc 90.6250 (93.1250) lr 3.1545e-04 eta 0:09:09
epoch [150/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.1703 (0.2800) acc 96.8750 (92.5000) lr 3.1545e-04 eta 0:06:26
epoch [150/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.041) loss 0.2720 (0.2945) acc 90.6250 (92.2917) lr 3.1545e-04 eta 0:05:32
epoch [150/200] batch [20/51] time 0.088 (0.118) data 0.000 (0.031) loss 0.3254 (0.2937) acc 90.6250 (92.3438) lr 3.1545e-04 eta 0:05:05
epoch [150/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2522 (0.3041) acc 93.7500 (92.1250) lr 3.1545e-04 eta 0:04:48
epoch [150/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.021) loss 0.1943 (0.2949) acc 96.8750 (92.8125) lr 3.1545e-04 eta 0:04:37
epoch [150/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.3628 (0.3046) acc 84.3750 (92.2321) lr 3.1545e-04 eta 0:04:29
epoch [150/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2500 (0.3051) acc 93.7500 (92.2656) lr 3.1545e-04 eta 0:04:23
epoch [150/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2238 (0.3038) acc 96.8750 (92.5000) lr 3.1545e-04 eta 0:04:17
epoch [150/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2212 (0.2912) acc 100.0000 (93.1875) lr 3.1545e-04 eta 0:04:13
epoch [151/200] batch [5/51] time 0.089 (0.213) data 0.000 (0.124) loss 0.1288 (0.2944) acc 100.0000 (93.7500) lr 3.0409e-04 eta 0:09:02
epoch [151/200] batch [10/51] time 0.088 (0.150) data 0.000 (0.062) loss 0.3750 (0.3032) acc 90.6250 (94.0625) lr 3.0409e-04 eta 0:06:22
epoch [151/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.1345 (0.2708) acc 96.8750 (94.1667) lr 3.0409e-04 eta 0:05:28
epoch [151/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.031) loss 0.2251 (0.2698) acc 93.7500 (94.2188) lr 3.0409e-04 eta 0:05:00
epoch [151/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2031 (0.2695) acc 96.8750 (94.0000) lr 3.0409e-04 eta 0:04:43
epoch [151/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3574 (0.2670) acc 90.6250 (93.8542) lr 3.0409e-04 eta 0:04:32
epoch [151/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.2581 (0.2603) acc 96.8750 (94.1071) lr 3.0409e-04 eta 0:04:24
epoch [151/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2349 (0.2712) acc 93.7500 (93.4375) lr 3.0409e-04 eta 0:04:17
epoch [151/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2281 (0.2759) acc 96.8750 (93.4722) lr 3.0409e-04 eta 0:04:12
epoch [151/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.1864 (0.2742) acc 100.0000 (93.6250) lr 3.0409e-04 eta 0:04:08
epoch [152/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.117) loss 0.4431 (0.2524) acc 87.5000 (95.6250) lr 2.9289e-04 eta 0:08:28
epoch [152/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.3528 (0.3270) acc 87.5000 (91.8750) lr 2.9289e-04 eta 0:06:01
epoch [152/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.039) loss 0.5278 (0.3251) acc 84.3750 (91.6667) lr 2.9289e-04 eta 0:05:12
epoch [152/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2117 (0.3227) acc 96.8750 (91.8750) lr 2.9289e-04 eta 0:04:48
epoch [152/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.1929 (0.3043) acc 96.8750 (92.5000) lr 2.9289e-04 eta 0:04:33
epoch [152/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.1749 (0.2953) acc 96.8750 (93.0208) lr 2.9289e-04 eta 0:04:22
epoch [152/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1309 (0.2869) acc 100.0000 (93.0357) lr 2.9289e-04 eta 0:04:15
epoch [152/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3049 (0.2917) acc 93.7500 (93.0469) lr 2.9289e-04 eta 0:04:09
epoch [152/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1469 (0.2919) acc 100.0000 (92.8472) lr 2.9289e-04 eta 0:04:04
epoch [152/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.4160 (0.2945) acc 84.3750 (92.6875) lr 2.9289e-04 eta 0:04:01
epoch [153/200] batch [5/51] time 0.088 (0.207) data 0.000 (0.119) loss 0.2266 (0.1816) acc 96.8750 (96.8750) lr 2.8187e-04 eta 0:08:26
epoch [153/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.4028 (0.2860) acc 90.6250 (93.7500) lr 2.8187e-04 eta 0:05:57
epoch [153/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.2128 (0.2728) acc 96.8750 (94.1667) lr 2.8187e-04 eta 0:05:08
epoch [153/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.030) loss 0.5400 (0.2760) acc 93.7500 (94.2188) lr 2.8187e-04 eta 0:04:43
epoch [153/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.4248 (0.2929) acc 87.5000 (93.8750) lr 2.8187e-04 eta 0:04:28
epoch [153/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2042 (0.3017) acc 96.8750 (93.2292) lr 2.8187e-04 eta 0:04:18
epoch [153/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3474 (0.3069) acc 93.7500 (93.1250) lr 2.8187e-04 eta 0:04:10
epoch [153/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5771 (0.3112) acc 90.6250 (93.2031) lr 2.8187e-04 eta 0:04:04
epoch [153/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4583 (0.3115) acc 90.6250 (93.1944) lr 2.8187e-04 eta 0:04:00
epoch [153/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1263 (0.3134) acc 96.8750 (92.9375) lr 2.8187e-04 eta 0:03:56
epoch [154/200] batch [5/51] time 0.087 (0.220) data 0.000 (0.132) loss 0.2081 (0.2645) acc 90.6250 (93.7500) lr 2.7103e-04 eta 0:08:45
epoch [154/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.1913 (0.2753) acc 96.8750 (93.4375) lr 2.7103e-04 eta 0:06:06
epoch [154/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.4622 (0.2745) acc 90.6250 (93.5417) lr 2.7103e-04 eta 0:05:12
epoch [154/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.2103 (0.2858) acc 96.8750 (93.7500) lr 2.7103e-04 eta 0:04:45
epoch [154/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3774 (0.2869) acc 93.7500 (93.7500) lr 2.7103e-04 eta 0:04:29
epoch [154/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4268 (0.3030) acc 87.5000 (93.0208) lr 2.7103e-04 eta 0:04:18
epoch [154/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3682 (0.3058) acc 90.6250 (92.9464) lr 2.7103e-04 eta 0:04:10
epoch [154/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2588 (0.2996) acc 90.6250 (92.8906) lr 2.7103e-04 eta 0:04:04
epoch [154/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1121 (0.2918) acc 100.0000 (93.1250) lr 2.7103e-04 eta 0:03:58
epoch [154/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.5786 (0.2953) acc 87.5000 (93.0000) lr 2.7103e-04 eta 0:03:54
epoch [155/200] batch [5/51] time 0.088 (0.206) data 0.000 (0.118) loss 0.2710 (0.2588) acc 93.7500 (93.1250) lr 2.6037e-04 eta 0:08:03
epoch [155/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.4280 (0.2460) acc 90.6250 (95.0000) lr 2.6037e-04 eta 0:05:43
epoch [155/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.3701 (0.2839) acc 90.6250 (93.7500) lr 2.6037e-04 eta 0:04:55
epoch [155/200] batch [20/51] time 0.091 (0.117) data 0.000 (0.030) loss 0.4534 (0.2876) acc 90.6250 (93.5938) lr 2.6037e-04 eta 0:04:32
epoch [155/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.4839 (0.3031) acc 87.5000 (93.2500) lr 2.6037e-04 eta 0:04:18
epoch [155/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.3591 (0.3106) acc 93.7500 (92.9167) lr 2.6037e-04 eta 0:04:08
epoch [155/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.2500 (0.3034) acc 90.6250 (93.0357) lr 2.6037e-04 eta 0:04:01
epoch [155/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.3179 (0.2931) acc 93.7500 (93.5156) lr 2.6037e-04 eta 0:03:55
epoch [155/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3164 (0.2880) acc 96.8750 (93.8889) lr 2.6037e-04 eta 0:03:50
epoch [155/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.3181 (0.2918) acc 93.7500 (93.8750) lr 2.6037e-04 eta 0:03:46
epoch [156/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.135) loss 0.2169 (0.2376) acc 93.7500 (95.0000) lr 2.4989e-04 eta 0:08:28
epoch [156/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.067) loss 0.2861 (0.2678) acc 96.8750 (94.3750) lr 2.4989e-04 eta 0:05:53
epoch [156/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.1263 (0.2508) acc 100.0000 (94.7917) lr 2.4989e-04 eta 0:05:01
epoch [156/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.1395 (0.2544) acc 96.8750 (94.8438) lr 2.4989e-04 eta 0:04:35
epoch [156/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2020 (0.2338) acc 96.8750 (95.3750) lr 2.4989e-04 eta 0:04:19
epoch [156/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2393 (0.2423) acc 87.5000 (94.7917) lr 2.4989e-04 eta 0:04:08
epoch [156/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4377 (0.2602) acc 87.5000 (94.2857) lr 2.4989e-04 eta 0:04:00
epoch [156/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2437 (0.2621) acc 93.7500 (94.1406) lr 2.4989e-04 eta 0:03:54
epoch [156/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3555 (0.2609) acc 90.6250 (94.0972) lr 2.4989e-04 eta 0:03:49
epoch [156/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2085 (0.2628) acc 93.7500 (93.9375) lr 2.4989e-04 eta 0:03:45
epoch [157/200] batch [5/51] time 0.089 (0.197) data 0.000 (0.109) loss 0.2871 (0.2935) acc 93.7500 (93.1250) lr 2.3959e-04 eta 0:07:20
epoch [157/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.2793 (0.2902) acc 90.6250 (93.1250) lr 2.3959e-04 eta 0:05:16
epoch [157/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.3367 (0.2880) acc 93.7500 (93.5417) lr 2.3959e-04 eta 0:04:35
epoch [157/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.1730 (0.2810) acc 93.7500 (93.7500) lr 2.3959e-04 eta 0:04:14
epoch [157/200] batch [25/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.2052 (0.2750) acc 96.8750 (94.0000) lr 2.3959e-04 eta 0:04:01
epoch [157/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3030 (0.2689) acc 87.5000 (93.8542) lr 2.3959e-04 eta 0:03:52
epoch [157/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2812 (0.2681) acc 93.7500 (93.7500) lr 2.3959e-04 eta 0:03:46
epoch [157/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2207 (0.2671) acc 90.6250 (93.5938) lr 2.3959e-04 eta 0:03:41
epoch [157/200] batch [45/51] time 0.087 (0.099) data 0.000 (0.012) loss 0.3650 (0.2726) acc 87.5000 (93.5417) lr 2.3959e-04 eta 0:03:37
epoch [157/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.6685 (0.2849) acc 90.6250 (93.3750) lr 2.3959e-04 eta 0:03:34
epoch [158/200] batch [5/51] time 0.086 (0.212) data 0.000 (0.125) loss 0.2629 (0.3000) acc 93.7500 (92.5000) lr 2.2949e-04 eta 0:07:43
epoch [158/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.063) loss 0.5742 (0.3536) acc 90.6250 (92.5000) lr 2.2949e-04 eta 0:05:26
epoch [158/200] batch [15/51] time 0.086 (0.129) data 0.000 (0.042) loss 0.2358 (0.3578) acc 96.8750 (92.0833) lr 2.2949e-04 eta 0:04:39
epoch [158/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.5874 (0.3450) acc 90.6250 (92.6562) lr 2.2949e-04 eta 0:04:16
epoch [158/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1301 (0.3116) acc 96.8750 (93.2500) lr 2.2949e-04 eta 0:04:02
epoch [158/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.1869 (0.2904) acc 96.8750 (93.8542) lr 2.2949e-04 eta 0:03:53
epoch [158/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.2061 (0.2908) acc 96.8750 (94.0179) lr 2.2949e-04 eta 0:03:46
epoch [158/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2333 (0.2798) acc 96.8750 (94.2969) lr 2.2949e-04 eta 0:03:40
epoch [158/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3403 (0.2784) acc 87.5000 (93.9583) lr 2.2949e-04 eta 0:03:36
epoch [158/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2312 (0.2697) acc 96.8750 (94.1875) lr 2.2949e-04 eta 0:03:32
epoch [159/200] batch [5/51] time 0.089 (0.203) data 0.000 (0.114) loss 0.2612 (0.2330) acc 93.7500 (95.0000) lr 2.1957e-04 eta 0:07:12
epoch [159/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.2576 (0.2550) acc 93.7500 (95.0000) lr 2.1957e-04 eta 0:05:09
epoch [159/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.1969 (0.2672) acc 96.8750 (95.2083) lr 2.1957e-04 eta 0:04:27
epoch [159/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2815 (0.2857) acc 96.8750 (94.6875) lr 2.1957e-04 eta 0:04:05
epoch [159/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.0683 (0.2893) acc 100.0000 (94.3750) lr 2.1957e-04 eta 0:03:53
epoch [159/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.0950 (0.2845) acc 100.0000 (94.1667) lr 2.1957e-04 eta 0:03:44
epoch [159/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.4321 (0.2822) acc 93.7500 (94.3750) lr 2.1957e-04 eta 0:03:38
epoch [159/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4993 (0.2741) acc 90.6250 (94.7656) lr 2.1957e-04 eta 0:03:33
epoch [159/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.0773 (0.2686) acc 100.0000 (94.8611) lr 2.1957e-04 eta 0:03:29
epoch [159/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2703 (0.2712) acc 93.7500 (94.5625) lr 2.1957e-04 eta 0:03:25
epoch [160/200] batch [5/51] time 0.087 (0.218) data 0.000 (0.131) loss 0.2422 (0.3996) acc 93.7500 (91.8750) lr 2.0984e-04 eta 0:07:35
epoch [160/200] batch [10/51] time 0.086 (0.153) data 0.000 (0.066) loss 0.3176 (0.3526) acc 93.7500 (92.8125) lr 2.0984e-04 eta 0:05:17
epoch [160/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.2771 (0.3141) acc 90.6250 (93.3333) lr 2.0984e-04 eta 0:04:31
epoch [160/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.2537 (0.2942) acc 96.8750 (94.0625) lr 2.0984e-04 eta 0:04:07
epoch [160/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2368 (0.3069) acc 93.7500 (93.5000) lr 2.0984e-04 eta 0:03:53
epoch [160/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1130 (0.3156) acc 96.8750 (93.3333) lr 2.0984e-04 eta 0:03:44
epoch [160/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1901 (0.3044) acc 96.8750 (93.6607) lr 2.0984e-04 eta 0:03:37
epoch [160/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.1995 (0.2968) acc 96.8750 (93.8281) lr 2.0984e-04 eta 0:03:31
epoch [160/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.5312 (0.3052) acc 87.5000 (93.4722) lr 2.0984e-04 eta 0:03:27
epoch [160/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3589 (0.3069) acc 90.6250 (93.3750) lr 2.0984e-04 eta 0:03:23
epoch [161/200] batch [5/51] time 0.088 (0.208) data 0.000 (0.120) loss 0.4143 (0.2560) acc 87.5000 (93.1250) lr 2.0032e-04 eta 0:07:03
epoch [161/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.2563 (0.2775) acc 96.8750 (93.4375) lr 2.0032e-04 eta 0:04:59
epoch [161/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.2747 (0.3176) acc 93.7500 (92.0833) lr 2.0032e-04 eta 0:04:17
epoch [161/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2588 (0.3206) acc 96.8750 (91.8750) lr 2.0032e-04 eta 0:03:56
epoch [161/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3516 (0.3213) acc 93.7500 (92.1250) lr 2.0032e-04 eta 0:03:43
epoch [161/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1323 (0.3172) acc 100.0000 (92.7083) lr 2.0032e-04 eta 0:03:35
epoch [161/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1142 (0.3105) acc 96.8750 (92.6786) lr 2.0032e-04 eta 0:03:28
epoch [161/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1743 (0.3065) acc 93.7500 (92.8125) lr 2.0032e-04 eta 0:03:24
epoch [161/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4709 (0.3118) acc 87.5000 (92.7083) lr 2.0032e-04 eta 0:03:19
epoch [161/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.1581 (0.3183) acc 100.0000 (92.5625) lr 2.0032e-04 eta 0:03:16
epoch [162/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.125) loss 0.3667 (0.3595) acc 93.7500 (91.8750) lr 1.9098e-04 eta 0:07:02
epoch [162/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.1708 (0.3269) acc 96.8750 (92.1875) lr 1.9098e-04 eta 0:04:57
epoch [162/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.4082 (0.3388) acc 84.3750 (91.2500) lr 1.9098e-04 eta 0:04:14
epoch [162/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.032) loss 0.5483 (0.3292) acc 81.2500 (91.5625) lr 1.9098e-04 eta 0:03:53
epoch [162/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2307 (0.3184) acc 93.7500 (91.8750) lr 1.9098e-04 eta 0:03:40
epoch [162/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2661 (0.3106) acc 90.6250 (91.7708) lr 1.9098e-04 eta 0:03:31
epoch [162/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3757 (0.3141) acc 90.6250 (91.6071) lr 1.9098e-04 eta 0:03:25
epoch [162/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1935 (0.3090) acc 96.8750 (91.9531) lr 1.9098e-04 eta 0:03:19
epoch [162/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.2546 (0.2994) acc 90.6250 (92.1528) lr 1.9098e-04 eta 0:03:15
epoch [162/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3247 (0.2977) acc 90.6250 (92.2500) lr 1.9098e-04 eta 0:03:12
epoch [163/200] batch [5/51] time 0.088 (0.214) data 0.000 (0.127) loss 0.1537 (0.2853) acc 96.8750 (91.8750) lr 1.8185e-04 eta 0:06:53
epoch [163/200] batch [10/51] time 0.086 (0.150) data 0.000 (0.063) loss 0.2412 (0.3094) acc 93.7500 (92.1875) lr 1.8185e-04 eta 0:04:50
epoch [163/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.3398 (0.3154) acc 93.7500 (92.7083) lr 1.8185e-04 eta 0:04:08
epoch [163/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.1598 (0.3097) acc 96.8750 (92.9688) lr 1.8185e-04 eta 0:03:47
epoch [163/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.0952 (0.3103) acc 100.0000 (92.6250) lr 1.8185e-04 eta 0:03:34
epoch [163/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3083 (0.2998) acc 87.5000 (92.9167) lr 1.8185e-04 eta 0:03:26
epoch [163/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1032 (0.3072) acc 100.0000 (92.5893) lr 1.8185e-04 eta 0:03:19
epoch [163/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1948 (0.3048) acc 96.8750 (92.7344) lr 1.8185e-04 eta 0:03:14
epoch [163/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.2354 (0.3020) acc 96.8750 (92.7083) lr 1.8185e-04 eta 0:03:10
epoch [163/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2391 (0.3052) acc 93.7500 (92.6250) lr 1.8185e-04 eta 0:03:07
epoch [164/200] batch [5/51] time 0.086 (0.209) data 0.000 (0.122) loss 0.2998 (0.3942) acc 90.6250 (90.0000) lr 1.7292e-04 eta 0:06:34
epoch [164/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.3367 (0.3204) acc 90.6250 (91.8750) lr 1.7292e-04 eta 0:04:38
epoch [164/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.2698 (0.2668) acc 93.7500 (93.7500) lr 1.7292e-04 eta 0:03:59
epoch [164/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.1509 (0.2583) acc 96.8750 (93.7500) lr 1.7292e-04 eta 0:03:39
epoch [164/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.025) loss 0.3171 (0.2737) acc 93.7500 (93.0000) lr 1.7292e-04 eta 0:03:27
epoch [164/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.2805 (0.2849) acc 96.8750 (92.8125) lr 1.7292e-04 eta 0:03:19
epoch [164/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.018) loss 0.3997 (0.2846) acc 90.6250 (93.0357) lr 1.7292e-04 eta 0:03:13
epoch [164/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.1296 (0.2842) acc 96.8750 (93.0469) lr 1.7292e-04 eta 0:03:08
epoch [164/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2930 (0.2803) acc 93.7500 (93.1944) lr 1.7292e-04 eta 0:03:04
epoch [164/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4937 (0.2806) acc 87.5000 (93.1250) lr 1.7292e-04 eta 0:03:01
epoch [165/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.114) loss 0.4448 (0.4120) acc 81.2500 (87.5000) lr 1.6419e-04 eta 0:06:08
epoch [165/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.2372 (0.3328) acc 100.0000 (91.5625) lr 1.6419e-04 eta 0:04:23
epoch [165/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.5015 (0.3181) acc 81.2500 (91.6667) lr 1.6419e-04 eta 0:03:48
epoch [165/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3577 (0.3038) acc 93.7500 (92.1875) lr 1.6419e-04 eta 0:03:30
epoch [165/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1949 (0.3067) acc 100.0000 (92.2500) lr 1.6419e-04 eta 0:03:19
epoch [165/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1578 (0.2902) acc 96.8750 (92.7083) lr 1.6419e-04 eta 0:03:11
epoch [165/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1035 (0.2679) acc 100.0000 (93.5714) lr 1.6419e-04 eta 0:03:06
epoch [165/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2416 (0.2713) acc 93.7500 (93.5938) lr 1.6419e-04 eta 0:03:01
epoch [165/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3774 (0.2734) acc 93.7500 (93.6806) lr 1.6419e-04 eta 0:02:58
epoch [165/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.4470 (0.2839) acc 93.7500 (93.6250) lr 1.6419e-04 eta 0:02:55
epoch [166/200] batch [5/51] time 0.088 (0.204) data 0.000 (0.115) loss 0.1930 (0.2447) acc 96.8750 (95.0000) lr 1.5567e-04 eta 0:06:02
epoch [166/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.1416 (0.2468) acc 100.0000 (93.4375) lr 1.5567e-04 eta 0:04:18
epoch [166/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.038) loss 0.2751 (0.2474) acc 93.7500 (93.9583) lr 1.5567e-04 eta 0:03:43
epoch [166/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.1521 (0.2591) acc 93.7500 (93.4375) lr 1.5567e-04 eta 0:03:25
epoch [166/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.023) loss 0.5273 (0.2697) acc 84.3750 (93.2500) lr 1.5567e-04 eta 0:03:14
epoch [166/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.019) loss 0.5088 (0.2800) acc 90.6250 (93.2292) lr 1.5567e-04 eta 0:03:07
epoch [166/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.6172 (0.2877) acc 87.5000 (93.3929) lr 1.5567e-04 eta 0:03:01
epoch [166/200] batch [40/51] time 0.087 (0.102) data 0.000 (0.015) loss 0.3137 (0.2869) acc 90.6250 (93.2031) lr 1.5567e-04 eta 0:02:57
epoch [166/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4775 (0.2890) acc 90.6250 (93.4722) lr 1.5567e-04 eta 0:02:53
epoch [166/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1260 (0.2862) acc 100.0000 (93.6875) lr 1.5567e-04 eta 0:02:50
epoch [167/200] batch [5/51] time 0.088 (0.200) data 0.000 (0.111) loss 0.1381 (0.2653) acc 96.8750 (93.1250) lr 1.4736e-04 eta 0:05:45
epoch [167/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.2247 (0.2721) acc 93.7500 (93.7500) lr 1.4736e-04 eta 0:04:07
epoch [167/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.037) loss 0.1775 (0.2820) acc 96.8750 (93.7500) lr 1.4736e-04 eta 0:03:34
epoch [167/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.028) loss 0.2371 (0.2755) acc 96.8750 (94.2188) lr 1.4736e-04 eta 0:03:17
epoch [167/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1114 (0.2640) acc 100.0000 (94.6250) lr 1.4736e-04 eta 0:03:07
epoch [167/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4912 (0.2796) acc 90.6250 (94.3750) lr 1.4736e-04 eta 0:03:00
epoch [167/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2119 (0.2674) acc 96.8750 (94.6429) lr 1.4736e-04 eta 0:02:55
epoch [167/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.1245 (0.2632) acc 96.8750 (94.5312) lr 1.4736e-04 eta 0:02:51
epoch [167/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.0573 (0.2689) acc 100.0000 (94.4444) lr 1.4736e-04 eta 0:02:47
epoch [167/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3623 (0.2684) acc 81.2500 (94.1875) lr 1.4736e-04 eta 0:02:44
epoch [168/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.123) loss 0.3464 (0.3395) acc 90.6250 (90.6250) lr 1.3926e-04 eta 0:05:53
epoch [168/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.4319 (0.2945) acc 87.5000 (92.5000) lr 1.3926e-04 eta 0:04:09
epoch [168/200] batch [15/51] time 0.088 (0.129) data 0.000 (0.041) loss 0.3694 (0.2692) acc 96.8750 (94.1667) lr 1.3926e-04 eta 0:03:34
epoch [168/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.2722 (0.2658) acc 93.7500 (94.2188) lr 1.3926e-04 eta 0:03:16
epoch [168/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2556 (0.2546) acc 90.6250 (94.3750) lr 1.3926e-04 eta 0:03:05
epoch [168/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2435 (0.2420) acc 90.6250 (94.2708) lr 1.3926e-04 eta 0:02:58
epoch [168/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.2932 (0.2441) acc 93.7500 (94.4643) lr 1.3926e-04 eta 0:02:52
epoch [168/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2345 (0.2446) acc 93.7500 (94.2969) lr 1.3926e-04 eta 0:02:48
epoch [168/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4417 (0.2519) acc 93.7500 (94.1667) lr 1.3926e-04 eta 0:02:44
epoch [168/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2856 (0.2540) acc 93.7500 (94.2500) lr 1.3926e-04 eta 0:02:42
epoch [169/200] batch [5/51] time 0.089 (0.197) data 0.000 (0.109) loss 0.2411 (0.2015) acc 93.7500 (94.3750) lr 1.3137e-04 eta 0:05:20
epoch [169/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.2203 (0.2085) acc 93.7500 (95.3125) lr 1.3137e-04 eta 0:03:50
epoch [169/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.3430 (0.2534) acc 87.5000 (93.5417) lr 1.3137e-04 eta 0:03:19
epoch [169/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.1234 (0.2565) acc 100.0000 (93.7500) lr 1.3137e-04 eta 0:03:04
epoch [169/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4011 (0.2647) acc 87.5000 (93.3750) lr 1.3137e-04 eta 0:02:55
epoch [169/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3105 (0.2655) acc 90.6250 (93.1250) lr 1.3137e-04 eta 0:02:48
epoch [169/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4250 (0.2768) acc 84.3750 (92.4107) lr 1.3137e-04 eta 0:02:43
epoch [169/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2524 (0.2769) acc 93.7500 (92.7344) lr 1.3137e-04 eta 0:02:40
epoch [169/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1322 (0.2752) acc 96.8750 (92.9861) lr 1.3137e-04 eta 0:02:37
epoch [169/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3386 (0.2748) acc 90.6250 (93.0625) lr 1.3137e-04 eta 0:02:34
epoch [170/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.3030 (0.3753) acc 90.6250 (90.6250) lr 1.2369e-04 eta 0:05:12
epoch [170/200] batch [10/51] time 0.086 (0.143) data 0.000 (0.055) loss 0.3098 (0.3145) acc 90.6250 (92.5000) lr 1.2369e-04 eta 0:03:43
epoch [170/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.1384 (0.2714) acc 96.8750 (93.1250) lr 1.2369e-04 eta 0:03:14
epoch [170/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2437 (0.2651) acc 96.8750 (93.5938) lr 1.2369e-04 eta 0:02:59
epoch [170/200] batch [25/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.1409 (0.2728) acc 100.0000 (93.7500) lr 1.2369e-04 eta 0:02:49
epoch [170/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.5845 (0.2713) acc 84.3750 (93.8542) lr 1.2369e-04 eta 0:02:43
epoch [170/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1788 (0.2661) acc 93.7500 (93.8393) lr 1.2369e-04 eta 0:02:38
epoch [170/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.0867 (0.2623) acc 96.8750 (93.4375) lr 1.2369e-04 eta 0:02:35
epoch [170/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4275 (0.2668) acc 93.7500 (93.3333) lr 1.2369e-04 eta 0:02:32
epoch [170/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4358 (0.2689) acc 84.3750 (93.0625) lr 1.2369e-04 eta 0:02:29
epoch [171/200] batch [5/51] time 0.086 (0.208) data 0.000 (0.121) loss 0.3491 (0.1961) acc 90.6250 (96.2500) lr 1.1623e-04 eta 0:05:17
epoch [171/200] batch [10/51] time 0.086 (0.147) data 0.000 (0.061) loss 0.1486 (0.2223) acc 96.8750 (94.6875) lr 1.1623e-04 eta 0:03:43
epoch [171/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.5146 (0.2462) acc 84.3750 (93.9583) lr 1.1623e-04 eta 0:03:12
epoch [171/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2622 (0.2431) acc 93.7500 (94.2188) lr 1.1623e-04 eta 0:02:56
epoch [171/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3193 (0.2566) acc 96.8750 (94.1250) lr 1.1623e-04 eta 0:02:46
epoch [171/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1410 (0.2526) acc 100.0000 (94.4792) lr 1.1623e-04 eta 0:02:40
epoch [171/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1425 (0.2510) acc 100.0000 (94.6429) lr 1.1623e-04 eta 0:02:35
epoch [171/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1109 (0.2522) acc 96.8750 (94.3750) lr 1.1623e-04 eta 0:02:31
epoch [171/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.3022 (0.2512) acc 93.7500 (94.3056) lr 1.1623e-04 eta 0:02:28
epoch [171/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.1635 (0.2490) acc 96.8750 (94.1875) lr 1.1623e-04 eta 0:02:25
epoch [172/200] batch [5/51] time 0.088 (0.204) data 0.000 (0.116) loss 0.1881 (0.1633) acc 93.7500 (96.8750) lr 1.0899e-04 eta 0:05:00
epoch [172/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.3186 (0.2142) acc 93.7500 (95.9375) lr 1.0899e-04 eta 0:03:33
epoch [172/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.1595 (0.2113) acc 93.7500 (95.6250) lr 1.0899e-04 eta 0:03:04
epoch [172/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2224 (0.2120) acc 96.8750 (95.6250) lr 1.0899e-04 eta 0:02:49
epoch [172/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2329 (0.2243) acc 93.7500 (95.3750) lr 1.0899e-04 eta 0:02:40
epoch [172/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2450 (0.2313) acc 93.7500 (95.2083) lr 1.0899e-04 eta 0:02:34
epoch [172/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1675 (0.2284) acc 96.8750 (95.1786) lr 1.0899e-04 eta 0:02:29
epoch [172/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3462 (0.2435) acc 90.6250 (94.6094) lr 1.0899e-04 eta 0:02:26
epoch [172/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1851 (0.2358) acc 96.8750 (94.8611) lr 1.0899e-04 eta 0:02:23
epoch [172/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1161 (0.2366) acc 100.0000 (94.9375) lr 1.0899e-04 eta 0:02:20
epoch [173/200] batch [5/51] time 0.087 (0.219) data 0.000 (0.131) loss 0.3994 (0.2893) acc 90.6250 (92.5000) lr 1.0197e-04 eta 0:05:11
epoch [173/200] batch [10/51] time 0.089 (0.153) data 0.000 (0.066) loss 0.3823 (0.3304) acc 93.7500 (91.2500) lr 1.0197e-04 eta 0:03:36
epoch [173/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.2439 (0.2969) acc 90.6250 (92.2917) lr 1.0197e-04 eta 0:03:05
epoch [173/200] batch [20/51] time 0.089 (0.120) data 0.000 (0.033) loss 0.1785 (0.2765) acc 100.0000 (93.4375) lr 1.0197e-04 eta 0:02:49
epoch [173/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.026) loss 0.3459 (0.2949) acc 93.7500 (93.0000) lr 1.0197e-04 eta 0:02:39
epoch [173/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.0861 (0.2915) acc 100.0000 (93.2292) lr 1.0197e-04 eta 0:02:32
epoch [173/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1373 (0.2866) acc 96.8750 (93.0357) lr 1.0197e-04 eta 0:02:27
epoch [173/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2476 (0.2841) acc 90.6250 (92.9688) lr 1.0197e-04 eta 0:02:23
epoch [173/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3560 (0.2883) acc 87.5000 (92.7083) lr 1.0197e-04 eta 0:02:20
epoch [173/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2395 (0.2851) acc 96.8750 (92.7500) lr 1.0197e-04 eta 0:02:17
epoch [174/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.116) loss 0.2510 (0.3309) acc 93.7500 (91.8750) lr 9.5173e-05 eta 0:04:40
epoch [174/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.2009 (0.3017) acc 93.7500 (92.8125) lr 9.5173e-05 eta 0:03:19
epoch [174/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.039) loss 0.4497 (0.3052) acc 87.5000 (92.7083) lr 9.5173e-05 eta 0:02:51
epoch [174/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.1046 (0.3122) acc 100.0000 (93.2812) lr 9.5173e-05 eta 0:02:37
epoch [174/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.0986 (0.3182) acc 100.0000 (93.1250) lr 9.5173e-05 eta 0:02:29
epoch [174/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.020) loss 0.2676 (0.3238) acc 93.7500 (92.8125) lr 9.5173e-05 eta 0:02:23
epoch [174/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.3225 (0.3284) acc 96.8750 (92.9464) lr 9.5173e-05 eta 0:02:19
epoch [174/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.0974 (0.3287) acc 100.0000 (92.7344) lr 9.5173e-05 eta 0:02:15
epoch [174/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2581 (0.3248) acc 90.6250 (92.5694) lr 9.5173e-05 eta 0:02:12
epoch [174/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2217 (0.3130) acc 96.8750 (92.9375) lr 9.5173e-05 eta 0:02:10
epoch [175/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.117) loss 0.3801 (0.3058) acc 93.7500 (94.3750) lr 8.8597e-05 eta 0:04:30
epoch [175/200] batch [10/51] time 0.086 (0.146) data 0.000 (0.059) loss 0.2083 (0.3111) acc 93.7500 (93.4375) lr 8.8597e-05 eta 0:03:11
epoch [175/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.2185 (0.2933) acc 96.8750 (93.9583) lr 8.8597e-05 eta 0:02:45
epoch [175/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.030) loss 0.2249 (0.2885) acc 93.7500 (93.7500) lr 8.8597e-05 eta 0:02:31
epoch [175/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.1691 (0.2983) acc 96.8750 (93.3750) lr 8.8597e-05 eta 0:02:23
epoch [175/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1661 (0.2791) acc 96.8750 (93.7500) lr 8.8597e-05 eta 0:02:18
epoch [175/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2600 (0.2812) acc 93.7500 (93.8393) lr 8.8597e-05 eta 0:02:13
epoch [175/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2157 (0.2880) acc 96.8750 (93.8281) lr 8.8597e-05 eta 0:02:10
epoch [175/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1133 (0.2829) acc 100.0000 (93.8889) lr 8.8597e-05 eta 0:02:07
epoch [175/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.0847 (0.2853) acc 100.0000 (93.9375) lr 8.8597e-05 eta 0:02:05
epoch [176/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.124) loss 0.1149 (0.2734) acc 100.0000 (93.7500) lr 8.2245e-05 eta 0:04:29
epoch [176/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.062) loss 0.3342 (0.2779) acc 87.5000 (93.4375) lr 8.2245e-05 eta 0:03:09
epoch [176/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.3401 (0.2839) acc 90.6250 (93.7500) lr 8.2245e-05 eta 0:02:42
epoch [176/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.2474 (0.3120) acc 93.7500 (93.5938) lr 8.2245e-05 eta 0:02:28
epoch [176/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2146 (0.3002) acc 96.8750 (93.8750) lr 8.2245e-05 eta 0:02:20
epoch [176/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.4226 (0.2922) acc 87.5000 (94.0625) lr 8.2245e-05 eta 0:02:14
epoch [176/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.2495 (0.2814) acc 100.0000 (94.5536) lr 8.2245e-05 eta 0:02:10
epoch [176/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1053 (0.2756) acc 100.0000 (94.6094) lr 8.2245e-05 eta 0:02:06
epoch [176/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4548 (0.2823) acc 87.5000 (94.0278) lr 8.2245e-05 eta 0:02:04
epoch [176/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2795 (0.2869) acc 96.8750 (93.8750) lr 8.2245e-05 eta 0:02:01
epoch [177/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.114) loss 0.2007 (0.1844) acc 93.7500 (94.3750) lr 7.6120e-05 eta 0:04:06
epoch [177/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.3926 (0.1884) acc 96.8750 (95.6250) lr 7.6120e-05 eta 0:02:55
epoch [177/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.5059 (0.2094) acc 87.5000 (95.2083) lr 7.6120e-05 eta 0:02:31
epoch [177/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.029) loss 0.1423 (0.2248) acc 96.8750 (94.6875) lr 7.6120e-05 eta 0:02:19
epoch [177/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.1272 (0.2210) acc 100.0000 (95.2500) lr 7.6120e-05 eta 0:02:12
epoch [177/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2874 (0.2227) acc 90.6250 (95.2083) lr 7.6120e-05 eta 0:02:06
epoch [177/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.016) loss 0.2234 (0.2281) acc 96.8750 (95.2679) lr 7.6120e-05 eta 0:02:03
epoch [177/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1008 (0.2259) acc 100.0000 (95.3906) lr 7.6120e-05 eta 0:02:00
epoch [177/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3018 (0.2299) acc 93.7500 (95.4167) lr 7.6120e-05 eta 0:01:57
epoch [177/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1564 (0.2322) acc 100.0000 (95.5000) lr 7.6120e-05 eta 0:01:55
epoch [178/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.1083 (0.2321) acc 100.0000 (95.0000) lr 7.0224e-05 eta 0:03:53
epoch [178/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.1993 (0.2442) acc 93.7500 (93.1250) lr 7.0224e-05 eta 0:02:47
epoch [178/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.2722 (0.2594) acc 93.7500 (93.9583) lr 7.0224e-05 eta 0:02:24
epoch [178/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.5762 (0.2668) acc 90.6250 (93.9062) lr 7.0224e-05 eta 0:02:12
epoch [178/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2620 (0.2645) acc 96.8750 (94.1250) lr 7.0224e-05 eta 0:02:05
epoch [178/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.2544 (0.2575) acc 96.8750 (94.3750) lr 7.0224e-05 eta 0:02:00
epoch [178/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4141 (0.2584) acc 90.6250 (94.5536) lr 7.0224e-05 eta 0:01:57
epoch [178/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2111 (0.2613) acc 100.0000 (94.4531) lr 7.0224e-05 eta 0:01:54
epoch [178/200] batch [45/51] time 0.087 (0.099) data 0.000 (0.013) loss 0.1633 (0.2631) acc 93.7500 (94.3750) lr 7.0224e-05 eta 0:01:51
epoch [178/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1946 (0.2595) acc 93.7500 (94.4375) lr 7.0224e-05 eta 0:01:49
epoch [179/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.134) loss 0.2096 (0.1974) acc 96.8750 (96.2500) lr 6.4556e-05 eta 0:04:07
epoch [179/200] batch [10/51] time 0.088 (0.154) data 0.000 (0.067) loss 0.1852 (0.2339) acc 96.8750 (95.3125) lr 6.4556e-05 eta 0:02:51
epoch [179/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.2893 (0.2621) acc 93.7500 (94.3750) lr 6.4556e-05 eta 0:02:26
epoch [179/200] batch [20/51] time 0.088 (0.121) data 0.000 (0.034) loss 0.4124 (0.2925) acc 93.7500 (93.5938) lr 6.4556e-05 eta 0:02:13
epoch [179/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.6611 (0.3099) acc 87.5000 (92.7500) lr 6.4556e-05 eta 0:02:05
epoch [179/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.1792 (0.2894) acc 93.7500 (93.2292) lr 6.4556e-05 eta 0:01:59
epoch [179/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3215 (0.3076) acc 93.7500 (92.9464) lr 6.4556e-05 eta 0:01:55
epoch [179/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.6123 (0.3260) acc 90.6250 (92.8125) lr 6.4556e-05 eta 0:01:52
epoch [179/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3411 (0.3163) acc 93.7500 (92.9167) lr 6.4556e-05 eta 0:01:49
epoch [179/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1693 (0.3211) acc 96.8750 (92.7500) lr 6.4556e-05 eta 0:01:47
epoch [180/200] batch [5/51] time 0.087 (0.216) data 0.000 (0.129) loss 0.1512 (0.2437) acc 100.0000 (96.8750) lr 5.9119e-05 eta 0:03:49
epoch [180/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.1434 (0.2764) acc 96.8750 (95.3125) lr 5.9119e-05 eta 0:02:40
epoch [180/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.2180 (0.2762) acc 90.6250 (94.3750) lr 5.9119e-05 eta 0:02:17
epoch [180/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.4534 (0.2896) acc 87.5000 (93.7500) lr 5.9119e-05 eta 0:02:05
epoch [180/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.3528 (0.2985) acc 90.6250 (93.3750) lr 5.9119e-05 eta 0:01:57
epoch [180/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.1394 (0.2911) acc 96.8750 (93.6458) lr 5.9119e-05 eta 0:01:53
epoch [180/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.019) loss 0.3823 (0.2884) acc 87.5000 (93.3929) lr 5.9119e-05 eta 0:01:49
epoch [180/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4058 (0.2965) acc 87.5000 (93.0469) lr 5.9119e-05 eta 0:01:46
epoch [180/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.0784 (0.2875) acc 100.0000 (93.2639) lr 5.9119e-05 eta 0:01:43
epoch [180/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2581 (0.2803) acc 96.8750 (93.5625) lr 5.9119e-05 eta 0:01:41
epoch [181/200] batch [5/51] time 0.087 (0.195) data 0.000 (0.107) loss 0.2986 (0.2657) acc 93.7500 (92.5000) lr 5.3915e-05 eta 0:03:17
epoch [181/200] batch [10/51] time 0.087 (0.141) data 0.000 (0.054) loss 0.2327 (0.2921) acc 93.7500 (91.5625) lr 5.3915e-05 eta 0:02:22
epoch [181/200] batch [15/51] time 0.086 (0.123) data 0.000 (0.036) loss 0.3923 (0.2852) acc 87.5000 (91.8750) lr 5.3915e-05 eta 0:02:03
epoch [181/200] batch [20/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.5654 (0.2877) acc 87.5000 (92.3438) lr 5.3915e-05 eta 0:01:53
epoch [181/200] batch [25/51] time 0.087 (0.108) data 0.000 (0.022) loss 0.2329 (0.2910) acc 93.7500 (92.3750) lr 5.3915e-05 eta 0:01:47
epoch [181/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.2323 (0.3113) acc 90.6250 (92.3958) lr 5.3915e-05 eta 0:01:43
epoch [181/200] batch [35/51] time 0.087 (0.102) data 0.000 (0.015) loss 0.2083 (0.3022) acc 93.7500 (92.5893) lr 5.3915e-05 eta 0:01:40
epoch [181/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3262 (0.3003) acc 87.5000 (92.3438) lr 5.3915e-05 eta 0:01:38
epoch [181/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3997 (0.3018) acc 90.6250 (92.0833) lr 5.3915e-05 eta 0:01:36
epoch [181/200] batch [50/51] time 0.086 (0.097) data 0.000 (0.011) loss 0.4177 (0.3020) acc 87.5000 (92.0000) lr 5.3915e-05 eta 0:01:34
epoch [182/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.111) loss 0.1051 (0.2735) acc 100.0000 (92.5000) lr 4.8943e-05 eta 0:03:11
epoch [182/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.5322 (0.2740) acc 84.3750 (93.1250) lr 4.8943e-05 eta 0:02:17
epoch [182/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2910 (0.2810) acc 90.6250 (93.1250) lr 4.8943e-05 eta 0:01:58
epoch [182/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3975 (0.2732) acc 87.5000 (93.7500) lr 4.8943e-05 eta 0:01:49
epoch [182/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.1753 (0.2759) acc 96.8750 (93.5000) lr 4.8943e-05 eta 0:01:43
epoch [182/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2001 (0.2910) acc 96.8750 (93.4375) lr 4.8943e-05 eta 0:01:39
epoch [182/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3333 (0.2923) acc 90.6250 (93.6607) lr 4.8943e-05 eta 0:01:36
epoch [182/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3240 (0.2985) acc 96.8750 (93.5938) lr 4.8943e-05 eta 0:01:33
epoch [182/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2844 (0.2874) acc 87.5000 (93.7500) lr 4.8943e-05 eta 0:01:31
epoch [182/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2783 (0.2870) acc 93.7500 (93.6250) lr 4.8943e-05 eta 0:01:30
epoch [183/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.111) loss 0.1510 (0.3084) acc 93.7500 (91.2500) lr 4.4207e-05 eta 0:03:00
epoch [183/200] batch [10/51] time 0.086 (0.143) data 0.000 (0.055) loss 0.2222 (0.2615) acc 93.7500 (92.5000) lr 4.4207e-05 eta 0:02:09
epoch [183/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.1345 (0.2769) acc 96.8750 (92.2917) lr 4.4207e-05 eta 0:01:52
epoch [183/200] batch [20/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.0926 (0.2490) acc 100.0000 (93.2812) lr 4.4207e-05 eta 0:01:43
epoch [183/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2551 (0.2597) acc 96.8750 (93.2500) lr 4.4207e-05 eta 0:01:37
epoch [183/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2639 (0.2727) acc 96.8750 (93.0208) lr 4.4207e-05 eta 0:01:33
epoch [183/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1881 (0.2703) acc 96.8750 (92.9464) lr 4.4207e-05 eta 0:01:30
epoch [183/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.2998 (0.2746) acc 90.6250 (92.8906) lr 4.4207e-05 eta 0:01:28
epoch [183/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4841 (0.2781) acc 87.5000 (92.8472) lr 4.4207e-05 eta 0:01:26
epoch [183/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4744 (0.2818) acc 90.6250 (92.6250) lr 4.4207e-05 eta 0:01:24
epoch [184/200] batch [5/51] time 0.087 (0.206) data 0.000 (0.118) loss 0.1165 (0.1733) acc 96.8750 (95.6250) lr 3.9706e-05 eta 0:02:57
epoch [184/200] batch [10/51] time 0.086 (0.146) data 0.000 (0.059) loss 0.0612 (0.2077) acc 100.0000 (94.6875) lr 3.9706e-05 eta 0:02:05
epoch [184/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.040) loss 0.2421 (0.2324) acc 93.7500 (94.1667) lr 3.9706e-05 eta 0:01:47
epoch [184/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.030) loss 0.2408 (0.2357) acc 93.7500 (94.5312) lr 3.9706e-05 eta 0:01:38
epoch [184/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.1202 (0.2352) acc 100.0000 (94.7500) lr 3.9706e-05 eta 0:01:32
epoch [184/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.2942 (0.2548) acc 90.6250 (94.2708) lr 3.9706e-05 eta 0:01:29
epoch [184/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.2859 (0.2633) acc 93.7500 (94.1071) lr 3.9706e-05 eta 0:01:26
epoch [184/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1600 (0.2592) acc 96.8750 (93.9062) lr 3.9706e-05 eta 0:01:24
epoch [184/200] batch [45/51] time 0.087 (0.100) data 0.000 (0.013) loss 0.1881 (0.2606) acc 100.0000 (94.0278) lr 3.9706e-05 eta 0:01:22
epoch [184/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1791 (0.2526) acc 96.8750 (94.3125) lr 3.9706e-05 eta 0:01:20
epoch [185/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.125) loss 0.2856 (0.3398) acc 96.8750 (91.2500) lr 3.5443e-05 eta 0:02:51
epoch [185/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 0.2175 (0.3105) acc 93.7500 (92.1875) lr 3.5443e-05 eta 0:02:00
epoch [185/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.042) loss 0.0742 (0.2925) acc 100.0000 (93.5417) lr 3.5443e-05 eta 0:01:42
epoch [185/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.3757 (0.3129) acc 90.6250 (93.1250) lr 3.5443e-05 eta 0:01:33
epoch [185/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.3481 (0.3000) acc 93.7500 (93.2500) lr 3.5443e-05 eta 0:01:28
epoch [185/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.021) loss 0.2207 (0.2868) acc 96.8750 (93.9583) lr 3.5443e-05 eta 0:01:24
epoch [185/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.2294 (0.2866) acc 93.7500 (93.8393) lr 3.5443e-05 eta 0:01:21
epoch [185/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.5806 (0.2940) acc 87.5000 (93.7500) lr 3.5443e-05 eta 0:01:19
epoch [185/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3428 (0.2974) acc 90.6250 (93.4722) lr 3.5443e-05 eta 0:01:17
epoch [185/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.1753 (0.3008) acc 96.8750 (93.3750) lr 3.5443e-05 eta 0:01:15
epoch [186/200] batch [5/51] time 0.088 (0.223) data 0.000 (0.135) loss 0.2037 (0.2144) acc 96.8750 (95.6250) lr 3.1417e-05 eta 0:02:49
epoch [186/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.3083 (0.2431) acc 90.6250 (93.7500) lr 3.1417e-05 eta 0:01:57
epoch [186/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.3704 (0.2400) acc 90.6250 (94.5833) lr 3.1417e-05 eta 0:01:39
epoch [186/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.2108 (0.2286) acc 90.6250 (94.5312) lr 3.1417e-05 eta 0:01:30
epoch [186/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.1686 (0.2398) acc 100.0000 (94.6250) lr 3.1417e-05 eta 0:01:24
epoch [186/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1786 (0.2351) acc 96.8750 (94.8958) lr 3.1417e-05 eta 0:01:20
epoch [186/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.2483 (0.2655) acc 90.6250 (94.3750) lr 3.1417e-05 eta 0:01:17
epoch [186/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1185 (0.2673) acc 96.8750 (94.2188) lr 3.1417e-05 eta 0:01:15
epoch [186/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2300 (0.2684) acc 93.7500 (94.0972) lr 3.1417e-05 eta 0:01:13
epoch [186/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2285 (0.2667) acc 96.8750 (94.1875) lr 3.1417e-05 eta 0:01:11
epoch [187/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.114) loss 0.3938 (0.2859) acc 87.5000 (91.2500) lr 2.7630e-05 eta 0:02:22
epoch [187/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.057) loss 0.2803 (0.2606) acc 93.7500 (92.1875) lr 2.7630e-05 eta 0:01:41
epoch [187/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.1735 (0.2783) acc 100.0000 (93.3333) lr 2.7630e-05 eta 0:01:27
epoch [187/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2072 (0.2723) acc 93.7500 (93.1250) lr 2.7630e-05 eta 0:01:20
epoch [187/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3000 (0.2545) acc 93.7500 (94.0000) lr 2.7630e-05 eta 0:01:15
epoch [187/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.1224 (0.2405) acc 100.0000 (94.4792) lr 2.7630e-05 eta 0:01:12
epoch [187/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.017) loss 0.5044 (0.2509) acc 87.5000 (94.4643) lr 2.7630e-05 eta 0:01:10
epoch [187/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.5449 (0.2571) acc 87.5000 (94.2969) lr 2.7630e-05 eta 0:01:08
epoch [187/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3752 (0.2593) acc 90.6250 (94.3750) lr 2.7630e-05 eta 0:01:06
epoch [187/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2920 (0.2603) acc 96.8750 (94.2500) lr 2.7630e-05 eta 0:01:05
epoch [188/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.113) loss 0.0909 (0.1895) acc 100.0000 (96.8750) lr 2.4083e-05 eta 0:02:12
epoch [188/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.2335 (0.2771) acc 93.7500 (94.0625) lr 2.4083e-05 eta 0:01:34
epoch [188/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.3625 (0.2823) acc 93.7500 (94.5833) lr 2.4083e-05 eta 0:01:20
epoch [188/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2925 (0.2837) acc 90.6250 (94.3750) lr 2.4083e-05 eta 0:01:14
epoch [188/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3169 (0.2756) acc 93.7500 (94.6250) lr 2.4083e-05 eta 0:01:10
epoch [188/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3162 (0.2659) acc 90.6250 (94.7917) lr 2.4083e-05 eta 0:01:07
epoch [188/200] batch [35/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2937 (0.2514) acc 96.8750 (95.1786) lr 2.4083e-05 eta 0:01:04
epoch [188/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.4607 (0.2662) acc 84.3750 (94.6094) lr 2.4083e-05 eta 0:01:02
epoch [188/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.1526 (0.2656) acc 96.8750 (94.5139) lr 2.4083e-05 eta 0:01:01
epoch [188/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.3767 (0.2715) acc 87.5000 (94.1250) lr 2.4083e-05 eta 0:01:00
epoch [189/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.114) loss 0.5449 (0.3853) acc 84.3750 (89.3750) lr 2.0777e-05 eta 0:02:02
epoch [189/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.5093 (0.3648) acc 81.2500 (90.3125) lr 2.0777e-05 eta 0:01:26
epoch [189/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.1014 (0.3182) acc 100.0000 (92.2917) lr 2.0777e-05 eta 0:01:14
epoch [189/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.029) loss 0.3621 (0.3244) acc 87.5000 (92.1875) lr 2.0777e-05 eta 0:01:08
epoch [189/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2157 (0.3336) acc 90.6250 (91.6250) lr 2.0777e-05 eta 0:01:04
epoch [189/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.3889 (0.3428) acc 87.5000 (91.3542) lr 2.0777e-05 eta 0:01:01
epoch [189/200] batch [35/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2563 (0.3249) acc 93.7500 (91.6071) lr 2.0777e-05 eta 0:00:59
epoch [189/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1262 (0.3059) acc 100.0000 (92.3438) lr 2.0777e-05 eta 0:00:57
epoch [189/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1783 (0.3049) acc 96.8750 (92.5694) lr 2.0777e-05 eta 0:00:56
epoch [189/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3196 (0.3023) acc 93.7500 (92.6875) lr 2.0777e-05 eta 0:00:54
epoch [190/200] batch [5/51] time 0.089 (0.207) data 0.000 (0.119) loss 0.2520 (0.3330) acc 93.7500 (91.8750) lr 1.7713e-05 eta 0:01:54
epoch [190/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.5352 (0.3091) acc 87.5000 (92.8125) lr 1.7713e-05 eta 0:01:21
epoch [190/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.1034 (0.3123) acc 100.0000 (92.7083) lr 1.7713e-05 eta 0:01:09
epoch [190/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.0745 (0.2973) acc 100.0000 (93.2812) lr 1.7713e-05 eta 0:01:03
epoch [190/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3674 (0.2809) acc 90.6250 (93.7500) lr 1.7713e-05 eta 0:00:59
epoch [190/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2327 (0.2782) acc 96.8750 (93.7500) lr 1.7713e-05 eta 0:00:57
epoch [190/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2297 (0.2658) acc 93.7500 (94.1071) lr 1.7713e-05 eta 0:00:54
epoch [190/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3362 (0.2718) acc 84.3750 (93.8281) lr 1.7713e-05 eta 0:00:53
epoch [190/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2297 (0.2750) acc 96.8750 (93.7500) lr 1.7713e-05 eta 0:00:51
epoch [190/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3545 (0.2762) acc 90.6250 (93.6250) lr 1.7713e-05 eta 0:00:50
epoch [191/200] batch [5/51] time 0.087 (0.209) data 0.000 (0.122) loss 0.3264 (0.3336) acc 96.8750 (92.5000) lr 1.4891e-05 eta 0:01:45
epoch [191/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.4023 (0.3192) acc 87.5000 (92.1875) lr 1.4891e-05 eta 0:01:14
epoch [191/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.3047 (0.3365) acc 93.7500 (91.6667) lr 1.4891e-05 eta 0:01:03
epoch [191/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.2386 (0.3198) acc 96.8750 (92.1875) lr 1.4891e-05 eta 0:00:57
epoch [191/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3003 (0.3043) acc 90.6250 (92.5000) lr 1.4891e-05 eta 0:00:54
epoch [191/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.0958 (0.2870) acc 100.0000 (92.9167) lr 1.4891e-05 eta 0:00:51
epoch [191/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.2495 (0.2823) acc 96.8750 (93.5714) lr 1.4891e-05 eta 0:00:49
epoch [191/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2725 (0.2738) acc 96.8750 (93.9062) lr 1.4891e-05 eta 0:00:48
epoch [191/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3191 (0.2835) acc 93.7500 (93.6111) lr 1.4891e-05 eta 0:00:46
epoch [191/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2717 (0.2770) acc 96.8750 (93.8750) lr 1.4891e-05 eta 0:00:45
epoch [192/200] batch [5/51] time 0.087 (0.219) data 0.000 (0.132) loss 0.4150 (0.3524) acc 87.5000 (89.3750) lr 1.2312e-05 eta 0:01:39
epoch [192/200] batch [10/51] time 0.086 (0.153) data 0.000 (0.066) loss 0.1653 (0.2938) acc 100.0000 (92.1875) lr 1.2312e-05 eta 0:01:08
epoch [192/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.1114 (0.2672) acc 100.0000 (93.3333) lr 1.2312e-05 eta 0:00:58
epoch [192/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.1207 (0.2436) acc 96.8750 (94.0625) lr 1.2312e-05 eta 0:00:52
epoch [192/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.027) loss 0.1403 (0.2267) acc 96.8750 (94.8750) lr 1.2312e-05 eta 0:00:49
epoch [192/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1106 (0.2345) acc 100.0000 (94.6875) lr 1.2312e-05 eta 0:00:46
epoch [192/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.2925 (0.2442) acc 90.6250 (94.3750) lr 1.2312e-05 eta 0:00:44
epoch [192/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.2781 (0.2548) acc 90.6250 (93.9844) lr 1.2312e-05 eta 0:00:43
epoch [192/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1704 (0.2588) acc 96.8750 (93.8889) lr 1.2312e-05 eta 0:00:41
epoch [192/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3848 (0.2562) acc 90.6250 (93.8750) lr 1.2312e-05 eta 0:00:40
epoch [193/200] batch [5/51] time 0.088 (0.217) data 0.000 (0.130) loss 0.2849 (0.3738) acc 90.6250 (91.2500) lr 9.9763e-06 eta 0:01:27
epoch [193/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.2798 (0.3701) acc 90.6250 (90.9375) lr 9.9763e-06 eta 0:01:00
epoch [193/200] batch [15/51] time 0.086 (0.130) data 0.000 (0.043) loss 0.2377 (0.3441) acc 96.8750 (92.0833) lr 9.9763e-06 eta 0:00:51
epoch [193/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.033) loss 0.5024 (0.3181) acc 78.1250 (92.3438) lr 9.9763e-06 eta 0:00:46
epoch [193/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.026) loss 0.4172 (0.3113) acc 87.5000 (92.3750) lr 9.9763e-06 eta 0:00:43
epoch [193/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2720 (0.2942) acc 93.7500 (92.8125) lr 9.9763e-06 eta 0:00:41
epoch [193/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.2002 (0.3098) acc 93.7500 (92.3214) lr 9.9763e-06 eta 0:00:39
epoch [193/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1144 (0.3125) acc 96.8750 (92.1094) lr 9.9763e-06 eta 0:00:37
epoch [193/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2126 (0.3151) acc 96.8750 (91.9444) lr 9.9763e-06 eta 0:00:36
epoch [193/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3220 (0.3167) acc 90.6250 (91.8125) lr 9.9763e-06 eta 0:00:35
epoch [194/200] batch [5/51] time 0.088 (0.196) data 0.000 (0.108) loss 0.5557 (0.3602) acc 87.5000 (91.8750) lr 7.8853e-06 eta 0:01:08
epoch [194/200] batch [10/51] time 0.087 (0.141) data 0.000 (0.054) loss 0.3000 (0.3263) acc 90.6250 (92.1875) lr 7.8853e-06 eta 0:00:49
epoch [194/200] batch [15/51] time 0.086 (0.123) data 0.000 (0.036) loss 0.3201 (0.3049) acc 93.7500 (92.7083) lr 7.8853e-06 eta 0:00:42
epoch [194/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.1381 (0.2764) acc 96.8750 (93.1250) lr 7.8853e-06 eta 0:00:38
epoch [194/200] batch [25/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.2910 (0.2955) acc 96.8750 (92.8750) lr 7.8853e-06 eta 0:00:36
epoch [194/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3328 (0.2868) acc 93.7500 (93.1250) lr 7.8853e-06 eta 0:00:34
epoch [194/200] batch [35/51] time 0.087 (0.102) data 0.000 (0.016) loss 0.2507 (0.2886) acc 93.7500 (93.2143) lr 7.8853e-06 eta 0:00:32
epoch [194/200] batch [40/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.1831 (0.2868) acc 96.8750 (93.4375) lr 7.8853e-06 eta 0:00:31
epoch [194/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1069 (0.2779) acc 100.0000 (93.6806) lr 7.8853e-06 eta 0:00:30
epoch [194/200] batch [50/51] time 0.086 (0.097) data 0.000 (0.011) loss 0.1990 (0.2710) acc 93.7500 (93.9375) lr 7.8853e-06 eta 0:00:29
epoch [195/200] batch [5/51] time 0.087 (0.216) data 0.000 (0.128) loss 0.3452 (0.3499) acc 90.6250 (91.8750) lr 6.0390e-06 eta 0:01:05
epoch [195/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.064) loss 0.3059 (0.3705) acc 90.6250 (91.2500) lr 6.0390e-06 eta 0:00:44
epoch [195/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.1155 (0.2956) acc 100.0000 (93.5417) lr 6.0390e-06 eta 0:00:37
epoch [195/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.2551 (0.2917) acc 93.7500 (93.1250) lr 6.0390e-06 eta 0:00:34
epoch [195/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.3032 (0.2870) acc 90.6250 (93.1250) lr 6.0390e-06 eta 0:00:31
epoch [195/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.022) loss 0.3223 (0.2846) acc 84.3750 (92.8125) lr 6.0390e-06 eta 0:00:29
epoch [195/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.6611 (0.2881) acc 84.3750 (93.0357) lr 6.0390e-06 eta 0:00:28
epoch [195/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3474 (0.2771) acc 93.7500 (93.5938) lr 6.0390e-06 eta 0:00:27
epoch [195/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5762 (0.2865) acc 87.5000 (93.4028) lr 6.0390e-06 eta 0:00:26
epoch [195/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2605 (0.2784) acc 96.8750 (93.5625) lr 6.0390e-06 eta 0:00:25
epoch [196/200] batch [5/51] time 0.087 (0.203) data 0.000 (0.115) loss 0.3022 (0.3597) acc 96.8750 (93.1250) lr 4.4380e-06 eta 0:00:50
epoch [196/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.3318 (0.3883) acc 93.7500 (91.5625) lr 4.4380e-06 eta 0:00:35
epoch [196/200] batch [15/51] time 0.089 (0.126) data 0.000 (0.038) loss 0.3645 (0.3520) acc 87.5000 (91.8750) lr 4.4380e-06 eta 0:00:30
epoch [196/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.0941 (0.3221) acc 96.8750 (92.3438) lr 4.4380e-06 eta 0:00:27
epoch [196/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3035 (0.3208) acc 93.7500 (92.3750) lr 4.4380e-06 eta 0:00:25
epoch [196/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2269 (0.3270) acc 93.7500 (92.3958) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1458 (0.3135) acc 96.8750 (92.6786) lr 4.4380e-06 eta 0:00:22
epoch [196/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3708 (0.3035) acc 96.8750 (93.1250) lr 4.4380e-06 eta 0:00:21
epoch [196/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3301 (0.3072) acc 90.6250 (92.8472) lr 4.4380e-06 eta 0:00:20
epoch [196/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1511 (0.3018) acc 96.8750 (92.8750) lr 4.4380e-06 eta 0:00:20
epoch [197/200] batch [5/51] time 0.087 (0.208) data 0.000 (0.121) loss 0.6616 (0.3510) acc 81.2500 (91.8750) lr 3.0827e-06 eta 0:00:41
epoch [197/200] batch [10/51] time 0.086 (0.148) data 0.000 (0.061) loss 0.1398 (0.2992) acc 100.0000 (93.4375) lr 3.0827e-06 eta 0:00:28
epoch [197/200] batch [15/51] time 0.088 (0.127) data 0.000 (0.040) loss 0.1470 (0.2825) acc 100.0000 (94.1667) lr 3.0827e-06 eta 0:00:24
epoch [197/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.5337 (0.2825) acc 84.3750 (94.0625) lr 3.0827e-06 eta 0:00:21
epoch [197/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.2421 (0.2855) acc 93.7500 (94.0000) lr 3.0827e-06 eta 0:00:19
epoch [197/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4438 (0.2880) acc 84.3750 (93.7500) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1710 (0.2997) acc 96.8750 (93.3929) lr 3.0827e-06 eta 0:00:17
epoch [197/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2079 (0.3065) acc 96.8750 (93.3594) lr 3.0827e-06 eta 0:00:16
epoch [197/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2664 (0.3182) acc 96.8750 (92.9861) lr 3.0827e-06 eta 0:00:15
epoch [197/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1265 (0.3227) acc 96.8750 (92.8750) lr 3.0827e-06 eta 0:00:15
epoch [198/200] batch [5/51] time 0.091 (0.200) data 0.000 (0.112) loss 0.5269 (0.3126) acc 87.5000 (94.3750) lr 1.9733e-06 eta 0:00:29
epoch [198/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.056) loss 0.3274 (0.2945) acc 87.5000 (93.4375) lr 1.9733e-06 eta 0:00:20
epoch [198/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.038) loss 0.2815 (0.2885) acc 93.7500 (93.1250) lr 1.9733e-06 eta 0:00:17
epoch [198/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4487 (0.2915) acc 90.6250 (92.9688) lr 1.9733e-06 eta 0:00:15
epoch [198/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1709 (0.2741) acc 96.8750 (93.6250) lr 1.9733e-06 eta 0:00:14
epoch [198/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1073 (0.2606) acc 96.8750 (94.1667) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3652 (0.2670) acc 93.7500 (94.1071) lr 1.9733e-06 eta 0:00:12
epoch [198/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2803 (0.2647) acc 96.8750 (94.2188) lr 1.9733e-06 eta 0:00:11
epoch [198/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2173 (0.2688) acc 93.7500 (94.3056) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1482 (0.2727) acc 100.0000 (94.1250) lr 1.9733e-06 eta 0:00:10
epoch [199/200] batch [5/51] time 0.088 (0.223) data 0.000 (0.135) loss 0.1942 (0.2591) acc 96.8750 (94.3750) lr 1.1101e-06 eta 0:00:21
epoch [199/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.4556 (0.2882) acc 87.5000 (92.8125) lr 1.1101e-06 eta 0:00:14
epoch [199/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.0734 (0.2658) acc 100.0000 (93.9583) lr 1.1101e-06 eta 0:00:11
epoch [199/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.2001 (0.2757) acc 93.7500 (93.5938) lr 1.1101e-06 eta 0:00:09
epoch [199/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3584 (0.2684) acc 93.7500 (94.0000) lr 1.1101e-06 eta 0:00:08
epoch [199/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2229 (0.2688) acc 96.8750 (94.1667) lr 1.1101e-06 eta 0:00:07
epoch [199/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3611 (0.2761) acc 90.6250 (94.1071) lr 1.1101e-06 eta 0:00:07
epoch [199/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2471 (0.2800) acc 90.6250 (93.8281) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [45/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.4341 (0.2791) acc 87.5000 (93.6806) lr 1.1101e-06 eta 0:00:05
epoch [199/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2302 (0.2758) acc 93.7500 (93.8125) lr 1.1101e-06 eta 0:00:05
epoch [200/200] batch [5/51] time 0.089 (0.216) data 0.001 (0.128) loss 0.1643 (0.1924) acc 96.8750 (95.6250) lr 4.9344e-07 eta 0:00:09
epoch [200/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.064) loss 0.3630 (0.2218) acc 90.6250 (94.6875) lr 4.9344e-07 eta 0:00:06
epoch [200/200] batch [15/51] time 0.088 (0.130) data 0.000 (0.043) loss 0.2061 (0.2482) acc 96.8750 (94.3750) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.3438 (0.2673) acc 93.7500 (93.4375) lr 4.9344e-07 eta 0:00:03
epoch [200/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.3818 (0.2692) acc 90.6250 (93.6250) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2345 (0.2945) acc 96.8750 (92.9167) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.2462 (0.2842) acc 93.7500 (93.3036) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.0714 (0.2829) acc 100.0000 (93.2031) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2922 (0.2813) acc 93.7500 (93.1250) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.4763 (0.2871) acc 84.3750 (92.8125) lr 4.9344e-07 eta 0:00:00
Checkpoint saved to output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:02<00:50,  2.09s/it]  8%|▊         | 2/25 [00:02<00:21,  1.07it/s] 12%|█▏        | 3/25 [00:02<00:12,  1.77it/s] 16%|█▌        | 4/25 [00:02<00:08,  2.56it/s] 20%|██        | 5/25 [00:02<00:05,  3.40it/s] 24%|██▍       | 6/25 [00:02<00:04,  4.24it/s] 28%|██▊       | 7/25 [00:02<00:03,  5.03it/s] 32%|███▏      | 8/25 [00:02<00:02,  5.72it/s] 36%|███▌      | 9/25 [00:03<00:05,  3.12it/s] 40%|████      | 10/25 [00:03<00:03,  3.85it/s] 44%|████▍     | 11/25 [00:03<00:03,  4.59it/s] 48%|████▊     | 12/25 [00:03<00:02,  5.29it/s] 52%|█████▏    | 13/25 [00:04<00:02,  5.93it/s] 56%|█████▌    | 14/25 [00:04<00:01,  6.46it/s] 60%|██████    | 15/25 [00:04<00:01,  6.88it/s] 64%|██████▍   | 16/25 [00:04<00:01,  7.22it/s] 68%|██████▊   | 17/25 [00:05<00:02,  3.42it/s] 72%|███████▏  | 18/25 [00:05<00:01,  4.14it/s] 76%|███████▌  | 19/25 [00:05<00:01,  4.86it/s] 80%|████████  | 20/25 [00:05<00:00,  5.54it/s] 84%|████████▍ | 21/25 [00:05<00:00,  6.13it/s] 88%|████████▊ | 22/25 [00:05<00:00,  6.63it/s] 92%|█████████▏| 23/25 [00:05<00:00,  7.03it/s] 96%|█████████▌| 24/25 [00:05<00:00,  7.34it/s]100%|██████████| 25/25 [00:06<00:00,  4.07it/s]
=> result
* total: 2,463
* correct: 2,374
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.4%
Elapsed: 0:17:16
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_train.sh oxford_flowers 3 0 vit_b16_ctxv1 16 CoOp
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_3.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/200] batch [5/51] time 0.086 (0.578) data 0.000 (0.180) loss 2.3027 (2.4092) acc 53.1250 (50.0000) lr 1.0000e-05 eta 1:38:12
epoch [1/200] batch [10/51] time 0.086 (0.332) data 0.000 (0.090) loss 2.3496 (2.1990) acc 56.2500 (56.2500) lr 1.0000e-05 eta 0:56:26
epoch [1/200] batch [15/51] time 0.087 (0.250) data 0.000 (0.060) loss 2.2383 (2.1937) acc 62.5000 (57.0833) lr 1.0000e-05 eta 0:42:30
epoch [1/200] batch [20/51] time 0.086 (0.209) data 0.000 (0.045) loss 1.4629 (2.0512) acc 71.8750 (58.9062) lr 1.0000e-05 eta 0:35:31
epoch [1/200] batch [25/51] time 0.086 (0.185) data 0.000 (0.036) loss 1.6445 (1.9801) acc 59.3750 (60.0000) lr 1.0000e-05 eta 0:31:20
epoch [1/200] batch [30/51] time 0.087 (0.168) data 0.000 (0.030) loss 2.4297 (2.0101) acc 59.3750 (59.6875) lr 1.0000e-05 eta 0:28:32
epoch [1/200] batch [35/51] time 0.086 (0.157) data 0.000 (0.026) loss 1.2041 (1.9798) acc 65.6250 (60.0000) lr 1.0000e-05 eta 0:26:32
epoch [1/200] batch [40/51] time 0.086 (0.148) data 0.000 (0.023) loss 2.2148 (2.0103) acc 62.5000 (59.5312) lr 1.0000e-05 eta 0:25:02
epoch [1/200] batch [45/51] time 0.085 (0.141) data 0.000 (0.020) loss 2.3086 (2.0128) acc 62.5000 (59.5833) lr 1.0000e-05 eta 0:23:51
epoch [1/200] batch [50/51] time 0.085 (0.135) data 0.000 (0.018) loss 1.1475 (1.9978) acc 65.6250 (60.0000) lr 1.0000e-05 eta 0:22:54
epoch [2/200] batch [5/51] time 0.086 (0.224) data 0.001 (0.137) loss 2.2695 (1.8691) acc 50.0000 (60.0000) lr 2.0000e-03 eta 0:37:55
epoch [2/200] batch [10/51] time 0.086 (0.155) data 0.000 (0.068) loss 1.5791 (1.6810) acc 59.3750 (61.2500) lr 2.0000e-03 eta 0:26:15
epoch [2/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.046) loss 1.5215 (1.5821) acc 59.3750 (61.0417) lr 2.0000e-03 eta 0:22:20
epoch [2/200] batch [20/51] time 0.086 (0.121) data 0.000 (0.034) loss 1.4189 (1.6007) acc 62.5000 (61.2500) lr 2.0000e-03 eta 0:20:22
epoch [2/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.028) loss 1.0225 (1.5070) acc 71.8750 (62.8750) lr 2.0000e-03 eta 0:19:12
epoch [2/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.023) loss 1.5938 (1.5323) acc 65.6250 (62.3958) lr 2.0000e-03 eta 0:18:25
epoch [2/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.020) loss 1.3633 (1.5016) acc 71.8750 (62.9464) lr 2.0000e-03 eta 0:17:51
epoch [2/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 1.1943 (1.4697) acc 71.8750 (63.2812) lr 2.0000e-03 eta 0:17:25
epoch [2/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 2.0781 (1.4823) acc 43.7500 (62.9861) lr 2.0000e-03 eta 0:17:04
epoch [2/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 1.4648 (1.4744) acc 53.1250 (63.0625) lr 2.0000e-03 eta 0:16:48
epoch [3/200] batch [5/51] time 0.087 (0.206) data 0.000 (0.118) loss 1.0684 (1.1800) acc 68.7500 (67.5000) lr 1.9999e-03 eta 0:34:39
epoch [3/200] batch [10/51] time 0.086 (0.146) data 0.000 (0.059) loss 1.2676 (1.1513) acc 68.7500 (68.7500) lr 1.9999e-03 eta 0:24:36
epoch [3/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.040) loss 1.3037 (1.2031) acc 62.5000 (67.5000) lr 1.9999e-03 eta 0:21:14
epoch [3/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.030) loss 0.9883 (1.1908) acc 65.6250 (68.1250) lr 1.9999e-03 eta 0:19:32
epoch [3/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.024) loss 1.3857 (1.2055) acc 71.8750 (67.7500) lr 1.9999e-03 eta 0:18:31
epoch [3/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.020) loss 0.9502 (1.2042) acc 75.0000 (68.0208) lr 1.9999e-03 eta 0:17:51
epoch [3/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 1.2822 (1.2064) acc 71.8750 (67.8571) lr 1.9999e-03 eta 0:17:22
epoch [3/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.8843 (1.1745) acc 71.8750 (68.1250) lr 1.9999e-03 eta 0:16:59
epoch [3/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 1.0889 (1.1541) acc 62.5000 (68.3333) lr 1.9999e-03 eta 0:16:40
epoch [3/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 1.0527 (1.1510) acc 71.8750 (68.2500) lr 1.9999e-03 eta 0:16:25
epoch [4/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.113) loss 1.0889 (0.9601) acc 75.0000 (74.3750) lr 1.9995e-03 eta 0:33:38
epoch [4/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 1.1895 (1.0053) acc 75.0000 (75.0000) lr 1.9995e-03 eta 0:24:04
epoch [4/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.038) loss 1.1084 (1.0818) acc 75.0000 (72.5000) lr 1.9995e-03 eta 0:20:52
epoch [4/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.029) loss 1.5293 (1.1185) acc 59.3750 (71.4062) lr 1.9995e-03 eta 0:19:16
epoch [4/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 1.2686 (1.1131) acc 59.3750 (70.0000) lr 1.9995e-03 eta 0:18:18
epoch [4/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.6304 (1.0851) acc 81.2500 (70.9375) lr 1.9995e-03 eta 0:17:40
epoch [4/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 1.0410 (1.0656) acc 65.6250 (71.6964) lr 1.9995e-03 eta 0:17:12
epoch [4/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 1.3545 (1.0802) acc 71.8750 (71.5625) lr 1.9995e-03 eta 0:16:50
epoch [4/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 1.1270 (1.0769) acc 71.8750 (71.4583) lr 1.9995e-03 eta 0:16:33
epoch [4/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 1.1016 (1.0731) acc 75.0000 (71.6250) lr 1.9995e-03 eta 0:16:19
epoch [5/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.124) loss 0.8237 (1.0923) acc 75.0000 (69.3750) lr 1.9989e-03 eta 0:35:08
epoch [5/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 0.5186 (0.9044) acc 90.6250 (75.0000) lr 1.9989e-03 eta 0:24:46
epoch [5/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.042) loss 0.9624 (0.9014) acc 71.8750 (74.3750) lr 1.9989e-03 eta 0:21:18
epoch [5/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 1.0244 (0.8936) acc 68.7500 (74.8438) lr 1.9989e-03 eta 0:19:33
epoch [5/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.025) loss 0.7383 (0.8745) acc 78.1250 (75.2500) lr 1.9989e-03 eta 0:18:30
epoch [5/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 1.2773 (0.9211) acc 59.3750 (74.1667) lr 1.9989e-03 eta 0:17:48
epoch [5/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.6162 (0.8899) acc 81.2500 (74.8214) lr 1.9989e-03 eta 0:17:18
epoch [5/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.8940 (0.8939) acc 75.0000 (74.9219) lr 1.9989e-03 eta 0:16:55
epoch [5/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 1.0674 (0.8990) acc 78.1250 (75.0000) lr 1.9989e-03 eta 0:16:36
epoch [5/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.9902 (0.9123) acc 71.8750 (74.8125) lr 1.9989e-03 eta 0:16:22
epoch [6/200] batch [5/51] time 0.087 (0.218) data 0.001 (0.131) loss 0.7300 (0.8700) acc 78.1250 (76.8750) lr 1.9980e-03 eta 0:36:04
epoch [6/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.9824 (0.9233) acc 78.1250 (75.3125) lr 1.9980e-03 eta 0:25:11
epoch [6/200] batch [15/51] time 0.086 (0.130) data 0.000 (0.044) loss 0.7578 (0.9000) acc 84.3750 (75.8333) lr 1.9980e-03 eta 0:21:33
epoch [6/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.033) loss 0.7056 (0.8825) acc 78.1250 (76.0938) lr 1.9980e-03 eta 0:19:44
epoch [6/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 1.0645 (0.8752) acc 71.8750 (76.7500) lr 1.9980e-03 eta 0:18:38
epoch [6/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.022) loss 0.6416 (0.8798) acc 84.3750 (76.4583) lr 1.9980e-03 eta 0:17:55
epoch [6/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.7090 (0.8641) acc 84.3750 (76.4286) lr 1.9980e-03 eta 0:17:23
epoch [6/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.9741 (0.8730) acc 75.0000 (76.1719) lr 1.9980e-03 eta 0:16:59
epoch [6/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.7461 (0.8560) acc 84.3750 (76.7361) lr 1.9980e-03 eta 0:16:39
epoch [6/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.7241 (0.8462) acc 75.0000 (76.6875) lr 1.9980e-03 eta 0:16:23
epoch [7/200] batch [5/51] time 0.088 (0.212) data 0.000 (0.124) loss 0.8433 (0.7969) acc 68.7500 (78.1250) lr 1.9969e-03 eta 0:34:55
epoch [7/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.6719 (0.7957) acc 81.2500 (77.1875) lr 1.9969e-03 eta 0:24:37
epoch [7/200] batch [15/51] time 0.088 (0.129) data 0.000 (0.042) loss 0.7637 (0.7752) acc 81.2500 (79.3750) lr 1.9969e-03 eta 0:21:10
epoch [7/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.9360 (0.7872) acc 75.0000 (80.0000) lr 1.9969e-03 eta 0:19:26
epoch [7/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.5947 (0.7788) acc 78.1250 (80.0000) lr 1.9969e-03 eta 0:18:24
epoch [7/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.8477 (0.8029) acc 81.2500 (79.2708) lr 1.9969e-03 eta 0:17:42
epoch [7/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.4790 (0.7814) acc 90.6250 (79.5536) lr 1.9969e-03 eta 0:17:12
epoch [7/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.4148 (0.7753) acc 87.5000 (80.0000) lr 1.9969e-03 eta 0:16:49
epoch [7/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.7251 (0.7577) acc 75.0000 (80.3472) lr 1.9969e-03 eta 0:16:30
epoch [7/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.6567 (0.7556) acc 75.0000 (80.3750) lr 1.9969e-03 eta 0:16:16
epoch [8/200] batch [5/51] time 0.086 (0.205) data 0.000 (0.118) loss 0.6626 (0.5160) acc 90.6250 (89.3750) lr 1.9956e-03 eta 0:33:37
epoch [8/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.7427 (0.5683) acc 68.7500 (84.3750) lr 1.9956e-03 eta 0:23:58
epoch [8/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.040) loss 0.5215 (0.6035) acc 81.2500 (82.5000) lr 1.9956e-03 eta 0:20:41
epoch [8/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.030) loss 0.7876 (0.6642) acc 75.0000 (81.0938) lr 1.9956e-03 eta 0:19:03
epoch [8/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.024) loss 0.6499 (0.6512) acc 78.1250 (81.5000) lr 1.9956e-03 eta 0:18:03
epoch [8/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.020) loss 0.4966 (0.6525) acc 81.2500 (81.7708) lr 1.9956e-03 eta 0:17:23
epoch [8/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.8667 (0.6429) acc 71.8750 (82.0536) lr 1.9956e-03 eta 0:16:55
epoch [8/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.4614 (0.6350) acc 84.3750 (82.3438) lr 1.9956e-03 eta 0:16:33
epoch [8/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.5459 (0.6292) acc 84.3750 (82.3611) lr 1.9956e-03 eta 0:16:15
epoch [8/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.6270 (0.6312) acc 84.3750 (82.2500) lr 1.9956e-03 eta 0:16:01
epoch [9/200] batch [5/51] time 0.087 (0.221) data 0.000 (0.133) loss 0.5068 (0.5139) acc 87.5000 (87.5000) lr 1.9940e-03 eta 0:35:58
epoch [9/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.3184 (0.5096) acc 93.7500 (86.8750) lr 1.9940e-03 eta 0:25:04
epoch [9/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.3477 (0.5355) acc 87.5000 (85.8333) lr 1.9940e-03 eta 0:21:25
epoch [9/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.4971 (0.5457) acc 81.2500 (85.1562) lr 1.9940e-03 eta 0:19:35
epoch [9/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.7861 (0.5632) acc 84.3750 (85.3750) lr 1.9940e-03 eta 0:18:29
epoch [9/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.7363 (0.5761) acc 78.1250 (84.8958) lr 1.9940e-03 eta 0:17:46
epoch [9/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3928 (0.5827) acc 90.6250 (84.6429) lr 1.9940e-03 eta 0:17:14
epoch [9/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.6753 (0.5779) acc 81.2500 (84.6875) lr 1.9940e-03 eta 0:16:50
epoch [9/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4680 (0.5675) acc 84.3750 (84.8611) lr 1.9940e-03 eta 0:16:30
epoch [9/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.7144 (0.5761) acc 78.1250 (84.5625) lr 1.9940e-03 eta 0:16:14
epoch [10/200] batch [5/51] time 0.089 (0.203) data 0.000 (0.114) loss 0.3999 (0.4683) acc 90.6250 (86.8750) lr 1.9921e-03 eta 0:32:54
epoch [10/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.4819 (0.5695) acc 84.3750 (85.0000) lr 1.9921e-03 eta 0:23:31
epoch [10/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.6738 (0.5722) acc 81.2500 (85.8333) lr 1.9921e-03 eta 0:20:24
epoch [10/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.6001 (0.5620) acc 90.6250 (85.9375) lr 1.9921e-03 eta 0:18:49
epoch [10/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.7095 (0.5523) acc 84.3750 (85.7500) lr 1.9921e-03 eta 0:17:52
epoch [10/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3877 (0.5445) acc 96.8750 (86.3542) lr 1.9921e-03 eta 0:17:13
epoch [10/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.5459 (0.5596) acc 87.5000 (85.8929) lr 1.9921e-03 eta 0:16:46
epoch [10/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.6147 (0.5733) acc 78.1250 (85.3125) lr 1.9921e-03 eta 0:16:24
epoch [10/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.4836 (0.5789) acc 87.5000 (85.1389) lr 1.9921e-03 eta 0:16:07
epoch [10/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.4287 (0.5829) acc 87.5000 (85.0625) lr 1.9921e-03 eta 0:15:53
epoch [11/200] batch [5/51] time 0.088 (0.220) data 0.000 (0.131) loss 0.3557 (0.5057) acc 87.5000 (86.2500) lr 1.9900e-03 eta 0:35:28
epoch [11/200] batch [10/51] time 0.086 (0.153) data 0.000 (0.066) loss 0.4006 (0.5326) acc 93.7500 (87.5000) lr 1.9900e-03 eta 0:24:44
epoch [11/200] batch [15/51] time 0.090 (0.131) data 0.000 (0.044) loss 0.3828 (0.5566) acc 93.7500 (86.8750) lr 1.9900e-03 eta 0:21:12
epoch [11/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3872 (0.5080) acc 93.7500 (87.9688) lr 1.9900e-03 eta 0:19:22
epoch [11/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.9580 (0.5516) acc 78.1250 (86.3750) lr 1.9900e-03 eta 0:18:17
epoch [11/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.6509 (0.5522) acc 81.2500 (86.0417) lr 1.9900e-03 eta 0:17:35
epoch [11/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.8223 (0.5690) acc 75.0000 (85.2679) lr 1.9900e-03 eta 0:17:03
epoch [11/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.4214 (0.5737) acc 96.8750 (85.3906) lr 1.9900e-03 eta 0:16:39
epoch [11/200] batch [45/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.5317 (0.5556) acc 87.5000 (85.6250) lr 1.9900e-03 eta 0:16:19
epoch [11/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4211 (0.5529) acc 93.7500 (85.8750) lr 1.9900e-03 eta 0:16:03
epoch [12/200] batch [5/51] time 0.087 (0.216) data 0.000 (0.128) loss 0.5283 (0.4669) acc 81.2500 (86.8750) lr 1.9877e-03 eta 0:34:39
epoch [12/200] batch [10/51] time 0.086 (0.152) data 0.000 (0.064) loss 0.6660 (0.5497) acc 84.3750 (85.0000) lr 1.9877e-03 eta 0:24:19
epoch [12/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.3948 (0.5580) acc 93.7500 (84.5833) lr 1.9877e-03 eta 0:20:50
epoch [12/200] batch [20/51] time 0.088 (0.119) data 0.000 (0.032) loss 0.5308 (0.5509) acc 81.2500 (84.5312) lr 1.9877e-03 eta 0:19:08
epoch [12/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.5044 (0.5514) acc 93.7500 (85.0000) lr 1.9877e-03 eta 0:18:06
epoch [12/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.6685 (0.5570) acc 78.1250 (84.8958) lr 1.9877e-03 eta 0:17:24
epoch [12/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.6196 (0.5628) acc 90.6250 (85.1786) lr 1.9877e-03 eta 0:16:54
epoch [12/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.5000 (0.5570) acc 84.3750 (85.7031) lr 1.9877e-03 eta 0:16:30
epoch [12/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4238 (0.5480) acc 87.5000 (85.6944) lr 1.9877e-03 eta 0:16:11
epoch [12/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.7959 (0.5543) acc 78.1250 (85.5000) lr 1.9877e-03 eta 0:15:56
epoch [13/200] batch [5/51] time 0.088 (0.221) data 0.000 (0.132) loss 0.5430 (0.4608) acc 90.6250 (91.2500) lr 1.9851e-03 eta 0:35:19
epoch [13/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.066) loss 0.6177 (0.5151) acc 90.6250 (90.0000) lr 1.9851e-03 eta 0:24:38
epoch [13/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.044) loss 0.5371 (0.5215) acc 90.6250 (88.1250) lr 1.9851e-03 eta 0:21:03
epoch [13/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.4031 (0.4962) acc 90.6250 (88.1250) lr 1.9851e-03 eta 0:19:12
epoch [13/200] batch [25/51] time 0.085 (0.114) data 0.000 (0.027) loss 0.2377 (0.5084) acc 90.6250 (87.7500) lr 1.9851e-03 eta 0:18:06
epoch [13/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.5693 (0.5037) acc 84.3750 (88.0208) lr 1.9851e-03 eta 0:17:23
epoch [13/200] batch [35/51] time 0.085 (0.106) data 0.000 (0.019) loss 0.3550 (0.5236) acc 84.3750 (87.5000) lr 1.9851e-03 eta 0:16:50
epoch [13/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.6562 (0.5226) acc 78.1250 (87.1094) lr 1.9851e-03 eta 0:16:26
epoch [13/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.4929 (0.5127) acc 90.6250 (87.3611) lr 1.9851e-03 eta 0:16:07
epoch [13/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.6655 (0.5147) acc 78.1250 (87.0625) lr 1.9851e-03 eta 0:15:51
epoch [14/200] batch [5/51] time 0.088 (0.227) data 0.000 (0.140) loss 0.6294 (0.5237) acc 84.3750 (86.2500) lr 1.9823e-03 eta 0:36:04
epoch [14/200] batch [10/51] time 0.087 (0.157) data 0.000 (0.070) loss 0.4890 (0.5036) acc 90.6250 (87.1875) lr 1.9823e-03 eta 0:24:56
epoch [14/200] batch [15/51] time 0.087 (0.134) data 0.000 (0.047) loss 0.4641 (0.5011) acc 90.6250 (86.6667) lr 1.9823e-03 eta 0:21:14
epoch [14/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.5894 (0.5287) acc 84.3750 (85.7812) lr 1.9823e-03 eta 0:19:22
epoch [14/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.8228 (0.5478) acc 81.2500 (85.5000) lr 1.9823e-03 eta 0:18:15
epoch [14/200] batch [30/51] time 0.088 (0.111) data 0.000 (0.023) loss 0.4973 (0.5473) acc 87.5000 (85.6250) lr 1.9823e-03 eta 0:17:30
epoch [14/200] batch [35/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.4907 (0.5705) acc 87.5000 (85.0000) lr 1.9823e-03 eta 0:16:58
epoch [14/200] batch [40/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.5376 (0.5538) acc 84.3750 (85.3125) lr 1.9823e-03 eta 0:16:33
epoch [14/200] batch [45/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.6260 (0.5540) acc 87.5000 (85.4167) lr 1.9823e-03 eta 0:16:12
epoch [14/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3708 (0.5447) acc 87.5000 (85.4375) lr 1.9823e-03 eta 0:15:56
epoch [15/200] batch [5/51] time 0.088 (0.204) data 0.000 (0.116) loss 0.7798 (0.5414) acc 81.2500 (88.1250) lr 1.9792e-03 eta 0:32:16
epoch [15/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.4478 (0.5274) acc 87.5000 (87.8125) lr 1.9792e-03 eta 0:23:01
epoch [15/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.6899 (0.5317) acc 81.2500 (86.4583) lr 1.9792e-03 eta 0:19:56
epoch [15/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.029) loss 0.2866 (0.5231) acc 96.8750 (86.8750) lr 1.9792e-03 eta 0:18:23
epoch [15/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.023) loss 0.5425 (0.5249) acc 78.1250 (86.5000) lr 1.9792e-03 eta 0:17:27
epoch [15/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.6392 (0.5236) acc 84.3750 (86.7708) lr 1.9792e-03 eta 0:16:50
epoch [15/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3674 (0.5257) acc 90.6250 (86.5179) lr 1.9792e-03 eta 0:16:23
epoch [15/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3699 (0.5326) acc 87.5000 (86.1719) lr 1.9792e-03 eta 0:16:02
epoch [15/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.6787 (0.5403) acc 84.3750 (86.0417) lr 1.9792e-03 eta 0:15:44
epoch [15/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.4578 (0.5364) acc 87.5000 (86.3125) lr 1.9792e-03 eta 0:15:30
epoch [16/200] batch [5/51] time 0.087 (0.214) data 0.000 (0.127) loss 0.3428 (0.3880) acc 90.6250 (90.6250) lr 1.9759e-03 eta 0:33:39
epoch [16/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.5386 (0.4322) acc 81.2500 (88.7500) lr 1.9759e-03 eta 0:23:38
epoch [16/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.3276 (0.4622) acc 90.6250 (88.1250) lr 1.9759e-03 eta 0:20:16
epoch [16/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.032) loss 0.2559 (0.4471) acc 96.8750 (88.9062) lr 1.9759e-03 eta 0:18:34
epoch [16/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.8428 (0.4621) acc 78.1250 (88.3750) lr 1.9759e-03 eta 0:17:33
epoch [16/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.021) loss 0.3005 (0.4795) acc 93.7500 (87.8125) lr 1.9759e-03 eta 0:16:52
epoch [16/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.5688 (0.4816) acc 84.3750 (87.8571) lr 1.9759e-03 eta 0:16:24
epoch [16/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.5786 (0.4796) acc 87.5000 (88.1250) lr 1.9759e-03 eta 0:16:02
epoch [16/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5186 (0.4967) acc 84.3750 (87.2917) lr 1.9759e-03 eta 0:15:44
epoch [16/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.6167 (0.5035) acc 87.5000 (87.0000) lr 1.9759e-03 eta 0:15:29
epoch [17/200] batch [5/51] time 0.087 (0.209) data 0.000 (0.121) loss 0.5249 (0.4093) acc 84.3750 (89.3750) lr 1.9724e-03 eta 0:32:41
epoch [17/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.2325 (0.3871) acc 93.7500 (90.9375) lr 1.9724e-03 eta 0:23:06
epoch [17/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.5776 (0.4549) acc 84.3750 (89.1667) lr 1.9724e-03 eta 0:19:54
epoch [17/200] batch [20/51] time 0.089 (0.117) data 0.000 (0.030) loss 0.6416 (0.4646) acc 90.6250 (88.9062) lr 1.9724e-03 eta 0:18:19
epoch [17/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.6143 (0.4701) acc 84.3750 (88.2500) lr 1.9724e-03 eta 0:17:21
epoch [17/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.6201 (0.4741) acc 84.3750 (88.1250) lr 1.9724e-03 eta 0:16:43
epoch [17/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1703 (0.4694) acc 96.8750 (88.1250) lr 1.9724e-03 eta 0:16:16
epoch [17/200] batch [40/51] time 0.088 (0.102) data 0.000 (0.015) loss 0.4443 (0.4649) acc 90.6250 (88.3594) lr 1.9724e-03 eta 0:15:54
epoch [17/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4631 (0.4765) acc 87.5000 (87.9861) lr 1.9724e-03 eta 0:15:37
epoch [17/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.6162 (0.4695) acc 81.2500 (88.1250) lr 1.9724e-03 eta 0:15:23
epoch [18/200] batch [5/51] time 0.088 (0.200) data 0.000 (0.112) loss 0.6450 (0.5925) acc 87.5000 (86.8750) lr 1.9686e-03 eta 0:31:08
epoch [18/200] batch [10/51] time 0.089 (0.144) data 0.000 (0.056) loss 0.3450 (0.5134) acc 96.8750 (88.7500) lr 1.9686e-03 eta 0:22:21
epoch [18/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.038) loss 0.7549 (0.5244) acc 87.5000 (87.2917) lr 1.9686e-03 eta 0:19:28
epoch [18/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.3979 (0.5513) acc 90.6250 (85.7812) lr 1.9686e-03 eta 0:17:57
epoch [18/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.3022 (0.5126) acc 87.5000 (86.6250) lr 1.9686e-03 eta 0:17:04
epoch [18/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.4709 (0.5021) acc 81.2500 (87.1875) lr 1.9686e-03 eta 0:16:28
epoch [18/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.016) loss 0.5239 (0.4763) acc 81.2500 (87.7679) lr 1.9686e-03 eta 0:16:02
epoch [18/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.2793 (0.4928) acc 96.8750 (87.1875) lr 1.9686e-03 eta 0:15:41
epoch [18/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.6455 (0.4905) acc 87.5000 (87.5000) lr 1.9686e-03 eta 0:15:24
epoch [18/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.2756 (0.4831) acc 93.7500 (87.5625) lr 1.9686e-03 eta 0:15:10
epoch [19/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.125) loss 0.5791 (0.4818) acc 84.3750 (86.8750) lr 1.9646e-03 eta 0:32:51
epoch [19/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.2749 (0.4320) acc 96.8750 (90.0000) lr 1.9646e-03 eta 0:23:08
epoch [19/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.3594 (0.4324) acc 87.5000 (89.7917) lr 1.9646e-03 eta 0:19:54
epoch [19/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.032) loss 0.7100 (0.4388) acc 81.2500 (88.9062) lr 1.9646e-03 eta 0:18:17
epoch [19/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.7554 (0.4389) acc 81.2500 (89.0000) lr 1.9646e-03 eta 0:17:17
epoch [19/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3767 (0.4389) acc 93.7500 (89.0625) lr 1.9646e-03 eta 0:16:38
epoch [19/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.4094 (0.4204) acc 93.7500 (89.8214) lr 1.9646e-03 eta 0:16:10
epoch [19/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2190 (0.4165) acc 93.7500 (89.7656) lr 1.9646e-03 eta 0:15:47
epoch [19/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.8306 (0.4270) acc 84.3750 (89.4444) lr 1.9646e-03 eta 0:15:29
epoch [19/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4817 (0.4327) acc 84.3750 (89.4375) lr 1.9646e-03 eta 0:15:15
epoch [20/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.113) loss 0.5967 (0.4307) acc 84.3750 (87.5000) lr 1.9603e-03 eta 0:30:49
epoch [20/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.4290 (0.4315) acc 90.6250 (88.7500) lr 1.9603e-03 eta 0:22:04
epoch [20/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.6191 (0.4983) acc 84.3750 (87.2917) lr 1.9603e-03 eta 0:19:08
epoch [20/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.7539 (0.5207) acc 84.3750 (87.1875) lr 1.9603e-03 eta 0:17:41
epoch [20/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.5132 (0.4959) acc 81.2500 (87.5000) lr 1.9603e-03 eta 0:16:47
epoch [20/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.6567 (0.5066) acc 78.1250 (86.9792) lr 1.9603e-03 eta 0:16:12
epoch [20/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.6436 (0.4954) acc 87.5000 (87.4107) lr 1.9603e-03 eta 0:15:47
epoch [20/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1692 (0.4811) acc 96.8750 (87.6562) lr 1.9603e-03 eta 0:15:27
epoch [20/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.4946 (0.4810) acc 84.3750 (87.5694) lr 1.9603e-03 eta 0:15:11
epoch [20/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3491 (0.4665) acc 93.7500 (88.0000) lr 1.9603e-03 eta 0:14:58
epoch [21/200] batch [5/51] time 0.087 (0.218) data 0.000 (0.130) loss 0.7524 (0.3983) acc 75.0000 (88.7500) lr 1.9558e-03 eta 0:33:20
epoch [21/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.065) loss 0.6138 (0.4309) acc 87.5000 (88.4375) lr 1.9558e-03 eta 0:23:19
epoch [21/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.6929 (0.4642) acc 84.3750 (87.9167) lr 1.9558e-03 eta 0:19:58
epoch [21/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.2230 (0.4320) acc 96.8750 (88.7500) lr 1.9558e-03 eta 0:18:17
epoch [21/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.026) loss 0.4285 (0.4228) acc 90.6250 (88.8750) lr 1.9558e-03 eta 0:17:16
epoch [21/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.5044 (0.4139) acc 84.3750 (88.9583) lr 1.9558e-03 eta 0:16:36
epoch [21/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.5312 (0.4180) acc 84.3750 (88.7500) lr 1.9558e-03 eta 0:16:07
epoch [21/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.6680 (0.4248) acc 87.5000 (89.0625) lr 1.9558e-03 eta 0:15:44
epoch [21/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4221 (0.4208) acc 90.6250 (89.2361) lr 1.9558e-03 eta 0:15:26
epoch [21/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3582 (0.4271) acc 87.5000 (89.0625) lr 1.9558e-03 eta 0:15:11
epoch [22/200] batch [5/51] time 0.086 (0.200) data 0.000 (0.112) loss 0.5786 (0.4287) acc 84.3750 (90.0000) lr 1.9511e-03 eta 0:30:22
epoch [22/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.3264 (0.4549) acc 96.8750 (90.3125) lr 1.9511e-03 eta 0:21:46
epoch [22/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.3821 (0.4520) acc 84.3750 (89.1667) lr 1.9511e-03 eta 0:18:56
epoch [22/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3594 (0.4614) acc 87.5000 (88.4375) lr 1.9511e-03 eta 0:17:29
epoch [22/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1554 (0.4310) acc 100.0000 (89.2500) lr 1.9511e-03 eta 0:16:37
epoch [22/200] batch [30/51] time 0.090 (0.106) data 0.000 (0.019) loss 0.5562 (0.4312) acc 84.3750 (89.2708) lr 1.9511e-03 eta 0:16:03
epoch [22/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4580 (0.4240) acc 93.7500 (89.5536) lr 1.9511e-03 eta 0:15:38
epoch [22/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2188 (0.4156) acc 96.8750 (89.6875) lr 1.9511e-03 eta 0:15:19
epoch [22/200] batch [45/51] time 0.087 (0.099) data 0.000 (0.013) loss 0.2832 (0.4215) acc 93.7500 (89.5833) lr 1.9511e-03 eta 0:15:03
epoch [22/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.5229 (0.4362) acc 84.3750 (89.0000) lr 1.9511e-03 eta 0:14:51
epoch [23/200] batch [5/51] time 0.088 (0.218) data 0.000 (0.130) loss 0.6187 (0.5046) acc 84.3750 (86.2500) lr 1.9461e-03 eta 0:32:57
epoch [23/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.1667 (0.4397) acc 96.8750 (87.5000) lr 1.9461e-03 eta 0:23:00
epoch [23/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.044) loss 0.3748 (0.4192) acc 90.6250 (88.9583) lr 1.9461e-03 eta 0:19:41
epoch [23/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3550 (0.3908) acc 96.8750 (90.7812) lr 1.9461e-03 eta 0:18:03
epoch [23/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.7812 (0.4050) acc 78.1250 (90.5000) lr 1.9461e-03 eta 0:17:03
epoch [23/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.3162 (0.4061) acc 90.6250 (90.4167) lr 1.9461e-03 eta 0:16:22
epoch [23/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3770 (0.4065) acc 87.5000 (90.5357) lr 1.9461e-03 eta 0:15:54
epoch [23/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.6489 (0.4198) acc 81.2500 (90.0000) lr 1.9461e-03 eta 0:15:31
epoch [23/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.6509 (0.4231) acc 78.1250 (89.5833) lr 1.9461e-03 eta 0:15:13
epoch [23/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.2769 (0.4177) acc 93.7500 (89.8125) lr 1.9461e-03 eta 0:14:59
epoch [24/200] batch [5/51] time 0.088 (0.196) data 0.000 (0.108) loss 0.6992 (0.4842) acc 84.3750 (88.1250) lr 1.9409e-03 eta 0:29:29
epoch [24/200] batch [10/51] time 0.087 (0.141) data 0.000 (0.054) loss 0.3989 (0.4791) acc 87.5000 (88.1250) lr 1.9409e-03 eta 0:21:15
epoch [24/200] batch [15/51] time 0.087 (0.123) data 0.000 (0.036) loss 0.4026 (0.4649) acc 93.7500 (88.9583) lr 1.9409e-03 eta 0:18:29
epoch [24/200] batch [20/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.5073 (0.4685) acc 90.6250 (89.0625) lr 1.9409e-03 eta 0:17:06
epoch [24/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.5610 (0.4675) acc 78.1250 (88.6250) lr 1.9409e-03 eta 0:16:17
epoch [24/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.4031 (0.4660) acc 90.6250 (88.1250) lr 1.9409e-03 eta 0:15:45
epoch [24/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4448 (0.4500) acc 87.5000 (88.6607) lr 1.9409e-03 eta 0:15:21
epoch [24/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5117 (0.4456) acc 81.2500 (88.2031) lr 1.9409e-03 eta 0:15:03
epoch [24/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3926 (0.4418) acc 90.6250 (88.3333) lr 1.9409e-03 eta 0:14:48
epoch [24/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1584 (0.4405) acc 96.8750 (88.4375) lr 1.9409e-03 eta 0:14:35
epoch [25/200] batch [5/51] time 0.086 (0.226) data 0.000 (0.139) loss 0.3154 (0.3647) acc 90.6250 (89.3750) lr 1.9354e-03 eta 0:33:43
epoch [25/200] batch [10/51] time 0.086 (0.156) data 0.000 (0.070) loss 0.2842 (0.3941) acc 90.6250 (88.7500) lr 1.9354e-03 eta 0:23:19
epoch [25/200] batch [15/51] time 0.086 (0.133) data 0.000 (0.046) loss 0.4761 (0.3937) acc 90.6250 (88.7500) lr 1.9354e-03 eta 0:19:51
epoch [25/200] batch [20/51] time 0.088 (0.121) data 0.000 (0.035) loss 0.4922 (0.4123) acc 87.5000 (89.0625) lr 1.9354e-03 eta 0:18:07
epoch [25/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.028) loss 0.3542 (0.4078) acc 87.5000 (89.5000) lr 1.9354e-03 eta 0:17:04
epoch [25/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1583 (0.3960) acc 96.8750 (89.6875) lr 1.9354e-03 eta 0:16:23
epoch [25/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3123 (0.4000) acc 93.7500 (89.4643) lr 1.9354e-03 eta 0:15:52
epoch [25/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.2988 (0.4046) acc 90.6250 (89.4531) lr 1.9354e-03 eta 0:15:29
epoch [25/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.4805 (0.4071) acc 90.6250 (89.4444) lr 1.9354e-03 eta 0:15:10
epoch [25/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4907 (0.4261) acc 87.5000 (88.8125) lr 1.9354e-03 eta 0:14:55
epoch [26/200] batch [5/51] time 0.086 (0.209) data 0.000 (0.122) loss 0.2466 (0.3570) acc 96.8750 (92.5000) lr 1.9298e-03 eta 0:31:02
epoch [26/200] batch [10/51] time 0.086 (0.148) data 0.000 (0.061) loss 0.4226 (0.3682) acc 87.5000 (91.5625) lr 1.9298e-03 eta 0:21:56
epoch [26/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.041) loss 0.3972 (0.3925) acc 90.6250 (90.6250) lr 1.9298e-03 eta 0:18:53
epoch [26/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.031) loss 0.5386 (0.4086) acc 87.5000 (90.3125) lr 1.9298e-03 eta 0:17:21
epoch [26/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.7334 (0.4212) acc 87.5000 (90.2500) lr 1.9298e-03 eta 0:16:27
epoch [26/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.7607 (0.4130) acc 75.0000 (90.4167) lr 1.9298e-03 eta 0:15:50
epoch [26/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.2646 (0.4372) acc 93.7500 (89.7321) lr 1.9298e-03 eta 0:15:23
epoch [26/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4243 (0.4376) acc 81.2500 (89.4531) lr 1.9298e-03 eta 0:15:02
epoch [26/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.8931 (0.4557) acc 71.8750 (88.8889) lr 1.9298e-03 eta 0:14:46
epoch [26/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.4290 (0.4523) acc 90.6250 (89.0625) lr 1.9298e-03 eta 0:14:33
epoch [27/200] batch [5/51] time 0.087 (0.226) data 0.000 (0.139) loss 0.4553 (0.3819) acc 93.7500 (92.5000) lr 1.9239e-03 eta 0:33:25
epoch [27/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.2225 (0.4228) acc 93.7500 (90.9375) lr 1.9239e-03 eta 0:23:07
epoch [27/200] batch [15/51] time 0.086 (0.133) data 0.000 (0.046) loss 0.1562 (0.3891) acc 100.0000 (91.6667) lr 1.9239e-03 eta 0:19:40
epoch [27/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.2432 (0.3994) acc 96.8750 (90.9375) lr 1.9239e-03 eta 0:17:56
epoch [27/200] batch [25/51] time 0.086 (0.115) data 0.000 (0.028) loss 0.2634 (0.4085) acc 93.7500 (90.3750) lr 1.9239e-03 eta 0:16:53
epoch [27/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5361 (0.4069) acc 87.5000 (90.4167) lr 1.9239e-03 eta 0:16:12
epoch [27/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4478 (0.4026) acc 87.5000 (90.8036) lr 1.9239e-03 eta 0:15:42
epoch [27/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.018) loss 0.3386 (0.4061) acc 90.6250 (90.4688) lr 1.9239e-03 eta 0:15:18
epoch [27/200] batch [45/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.3979 (0.4063) acc 90.6250 (90.4167) lr 1.9239e-03 eta 0:15:00
epoch [27/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.5850 (0.4067) acc 81.2500 (90.3750) lr 1.9239e-03 eta 0:14:45
epoch [28/200] batch [5/51] time 0.088 (0.207) data 0.000 (0.119) loss 0.6172 (0.4880) acc 87.5000 (87.5000) lr 1.9178e-03 eta 0:30:28
epoch [28/200] batch [10/51] time 0.088 (0.147) data 0.000 (0.059) loss 0.2812 (0.4335) acc 90.6250 (88.4375) lr 1.9178e-03 eta 0:21:36
epoch [28/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.2625 (0.4571) acc 96.8750 (88.7500) lr 1.9178e-03 eta 0:18:39
epoch [28/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3923 (0.4457) acc 93.7500 (89.5312) lr 1.9178e-03 eta 0:17:09
epoch [28/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4290 (0.4210) acc 87.5000 (90.0000) lr 1.9178e-03 eta 0:16:15
epoch [28/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4626 (0.4158) acc 90.6250 (90.2083) lr 1.9178e-03 eta 0:15:39
epoch [28/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.5425 (0.4364) acc 84.3750 (89.3750) lr 1.9178e-03 eta 0:15:14
epoch [28/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.5010 (0.4443) acc 90.6250 (89.1406) lr 1.9178e-03 eta 0:14:53
epoch [28/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.3845 (0.4362) acc 93.7500 (89.3750) lr 1.9178e-03 eta 0:14:37
epoch [28/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3879 (0.4458) acc 81.2500 (89.1250) lr 1.9178e-03 eta 0:14:24
epoch [29/200] batch [5/51] time 0.087 (0.224) data 0.000 (0.137) loss 0.3008 (0.3884) acc 90.6250 (86.8750) lr 1.9114e-03 eta 0:32:41
epoch [29/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.4355 (0.4204) acc 87.5000 (88.4375) lr 1.9114e-03 eta 0:22:42
epoch [29/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.4961 (0.4365) acc 90.6250 (88.9583) lr 1.9114e-03 eta 0:19:21
epoch [29/200] batch [20/51] time 0.088 (0.121) data 0.000 (0.034) loss 0.2903 (0.4374) acc 90.6250 (88.5938) lr 1.9114e-03 eta 0:17:41
epoch [29/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.6587 (0.4450) acc 78.1250 (88.2500) lr 1.9114e-03 eta 0:16:41
epoch [29/200] batch [30/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.3960 (0.4384) acc 93.7500 (88.3333) lr 1.9114e-03 eta 0:16:00
epoch [29/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.6489 (0.4396) acc 81.2500 (88.3929) lr 1.9114e-03 eta 0:15:31
epoch [29/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1935 (0.4313) acc 96.8750 (88.7500) lr 1.9114e-03 eta 0:15:08
epoch [29/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3325 (0.4153) acc 96.8750 (89.4444) lr 1.9114e-03 eta 0:14:50
epoch [29/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3315 (0.4065) acc 90.6250 (89.7500) lr 1.9114e-03 eta 0:14:36
epoch [30/200] batch [5/51] time 0.087 (0.208) data 0.000 (0.121) loss 0.3857 (0.4158) acc 90.6250 (90.6250) lr 1.9048e-03 eta 0:30:10
epoch [30/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.061) loss 0.2172 (0.3740) acc 96.8750 (90.9375) lr 1.9048e-03 eta 0:21:24
epoch [30/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.3799 (0.3740) acc 84.3750 (90.4167) lr 1.9048e-03 eta 0:18:27
epoch [30/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.5361 (0.3772) acc 84.3750 (90.6250) lr 1.9048e-03 eta 0:16:58
epoch [30/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3208 (0.3717) acc 93.7500 (91.0000) lr 1.9048e-03 eta 0:16:05
epoch [30/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.020) loss 0.2783 (0.4179) acc 93.7500 (90.1042) lr 1.9048e-03 eta 0:15:29
epoch [30/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2515 (0.4185) acc 96.8750 (90.0893) lr 1.9048e-03 eta 0:15:04
epoch [30/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.6597 (0.4149) acc 84.3750 (90.0781) lr 1.9048e-03 eta 0:14:43
epoch [30/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.8271 (0.4235) acc 84.3750 (89.6528) lr 1.9048e-03 eta 0:14:27
epoch [30/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.2090 (0.4118) acc 96.8750 (89.9375) lr 1.9048e-03 eta 0:14:14
epoch [31/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.117) loss 0.2844 (0.2969) acc 90.6250 (92.5000) lr 1.8980e-03 eta 0:29:31
epoch [31/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.3904 (0.2913) acc 87.5000 (93.1250) lr 1.8980e-03 eta 0:21:00
epoch [31/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.039) loss 0.2406 (0.2864) acc 93.7500 (92.9167) lr 1.8980e-03 eta 0:18:11
epoch [31/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.5513 (0.3164) acc 81.2500 (91.5625) lr 1.8980e-03 eta 0:16:47
epoch [31/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3259 (0.3245) acc 93.7500 (91.8750) lr 1.8980e-03 eta 0:15:56
epoch [31/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.5093 (0.3353) acc 84.3750 (91.6667) lr 1.8980e-03 eta 0:15:21
epoch [31/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3921 (0.3544) acc 87.5000 (90.9821) lr 1.8980e-03 eta 0:14:56
epoch [31/200] batch [40/51] time 0.088 (0.102) data 0.000 (0.015) loss 0.3132 (0.3575) acc 90.6250 (90.9375) lr 1.8980e-03 eta 0:14:37
epoch [31/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5479 (0.3739) acc 84.3750 (90.2083) lr 1.8980e-03 eta 0:14:21
epoch [31/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2445 (0.3764) acc 90.6250 (90.1875) lr 1.8980e-03 eta 0:14:08
epoch [32/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.134) loss 0.1715 (0.3166) acc 100.0000 (94.3750) lr 1.8910e-03 eta 0:31:49
epoch [32/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.4019 (0.4061) acc 87.5000 (90.9375) lr 1.8910e-03 eta 0:22:10
epoch [32/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.3203 (0.3771) acc 93.7500 (91.6667) lr 1.8910e-03 eta 0:18:55
epoch [32/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.5400 (0.3722) acc 87.5000 (91.5625) lr 1.8910e-03 eta 0:17:18
epoch [32/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3608 (0.3702) acc 90.6250 (91.2500) lr 1.8910e-03 eta 0:16:19
epoch [32/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.023) loss 0.7139 (0.3839) acc 78.1250 (90.7292) lr 1.8910e-03 eta 0:15:40
epoch [32/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3716 (0.3787) acc 93.7500 (90.9821) lr 1.8910e-03 eta 0:15:12
epoch [32/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.5161 (0.3874) acc 84.3750 (90.6250) lr 1.8910e-03 eta 0:14:49
epoch [32/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3613 (0.3857) acc 90.6250 (90.7639) lr 1.8910e-03 eta 0:14:32
epoch [32/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.4717 (0.3928) acc 84.3750 (90.6250) lr 1.8910e-03 eta 0:14:17
epoch [33/200] batch [5/51] time 0.087 (0.225) data 0.000 (0.137) loss 0.2773 (0.3472) acc 93.7500 (92.5000) lr 1.8838e-03 eta 0:32:03
epoch [33/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.4724 (0.4644) acc 87.5000 (88.1250) lr 1.8838e-03 eta 0:22:13
epoch [33/200] batch [15/51] time 0.089 (0.133) data 0.000 (0.046) loss 0.3708 (0.4541) acc 96.8750 (89.3750) lr 1.8838e-03 eta 0:18:57
epoch [33/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.035) loss 0.3264 (0.4357) acc 93.7500 (90.1562) lr 1.8838e-03 eta 0:17:17
epoch [33/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4905 (0.4188) acc 87.5000 (90.6250) lr 1.8838e-03 eta 0:16:18
epoch [33/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4778 (0.4214) acc 87.5000 (90.4167) lr 1.8838e-03 eta 0:15:38
epoch [33/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3340 (0.4169) acc 90.6250 (90.1786) lr 1.8838e-03 eta 0:15:09
epoch [33/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.2325 (0.4051) acc 96.8750 (90.3906) lr 1.8838e-03 eta 0:14:47
epoch [33/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3240 (0.3949) acc 90.6250 (90.5556) lr 1.8838e-03 eta 0:14:29
epoch [33/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3975 (0.4055) acc 93.7500 (90.2500) lr 1.8838e-03 eta 0:14:15
epoch [34/200] batch [5/51] time 0.088 (0.207) data 0.000 (0.119) loss 0.2290 (0.3830) acc 93.7500 (90.0000) lr 1.8763e-03 eta 0:29:21
epoch [34/200] batch [10/51] time 0.088 (0.147) data 0.000 (0.059) loss 0.5684 (0.3696) acc 84.3750 (90.9375) lr 1.8763e-03 eta 0:20:52
epoch [34/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.4041 (0.3803) acc 90.6250 (90.2083) lr 1.8763e-03 eta 0:18:02
epoch [34/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2472 (0.3671) acc 90.6250 (90.6250) lr 1.8763e-03 eta 0:16:36
epoch [34/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.5151 (0.3533) acc 78.1250 (90.8750) lr 1.8763e-03 eta 0:15:44
epoch [34/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3804 (0.3472) acc 90.6250 (91.1458) lr 1.8763e-03 eta 0:15:09
epoch [34/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2747 (0.3812) acc 93.7500 (90.7143) lr 1.8763e-03 eta 0:14:44
epoch [34/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.6069 (0.3807) acc 84.3750 (90.5469) lr 1.8763e-03 eta 0:14:25
epoch [34/200] batch [45/51] time 0.088 (0.100) data 0.000 (0.013) loss 0.2288 (0.3722) acc 93.7500 (90.9028) lr 1.8763e-03 eta 0:14:10
epoch [34/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3674 (0.3812) acc 90.6250 (90.6875) lr 1.8763e-03 eta 0:13:57
epoch [35/200] batch [5/51] time 0.088 (0.226) data 0.000 (0.138) loss 0.4285 (0.4294) acc 93.7500 (90.0000) lr 1.8686e-03 eta 0:31:53
epoch [35/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.3943 (0.4108) acc 90.6250 (91.2500) lr 1.8686e-03 eta 0:22:03
epoch [35/200] batch [15/51] time 0.088 (0.134) data 0.000 (0.046) loss 0.2474 (0.4188) acc 96.8750 (90.8333) lr 1.8686e-03 eta 0:18:48
epoch [35/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.2654 (0.3909) acc 93.7500 (91.2500) lr 1.8686e-03 eta 0:17:09
epoch [35/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.0976 (0.3908) acc 100.0000 (91.1250) lr 1.8686e-03 eta 0:16:10
epoch [35/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2676 (0.3958) acc 90.6250 (91.2500) lr 1.8686e-03 eta 0:15:30
epoch [35/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1870 (0.3787) acc 96.8750 (91.6964) lr 1.8686e-03 eta 0:15:02
epoch [35/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.6304 (0.4006) acc 81.2500 (90.9375) lr 1.8686e-03 eta 0:14:39
epoch [35/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.6909 (0.4113) acc 78.1250 (90.4167) lr 1.8686e-03 eta 0:14:21
epoch [35/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2983 (0.4112) acc 93.7500 (90.3750) lr 1.8686e-03 eta 0:14:07
epoch [36/200] batch [5/51] time 0.087 (0.206) data 0.000 (0.118) loss 0.3914 (0.3534) acc 93.7500 (91.2500) lr 1.8607e-03 eta 0:28:53
epoch [36/200] batch [10/51] time 0.088 (0.147) data 0.000 (0.059) loss 0.3677 (0.3884) acc 90.6250 (90.6250) lr 1.8607e-03 eta 0:20:31
epoch [36/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.039) loss 0.4448 (0.3777) acc 90.6250 (90.8333) lr 1.8607e-03 eta 0:17:44
epoch [36/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.1630 (0.3738) acc 93.7500 (91.0938) lr 1.8607e-03 eta 0:16:20
epoch [36/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4722 (0.3908) acc 90.6250 (90.1250) lr 1.8607e-03 eta 0:15:29
epoch [36/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3552 (0.3689) acc 93.7500 (90.7292) lr 1.8607e-03 eta 0:14:56
epoch [36/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.5229 (0.3782) acc 93.7500 (90.7143) lr 1.8607e-03 eta 0:14:31
epoch [36/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3879 (0.3729) acc 84.3750 (90.7031) lr 1.8607e-03 eta 0:14:12
epoch [36/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5127 (0.3894) acc 84.3750 (89.7917) lr 1.8607e-03 eta 0:13:57
epoch [36/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4326 (0.3914) acc 84.3750 (89.5000) lr 1.8607e-03 eta 0:13:45
epoch [37/200] batch [5/51] time 0.089 (0.203) data 0.000 (0.114) loss 0.2394 (0.2944) acc 96.8750 (92.5000) lr 1.8526e-03 eta 0:28:13
epoch [37/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.3904 (0.2924) acc 93.7500 (92.8125) lr 1.8526e-03 eta 0:20:13
epoch [37/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.4260 (0.3069) acc 93.7500 (93.1250) lr 1.8526e-03 eta 0:17:30
epoch [37/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.4167 (0.3308) acc 90.6250 (91.8750) lr 1.8526e-03 eta 0:16:07
epoch [37/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.4832 (0.3582) acc 84.3750 (91.0000) lr 1.8526e-03 eta 0:15:18
epoch [37/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.7808 (0.3868) acc 87.5000 (90.0000) lr 1.8526e-03 eta 0:14:44
epoch [37/200] batch [35/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.6157 (0.3902) acc 81.2500 (89.8214) lr 1.8526e-03 eta 0:14:20
epoch [37/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3577 (0.3967) acc 93.7500 (89.6875) lr 1.8526e-03 eta 0:14:01
epoch [37/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1207 (0.3756) acc 100.0000 (90.4167) lr 1.8526e-03 eta 0:13:47
epoch [37/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2798 (0.3845) acc 93.7500 (90.2500) lr 1.8526e-03 eta 0:13:35
epoch [38/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.111) loss 0.3606 (0.3534) acc 90.6250 (93.1250) lr 1.8443e-03 eta 0:27:32
epoch [38/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.2291 (0.3590) acc 93.7500 (92.1875) lr 1.8443e-03 eta 0:19:46
epoch [38/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2556 (0.3706) acc 90.6250 (91.0417) lr 1.8443e-03 eta 0:17:10
epoch [38/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.5049 (0.3705) acc 87.5000 (90.9375) lr 1.8443e-03 eta 0:15:51
epoch [38/200] batch [25/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.3875 (0.3688) acc 90.6250 (91.0000) lr 1.8443e-03 eta 0:15:04
epoch [38/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.3149 (0.3804) acc 93.7500 (90.8333) lr 1.8443e-03 eta 0:14:32
epoch [38/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2949 (0.3856) acc 96.8750 (90.1786) lr 1.8443e-03 eta 0:14:09
epoch [38/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1893 (0.3731) acc 96.8750 (90.3906) lr 1.8443e-03 eta 0:13:52
epoch [38/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3425 (0.3690) acc 93.7500 (90.4167) lr 1.8443e-03 eta 0:13:37
epoch [38/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3296 (0.3835) acc 90.6250 (90.1250) lr 1.8443e-03 eta 0:13:26
epoch [39/200] batch [5/51] time 0.086 (0.205) data 0.000 (0.118) loss 0.5791 (0.3721) acc 84.3750 (91.8750) lr 1.8358e-03 eta 0:28:13
epoch [39/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.3718 (0.3205) acc 84.3750 (92.8125) lr 1.8358e-03 eta 0:20:04
epoch [39/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.040) loss 0.5254 (0.3733) acc 84.3750 (91.4583) lr 1.8358e-03 eta 0:17:21
epoch [39/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.030) loss 0.4893 (0.3911) acc 84.3750 (91.0938) lr 1.8358e-03 eta 0:15:59
epoch [39/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.3582 (0.3942) acc 90.6250 (90.5000) lr 1.8358e-03 eta 0:15:10
epoch [39/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.6021 (0.3917) acc 84.3750 (90.3125) lr 1.8358e-03 eta 0:14:37
epoch [39/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.4604 (0.3998) acc 87.5000 (90.0893) lr 1.8358e-03 eta 0:14:13
epoch [39/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.5581 (0.4071) acc 90.6250 (90.0781) lr 1.8358e-03 eta 0:13:54
epoch [39/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.6138 (0.4044) acc 84.3750 (90.0694) lr 1.8358e-03 eta 0:13:39
epoch [39/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.5889 (0.4031) acc 87.5000 (90.0625) lr 1.8358e-03 eta 0:13:27
epoch [40/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.134) loss 0.3511 (0.4301) acc 87.5000 (86.2500) lr 1.8271e-03 eta 0:30:23
epoch [40/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.067) loss 0.4619 (0.4395) acc 81.2500 (86.5625) lr 1.8271e-03 eta 0:21:09
epoch [40/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.3408 (0.4272) acc 93.7500 (87.9167) lr 1.8271e-03 eta 0:18:03
epoch [40/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.3584 (0.4051) acc 87.5000 (88.2812) lr 1.8271e-03 eta 0:16:30
epoch [40/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.7734 (0.4182) acc 84.3750 (88.3750) lr 1.8271e-03 eta 0:15:34
epoch [40/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3042 (0.4213) acc 93.7500 (88.5417) lr 1.8271e-03 eta 0:14:56
epoch [40/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2478 (0.4014) acc 90.6250 (89.1964) lr 1.8271e-03 eta 0:14:29
epoch [40/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2913 (0.3813) acc 96.8750 (89.9219) lr 1.8271e-03 eta 0:14:08
epoch [40/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4431 (0.3840) acc 87.5000 (89.9306) lr 1.8271e-03 eta 0:13:52
epoch [40/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4939 (0.3870) acc 90.6250 (89.8750) lr 1.8271e-03 eta 0:13:38
epoch [41/200] batch [5/51] time 0.086 (0.219) data 0.000 (0.132) loss 0.2712 (0.3877) acc 93.7500 (91.2500) lr 1.8181e-03 eta 0:29:42
epoch [41/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.1747 (0.3382) acc 100.0000 (93.1250) lr 1.8181e-03 eta 0:20:45
epoch [41/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.4080 (0.3367) acc 90.6250 (92.7083) lr 1.8181e-03 eta 0:17:44
epoch [41/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.2290 (0.3261) acc 90.6250 (92.5000) lr 1.8181e-03 eta 0:16:14
epoch [41/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.1302 (0.3229) acc 100.0000 (92.5000) lr 1.8181e-03 eta 0:15:20
epoch [41/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2239 (0.3327) acc 96.8750 (92.1875) lr 1.8181e-03 eta 0:14:44
epoch [41/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.5073 (0.3410) acc 87.5000 (91.8750) lr 1.8181e-03 eta 0:14:18
epoch [41/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.4255 (0.3448) acc 90.6250 (91.7969) lr 1.8181e-03 eta 0:13:57
epoch [41/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3997 (0.3502) acc 90.6250 (91.4583) lr 1.8181e-03 eta 0:13:41
epoch [41/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2866 (0.3571) acc 96.8750 (91.2500) lr 1.8181e-03 eta 0:13:28
epoch [42/200] batch [5/51] time 0.088 (0.196) data 0.000 (0.109) loss 0.5776 (0.4309) acc 87.5000 (90.0000) lr 1.8090e-03 eta 0:26:32
epoch [42/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.054) loss 0.4270 (0.4229) acc 81.2500 (88.4375) lr 1.8090e-03 eta 0:19:09
epoch [42/200] batch [15/51] time 0.086 (0.123) data 0.000 (0.036) loss 0.4478 (0.3964) acc 87.5000 (90.0000) lr 1.8090e-03 eta 0:16:38
epoch [42/200] batch [20/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.4609 (0.4141) acc 87.5000 (89.5312) lr 1.8090e-03 eta 0:15:23
epoch [42/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4121 (0.3978) acc 93.7500 (90.0000) lr 1.8090e-03 eta 0:14:38
epoch [42/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.2852 (0.4055) acc 87.5000 (89.5833) lr 1.8090e-03 eta 0:14:07
epoch [42/200] batch [35/51] time 0.087 (0.102) data 0.000 (0.016) loss 0.6221 (0.3993) acc 78.1250 (89.4643) lr 1.8090e-03 eta 0:13:46
epoch [42/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3521 (0.3949) acc 90.6250 (89.6875) lr 1.8090e-03 eta 0:13:29
epoch [42/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2478 (0.3999) acc 96.8750 (89.7222) lr 1.8090e-03 eta 0:13:15
epoch [42/200] batch [50/51] time 0.086 (0.097) data 0.000 (0.011) loss 0.2089 (0.3901) acc 100.0000 (89.9375) lr 1.8090e-03 eta 0:13:05
epoch [43/200] batch [5/51] time 0.087 (0.214) data 0.000 (0.126) loss 0.2299 (0.3816) acc 90.6250 (90.0000) lr 1.7997e-03 eta 0:28:40
epoch [43/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.2954 (0.3400) acc 93.7500 (91.5625) lr 1.7997e-03 eta 0:20:09
epoch [43/200] batch [15/51] time 0.088 (0.129) data 0.000 (0.042) loss 0.5762 (0.3483) acc 84.3750 (90.8333) lr 1.7997e-03 eta 0:17:19
epoch [43/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.5488 (0.3443) acc 90.6250 (91.2500) lr 1.7997e-03 eta 0:15:54
epoch [43/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3198 (0.3382) acc 90.6250 (91.5000) lr 1.7997e-03 eta 0:15:02
epoch [43/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3748 (0.3549) acc 93.7500 (91.1458) lr 1.7997e-03 eta 0:14:27
epoch [43/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3142 (0.3581) acc 96.8750 (91.3393) lr 1.7997e-03 eta 0:14:02
epoch [43/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.2681 (0.3624) acc 100.0000 (91.6406) lr 1.7997e-03 eta 0:13:43
epoch [43/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3467 (0.3596) acc 90.6250 (91.4583) lr 1.7997e-03 eta 0:13:27
epoch [43/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3987 (0.3699) acc 87.5000 (91.1250) lr 1.7997e-03 eta 0:13:14
epoch [44/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.112) loss 0.3577 (0.4317) acc 90.6250 (90.6250) lr 1.7902e-03 eta 0:26:32
epoch [44/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.3188 (0.3971) acc 90.6250 (90.6250) lr 1.7902e-03 eta 0:19:03
epoch [44/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.3572 (0.4099) acc 90.6250 (90.0000) lr 1.7902e-03 eta 0:16:32
epoch [44/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2617 (0.3872) acc 96.8750 (91.2500) lr 1.7902e-03 eta 0:15:18
epoch [44/200] batch [25/51] time 0.086 (0.109) data 0.000 (0.023) loss 0.2820 (0.3686) acc 90.6250 (91.2500) lr 1.7902e-03 eta 0:14:32
epoch [44/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4800 (0.3762) acc 90.6250 (91.2500) lr 1.7902e-03 eta 0:14:02
epoch [44/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3608 (0.3738) acc 90.6250 (91.3393) lr 1.7902e-03 eta 0:13:40
epoch [44/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.6343 (0.3764) acc 81.2500 (91.0938) lr 1.7902e-03 eta 0:13:23
epoch [44/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1237 (0.3843) acc 100.0000 (90.9722) lr 1.7902e-03 eta 0:13:09
epoch [44/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.3638 (0.3758) acc 90.6250 (91.1250) lr 1.7902e-03 eta 0:12:58
epoch [45/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.112) loss 0.2737 (0.3608) acc 90.6250 (89.3750) lr 1.7804e-03 eta 0:26:22
epoch [45/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.056) loss 0.3972 (0.3737) acc 87.5000 (89.6875) lr 1.7804e-03 eta 0:18:54
epoch [45/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2274 (0.3816) acc 96.8750 (89.3750) lr 1.7804e-03 eta 0:16:26
epoch [45/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4170 (0.4115) acc 90.6250 (89.5312) lr 1.7804e-03 eta 0:15:11
epoch [45/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.6392 (0.4010) acc 87.5000 (90.1250) lr 1.7804e-03 eta 0:14:28
epoch [45/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.3049 (0.3912) acc 93.7500 (90.1042) lr 1.7804e-03 eta 0:13:58
epoch [45/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2876 (0.3844) acc 96.8750 (90.6250) lr 1.7804e-03 eta 0:13:37
epoch [45/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3545 (0.3832) acc 90.6250 (90.5469) lr 1.7804e-03 eta 0:13:20
epoch [45/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.5005 (0.3865) acc 90.6250 (90.6944) lr 1.7804e-03 eta 0:13:06
epoch [45/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1921 (0.3747) acc 96.8750 (91.0000) lr 1.7804e-03 eta 0:12:55
epoch [46/200] batch [5/51] time 0.088 (0.197) data 0.000 (0.109) loss 0.4858 (0.5174) acc 84.3750 (83.7500) lr 1.7705e-03 eta 0:25:56
epoch [46/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.2128 (0.4227) acc 90.6250 (87.5000) lr 1.7705e-03 eta 0:18:40
epoch [46/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.036) loss 0.3152 (0.4020) acc 93.7500 (89.3750) lr 1.7705e-03 eta 0:16:15
epoch [46/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.027) loss 0.2661 (0.3765) acc 90.6250 (90.1562) lr 1.7705e-03 eta 0:15:03
epoch [46/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4224 (0.3885) acc 81.2500 (89.7500) lr 1.7705e-03 eta 0:14:19
epoch [46/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.4856 (0.3983) acc 87.5000 (89.6875) lr 1.7705e-03 eta 0:13:50
epoch [46/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.6548 (0.4076) acc 81.2500 (89.8214) lr 1.7705e-03 eta 0:13:29
epoch [46/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5874 (0.4074) acc 81.2500 (89.7656) lr 1.7705e-03 eta 0:13:12
epoch [46/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3391 (0.4003) acc 93.7500 (90.0000) lr 1.7705e-03 eta 0:12:59
epoch [46/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3896 (0.4015) acc 87.5000 (90.1250) lr 1.7705e-03 eta 0:12:48
epoch [47/200] batch [5/51] time 0.088 (0.199) data 0.000 (0.110) loss 0.3394 (0.3308) acc 90.6250 (91.8750) lr 1.7604e-03 eta 0:26:01
epoch [47/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.4531 (0.3487) acc 90.6250 (90.6250) lr 1.7604e-03 eta 0:18:41
epoch [47/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2107 (0.3480) acc 90.6250 (90.6250) lr 1.7604e-03 eta 0:16:15
epoch [47/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2340 (0.3211) acc 96.8750 (91.8750) lr 1.7604e-03 eta 0:15:01
epoch [47/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4268 (0.3345) acc 90.6250 (91.2500) lr 1.7604e-03 eta 0:14:16
epoch [47/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.5742 (0.3373) acc 90.6250 (91.0417) lr 1.7604e-03 eta 0:13:47
epoch [47/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4756 (0.3393) acc 87.5000 (91.0714) lr 1.7604e-03 eta 0:13:26
epoch [47/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2310 (0.3391) acc 96.8750 (91.3281) lr 1.7604e-03 eta 0:13:09
epoch [47/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2759 (0.3375) acc 90.6250 (91.2500) lr 1.7604e-03 eta 0:12:55
epoch [47/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.6162 (0.3551) acc 78.1250 (90.7500) lr 1.7604e-03 eta 0:12:44
epoch [48/200] batch [5/51] time 0.086 (0.215) data 0.000 (0.129) loss 0.3054 (0.3253) acc 93.7500 (91.2500) lr 1.7501e-03 eta 0:27:59
epoch [48/200] batch [10/51] time 0.088 (0.151) data 0.000 (0.064) loss 0.1908 (0.3453) acc 96.8750 (90.9375) lr 1.7501e-03 eta 0:19:38
epoch [48/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.2223 (0.3324) acc 96.8750 (91.6667) lr 1.7501e-03 eta 0:16:50
epoch [48/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.3369 (0.3350) acc 90.6250 (91.5625) lr 1.7501e-03 eta 0:15:26
epoch [48/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2493 (0.3426) acc 96.8750 (91.3750) lr 1.7501e-03 eta 0:14:36
epoch [48/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.022) loss 0.4026 (0.3817) acc 90.6250 (90.4167) lr 1.7501e-03 eta 0:14:02
epoch [48/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.2374 (0.4039) acc 96.8750 (89.5536) lr 1.7501e-03 eta 0:13:38
epoch [48/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2949 (0.4064) acc 90.6250 (89.5312) lr 1.7501e-03 eta 0:13:19
epoch [48/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3555 (0.3964) acc 87.5000 (89.7222) lr 1.7501e-03 eta 0:13:04
epoch [48/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1857 (0.3887) acc 96.8750 (89.9375) lr 1.7501e-03 eta 0:12:51
epoch [49/200] batch [5/51] time 0.088 (0.221) data 0.000 (0.132) loss 0.6255 (0.3934) acc 84.3750 (90.6250) lr 1.7396e-03 eta 0:28:29
epoch [49/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.066) loss 0.2590 (0.3513) acc 96.8750 (91.5625) lr 1.7396e-03 eta 0:19:52
epoch [49/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.044) loss 0.2261 (0.3285) acc 90.6250 (92.2917) lr 1.7396e-03 eta 0:17:00
epoch [49/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.033) loss 0.1716 (0.3311) acc 100.0000 (92.6562) lr 1.7396e-03 eta 0:15:33
epoch [49/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3438 (0.3433) acc 90.6250 (92.2500) lr 1.7396e-03 eta 0:14:41
epoch [49/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.022) loss 0.1575 (0.3455) acc 93.7500 (92.0833) lr 1.7396e-03 eta 0:14:05
epoch [49/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4509 (0.3512) acc 87.5000 (91.6964) lr 1.7396e-03 eta 0:13:40
epoch [49/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3357 (0.3445) acc 90.6250 (92.0312) lr 1.7396e-03 eta 0:13:21
epoch [49/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3501 (0.3451) acc 93.7500 (92.0139) lr 1.7396e-03 eta 0:13:05
epoch [49/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3591 (0.3563) acc 96.8750 (91.8750) lr 1.7396e-03 eta 0:12:52
epoch [50/200] batch [5/51] time 0.088 (0.208) data 0.000 (0.119) loss 0.3889 (0.3743) acc 93.7500 (93.1250) lr 1.7290e-03 eta 0:26:37
epoch [50/200] batch [10/51] time 0.086 (0.147) data 0.000 (0.060) loss 0.2418 (0.3449) acc 96.8750 (93.4375) lr 1.7290e-03 eta 0:18:52
epoch [50/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.3567 (0.3327) acc 90.6250 (93.3333) lr 1.7290e-03 eta 0:16:16
epoch [50/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.4653 (0.3663) acc 87.5000 (91.7188) lr 1.7290e-03 eta 0:14:58
epoch [50/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.6338 (0.3811) acc 81.2500 (91.0000) lr 1.7290e-03 eta 0:14:11
epoch [50/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3735 (0.3616) acc 93.7500 (91.5625) lr 1.7290e-03 eta 0:13:40
epoch [50/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1345 (0.3566) acc 100.0000 (91.6964) lr 1.7290e-03 eta 0:13:18
epoch [50/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.8076 (0.3576) acc 84.3750 (91.8750) lr 1.7290e-03 eta 0:13:00
epoch [50/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3420 (0.3507) acc 96.8750 (92.0833) lr 1.7290e-03 eta 0:12:46
epoch [50/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3010 (0.3533) acc 96.8750 (91.8750) lr 1.7290e-03 eta 0:12:35
epoch [51/200] batch [5/51] time 0.088 (0.205) data 0.000 (0.117) loss 0.2239 (0.3222) acc 93.7500 (93.1250) lr 1.7181e-03 eta 0:26:03
epoch [51/200] batch [10/51] time 0.086 (0.146) data 0.000 (0.059) loss 0.3652 (0.3616) acc 87.5000 (90.6250) lr 1.7181e-03 eta 0:18:33
epoch [51/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.2886 (0.3462) acc 90.6250 (90.4167) lr 1.7181e-03 eta 0:16:03
epoch [51/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.029) loss 0.1281 (0.3313) acc 96.8750 (90.9375) lr 1.7181e-03 eta 0:14:49
epoch [51/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.3582 (0.3290) acc 90.6250 (91.1250) lr 1.7181e-03 eta 0:14:03
epoch [51/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3521 (0.3257) acc 87.5000 (91.4583) lr 1.7181e-03 eta 0:13:33
epoch [51/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.4851 (0.3315) acc 87.5000 (91.7857) lr 1.7181e-03 eta 0:13:11
epoch [51/200] batch [40/51] time 0.088 (0.102) data 0.000 (0.015) loss 0.3738 (0.3324) acc 93.7500 (91.7969) lr 1.7181e-03 eta 0:12:55
epoch [51/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2456 (0.3272) acc 96.8750 (92.0833) lr 1.7181e-03 eta 0:12:41
epoch [51/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3560 (0.3264) acc 90.6250 (92.0625) lr 1.7181e-03 eta 0:12:30
epoch [52/200] batch [5/51] time 0.088 (0.219) data 0.000 (0.130) loss 0.6719 (0.4876) acc 84.3750 (88.7500) lr 1.7071e-03 eta 0:27:42
epoch [52/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.065) loss 0.3313 (0.3913) acc 93.7500 (90.9375) lr 1.7071e-03 eta 0:19:22
epoch [52/200] batch [15/51] time 0.088 (0.131) data 0.000 (0.044) loss 0.4802 (0.3654) acc 87.5000 (90.8333) lr 1.7071e-03 eta 0:16:34
epoch [52/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3140 (0.3863) acc 93.7500 (90.6250) lr 1.7071e-03 eta 0:15:11
epoch [52/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.026) loss 0.3933 (0.4158) acc 87.5000 (90.3750) lr 1.7071e-03 eta 0:14:20
epoch [52/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.5010 (0.4004) acc 90.6250 (90.9375) lr 1.7071e-03 eta 0:13:46
epoch [52/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.3428 (0.3748) acc 90.6250 (91.3393) lr 1.7071e-03 eta 0:13:22
epoch [52/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1902 (0.3550) acc 96.8750 (91.7969) lr 1.7071e-03 eta 0:13:02
epoch [52/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2123 (0.3499) acc 90.6250 (91.8750) lr 1.7071e-03 eta 0:12:47
epoch [52/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5220 (0.3436) acc 81.2500 (91.9375) lr 1.7071e-03 eta 0:12:34
epoch [53/200] batch [5/51] time 0.087 (0.208) data 0.000 (0.121) loss 0.1992 (0.3356) acc 96.8750 (91.2500) lr 1.6959e-03 eta 0:26:08
epoch [53/200] batch [10/51] time 0.088 (0.148) data 0.000 (0.060) loss 0.1414 (0.3663) acc 96.8750 (90.9375) lr 1.6959e-03 eta 0:18:33
epoch [53/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.2166 (0.3579) acc 93.7500 (91.2500) lr 1.6959e-03 eta 0:16:00
epoch [53/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.030) loss 0.6768 (0.3724) acc 78.1250 (90.3125) lr 1.6959e-03 eta 0:14:43
epoch [53/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.1698 (0.3761) acc 93.7500 (90.5000) lr 1.6959e-03 eta 0:13:56
epoch [53/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2203 (0.3647) acc 96.8750 (90.8333) lr 1.6959e-03 eta 0:13:25
epoch [53/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2983 (0.3783) acc 93.7500 (90.3571) lr 1.6959e-03 eta 0:13:02
epoch [53/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3086 (0.3668) acc 90.6250 (90.7031) lr 1.6959e-03 eta 0:12:44
epoch [53/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4805 (0.3674) acc 87.5000 (90.6944) lr 1.6959e-03 eta 0:12:30
epoch [53/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4817 (0.3716) acc 90.6250 (90.6250) lr 1.6959e-03 eta 0:12:19
epoch [54/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.4153 (0.3720) acc 90.6250 (91.2500) lr 1.6845e-03 eta 0:25:02
epoch [54/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.3296 (0.3196) acc 96.8750 (92.5000) lr 1.6845e-03 eta 0:17:55
epoch [54/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.3506 (0.3345) acc 90.6250 (92.0833) lr 1.6845e-03 eta 0:15:32
epoch [54/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3582 (0.3490) acc 93.7500 (92.1875) lr 1.6845e-03 eta 0:14:21
epoch [54/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.2837 (0.3441) acc 87.5000 (91.7500) lr 1.6845e-03 eta 0:13:37
epoch [54/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3608 (0.3470) acc 87.5000 (91.5625) lr 1.6845e-03 eta 0:13:09
epoch [54/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.5249 (0.3612) acc 90.6250 (91.5179) lr 1.6845e-03 eta 0:12:48
epoch [54/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2517 (0.3548) acc 96.8750 (91.4844) lr 1.6845e-03 eta 0:12:32
epoch [54/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.6201 (0.3619) acc 90.6250 (91.4583) lr 1.6845e-03 eta 0:12:19
epoch [54/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.3914 (0.3645) acc 90.6250 (91.1875) lr 1.6845e-03 eta 0:12:08
epoch [55/200] batch [5/51] time 0.087 (0.210) data 0.000 (0.123) loss 0.3696 (0.2887) acc 90.6250 (93.7500) lr 1.6730e-03 eta 0:26:04
epoch [55/200] batch [10/51] time 0.088 (0.149) data 0.000 (0.061) loss 0.3804 (0.2889) acc 90.6250 (94.0625) lr 1.6730e-03 eta 0:18:25
epoch [55/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.0991 (0.2873) acc 100.0000 (93.9583) lr 1.6730e-03 eta 0:15:51
epoch [55/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.1621 (0.2732) acc 96.8750 (94.2188) lr 1.6730e-03 eta 0:14:35
epoch [55/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2388 (0.2653) acc 100.0000 (94.6250) lr 1.6730e-03 eta 0:13:48
epoch [55/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.1492 (0.2955) acc 96.8750 (93.6458) lr 1.6730e-03 eta 0:13:16
epoch [55/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.5234 (0.3125) acc 81.2500 (92.9464) lr 1.6730e-03 eta 0:12:54
epoch [55/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.6196 (0.3226) acc 84.3750 (92.5781) lr 1.6730e-03 eta 0:12:36
epoch [55/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 1.0176 (0.3410) acc 78.1250 (92.1528) lr 1.6730e-03 eta 0:12:22
epoch [55/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1384 (0.3351) acc 100.0000 (92.1875) lr 1.6730e-03 eta 0:12:11
epoch [56/200] batch [5/51] time 0.087 (0.209) data 0.000 (0.121) loss 0.1803 (0.3671) acc 96.8750 (88.7500) lr 1.6613e-03 eta 0:25:44
epoch [56/200] batch [10/51] time 0.090 (0.148) data 0.003 (0.061) loss 0.4417 (0.3672) acc 87.5000 (89.6875) lr 1.6613e-03 eta 0:18:15
epoch [56/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.3394 (0.3562) acc 87.5000 (90.4167) lr 1.6613e-03 eta 0:15:43
epoch [56/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.1655 (0.3430) acc 96.8750 (90.7812) lr 1.6613e-03 eta 0:14:27
epoch [56/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2615 (0.3462) acc 90.6250 (90.2500) lr 1.6613e-03 eta 0:13:42
epoch [56/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3240 (0.3478) acc 90.6250 (90.4167) lr 1.6613e-03 eta 0:13:11
epoch [56/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1960 (0.3401) acc 96.8750 (90.5357) lr 1.6613e-03 eta 0:12:49
epoch [56/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1665 (0.3414) acc 96.8750 (90.5469) lr 1.6613e-03 eta 0:12:32
epoch [56/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2542 (0.3403) acc 93.7500 (90.6250) lr 1.6613e-03 eta 0:12:18
epoch [56/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3896 (0.3570) acc 87.5000 (90.3125) lr 1.6613e-03 eta 0:12:07
epoch [57/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.2810 (0.3187) acc 96.8750 (93.7500) lr 1.6494e-03 eta 0:24:36
epoch [57/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.5557 (0.3291) acc 90.6250 (93.7500) lr 1.6494e-03 eta 0:17:39
epoch [57/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.4285 (0.3348) acc 93.7500 (92.7083) lr 1.6494e-03 eta 0:15:18
epoch [57/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.2878 (0.3498) acc 93.7500 (92.0312) lr 1.6494e-03 eta 0:14:08
epoch [57/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.3057 (0.3390) acc 90.6250 (92.3750) lr 1.6494e-03 eta 0:13:25
epoch [57/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3228 (0.3386) acc 96.8750 (92.7083) lr 1.6494e-03 eta 0:12:56
epoch [57/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.016) loss 0.2069 (0.3367) acc 96.8750 (92.5893) lr 1.6494e-03 eta 0:12:36
epoch [57/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1608 (0.3367) acc 96.8750 (92.8125) lr 1.6494e-03 eta 0:12:20
epoch [57/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3198 (0.3471) acc 90.6250 (92.4306) lr 1.6494e-03 eta 0:12:07
epoch [57/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3359 (0.3397) acc 90.6250 (92.6250) lr 1.6494e-03 eta 0:11:57
epoch [58/200] batch [5/51] time 0.086 (0.215) data 0.000 (0.128) loss 0.3792 (0.3553) acc 84.3750 (91.2500) lr 1.6374e-03 eta 0:26:04
epoch [58/200] batch [10/51] time 0.086 (0.151) data 0.000 (0.064) loss 0.7153 (0.4248) acc 81.2500 (90.0000) lr 1.6374e-03 eta 0:18:18
epoch [58/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.043) loss 0.3398 (0.3750) acc 90.6250 (91.6667) lr 1.6374e-03 eta 0:15:42
epoch [58/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.3535 (0.3426) acc 84.3750 (92.0312) lr 1.6374e-03 eta 0:14:23
epoch [58/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.026) loss 0.1637 (0.3289) acc 96.8750 (92.3750) lr 1.6374e-03 eta 0:13:36
epoch [58/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.022) loss 0.4204 (0.3351) acc 90.6250 (92.2917) lr 1.6374e-03 eta 0:13:05
epoch [58/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.2028 (0.3145) acc 96.8750 (92.7679) lr 1.6374e-03 eta 0:12:42
epoch [58/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.7939 (0.3352) acc 81.2500 (92.5781) lr 1.6374e-03 eta 0:12:24
epoch [58/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.5044 (0.3525) acc 87.5000 (92.2222) lr 1.6374e-03 eta 0:12:09
epoch [58/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.1782 (0.3567) acc 100.0000 (92.1875) lr 1.6374e-03 eta 0:11:58
epoch [59/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.129) loss 0.2209 (0.3458) acc 100.0000 (92.5000) lr 1.6252e-03 eta 0:26:09
epoch [59/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.3347 (0.3549) acc 90.6250 (90.9375) lr 1.6252e-03 eta 0:18:18
epoch [59/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.2827 (0.3684) acc 90.6250 (90.4167) lr 1.6252e-03 eta 0:15:41
epoch [59/200] batch [20/51] time 0.088 (0.119) data 0.000 (0.032) loss 0.2198 (0.3510) acc 96.8750 (91.0938) lr 1.6252e-03 eta 0:14:22
epoch [59/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.1422 (0.3364) acc 96.8750 (91.6250) lr 1.6252e-03 eta 0:13:35
epoch [59/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4124 (0.3583) acc 90.6250 (91.2500) lr 1.6252e-03 eta 0:13:03
epoch [59/200] batch [35/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.6519 (0.3668) acc 84.3750 (91.0714) lr 1.6252e-03 eta 0:12:41
epoch [59/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2292 (0.3581) acc 96.8750 (91.0938) lr 1.6252e-03 eta 0:12:23
epoch [59/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2404 (0.3535) acc 93.7500 (91.1806) lr 1.6252e-03 eta 0:12:08
epoch [59/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.1177 (0.3500) acc 100.0000 (91.4375) lr 1.6252e-03 eta 0:11:56
epoch [60/200] batch [5/51] time 0.088 (0.208) data 0.000 (0.119) loss 0.2123 (0.4118) acc 96.8750 (91.8750) lr 1.6129e-03 eta 0:24:55
epoch [60/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.3176 (0.3721) acc 93.7500 (92.1875) lr 1.6129e-03 eta 0:17:39
epoch [60/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.1283 (0.3671) acc 100.0000 (92.0833) lr 1.6129e-03 eta 0:15:14
epoch [60/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.4436 (0.3744) acc 84.3750 (91.5625) lr 1.6129e-03 eta 0:14:01
epoch [60/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3320 (0.3589) acc 93.7500 (91.6250) lr 1.6129e-03 eta 0:13:17
epoch [60/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1697 (0.3449) acc 100.0000 (92.1875) lr 1.6129e-03 eta 0:12:48
epoch [60/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1738 (0.3381) acc 93.7500 (91.9643) lr 1.6129e-03 eta 0:12:26
epoch [60/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3413 (0.3400) acc 93.7500 (92.1875) lr 1.6129e-03 eta 0:12:09
epoch [60/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2832 (0.3495) acc 93.7500 (92.2222) lr 1.6129e-03 eta 0:11:56
epoch [60/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2484 (0.3468) acc 93.7500 (92.1875) lr 1.6129e-03 eta 0:11:45
epoch [61/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.115) loss 0.1611 (0.3094) acc 93.7500 (92.5000) lr 1.6004e-03 eta 0:24:08
epoch [61/200] batch [10/51] time 0.088 (0.145) data 0.000 (0.058) loss 0.1570 (0.3224) acc 96.8750 (92.8125) lr 1.6004e-03 eta 0:17:14
epoch [61/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.038) loss 0.5610 (0.3411) acc 87.5000 (92.2917) lr 1.6004e-03 eta 0:14:55
epoch [61/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.029) loss 0.2202 (0.3559) acc 96.8750 (92.5000) lr 1.6004e-03 eta 0:13:46
epoch [61/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.2520 (0.3408) acc 96.8750 (92.6250) lr 1.6004e-03 eta 0:13:04
epoch [61/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3984 (0.3274) acc 93.7500 (92.8125) lr 1.6004e-03 eta 0:12:37
epoch [61/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.6104 (0.3297) acc 87.5000 (92.8571) lr 1.6004e-03 eta 0:12:16
epoch [61/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3552 (0.3312) acc 93.7500 (92.5781) lr 1.6004e-03 eta 0:12:00
epoch [61/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2500 (0.3334) acc 93.7500 (92.6389) lr 1.6004e-03 eta 0:11:47
epoch [61/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.4878 (0.3334) acc 81.2500 (92.4375) lr 1.6004e-03 eta 0:11:37
epoch [62/200] batch [5/51] time 0.088 (0.198) data 0.000 (0.110) loss 0.2424 (0.3856) acc 96.8750 (89.3750) lr 1.5878e-03 eta 0:23:23
epoch [62/200] batch [10/51] time 0.088 (0.143) data 0.000 (0.055) loss 0.5073 (0.3623) acc 84.3750 (90.0000) lr 1.5878e-03 eta 0:16:48
epoch [62/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.3323 (0.3584) acc 93.7500 (90.4167) lr 1.5878e-03 eta 0:14:36
epoch [62/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3826 (0.3739) acc 90.6250 (90.3125) lr 1.5878e-03 eta 0:13:29
epoch [62/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2288 (0.3889) acc 90.6250 (89.7500) lr 1.5878e-03 eta 0:12:50
epoch [62/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.2275 (0.3769) acc 96.8750 (90.2083) lr 1.5878e-03 eta 0:12:23
epoch [62/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4597 (0.3864) acc 87.5000 (89.9107) lr 1.5878e-03 eta 0:12:04
epoch [62/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3716 (0.3843) acc 93.7500 (90.0000) lr 1.5878e-03 eta 0:11:49
epoch [62/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.3157 (0.3689) acc 90.6250 (90.5556) lr 1.5878e-03 eta 0:11:37
epoch [62/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3687 (0.3704) acc 90.6250 (90.7500) lr 1.5878e-03 eta 0:11:27
epoch [63/200] batch [5/51] time 0.087 (0.209) data 0.000 (0.121) loss 0.3904 (0.3119) acc 87.5000 (91.2500) lr 1.5750e-03 eta 0:24:27
epoch [63/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.4099 (0.3184) acc 90.6250 (91.2500) lr 1.5750e-03 eta 0:17:20
epoch [63/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.2996 (0.3389) acc 93.7500 (91.0417) lr 1.5750e-03 eta 0:14:57
epoch [63/200] batch [20/51] time 0.088 (0.118) data 0.000 (0.030) loss 0.2234 (0.3216) acc 96.8750 (91.4062) lr 1.5750e-03 eta 0:13:45
epoch [63/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3240 (0.3273) acc 90.6250 (91.2500) lr 1.5750e-03 eta 0:13:01
epoch [63/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2891 (0.3317) acc 90.6250 (91.1458) lr 1.5750e-03 eta 0:12:33
epoch [63/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3882 (0.3304) acc 90.6250 (91.2500) lr 1.5750e-03 eta 0:12:12
epoch [63/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3196 (0.3450) acc 93.7500 (90.8594) lr 1.5750e-03 eta 0:11:55
epoch [63/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2079 (0.3481) acc 93.7500 (90.6250) lr 1.5750e-03 eta 0:11:42
epoch [63/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1236 (0.3419) acc 100.0000 (90.6875) lr 1.5750e-03 eta 0:11:32
epoch [64/200] batch [5/51] time 0.088 (0.210) data 0.000 (0.121) loss 0.3845 (0.3537) acc 87.5000 (91.8750) lr 1.5621e-03 eta 0:24:22
epoch [64/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.3616 (0.3808) acc 90.6250 (90.0000) lr 1.5621e-03 eta 0:17:13
epoch [64/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.3523 (0.3709) acc 90.6250 (90.6250) lr 1.5621e-03 eta 0:14:51
epoch [64/200] batch [20/51] time 0.088 (0.118) data 0.000 (0.031) loss 0.2622 (0.3329) acc 90.6250 (91.8750) lr 1.5621e-03 eta 0:13:40
epoch [64/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.024) loss 0.3403 (0.3268) acc 90.6250 (91.6250) lr 1.5621e-03 eta 0:12:56
epoch [64/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3428 (0.3330) acc 90.6250 (91.3542) lr 1.5621e-03 eta 0:12:27
epoch [64/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3501 (0.3326) acc 90.6250 (91.3393) lr 1.5621e-03 eta 0:12:06
epoch [64/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2712 (0.3267) acc 96.8750 (91.4844) lr 1.5621e-03 eta 0:11:50
epoch [64/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.7603 (0.3428) acc 71.8750 (90.8333) lr 1.5621e-03 eta 0:11:37
epoch [64/200] batch [50/51] time 0.087 (0.099) data 0.000 (0.012) loss 0.4150 (0.3461) acc 87.5000 (90.6250) lr 1.5621e-03 eta 0:11:26
epoch [65/200] batch [5/51] time 0.086 (0.219) data 0.000 (0.132) loss 0.2018 (0.2163) acc 96.8750 (95.0000) lr 1.5490e-03 eta 0:25:19
epoch [65/200] batch [10/51] time 0.086 (0.153) data 0.000 (0.066) loss 0.1444 (0.2205) acc 96.8750 (94.6875) lr 1.5490e-03 eta 0:17:39
epoch [65/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.3896 (0.2640) acc 87.5000 (93.7500) lr 1.5490e-03 eta 0:15:06
epoch [65/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.2632 (0.2938) acc 90.6250 (93.2812) lr 1.5490e-03 eta 0:13:47
epoch [65/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.027) loss 0.2996 (0.3047) acc 90.6250 (93.0000) lr 1.5490e-03 eta 0:13:01
epoch [65/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.4402 (0.3094) acc 90.6250 (92.9167) lr 1.5490e-03 eta 0:12:30
epoch [65/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.2737 (0.3217) acc 93.7500 (92.3214) lr 1.5490e-03 eta 0:12:07
epoch [65/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.4463 (0.3297) acc 87.5000 (92.1094) lr 1.5490e-03 eta 0:11:50
epoch [65/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3538 (0.3288) acc 90.6250 (92.0833) lr 1.5490e-03 eta 0:11:36
epoch [65/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5137 (0.3357) acc 84.3750 (92.0625) lr 1.5490e-03 eta 0:11:25
epoch [66/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.125) loss 0.3022 (0.3039) acc 90.6250 (92.5000) lr 1.5358e-03 eta 0:24:24
epoch [66/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.5537 (0.3800) acc 90.6250 (91.8750) lr 1.5358e-03 eta 0:17:12
epoch [66/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.2847 (0.3585) acc 90.6250 (92.0833) lr 1.5358e-03 eta 0:14:46
epoch [66/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.031) loss 0.3289 (0.3435) acc 90.6250 (92.3438) lr 1.5358e-03 eta 0:13:33
epoch [66/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.5317 (0.3444) acc 87.5000 (92.6250) lr 1.5358e-03 eta 0:12:49
epoch [66/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.4138 (0.3453) acc 81.2500 (92.1875) lr 1.5358e-03 eta 0:12:20
epoch [66/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.0679 (0.3396) acc 100.0000 (92.5893) lr 1.5358e-03 eta 0:11:59
epoch [66/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.2061 (0.3282) acc 93.7500 (92.8906) lr 1.5358e-03 eta 0:11:42
epoch [66/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2213 (0.3281) acc 93.7500 (92.9861) lr 1.5358e-03 eta 0:11:29
epoch [66/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2493 (0.3223) acc 100.0000 (93.2500) lr 1.5358e-03 eta 0:11:18
epoch [67/200] batch [5/51] time 0.087 (0.219) data 0.000 (0.131) loss 0.2883 (0.3476) acc 96.8750 (92.5000) lr 1.5225e-03 eta 0:24:57
epoch [67/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.065) loss 0.3206 (0.3548) acc 93.7500 (92.5000) lr 1.5225e-03 eta 0:17:24
epoch [67/200] batch [15/51] time 0.086 (0.131) data 0.000 (0.044) loss 0.3000 (0.3736) acc 90.6250 (90.6250) lr 1.5225e-03 eta 0:14:53
epoch [67/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3582 (0.3752) acc 90.6250 (90.4688) lr 1.5225e-03 eta 0:13:37
epoch [67/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.4026 (0.3951) acc 87.5000 (89.5000) lr 1.5225e-03 eta 0:12:51
epoch [67/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1076 (0.3910) acc 96.8750 (89.7917) lr 1.5225e-03 eta 0:12:21
epoch [67/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4641 (0.3774) acc 87.5000 (90.2679) lr 1.5225e-03 eta 0:11:59
epoch [67/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.1523 (0.3776) acc 100.0000 (90.4688) lr 1.5225e-03 eta 0:11:42
epoch [67/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4023 (0.3865) acc 87.5000 (90.1389) lr 1.5225e-03 eta 0:11:28
epoch [67/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3752 (0.3828) acc 87.5000 (90.2500) lr 1.5225e-03 eta 0:11:17
epoch [68/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.126) loss 0.2734 (0.3865) acc 93.7500 (90.0000) lr 1.5090e-03 eta 0:24:05
epoch [68/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.4526 (0.3905) acc 87.5000 (90.0000) lr 1.5090e-03 eta 0:16:57
epoch [68/200] batch [15/51] time 0.086 (0.129) data 0.000 (0.042) loss 0.2795 (0.3667) acc 93.7500 (90.6250) lr 1.5090e-03 eta 0:14:33
epoch [68/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.4026 (0.3528) acc 90.6250 (91.2500) lr 1.5090e-03 eta 0:13:22
epoch [68/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1971 (0.3306) acc 90.6250 (91.3750) lr 1.5090e-03 eta 0:12:38
epoch [68/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3193 (0.3286) acc 93.7500 (91.7708) lr 1.5090e-03 eta 0:12:09
epoch [68/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.5635 (0.3456) acc 84.3750 (91.3393) lr 1.5090e-03 eta 0:11:49
epoch [68/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.6226 (0.3553) acc 87.5000 (91.0938) lr 1.5090e-03 eta 0:11:33
epoch [68/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3020 (0.3671) acc 93.7500 (90.6944) lr 1.5090e-03 eta 0:11:20
epoch [68/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4014 (0.3682) acc 93.7500 (90.8125) lr 1.5090e-03 eta 0:11:09
epoch [69/200] batch [5/51] time 0.087 (0.221) data 0.001 (0.133) loss 0.3696 (0.2936) acc 93.7500 (93.7500) lr 1.4955e-03 eta 0:24:44
epoch [69/200] batch [10/51] time 0.086 (0.154) data 0.000 (0.067) loss 0.2712 (0.2788) acc 93.7500 (94.0625) lr 1.4955e-03 eta 0:17:13
epoch [69/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.045) loss 0.1906 (0.2967) acc 100.0000 (93.3333) lr 1.4955e-03 eta 0:14:43
epoch [69/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.034) loss 0.6626 (0.3388) acc 75.0000 (92.1875) lr 1.4955e-03 eta 0:13:27
epoch [69/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3342 (0.3480) acc 90.6250 (92.2500) lr 1.4955e-03 eta 0:12:42
epoch [69/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1262 (0.3341) acc 100.0000 (92.7083) lr 1.4955e-03 eta 0:12:11
epoch [69/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.4070 (0.3426) acc 90.6250 (92.5893) lr 1.4955e-03 eta 0:11:49
epoch [69/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.7075 (0.3593) acc 81.2500 (91.9531) lr 1.4955e-03 eta 0:11:32
epoch [69/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5308 (0.3597) acc 87.5000 (91.9444) lr 1.4955e-03 eta 0:11:18
epoch [69/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.5425 (0.3634) acc 84.3750 (91.8125) lr 1.4955e-03 eta 0:11:08
epoch [70/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.134) loss 0.2375 (0.3771) acc 93.7500 (91.8750) lr 1.4818e-03 eta 0:24:38
epoch [70/200] batch [10/51] time 0.086 (0.154) data 0.000 (0.067) loss 0.2089 (0.3085) acc 93.7500 (92.8125) lr 1.4818e-03 eta 0:17:07
epoch [70/200] batch [15/51] time 0.086 (0.131) data 0.000 (0.045) loss 0.4465 (0.3211) acc 90.6250 (92.9167) lr 1.4818e-03 eta 0:14:36
epoch [70/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.034) loss 0.3176 (0.3224) acc 93.7500 (92.6562) lr 1.4818e-03 eta 0:13:20
epoch [70/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.3916 (0.3236) acc 84.3750 (92.2500) lr 1.4818e-03 eta 0:12:35
epoch [70/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.023) loss 0.3918 (0.3257) acc 84.3750 (91.9792) lr 1.4818e-03 eta 0:12:04
epoch [70/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2189 (0.3243) acc 96.8750 (92.0536) lr 1.4818e-03 eta 0:11:43
epoch [70/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.2196 (0.3137) acc 96.8750 (92.5781) lr 1.4818e-03 eta 0:11:26
epoch [70/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4902 (0.3207) acc 84.3750 (92.5694) lr 1.4818e-03 eta 0:11:12
epoch [70/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.3127 (0.3305) acc 90.6250 (92.3750) lr 1.4818e-03 eta 0:11:01
epoch [71/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.1521 (0.3398) acc 96.8750 (90.6250) lr 1.4679e-03 eta 0:22:08
epoch [71/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.0919 (0.3693) acc 100.0000 (90.6250) lr 1.4679e-03 eta 0:15:51
epoch [71/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.3535 (0.3813) acc 90.6250 (90.4167) lr 1.4679e-03 eta 0:13:45
epoch [71/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.7520 (0.3996) acc 81.2500 (90.4688) lr 1.4679e-03 eta 0:12:42
epoch [71/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1968 (0.3691) acc 93.7500 (91.1250) lr 1.4679e-03 eta 0:12:04
epoch [71/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.7388 (0.3846) acc 78.1250 (90.4167) lr 1.4679e-03 eta 0:11:38
epoch [71/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3308 (0.3730) acc 90.6250 (90.7143) lr 1.4679e-03 eta 0:11:20
epoch [71/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2871 (0.3723) acc 93.7500 (91.0938) lr 1.4679e-03 eta 0:11:05
epoch [71/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.4290 (0.3666) acc 87.5000 (91.2500) lr 1.4679e-03 eta 0:10:53
epoch [71/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2400 (0.3589) acc 96.8750 (91.5000) lr 1.4679e-03 eta 0:10:44
epoch [72/200] batch [5/51] time 0.087 (0.220) data 0.000 (0.132) loss 0.2822 (0.4356) acc 87.5000 (89.3750) lr 1.4540e-03 eta 0:24:05
epoch [72/200] batch [10/51] time 0.088 (0.154) data 0.000 (0.066) loss 0.3723 (0.4022) acc 90.6250 (90.3125) lr 1.4540e-03 eta 0:16:48
epoch [72/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.2729 (0.3831) acc 93.7500 (90.6250) lr 1.4540e-03 eta 0:14:22
epoch [72/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.2277 (0.3637) acc 93.7500 (91.4062) lr 1.4540e-03 eta 0:13:10
epoch [72/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2642 (0.3499) acc 93.7500 (91.8750) lr 1.4540e-03 eta 0:12:25
epoch [72/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.1837 (0.3611) acc 96.8750 (91.6667) lr 1.4540e-03 eta 0:11:55
epoch [72/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3262 (0.3635) acc 87.5000 (91.5179) lr 1.4540e-03 eta 0:11:34
epoch [72/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1874 (0.3530) acc 93.7500 (91.6406) lr 1.4540e-03 eta 0:11:17
epoch [72/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2886 (0.3512) acc 93.7500 (91.5972) lr 1.4540e-03 eta 0:11:04
epoch [72/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3000 (0.3443) acc 93.7500 (91.9375) lr 1.4540e-03 eta 0:10:53
epoch [73/200] batch [5/51] time 0.087 (0.226) data 0.000 (0.138) loss 0.4519 (0.3607) acc 87.5000 (90.6250) lr 1.4399e-03 eta 0:24:33
epoch [73/200] batch [10/51] time 0.088 (0.157) data 0.000 (0.069) loss 0.3691 (0.2875) acc 90.6250 (92.8125) lr 1.4399e-03 eta 0:17:01
epoch [73/200] batch [15/51] time 0.087 (0.134) data 0.000 (0.046) loss 0.5332 (0.3009) acc 84.3750 (92.5000) lr 1.4399e-03 eta 0:14:30
epoch [73/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.2595 (0.3034) acc 93.7500 (92.8125) lr 1.4399e-03 eta 0:13:13
epoch [73/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2529 (0.3001) acc 90.6250 (93.0000) lr 1.4399e-03 eta 0:12:28
epoch [73/200] batch [30/51] time 0.087 (0.111) data 0.000 (0.023) loss 0.2576 (0.2968) acc 93.7500 (93.2292) lr 1.4399e-03 eta 0:11:58
epoch [73/200] batch [35/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.3735 (0.3055) acc 81.2500 (92.5000) lr 1.4399e-03 eta 0:11:36
epoch [73/200] batch [40/51] time 0.086 (0.105) data 0.000 (0.017) loss 0.3931 (0.3287) acc 90.6250 (91.9531) lr 1.4399e-03 eta 0:11:18
epoch [73/200] batch [45/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4673 (0.3388) acc 87.5000 (91.5278) lr 1.4399e-03 eta 0:11:04
epoch [73/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3000 (0.3312) acc 90.6250 (91.6875) lr 1.4399e-03 eta 0:10:53
epoch [74/200] batch [5/51] time 0.087 (0.226) data 0.000 (0.140) loss 0.2788 (0.3332) acc 93.7500 (91.2500) lr 1.4258e-03 eta 0:24:24
epoch [74/200] batch [10/51] time 0.087 (0.157) data 0.000 (0.070) loss 0.0979 (0.2704) acc 100.0000 (93.7500) lr 1.4258e-03 eta 0:16:52
epoch [74/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.047) loss 0.5693 (0.3212) acc 87.5000 (92.5000) lr 1.4258e-03 eta 0:14:22
epoch [74/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.2255 (0.3233) acc 96.8750 (92.5000) lr 1.4258e-03 eta 0:13:07
epoch [74/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3857 (0.3278) acc 90.6250 (92.1250) lr 1.4258e-03 eta 0:12:21
epoch [74/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2749 (0.3250) acc 90.6250 (92.5000) lr 1.4258e-03 eta 0:11:50
epoch [74/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.5366 (0.3534) acc 84.3750 (91.6964) lr 1.4258e-03 eta 0:11:28
epoch [74/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.1837 (0.3488) acc 96.8750 (91.8750) lr 1.4258e-03 eta 0:11:11
epoch [74/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.6748 (0.3426) acc 78.1250 (92.0139) lr 1.4258e-03 eta 0:10:58
epoch [74/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3513 (0.3291) acc 87.5000 (92.3750) lr 1.4258e-03 eta 0:10:47
epoch [75/200] batch [5/51] time 0.089 (0.199) data 0.000 (0.110) loss 0.1744 (0.1833) acc 93.7500 (94.3750) lr 1.4115e-03 eta 0:21:15
epoch [75/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.2297 (0.2559) acc 96.8750 (93.1250) lr 1.4115e-03 eta 0:15:15
epoch [75/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.1580 (0.2571) acc 93.7500 (93.5417) lr 1.4115e-03 eta 0:13:15
epoch [75/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4382 (0.2597) acc 84.3750 (93.4375) lr 1.4115e-03 eta 0:12:15
epoch [75/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1750 (0.2801) acc 100.0000 (92.7500) lr 1.4115e-03 eta 0:11:39
epoch [75/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4746 (0.2860) acc 90.6250 (92.8125) lr 1.4115e-03 eta 0:11:15
epoch [75/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.1437 (0.2959) acc 96.8750 (92.5000) lr 1.4115e-03 eta 0:10:58
epoch [75/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3154 (0.2993) acc 93.7500 (92.5000) lr 1.4115e-03 eta 0:10:44
epoch [75/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.5532 (0.3007) acc 87.5000 (92.5694) lr 1.4115e-03 eta 0:10:33
epoch [75/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4109 (0.3014) acc 87.5000 (92.5000) lr 1.4115e-03 eta 0:10:24
epoch [76/200] batch [5/51] time 0.087 (0.210) data 0.000 (0.122) loss 0.4702 (0.3517) acc 87.5000 (91.8750) lr 1.3971e-03 eta 0:22:16
epoch [76/200] batch [10/51] time 0.086 (0.148) data 0.000 (0.061) loss 0.3892 (0.3424) acc 87.5000 (90.9375) lr 1.3971e-03 eta 0:15:44
epoch [76/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.3303 (0.3315) acc 93.7500 (91.4583) lr 1.3971e-03 eta 0:13:31
epoch [76/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.031) loss 0.3259 (0.3254) acc 90.6250 (91.8750) lr 1.3971e-03 eta 0:12:25
epoch [76/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.025) loss 0.2651 (0.3287) acc 93.7500 (91.8750) lr 1.3971e-03 eta 0:11:45
epoch [76/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.4368 (0.3324) acc 90.6250 (91.9792) lr 1.3971e-03 eta 0:11:19
epoch [76/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.3914 (0.3291) acc 90.6250 (92.2321) lr 1.3971e-03 eta 0:11:00
epoch [76/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2156 (0.3262) acc 100.0000 (92.3438) lr 1.3971e-03 eta 0:10:45
epoch [76/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3892 (0.3264) acc 90.6250 (92.4306) lr 1.3971e-03 eta 0:10:33
epoch [76/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3948 (0.3280) acc 90.6250 (92.4375) lr 1.3971e-03 eta 0:10:23
epoch [77/200] batch [5/51] time 0.087 (0.206) data 0.000 (0.119) loss 0.4126 (0.3703) acc 87.5000 (89.3750) lr 1.3827e-03 eta 0:21:43
epoch [77/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.3438 (0.4180) acc 96.8750 (90.9375) lr 1.3827e-03 eta 0:15:28
epoch [77/200] batch [15/51] time 0.088 (0.127) data 0.000 (0.040) loss 0.2432 (0.4074) acc 96.8750 (91.2500) lr 1.3827e-03 eta 0:13:21
epoch [77/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2227 (0.3690) acc 90.6250 (91.7188) lr 1.3827e-03 eta 0:12:18
epoch [77/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.4070 (0.3583) acc 93.7500 (92.1250) lr 1.3827e-03 eta 0:11:40
epoch [77/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1422 (0.3553) acc 96.8750 (92.1875) lr 1.3827e-03 eta 0:11:14
epoch [77/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3445 (0.3493) acc 93.7500 (92.5000) lr 1.3827e-03 eta 0:10:56
epoch [77/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1995 (0.3443) acc 96.8750 (92.1875) lr 1.3827e-03 eta 0:10:41
epoch [77/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3655 (0.3377) acc 90.6250 (92.2222) lr 1.3827e-03 eta 0:10:29
epoch [77/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1733 (0.3336) acc 93.7500 (92.2500) lr 1.3827e-03 eta 0:10:20
epoch [78/200] batch [5/51] time 0.086 (0.222) data 0.000 (0.135) loss 0.4739 (0.2830) acc 87.5000 (94.3750) lr 1.3681e-03 eta 0:23:08
epoch [78/200] batch [10/51] time 0.086 (0.154) data 0.000 (0.068) loss 0.3057 (0.2729) acc 93.7500 (94.3750) lr 1.3681e-03 eta 0:16:05
epoch [78/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.2739 (0.2721) acc 93.7500 (94.3750) lr 1.3681e-03 eta 0:13:43
epoch [78/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.034) loss 0.3396 (0.2784) acc 93.7500 (93.9062) lr 1.3681e-03 eta 0:12:32
epoch [78/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.2167 (0.2782) acc 96.8750 (93.8750) lr 1.3681e-03 eta 0:11:49
epoch [78/200] batch [30/51] time 0.090 (0.109) data 0.000 (0.023) loss 0.4180 (0.2830) acc 87.5000 (93.5417) lr 1.3681e-03 eta 0:11:21
epoch [78/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3093 (0.2987) acc 93.7500 (93.1250) lr 1.3681e-03 eta 0:11:00
epoch [78/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.3000 (0.3084) acc 87.5000 (92.7344) lr 1.3681e-03 eta 0:10:44
epoch [78/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.3118 (0.2951) acc 96.8750 (93.1250) lr 1.3681e-03 eta 0:10:31
epoch [78/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1840 (0.2906) acc 93.7500 (93.1875) lr 1.3681e-03 eta 0:10:21
epoch [79/200] batch [5/51] time 0.089 (0.219) data 0.000 (0.131) loss 0.4910 (0.4493) acc 90.6250 (89.3750) lr 1.3535e-03 eta 0:22:42
epoch [79/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.4834 (0.3706) acc 87.5000 (91.5625) lr 1.3535e-03 eta 0:15:51
epoch [79/200] batch [15/51] time 0.088 (0.131) data 0.001 (0.044) loss 0.2991 (0.3616) acc 90.6250 (91.0417) lr 1.3535e-03 eta 0:13:34
epoch [79/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.4741 (0.3664) acc 84.3750 (90.6250) lr 1.3535e-03 eta 0:12:25
epoch [79/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.026) loss 0.3438 (0.3503) acc 90.6250 (91.1250) lr 1.3535e-03 eta 0:11:43
epoch [79/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3521 (0.3434) acc 93.7500 (91.0417) lr 1.3535e-03 eta 0:11:16
epoch [79/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.6021 (0.3437) acc 78.1250 (90.8036) lr 1.3535e-03 eta 0:10:56
epoch [79/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1642 (0.3271) acc 96.8750 (91.3281) lr 1.3535e-03 eta 0:10:40
epoch [79/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2649 (0.3134) acc 93.7500 (91.7361) lr 1.3535e-03 eta 0:10:27
epoch [79/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2180 (0.3059) acc 96.8750 (92.1875) lr 1.3535e-03 eta 0:10:17
epoch [80/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.117) loss 0.1636 (0.2234) acc 93.7500 (94.3750) lr 1.3387e-03 eta 0:20:57
epoch [80/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.1193 (0.2673) acc 100.0000 (93.7500) lr 1.3387e-03 eta 0:14:57
epoch [80/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.2520 (0.2794) acc 96.8750 (93.9583) lr 1.3387e-03 eta 0:12:55
epoch [80/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.4861 (0.2942) acc 87.5000 (93.4375) lr 1.3387e-03 eta 0:11:54
epoch [80/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.3579 (0.2977) acc 93.7500 (93.7500) lr 1.3387e-03 eta 0:11:18
epoch [80/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.5474 (0.3088) acc 90.6250 (93.6458) lr 1.3387e-03 eta 0:10:53
epoch [80/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3967 (0.3136) acc 90.6250 (93.4821) lr 1.3387e-03 eta 0:10:36
epoch [80/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2725 (0.3231) acc 93.7500 (93.2031) lr 1.3387e-03 eta 0:10:22
epoch [80/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2871 (0.3215) acc 93.7500 (93.2639) lr 1.3387e-03 eta 0:10:10
epoch [80/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3931 (0.3278) acc 87.5000 (92.8125) lr 1.3387e-03 eta 0:10:01
epoch [81/200] batch [5/51] time 0.088 (0.204) data 0.000 (0.116) loss 0.3193 (0.2845) acc 87.5000 (91.8750) lr 1.3239e-03 eta 0:20:49
epoch [81/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.2810 (0.2684) acc 90.6250 (93.4375) lr 1.3239e-03 eta 0:14:51
epoch [81/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.4104 (0.2996) acc 90.6250 (92.9167) lr 1.3239e-03 eta 0:12:52
epoch [81/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.029) loss 0.5249 (0.3185) acc 84.3750 (92.3438) lr 1.3239e-03 eta 0:11:52
epoch [81/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.023) loss 0.1427 (0.3233) acc 100.0000 (92.2500) lr 1.3239e-03 eta 0:11:15
epoch [81/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.1827 (0.3098) acc 93.7500 (92.1875) lr 1.3239e-03 eta 0:10:51
epoch [81/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.2791 (0.3159) acc 93.7500 (91.8750) lr 1.3239e-03 eta 0:10:33
epoch [81/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4988 (0.3153) acc 87.5000 (92.0312) lr 1.3239e-03 eta 0:10:19
epoch [81/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.5283 (0.3245) acc 87.5000 (92.0833) lr 1.3239e-03 eta 0:10:08
epoch [81/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4946 (0.3350) acc 90.6250 (91.9375) lr 1.3239e-03 eta 0:09:59
epoch [82/200] batch [5/51] time 0.088 (0.204) data 0.000 (0.116) loss 0.6206 (0.3184) acc 93.7500 (94.3750) lr 1.3090e-03 eta 0:20:39
epoch [82/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.2864 (0.3655) acc 93.7500 (92.8125) lr 1.3090e-03 eta 0:14:44
epoch [82/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.039) loss 0.5347 (0.3646) acc 84.3750 (92.0833) lr 1.3090e-03 eta 0:12:44
epoch [82/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.029) loss 0.2368 (0.3434) acc 93.7500 (92.1875) lr 1.3090e-03 eta 0:11:44
epoch [82/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.023) loss 0.4922 (0.3478) acc 84.3750 (92.1250) lr 1.3090e-03 eta 0:11:08
epoch [82/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.7490 (0.3584) acc 84.3750 (91.7708) lr 1.3090e-03 eta 0:10:44
epoch [82/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1641 (0.3499) acc 96.8750 (91.9643) lr 1.3090e-03 eta 0:10:27
epoch [82/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1854 (0.3369) acc 96.8750 (92.1094) lr 1.3090e-03 eta 0:10:13
epoch [82/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3933 (0.3385) acc 90.6250 (92.0139) lr 1.3090e-03 eta 0:10:02
epoch [82/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3350 (0.3418) acc 93.7500 (92.0625) lr 1.3090e-03 eta 0:09:53
epoch [83/200] batch [5/51] time 0.086 (0.205) data 0.000 (0.117) loss 0.2603 (0.2473) acc 96.8750 (96.8750) lr 1.2940e-03 eta 0:20:34
epoch [83/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.1550 (0.2776) acc 96.8750 (94.6875) lr 1.2940e-03 eta 0:14:38
epoch [83/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.1277 (0.2460) acc 96.8750 (95.2083) lr 1.2940e-03 eta 0:12:38
epoch [83/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3159 (0.2426) acc 87.5000 (94.2188) lr 1.2940e-03 eta 0:11:38
epoch [83/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.5601 (0.2691) acc 87.5000 (93.3750) lr 1.2940e-03 eta 0:11:02
epoch [83/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2722 (0.2783) acc 93.7500 (93.1250) lr 1.2940e-03 eta 0:10:38
epoch [83/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3254 (0.2830) acc 96.8750 (92.9464) lr 1.2940e-03 eta 0:10:20
epoch [83/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.3296 (0.2861) acc 90.6250 (92.8906) lr 1.2940e-03 eta 0:10:06
epoch [83/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2632 (0.2774) acc 90.6250 (93.1944) lr 1.2940e-03 eta 0:09:55
epoch [83/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.3179 (0.2886) acc 90.6250 (92.8125) lr 1.2940e-03 eta 0:09:46
epoch [84/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.115) loss 0.3625 (0.2525) acc 87.5000 (94.3750) lr 1.2790e-03 eta 0:20:07
epoch [84/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.2690 (0.3102) acc 96.8750 (93.4375) lr 1.2790e-03 eta 0:14:21
epoch [84/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.5352 (0.3369) acc 84.3750 (92.2917) lr 1.2790e-03 eta 0:12:26
epoch [84/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3745 (0.3435) acc 84.3750 (92.0312) lr 1.2790e-03 eta 0:11:28
epoch [84/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.2428 (0.3407) acc 93.7500 (92.1250) lr 1.2790e-03 eta 0:10:52
epoch [84/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2783 (0.3292) acc 90.6250 (92.3958) lr 1.2790e-03 eta 0:10:29
epoch [84/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.017) loss 0.3015 (0.3173) acc 93.7500 (92.7679) lr 1.2790e-03 eta 0:10:12
epoch [84/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.4199 (0.3172) acc 90.6250 (92.8906) lr 1.2790e-03 eta 0:09:59
epoch [84/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2262 (0.3160) acc 93.7500 (92.9167) lr 1.2790e-03 eta 0:09:48
epoch [84/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.012) loss 0.3992 (0.3203) acc 84.3750 (92.5625) lr 1.2790e-03 eta 0:09:40
epoch [85/200] batch [5/51] time 0.088 (0.213) data 0.000 (0.125) loss 0.4268 (0.3028) acc 93.7500 (94.3750) lr 1.2639e-03 eta 0:20:57
epoch [85/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.1663 (0.3150) acc 93.7500 (93.4375) lr 1.2639e-03 eta 0:14:45
epoch [85/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.4153 (0.3348) acc 90.6250 (92.7083) lr 1.2639e-03 eta 0:12:41
epoch [85/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.4556 (0.3187) acc 84.3750 (92.6562) lr 1.2639e-03 eta 0:11:37
epoch [85/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3098 (0.3097) acc 90.6250 (92.7500) lr 1.2639e-03 eta 0:11:00
epoch [85/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.3096 (0.3162) acc 90.6250 (91.8750) lr 1.2639e-03 eta 0:10:34
epoch [85/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.5234 (0.3136) acc 84.3750 (91.8750) lr 1.2639e-03 eta 0:10:16
epoch [85/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1926 (0.3121) acc 96.8750 (92.2656) lr 1.2639e-03 eta 0:10:02
epoch [85/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4634 (0.3204) acc 90.6250 (92.1528) lr 1.2639e-03 eta 0:09:51
epoch [85/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4651 (0.3252) acc 87.5000 (92.1250) lr 1.2639e-03 eta 0:09:42
epoch [86/200] batch [5/51] time 0.088 (0.209) data 0.000 (0.121) loss 0.0977 (0.2995) acc 100.0000 (90.6250) lr 1.2487e-03 eta 0:20:25
epoch [86/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.5483 (0.3350) acc 81.2500 (89.3750) lr 1.2487e-03 eta 0:14:28
epoch [86/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.040) loss 0.3391 (0.3407) acc 93.7500 (90.2083) lr 1.2487e-03 eta 0:12:27
epoch [86/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.030) loss 0.4387 (0.3435) acc 90.6250 (90.9375) lr 1.2487e-03 eta 0:11:27
epoch [86/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.2091 (0.3440) acc 96.8750 (91.0000) lr 1.2487e-03 eta 0:10:50
epoch [86/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4219 (0.3419) acc 90.6250 (91.1458) lr 1.2487e-03 eta 0:10:26
epoch [86/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.017) loss 0.2399 (0.3346) acc 100.0000 (91.4286) lr 1.2487e-03 eta 0:10:09
epoch [86/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1205 (0.3296) acc 100.0000 (91.5625) lr 1.2487e-03 eta 0:09:55
epoch [86/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3149 (0.3246) acc 96.8750 (91.9444) lr 1.2487e-03 eta 0:09:44
epoch [86/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3381 (0.3239) acc 93.7500 (91.8125) lr 1.2487e-03 eta 0:09:35
epoch [87/200] batch [5/51] time 0.089 (0.205) data 0.000 (0.117) loss 0.5615 (0.4544) acc 84.3750 (88.1250) lr 1.2334e-03 eta 0:19:51
epoch [87/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.2273 (0.3844) acc 96.8750 (90.6250) lr 1.2334e-03 eta 0:14:08
epoch [87/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.039) loss 0.5293 (0.3718) acc 90.6250 (91.2500) lr 1.2334e-03 eta 0:12:13
epoch [87/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.029) loss 0.6108 (0.3912) acc 87.5000 (90.0000) lr 1.2334e-03 eta 0:11:16
epoch [87/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.5562 (0.3933) acc 90.6250 (90.2500) lr 1.2334e-03 eta 0:10:41
epoch [87/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.3137 (0.3794) acc 93.7500 (90.9375) lr 1.2334e-03 eta 0:10:19
epoch [87/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.2225 (0.3751) acc 90.6250 (91.0714) lr 1.2334e-03 eta 0:10:02
epoch [87/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1910 (0.3634) acc 96.8750 (91.3281) lr 1.2334e-03 eta 0:09:49
epoch [87/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2629 (0.3603) acc 96.8750 (91.5972) lr 1.2334e-03 eta 0:09:38
epoch [87/200] batch [50/51] time 0.087 (0.099) data 0.000 (0.012) loss 0.4094 (0.3636) acc 90.6250 (91.6250) lr 1.2334e-03 eta 0:09:30
epoch [88/200] batch [5/51] time 0.087 (0.210) data 0.000 (0.122) loss 0.1521 (0.2170) acc 100.0000 (95.6250) lr 1.2181e-03 eta 0:20:07
epoch [88/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.061) loss 0.5103 (0.3363) acc 90.6250 (92.1875) lr 1.2181e-03 eta 0:14:11
epoch [88/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.3799 (0.3152) acc 90.6250 (92.9167) lr 1.2181e-03 eta 0:12:13
epoch [88/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.031) loss 0.1536 (0.2894) acc 96.8750 (93.2812) lr 1.2181e-03 eta 0:11:14
epoch [88/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.025) loss 0.3972 (0.3233) acc 84.3750 (92.1250) lr 1.2181e-03 eta 0:10:39
epoch [88/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.021) loss 0.2678 (0.3362) acc 93.7500 (91.8750) lr 1.2181e-03 eta 0:10:15
epoch [88/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.1510 (0.3300) acc 96.8750 (91.7857) lr 1.2181e-03 eta 0:09:57
epoch [88/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3865 (0.3314) acc 87.5000 (91.7969) lr 1.2181e-03 eta 0:09:44
epoch [88/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.0860 (0.3251) acc 100.0000 (92.1528) lr 1.2181e-03 eta 0:09:33
epoch [88/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4211 (0.3323) acc 87.5000 (91.9375) lr 1.2181e-03 eta 0:09:24
epoch [89/200] batch [5/51] time 0.086 (0.222) data 0.000 (0.135) loss 0.5352 (0.3352) acc 90.6250 (91.8750) lr 1.2028e-03 eta 0:21:05
epoch [89/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.2534 (0.2812) acc 93.7500 (93.1250) lr 1.2028e-03 eta 0:14:40
epoch [89/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.2006 (0.2704) acc 96.8750 (93.5417) lr 1.2028e-03 eta 0:12:31
epoch [89/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.2639 (0.2662) acc 96.8750 (93.9062) lr 1.2028e-03 eta 0:11:26
epoch [89/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3030 (0.2908) acc 90.6250 (93.1250) lr 1.2028e-03 eta 0:10:48
epoch [89/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.5840 (0.3047) acc 84.3750 (92.9167) lr 1.2028e-03 eta 0:10:21
epoch [89/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.2981 (0.3058) acc 96.8750 (93.1250) lr 1.2028e-03 eta 0:10:02
epoch [89/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2028 (0.2977) acc 90.6250 (93.2031) lr 1.2028e-03 eta 0:09:48
epoch [89/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1293 (0.3071) acc 96.8750 (92.9861) lr 1.2028e-03 eta 0:09:36
epoch [89/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2649 (0.3033) acc 93.7500 (93.0625) lr 1.2028e-03 eta 0:09:26
epoch [90/200] batch [5/51] time 0.088 (0.222) data 0.000 (0.135) loss 0.1580 (0.3287) acc 96.8750 (92.5000) lr 1.1874e-03 eta 0:20:56
epoch [90/200] batch [10/51] time 0.088 (0.155) data 0.000 (0.068) loss 0.2764 (0.3514) acc 93.7500 (91.5625) lr 1.1874e-03 eta 0:14:35
epoch [90/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.1670 (0.3306) acc 93.7500 (92.5000) lr 1.1874e-03 eta 0:12:27
epoch [90/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.1898 (0.3317) acc 96.8750 (92.6562) lr 1.1874e-03 eta 0:11:22
epoch [90/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.5332 (0.3390) acc 87.5000 (92.2500) lr 1.1874e-03 eta 0:10:43
epoch [90/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3723 (0.3204) acc 90.6250 (92.6042) lr 1.1874e-03 eta 0:10:17
epoch [90/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.1989 (0.3191) acc 93.7500 (92.4107) lr 1.1874e-03 eta 0:09:58
epoch [90/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2230 (0.3190) acc 93.7500 (92.4219) lr 1.1874e-03 eta 0:09:43
epoch [90/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2206 (0.3129) acc 93.7500 (92.7778) lr 1.1874e-03 eta 0:09:32
epoch [90/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2546 (0.3221) acc 96.8750 (92.5000) lr 1.1874e-03 eta 0:09:22
epoch [91/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.124) loss 0.1954 (0.2508) acc 93.7500 (93.1250) lr 1.1719e-03 eta 0:19:47
epoch [91/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.2693 (0.3078) acc 87.5000 (91.5625) lr 1.1719e-03 eta 0:13:55
epoch [91/200] batch [15/51] time 0.088 (0.129) data 0.000 (0.042) loss 0.4341 (0.2993) acc 93.7500 (91.8750) lr 1.1719e-03 eta 0:11:59
epoch [91/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.1776 (0.3004) acc 96.8750 (91.7188) lr 1.1719e-03 eta 0:11:01
epoch [91/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.1884 (0.2944) acc 96.8750 (92.3750) lr 1.1719e-03 eta 0:10:25
epoch [91/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.021) loss 0.4292 (0.2984) acc 87.5000 (92.5000) lr 1.1719e-03 eta 0:10:01
epoch [91/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.5088 (0.3093) acc 90.6250 (92.2321) lr 1.1719e-03 eta 0:09:44
epoch [91/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.1644 (0.3017) acc 96.8750 (92.5000) lr 1.1719e-03 eta 0:09:31
epoch [91/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4370 (0.2978) acc 87.5000 (92.6389) lr 1.1719e-03 eta 0:09:20
epoch [91/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.5474 (0.3007) acc 84.3750 (92.6250) lr 1.1719e-03 eta 0:09:11
epoch [92/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.125) loss 0.4539 (0.3165) acc 84.3750 (92.5000) lr 1.1564e-03 eta 0:19:42
epoch [92/200] batch [10/51] time 0.086 (0.150) data 0.000 (0.063) loss 0.2791 (0.2985) acc 96.8750 (92.5000) lr 1.1564e-03 eta 0:13:51
epoch [92/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.4487 (0.3135) acc 90.6250 (92.5000) lr 1.1564e-03 eta 0:11:53
epoch [92/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.1536 (0.3079) acc 93.7500 (92.3438) lr 1.1564e-03 eta 0:10:54
epoch [92/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2524 (0.3299) acc 93.7500 (92.3750) lr 1.1564e-03 eta 0:10:18
epoch [92/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.1960 (0.3233) acc 93.7500 (92.9167) lr 1.1564e-03 eta 0:09:55
epoch [92/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3076 (0.3046) acc 90.6250 (93.3036) lr 1.1564e-03 eta 0:09:38
epoch [92/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.1683 (0.3109) acc 93.7500 (93.2031) lr 1.1564e-03 eta 0:09:24
epoch [92/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1940 (0.3152) acc 96.8750 (92.8472) lr 1.1564e-03 eta 0:09:14
epoch [92/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4082 (0.3357) acc 90.6250 (92.4375) lr 1.1564e-03 eta 0:09:05
epoch [93/200] batch [5/51] time 0.090 (0.208) data 0.000 (0.119) loss 0.6367 (0.3557) acc 78.1250 (88.7500) lr 1.1409e-03 eta 0:19:03
epoch [93/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.059) loss 0.4182 (0.3303) acc 90.6250 (91.2500) lr 1.1409e-03 eta 0:13:32
epoch [93/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.040) loss 0.5132 (0.3167) acc 84.3750 (91.8750) lr 1.1409e-03 eta 0:11:40
epoch [93/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2108 (0.2977) acc 93.7500 (92.3438) lr 1.1409e-03 eta 0:10:44
epoch [93/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.2280 (0.2839) acc 93.7500 (92.8750) lr 1.1409e-03 eta 0:10:11
epoch [93/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1473 (0.2660) acc 96.8750 (93.1250) lr 1.1409e-03 eta 0:09:48
epoch [93/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.017) loss 0.6035 (0.2940) acc 81.2500 (92.5893) lr 1.1409e-03 eta 0:09:32
epoch [93/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2280 (0.3015) acc 90.6250 (92.3438) lr 1.1409e-03 eta 0:09:19
epoch [93/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.013) loss 0.3147 (0.3057) acc 93.7500 (92.3611) lr 1.1409e-03 eta 0:09:09
epoch [93/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1699 (0.3048) acc 96.8750 (92.4375) lr 1.1409e-03 eta 0:09:00
epoch [94/200] batch [5/51] time 0.087 (0.210) data 0.000 (0.121) loss 0.2252 (0.2977) acc 93.7500 (92.5000) lr 1.1253e-03 eta 0:19:04
epoch [94/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.061) loss 0.3516 (0.2742) acc 90.6250 (93.7500) lr 1.1253e-03 eta 0:13:29
epoch [94/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.2825 (0.3163) acc 93.7500 (92.5000) lr 1.1253e-03 eta 0:11:37
epoch [94/200] batch [20/51] time 0.088 (0.118) data 0.000 (0.031) loss 0.3464 (0.3173) acc 87.5000 (92.1875) lr 1.1253e-03 eta 0:10:41
epoch [94/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.024) loss 0.0834 (0.2990) acc 100.0000 (92.7500) lr 1.1253e-03 eta 0:10:07
epoch [94/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.020) loss 0.3354 (0.2915) acc 90.6250 (93.1250) lr 1.1253e-03 eta 0:09:44
epoch [94/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3413 (0.2882) acc 93.7500 (93.3036) lr 1.1253e-03 eta 0:09:28
epoch [94/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.015) loss 0.3401 (0.2962) acc 96.8750 (93.0469) lr 1.1253e-03 eta 0:09:15
epoch [94/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1453 (0.2939) acc 100.0000 (92.9861) lr 1.1253e-03 eta 0:09:04
epoch [94/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.2150 (0.2982) acc 93.7500 (92.8750) lr 1.1253e-03 eta 0:08:56
epoch [95/200] batch [5/51] time 0.087 (0.206) data 0.000 (0.118) loss 0.2954 (0.2912) acc 93.7500 (93.1250) lr 1.1097e-03 eta 0:18:32
epoch [95/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.1760 (0.2945) acc 96.8750 (93.1250) lr 1.1097e-03 eta 0:13:10
epoch [95/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.2727 (0.2951) acc 93.7500 (93.7500) lr 1.1097e-03 eta 0:11:22
epoch [95/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3716 (0.2872) acc 90.6250 (93.7500) lr 1.1097e-03 eta 0:10:28
epoch [95/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3196 (0.2993) acc 93.7500 (93.6250) lr 1.1097e-03 eta 0:09:56
epoch [95/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.3696 (0.3101) acc 90.6250 (93.1250) lr 1.1097e-03 eta 0:09:34
epoch [95/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2769 (0.3001) acc 96.8750 (93.6607) lr 1.1097e-03 eta 0:09:19
epoch [95/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2788 (0.2932) acc 93.7500 (93.5938) lr 1.1097e-03 eta 0:09:06
epoch [95/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3450 (0.2933) acc 90.6250 (93.5417) lr 1.1097e-03 eta 0:08:56
epoch [95/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3599 (0.2918) acc 93.7500 (93.6250) lr 1.1097e-03 eta 0:08:48
epoch [96/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.112) loss 0.1857 (0.1918) acc 93.7500 (96.8750) lr 1.0941e-03 eta 0:17:48
epoch [96/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.3193 (0.2327) acc 84.3750 (94.6875) lr 1.0941e-03 eta 0:12:47
epoch [96/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.037) loss 0.2186 (0.2500) acc 90.6250 (94.1667) lr 1.0941e-03 eta 0:11:06
epoch [96/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2310 (0.2664) acc 93.7500 (93.7500) lr 1.0941e-03 eta 0:10:15
epoch [96/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3530 (0.2722) acc 96.8750 (93.8750) lr 1.0941e-03 eta 0:09:44
epoch [96/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2756 (0.2848) acc 93.7500 (93.6458) lr 1.0941e-03 eta 0:09:24
epoch [96/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1015 (0.2760) acc 100.0000 (94.0179) lr 1.0941e-03 eta 0:09:09
epoch [96/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2690 (0.2811) acc 93.7500 (93.7500) lr 1.0941e-03 eta 0:08:57
epoch [96/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1456 (0.2860) acc 96.8750 (93.6806) lr 1.0941e-03 eta 0:08:48
epoch [96/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1741 (0.2817) acc 93.7500 (93.6250) lr 1.0941e-03 eta 0:08:40
epoch [97/200] batch [5/51] time 0.088 (0.197) data 0.000 (0.109) loss 0.4133 (0.3245) acc 90.6250 (95.0000) lr 1.0785e-03 eta 0:17:21
epoch [97/200] batch [10/51] time 0.088 (0.142) data 0.000 (0.055) loss 0.2810 (0.3373) acc 93.7500 (92.8125) lr 1.0785e-03 eta 0:12:30
epoch [97/200] batch [15/51] time 0.087 (0.123) data 0.000 (0.036) loss 0.3555 (0.3245) acc 90.6250 (92.7083) lr 1.0785e-03 eta 0:10:52
epoch [97/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3223 (0.3097) acc 90.6250 (92.9688) lr 1.0785e-03 eta 0:10:04
epoch [97/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2267 (0.3174) acc 93.7500 (92.5000) lr 1.0785e-03 eta 0:09:34
epoch [97/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1522 (0.3126) acc 96.8750 (92.5000) lr 1.0785e-03 eta 0:09:14
epoch [97/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1748 (0.3135) acc 100.0000 (92.9464) lr 1.0785e-03 eta 0:09:00
epoch [97/200] batch [40/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.1752 (0.3273) acc 96.8750 (92.3438) lr 1.0785e-03 eta 0:08:48
epoch [97/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2179 (0.3190) acc 96.8750 (92.4306) lr 1.0785e-03 eta 0:08:39
epoch [97/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.0764 (0.3089) acc 100.0000 (92.6875) lr 1.0785e-03 eta 0:08:32
epoch [98/200] batch [5/51] time 0.087 (0.203) data 0.000 (0.115) loss 0.2404 (0.1922) acc 96.8750 (96.8750) lr 1.0628e-03 eta 0:17:45
epoch [98/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.0807 (0.2118) acc 100.0000 (96.8750) lr 1.0628e-03 eta 0:12:40
epoch [98/200] batch [15/51] time 0.089 (0.126) data 0.000 (0.039) loss 0.1663 (0.2424) acc 93.7500 (96.2500) lr 1.0628e-03 eta 0:10:59
epoch [98/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.2415 (0.2686) acc 93.7500 (95.1562) lr 1.0628e-03 eta 0:10:08
epoch [98/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1573 (0.2820) acc 96.8750 (93.7500) lr 1.0628e-03 eta 0:09:37
epoch [98/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.019) loss 0.2561 (0.3041) acc 90.6250 (92.6042) lr 1.0628e-03 eta 0:09:16
epoch [98/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2734 (0.3083) acc 90.6250 (92.5000) lr 1.0628e-03 eta 0:09:01
epoch [98/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2078 (0.2991) acc 93.7500 (92.6562) lr 1.0628e-03 eta 0:08:49
epoch [98/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3162 (0.3190) acc 87.5000 (92.3611) lr 1.0628e-03 eta 0:08:40
epoch [98/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1759 (0.3237) acc 96.8750 (92.2500) lr 1.0628e-03 eta 0:08:32
epoch [99/200] batch [5/51] time 0.086 (0.220) data 0.000 (0.133) loss 0.3096 (0.3575) acc 90.6250 (91.2500) lr 1.0471e-03 eta 0:19:01
epoch [99/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.067) loss 0.3196 (0.3154) acc 93.7500 (92.5000) lr 1.0471e-03 eta 0:13:14
epoch [99/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.2008 (0.3048) acc 100.0000 (93.5417) lr 1.0471e-03 eta 0:11:19
epoch [99/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.0948 (0.2851) acc 100.0000 (93.7500) lr 1.0471e-03 eta 0:10:21
epoch [99/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.027) loss 0.2250 (0.2863) acc 93.7500 (93.0000) lr 1.0471e-03 eta 0:09:46
epoch [99/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.4736 (0.2979) acc 90.6250 (92.8125) lr 1.0471e-03 eta 0:09:22
epoch [99/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.3560 (0.3013) acc 87.5000 (92.5000) lr 1.0471e-03 eta 0:09:05
epoch [99/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.2056 (0.2967) acc 96.8750 (92.8125) lr 1.0471e-03 eta 0:08:52
epoch [99/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.6904 (0.3057) acc 84.3750 (92.2222) lr 1.0471e-03 eta 0:08:41
epoch [99/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1857 (0.3024) acc 96.8750 (92.2500) lr 1.0471e-03 eta 0:08:33
epoch [100/200] batch [5/51] time 0.088 (0.214) data 0.000 (0.126) loss 0.3579 (0.2688) acc 87.5000 (92.5000) lr 1.0314e-03 eta 0:18:20
epoch [100/200] batch [10/51] time 0.086 (0.150) data 0.000 (0.063) loss 0.1785 (0.2817) acc 96.8750 (92.5000) lr 1.0314e-03 eta 0:12:52
epoch [100/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.3662 (0.2930) acc 93.7500 (92.7083) lr 1.0314e-03 eta 0:11:03
epoch [100/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.2206 (0.2935) acc 96.8750 (93.2812) lr 1.0314e-03 eta 0:10:08
epoch [100/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.4116 (0.2947) acc 90.6250 (93.1250) lr 1.0314e-03 eta 0:09:35
epoch [100/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.6421 (0.3046) acc 87.5000 (92.9167) lr 1.0314e-03 eta 0:09:13
epoch [100/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.4124 (0.3078) acc 90.6250 (92.6786) lr 1.0314e-03 eta 0:08:57
epoch [100/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4155 (0.3157) acc 90.6250 (92.5000) lr 1.0314e-03 eta 0:08:44
epoch [100/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3003 (0.3117) acc 90.6250 (92.5694) lr 1.0314e-03 eta 0:08:34
epoch [100/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1954 (0.3067) acc 96.8750 (92.7500) lr 1.0314e-03 eta 0:08:26
epoch [101/200] batch [5/51] time 0.086 (0.220) data 0.000 (0.133) loss 0.3049 (0.2803) acc 90.6250 (94.3750) lr 1.0157e-03 eta 0:18:42
epoch [101/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.2059 (0.2847) acc 96.8750 (93.1250) lr 1.0157e-03 eta 0:13:02
epoch [101/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.045) loss 0.2678 (0.2988) acc 93.7500 (92.7083) lr 1.0157e-03 eta 0:11:08
epoch [101/200] batch [20/51] time 0.088 (0.120) data 0.000 (0.033) loss 0.3037 (0.2985) acc 87.5000 (92.1875) lr 1.0157e-03 eta 0:10:11
epoch [101/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.2010 (0.3065) acc 96.8750 (91.7500) lr 1.0157e-03 eta 0:09:36
epoch [101/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.3264 (0.3032) acc 87.5000 (91.8750) lr 1.0157e-03 eta 0:09:13
epoch [101/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.1366 (0.3035) acc 100.0000 (92.0536) lr 1.0157e-03 eta 0:08:56
epoch [101/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.3228 (0.3077) acc 93.7500 (92.1094) lr 1.0157e-03 eta 0:08:43
epoch [101/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2146 (0.3157) acc 93.7500 (92.1528) lr 1.0157e-03 eta 0:08:33
epoch [101/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4224 (0.3163) acc 84.3750 (92.0625) lr 1.0157e-03 eta 0:08:24
epoch [102/200] batch [5/51] time 0.088 (0.205) data 0.000 (0.116) loss 0.3533 (0.3464) acc 90.6250 (91.2500) lr 1.0000e-03 eta 0:17:11
epoch [102/200] batch [10/51] time 0.086 (0.146) data 0.000 (0.058) loss 0.3250 (0.2817) acc 87.5000 (92.5000) lr 1.0000e-03 eta 0:12:14
epoch [102/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.039) loss 0.2340 (0.2637) acc 96.8750 (93.3333) lr 1.0000e-03 eta 0:10:35
epoch [102/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.4956 (0.2658) acc 90.6250 (93.2812) lr 1.0000e-03 eta 0:09:45
epoch [102/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.023) loss 0.2981 (0.2760) acc 93.7500 (93.1250) lr 1.0000e-03 eta 0:09:15
epoch [102/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4199 (0.2791) acc 96.8750 (93.4375) lr 1.0000e-03 eta 0:08:55
epoch [102/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3660 (0.2987) acc 90.6250 (93.3036) lr 1.0000e-03 eta 0:08:40
epoch [102/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3145 (0.2922) acc 96.8750 (93.5938) lr 1.0000e-03 eta 0:08:28
epoch [102/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1836 (0.2865) acc 96.8750 (93.6806) lr 1.0000e-03 eta 0:08:19
epoch [102/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.5820 (0.2898) acc 84.3750 (93.3750) lr 1.0000e-03 eta 0:08:12
epoch [103/200] batch [5/51] time 0.089 (0.204) data 0.000 (0.116) loss 0.4851 (0.3006) acc 84.3750 (93.1250) lr 9.8429e-04 eta 0:17:00
epoch [103/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.1731 (0.2697) acc 93.7500 (94.0625) lr 9.8429e-04 eta 0:12:06
epoch [103/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.1569 (0.2687) acc 96.8750 (93.7500) lr 9.8429e-04 eta 0:10:29
epoch [103/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.1312 (0.2720) acc 100.0000 (93.9062) lr 9.8429e-04 eta 0:09:39
epoch [103/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.023) loss 0.2722 (0.2934) acc 90.6250 (93.1250) lr 9.8429e-04 eta 0:09:09
epoch [103/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4094 (0.2944) acc 87.5000 (92.7083) lr 9.8429e-04 eta 0:08:49
epoch [103/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3943 (0.2977) acc 81.2500 (92.4107) lr 9.8429e-04 eta 0:08:35
epoch [103/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.3091 (0.3084) acc 93.7500 (92.2656) lr 9.8429e-04 eta 0:08:23
epoch [103/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.1466 (0.2985) acc 100.0000 (92.7083) lr 9.8429e-04 eta 0:08:14
epoch [103/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3594 (0.2977) acc 90.6250 (92.6250) lr 9.8429e-04 eta 0:08:06
epoch [104/200] batch [5/51] time 0.088 (0.211) data 0.000 (0.122) loss 0.1724 (0.3217) acc 93.7500 (89.3750) lr 9.6859e-04 eta 0:17:21
epoch [104/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.061) loss 0.2075 (0.2667) acc 96.8750 (92.5000) lr 9.6859e-04 eta 0:12:14
epoch [104/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.1560 (0.2613) acc 100.0000 (93.1250) lr 9.6859e-04 eta 0:10:32
epoch [104/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.3323 (0.2661) acc 93.7500 (93.2812) lr 9.6859e-04 eta 0:09:40
epoch [104/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1655 (0.2788) acc 100.0000 (93.3750) lr 9.6859e-04 eta 0:09:09
epoch [104/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.1394 (0.2739) acc 96.8750 (93.5417) lr 9.6859e-04 eta 0:08:48
epoch [104/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.8042 (0.2968) acc 75.0000 (92.8571) lr 9.6859e-04 eta 0:08:34
epoch [104/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2115 (0.2993) acc 96.8750 (92.7344) lr 9.6859e-04 eta 0:08:22
epoch [104/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3340 (0.3048) acc 93.7500 (92.6389) lr 9.6859e-04 eta 0:08:12
epoch [104/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3701 (0.2995) acc 87.5000 (92.8750) lr 9.6859e-04 eta 0:08:05
epoch [105/200] batch [5/51] time 0.087 (0.221) data 0.000 (0.134) loss 0.3857 (0.3225) acc 90.6250 (92.5000) lr 9.5289e-04 eta 0:18:03
epoch [105/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.2761 (0.3490) acc 93.7500 (90.6250) lr 9.5289e-04 eta 0:12:33
epoch [105/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.2267 (0.3278) acc 93.7500 (91.2500) lr 9.5289e-04 eta 0:10:43
epoch [105/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.2386 (0.3140) acc 100.0000 (91.7188) lr 9.5289e-04 eta 0:09:47
epoch [105/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2340 (0.3128) acc 96.8750 (92.0000) lr 9.5289e-04 eta 0:09:14
epoch [105/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.0624 (0.3060) acc 100.0000 (92.5000) lr 9.5289e-04 eta 0:08:51
epoch [105/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3450 (0.3025) acc 93.7500 (92.6786) lr 9.5289e-04 eta 0:08:35
epoch [105/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3523 (0.3079) acc 93.7500 (92.8906) lr 9.5289e-04 eta 0:08:23
epoch [105/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4094 (0.3154) acc 90.6250 (92.6389) lr 9.5289e-04 eta 0:08:13
epoch [105/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1224 (0.3212) acc 100.0000 (92.5000) lr 9.5289e-04 eta 0:08:04
epoch [106/200] batch [5/51] time 0.088 (0.204) data 0.000 (0.117) loss 0.2461 (0.2930) acc 93.7500 (93.7500) lr 9.3721e-04 eta 0:16:29
epoch [106/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.2274 (0.2763) acc 93.7500 (92.8125) lr 9.3721e-04 eta 0:11:44
epoch [106/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.039) loss 0.1786 (0.2749) acc 96.8750 (93.3333) lr 9.3721e-04 eta 0:10:08
epoch [106/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.4829 (0.2996) acc 87.5000 (92.3438) lr 9.3721e-04 eta 0:09:21
epoch [106/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.024) loss 0.4956 (0.2958) acc 87.5000 (92.6250) lr 9.3721e-04 eta 0:08:52
epoch [106/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.2849 (0.2908) acc 96.8750 (92.9167) lr 9.3721e-04 eta 0:08:32
epoch [106/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3010 (0.2913) acc 93.7500 (92.7679) lr 9.3721e-04 eta 0:08:18
epoch [106/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.5620 (0.3109) acc 71.8750 (91.6406) lr 9.3721e-04 eta 0:08:07
epoch [106/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.1350 (0.2994) acc 96.8750 (92.0833) lr 9.3721e-04 eta 0:07:58
epoch [106/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2957 (0.2920) acc 90.6250 (92.3125) lr 9.3721e-04 eta 0:07:51
epoch [107/200] batch [5/51] time 0.087 (0.225) data 0.000 (0.137) loss 0.1974 (0.2655) acc 96.8750 (93.7500) lr 9.2154e-04 eta 0:17:57
epoch [107/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.2988 (0.2660) acc 93.7500 (94.3750) lr 9.2154e-04 eta 0:12:26
epoch [107/200] batch [15/51] time 0.086 (0.133) data 0.000 (0.046) loss 0.1396 (0.3196) acc 96.8750 (93.3333) lr 9.2154e-04 eta 0:10:35
epoch [107/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.2096 (0.2996) acc 93.7500 (93.4375) lr 9.2154e-04 eta 0:09:40
epoch [107/200] batch [25/51] time 0.088 (0.115) data 0.000 (0.028) loss 0.2261 (0.2904) acc 96.8750 (93.6250) lr 9.2154e-04 eta 0:09:06
epoch [107/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4028 (0.3086) acc 90.6250 (93.4375) lr 9.2154e-04 eta 0:08:44
epoch [107/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1425 (0.2905) acc 96.8750 (93.6607) lr 9.2154e-04 eta 0:08:28
epoch [107/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3320 (0.2884) acc 93.7500 (93.7500) lr 9.2154e-04 eta 0:08:15
epoch [107/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4170 (0.2947) acc 84.3750 (93.4722) lr 9.2154e-04 eta 0:08:05
epoch [107/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1985 (0.2897) acc 100.0000 (93.6875) lr 9.2154e-04 eta 0:07:57
epoch [108/200] batch [5/51] time 0.087 (0.226) data 0.000 (0.139) loss 0.6821 (0.4048) acc 78.1250 (88.7500) lr 9.0589e-04 eta 0:17:52
epoch [108/200] batch [10/51] time 0.087 (0.157) data 0.000 (0.070) loss 0.1946 (0.3211) acc 96.8750 (91.5625) lr 9.0589e-04 eta 0:12:21
epoch [108/200] batch [15/51] time 0.087 (0.134) data 0.000 (0.047) loss 0.3142 (0.2953) acc 87.5000 (92.2917) lr 9.0589e-04 eta 0:10:31
epoch [108/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.5718 (0.3058) acc 87.5000 (92.3438) lr 9.0589e-04 eta 0:09:35
epoch [108/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2205 (0.3272) acc 96.8750 (91.6250) lr 9.0589e-04 eta 0:09:02
epoch [108/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.0772 (0.3209) acc 100.0000 (91.9792) lr 9.0589e-04 eta 0:08:39
epoch [108/200] batch [35/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.3328 (0.3176) acc 93.7500 (92.2321) lr 9.0589e-04 eta 0:08:23
epoch [108/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.4539 (0.3147) acc 87.5000 (92.1875) lr 9.0589e-04 eta 0:08:10
epoch [108/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2832 (0.3117) acc 93.7500 (92.3611) lr 9.0589e-04 eta 0:08:00
epoch [108/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2559 (0.3150) acc 90.6250 (92.2500) lr 9.0589e-04 eta 0:07:52
epoch [109/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.114) loss 0.2253 (0.2803) acc 93.7500 (92.5000) lr 8.9027e-04 eta 0:15:49
epoch [109/200] batch [10/51] time 0.088 (0.145) data 0.000 (0.057) loss 0.3037 (0.3187) acc 84.3750 (90.9375) lr 8.9027e-04 eta 0:11:17
epoch [109/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.2245 (0.2789) acc 96.8750 (92.5000) lr 8.9027e-04 eta 0:09:46
epoch [109/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.4158 (0.2948) acc 93.7500 (92.5000) lr 8.9027e-04 eta 0:09:01
epoch [109/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.2260 (0.2923) acc 93.7500 (92.7500) lr 8.9027e-04 eta 0:08:33
epoch [109/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2172 (0.2879) acc 96.8750 (92.8125) lr 8.9027e-04 eta 0:08:14
epoch [109/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3657 (0.2864) acc 87.5000 (92.7679) lr 8.9027e-04 eta 0:08:01
epoch [109/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5464 (0.3000) acc 90.6250 (92.5781) lr 8.9027e-04 eta 0:07:50
epoch [109/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3398 (0.3009) acc 96.8750 (92.8472) lr 8.9027e-04 eta 0:07:42
epoch [109/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1254 (0.2946) acc 96.8750 (92.9375) lr 8.9027e-04 eta 0:07:35
epoch [110/200] batch [5/51] time 0.087 (0.227) data 0.000 (0.140) loss 0.3462 (0.3571) acc 87.5000 (90.6250) lr 8.7467e-04 eta 0:17:33
epoch [110/200] batch [10/51] time 0.087 (0.157) data 0.000 (0.070) loss 0.1957 (0.3534) acc 96.8750 (90.9375) lr 8.7467e-04 eta 0:12:08
epoch [110/200] batch [15/51] time 0.087 (0.134) data 0.000 (0.047) loss 0.2361 (0.3160) acc 93.7500 (92.7083) lr 8.7467e-04 eta 0:10:19
epoch [110/200] batch [20/51] time 0.087 (0.122) data 0.000 (0.035) loss 0.2717 (0.3188) acc 96.8750 (92.5000) lr 8.7467e-04 eta 0:09:24
epoch [110/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3940 (0.3302) acc 90.6250 (92.1250) lr 8.7467e-04 eta 0:08:51
epoch [110/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.3340 (0.3120) acc 96.8750 (92.7083) lr 8.7467e-04 eta 0:08:29
epoch [110/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3782 (0.3111) acc 90.6250 (92.5893) lr 8.7467e-04 eta 0:08:13
epoch [110/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.018) loss 0.2505 (0.3137) acc 93.7500 (92.5000) lr 8.7467e-04 eta 0:08:00
epoch [110/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.3906 (0.3103) acc 90.6250 (92.9167) lr 8.7467e-04 eta 0:07:50
epoch [110/200] batch [50/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.2974 (0.3089) acc 87.5000 (92.8750) lr 8.7467e-04 eta 0:07:41
epoch [111/200] batch [5/51] time 0.087 (0.220) data 0.000 (0.132) loss 0.1975 (0.1679) acc 100.0000 (97.5000) lr 8.5910e-04 eta 0:16:48
epoch [111/200] batch [10/51] time 0.086 (0.153) data 0.000 (0.066) loss 0.1588 (0.2424) acc 96.8750 (95.3125) lr 8.5910e-04 eta 0:11:42
epoch [111/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.1925 (0.2503) acc 96.8750 (95.0000) lr 8.5910e-04 eta 0:10:00
epoch [111/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.4856 (0.2460) acc 90.6250 (95.0000) lr 8.5910e-04 eta 0:09:08
epoch [111/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.027) loss 0.1632 (0.2493) acc 100.0000 (94.7500) lr 8.5910e-04 eta 0:08:37
epoch [111/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.2463 (0.2680) acc 90.6250 (94.0625) lr 8.5910e-04 eta 0:08:16
epoch [111/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.6865 (0.2917) acc 87.5000 (93.6607) lr 8.5910e-04 eta 0:08:01
epoch [111/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.3525 (0.2991) acc 93.7500 (93.1250) lr 8.5910e-04 eta 0:07:49
epoch [111/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4907 (0.3038) acc 84.3750 (92.9167) lr 8.5910e-04 eta 0:07:40
epoch [111/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.6460 (0.3163) acc 84.3750 (92.6250) lr 8.5910e-04 eta 0:07:32
epoch [112/200] batch [5/51] time 0.087 (0.196) data 0.000 (0.108) loss 0.4148 (0.3187) acc 90.6250 (93.1250) lr 8.4357e-04 eta 0:14:46
epoch [112/200] batch [10/51] time 0.088 (0.141) data 0.000 (0.054) loss 0.2177 (0.2853) acc 96.8750 (93.4375) lr 8.4357e-04 eta 0:10:39
epoch [112/200] batch [15/51] time 0.086 (0.123) data 0.000 (0.036) loss 0.2920 (0.2576) acc 96.8750 (94.1667) lr 8.4357e-04 eta 0:09:15
epoch [112/200] batch [20/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.4465 (0.2821) acc 93.7500 (93.4375) lr 8.4357e-04 eta 0:08:34
epoch [112/200] batch [25/51] time 0.088 (0.108) data 0.000 (0.022) loss 0.2827 (0.2793) acc 96.8750 (93.8750) lr 8.4357e-04 eta 0:08:09
epoch [112/200] batch [30/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.2551 (0.2763) acc 93.7500 (93.8542) lr 8.4357e-04 eta 0:07:52
epoch [112/200] batch [35/51] time 0.087 (0.102) data 0.000 (0.016) loss 0.2620 (0.2929) acc 93.7500 (93.2143) lr 8.4357e-04 eta 0:07:40
epoch [112/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1711 (0.3047) acc 96.8750 (92.7344) lr 8.4357e-04 eta 0:07:31
epoch [112/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2502 (0.2963) acc 93.7500 (92.7778) lr 8.4357e-04 eta 0:07:24
epoch [112/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.4692 (0.2982) acc 87.5000 (92.8125) lr 8.4357e-04 eta 0:07:17
epoch [113/200] batch [5/51] time 0.087 (0.220) data 0.000 (0.132) loss 0.2803 (0.2741) acc 90.6250 (93.1250) lr 8.2807e-04 eta 0:16:25
epoch [113/200] batch [10/51] time 0.086 (0.153) data 0.000 (0.066) loss 0.6416 (0.3175) acc 84.3750 (92.8125) lr 8.2807e-04 eta 0:11:26
epoch [113/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.2365 (0.2970) acc 96.8750 (93.5417) lr 8.2807e-04 eta 0:09:46
epoch [113/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.4077 (0.3098) acc 90.6250 (92.8125) lr 8.2807e-04 eta 0:08:56
epoch [113/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.027) loss 0.1385 (0.2930) acc 100.0000 (93.3750) lr 8.2807e-04 eta 0:08:25
epoch [113/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.3621 (0.2924) acc 84.3750 (93.2292) lr 8.2807e-04 eta 0:08:05
epoch [113/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2615 (0.2827) acc 93.7500 (93.5714) lr 8.2807e-04 eta 0:07:51
epoch [113/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.4011 (0.2838) acc 87.5000 (93.2031) lr 8.2807e-04 eta 0:07:39
epoch [113/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1691 (0.2804) acc 93.7500 (93.2639) lr 8.2807e-04 eta 0:07:30
epoch [113/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3301 (0.2786) acc 93.7500 (93.3125) lr 8.2807e-04 eta 0:07:23
epoch [114/200] batch [5/51] time 0.088 (0.217) data 0.000 (0.129) loss 0.4697 (0.3157) acc 84.3750 (90.6250) lr 8.1262e-04 eta 0:16:02
epoch [114/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.1102 (0.2500) acc 100.0000 (93.4375) lr 8.1262e-04 eta 0:11:13
epoch [114/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.043) loss 0.1754 (0.2617) acc 93.7500 (93.7500) lr 8.1262e-04 eta 0:09:37
epoch [114/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3237 (0.2864) acc 90.6250 (93.2812) lr 8.1262e-04 eta 0:08:48
epoch [114/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.1110 (0.2803) acc 96.8750 (93.1250) lr 8.1262e-04 eta 0:08:19
epoch [114/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2327 (0.2862) acc 90.6250 (92.7083) lr 8.1262e-04 eta 0:07:59
epoch [114/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.1376 (0.2773) acc 96.8750 (93.0357) lr 8.1262e-04 eta 0:07:44
epoch [114/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3481 (0.2938) acc 90.6250 (92.4219) lr 8.1262e-04 eta 0:07:33
epoch [114/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.2212 (0.2909) acc 96.8750 (92.2917) lr 8.1262e-04 eta 0:07:24
epoch [114/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4922 (0.2964) acc 84.3750 (92.3125) lr 8.1262e-04 eta 0:07:17
epoch [115/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.2202 (0.3058) acc 96.8750 (93.1250) lr 7.9721e-04 eta 0:14:41
epoch [115/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.4192 (0.2997) acc 87.5000 (92.8125) lr 7.9721e-04 eta 0:10:30
epoch [115/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.2085 (0.3192) acc 93.7500 (92.5000) lr 7.9721e-04 eta 0:09:06
epoch [115/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2693 (0.3155) acc 93.7500 (92.5000) lr 7.9721e-04 eta 0:08:23
epoch [115/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.2700 (0.3013) acc 93.7500 (92.5000) lr 7.9721e-04 eta 0:07:58
epoch [115/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3228 (0.3059) acc 87.5000 (92.1875) lr 7.9721e-04 eta 0:07:41
epoch [115/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.5029 (0.3013) acc 90.6250 (92.5000) lr 7.9721e-04 eta 0:07:28
epoch [115/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2551 (0.3038) acc 96.8750 (92.5781) lr 7.9721e-04 eta 0:07:19
epoch [115/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1868 (0.2918) acc 93.7500 (92.9861) lr 7.9721e-04 eta 0:07:11
epoch [115/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3140 (0.2994) acc 90.6250 (92.9375) lr 7.9721e-04 eta 0:07:04
epoch [116/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.112) loss 0.2803 (0.3335) acc 93.7500 (93.1250) lr 7.8186e-04 eta 0:14:28
epoch [116/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.2939 (0.3547) acc 96.8750 (93.1250) lr 7.8186e-04 eta 0:10:22
epoch [116/200] batch [15/51] time 0.088 (0.125) data 0.000 (0.037) loss 0.2156 (0.3349) acc 96.8750 (93.3333) lr 7.8186e-04 eta 0:09:00
epoch [116/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.028) loss 0.1244 (0.3081) acc 96.8750 (94.0625) lr 7.8186e-04 eta 0:08:18
epoch [116/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4448 (0.3131) acc 90.6250 (93.8750) lr 7.8186e-04 eta 0:07:54
epoch [116/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2710 (0.3091) acc 96.8750 (93.9583) lr 7.8186e-04 eta 0:07:36
epoch [116/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2036 (0.3004) acc 96.8750 (94.0179) lr 7.8186e-04 eta 0:07:24
epoch [116/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3530 (0.3068) acc 87.5000 (93.5938) lr 7.8186e-04 eta 0:07:15
epoch [116/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2605 (0.3056) acc 93.7500 (93.8194) lr 7.8186e-04 eta 0:07:07
epoch [116/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2842 (0.3073) acc 93.7500 (93.6875) lr 7.8186e-04 eta 0:07:00
epoch [117/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.117) loss 0.3145 (0.2745) acc 90.6250 (93.1250) lr 7.6655e-04 eta 0:14:38
epoch [117/200] batch [10/51] time 0.088 (0.146) data 0.000 (0.059) loss 0.5498 (0.3309) acc 93.7500 (93.4375) lr 7.6655e-04 eta 0:10:25
epoch [117/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.2612 (0.3064) acc 90.6250 (93.1250) lr 7.6655e-04 eta 0:09:00
epoch [117/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.029) loss 0.4070 (0.3054) acc 90.6250 (92.8125) lr 7.6655e-04 eta 0:08:17
epoch [117/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.2241 (0.2921) acc 96.8750 (93.2500) lr 7.6655e-04 eta 0:07:51
epoch [117/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2280 (0.2884) acc 93.7500 (93.3333) lr 7.6655e-04 eta 0:07:34
epoch [117/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.3401 (0.2957) acc 96.8750 (93.4821) lr 7.6655e-04 eta 0:07:22
epoch [117/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1943 (0.2926) acc 100.0000 (93.5938) lr 7.6655e-04 eta 0:07:12
epoch [117/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2225 (0.2894) acc 90.6250 (93.6111) lr 7.6655e-04 eta 0:07:04
epoch [117/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1689 (0.2877) acc 96.8750 (93.5000) lr 7.6655e-04 eta 0:06:58
epoch [118/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.112) loss 0.2607 (0.2523) acc 93.7500 (93.7500) lr 7.5131e-04 eta 0:14:07
epoch [118/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.3296 (0.2673) acc 96.8750 (93.4375) lr 7.5131e-04 eta 0:10:07
epoch [118/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.2367 (0.2514) acc 96.8750 (94.1667) lr 7.5131e-04 eta 0:08:46
epoch [118/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.1864 (0.2644) acc 96.8750 (93.4375) lr 7.5131e-04 eta 0:08:06
epoch [118/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5859 (0.2703) acc 84.3750 (93.6250) lr 7.5131e-04 eta 0:07:41
epoch [118/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1091 (0.2686) acc 100.0000 (93.7500) lr 7.5131e-04 eta 0:07:25
epoch [118/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.6050 (0.2916) acc 84.3750 (93.0357) lr 7.5131e-04 eta 0:07:13
epoch [118/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.7466 (0.2971) acc 87.5000 (93.1250) lr 7.5131e-04 eta 0:07:04
epoch [118/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2812 (0.2844) acc 96.8750 (93.6806) lr 7.5131e-04 eta 0:06:56
epoch [118/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2299 (0.2958) acc 93.7500 (93.5000) lr 7.5131e-04 eta 0:06:50
epoch [119/200] batch [5/51] time 0.089 (0.223) data 0.000 (0.135) loss 0.5605 (0.3510) acc 90.6250 (93.7500) lr 7.3613e-04 eta 0:15:31
epoch [119/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.067) loss 0.2615 (0.3107) acc 96.8750 (94.6875) lr 7.3613e-04 eta 0:10:47
epoch [119/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.045) loss 0.1384 (0.3059) acc 96.8750 (94.3750) lr 7.3613e-04 eta 0:09:12
epoch [119/200] batch [20/51] time 0.086 (0.121) data 0.000 (0.034) loss 0.3213 (0.2999) acc 93.7500 (94.2188) lr 7.3613e-04 eta 0:08:24
epoch [119/200] batch [25/51] time 0.088 (0.114) data 0.000 (0.027) loss 0.2042 (0.2772) acc 96.8750 (94.8750) lr 7.3613e-04 eta 0:07:54
epoch [119/200] batch [30/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.4910 (0.2937) acc 87.5000 (93.8542) lr 7.3613e-04 eta 0:07:34
epoch [119/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.3484 (0.2911) acc 87.5000 (93.6607) lr 7.3613e-04 eta 0:07:20
epoch [119/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3176 (0.2893) acc 93.7500 (93.7500) lr 7.3613e-04 eta 0:07:09
epoch [119/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3418 (0.2928) acc 93.7500 (93.4722) lr 7.3613e-04 eta 0:07:00
epoch [119/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.1696 (0.2963) acc 93.7500 (93.3750) lr 7.3613e-04 eta 0:06:53
epoch [120/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.116) loss 0.4956 (0.2885) acc 90.6250 (93.7500) lr 7.2101e-04 eta 0:14:05
epoch [120/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.2487 (0.2911) acc 93.7500 (93.1250) lr 7.2101e-04 eta 0:10:00
epoch [120/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.039) loss 0.1172 (0.2917) acc 96.8750 (93.5417) lr 7.2101e-04 eta 0:08:38
epoch [120/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.4963 (0.2976) acc 90.6250 (93.2812) lr 7.2101e-04 eta 0:07:58
epoch [120/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.2915 (0.2994) acc 90.6250 (93.1250) lr 7.2101e-04 eta 0:07:32
epoch [120/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.020) loss 0.1748 (0.2924) acc 100.0000 (93.3333) lr 7.2101e-04 eta 0:07:16
epoch [120/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3906 (0.3073) acc 93.7500 (92.9464) lr 7.2101e-04 eta 0:07:03
epoch [120/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4968 (0.3097) acc 93.7500 (93.2031) lr 7.2101e-04 eta 0:06:54
epoch [120/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.3862 (0.3015) acc 87.5000 (93.2639) lr 7.2101e-04 eta 0:06:46
epoch [120/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2097 (0.2965) acc 96.8750 (93.3125) lr 7.2101e-04 eta 0:06:40
epoch [121/200] batch [5/51] time 0.087 (0.199) data 0.000 (0.111) loss 0.4060 (0.2696) acc 90.6250 (94.3750) lr 7.0596e-04 eta 0:13:29
epoch [121/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.4138 (0.2597) acc 90.6250 (94.3750) lr 7.0596e-04 eta 0:09:40
epoch [121/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.1614 (0.2425) acc 96.8750 (95.0000) lr 7.0596e-04 eta 0:08:23
epoch [121/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.028) loss 0.2092 (0.2566) acc 93.7500 (94.2188) lr 7.0596e-04 eta 0:07:45
epoch [121/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1967 (0.2599) acc 96.8750 (93.8750) lr 7.0596e-04 eta 0:07:21
epoch [121/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.4241 (0.2726) acc 87.5000 (93.3333) lr 7.0596e-04 eta 0:07:06
epoch [121/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.3044 (0.2619) acc 93.7500 (93.7500) lr 7.0596e-04 eta 0:06:54
epoch [121/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2510 (0.2779) acc 96.8750 (93.5938) lr 7.0596e-04 eta 0:06:46
epoch [121/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3191 (0.2896) acc 90.6250 (93.4028) lr 7.0596e-04 eta 0:06:39
epoch [121/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3645 (0.2903) acc 87.5000 (93.1875) lr 7.0596e-04 eta 0:06:33
epoch [122/200] batch [5/51] time 0.086 (0.224) data 0.000 (0.137) loss 0.3198 (0.2926) acc 93.7500 (94.3750) lr 6.9098e-04 eta 0:14:59
epoch [122/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.069) loss 0.1471 (0.2879) acc 96.8750 (93.4375) lr 6.9098e-04 eta 0:10:24
epoch [122/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.2856 (0.2904) acc 93.7500 (93.5417) lr 6.9098e-04 eta 0:08:52
epoch [122/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.1830 (0.3014) acc 93.7500 (93.1250) lr 6.9098e-04 eta 0:08:05
epoch [122/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.4824 (0.3127) acc 87.5000 (92.7500) lr 6.9098e-04 eta 0:07:37
epoch [122/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3000 (0.3138) acc 93.7500 (92.8125) lr 6.9098e-04 eta 0:07:19
epoch [122/200] batch [35/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.1901 (0.3093) acc 96.8750 (92.9464) lr 6.9098e-04 eta 0:07:05
epoch [122/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.4045 (0.3049) acc 93.7500 (92.9688) lr 6.9098e-04 eta 0:06:55
epoch [122/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3647 (0.3034) acc 93.7500 (93.1944) lr 6.9098e-04 eta 0:06:46
epoch [122/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3750 (0.3012) acc 93.7500 (93.2500) lr 6.9098e-04 eta 0:06:39
epoch [123/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.111) loss 0.1692 (0.2513) acc 96.8750 (95.6250) lr 6.7608e-04 eta 0:13:07
epoch [123/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.2050 (0.2878) acc 100.0000 (94.3750) lr 6.7608e-04 eta 0:09:25
epoch [123/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.5259 (0.3039) acc 90.6250 (93.5417) lr 6.7608e-04 eta 0:08:10
epoch [123/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3220 (0.2986) acc 93.7500 (93.5938) lr 6.7608e-04 eta 0:07:34
epoch [123/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1537 (0.2986) acc 100.0000 (93.6250) lr 6.7608e-04 eta 0:07:11
epoch [123/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.4556 (0.3132) acc 90.6250 (93.0208) lr 6.7608e-04 eta 0:06:56
epoch [123/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4556 (0.3125) acc 87.5000 (92.8571) lr 6.7608e-04 eta 0:06:45
epoch [123/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2002 (0.3022) acc 93.7500 (92.9688) lr 6.7608e-04 eta 0:06:36
epoch [123/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.1753 (0.3007) acc 90.6250 (92.7778) lr 6.7608e-04 eta 0:06:29
epoch [123/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3650 (0.3062) acc 90.6250 (92.6250) lr 6.7608e-04 eta 0:06:23
epoch [124/200] batch [5/51] time 0.087 (0.225) data 0.000 (0.138) loss 0.3237 (0.2680) acc 93.7500 (93.7500) lr 6.6126e-04 eta 0:14:42
epoch [124/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.2986 (0.3339) acc 90.6250 (91.8750) lr 6.6126e-04 eta 0:10:10
epoch [124/200] batch [15/51] time 0.088 (0.133) data 0.000 (0.046) loss 0.1410 (0.3138) acc 100.0000 (93.1250) lr 6.6126e-04 eta 0:08:39
epoch [124/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.035) loss 0.2969 (0.2965) acc 93.7500 (93.7500) lr 6.6126e-04 eta 0:07:53
epoch [124/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.5757 (0.3056) acc 87.5000 (93.5000) lr 6.6126e-04 eta 0:07:26
epoch [124/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5220 (0.3128) acc 84.3750 (93.2292) lr 6.6126e-04 eta 0:07:07
epoch [124/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.020) loss 0.2233 (0.2965) acc 96.8750 (93.5714) lr 6.6126e-04 eta 0:06:54
epoch [124/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.4641 (0.2976) acc 87.5000 (93.2812) lr 6.6126e-04 eta 0:06:43
epoch [124/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5532 (0.3241) acc 90.6250 (92.5000) lr 6.6126e-04 eta 0:06:35
epoch [124/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.0953 (0.3270) acc 100.0000 (92.6250) lr 6.6126e-04 eta 0:06:28
epoch [125/200] batch [5/51] time 0.088 (0.213) data 0.001 (0.125) loss 0.8340 (0.4871) acc 84.3750 (90.0000) lr 6.4653e-04 eta 0:13:45
epoch [125/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.1962 (0.3857) acc 96.8750 (90.9375) lr 6.4653e-04 eta 0:09:41
epoch [125/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.3281 (0.3446) acc 96.8750 (92.2917) lr 6.4653e-04 eta 0:08:19
epoch [125/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.031) loss 0.2042 (0.3204) acc 96.8750 (92.8125) lr 6.4653e-04 eta 0:07:38
epoch [125/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.5166 (0.3223) acc 87.5000 (92.3750) lr 6.4653e-04 eta 0:07:13
epoch [125/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2379 (0.3061) acc 96.8750 (92.8125) lr 6.4653e-04 eta 0:06:56
epoch [125/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.3987 (0.3021) acc 90.6250 (93.0357) lr 6.4653e-04 eta 0:06:44
epoch [125/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3245 (0.3013) acc 93.7500 (92.9688) lr 6.4653e-04 eta 0:06:34
epoch [125/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4282 (0.2966) acc 87.5000 (93.1250) lr 6.4653e-04 eta 0:06:26
epoch [125/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2886 (0.2875) acc 90.6250 (93.4375) lr 6.4653e-04 eta 0:06:20
epoch [126/200] batch [5/51] time 0.087 (0.218) data 0.000 (0.131) loss 0.1488 (0.2736) acc 100.0000 (95.0000) lr 6.3188e-04 eta 0:13:50
epoch [126/200] batch [10/51] time 0.087 (0.152) data 0.000 (0.065) loss 0.2698 (0.2936) acc 93.7500 (93.7500) lr 6.3188e-04 eta 0:09:40
epoch [126/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.044) loss 0.5591 (0.2982) acc 87.5000 (93.1250) lr 6.3188e-04 eta 0:08:16
epoch [126/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.033) loss 0.2700 (0.3056) acc 93.7500 (92.9688) lr 6.3188e-04 eta 0:07:34
epoch [126/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2917 (0.3150) acc 90.6250 (92.8750) lr 6.3188e-04 eta 0:07:09
epoch [126/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.0926 (0.2866) acc 96.8750 (93.5417) lr 6.3188e-04 eta 0:06:51
epoch [126/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.019) loss 0.2435 (0.2838) acc 93.7500 (93.6607) lr 6.3188e-04 eta 0:06:39
epoch [126/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.2129 (0.2886) acc 93.7500 (93.5156) lr 6.3188e-04 eta 0:06:30
epoch [126/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1111 (0.2847) acc 96.8750 (93.4722) lr 6.3188e-04 eta 0:06:22
epoch [126/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2524 (0.2969) acc 93.7500 (93.0000) lr 6.3188e-04 eta 0:06:15
epoch [127/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.113) loss 0.2502 (0.2469) acc 96.8750 (93.1250) lr 6.1732e-04 eta 0:12:35
epoch [127/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.056) loss 0.4004 (0.2808) acc 87.5000 (91.8750) lr 6.1732e-04 eta 0:09:01
epoch [127/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.1963 (0.2729) acc 93.7500 (93.1250) lr 6.1732e-04 eta 0:07:50
epoch [127/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.3306 (0.2665) acc 93.7500 (93.5938) lr 6.1732e-04 eta 0:07:14
epoch [127/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1152 (0.2642) acc 96.8750 (93.3750) lr 6.1732e-04 eta 0:06:52
epoch [127/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.3342 (0.2758) acc 93.7500 (93.1250) lr 6.1732e-04 eta 0:06:37
epoch [127/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.016) loss 0.4875 (0.2872) acc 87.5000 (92.8571) lr 6.1732e-04 eta 0:06:26
epoch [127/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1808 (0.2992) acc 100.0000 (92.7344) lr 6.1732e-04 eta 0:06:18
epoch [127/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2172 (0.2883) acc 96.8750 (93.0556) lr 6.1732e-04 eta 0:06:11
epoch [127/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3418 (0.2900) acc 90.6250 (93.0625) lr 6.1732e-04 eta 0:06:05
epoch [128/200] batch [5/51] time 0.087 (0.220) data 0.000 (0.132) loss 0.4270 (0.3468) acc 84.3750 (90.6250) lr 6.0285e-04 eta 0:13:36
epoch [128/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.2208 (0.2965) acc 96.8750 (92.5000) lr 6.0285e-04 eta 0:09:28
epoch [128/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.2158 (0.2853) acc 93.7500 (92.5000) lr 6.0285e-04 eta 0:08:06
epoch [128/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.5356 (0.3020) acc 87.5000 (92.3438) lr 6.0285e-04 eta 0:07:24
epoch [128/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.027) loss 0.3040 (0.3046) acc 96.8750 (92.2500) lr 6.0285e-04 eta 0:06:58
epoch [128/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4021 (0.2960) acc 93.7500 (92.8125) lr 6.0285e-04 eta 0:06:41
epoch [128/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1179 (0.2933) acc 96.8750 (93.1250) lr 6.0285e-04 eta 0:06:29
epoch [128/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.017) loss 0.1671 (0.2954) acc 100.0000 (93.1250) lr 6.0285e-04 eta 0:06:19
epoch [128/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3418 (0.2947) acc 93.7500 (92.9861) lr 6.0285e-04 eta 0:06:12
epoch [128/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2273 (0.2912) acc 93.7500 (93.0625) lr 6.0285e-04 eta 0:06:06
epoch [129/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.125) loss 0.5259 (0.3165) acc 87.5000 (91.2500) lr 5.8849e-04 eta 0:12:56
epoch [129/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 0.2529 (0.3261) acc 93.7500 (91.5625) lr 5.8849e-04 eta 0:09:06
epoch [129/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.042) loss 0.2883 (0.3065) acc 90.6250 (92.0833) lr 5.8849e-04 eta 0:07:49
epoch [129/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.1797 (0.2798) acc 96.8750 (93.4375) lr 5.8849e-04 eta 0:07:09
epoch [129/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.1938 (0.3171) acc 93.7500 (93.0000) lr 5.8849e-04 eta 0:06:46
epoch [129/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.021) loss 0.4192 (0.3049) acc 90.6250 (93.4375) lr 5.8849e-04 eta 0:06:30
epoch [129/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.3521 (0.2943) acc 90.6250 (93.4821) lr 5.8849e-04 eta 0:06:19
epoch [129/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2373 (0.2925) acc 90.6250 (93.3594) lr 5.8849e-04 eta 0:06:10
epoch [129/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2240 (0.3010) acc 96.8750 (92.9861) lr 5.8849e-04 eta 0:06:03
epoch [129/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1813 (0.3023) acc 96.8750 (92.8750) lr 5.8849e-04 eta 0:05:57
epoch [130/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.116) loss 0.4099 (0.1987) acc 90.6250 (96.2500) lr 5.7422e-04 eta 0:12:15
epoch [130/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.3083 (0.2152) acc 93.7500 (94.6875) lr 5.7422e-04 eta 0:08:45
epoch [130/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.4563 (0.2249) acc 90.6250 (94.7917) lr 5.7422e-04 eta 0:07:34
epoch [130/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3511 (0.2648) acc 87.5000 (93.7500) lr 5.7422e-04 eta 0:06:58
epoch [130/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.6230 (0.2684) acc 78.1250 (93.3750) lr 5.7422e-04 eta 0:06:37
epoch [130/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.019) loss 0.1615 (0.2666) acc 96.8750 (93.5417) lr 5.7422e-04 eta 0:06:22
epoch [130/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.3630 (0.2656) acc 90.6250 (93.6607) lr 5.7422e-04 eta 0:06:12
epoch [130/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2820 (0.2702) acc 93.7500 (93.5938) lr 5.7422e-04 eta 0:06:03
epoch [130/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4380 (0.2785) acc 90.6250 (93.3333) lr 5.7422e-04 eta 0:05:57
epoch [130/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1182 (0.2752) acc 100.0000 (93.4375) lr 5.7422e-04 eta 0:05:51
epoch [131/200] batch [5/51] time 0.088 (0.208) data 0.000 (0.119) loss 0.2522 (0.2455) acc 93.7500 (94.3750) lr 5.6006e-04 eta 0:12:21
epoch [131/200] batch [10/51] time 0.088 (0.148) data 0.000 (0.060) loss 0.1714 (0.2479) acc 96.8750 (93.7500) lr 5.6006e-04 eta 0:08:45
epoch [131/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.4351 (0.2606) acc 93.7500 (93.9583) lr 5.6006e-04 eta 0:07:32
epoch [131/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2607 (0.2732) acc 90.6250 (93.5938) lr 5.6006e-04 eta 0:06:56
epoch [131/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.3730 (0.2778) acc 90.6250 (93.5000) lr 5.6006e-04 eta 0:06:34
epoch [131/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.5234 (0.2790) acc 90.6250 (93.6458) lr 5.6006e-04 eta 0:06:19
epoch [131/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2996 (0.2724) acc 96.8750 (93.8393) lr 5.6006e-04 eta 0:06:09
epoch [131/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2593 (0.2825) acc 90.6250 (93.5156) lr 5.6006e-04 eta 0:06:00
epoch [131/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1647 (0.2800) acc 100.0000 (93.5417) lr 5.6006e-04 eta 0:05:53
epoch [131/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2681 (0.2806) acc 90.6250 (93.5625) lr 5.6006e-04 eta 0:05:48
epoch [132/200] batch [5/51] time 0.087 (0.223) data 0.000 (0.136) loss 0.3086 (0.4281) acc 96.8750 (91.8750) lr 5.4601e-04 eta 0:13:03
epoch [132/200] batch [10/51] time 0.086 (0.155) data 0.000 (0.068) loss 0.1678 (0.3371) acc 100.0000 (93.7500) lr 5.4601e-04 eta 0:09:04
epoch [132/200] batch [15/51] time 0.086 (0.132) data 0.000 (0.046) loss 0.3469 (0.3603) acc 90.6250 (92.2917) lr 5.4601e-04 eta 0:07:43
epoch [132/200] batch [20/51] time 0.086 (0.121) data 0.000 (0.034) loss 0.3169 (0.3400) acc 90.6250 (92.5000) lr 5.4601e-04 eta 0:07:02
epoch [132/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.2661 (0.3225) acc 93.7500 (92.5000) lr 5.4601e-04 eta 0:06:38
epoch [132/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.3088 (0.3209) acc 93.7500 (92.2917) lr 5.4601e-04 eta 0:06:21
epoch [132/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.3730 (0.3105) acc 90.6250 (92.5000) lr 5.4601e-04 eta 0:06:09
epoch [132/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2131 (0.3140) acc 93.7500 (92.1875) lr 5.4601e-04 eta 0:06:00
epoch [132/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5327 (0.3055) acc 84.3750 (92.4306) lr 5.4601e-04 eta 0:05:53
epoch [132/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4907 (0.3097) acc 87.5000 (92.2500) lr 5.4601e-04 eta 0:05:47
epoch [133/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.115) loss 0.1986 (0.2169) acc 93.7500 (95.0000) lr 5.3207e-04 eta 0:11:43
epoch [133/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.1926 (0.2530) acc 96.8750 (93.7500) lr 5.3207e-04 eta 0:08:21
epoch [133/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.039) loss 0.5659 (0.2814) acc 84.3750 (93.3333) lr 5.3207e-04 eta 0:07:14
epoch [133/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.029) loss 0.5146 (0.2839) acc 90.6250 (93.2812) lr 5.3207e-04 eta 0:06:41
epoch [133/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.023) loss 0.2820 (0.2954) acc 90.6250 (93.1250) lr 5.3207e-04 eta 0:06:20
epoch [133/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.019) loss 0.3982 (0.2940) acc 90.6250 (93.2292) lr 5.3207e-04 eta 0:06:06
epoch [133/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.2255 (0.2937) acc 93.7500 (93.2143) lr 5.3207e-04 eta 0:05:56
epoch [133/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3086 (0.2888) acc 90.6250 (93.1250) lr 5.3207e-04 eta 0:05:48
epoch [133/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2883 (0.2901) acc 93.7500 (93.0556) lr 5.3207e-04 eta 0:05:42
epoch [133/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1372 (0.2943) acc 96.8750 (92.9375) lr 5.3207e-04 eta 0:05:36
epoch [134/200] batch [5/51] time 0.088 (0.210) data 0.000 (0.122) loss 0.1967 (0.2440) acc 100.0000 (95.0000) lr 5.1825e-04 eta 0:11:56
epoch [134/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.061) loss 0.2117 (0.2609) acc 96.8750 (93.4375) lr 5.1825e-04 eta 0:08:26
epoch [134/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.6313 (0.2867) acc 84.3750 (92.7083) lr 5.1825e-04 eta 0:07:15
epoch [134/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.0912 (0.2758) acc 100.0000 (93.2812) lr 5.1825e-04 eta 0:06:40
epoch [134/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.5303 (0.2925) acc 87.5000 (92.8750) lr 5.1825e-04 eta 0:06:18
epoch [134/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.5381 (0.2970) acc 84.3750 (92.6042) lr 5.1825e-04 eta 0:06:03
epoch [134/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.3958 (0.2975) acc 90.6250 (92.6786) lr 5.1825e-04 eta 0:05:53
epoch [134/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.7598 (0.2995) acc 87.5000 (92.8906) lr 5.1825e-04 eta 0:05:44
epoch [134/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2229 (0.2951) acc 93.7500 (92.8472) lr 5.1825e-04 eta 0:05:38
epoch [134/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4128 (0.2978) acc 84.3750 (92.8125) lr 5.1825e-04 eta 0:05:32
epoch [135/200] batch [5/51] time 0.087 (0.198) data 0.000 (0.110) loss 0.4158 (0.3380) acc 87.5000 (90.0000) lr 5.0454e-04 eta 0:11:06
epoch [135/200] batch [10/51] time 0.087 (0.143) data 0.000 (0.055) loss 0.4426 (0.3411) acc 90.6250 (90.6250) lr 5.0454e-04 eta 0:07:58
epoch [135/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.1320 (0.3082) acc 96.8750 (92.5000) lr 5.0454e-04 eta 0:06:56
epoch [135/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.5112 (0.3024) acc 81.2500 (92.5000) lr 5.0454e-04 eta 0:06:24
epoch [135/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4219 (0.3129) acc 87.5000 (92.1250) lr 5.0454e-04 eta 0:06:05
epoch [135/200] batch [30/51] time 0.088 (0.106) data 0.000 (0.019) loss 0.1780 (0.3113) acc 96.8750 (92.0833) lr 5.0454e-04 eta 0:05:52
epoch [135/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2693 (0.3193) acc 93.7500 (91.8750) lr 5.0454e-04 eta 0:05:43
epoch [135/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3247 (0.3185) acc 93.7500 (92.1094) lr 5.0454e-04 eta 0:05:35
epoch [135/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.2986 (0.3097) acc 93.7500 (92.3611) lr 5.0454e-04 eta 0:05:29
epoch [135/200] batch [50/51] time 0.085 (0.098) data 0.000 (0.011) loss 0.2079 (0.3053) acc 93.7500 (92.4375) lr 5.0454e-04 eta 0:05:24
epoch [136/200] batch [5/51] time 0.087 (0.238) data 0.000 (0.151) loss 0.1848 (0.2232) acc 93.7500 (93.7500) lr 4.9096e-04 eta 0:13:08
epoch [136/200] batch [10/51] time 0.086 (0.163) data 0.000 (0.076) loss 0.3440 (0.2934) acc 90.6250 (91.5625) lr 4.9096e-04 eta 0:08:57
epoch [136/200] batch [15/51] time 0.086 (0.137) data 0.000 (0.051) loss 0.3101 (0.2829) acc 96.8750 (92.5000) lr 4.9096e-04 eta 0:07:32
epoch [136/200] batch [20/51] time 0.086 (0.124) data 0.000 (0.038) loss 0.4001 (0.2847) acc 93.7500 (92.8125) lr 4.9096e-04 eta 0:06:49
epoch [136/200] batch [25/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2451 (0.2739) acc 93.7500 (93.2500) lr 4.9096e-04 eta 0:06:24
epoch [136/200] batch [30/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.2686 (0.2706) acc 90.6250 (93.2292) lr 4.9096e-04 eta 0:06:07
epoch [136/200] batch [35/51] time 0.086 (0.108) data 0.000 (0.022) loss 0.4204 (0.2783) acc 84.3750 (92.9464) lr 4.9096e-04 eta 0:05:54
epoch [136/200] batch [40/51] time 0.086 (0.105) data 0.000 (0.019) loss 0.3296 (0.2773) acc 93.7500 (93.0469) lr 4.9096e-04 eta 0:05:45
epoch [136/200] batch [45/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.1595 (0.2770) acc 100.0000 (93.1944) lr 4.9096e-04 eta 0:05:37
epoch [136/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4021 (0.2801) acc 90.6250 (93.1875) lr 4.9096e-04 eta 0:05:31
epoch [137/200] batch [5/51] time 0.086 (0.214) data 0.000 (0.126) loss 0.3191 (0.4021) acc 93.7500 (89.3750) lr 4.7750e-04 eta 0:11:36
epoch [137/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.063) loss 0.3318 (0.3589) acc 93.7500 (91.2500) lr 4.7750e-04 eta 0:08:09
epoch [137/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.1344 (0.3128) acc 100.0000 (92.2917) lr 4.7750e-04 eta 0:07:00
epoch [137/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.032) loss 0.2246 (0.2983) acc 93.7500 (92.8125) lr 4.7750e-04 eta 0:06:25
epoch [137/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.6465 (0.3171) acc 81.2500 (92.1250) lr 4.7750e-04 eta 0:06:04
epoch [137/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2773 (0.3047) acc 90.6250 (92.6042) lr 4.7750e-04 eta 0:05:49
epoch [137/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1395 (0.3025) acc 96.8750 (92.8571) lr 4.7750e-04 eta 0:05:39
epoch [137/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.4761 (0.2960) acc 90.6250 (92.9688) lr 4.7750e-04 eta 0:05:31
epoch [137/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2808 (0.2957) acc 96.8750 (92.9167) lr 4.7750e-04 eta 0:05:25
epoch [137/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3682 (0.2912) acc 96.8750 (93.1250) lr 4.7750e-04 eta 0:05:19
epoch [138/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.123) loss 0.3982 (0.3144) acc 84.3750 (92.5000) lr 4.6417e-04 eta 0:11:16
epoch [138/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 0.1063 (0.2630) acc 100.0000 (93.4375) lr 4.6417e-04 eta 0:07:56
epoch [138/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.3574 (0.2621) acc 90.6250 (93.9583) lr 4.6417e-04 eta 0:06:48
epoch [138/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.1444 (0.2439) acc 93.7500 (94.2188) lr 4.6417e-04 eta 0:06:15
epoch [138/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.025) loss 0.5825 (0.2920) acc 87.5000 (93.1250) lr 4.6417e-04 eta 0:05:54
epoch [138/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.1786 (0.2915) acc 96.8750 (93.3333) lr 4.6417e-04 eta 0:05:41
epoch [138/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.2258 (0.2945) acc 93.7500 (93.1250) lr 4.6417e-04 eta 0:05:31
epoch [138/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.1012 (0.2917) acc 100.0000 (93.2031) lr 4.6417e-04 eta 0:05:23
epoch [138/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.5693 (0.2975) acc 87.5000 (93.1944) lr 4.6417e-04 eta 0:05:17
epoch [138/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1722 (0.2879) acc 96.8750 (93.4375) lr 4.6417e-04 eta 0:05:12
epoch [139/200] batch [5/51] time 0.087 (0.203) data 0.000 (0.115) loss 0.2510 (0.3328) acc 90.6250 (91.2500) lr 4.5098e-04 eta 0:10:39
epoch [139/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.2727 (0.2966) acc 93.7500 (92.1875) lr 4.5098e-04 eta 0:07:36
epoch [139/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.1794 (0.2741) acc 96.8750 (93.5417) lr 4.5098e-04 eta 0:06:34
epoch [139/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.4209 (0.2620) acc 90.6250 (94.0625) lr 4.5098e-04 eta 0:06:04
epoch [139/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5273 (0.2718) acc 90.6250 (93.6250) lr 4.5098e-04 eta 0:05:45
epoch [139/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2578 (0.2705) acc 93.7500 (93.6458) lr 4.5098e-04 eta 0:05:33
epoch [139/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.0998 (0.2684) acc 96.8750 (93.4821) lr 4.5098e-04 eta 0:05:24
epoch [139/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.5615 (0.2794) acc 84.3750 (93.1250) lr 4.5098e-04 eta 0:05:16
epoch [139/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3665 (0.2986) acc 90.6250 (92.6389) lr 4.5098e-04 eta 0:05:10
epoch [139/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3696 (0.3050) acc 87.5000 (92.4375) lr 4.5098e-04 eta 0:05:06
epoch [140/200] batch [5/51] time 0.088 (0.199) data 0.000 (0.112) loss 0.2864 (0.3404) acc 93.7500 (90.0000) lr 4.3792e-04 eta 0:10:18
epoch [140/200] batch [10/51] time 0.086 (0.143) data 0.000 (0.056) loss 0.2152 (0.2825) acc 90.6250 (91.8750) lr 4.3792e-04 eta 0:07:23
epoch [140/200] batch [15/51] time 0.087 (0.124) data 0.000 (0.037) loss 0.2214 (0.2750) acc 96.8750 (93.1250) lr 4.3792e-04 eta 0:06:24
epoch [140/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2181 (0.3018) acc 93.7500 (92.8125) lr 4.3792e-04 eta 0:05:54
epoch [140/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.4592 (0.3013) acc 87.5000 (92.8750) lr 4.3792e-04 eta 0:05:37
epoch [140/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4268 (0.2967) acc 87.5000 (93.0208) lr 4.3792e-04 eta 0:05:25
epoch [140/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2336 (0.2939) acc 93.7500 (93.0357) lr 4.3792e-04 eta 0:05:16
epoch [140/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1982 (0.2931) acc 96.8750 (92.8906) lr 4.3792e-04 eta 0:05:09
epoch [140/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2852 (0.2885) acc 96.8750 (93.2639) lr 4.3792e-04 eta 0:05:03
epoch [140/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.2435 (0.2782) acc 93.7500 (93.5625) lr 4.3792e-04 eta 0:04:59
epoch [141/200] batch [5/51] time 0.088 (0.223) data 0.000 (0.135) loss 0.2769 (0.2906) acc 93.7500 (92.5000) lr 4.2499e-04 eta 0:11:22
epoch [141/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.2284 (0.2739) acc 96.8750 (93.4375) lr 4.2499e-04 eta 0:07:53
epoch [141/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.045) loss 0.3374 (0.2955) acc 90.6250 (92.7083) lr 4.2499e-04 eta 0:06:43
epoch [141/200] batch [20/51] time 0.088 (0.121) data 0.000 (0.034) loss 0.2998 (0.2764) acc 90.6250 (93.2812) lr 4.2499e-04 eta 0:06:08
epoch [141/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.2244 (0.2649) acc 93.7500 (93.6250) lr 4.2499e-04 eta 0:05:46
epoch [141/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1716 (0.2717) acc 96.8750 (93.3333) lr 4.2499e-04 eta 0:05:32
epoch [141/200] batch [35/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.1427 (0.2708) acc 96.8750 (93.3036) lr 4.2499e-04 eta 0:05:22
epoch [141/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1605 (0.2744) acc 96.8750 (93.4375) lr 4.2499e-04 eta 0:05:14
epoch [141/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.5283 (0.2770) acc 87.5000 (93.3333) lr 4.2499e-04 eta 0:05:07
epoch [141/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3435 (0.2813) acc 93.7500 (93.1875) lr 4.2499e-04 eta 0:05:02
epoch [142/200] batch [5/51] time 0.088 (0.198) data 0.000 (0.110) loss 0.2080 (0.2565) acc 96.8750 (94.3750) lr 4.1221e-04 eta 0:09:53
epoch [142/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.3525 (0.2848) acc 93.7500 (93.7500) lr 4.1221e-04 eta 0:07:06
epoch [142/200] batch [15/51] time 0.086 (0.124) data 0.000 (0.037) loss 0.1742 (0.2562) acc 96.8750 (94.7917) lr 4.1221e-04 eta 0:06:10
epoch [142/200] batch [20/51] time 0.086 (0.115) data 0.000 (0.028) loss 0.3259 (0.2833) acc 90.6250 (93.7500) lr 4.1221e-04 eta 0:05:42
epoch [142/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4404 (0.2839) acc 90.6250 (93.7500) lr 4.1221e-04 eta 0:05:25
epoch [142/200] batch [30/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1427 (0.2950) acc 100.0000 (93.4375) lr 4.1221e-04 eta 0:05:13
epoch [142/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3901 (0.2966) acc 90.6250 (93.4821) lr 4.1221e-04 eta 0:05:05
epoch [142/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.3486 (0.2969) acc 87.5000 (93.4375) lr 4.1221e-04 eta 0:04:58
epoch [142/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.1952 (0.2973) acc 93.7500 (93.3333) lr 4.1221e-04 eta 0:04:53
epoch [142/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3171 (0.2936) acc 93.7500 (93.4375) lr 4.1221e-04 eta 0:04:48
epoch [143/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.134) loss 0.2161 (0.3254) acc 93.7500 (91.2500) lr 3.9958e-04 eta 0:10:55
epoch [143/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.067) loss 0.3330 (0.2930) acc 93.7500 (93.4375) lr 3.9958e-04 eta 0:07:36
epoch [143/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.1587 (0.2508) acc 100.0000 (94.5833) lr 3.9958e-04 eta 0:06:28
epoch [143/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.2341 (0.2438) acc 96.8750 (95.0000) lr 3.9958e-04 eta 0:05:54
epoch [143/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.1510 (0.2500) acc 96.8750 (94.2500) lr 3.9958e-04 eta 0:05:34
epoch [143/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.0777 (0.2431) acc 100.0000 (94.5833) lr 3.9958e-04 eta 0:05:20
epoch [143/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1562 (0.2495) acc 96.8750 (94.4643) lr 3.9958e-04 eta 0:05:10
epoch [143/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.1750 (0.2569) acc 96.8750 (94.2188) lr 3.9958e-04 eta 0:05:03
epoch [143/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1346 (0.2634) acc 100.0000 (94.0278) lr 3.9958e-04 eta 0:04:56
epoch [143/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4678 (0.2642) acc 93.7500 (94.1875) lr 3.9958e-04 eta 0:04:51
epoch [144/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.124) loss 0.1593 (0.2346) acc 100.0000 (95.6250) lr 3.8709e-04 eta 0:10:17
epoch [144/200] batch [10/51] time 0.088 (0.150) data 0.000 (0.062) loss 0.2133 (0.2235) acc 93.7500 (95.0000) lr 3.8709e-04 eta 0:07:15
epoch [144/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.6470 (0.2803) acc 84.3750 (93.7500) lr 3.8709e-04 eta 0:06:13
epoch [144/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.2416 (0.2983) acc 96.8750 (93.5938) lr 3.8709e-04 eta 0:05:42
epoch [144/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.4805 (0.2920) acc 84.3750 (93.5000) lr 3.8709e-04 eta 0:05:22
epoch [144/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.021) loss 0.2147 (0.2926) acc 96.8750 (93.4375) lr 3.8709e-04 eta 0:05:09
epoch [144/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.0965 (0.2834) acc 100.0000 (93.8393) lr 3.8709e-04 eta 0:05:00
epoch [144/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.0895 (0.2897) acc 96.8750 (93.6719) lr 3.8709e-04 eta 0:04:53
epoch [144/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5986 (0.2988) acc 87.5000 (93.4028) lr 3.8709e-04 eta 0:04:47
epoch [144/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.4880 (0.3147) acc 87.5000 (92.5625) lr 3.8709e-04 eta 0:04:42
epoch [145/200] batch [5/51] time 0.087 (0.208) data 0.000 (0.120) loss 0.2578 (0.2232) acc 93.7500 (97.5000) lr 3.7476e-04 eta 0:09:53
epoch [145/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.4702 (0.2413) acc 87.5000 (95.6250) lr 3.7476e-04 eta 0:07:01
epoch [145/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.040) loss 0.2274 (0.2326) acc 96.8750 (95.4167) lr 3.7476e-04 eta 0:06:02
epoch [145/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.030) loss 0.2637 (0.2530) acc 87.5000 (94.2188) lr 3.7476e-04 eta 0:05:33
epoch [145/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1115 (0.2572) acc 96.8750 (94.1250) lr 3.7476e-04 eta 0:05:15
epoch [145/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.0768 (0.2573) acc 100.0000 (94.1667) lr 3.7476e-04 eta 0:05:03
epoch [145/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2144 (0.2573) acc 96.8750 (94.1964) lr 3.7476e-04 eta 0:04:54
epoch [145/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1946 (0.2548) acc 96.8750 (94.3750) lr 3.7476e-04 eta 0:04:47
epoch [145/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2068 (0.2661) acc 96.8750 (93.8889) lr 3.7476e-04 eta 0:04:42
epoch [145/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2773 (0.2715) acc 96.8750 (93.6875) lr 3.7476e-04 eta 0:04:37
epoch [146/200] batch [5/51] time 0.087 (0.204) data 0.000 (0.116) loss 0.2223 (0.2423) acc 93.7500 (93.7500) lr 3.6258e-04 eta 0:09:30
epoch [146/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.2632 (0.2449) acc 90.6250 (93.7500) lr 3.6258e-04 eta 0:06:45
epoch [146/200] batch [15/51] time 0.086 (0.126) data 0.000 (0.039) loss 0.1414 (0.2517) acc 93.7500 (93.5417) lr 3.6258e-04 eta 0:05:51
epoch [146/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3186 (0.2467) acc 90.6250 (94.3750) lr 3.6258e-04 eta 0:05:23
epoch [146/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4243 (0.2434) acc 90.6250 (94.5000) lr 3.6258e-04 eta 0:05:06
epoch [146/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.4651 (0.2632) acc 93.7500 (94.0625) lr 3.6258e-04 eta 0:04:55
epoch [146/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2212 (0.2586) acc 93.7500 (94.1071) lr 3.6258e-04 eta 0:04:47
epoch [146/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3811 (0.2812) acc 90.6250 (93.3594) lr 3.6258e-04 eta 0:04:40
epoch [146/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2664 (0.2775) acc 96.8750 (93.4722) lr 3.6258e-04 eta 0:04:35
epoch [146/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.4553 (0.2813) acc 84.3750 (93.3750) lr 3.6258e-04 eta 0:04:31
epoch [147/200] batch [5/51] time 0.087 (0.228) data 0.000 (0.140) loss 0.3284 (0.2970) acc 96.8750 (93.1250) lr 3.5055e-04 eta 0:10:26
epoch [147/200] batch [10/51] time 0.087 (0.158) data 0.000 (0.070) loss 0.2954 (0.2473) acc 90.6250 (94.6875) lr 3.5055e-04 eta 0:07:13
epoch [147/200] batch [15/51] time 0.087 (0.134) data 0.000 (0.047) loss 0.1779 (0.2759) acc 93.7500 (93.7500) lr 3.5055e-04 eta 0:06:08
epoch [147/200] batch [20/51] time 0.087 (0.123) data 0.000 (0.035) loss 0.3044 (0.3103) acc 90.6250 (92.5000) lr 3.5055e-04 eta 0:05:35
epoch [147/200] batch [25/51] time 0.087 (0.116) data 0.000 (0.028) loss 0.4124 (0.2896) acc 90.6250 (93.1250) lr 3.5055e-04 eta 0:05:15
epoch [147/200] batch [30/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1843 (0.2897) acc 93.7500 (92.8125) lr 3.5055e-04 eta 0:05:02
epoch [147/200] batch [35/51] time 0.087 (0.108) data 0.000 (0.020) loss 0.2976 (0.2852) acc 90.6250 (93.0357) lr 3.5055e-04 eta 0:04:52
epoch [147/200] batch [40/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.6274 (0.2840) acc 81.2500 (93.1250) lr 3.5055e-04 eta 0:04:45
epoch [147/200] batch [45/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3137 (0.2835) acc 93.7500 (93.2639) lr 3.5055e-04 eta 0:04:38
epoch [147/200] batch [50/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1688 (0.2828) acc 100.0000 (93.3125) lr 3.5055e-04 eta 0:04:33
epoch [148/200] batch [5/51] time 0.088 (0.206) data 0.000 (0.117) loss 0.3301 (0.2469) acc 96.8750 (96.8750) lr 3.3869e-04 eta 0:09:14
epoch [148/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.059) loss 0.2437 (0.2483) acc 93.7500 (95.3125) lr 3.3869e-04 eta 0:06:34
epoch [148/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.039) loss 0.2013 (0.2892) acc 93.7500 (94.7917) lr 3.3869e-04 eta 0:05:40
epoch [148/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.029) loss 0.3250 (0.2716) acc 90.6250 (94.6875) lr 3.3869e-04 eta 0:05:13
epoch [148/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.3604 (0.2928) acc 90.6250 (93.6250) lr 3.3869e-04 eta 0:04:56
epoch [148/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3113 (0.3075) acc 87.5000 (93.0208) lr 3.3869e-04 eta 0:04:45
epoch [148/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2145 (0.2979) acc 93.7500 (93.2143) lr 3.3869e-04 eta 0:04:37
epoch [148/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.4060 (0.2960) acc 90.6250 (93.4375) lr 3.3869e-04 eta 0:04:30
epoch [148/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3325 (0.2877) acc 90.6250 (93.6111) lr 3.3869e-04 eta 0:04:25
epoch [148/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2571 (0.2967) acc 93.7500 (93.5000) lr 3.3869e-04 eta 0:04:21
epoch [149/200] batch [5/51] time 0.087 (0.212) data 0.000 (0.125) loss 0.2046 (0.2483) acc 96.8750 (95.0000) lr 3.2699e-04 eta 0:09:20
epoch [149/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 0.3403 (0.2783) acc 96.8750 (93.7500) lr 3.2699e-04 eta 0:06:33
epoch [149/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.042) loss 0.3738 (0.2697) acc 90.6250 (93.7500) lr 3.2699e-04 eta 0:05:38
epoch [149/200] batch [20/51] time 0.089 (0.118) data 0.000 (0.031) loss 0.2030 (0.2647) acc 96.8750 (93.9062) lr 3.2699e-04 eta 0:05:10
epoch [149/200] batch [25/51] time 0.085 (0.112) data 0.000 (0.025) loss 0.1409 (0.2632) acc 96.8750 (93.8750) lr 3.2699e-04 eta 0:04:52
epoch [149/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.021) loss 0.1350 (0.2603) acc 96.8750 (93.8542) lr 3.2699e-04 eta 0:04:41
epoch [149/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.018) loss 0.5244 (0.2744) acc 90.6250 (93.7500) lr 3.2699e-04 eta 0:04:33
epoch [149/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.3413 (0.2789) acc 90.6250 (93.5938) lr 3.2699e-04 eta 0:04:26
epoch [149/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2246 (0.2823) acc 96.8750 (93.4722) lr 3.2699e-04 eta 0:04:21
epoch [149/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2593 (0.2743) acc 90.6250 (93.5625) lr 3.2699e-04 eta 0:04:17
epoch [150/200] batch [5/51] time 0.087 (0.202) data 0.000 (0.114) loss 0.0920 (0.1997) acc 100.0000 (95.6250) lr 3.1545e-04 eta 0:08:43
epoch [150/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.057) loss 0.2092 (0.2088) acc 100.0000 (96.2500) lr 3.1545e-04 eta 0:06:14
epoch [150/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.4380 (0.2319) acc 81.2500 (94.7917) lr 3.1545e-04 eta 0:05:24
epoch [150/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.1774 (0.2530) acc 96.8750 (94.6875) lr 3.1545e-04 eta 0:04:58
epoch [150/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2568 (0.2662) acc 93.7500 (94.5000) lr 3.1545e-04 eta 0:04:43
epoch [150/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.1263 (0.2567) acc 96.8750 (94.5833) lr 3.1545e-04 eta 0:04:32
epoch [150/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.2023 (0.2580) acc 93.7500 (94.4643) lr 3.1545e-04 eta 0:04:25
epoch [150/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4556 (0.2662) acc 87.5000 (94.1406) lr 3.1545e-04 eta 0:04:19
epoch [150/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1710 (0.2595) acc 96.8750 (94.3056) lr 3.1545e-04 eta 0:04:14
epoch [150/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1359 (0.2523) acc 100.0000 (94.5625) lr 3.1545e-04 eta 0:04:10
epoch [151/200] batch [5/51] time 0.088 (0.207) data 0.000 (0.118) loss 0.2230 (0.2778) acc 96.8750 (93.7500) lr 3.0409e-04 eta 0:08:45
epoch [151/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.3508 (0.3201) acc 93.7500 (93.1250) lr 3.0409e-04 eta 0:06:12
epoch [151/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.2463 (0.2807) acc 93.7500 (94.3750) lr 3.0409e-04 eta 0:05:21
epoch [151/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.030) loss 0.1335 (0.2884) acc 96.8750 (93.9062) lr 3.0409e-04 eta 0:04:56
epoch [151/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.024) loss 0.4805 (0.2936) acc 87.5000 (93.7500) lr 3.0409e-04 eta 0:04:40
epoch [151/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.5361 (0.3170) acc 81.2500 (92.9167) lr 3.0409e-04 eta 0:04:29
epoch [151/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.3970 (0.3214) acc 90.6250 (92.5000) lr 3.0409e-04 eta 0:04:22
epoch [151/200] batch [40/51] time 0.087 (0.102) data 0.000 (0.015) loss 0.3218 (0.3090) acc 90.6250 (92.6562) lr 3.0409e-04 eta 0:04:16
epoch [151/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1766 (0.3079) acc 96.8750 (92.7083) lr 3.0409e-04 eta 0:04:11
epoch [151/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1660 (0.2995) acc 96.8750 (92.8750) lr 3.0409e-04 eta 0:04:07
epoch [152/200] batch [5/51] time 0.088 (0.212) data 0.000 (0.124) loss 0.5298 (0.3077) acc 87.5000 (91.8750) lr 2.9289e-04 eta 0:08:48
epoch [152/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 0.3220 (0.3285) acc 93.7500 (92.5000) lr 2.9289e-04 eta 0:06:11
epoch [152/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.3857 (0.3296) acc 90.6250 (92.7083) lr 2.9289e-04 eta 0:05:18
epoch [152/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.1683 (0.3080) acc 93.7500 (92.9688) lr 2.9289e-04 eta 0:04:52
epoch [152/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.0803 (0.2907) acc 100.0000 (94.0000) lr 2.9289e-04 eta 0:04:36
epoch [152/200] batch [30/51] time 0.086 (0.108) data 0.000 (0.021) loss 0.3230 (0.2876) acc 90.6250 (93.9583) lr 2.9289e-04 eta 0:04:25
epoch [152/200] batch [35/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.1395 (0.2856) acc 93.7500 (93.7500) lr 2.9289e-04 eta 0:04:17
epoch [152/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.1444 (0.2907) acc 100.0000 (93.2812) lr 2.9289e-04 eta 0:04:11
epoch [152/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.1930 (0.2871) acc 96.8750 (93.5417) lr 2.9289e-04 eta 0:04:06
epoch [152/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.2445 (0.2945) acc 96.8750 (93.2500) lr 2.9289e-04 eta 0:04:02
epoch [153/200] batch [5/51] time 0.087 (0.207) data 0.000 (0.120) loss 0.3467 (0.3125) acc 90.6250 (91.8750) lr 2.8187e-04 eta 0:08:26
epoch [153/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.1053 (0.3005) acc 100.0000 (93.4375) lr 2.8187e-04 eta 0:05:59
epoch [153/200] batch [15/51] time 0.088 (0.127) data 0.000 (0.040) loss 0.2487 (0.3002) acc 96.8750 (93.3333) lr 2.8187e-04 eta 0:05:09
epoch [153/200] batch [20/51] time 0.086 (0.117) data 0.000 (0.030) loss 0.4727 (0.2902) acc 84.3750 (93.1250) lr 2.8187e-04 eta 0:04:44
epoch [153/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.6440 (0.3019) acc 84.3750 (93.0000) lr 2.8187e-04 eta 0:04:29
epoch [153/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1581 (0.3066) acc 93.7500 (92.2917) lr 2.8187e-04 eta 0:04:18
epoch [153/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.4712 (0.3103) acc 87.5000 (92.4107) lr 2.8187e-04 eta 0:04:11
epoch [153/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3708 (0.3184) acc 90.6250 (92.1094) lr 2.8187e-04 eta 0:04:05
epoch [153/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.4780 (0.3159) acc 87.5000 (92.3611) lr 2.8187e-04 eta 0:04:00
epoch [153/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1482 (0.3198) acc 96.8750 (92.3750) lr 2.8187e-04 eta 0:03:56
epoch [154/200] batch [5/51] time 0.087 (0.201) data 0.000 (0.113) loss 0.3674 (0.2580) acc 87.5000 (93.7500) lr 2.7103e-04 eta 0:08:01
epoch [154/200] batch [10/51] time 0.086 (0.144) data 0.000 (0.056) loss 0.5273 (0.3308) acc 87.5000 (91.5625) lr 2.7103e-04 eta 0:05:43
epoch [154/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.1600 (0.3331) acc 100.0000 (91.4583) lr 2.7103e-04 eta 0:04:57
epoch [154/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.1246 (0.2958) acc 96.8750 (92.5000) lr 2.7103e-04 eta 0:04:34
epoch [154/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1323 (0.2763) acc 93.7500 (93.1250) lr 2.7103e-04 eta 0:04:20
epoch [154/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2466 (0.2855) acc 96.8750 (93.1250) lr 2.7103e-04 eta 0:04:10
epoch [154/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1099 (0.2766) acc 96.8750 (93.3929) lr 2.7103e-04 eta 0:04:03
epoch [154/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2104 (0.2694) acc 93.7500 (93.3594) lr 2.7103e-04 eta 0:03:58
epoch [154/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1641 (0.2698) acc 100.0000 (93.4028) lr 2.7103e-04 eta 0:03:53
epoch [154/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.1245 (0.2646) acc 100.0000 (93.6875) lr 2.7103e-04 eta 0:03:50
epoch [155/200] batch [5/51] time 0.086 (0.204) data 0.000 (0.117) loss 0.1132 (0.2055) acc 96.8750 (95.6250) lr 2.6037e-04 eta 0:07:57
epoch [155/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.2783 (0.2611) acc 93.7500 (93.7500) lr 2.6037e-04 eta 0:05:39
epoch [155/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.3406 (0.3103) acc 93.7500 (93.1250) lr 2.6037e-04 eta 0:04:53
epoch [155/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.3450 (0.2963) acc 87.5000 (92.9688) lr 2.6037e-04 eta 0:04:30
epoch [155/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.024) loss 0.2698 (0.2845) acc 93.7500 (93.1250) lr 2.6037e-04 eta 0:04:15
epoch [155/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.1262 (0.2998) acc 96.8750 (92.8125) lr 2.6037e-04 eta 0:04:06
epoch [155/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.3201 (0.2957) acc 87.5000 (93.1250) lr 2.6037e-04 eta 0:03:59
epoch [155/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3237 (0.2979) acc 90.6250 (93.1250) lr 2.6037e-04 eta 0:03:53
epoch [155/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4077 (0.3059) acc 90.6250 (92.9167) lr 2.6037e-04 eta 0:03:49
epoch [155/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1287 (0.3060) acc 93.7500 (92.8125) lr 2.6037e-04 eta 0:03:45
epoch [156/200] batch [5/51] time 0.087 (0.222) data 0.000 (0.135) loss 0.0512 (0.1344) acc 100.0000 (98.1250) lr 2.4989e-04 eta 0:08:28
epoch [156/200] batch [10/51] time 0.086 (0.155) data 0.000 (0.068) loss 0.4465 (0.2017) acc 87.5000 (95.6250) lr 2.4989e-04 eta 0:05:53
epoch [156/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.3711 (0.2436) acc 90.6250 (94.1667) lr 2.4989e-04 eta 0:05:00
epoch [156/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.5635 (0.2619) acc 84.3750 (93.7500) lr 2.4989e-04 eta 0:04:34
epoch [156/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.027) loss 0.2156 (0.2784) acc 93.7500 (93.2500) lr 2.4989e-04 eta 0:04:18
epoch [156/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.023) loss 0.3562 (0.2858) acc 90.6250 (93.1250) lr 2.4989e-04 eta 0:04:07
epoch [156/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.3245 (0.2731) acc 90.6250 (93.6607) lr 2.4989e-04 eta 0:03:59
epoch [156/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.4556 (0.2834) acc 87.5000 (93.4375) lr 2.4989e-04 eta 0:03:53
epoch [156/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3955 (0.2787) acc 87.5000 (93.4722) lr 2.4989e-04 eta 0:03:48
epoch [156/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2603 (0.2765) acc 96.8750 (93.5000) lr 2.4989e-04 eta 0:03:44
epoch [157/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.1880 (0.3380) acc 93.7500 (91.2500) lr 2.3959e-04 eta 0:07:29
epoch [157/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.3289 (0.3099) acc 90.6250 (92.8125) lr 2.3959e-04 eta 0:05:21
epoch [157/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.2415 (0.2669) acc 93.7500 (93.9583) lr 2.3959e-04 eta 0:04:38
epoch [157/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3813 (0.2958) acc 93.7500 (93.4375) lr 2.3959e-04 eta 0:04:16
epoch [157/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4639 (0.2872) acc 90.6250 (93.7500) lr 2.3959e-04 eta 0:04:03
epoch [157/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.1404 (0.2770) acc 93.7500 (94.0625) lr 2.3959e-04 eta 0:03:54
epoch [157/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.3311 (0.2837) acc 90.6250 (93.6607) lr 2.3959e-04 eta 0:03:47
epoch [157/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1650 (0.2745) acc 96.8750 (93.9844) lr 2.3959e-04 eta 0:03:42
epoch [157/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.2712 (0.2743) acc 93.7500 (93.8194) lr 2.3959e-04 eta 0:03:38
epoch [157/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.3108 (0.2764) acc 93.7500 (93.6250) lr 2.3959e-04 eta 0:03:34
epoch [158/200] batch [5/51] time 0.087 (0.200) data 0.000 (0.113) loss 0.4072 (0.2826) acc 87.5000 (92.5000) lr 2.2949e-04 eta 0:07:18
epoch [158/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.3196 (0.2552) acc 90.6250 (93.4375) lr 2.2949e-04 eta 0:05:13
epoch [158/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.2961 (0.2647) acc 90.6250 (93.3333) lr 2.2949e-04 eta 0:04:31
epoch [158/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.3718 (0.2859) acc 93.7500 (93.2812) lr 2.2949e-04 eta 0:04:10
epoch [158/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.3328 (0.2804) acc 96.8750 (93.3750) lr 2.2949e-04 eta 0:03:57
epoch [158/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2389 (0.2900) acc 93.7500 (92.8125) lr 2.2949e-04 eta 0:03:48
epoch [158/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.2561 (0.2775) acc 96.8750 (93.2143) lr 2.2949e-04 eta 0:03:42
epoch [158/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.4751 (0.2845) acc 87.5000 (92.9688) lr 2.2949e-04 eta 0:03:37
epoch [158/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1458 (0.2947) acc 96.8750 (92.7083) lr 2.2949e-04 eta 0:03:33
epoch [158/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.5059 (0.2938) acc 90.6250 (92.8750) lr 2.2949e-04 eta 0:03:29
epoch [159/200] batch [5/51] time 0.087 (0.219) data 0.000 (0.131) loss 0.4175 (0.4026) acc 90.6250 (89.3750) lr 2.1957e-04 eta 0:07:47
epoch [159/200] batch [10/51] time 0.088 (0.153) data 0.000 (0.066) loss 0.2334 (0.3081) acc 90.6250 (91.8750) lr 2.1957e-04 eta 0:05:25
epoch [159/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.1533 (0.2747) acc 96.8750 (93.1250) lr 2.1957e-04 eta 0:04:38
epoch [159/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.4446 (0.2682) acc 87.5000 (93.1250) lr 2.1957e-04 eta 0:04:14
epoch [159/200] batch [25/51] time 0.086 (0.113) data 0.000 (0.026) loss 0.1737 (0.2586) acc 96.8750 (93.5000) lr 2.1957e-04 eta 0:04:00
epoch [159/200] batch [30/51] time 0.088 (0.109) data 0.000 (0.022) loss 0.3967 (0.2669) acc 90.6250 (93.3333) lr 2.1957e-04 eta 0:03:50
epoch [159/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2637 (0.2627) acc 93.7500 (93.6607) lr 2.1957e-04 eta 0:03:42
epoch [159/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.2859 (0.2671) acc 93.7500 (93.4375) lr 2.1957e-04 eta 0:03:37
epoch [159/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3743 (0.2806) acc 87.5000 (93.1250) lr 2.1957e-04 eta 0:03:32
epoch [159/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.6836 (0.2871) acc 84.3750 (93.1875) lr 2.1957e-04 eta 0:03:28
epoch [160/200] batch [5/51] time 0.087 (0.207) data 0.000 (0.118) loss 0.1160 (0.2908) acc 100.0000 (93.7500) lr 2.0984e-04 eta 0:07:11
epoch [160/200] batch [10/51] time 0.086 (0.147) data 0.000 (0.059) loss 0.1066 (0.2605) acc 93.7500 (93.7500) lr 2.0984e-04 eta 0:05:05
epoch [160/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.2395 (0.2595) acc 93.7500 (93.7500) lr 2.0984e-04 eta 0:04:23
epoch [160/200] batch [20/51] time 0.088 (0.117) data 0.000 (0.030) loss 0.3572 (0.2888) acc 87.5000 (92.8125) lr 2.0984e-04 eta 0:04:02
epoch [160/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.1370 (0.2857) acc 96.8750 (92.7500) lr 2.0984e-04 eta 0:03:48
epoch [160/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3345 (0.2701) acc 87.5000 (93.1250) lr 2.0984e-04 eta 0:03:40
epoch [160/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.3962 (0.2820) acc 84.3750 (92.6786) lr 2.0984e-04 eta 0:03:33
epoch [160/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.4873 (0.2796) acc 81.2500 (92.7344) lr 2.0984e-04 eta 0:03:28
epoch [160/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2325 (0.2753) acc 93.7500 (92.8472) lr 2.0984e-04 eta 0:03:24
epoch [160/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1760 (0.2935) acc 96.8750 (92.3750) lr 2.0984e-04 eta 0:03:21
epoch [161/200] batch [5/51] time 0.087 (0.213) data 0.000 (0.125) loss 0.3479 (0.2827) acc 90.6250 (92.5000) lr 2.0032e-04 eta 0:07:12
epoch [161/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.063) loss 0.2449 (0.3198) acc 87.5000 (91.2500) lr 2.0032e-04 eta 0:05:04
epoch [161/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.4221 (0.3047) acc 87.5000 (91.8750) lr 2.0032e-04 eta 0:04:21
epoch [161/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.0696 (0.2859) acc 100.0000 (92.3438) lr 2.0032e-04 eta 0:03:59
epoch [161/200] batch [25/51] time 0.086 (0.112) data 0.000 (0.025) loss 0.4846 (0.3024) acc 84.3750 (92.1250) lr 2.0032e-04 eta 0:03:45
epoch [161/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.021) loss 0.2465 (0.2954) acc 96.8750 (92.8125) lr 2.0032e-04 eta 0:03:37
epoch [161/200] batch [35/51] time 0.088 (0.105) data 0.000 (0.018) loss 0.2703 (0.3045) acc 93.7500 (92.5000) lr 2.0032e-04 eta 0:03:30
epoch [161/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.6118 (0.3159) acc 84.3750 (92.2656) lr 2.0032e-04 eta 0:03:25
epoch [161/200] batch [45/51] time 0.087 (0.101) data 0.000 (0.014) loss 0.3713 (0.3110) acc 93.7500 (92.5000) lr 2.0032e-04 eta 0:03:21
epoch [161/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.5259 (0.3098) acc 84.3750 (92.3750) lr 2.0032e-04 eta 0:03:17
epoch [162/200] batch [5/51] time 0.088 (0.204) data 0.000 (0.116) loss 0.4260 (0.2252) acc 87.5000 (94.3750) lr 1.9098e-04 eta 0:06:44
epoch [162/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.3042 (0.2124) acc 90.6250 (94.3750) lr 1.9098e-04 eta 0:04:47
epoch [162/200] batch [15/51] time 0.088 (0.126) data 0.000 (0.039) loss 0.4172 (0.2254) acc 90.6250 (93.9583) lr 1.9098e-04 eta 0:04:08
epoch [162/200] batch [20/51] time 0.086 (0.116) data 0.000 (0.029) loss 0.3474 (0.2280) acc 84.3750 (94.0625) lr 1.9098e-04 eta 0:03:49
epoch [162/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4929 (0.2498) acc 90.6250 (93.8750) lr 1.9098e-04 eta 0:03:36
epoch [162/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.4287 (0.2519) acc 87.5000 (93.9583) lr 1.9098e-04 eta 0:03:28
epoch [162/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.2637 (0.2635) acc 93.7500 (93.7500) lr 1.9098e-04 eta 0:03:22
epoch [162/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1006 (0.2578) acc 100.0000 (94.0625) lr 1.9098e-04 eta 0:03:17
epoch [162/200] batch [45/51] time 0.087 (0.100) data 0.000 (0.013) loss 0.2793 (0.2613) acc 87.5000 (93.9583) lr 1.9098e-04 eta 0:03:13
epoch [162/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.3596 (0.2571) acc 87.5000 (94.1250) lr 1.9098e-04 eta 0:03:10
epoch [163/200] batch [5/51] time 0.087 (0.207) data 0.000 (0.119) loss 0.1282 (0.2038) acc 100.0000 (98.7500) lr 1.8185e-04 eta 0:06:39
epoch [163/200] batch [10/51] time 0.088 (0.147) data 0.000 (0.060) loss 0.2654 (0.2178) acc 93.7500 (97.1875) lr 1.8185e-04 eta 0:04:43
epoch [163/200] batch [15/51] time 0.089 (0.127) data 0.000 (0.040) loss 0.4270 (0.2786) acc 90.6250 (95.0000) lr 1.8185e-04 eta 0:04:04
epoch [163/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.1941 (0.2702) acc 96.8750 (95.0000) lr 1.8185e-04 eta 0:03:44
epoch [163/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.2354 (0.2508) acc 93.7500 (95.0000) lr 1.8185e-04 eta 0:03:32
epoch [163/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.3755 (0.2533) acc 90.6250 (95.1042) lr 1.8185e-04 eta 0:03:24
epoch [163/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2456 (0.2473) acc 96.8750 (95.1786) lr 1.8185e-04 eta 0:03:18
epoch [163/200] batch [40/51] time 0.087 (0.102) data 0.000 (0.015) loss 0.1188 (0.2535) acc 96.8750 (94.7656) lr 1.8185e-04 eta 0:03:13
epoch [163/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3301 (0.2510) acc 96.8750 (94.7917) lr 1.8185e-04 eta 0:03:09
epoch [163/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.1770 (0.2476) acc 93.7500 (94.8750) lr 1.8185e-04 eta 0:03:06
epoch [164/200] batch [5/51] time 0.088 (0.204) data 0.000 (0.116) loss 0.3491 (0.3220) acc 87.5000 (90.0000) lr 1.7292e-04 eta 0:06:24
epoch [164/200] batch [10/51] time 0.087 (0.146) data 0.000 (0.058) loss 0.1888 (0.3210) acc 96.8750 (92.1875) lr 1.7292e-04 eta 0:04:33
epoch [164/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.2566 (0.3038) acc 93.7500 (92.9167) lr 1.7292e-04 eta 0:03:55
epoch [164/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.1527 (0.2905) acc 96.8750 (92.8125) lr 1.7292e-04 eta 0:03:36
epoch [164/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.2812 (0.2807) acc 93.7500 (93.1250) lr 1.7292e-04 eta 0:03:25
epoch [164/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.5093 (0.2760) acc 78.1250 (92.9167) lr 1.7292e-04 eta 0:03:17
epoch [164/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1665 (0.2790) acc 96.8750 (93.0357) lr 1.7292e-04 eta 0:03:12
epoch [164/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.3191 (0.2787) acc 93.7500 (93.0469) lr 1.7292e-04 eta 0:03:07
epoch [164/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1934 (0.2782) acc 96.8750 (93.1250) lr 1.7292e-04 eta 0:03:03
epoch [164/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1598 (0.2703) acc 96.8750 (93.5000) lr 1.7292e-04 eta 0:03:00
epoch [165/200] batch [5/51] time 0.087 (0.217) data 0.000 (0.129) loss 0.2178 (0.3086) acc 96.8750 (92.5000) lr 1.6419e-04 eta 0:06:37
epoch [165/200] batch [10/51] time 0.086 (0.152) data 0.000 (0.065) loss 0.2285 (0.2645) acc 96.8750 (94.0625) lr 1.6419e-04 eta 0:04:37
epoch [165/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.043) loss 0.1148 (0.2440) acc 100.0000 (94.5833) lr 1.6419e-04 eta 0:03:57
epoch [165/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.033) loss 0.1432 (0.2405) acc 100.0000 (94.8438) lr 1.6419e-04 eta 0:03:36
epoch [165/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2014 (0.2548) acc 93.7500 (94.1250) lr 1.6419e-04 eta 0:03:24
epoch [165/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1493 (0.2625) acc 93.7500 (93.9583) lr 1.6419e-04 eta 0:03:16
epoch [165/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2520 (0.2570) acc 90.6250 (94.0179) lr 1.6419e-04 eta 0:03:10
epoch [165/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.7178 (0.2694) acc 81.2500 (93.6719) lr 1.6419e-04 eta 0:03:05
epoch [165/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1053 (0.2747) acc 100.0000 (93.4722) lr 1.6419e-04 eta 0:03:01
epoch [165/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2383 (0.2739) acc 90.6250 (93.3125) lr 1.6419e-04 eta 0:02:57
epoch [166/200] batch [5/51] time 0.087 (0.205) data 0.000 (0.118) loss 0.1976 (0.3376) acc 93.7500 (91.8750) lr 1.5567e-04 eta 0:06:05
epoch [166/200] batch [10/51] time 0.086 (0.146) data 0.000 (0.059) loss 0.2242 (0.3051) acc 93.7500 (93.4375) lr 1.5567e-04 eta 0:04:19
epoch [166/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.2061 (0.3087) acc 93.7500 (93.1250) lr 1.5567e-04 eta 0:03:43
epoch [166/200] batch [20/51] time 0.089 (0.116) data 0.000 (0.030) loss 0.2153 (0.2994) acc 96.8750 (93.4375) lr 1.5567e-04 eta 0:03:25
epoch [166/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.024) loss 0.1107 (0.2906) acc 96.8750 (93.2500) lr 1.5567e-04 eta 0:03:14
epoch [166/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2666 (0.2975) acc 90.6250 (92.9167) lr 1.5567e-04 eta 0:03:07
epoch [166/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2556 (0.3058) acc 90.6250 (92.6786) lr 1.5567e-04 eta 0:03:01
epoch [166/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1056 (0.3068) acc 96.8750 (92.6562) lr 1.5567e-04 eta 0:02:57
epoch [166/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1176 (0.3085) acc 100.0000 (92.3611) lr 1.5567e-04 eta 0:02:53
epoch [166/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2058 (0.3022) acc 96.8750 (92.6875) lr 1.5567e-04 eta 0:02:50
epoch [167/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.115) loss 0.5308 (0.3724) acc 84.3750 (90.6250) lr 1.4736e-04 eta 0:05:51
epoch [167/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.1573 (0.3050) acc 96.8750 (92.1875) lr 1.4736e-04 eta 0:04:10
epoch [167/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.4265 (0.3257) acc 87.5000 (92.2917) lr 1.4736e-04 eta 0:03:36
epoch [167/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.2861 (0.3071) acc 90.6250 (92.6562) lr 1.4736e-04 eta 0:03:18
epoch [167/200] batch [25/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.2097 (0.3006) acc 93.7500 (93.0000) lr 1.4736e-04 eta 0:03:08
epoch [167/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1409 (0.2915) acc 100.0000 (93.1250) lr 1.4736e-04 eta 0:03:01
epoch [167/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.017) loss 0.3721 (0.3028) acc 87.5000 (92.7679) lr 1.4736e-04 eta 0:02:55
epoch [167/200] batch [40/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.4441 (0.2973) acc 87.5000 (92.9688) lr 1.4736e-04 eta 0:02:51
epoch [167/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2191 (0.3021) acc 93.7500 (92.7778) lr 1.4736e-04 eta 0:02:48
epoch [167/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2305 (0.3019) acc 96.8750 (92.6875) lr 1.4736e-04 eta 0:02:45
epoch [168/200] batch [5/51] time 0.087 (0.208) data 0.000 (0.121) loss 0.6943 (0.3557) acc 81.2500 (91.2500) lr 1.3926e-04 eta 0:05:49
epoch [168/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.060) loss 0.3220 (0.2767) acc 93.7500 (93.4375) lr 1.3926e-04 eta 0:04:06
epoch [168/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.2571 (0.2638) acc 93.7500 (94.1667) lr 1.3926e-04 eta 0:03:32
epoch [168/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3796 (0.2791) acc 87.5000 (93.4375) lr 1.3926e-04 eta 0:03:14
epoch [168/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.2634 (0.2909) acc 93.7500 (93.2500) lr 1.3926e-04 eta 0:03:04
epoch [168/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2742 (0.2958) acc 93.7500 (93.0208) lr 1.3926e-04 eta 0:02:56
epoch [168/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2394 (0.2983) acc 93.7500 (93.1250) lr 1.3926e-04 eta 0:02:51
epoch [168/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.1404 (0.2967) acc 96.8750 (93.2812) lr 1.3926e-04 eta 0:02:47
epoch [168/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3762 (0.3002) acc 90.6250 (93.1250) lr 1.3926e-04 eta 0:02:43
epoch [168/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2029 (0.2926) acc 93.7500 (93.2500) lr 1.3926e-04 eta 0:02:40
epoch [169/200] batch [5/51] time 0.087 (0.226) data 0.000 (0.138) loss 0.2429 (0.3106) acc 93.7500 (91.8750) lr 1.3137e-04 eta 0:06:06
epoch [169/200] batch [10/51] time 0.086 (0.156) data 0.000 (0.069) loss 0.2588 (0.2823) acc 93.7500 (93.4375) lr 1.3137e-04 eta 0:04:13
epoch [169/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.3127 (0.2619) acc 87.5000 (93.9583) lr 1.3137e-04 eta 0:03:35
epoch [169/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.035) loss 0.0869 (0.2368) acc 100.0000 (94.6875) lr 1.3137e-04 eta 0:03:15
epoch [169/200] batch [25/51] time 0.086 (0.115) data 0.000 (0.028) loss 0.4668 (0.2631) acc 90.6250 (94.1250) lr 1.3137e-04 eta 0:03:04
epoch [169/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1633 (0.2612) acc 93.7500 (94.0625) lr 1.3137e-04 eta 0:02:56
epoch [169/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.3169 (0.2637) acc 96.8750 (94.1071) lr 1.3137e-04 eta 0:02:50
epoch [169/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.1650 (0.2626) acc 96.8750 (94.0625) lr 1.3137e-04 eta 0:02:45
epoch [169/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.5093 (0.2690) acc 84.3750 (93.7500) lr 1.3137e-04 eta 0:02:41
epoch [169/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2146 (0.2659) acc 93.7500 (93.5000) lr 1.3137e-04 eta 0:02:38
epoch [170/200] batch [5/51] time 0.089 (0.210) data 0.000 (0.121) loss 0.1742 (0.2391) acc 96.8750 (95.6250) lr 1.2369e-04 eta 0:05:30
epoch [170/200] batch [10/51] time 0.088 (0.148) data 0.000 (0.061) loss 0.1938 (0.2422) acc 96.8750 (95.6250) lr 1.2369e-04 eta 0:03:53
epoch [170/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.4070 (0.2796) acc 84.3750 (93.9583) lr 1.2369e-04 eta 0:03:20
epoch [170/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.030) loss 0.3638 (0.3018) acc 90.6250 (92.9688) lr 1.2369e-04 eta 0:03:03
epoch [170/200] batch [25/51] time 0.086 (0.111) data 0.000 (0.024) loss 0.1263 (0.2906) acc 96.8750 (93.3750) lr 1.2369e-04 eta 0:02:53
epoch [170/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.4363 (0.2860) acc 87.5000 (93.3333) lr 1.2369e-04 eta 0:02:46
epoch [170/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.018) loss 0.2976 (0.2952) acc 87.5000 (92.9464) lr 1.2369e-04 eta 0:02:41
epoch [170/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.4250 (0.2959) acc 90.6250 (92.7344) lr 1.2369e-04 eta 0:02:37
epoch [170/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1282 (0.2827) acc 100.0000 (93.2639) lr 1.2369e-04 eta 0:02:34
epoch [170/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2260 (0.2854) acc 96.8750 (93.1875) lr 1.2369e-04 eta 0:02:31
epoch [171/200] batch [5/51] time 0.086 (0.225) data 0.000 (0.138) loss 0.3357 (0.2898) acc 93.7500 (93.1250) lr 1.1623e-04 eta 0:05:43
epoch [171/200] batch [10/51] time 0.086 (0.156) data 0.000 (0.069) loss 0.3525 (0.3166) acc 93.7500 (92.8125) lr 1.1623e-04 eta 0:03:56
epoch [171/200] batch [15/51] time 0.086 (0.133) data 0.000 (0.046) loss 0.1902 (0.2935) acc 93.7500 (93.5417) lr 1.1623e-04 eta 0:03:21
epoch [171/200] batch [20/51] time 0.086 (0.121) data 0.000 (0.035) loss 0.1547 (0.2843) acc 96.8750 (93.5938) lr 1.1623e-04 eta 0:03:02
epoch [171/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.3132 (0.2956) acc 93.7500 (93.5000) lr 1.1623e-04 eta 0:02:52
epoch [171/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5591 (0.2969) acc 84.3750 (93.3333) lr 1.1623e-04 eta 0:02:44
epoch [171/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.4124 (0.2840) acc 90.6250 (93.6607) lr 1.1623e-04 eta 0:02:39
epoch [171/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3362 (0.2817) acc 87.5000 (93.5938) lr 1.1623e-04 eta 0:02:34
epoch [171/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2312 (0.2765) acc 93.7500 (93.8194) lr 1.1623e-04 eta 0:02:31
epoch [171/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.3467 (0.2774) acc 93.7500 (93.8750) lr 1.1623e-04 eta 0:02:28
epoch [172/200] batch [5/51] time 0.087 (0.218) data 0.000 (0.131) loss 0.3145 (0.2182) acc 90.6250 (96.2500) lr 1.0899e-04 eta 0:05:21
epoch [172/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.1034 (0.3114) acc 100.0000 (93.1250) lr 1.0899e-04 eta 0:03:44
epoch [172/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.1420 (0.3005) acc 96.8750 (92.2917) lr 1.0899e-04 eta 0:03:11
epoch [172/200] batch [20/51] time 0.086 (0.120) data 0.000 (0.033) loss 0.5415 (0.3121) acc 87.5000 (92.0312) lr 1.0899e-04 eta 0:02:54
epoch [172/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.4927 (0.3117) acc 87.5000 (92.1250) lr 1.0899e-04 eta 0:02:44
epoch [172/200] batch [30/51] time 0.086 (0.109) data 0.000 (0.022) loss 0.2749 (0.3117) acc 93.7500 (92.3958) lr 1.0899e-04 eta 0:02:37
epoch [172/200] batch [35/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.2091 (0.3006) acc 96.8750 (92.8571) lr 1.0899e-04 eta 0:02:32
epoch [172/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.1548 (0.2868) acc 96.8750 (93.2812) lr 1.0899e-04 eta 0:02:28
epoch [172/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.015) loss 0.2595 (0.2853) acc 90.6250 (93.2639) lr 1.0899e-04 eta 0:02:25
epoch [172/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.3633 (0.2895) acc 87.5000 (92.9375) lr 1.0899e-04 eta 0:02:22
epoch [173/200] batch [5/51] time 0.088 (0.202) data 0.000 (0.113) loss 0.1718 (0.3140) acc 93.7500 (92.5000) lr 1.0197e-04 eta 0:04:47
epoch [173/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.3030 (0.3536) acc 93.7500 (92.1875) lr 1.0197e-04 eta 0:03:24
epoch [173/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.1327 (0.2973) acc 96.8750 (93.5417) lr 1.0197e-04 eta 0:02:57
epoch [173/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.028) loss 0.2118 (0.2953) acc 93.7500 (93.4375) lr 1.0197e-04 eta 0:02:43
epoch [173/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.2267 (0.2881) acc 90.6250 (93.6250) lr 1.0197e-04 eta 0:02:34
epoch [173/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.0972 (0.2867) acc 100.0000 (93.9583) lr 1.0197e-04 eta 0:02:28
epoch [173/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.016) loss 0.1743 (0.2880) acc 96.8750 (93.8393) lr 1.0197e-04 eta 0:02:24
epoch [173/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.014) loss 0.2468 (0.2815) acc 90.6250 (93.8281) lr 1.0197e-04 eta 0:02:20
epoch [173/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2896 (0.2840) acc 90.6250 (93.6806) lr 1.0197e-04 eta 0:02:18
epoch [173/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2041 (0.2763) acc 96.8750 (93.8125) lr 1.0197e-04 eta 0:02:15
epoch [174/200] batch [5/51] time 0.088 (0.206) data 0.000 (0.118) loss 0.2834 (0.3385) acc 96.8750 (92.5000) lr 9.5173e-05 eta 0:04:43
epoch [174/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.1338 (0.2934) acc 100.0000 (93.4375) lr 9.5173e-05 eta 0:03:20
epoch [174/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.2522 (0.2987) acc 93.7500 (92.7083) lr 9.5173e-05 eta 0:02:53
epoch [174/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.5962 (0.3313) acc 84.3750 (91.7188) lr 9.5173e-05 eta 0:02:39
epoch [174/200] batch [25/51] time 0.090 (0.111) data 0.000 (0.024) loss 0.2358 (0.3263) acc 93.7500 (91.8750) lr 9.5173e-05 eta 0:02:30
epoch [174/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2336 (0.3207) acc 96.8750 (91.9792) lr 9.5173e-05 eta 0:02:24
epoch [174/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.017) loss 0.5107 (0.3183) acc 90.6250 (92.1429) lr 9.5173e-05 eta 0:02:20
epoch [174/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3423 (0.3068) acc 90.6250 (92.4219) lr 9.5173e-05 eta 0:02:16
epoch [174/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1855 (0.3027) acc 93.7500 (92.5694) lr 9.5173e-05 eta 0:02:13
epoch [174/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3079 (0.2961) acc 90.6250 (92.8125) lr 9.5173e-05 eta 0:02:11
epoch [175/200] batch [5/51] time 0.088 (0.211) data 0.000 (0.123) loss 0.3809 (0.2836) acc 90.6250 (93.7500) lr 8.8597e-05 eta 0:04:38
epoch [175/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.1797 (0.2746) acc 96.8750 (93.7500) lr 8.8597e-05 eta 0:03:16
epoch [175/200] batch [15/51] time 0.086 (0.128) data 0.000 (0.041) loss 0.1771 (0.2817) acc 96.8750 (93.5417) lr 8.8597e-05 eta 0:02:48
epoch [175/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.4465 (0.2903) acc 87.5000 (93.2812) lr 8.8597e-05 eta 0:02:34
epoch [175/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.0737 (0.2774) acc 100.0000 (93.8750) lr 8.8597e-05 eta 0:02:25
epoch [175/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.1935 (0.2672) acc 96.8750 (94.0625) lr 8.8597e-05 eta 0:02:19
epoch [175/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1417 (0.2594) acc 96.8750 (94.2857) lr 8.8597e-05 eta 0:02:15
epoch [175/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.1181 (0.2566) acc 100.0000 (94.4531) lr 8.8597e-05 eta 0:02:11
epoch [175/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2764 (0.2573) acc 93.7500 (94.5833) lr 8.8597e-05 eta 0:02:08
epoch [175/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.1698 (0.2615) acc 96.8750 (94.2500) lr 8.8597e-05 eta 0:02:06
epoch [176/200] batch [5/51] time 0.087 (0.203) data 0.000 (0.115) loss 0.0623 (0.1810) acc 100.0000 (96.8750) lr 8.2245e-05 eta 0:04:17
epoch [176/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.1796 (0.1979) acc 96.8750 (95.9375) lr 8.2245e-05 eta 0:03:03
epoch [176/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.0931 (0.2428) acc 100.0000 (94.7917) lr 8.2245e-05 eta 0:02:38
epoch [176/200] batch [20/51] time 0.088 (0.116) data 0.000 (0.029) loss 0.1443 (0.2505) acc 96.8750 (94.5312) lr 8.2245e-05 eta 0:02:25
epoch [176/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.5063 (0.2561) acc 87.5000 (94.3750) lr 8.2245e-05 eta 0:02:17
epoch [176/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1088 (0.2711) acc 96.8750 (93.8542) lr 8.2245e-05 eta 0:02:12
epoch [176/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2759 (0.2687) acc 93.7500 (93.9286) lr 8.2245e-05 eta 0:02:08
epoch [176/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.0947 (0.2524) acc 100.0000 (94.2969) lr 8.2245e-05 eta 0:02:05
epoch [176/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4407 (0.2586) acc 90.6250 (94.1667) lr 8.2245e-05 eta 0:02:02
epoch [176/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.0760 (0.2598) acc 100.0000 (93.9375) lr 8.2245e-05 eta 0:02:00
epoch [177/200] batch [5/51] time 0.087 (0.225) data 0.000 (0.137) loss 0.1753 (0.2365) acc 96.8750 (95.0000) lr 7.6120e-05 eta 0:04:33
epoch [177/200] batch [10/51] time 0.087 (0.156) data 0.000 (0.069) loss 0.3203 (0.2334) acc 90.6250 (95.0000) lr 7.6120e-05 eta 0:03:09
epoch [177/200] batch [15/51] time 0.087 (0.133) data 0.000 (0.046) loss 0.2347 (0.2376) acc 93.7500 (94.7917) lr 7.6120e-05 eta 0:02:40
epoch [177/200] batch [20/51] time 0.086 (0.121) data 0.000 (0.035) loss 0.2654 (0.2393) acc 93.7500 (94.3750) lr 7.6120e-05 eta 0:02:25
epoch [177/200] batch [25/51] time 0.086 (0.114) data 0.000 (0.028) loss 0.4907 (0.2608) acc 87.5000 (93.6250) lr 7.6120e-05 eta 0:02:17
epoch [177/200] batch [30/51] time 0.090 (0.110) data 0.000 (0.023) loss 0.2040 (0.2566) acc 96.8750 (94.0625) lr 7.6120e-05 eta 0:02:11
epoch [177/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1221 (0.2564) acc 96.8750 (93.8393) lr 7.6120e-05 eta 0:02:06
epoch [177/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.2413 (0.2535) acc 96.8750 (93.9844) lr 7.6120e-05 eta 0:02:03
epoch [177/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1137 (0.2517) acc 100.0000 (94.0278) lr 7.6120e-05 eta 0:02:00
epoch [177/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3020 (0.2575) acc 90.6250 (93.8125) lr 7.6120e-05 eta 0:01:57
epoch [178/200] batch [5/51] time 0.088 (0.223) data 0.000 (0.135) loss 0.3052 (0.3063) acc 90.6250 (91.2500) lr 7.0224e-05 eta 0:04:19
epoch [178/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.068) loss 0.1382 (0.2541) acc 100.0000 (93.1250) lr 7.0224e-05 eta 0:03:00
epoch [178/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.1270 (0.2558) acc 96.8750 (93.5417) lr 7.0224e-05 eta 0:02:33
epoch [178/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.034) loss 0.2345 (0.2471) acc 93.7500 (94.0625) lr 7.0224e-05 eta 0:02:19
epoch [178/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.3516 (0.2550) acc 93.7500 (94.1250) lr 7.0224e-05 eta 0:02:11
epoch [178/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3564 (0.2618) acc 90.6250 (94.0625) lr 7.0224e-05 eta 0:02:05
epoch [178/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.3982 (0.2738) acc 90.6250 (93.8393) lr 7.0224e-05 eta 0:02:01
epoch [178/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2244 (0.2722) acc 96.8750 (94.0625) lr 7.0224e-05 eta 0:01:57
epoch [178/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2751 (0.2699) acc 90.6250 (93.8889) lr 7.0224e-05 eta 0:01:54
epoch [178/200] batch [50/51] time 0.089 (0.100) data 0.000 (0.014) loss 0.6030 (0.2824) acc 75.0000 (93.2500) lr 7.0224e-05 eta 0:01:52
epoch [179/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.113) loss 0.4360 (0.2959) acc 87.5000 (91.8750) lr 6.4556e-05 eta 0:03:44
epoch [179/200] batch [10/51] time 0.088 (0.144) data 0.000 (0.057) loss 0.1721 (0.2753) acc 100.0000 (92.8125) lr 6.4556e-05 eta 0:02:40
epoch [179/200] batch [15/51] time 0.087 (0.125) data 0.000 (0.038) loss 0.3677 (0.2980) acc 90.6250 (92.0833) lr 6.4556e-05 eta 0:02:18
epoch [179/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.4504 (0.2895) acc 96.8750 (93.1250) lr 6.4556e-05 eta 0:02:07
epoch [179/200] batch [25/51] time 0.089 (0.110) data 0.000 (0.023) loss 0.4841 (0.2896) acc 87.5000 (93.0000) lr 6.4556e-05 eta 0:02:00
epoch [179/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2496 (0.2934) acc 93.7500 (92.7083) lr 6.4556e-05 eta 0:01:56
epoch [179/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.016) loss 0.3196 (0.2950) acc 90.6250 (92.6786) lr 6.4556e-05 eta 0:01:52
epoch [179/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.014) loss 0.1877 (0.2867) acc 96.8750 (93.0469) lr 6.4556e-05 eta 0:01:49
epoch [179/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4211 (0.2780) acc 87.5000 (93.1944) lr 6.4556e-05 eta 0:01:47
epoch [179/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.4236 (0.2815) acc 90.6250 (93.1250) lr 6.4556e-05 eta 0:01:45
epoch [180/200] batch [5/51] time 0.087 (0.211) data 0.000 (0.124) loss 0.2527 (0.2910) acc 93.7500 (92.5000) lr 5.9119e-05 eta 0:03:45
epoch [180/200] batch [10/51] time 0.087 (0.149) data 0.000 (0.062) loss 0.1617 (0.3259) acc 93.7500 (92.5000) lr 5.9119e-05 eta 0:02:38
epoch [180/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.1799 (0.3080) acc 100.0000 (93.5417) lr 5.9119e-05 eta 0:02:15
epoch [180/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.2361 (0.2723) acc 93.7500 (94.5312) lr 5.9119e-05 eta 0:02:03
epoch [180/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.2754 (0.2743) acc 93.7500 (94.3750) lr 5.9119e-05 eta 0:01:56
epoch [180/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.2217 (0.2804) acc 96.8750 (94.0625) lr 5.9119e-05 eta 0:01:51
epoch [180/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1699 (0.2740) acc 96.8750 (94.2857) lr 5.9119e-05 eta 0:01:48
epoch [180/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.1554 (0.2708) acc 96.8750 (94.2188) lr 5.9119e-05 eta 0:01:45
epoch [180/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.1483 (0.2667) acc 100.0000 (94.5833) lr 5.9119e-05 eta 0:01:43
epoch [180/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.2830 (0.2683) acc 93.7500 (94.5000) lr 5.9119e-05 eta 0:01:41
epoch [181/200] batch [5/51] time 0.088 (0.203) data 0.000 (0.115) loss 0.2478 (0.3983) acc 93.7500 (90.0000) lr 5.3915e-05 eta 0:03:26
epoch [181/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.2417 (0.2969) acc 93.7500 (93.1250) lr 5.3915e-05 eta 0:02:26
epoch [181/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.038) loss 0.3413 (0.3061) acc 90.6250 (92.9167) lr 5.3915e-05 eta 0:02:06
epoch [181/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.1967 (0.2813) acc 96.8750 (93.1250) lr 5.3915e-05 eta 0:01:56
epoch [181/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.3572 (0.2702) acc 93.7500 (93.3750) lr 5.3915e-05 eta 0:01:49
epoch [181/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1370 (0.2636) acc 100.0000 (93.4375) lr 5.3915e-05 eta 0:01:45
epoch [181/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.5737 (0.2737) acc 87.5000 (93.4821) lr 5.3915e-05 eta 0:01:42
epoch [181/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.1566 (0.2667) acc 96.8750 (93.6719) lr 5.3915e-05 eta 0:01:39
epoch [181/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.2588 (0.2681) acc 90.6250 (93.4722) lr 5.3915e-05 eta 0:01:37
epoch [181/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.2294 (0.2616) acc 96.8750 (93.6250) lr 5.3915e-05 eta 0:01:35
epoch [182/200] batch [5/51] time 0.088 (0.206) data 0.000 (0.118) loss 0.2089 (0.2956) acc 93.7500 (93.7500) lr 4.8943e-05 eta 0:03:18
epoch [182/200] batch [10/51] time 0.087 (0.147) data 0.000 (0.059) loss 0.2722 (0.3101) acc 93.7500 (93.1250) lr 4.8943e-05 eta 0:02:20
epoch [182/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.4370 (0.3086) acc 90.6250 (93.1250) lr 4.8943e-05 eta 0:02:00
epoch [182/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.7334 (0.3268) acc 84.3750 (92.6562) lr 4.8943e-05 eta 0:01:50
epoch [182/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1948 (0.3075) acc 93.7500 (92.7500) lr 4.8943e-05 eta 0:01:44
epoch [182/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2142 (0.2944) acc 96.8750 (93.2292) lr 4.8943e-05 eta 0:01:40
epoch [182/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.2009 (0.2983) acc 96.8750 (93.3036) lr 4.8943e-05 eta 0:01:37
epoch [182/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.3416 (0.2867) acc 90.6250 (93.5156) lr 4.8943e-05 eta 0:01:34
epoch [182/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3091 (0.2856) acc 90.6250 (93.5417) lr 4.8943e-05 eta 0:01:32
epoch [182/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.0802 (0.2745) acc 100.0000 (93.9375) lr 4.8943e-05 eta 0:01:30
epoch [183/200] batch [5/51] time 0.087 (0.225) data 0.000 (0.138) loss 0.1919 (0.3857) acc 93.7500 (90.6250) lr 4.4207e-05 eta 0:03:25
epoch [183/200] batch [10/51] time 0.086 (0.156) data 0.000 (0.069) loss 0.1600 (0.3198) acc 96.8750 (92.5000) lr 4.4207e-05 eta 0:02:21
epoch [183/200] batch [15/51] time 0.086 (0.133) data 0.000 (0.046) loss 0.3325 (0.2968) acc 93.7500 (93.5417) lr 4.4207e-05 eta 0:01:59
epoch [183/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.035) loss 0.2349 (0.2881) acc 90.6250 (93.1250) lr 4.4207e-05 eta 0:01:48
epoch [183/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.2490 (0.2808) acc 93.7500 (93.3750) lr 4.4207e-05 eta 0:01:42
epoch [183/200] batch [30/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.1787 (0.2683) acc 96.8750 (93.8542) lr 4.4207e-05 eta 0:01:37
epoch [183/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.2927 (0.2735) acc 93.7500 (93.4821) lr 4.4207e-05 eta 0:01:33
epoch [183/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.1138 (0.2715) acc 100.0000 (93.3594) lr 4.4207e-05 eta 0:01:31
epoch [183/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3208 (0.2792) acc 93.7500 (93.0556) lr 4.4207e-05 eta 0:01:28
epoch [183/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.1581 (0.2786) acc 96.8750 (93.1875) lr 4.4207e-05 eta 0:01:26
epoch [184/200] batch [5/51] time 0.086 (0.214) data 0.000 (0.126) loss 0.4922 (0.2415) acc 81.2500 (93.1250) lr 3.9706e-05 eta 0:03:04
epoch [184/200] batch [10/51] time 0.087 (0.151) data 0.000 (0.063) loss 0.2671 (0.2410) acc 96.8750 (93.4375) lr 3.9706e-05 eta 0:02:09
epoch [184/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.5093 (0.2744) acc 84.3750 (92.5000) lr 3.9706e-05 eta 0:01:50
epoch [184/200] batch [20/51] time 0.086 (0.119) data 0.000 (0.032) loss 0.4253 (0.2807) acc 87.5000 (92.5000) lr 3.9706e-05 eta 0:01:40
epoch [184/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.4558 (0.2867) acc 78.1250 (92.1250) lr 3.9706e-05 eta 0:01:34
epoch [184/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.0861 (0.2798) acc 100.0000 (92.3958) lr 3.9706e-05 eta 0:01:30
epoch [184/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.2062 (0.2726) acc 96.8750 (92.8571) lr 3.9706e-05 eta 0:01:27
epoch [184/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.016) loss 0.3394 (0.2741) acc 93.7500 (93.2031) lr 3.9706e-05 eta 0:01:25
epoch [184/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.5508 (0.2730) acc 87.5000 (93.4028) lr 3.9706e-05 eta 0:01:22
epoch [184/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.3984 (0.2729) acc 90.6250 (93.5000) lr 3.9706e-05 eta 0:01:21
epoch [185/200] batch [5/51] time 0.086 (0.218) data 0.000 (0.130) loss 0.3098 (0.2546) acc 93.7500 (94.3750) lr 3.5443e-05 eta 0:02:56
epoch [185/200] batch [10/51] time 0.086 (0.152) data 0.000 (0.065) loss 0.4336 (0.3049) acc 90.6250 (92.8125) lr 3.5443e-05 eta 0:02:02
epoch [185/200] batch [15/51] time 0.087 (0.130) data 0.000 (0.044) loss 0.4712 (0.3174) acc 90.6250 (92.0833) lr 3.5443e-05 eta 0:01:44
epoch [185/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.1077 (0.3137) acc 100.0000 (92.6562) lr 3.5443e-05 eta 0:01:35
epoch [185/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.1317 (0.2850) acc 100.0000 (93.2500) lr 3.5443e-05 eta 0:01:29
epoch [185/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.4299 (0.2857) acc 87.5000 (93.0208) lr 3.5443e-05 eta 0:01:25
epoch [185/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1390 (0.2720) acc 96.8750 (93.5714) lr 3.5443e-05 eta 0:01:22
epoch [185/200] batch [40/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1453 (0.2746) acc 100.0000 (93.6719) lr 3.5443e-05 eta 0:01:20
epoch [185/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.4326 (0.2793) acc 90.6250 (93.6806) lr 3.5443e-05 eta 0:01:18
epoch [185/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.4653 (0.2817) acc 93.7500 (93.8750) lr 3.5443e-05 eta 0:01:16
epoch [186/200] batch [5/51] time 0.088 (0.211) data 0.000 (0.124) loss 0.2693 (0.2256) acc 93.7500 (97.5000) lr 3.1417e-05 eta 0:02:40
epoch [186/200] batch [10/51] time 0.086 (0.149) data 0.000 (0.062) loss 0.1094 (0.2046) acc 96.8750 (96.5625) lr 3.1417e-05 eta 0:01:52
epoch [186/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.2820 (0.2226) acc 93.7500 (95.4167) lr 3.1417e-05 eta 0:01:36
epoch [186/200] batch [20/51] time 0.086 (0.118) data 0.000 (0.031) loss 0.1804 (0.2225) acc 96.8750 (95.9375) lr 3.1417e-05 eta 0:01:27
epoch [186/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.3352 (0.2272) acc 90.6250 (95.3750) lr 3.1417e-05 eta 0:01:22
epoch [186/200] batch [30/51] time 0.086 (0.107) data 0.000 (0.021) loss 0.1852 (0.2235) acc 96.8750 (95.3125) lr 3.1417e-05 eta 0:01:18
epoch [186/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.018) loss 0.1918 (0.2308) acc 96.8750 (95.0000) lr 3.1417e-05 eta 0:01:16
epoch [186/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.016) loss 0.3135 (0.2445) acc 93.7500 (94.3750) lr 3.1417e-05 eta 0:01:13
epoch [186/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2236 (0.2437) acc 93.7500 (94.3056) lr 3.1417e-05 eta 0:01:12
epoch [186/200] batch [50/51] time 0.085 (0.099) data 0.000 (0.013) loss 0.5801 (0.2503) acc 81.2500 (93.8750) lr 3.1417e-05 eta 0:01:10
epoch [187/200] batch [5/51] time 0.087 (0.221) data 0.000 (0.133) loss 0.1818 (0.3289) acc 96.8750 (91.8750) lr 2.7630e-05 eta 0:02:36
epoch [187/200] batch [10/51] time 0.087 (0.154) data 0.000 (0.067) loss 0.3394 (0.3232) acc 93.7500 (91.5625) lr 2.7630e-05 eta 0:01:48
epoch [187/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.045) loss 0.2275 (0.2910) acc 96.8750 (93.1250) lr 2.7630e-05 eta 0:01:32
epoch [187/200] batch [20/51] time 0.087 (0.121) data 0.000 (0.033) loss 0.1681 (0.2826) acc 96.8750 (93.7500) lr 2.7630e-05 eta 0:01:23
epoch [187/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.027) loss 0.2900 (0.2956) acc 87.5000 (92.8750) lr 2.7630e-05 eta 0:01:18
epoch [187/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2319 (0.2882) acc 93.7500 (92.9167) lr 2.7630e-05 eta 0:01:14
epoch [187/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.3784 (0.2987) acc 90.6250 (92.9464) lr 2.7630e-05 eta 0:01:12
epoch [187/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.2610 (0.2958) acc 90.6250 (92.8906) lr 2.7630e-05 eta 0:01:09
epoch [187/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.1339 (0.2941) acc 96.8750 (92.6389) lr 2.7630e-05 eta 0:01:07
epoch [187/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.2048 (0.2896) acc 96.8750 (92.7500) lr 2.7630e-05 eta 0:01:06
epoch [188/200] batch [5/51] time 0.088 (0.201) data 0.000 (0.114) loss 0.2563 (0.2070) acc 93.7500 (96.8750) lr 2.4083e-05 eta 0:02:12
epoch [188/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.057) loss 0.5024 (0.2470) acc 87.5000 (95.0000) lr 2.4083e-05 eta 0:01:34
epoch [188/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.038) loss 0.4998 (0.2501) acc 84.3750 (94.3750) lr 2.4083e-05 eta 0:01:20
epoch [188/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.029) loss 0.1661 (0.2673) acc 100.0000 (94.0625) lr 2.4083e-05 eta 0:01:14
epoch [188/200] batch [25/51] time 0.088 (0.110) data 0.000 (0.023) loss 0.4033 (0.2715) acc 87.5000 (93.7500) lr 2.4083e-05 eta 0:01:10
epoch [188/200] batch [30/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.1884 (0.2736) acc 96.8750 (93.4375) lr 2.4083e-05 eta 0:01:07
epoch [188/200] batch [35/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.1991 (0.2676) acc 96.8750 (93.6607) lr 2.4083e-05 eta 0:01:04
epoch [188/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2008 (0.2653) acc 96.8750 (93.6719) lr 2.4083e-05 eta 0:01:03
epoch [188/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.3464 (0.2660) acc 90.6250 (93.4722) lr 2.4083e-05 eta 0:01:01
epoch [188/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1654 (0.2615) acc 100.0000 (93.8125) lr 2.4083e-05 eta 0:01:00
epoch [189/200] batch [5/51] time 0.086 (0.208) data 0.000 (0.121) loss 0.2500 (0.2589) acc 93.7500 (93.1250) lr 2.0777e-05 eta 0:02:06
epoch [189/200] batch [10/51] time 0.086 (0.147) data 0.000 (0.061) loss 0.3621 (0.2691) acc 93.7500 (93.4375) lr 2.0777e-05 eta 0:01:28
epoch [189/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.1689 (0.2581) acc 96.8750 (93.5417) lr 2.0777e-05 eta 0:01:15
epoch [189/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.4580 (0.2771) acc 87.5000 (93.2812) lr 2.0777e-05 eta 0:01:09
epoch [189/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.2610 (0.2775) acc 93.7500 (93.2500) lr 2.0777e-05 eta 0:01:05
epoch [189/200] batch [30/51] time 0.088 (0.107) data 0.000 (0.020) loss 0.4319 (0.2715) acc 90.6250 (93.4375) lr 2.0777e-05 eta 0:01:02
epoch [189/200] batch [35/51] time 0.088 (0.104) data 0.000 (0.017) loss 0.3391 (0.2687) acc 90.6250 (93.5714) lr 2.0777e-05 eta 0:01:00
epoch [189/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.2529 (0.2678) acc 96.8750 (93.6719) lr 2.0777e-05 eta 0:00:58
epoch [189/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.0950 (0.2632) acc 100.0000 (93.8194) lr 2.0777e-05 eta 0:00:56
epoch [189/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2822 (0.2641) acc 90.6250 (93.6875) lr 2.0777e-05 eta 0:00:55
epoch [190/200] batch [5/51] time 0.088 (0.197) data 0.000 (0.110) loss 0.1703 (0.2142) acc 96.8750 (97.5000) lr 1.7713e-05 eta 0:01:49
epoch [190/200] batch [10/51] time 0.087 (0.142) data 0.000 (0.055) loss 0.1594 (0.2220) acc 96.8750 (95.9375) lr 1.7713e-05 eta 0:01:18
epoch [190/200] batch [15/51] time 0.086 (0.123) data 0.000 (0.037) loss 0.4277 (0.2443) acc 93.7500 (95.4167) lr 1.7713e-05 eta 0:01:07
epoch [190/200] batch [20/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.1825 (0.2573) acc 96.8750 (94.8438) lr 1.7713e-05 eta 0:01:01
epoch [190/200] batch [25/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.1279 (0.2591) acc 100.0000 (94.1250) lr 1.7713e-05 eta 0:00:58
epoch [190/200] batch [30/51] time 0.086 (0.105) data 0.000 (0.018) loss 0.3208 (0.2560) acc 93.7500 (94.5833) lr 1.7713e-05 eta 0:00:55
epoch [190/200] batch [35/51] time 0.087 (0.102) data 0.000 (0.016) loss 0.3071 (0.2617) acc 96.8750 (94.6429) lr 1.7713e-05 eta 0:00:53
epoch [190/200] batch [40/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.3735 (0.2799) acc 90.6250 (93.9844) lr 1.7713e-05 eta 0:00:52
epoch [190/200] batch [45/51] time 0.085 (0.099) data 0.000 (0.012) loss 0.2910 (0.2704) acc 93.7500 (93.9583) lr 1.7713e-05 eta 0:00:50
epoch [190/200] batch [50/51] time 0.085 (0.097) data 0.000 (0.011) loss 0.3679 (0.2747) acc 87.5000 (93.7500) lr 1.7713e-05 eta 0:00:49
epoch [191/200] batch [5/51] time 0.087 (0.207) data 0.000 (0.120) loss 0.1324 (0.2624) acc 100.0000 (93.1250) lr 1.4891e-05 eta 0:01:44
epoch [191/200] batch [10/51] time 0.086 (0.147) data 0.000 (0.060) loss 0.2394 (0.2905) acc 93.7500 (93.1250) lr 1.4891e-05 eta 0:01:13
epoch [191/200] batch [15/51] time 0.087 (0.127) data 0.000 (0.040) loss 0.1985 (0.2796) acc 96.8750 (92.9167) lr 1.4891e-05 eta 0:01:02
epoch [191/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.3159 (0.2958) acc 90.6250 (92.8125) lr 1.4891e-05 eta 0:00:57
epoch [191/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1782 (0.2848) acc 93.7500 (93.0000) lr 1.4891e-05 eta 0:00:53
epoch [191/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2734 (0.2970) acc 93.7500 (92.7083) lr 1.4891e-05 eta 0:00:51
epoch [191/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2310 (0.2889) acc 93.7500 (92.8571) lr 1.4891e-05 eta 0:00:49
epoch [191/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.1279 (0.2856) acc 96.8750 (92.8906) lr 1.4891e-05 eta 0:00:47
epoch [191/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1003 (0.2852) acc 100.0000 (92.9861) lr 1.4891e-05 eta 0:00:46
epoch [191/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.1120 (0.2835) acc 96.8750 (93.1875) lr 1.4891e-05 eta 0:00:45
epoch [192/200] batch [5/51] time 0.088 (0.200) data 0.000 (0.112) loss 0.4629 (0.3369) acc 87.5000 (93.1250) lr 1.2312e-05 eta 0:01:31
epoch [192/200] batch [10/51] time 0.087 (0.144) data 0.000 (0.056) loss 0.4028 (0.3119) acc 93.7500 (94.0625) lr 1.2312e-05 eta 0:01:04
epoch [192/200] batch [15/51] time 0.086 (0.125) data 0.000 (0.037) loss 0.5894 (0.3449) acc 84.3750 (92.2917) lr 1.2312e-05 eta 0:00:55
epoch [192/200] batch [20/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.2871 (0.3185) acc 87.5000 (92.9688) lr 1.2312e-05 eta 0:00:50
epoch [192/200] batch [25/51] time 0.087 (0.110) data 0.000 (0.023) loss 0.4365 (0.3226) acc 90.6250 (92.8750) lr 1.2312e-05 eta 0:00:47
epoch [192/200] batch [30/51] time 0.086 (0.106) data 0.000 (0.019) loss 0.3005 (0.3147) acc 93.7500 (93.0208) lr 1.2312e-05 eta 0:00:45
epoch [192/200] batch [35/51] time 0.088 (0.103) data 0.000 (0.016) loss 0.4766 (0.3140) acc 90.6250 (92.8571) lr 1.2312e-05 eta 0:00:43
epoch [192/200] batch [40/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.1917 (0.3108) acc 96.8750 (92.9688) lr 1.2312e-05 eta 0:00:42
epoch [192/200] batch [45/51] time 0.086 (0.099) data 0.000 (0.013) loss 0.0777 (0.3026) acc 100.0000 (93.1944) lr 1.2312e-05 eta 0:00:41
epoch [192/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.011) loss 0.0999 (0.2916) acc 100.0000 (93.6250) lr 1.2312e-05 eta 0:00:40
epoch [193/200] batch [5/51] time 0.087 (0.219) data 0.000 (0.131) loss 0.3401 (0.2368) acc 93.7500 (95.6250) lr 9.9763e-06 eta 0:01:28
epoch [193/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.0731 (0.2514) acc 100.0000 (93.7500) lr 9.9763e-06 eta 0:01:00
epoch [193/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.1490 (0.2431) acc 100.0000 (94.7917) lr 9.9763e-06 eta 0:00:51
epoch [193/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.4680 (0.2498) acc 81.2500 (94.2188) lr 9.9763e-06 eta 0:00:46
epoch [193/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.2426 (0.2413) acc 93.7500 (94.6250) lr 9.9763e-06 eta 0:00:43
epoch [193/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.2314 (0.2454) acc 96.8750 (94.3750) lr 9.9763e-06 eta 0:00:41
epoch [193/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.2634 (0.2531) acc 90.6250 (94.0179) lr 9.9763e-06 eta 0:00:39
epoch [193/200] batch [40/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.2439 (0.2572) acc 93.7500 (93.8281) lr 9.9763e-06 eta 0:00:38
epoch [193/200] batch [45/51] time 0.087 (0.102) data 0.000 (0.015) loss 0.1842 (0.2623) acc 96.8750 (93.8194) lr 9.9763e-06 eta 0:00:36
epoch [193/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1719 (0.2647) acc 93.7500 (93.7500) lr 9.9763e-06 eta 0:00:35
epoch [194/200] batch [5/51] time 0.088 (0.209) data 0.000 (0.121) loss 0.5449 (0.3321) acc 90.6250 (93.1250) lr 7.8853e-06 eta 0:01:13
epoch [194/200] batch [10/51] time 0.087 (0.148) data 0.000 (0.060) loss 0.1526 (0.2945) acc 96.8750 (92.8125) lr 7.8853e-06 eta 0:00:51
epoch [194/200] batch [15/51] time 0.086 (0.127) data 0.000 (0.040) loss 0.4236 (0.3156) acc 90.6250 (92.0833) lr 7.8853e-06 eta 0:00:43
epoch [194/200] batch [20/51] time 0.087 (0.117) data 0.000 (0.030) loss 0.2852 (0.2953) acc 90.6250 (92.1875) lr 7.8853e-06 eta 0:00:39
epoch [194/200] batch [25/51] time 0.087 (0.111) data 0.000 (0.024) loss 0.1414 (0.2960) acc 93.7500 (92.2500) lr 7.8853e-06 eta 0:00:36
epoch [194/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.2974 (0.2889) acc 93.7500 (92.7083) lr 7.8853e-06 eta 0:00:34
epoch [194/200] batch [35/51] time 0.086 (0.104) data 0.000 (0.017) loss 0.3301 (0.2912) acc 90.6250 (92.8571) lr 7.8853e-06 eta 0:00:33
epoch [194/200] batch [40/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3201 (0.2811) acc 93.7500 (93.3594) lr 7.8853e-06 eta 0:00:32
epoch [194/200] batch [45/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2212 (0.2786) acc 93.7500 (93.4028) lr 7.8853e-06 eta 0:00:31
epoch [194/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.3076 (0.2743) acc 93.7500 (93.4375) lr 7.8853e-06 eta 0:00:30
epoch [195/200] batch [5/51] time 0.089 (0.213) data 0.000 (0.124) loss 0.2803 (0.3329) acc 96.8750 (95.6250) lr 6.0390e-06 eta 0:01:04
epoch [195/200] batch [10/51] time 0.087 (0.150) data 0.000 (0.062) loss 0.2362 (0.3293) acc 93.7500 (94.0625) lr 6.0390e-06 eta 0:00:44
epoch [195/200] batch [15/51] time 0.087 (0.129) data 0.000 (0.042) loss 0.2467 (0.2824) acc 90.6250 (94.5833) lr 6.0390e-06 eta 0:00:37
epoch [195/200] batch [20/51] time 0.087 (0.119) data 0.000 (0.031) loss 0.3291 (0.2803) acc 90.6250 (94.5312) lr 6.0390e-06 eta 0:00:33
epoch [195/200] batch [25/51] time 0.088 (0.113) data 0.000 (0.025) loss 0.2971 (0.2651) acc 90.6250 (94.7500) lr 6.0390e-06 eta 0:00:31
epoch [195/200] batch [30/51] time 0.088 (0.108) data 0.000 (0.021) loss 0.2625 (0.2711) acc 96.8750 (94.8958) lr 6.0390e-06 eta 0:00:29
epoch [195/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.1317 (0.2674) acc 96.8750 (94.8214) lr 6.0390e-06 eta 0:00:28
epoch [195/200] batch [40/51] time 0.085 (0.103) data 0.000 (0.016) loss 0.4661 (0.2802) acc 87.5000 (94.2969) lr 6.0390e-06 eta 0:00:27
epoch [195/200] batch [45/51] time 0.085 (0.101) data 0.000 (0.014) loss 0.1215 (0.2798) acc 96.8750 (94.3056) lr 6.0390e-06 eta 0:00:26
epoch [195/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1458 (0.2715) acc 93.7500 (94.3125) lr 6.0390e-06 eta 0:00:25
epoch [196/200] batch [5/51] time 0.087 (0.218) data 0.000 (0.131) loss 0.1459 (0.2312) acc 96.8750 (95.6250) lr 4.4380e-06 eta 0:00:54
epoch [196/200] batch [10/51] time 0.087 (0.153) data 0.000 (0.066) loss 0.4597 (0.2772) acc 81.2500 (93.1250) lr 4.4380e-06 eta 0:00:37
epoch [196/200] batch [15/51] time 0.087 (0.131) data 0.000 (0.044) loss 0.3301 (0.2799) acc 90.6250 (93.5417) lr 4.4380e-06 eta 0:00:31
epoch [196/200] batch [20/51] time 0.087 (0.120) data 0.000 (0.033) loss 0.3752 (0.3063) acc 87.5000 (92.6562) lr 4.4380e-06 eta 0:00:28
epoch [196/200] batch [25/51] time 0.087 (0.113) data 0.000 (0.026) loss 0.1692 (0.2927) acc 100.0000 (93.2500) lr 4.4380e-06 eta 0:00:26
epoch [196/200] batch [30/51] time 0.087 (0.109) data 0.000 (0.022) loss 0.5054 (0.2843) acc 84.3750 (93.4375) lr 4.4380e-06 eta 0:00:24
epoch [196/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.019) loss 0.4302 (0.2913) acc 90.6250 (93.3929) lr 4.4380e-06 eta 0:00:23
epoch [196/200] batch [40/51] time 0.086 (0.103) data 0.000 (0.017) loss 0.7285 (0.3039) acc 84.3750 (93.0469) lr 4.4380e-06 eta 0:00:22
epoch [196/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.015) loss 0.5181 (0.2976) acc 84.3750 (93.0556) lr 4.4380e-06 eta 0:00:21
epoch [196/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.013) loss 0.1552 (0.2925) acc 96.8750 (93.3125) lr 4.4380e-06 eta 0:00:20
epoch [197/200] batch [5/51] time 0.088 (0.210) data 0.000 (0.122) loss 0.1830 (0.3198) acc 100.0000 (93.1250) lr 3.0827e-06 eta 0:00:41
epoch [197/200] batch [10/51] time 0.088 (0.149) data 0.000 (0.061) loss 0.1691 (0.2795) acc 96.8750 (94.0625) lr 3.0827e-06 eta 0:00:28
epoch [197/200] batch [15/51] time 0.087 (0.128) data 0.000 (0.041) loss 0.2422 (0.2817) acc 90.6250 (93.5417) lr 3.0827e-06 eta 0:00:24
epoch [197/200] batch [20/51] time 0.087 (0.118) data 0.000 (0.031) loss 0.1884 (0.2414) acc 96.8750 (94.5312) lr 3.0827e-06 eta 0:00:21
epoch [197/200] batch [25/51] time 0.087 (0.112) data 0.000 (0.025) loss 0.5835 (0.2627) acc 87.5000 (94.1250) lr 3.0827e-06 eta 0:00:20
epoch [197/200] batch [30/51] time 0.087 (0.108) data 0.000 (0.021) loss 0.1520 (0.2587) acc 96.8750 (94.2708) lr 3.0827e-06 eta 0:00:18
epoch [197/200] batch [35/51] time 0.087 (0.105) data 0.000 (0.018) loss 0.2485 (0.2589) acc 93.7500 (94.0179) lr 3.0827e-06 eta 0:00:17
epoch [197/200] batch [40/51] time 0.087 (0.103) data 0.000 (0.016) loss 0.4021 (0.2659) acc 87.5000 (93.8281) lr 3.0827e-06 eta 0:00:16
epoch [197/200] batch [45/51] time 0.086 (0.101) data 0.000 (0.014) loss 0.2783 (0.2684) acc 96.8750 (93.7500) lr 3.0827e-06 eta 0:00:16
epoch [197/200] batch [50/51] time 0.086 (0.099) data 0.000 (0.012) loss 0.2371 (0.2713) acc 96.8750 (93.6875) lr 3.0827e-06 eta 0:00:15
epoch [198/200] batch [5/51] time 0.087 (0.224) data 0.000 (0.137) loss 0.2233 (0.2587) acc 93.7500 (95.0000) lr 1.9733e-06 eta 0:00:33
epoch [198/200] batch [10/51] time 0.087 (0.155) data 0.000 (0.069) loss 0.3281 (0.2764) acc 93.7500 (93.7500) lr 1.9733e-06 eta 0:00:22
epoch [198/200] batch [15/51] time 0.087 (0.132) data 0.000 (0.046) loss 0.4131 (0.3013) acc 90.6250 (92.9167) lr 1.9733e-06 eta 0:00:18
epoch [198/200] batch [20/51] time 0.086 (0.121) data 0.000 (0.034) loss 0.4385 (0.2938) acc 87.5000 (93.1250) lr 1.9733e-06 eta 0:00:16
epoch [198/200] batch [25/51] time 0.087 (0.114) data 0.000 (0.028) loss 0.2629 (0.2969) acc 96.8750 (93.1250) lr 1.9733e-06 eta 0:00:14
epoch [198/200] batch [30/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.1399 (0.2938) acc 96.8750 (93.2292) lr 1.9733e-06 eta 0:00:13
epoch [198/200] batch [35/51] time 0.087 (0.106) data 0.000 (0.020) loss 0.1804 (0.2888) acc 96.8750 (93.3036) lr 1.9733e-06 eta 0:00:12
epoch [198/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.017) loss 0.2981 (0.2856) acc 90.6250 (93.2812) lr 1.9733e-06 eta 0:00:11
epoch [198/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.015) loss 0.3015 (0.2858) acc 90.6250 (93.1250) lr 1.9733e-06 eta 0:00:10
epoch [198/200] batch [50/51] time 0.086 (0.100) data 0.000 (0.014) loss 0.2238 (0.2772) acc 93.7500 (93.4375) lr 1.9733e-06 eta 0:00:10
epoch [199/200] batch [5/51] time 0.087 (0.203) data 0.000 (0.115) loss 0.0811 (0.2219) acc 100.0000 (95.0000) lr 1.1101e-06 eta 0:00:19
epoch [199/200] batch [10/51] time 0.087 (0.145) data 0.000 (0.058) loss 0.1974 (0.2227) acc 93.7500 (94.3750) lr 1.1101e-06 eta 0:00:13
epoch [199/200] batch [15/51] time 0.087 (0.126) data 0.000 (0.039) loss 0.2744 (0.2323) acc 90.6250 (93.9583) lr 1.1101e-06 eta 0:00:10
epoch [199/200] batch [20/51] time 0.087 (0.116) data 0.000 (0.029) loss 0.1810 (0.2450) acc 96.8750 (94.2188) lr 1.1101e-06 eta 0:00:09
epoch [199/200] batch [25/51] time 0.088 (0.111) data 0.000 (0.023) loss 0.3235 (0.2458) acc 96.8750 (94.0000) lr 1.1101e-06 eta 0:00:08
epoch [199/200] batch [30/51] time 0.087 (0.107) data 0.000 (0.019) loss 0.4177 (0.2490) acc 90.6250 (94.0625) lr 1.1101e-06 eta 0:00:07
epoch [199/200] batch [35/51] time 0.087 (0.104) data 0.000 (0.017) loss 0.1787 (0.2475) acc 93.7500 (94.1964) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [40/51] time 0.085 (0.102) data 0.000 (0.015) loss 0.2271 (0.2451) acc 93.7500 (94.2969) lr 1.1101e-06 eta 0:00:06
epoch [199/200] batch [45/51] time 0.086 (0.100) data 0.000 (0.013) loss 0.1071 (0.2495) acc 100.0000 (94.1667) lr 1.1101e-06 eta 0:00:05
epoch [199/200] batch [50/51] time 0.086 (0.098) data 0.000 (0.012) loss 0.4731 (0.2617) acc 93.7500 (93.7500) lr 1.1101e-06 eta 0:00:05
epoch [200/200] batch [5/51] time 0.087 (0.226) data 0.000 (0.139) loss 0.3704 (0.2656) acc 87.5000 (92.5000) lr 4.9344e-07 eta 0:00:10
epoch [200/200] batch [10/51] time 0.087 (0.157) data 0.000 (0.070) loss 0.3457 (0.2868) acc 87.5000 (91.8750) lr 4.9344e-07 eta 0:00:06
epoch [200/200] batch [15/51] time 0.086 (0.133) data 0.000 (0.047) loss 0.5972 (0.2918) acc 87.5000 (92.0833) lr 4.9344e-07 eta 0:00:04
epoch [200/200] batch [20/51] time 0.088 (0.122) data 0.000 (0.035) loss 0.3906 (0.2693) acc 87.5000 (92.6562) lr 4.9344e-07 eta 0:00:03
epoch [200/200] batch [25/51] time 0.087 (0.115) data 0.000 (0.028) loss 0.4202 (0.2944) acc 87.5000 (92.2500) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [30/51] time 0.086 (0.110) data 0.000 (0.023) loss 0.2102 (0.2882) acc 93.7500 (92.5000) lr 4.9344e-07 eta 0:00:02
epoch [200/200] batch [35/51] time 0.087 (0.107) data 0.000 (0.020) loss 0.1720 (0.2803) acc 90.6250 (92.6786) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [40/51] time 0.085 (0.104) data 0.000 (0.018) loss 0.1635 (0.2640) acc 96.8750 (93.2812) lr 4.9344e-07 eta 0:00:01
epoch [200/200] batch [45/51] time 0.086 (0.102) data 0.000 (0.016) loss 0.2651 (0.2629) acc 90.6250 (93.2639) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [50/51] time 0.085 (0.100) data 0.000 (0.014) loss 0.2197 (0.2606) acc 93.7500 (93.5625) lr 4.9344e-07 eta 0:00:00
Checkpoint saved to output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:01<00:44,  1.84s/it]  8%|▊         | 2/25 [00:01<00:19,  1.20it/s] 12%|█▏        | 3/25 [00:02<00:11,  1.97it/s] 16%|█▌        | 4/25 [00:02<00:07,  2.81it/s] 20%|██        | 5/25 [00:02<00:05,  3.68it/s] 24%|██▍       | 6/25 [00:02<00:04,  4.51it/s] 28%|██▊       | 7/25 [00:02<00:03,  5.28it/s] 32%|███▏      | 8/25 [00:02<00:02,  5.94it/s] 36%|███▌      | 9/25 [00:02<00:02,  6.49it/s] 40%|████      | 10/25 [00:02<00:02,  6.91it/s] 44%|████▍     | 11/25 [00:03<00:01,  7.24it/s] 48%|████▊     | 12/25 [00:03<00:01,  7.49it/s] 52%|█████▏    | 13/25 [00:03<00:01,  7.67it/s] 56%|█████▌    | 14/25 [00:03<00:01,  7.80it/s] 60%|██████    | 15/25 [00:03<00:01,  7.90it/s] 64%|██████▍   | 16/25 [00:03<00:01,  7.96it/s] 68%|██████▊   | 17/25 [00:03<00:01,  6.14it/s] 72%|███████▏  | 18/25 [00:04<00:01,  6.63it/s] 76%|███████▌  | 19/25 [00:04<00:00,  7.03it/s] 80%|████████  | 20/25 [00:04<00:00,  7.34it/s] 84%|████████▍ | 21/25 [00:04<00:00,  7.57it/s] 88%|████████▊ | 22/25 [00:04<00:00,  7.74it/s] 92%|█████████▏| 23/25 [00:04<00:00,  7.87it/s] 96%|█████████▌| 24/25 [00:04<00:00,  7.95it/s]100%|██████████| 25/25 [00:04<00:00,  5.02it/s]
=> result
* total: 2,463
* correct: 2,367
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 95.8%
Elapsed: 0:17:14

for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat 
do
    for seed in 1 2 3
    do
        # evaluation
        sh scripts/coop/crossdataset_test.sh oxford_flowers ${dataset} ${seed} ${GPU} ${cfg} ${SHOT} ${EPOCH} ${TRAINER}
    done
done
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers imagenet 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/imagenet/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/imagenet/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:ImageNet
Loading dataset: ImageNet
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ImageNet/split_fewshot_taesup/shot_16-seed_1.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:03<30:59,  3.73s/it]  0%|          | 2/500 [00:04<14:10,  1.71s/it]  1%|          | 3/500 [00:04<08:47,  1.06s/it]  1%|          | 4/500 [00:04<06:17,  1.32it/s]  1%|          | 5/500 [00:04<04:53,  1.69it/s]  1%|          | 6/500 [00:05<04:03,  2.03it/s]  1%|▏         | 7/500 [00:05<03:31,  2.33it/s]  2%|▏         | 8/500 [00:05<03:10,  2.59it/s]  2%|▏         | 9/500 [00:06<02:55,  2.79it/s]  2%|▏         | 10/500 [00:06<02:46,  2.95it/s]  2%|▏         | 11/500 [00:06<02:39,  3.06it/s]  2%|▏         | 12/500 [00:06<02:35,  3.15it/s]  3%|▎         | 13/500 [00:07<02:31,  3.21it/s]  3%|▎         | 14/500 [00:07<02:29,  3.25it/s]  3%|▎         | 15/500 [00:07<02:27,  3.28it/s]  3%|▎         | 16/500 [00:08<02:26,  3.31it/s]  3%|▎         | 17/500 [00:08<02:25,  3.33it/s]  4%|▎         | 18/500 [00:08<02:24,  3.34it/s]  4%|▍         | 19/500 [00:09<02:23,  3.35it/s]  4%|▍         | 20/500 [00:09<02:23,  3.36it/s]  4%|▍         | 21/500 [00:09<02:22,  3.36it/s]  4%|▍         | 22/500 [00:09<02:22,  3.36it/s]  5%|▍         | 23/500 [00:10<02:21,  3.36it/s]  5%|▍         | 24/500 [00:10<02:21,  3.37it/s]  5%|▌         | 25/500 [00:10<02:21,  3.37it/s]  5%|▌         | 26/500 [00:11<02:20,  3.37it/s]  5%|▌         | 27/500 [00:11<02:20,  3.37it/s]  6%|▌         | 28/500 [00:11<02:19,  3.37it/s]  6%|▌         | 29/500 [00:12<02:19,  3.37it/s]  6%|▌         | 30/500 [00:12<02:19,  3.37it/s]  6%|▌         | 31/500 [00:12<02:19,  3.37it/s]  6%|▋         | 32/500 [00:12<02:18,  3.37it/s]  7%|▋         | 33/500 [00:13<02:18,  3.37it/s]  7%|▋         | 34/500 [00:13<02:18,  3.37it/s]  7%|▋         | 35/500 [00:13<02:18,  3.37it/s]  7%|▋         | 36/500 [00:14<02:17,  3.37it/s]  7%|▋         | 37/500 [00:14<02:17,  3.36it/s]  8%|▊         | 38/500 [00:14<02:17,  3.36it/s]  8%|▊         | 39/500 [00:15<02:17,  3.36it/s]  8%|▊         | 40/500 [00:15<02:16,  3.37it/s]  8%|▊         | 41/500 [00:15<02:16,  3.37it/s]  8%|▊         | 42/500 [00:15<02:15,  3.37it/s]  9%|▊         | 43/500 [00:16<02:15,  3.37it/s]  9%|▉         | 44/500 [00:16<02:15,  3.37it/s]  9%|▉         | 45/500 [00:16<02:15,  3.36it/s]  9%|▉         | 46/500 [00:17<02:15,  3.35it/s]  9%|▉         | 47/500 [00:17<02:15,  3.35it/s] 10%|▉         | 48/500 [00:17<02:14,  3.36it/s] 10%|▉         | 49/500 [00:17<02:14,  3.36it/s] 10%|█         | 50/500 [00:18<02:14,  3.35it/s] 10%|█         | 51/500 [00:18<02:13,  3.35it/s] 10%|█         | 52/500 [00:18<02:13,  3.36it/s] 11%|█         | 53/500 [00:19<02:12,  3.36it/s] 11%|█         | 54/500 [00:19<02:12,  3.37it/s] 11%|█         | 55/500 [00:19<02:12,  3.36it/s] 11%|█         | 56/500 [00:20<02:11,  3.37it/s] 11%|█▏        | 57/500 [00:20<02:11,  3.36it/s] 12%|█▏        | 58/500 [00:20<02:11,  3.36it/s] 12%|█▏        | 59/500 [00:20<02:11,  3.37it/s] 12%|█▏        | 60/500 [00:21<02:10,  3.37it/s] 12%|█▏        | 61/500 [00:21<02:10,  3.37it/s] 12%|█▏        | 62/500 [00:21<02:10,  3.37it/s] 13%|█▎        | 63/500 [00:22<02:09,  3.37it/s] 13%|█▎        | 64/500 [00:22<02:09,  3.37it/s] 13%|█▎        | 65/500 [00:22<02:09,  3.36it/s] 13%|█▎        | 66/500 [00:23<02:09,  3.36it/s] 13%|█▎        | 67/500 [00:23<02:08,  3.36it/s] 14%|█▎        | 68/500 [00:23<02:08,  3.36it/s] 14%|█▍        | 69/500 [00:23<02:08,  3.36it/s] 14%|█▍        | 70/500 [00:24<02:07,  3.36it/s] 14%|█▍        | 71/500 [00:24<02:07,  3.36it/s] 14%|█▍        | 72/500 [00:24<02:07,  3.36it/s] 15%|█▍        | 73/500 [00:25<02:06,  3.36it/s] 15%|█▍        | 74/500 [00:25<02:06,  3.36it/s] 15%|█▌        | 75/500 [00:25<02:06,  3.36it/s] 15%|█▌        | 76/500 [00:26<02:06,  3.36it/s] 15%|█▌        | 77/500 [00:26<02:05,  3.36it/s] 16%|█▌        | 78/500 [00:26<02:05,  3.36it/s] 16%|█▌        | 79/500 [00:26<02:05,  3.36it/s] 16%|█▌        | 80/500 [00:27<02:05,  3.36it/s] 16%|█▌        | 81/500 [00:27<02:04,  3.36it/s] 16%|█▋        | 82/500 [00:27<02:04,  3.36it/s] 17%|█▋        | 83/500 [00:28<02:04,  3.35it/s] 17%|█▋        | 84/500 [00:28<02:03,  3.36it/s] 17%|█▋        | 85/500 [00:28<02:03,  3.36it/s] 17%|█▋        | 86/500 [00:28<02:03,  3.36it/s] 17%|█▋        | 87/500 [00:29<02:02,  3.36it/s] 18%|█▊        | 88/500 [00:29<02:02,  3.36it/s] 18%|█▊        | 89/500 [00:29<02:02,  3.36it/s] 18%|█▊        | 90/500 [00:30<02:02,  3.36it/s] 18%|█▊        | 91/500 [00:30<02:01,  3.36it/s] 18%|█▊        | 92/500 [00:30<02:01,  3.36it/s] 19%|█▊        | 93/500 [00:31<02:01,  3.36it/s] 19%|█▉        | 94/500 [00:31<02:00,  3.36it/s] 19%|█▉        | 95/500 [00:31<02:00,  3.36it/s] 19%|█▉        | 96/500 [00:31<02:00,  3.36it/s] 19%|█▉        | 97/500 [00:32<01:59,  3.36it/s] 20%|█▉        | 98/500 [00:32<01:59,  3.36it/s] 20%|█▉        | 99/500 [00:32<01:59,  3.36it/s] 20%|██        | 100/500 [00:33<01:59,  3.36it/s] 20%|██        | 101/500 [00:33<01:58,  3.36it/s] 20%|██        | 102/500 [00:33<01:58,  3.36it/s] 21%|██        | 103/500 [00:34<01:58,  3.36it/s] 21%|██        | 104/500 [00:34<01:57,  3.36it/s] 21%|██        | 105/500 [00:34<01:57,  3.36it/s] 21%|██        | 106/500 [00:34<01:57,  3.36it/s] 21%|██▏       | 107/500 [00:35<01:57,  3.36it/s] 22%|██▏       | 108/500 [00:35<01:56,  3.36it/s] 22%|██▏       | 109/500 [00:35<01:56,  3.36it/s] 22%|██▏       | 110/500 [00:36<01:56,  3.35it/s] 22%|██▏       | 111/500 [00:36<01:56,  3.35it/s] 22%|██▏       | 112/500 [00:36<01:55,  3.35it/s] 23%|██▎       | 113/500 [00:37<01:55,  3.35it/s] 23%|██▎       | 114/500 [00:37<01:55,  3.35it/s] 23%|██▎       | 115/500 [00:37<01:54,  3.35it/s] 23%|██▎       | 116/500 [00:37<01:54,  3.35it/s] 23%|██▎       | 117/500 [00:38<01:54,  3.35it/s] 24%|██▎       | 118/500 [00:38<01:53,  3.36it/s] 24%|██▍       | 119/500 [00:38<01:53,  3.35it/s] 24%|██▍       | 120/500 [00:39<01:53,  3.35it/s] 24%|██▍       | 121/500 [00:39<01:53,  3.35it/s] 24%|██▍       | 122/500 [00:39<01:52,  3.35it/s] 25%|██▍       | 123/500 [00:40<01:52,  3.35it/s] 25%|██▍       | 124/500 [00:40<01:52,  3.35it/s] 25%|██▌       | 125/500 [00:40<01:51,  3.35it/s] 25%|██▌       | 126/500 [00:40<01:51,  3.35it/s] 25%|██▌       | 127/500 [00:41<01:51,  3.35it/s] 26%|██▌       | 128/500 [00:41<01:51,  3.35it/s] 26%|██▌       | 129/500 [00:41<01:50,  3.35it/s] 26%|██▌       | 130/500 [00:42<01:50,  3.35it/s] 26%|██▌       | 131/500 [00:42<01:50,  3.35it/s] 26%|██▋       | 132/500 [00:42<01:49,  3.35it/s] 27%|██▋       | 133/500 [00:42<01:49,  3.35it/s] 27%|██▋       | 134/500 [00:43<01:49,  3.35it/s] 27%|██▋       | 135/500 [00:43<01:49,  3.34it/s] 27%|██▋       | 136/500 [00:43<01:48,  3.34it/s] 27%|██▋       | 137/500 [00:44<01:48,  3.34it/s] 28%|██▊       | 138/500 [00:44<01:48,  3.34it/s] 28%|██▊       | 139/500 [00:44<01:47,  3.35it/s] 28%|██▊       | 140/500 [00:45<01:47,  3.35it/s] 28%|██▊       | 141/500 [00:45<01:47,  3.35it/s] 28%|██▊       | 142/500 [00:45<01:46,  3.35it/s] 29%|██▊       | 143/500 [00:45<01:46,  3.35it/s] 29%|██▉       | 144/500 [00:46<01:46,  3.35it/s] 29%|██▉       | 145/500 [00:46<01:46,  3.35it/s] 29%|██▉       | 146/500 [00:46<01:45,  3.35it/s] 29%|██▉       | 147/500 [00:47<01:45,  3.35it/s] 30%|██▉       | 148/500 [00:47<01:45,  3.35it/s] 30%|██▉       | 149/500 [00:47<01:44,  3.35it/s] 30%|███       | 150/500 [00:48<01:44,  3.35it/s] 30%|███       | 151/500 [00:48<01:44,  3.35it/s] 30%|███       | 152/500 [00:48<01:43,  3.35it/s] 31%|███       | 153/500 [00:48<01:43,  3.35it/s] 31%|███       | 154/500 [00:49<01:43,  3.35it/s] 31%|███       | 155/500 [00:49<01:42,  3.35it/s] 31%|███       | 156/500 [00:49<01:42,  3.35it/s] 31%|███▏      | 157/500 [00:50<01:42,  3.35it/s] 32%|███▏      | 158/500 [00:50<01:42,  3.35it/s] 32%|███▏      | 159/500 [00:50<01:41,  3.35it/s] 32%|███▏      | 160/500 [00:51<01:41,  3.35it/s] 32%|███▏      | 161/500 [00:51<01:41,  3.35it/s] 32%|███▏      | 162/500 [00:51<01:40,  3.35it/s] 33%|███▎      | 163/500 [00:51<01:40,  3.34it/s] 33%|███▎      | 164/500 [00:52<01:40,  3.34it/s] 33%|███▎      | 165/500 [00:52<01:40,  3.34it/s] 33%|███▎      | 166/500 [00:52<01:39,  3.34it/s] 33%|███▎      | 167/500 [00:53<01:39,  3.34it/s] 34%|███▎      | 168/500 [00:53<01:39,  3.34it/s] 34%|███▍      | 169/500 [00:53<01:39,  3.34it/s] 34%|███▍      | 170/500 [00:54<01:38,  3.34it/s] 34%|███▍      | 171/500 [00:54<01:38,  3.34it/s] 34%|███▍      | 172/500 [00:54<01:38,  3.34it/s] 35%|███▍      | 173/500 [00:54<01:37,  3.34it/s] 35%|███▍      | 174/500 [00:55<01:37,  3.34it/s] 35%|███▌      | 175/500 [00:55<01:37,  3.35it/s] 35%|███▌      | 176/500 [00:55<01:36,  3.35it/s] 35%|███▌      | 177/500 [00:56<01:36,  3.34it/s] 36%|███▌      | 178/500 [00:56<01:36,  3.34it/s] 36%|███▌      | 179/500 [00:56<01:36,  3.34it/s] 36%|███▌      | 180/500 [00:57<01:35,  3.34it/s] 36%|███▌      | 181/500 [00:57<01:35,  3.34it/s] 36%|███▋      | 182/500 [00:57<01:35,  3.34it/s] 37%|███▋      | 183/500 [00:57<01:34,  3.35it/s] 37%|███▋      | 184/500 [00:58<01:34,  3.34it/s] 37%|███▋      | 185/500 [00:58<01:34,  3.34it/s] 37%|███▋      | 186/500 [00:58<01:33,  3.34it/s] 37%|███▋      | 187/500 [00:59<01:33,  3.34it/s] 38%|███▊      | 188/500 [00:59<01:33,  3.34it/s] 38%|███▊      | 189/500 [00:59<01:32,  3.34it/s] 38%|███▊      | 190/500 [01:00<01:32,  3.35it/s] 38%|███▊      | 191/500 [01:00<01:32,  3.35it/s] 38%|███▊      | 192/500 [01:00<01:31,  3.35it/s] 39%|███▊      | 193/500 [01:00<01:31,  3.35it/s] 39%|███▉      | 194/500 [01:01<01:31,  3.35it/s] 39%|███▉      | 195/500 [01:01<01:31,  3.35it/s] 39%|███▉      | 196/500 [01:01<01:30,  3.35it/s] 39%|███▉      | 197/500 [01:02<01:30,  3.35it/s] 40%|███▉      | 198/500 [01:02<01:30,  3.35it/s] 40%|███▉      | 199/500 [01:02<01:29,  3.35it/s] 40%|████      | 200/500 [01:03<01:29,  3.35it/s] 40%|████      | 201/500 [01:03<01:29,  3.35it/s] 40%|████      | 202/500 [01:03<01:28,  3.35it/s] 41%|████      | 203/500 [01:03<01:28,  3.35it/s] 41%|████      | 204/500 [01:04<01:28,  3.35it/s] 41%|████      | 205/500 [01:04<01:28,  3.35it/s] 41%|████      | 206/500 [01:04<01:27,  3.35it/s] 41%|████▏     | 207/500 [01:05<01:27,  3.35it/s] 42%|████▏     | 208/500 [01:05<01:27,  3.34it/s] 42%|████▏     | 209/500 [01:05<01:27,  3.34it/s] 42%|████▏     | 210/500 [01:06<01:26,  3.35it/s] 42%|████▏     | 211/500 [01:06<01:26,  3.35it/s] 42%|████▏     | 212/500 [01:06<01:25,  3.35it/s] 43%|████▎     | 213/500 [01:06<01:25,  3.35it/s] 43%|████▎     | 214/500 [01:07<01:25,  3.35it/s] 43%|████▎     | 215/500 [01:07<01:25,  3.35it/s] 43%|████▎     | 216/500 [01:07<01:24,  3.35it/s] 43%|████▎     | 217/500 [01:08<01:24,  3.35it/s] 44%|████▎     | 218/500 [01:08<01:24,  3.35it/s] 44%|████▍     | 219/500 [01:08<01:23,  3.35it/s] 44%|████▍     | 220/500 [01:09<01:23,  3.35it/s] 44%|████▍     | 221/500 [01:09<01:23,  3.35it/s] 44%|████▍     | 222/500 [01:09<01:23,  3.34it/s] 45%|████▍     | 223/500 [01:09<01:22,  3.34it/s] 45%|████▍     | 224/500 [01:10<01:22,  3.34it/s] 45%|████▌     | 225/500 [01:10<01:22,  3.34it/s] 45%|████▌     | 226/500 [01:10<01:21,  3.34it/s] 45%|████▌     | 227/500 [01:11<01:21,  3.34it/s] 46%|████▌     | 228/500 [01:11<01:21,  3.35it/s] 46%|████▌     | 229/500 [01:11<01:21,  3.34it/s] 46%|████▌     | 230/500 [01:11<01:20,  3.34it/s] 46%|████▌     | 231/500 [01:12<01:20,  3.35it/s] 46%|████▋     | 232/500 [01:12<01:20,  3.35it/s] 47%|████▋     | 233/500 [01:12<01:19,  3.35it/s] 47%|████▋     | 234/500 [01:13<01:19,  3.35it/s] 47%|████▋     | 235/500 [01:13<01:19,  3.35it/s] 47%|████▋     | 236/500 [01:13<01:18,  3.35it/s] 47%|████▋     | 237/500 [01:14<01:18,  3.35it/s] 48%|████▊     | 238/500 [01:14<01:18,  3.33it/s] 48%|████▊     | 239/500 [01:14<01:18,  3.34it/s] 48%|████▊     | 240/500 [01:14<01:17,  3.34it/s] 48%|████▊     | 241/500 [01:15<01:17,  3.34it/s] 48%|████▊     | 242/500 [01:15<01:17,  3.34it/s] 49%|████▊     | 243/500 [01:15<01:16,  3.34it/s] 49%|████▉     | 244/500 [01:16<01:16,  3.34it/s] 49%|████▉     | 245/500 [01:16<01:16,  3.34it/s] 49%|████▉     | 246/500 [01:16<01:16,  3.34it/s] 49%|████▉     | 247/500 [01:17<01:15,  3.34it/s] 50%|████▉     | 248/500 [01:17<01:15,  3.34it/s] 50%|████▉     | 249/500 [01:17<01:15,  3.34it/s] 50%|█████     | 250/500 [01:17<01:14,  3.34it/s] 50%|█████     | 251/500 [01:18<01:14,  3.34it/s] 50%|█████     | 252/500 [01:18<01:14,  3.34it/s] 51%|█████     | 253/500 [01:18<01:13,  3.34it/s] 51%|█████     | 254/500 [01:19<01:13,  3.33it/s] 51%|█████     | 255/500 [01:19<01:13,  3.34it/s] 51%|█████     | 256/500 [01:19<01:13,  3.34it/s] 51%|█████▏    | 257/500 [01:20<01:12,  3.34it/s] 52%|█████▏    | 258/500 [01:20<01:12,  3.34it/s] 52%|█████▏    | 259/500 [01:20<01:12,  3.34it/s] 52%|█████▏    | 260/500 [01:20<01:11,  3.34it/s] 52%|█████▏    | 261/500 [01:21<01:11,  3.33it/s] 52%|█████▏    | 262/500 [01:21<01:11,  3.34it/s] 53%|█████▎    | 263/500 [01:21<01:11,  3.34it/s] 53%|█████▎    | 264/500 [01:22<01:10,  3.34it/s] 53%|█████▎    | 265/500 [01:22<01:10,  3.33it/s] 53%|█████▎    | 266/500 [01:22<01:10,  3.34it/s] 53%|█████▎    | 267/500 [01:23<01:09,  3.33it/s] 54%|█████▎    | 268/500 [01:23<01:09,  3.33it/s] 54%|█████▍    | 269/500 [01:23<01:09,  3.34it/s] 54%|█████▍    | 270/500 [01:23<01:09,  3.33it/s] 54%|█████▍    | 271/500 [01:24<01:08,  3.33it/s] 54%|█████▍    | 272/500 [01:24<01:08,  3.33it/s] 55%|█████▍    | 273/500 [01:24<01:08,  3.32it/s] 55%|█████▍    | 274/500 [01:25<01:07,  3.33it/s] 55%|█████▌    | 275/500 [01:25<01:07,  3.33it/s] 55%|█████▌    | 276/500 [01:25<01:07,  3.33it/s] 55%|█████▌    | 277/500 [01:26<01:06,  3.33it/s] 56%|█████▌    | 278/500 [01:26<01:06,  3.33it/s] 56%|█████▌    | 279/500 [01:26<01:06,  3.33it/s] 56%|█████▌    | 280/500 [01:26<01:06,  3.33it/s] 56%|█████▌    | 281/500 [01:27<01:05,  3.33it/s] 56%|█████▋    | 282/500 [01:27<01:05,  3.33it/s] 57%|█████▋    | 283/500 [01:27<01:05,  3.32it/s] 57%|█████▋    | 284/500 [01:28<01:04,  3.32it/s] 57%|█████▋    | 285/500 [01:28<01:04,  3.32it/s] 57%|█████▋    | 286/500 [01:28<01:04,  3.33it/s] 57%|█████▋    | 287/500 [01:29<01:03,  3.33it/s] 58%|█████▊    | 288/500 [01:29<01:03,  3.33it/s] 58%|█████▊    | 289/500 [01:29<01:03,  3.34it/s] 58%|█████▊    | 290/500 [01:29<01:02,  3.34it/s] 58%|█████▊    | 291/500 [01:30<01:02,  3.34it/s] 58%|█████▊    | 292/500 [01:30<01:02,  3.34it/s] 59%|█████▊    | 293/500 [01:30<01:01,  3.35it/s] 59%|█████▉    | 294/500 [01:31<01:01,  3.34it/s] 59%|█████▉    | 295/500 [01:31<01:01,  3.35it/s] 59%|█████▉    | 296/500 [01:31<01:00,  3.35it/s] 59%|█████▉    | 297/500 [01:32<01:00,  3.35it/s] 60%|█████▉    | 298/500 [01:32<01:00,  3.34it/s] 60%|█████▉    | 299/500 [01:32<01:00,  3.34it/s] 60%|██████    | 300/500 [01:32<00:59,  3.34it/s] 60%|██████    | 301/500 [01:33<00:59,  3.34it/s] 60%|██████    | 302/500 [01:33<00:59,  3.34it/s] 61%|██████    | 303/500 [01:33<00:58,  3.34it/s] 61%|██████    | 304/500 [01:34<00:58,  3.34it/s] 61%|██████    | 305/500 [01:34<00:58,  3.34it/s] 61%|██████    | 306/500 [01:34<00:58,  3.34it/s] 61%|██████▏   | 307/500 [01:35<00:57,  3.34it/s] 62%|██████▏   | 308/500 [01:35<00:57,  3.34it/s] 62%|██████▏   | 309/500 [01:35<00:57,  3.34it/s] 62%|██████▏   | 310/500 [01:35<00:56,  3.34it/s] 62%|██████▏   | 311/500 [01:36<00:56,  3.34it/s] 62%|██████▏   | 312/500 [01:36<00:56,  3.34it/s] 63%|██████▎   | 313/500 [01:36<00:55,  3.34it/s] 63%|██████▎   | 314/500 [01:37<00:55,  3.34it/s] 63%|██████▎   | 315/500 [01:37<00:55,  3.34it/s] 63%|██████▎   | 316/500 [01:37<00:55,  3.34it/s] 63%|██████▎   | 317/500 [01:38<00:54,  3.34it/s] 64%|██████▎   | 318/500 [01:38<00:54,  3.34it/s] 64%|██████▍   | 319/500 [01:38<00:54,  3.34it/s] 64%|██████▍   | 320/500 [01:38<00:53,  3.34it/s] 64%|██████▍   | 321/500 [01:39<00:53,  3.34it/s] 64%|██████▍   | 322/500 [01:39<00:53,  3.34it/s] 65%|██████▍   | 323/500 [01:39<00:52,  3.34it/s] 65%|██████▍   | 324/500 [01:40<00:52,  3.34it/s] 65%|██████▌   | 325/500 [01:40<00:52,  3.34it/s] 65%|██████▌   | 326/500 [01:40<00:52,  3.34it/s] 65%|██████▌   | 327/500 [01:41<00:51,  3.34it/s] 66%|██████▌   | 328/500 [01:41<00:51,  3.34it/s] 66%|██████▌   | 329/500 [01:41<00:51,  3.34it/s] 66%|██████▌   | 330/500 [01:41<00:50,  3.34it/s] 66%|██████▌   | 331/500 [01:42<00:50,  3.33it/s] 66%|██████▋   | 332/500 [01:42<00:50,  3.34it/s] 67%|██████▋   | 333/500 [01:42<00:50,  3.34it/s] 67%|██████▋   | 334/500 [01:43<00:49,  3.34it/s] 67%|██████▋   | 335/500 [01:43<00:49,  3.34it/s] 67%|██████▋   | 336/500 [01:43<00:49,  3.34it/s] 67%|██████▋   | 337/500 [01:44<00:48,  3.34it/s] 68%|██████▊   | 338/500 [01:44<00:48,  3.34it/s] 68%|██████▊   | 339/500 [01:44<00:48,  3.34it/s] 68%|██████▊   | 340/500 [01:44<00:47,  3.34it/s] 68%|██████▊   | 341/500 [01:45<00:47,  3.34it/s] 68%|██████▊   | 342/500 [01:45<00:47,  3.34it/s] 69%|██████▊   | 343/500 [01:45<00:46,  3.35it/s] 69%|██████▉   | 344/500 [01:46<00:46,  3.34it/s] 69%|██████▉   | 345/500 [01:46<00:46,  3.34it/s] 69%|██████▉   | 346/500 [01:46<00:46,  3.34it/s] 69%|██████▉   | 347/500 [01:47<00:45,  3.34it/s] 70%|██████▉   | 348/500 [01:47<00:45,  3.34it/s] 70%|██████▉   | 349/500 [01:47<00:45,  3.34it/s] 70%|███████   | 350/500 [01:47<00:44,  3.34it/s] 70%|███████   | 351/500 [01:48<00:44,  3.34it/s] 70%|███████   | 352/500 [01:48<00:44,  3.34it/s] 71%|███████   | 353/500 [01:48<00:44,  3.34it/s] 71%|███████   | 354/500 [01:49<00:43,  3.34it/s] 71%|███████   | 355/500 [01:49<00:43,  3.34it/s] 71%|███████   | 356/500 [01:49<00:43,  3.33it/s] 71%|███████▏  | 357/500 [01:50<00:42,  3.33it/s] 72%|███████▏  | 358/500 [01:50<00:42,  3.34it/s] 72%|███████▏  | 359/500 [01:50<00:42,  3.34it/s] 72%|███████▏  | 360/500 [01:50<00:41,  3.34it/s] 72%|███████▏  | 361/500 [01:51<00:41,  3.34it/s] 72%|███████▏  | 362/500 [01:51<00:41,  3.34it/s] 73%|███████▎  | 363/500 [01:51<00:41,  3.34it/s] 73%|███████▎  | 364/500 [01:52<00:40,  3.34it/s] 73%|███████▎  | 365/500 [01:52<00:40,  3.34it/s] 73%|███████▎  | 366/500 [01:52<00:40,  3.34it/s] 73%|███████▎  | 367/500 [01:53<00:39,  3.34it/s] 74%|███████▎  | 368/500 [01:53<00:39,  3.34it/s] 74%|███████▍  | 369/500 [01:53<00:39,  3.34it/s] 74%|███████▍  | 370/500 [01:53<00:38,  3.34it/s] 74%|███████▍  | 371/500 [01:54<00:38,  3.34it/s] 74%|███████▍  | 372/500 [01:54<00:38,  3.34it/s] 75%|███████▍  | 373/500 [01:54<00:38,  3.34it/s] 75%|███████▍  | 374/500 [01:55<00:37,  3.34it/s] 75%|███████▌  | 375/500 [01:55<00:37,  3.33it/s] 75%|███████▌  | 376/500 [01:55<00:37,  3.33it/s] 75%|███████▌  | 377/500 [01:56<00:36,  3.34it/s] 76%|███████▌  | 378/500 [01:56<00:36,  3.34it/s] 76%|███████▌  | 379/500 [01:56<00:36,  3.34it/s] 76%|███████▌  | 380/500 [01:56<00:35,  3.34it/s] 76%|███████▌  | 381/500 [01:57<00:35,  3.34it/s] 76%|███████▋  | 382/500 [01:57<00:35,  3.34it/s] 77%|███████▋  | 383/500 [01:57<00:35,  3.33it/s] 77%|███████▋  | 384/500 [01:58<00:34,  3.33it/s] 77%|███████▋  | 385/500 [01:58<00:34,  3.34it/s] 77%|███████▋  | 386/500 [01:58<00:34,  3.34it/s] 77%|███████▋  | 387/500 [01:59<00:33,  3.34it/s] 78%|███████▊  | 388/500 [01:59<00:33,  3.34it/s] 78%|███████▊  | 389/500 [01:59<00:33,  3.34it/s] 78%|███████▊  | 390/500 [01:59<00:32,  3.34it/s] 78%|███████▊  | 391/500 [02:00<00:32,  3.34it/s] 78%|███████▊  | 392/500 [02:00<00:32,  3.33it/s] 79%|███████▊  | 393/500 [02:00<00:32,  3.33it/s] 79%|███████▉  | 394/500 [02:01<00:31,  3.33it/s] 79%|███████▉  | 395/500 [02:01<00:31,  3.33it/s] 79%|███████▉  | 396/500 [02:01<00:31,  3.34it/s] 79%|███████▉  | 397/500 [02:02<00:30,  3.34it/s] 80%|███████▉  | 398/500 [02:02<00:30,  3.34it/s] 80%|███████▉  | 399/500 [02:02<00:30,  3.34it/s] 80%|████████  | 400/500 [02:02<00:29,  3.34it/s] 80%|████████  | 401/500 [02:03<00:29,  3.34it/s] 80%|████████  | 402/500 [02:03<00:29,  3.34it/s] 81%|████████  | 403/500 [02:03<00:29,  3.34it/s] 81%|████████  | 404/500 [02:04<00:28,  3.34it/s] 81%|████████  | 405/500 [02:04<00:28,  3.34it/s] 81%|████████  | 406/500 [02:04<00:28,  3.34it/s] 81%|████████▏ | 407/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 408/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 409/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 410/500 [02:05<00:26,  3.34it/s] 82%|████████▏ | 411/500 [02:06<00:26,  3.34it/s] 82%|████████▏ | 412/500 [02:06<00:26,  3.34it/s] 83%|████████▎ | 413/500 [02:06<00:26,  3.34it/s] 83%|████████▎ | 414/500 [02:07<00:25,  3.34it/s] 83%|████████▎ | 415/500 [02:07<00:25,  3.34it/s] 83%|████████▎ | 416/500 [02:07<00:25,  3.34it/s] 83%|████████▎ | 417/500 [02:08<00:24,  3.34it/s] 84%|████████▎ | 418/500 [02:08<00:24,  3.34it/s] 84%|████████▍ | 419/500 [02:08<00:24,  3.35it/s] 84%|████████▍ | 420/500 [02:08<00:23,  3.35it/s] 84%|████████▍ | 421/500 [02:09<00:23,  3.34it/s] 84%|████████▍ | 422/500 [02:09<00:23,  3.34it/s] 85%|████████▍ | 423/500 [02:09<00:23,  3.34it/s] 85%|████████▍ | 424/500 [02:10<00:22,  3.34it/s] 85%|████████▌ | 425/500 [02:10<00:22,  3.34it/s] 85%|████████▌ | 426/500 [02:10<00:22,  3.34it/s] 85%|████████▌ | 427/500 [02:10<00:21,  3.33it/s] 86%|████████▌ | 428/500 [02:11<00:21,  3.34it/s] 86%|████████▌ | 429/500 [02:11<00:21,  3.34it/s] 86%|████████▌ | 430/500 [02:11<00:20,  3.34it/s] 86%|████████▌ | 431/500 [02:12<00:20,  3.34it/s] 86%|████████▋ | 432/500 [02:12<00:20,  3.34it/s] 87%|████████▋ | 433/500 [02:12<00:20,  3.34it/s] 87%|████████▋ | 434/500 [02:13<00:19,  3.34it/s] 87%|████████▋ | 435/500 [02:13<00:19,  3.34it/s] 87%|████████▋ | 436/500 [02:13<00:19,  3.34it/s] 87%|████████▋ | 437/500 [02:13<00:18,  3.34it/s] 88%|████████▊ | 438/500 [02:14<00:18,  3.34it/s] 88%|████████▊ | 439/500 [02:14<00:18,  3.34it/s] 88%|████████▊ | 440/500 [02:14<00:17,  3.34it/s] 88%|████████▊ | 441/500 [02:15<00:17,  3.34it/s] 88%|████████▊ | 442/500 [02:15<00:17,  3.34it/s] 89%|████████▊ | 443/500 [02:15<00:17,  3.34it/s] 89%|████████▉ | 444/500 [02:16<00:16,  3.34it/s] 89%|████████▉ | 445/500 [02:16<00:16,  3.34it/s] 89%|████████▉ | 446/500 [02:16<00:16,  3.34it/s] 89%|████████▉ | 447/500 [02:16<00:15,  3.34it/s] 90%|████████▉ | 448/500 [02:17<00:15,  3.34it/s] 90%|████████▉ | 449/500 [02:17<00:15,  3.34it/s] 90%|█████████ | 450/500 [02:17<00:14,  3.34it/s] 90%|█████████ | 451/500 [02:18<00:14,  3.35it/s] 90%|█████████ | 452/500 [02:18<00:14,  3.35it/s] 91%|█████████ | 453/500 [02:18<00:14,  3.34it/s] 91%|█████████ | 454/500 [02:19<00:13,  3.35it/s] 91%|█████████ | 455/500 [02:19<00:13,  3.34it/s] 91%|█████████ | 456/500 [02:19<00:13,  3.34it/s] 91%|█████████▏| 457/500 [02:19<00:12,  3.34it/s] 92%|█████████▏| 458/500 [02:20<00:12,  3.34it/s] 92%|█████████▏| 459/500 [02:20<00:12,  3.34it/s] 92%|█████████▏| 460/500 [02:20<00:11,  3.34it/s] 92%|█████████▏| 461/500 [02:21<00:11,  3.34it/s] 92%|█████████▏| 462/500 [02:21<00:11,  3.34it/s] 93%|█████████▎| 463/500 [02:21<00:11,  3.34it/s] 93%|█████████▎| 464/500 [02:22<00:10,  3.34it/s] 93%|█████████▎| 465/500 [02:22<00:10,  3.34it/s] 93%|█████████▎| 466/500 [02:22<00:10,  3.34it/s] 93%|█████████▎| 467/500 [02:22<00:09,  3.34it/s] 94%|█████████▎| 468/500 [02:23<00:09,  3.34it/s] 94%|█████████▍| 469/500 [02:23<00:09,  3.34it/s] 94%|█████████▍| 470/500 [02:23<00:08,  3.34it/s] 94%|█████████▍| 471/500 [02:24<00:08,  3.34it/s] 94%|█████████▍| 472/500 [02:24<00:08,  3.34it/s] 95%|█████████▍| 473/500 [02:24<00:08,  3.34it/s] 95%|█████████▍| 474/500 [02:25<00:07,  3.34it/s] 95%|█████████▌| 475/500 [02:25<00:07,  3.34it/s] 95%|█████████▌| 476/500 [02:25<00:07,  3.34it/s] 95%|█████████▌| 477/500 [02:25<00:06,  3.34it/s] 96%|█████████▌| 478/500 [02:26<00:06,  3.34it/s] 96%|█████████▌| 479/500 [02:26<00:06,  3.34it/s] 96%|█████████▌| 480/500 [02:26<00:05,  3.34it/s] 96%|█████████▌| 481/500 [02:27<00:05,  3.34it/s] 96%|█████████▋| 482/500 [02:27<00:05,  3.34it/s] 97%|█████████▋| 483/500 [02:27<00:05,  3.34it/s] 97%|█████████▋| 484/500 [02:28<00:04,  3.34it/s] 97%|█████████▋| 485/500 [02:28<00:04,  3.34it/s] 97%|█████████▋| 486/500 [02:28<00:04,  3.34it/s] 97%|█████████▋| 487/500 [02:28<00:03,  3.35it/s] 98%|█████████▊| 488/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 489/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 490/500 [02:29<00:02,  3.35it/s] 98%|█████████▊| 491/500 [02:30<00:02,  3.35it/s] 98%|█████████▊| 492/500 [02:30<00:02,  3.35it/s] 99%|█████████▊| 493/500 [02:30<00:02,  3.35it/s] 99%|█████████▉| 494/500 [02:31<00:01,  3.35it/s] 99%|█████████▉| 495/500 [02:31<00:01,  3.35it/s] 99%|█████████▉| 496/500 [02:31<00:01,  3.36it/s] 99%|█████████▉| 497/500 [02:31<00:00,  3.36it/s]100%|█████████▉| 498/500 [02:32<00:00,  3.35it/s]100%|█████████▉| 499/500 [02:32<00:00,  3.35it/s]100%|██████████| 500/500 [02:32<00:00,  3.36it/s]100%|██████████| 500/500 [02:32<00:00,  3.27it/s]
=> result
* total: 50,000
* correct: 20,419
* accuracy: 40.8%
* error: 59.2%
* macro_f1: 37.1%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers imagenet 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/imagenet/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/imagenet/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:ImageNet
Loading dataset: ImageNet
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ImageNet/split_fewshot_taesup/shot_16-seed_2.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:04<33:20,  4.01s/it]  0%|          | 2/500 [00:04<15:08,  1.82s/it]  1%|          | 3/500 [00:04<09:19,  1.13s/it]  1%|          | 4/500 [00:04<06:36,  1.25it/s]  1%|          | 5/500 [00:05<05:05,  1.62it/s]  1%|          | 6/500 [00:05<04:11,  1.97it/s]  1%|▏         | 7/500 [00:05<03:36,  2.28it/s]  2%|▏         | 8/500 [00:06<03:13,  2.54it/s]  2%|▏         | 9/500 [00:06<02:58,  2.75it/s]  2%|▏         | 10/500 [00:06<02:47,  2.92it/s]  2%|▏         | 11/500 [00:06<02:40,  3.05it/s]  2%|▏         | 12/500 [00:07<02:35,  3.14it/s]  3%|▎         | 13/500 [00:07<02:31,  3.21it/s]  3%|▎         | 14/500 [00:07<02:28,  3.26it/s]  3%|▎         | 15/500 [00:08<02:27,  3.29it/s]  3%|▎         | 16/500 [00:08<02:26,  3.31it/s]  3%|▎         | 17/500 [00:08<02:25,  3.33it/s]  4%|▎         | 18/500 [00:09<02:24,  3.34it/s]  4%|▍         | 19/500 [00:09<02:23,  3.35it/s]  4%|▍         | 20/500 [00:09<02:22,  3.36it/s]  4%|▍         | 21/500 [00:09<02:22,  3.36it/s]  4%|▍         | 22/500 [00:10<02:22,  3.36it/s]  5%|▍         | 23/500 [00:10<02:22,  3.35it/s]  5%|▍         | 24/500 [00:10<02:22,  3.35it/s]  5%|▌         | 25/500 [00:11<02:21,  3.35it/s]  5%|▌         | 26/500 [00:11<02:21,  3.35it/s]  5%|▌         | 27/500 [00:11<02:20,  3.35it/s]  6%|▌         | 28/500 [00:12<02:20,  3.36it/s]  6%|▌         | 29/500 [00:12<02:20,  3.36it/s]  6%|▌         | 30/500 [00:12<02:19,  3.36it/s]  6%|▌         | 31/500 [00:12<02:19,  3.36it/s]  6%|▋         | 32/500 [00:13<02:19,  3.37it/s]  7%|▋         | 33/500 [00:13<02:18,  3.36it/s]  7%|▋         | 34/500 [00:13<02:18,  3.36it/s]  7%|▋         | 35/500 [00:14<02:18,  3.36it/s]  7%|▋         | 36/500 [00:14<02:18,  3.36it/s]  7%|▋         | 37/500 [00:14<02:17,  3.36it/s]  8%|▊         | 38/500 [00:14<02:17,  3.36it/s]  8%|▊         | 39/500 [00:15<02:17,  3.36it/s]  8%|▊         | 40/500 [00:15<02:16,  3.36it/s]  8%|▊         | 41/500 [00:15<02:16,  3.36it/s]  8%|▊         | 42/500 [00:16<02:16,  3.36it/s]  9%|▊         | 43/500 [00:16<02:16,  3.36it/s]  9%|▉         | 44/500 [00:16<02:15,  3.36it/s]  9%|▉         | 45/500 [00:17<02:15,  3.36it/s]  9%|▉         | 46/500 [00:17<02:15,  3.36it/s]  9%|▉         | 47/500 [00:17<02:14,  3.36it/s] 10%|▉         | 48/500 [00:17<02:14,  3.36it/s] 10%|▉         | 49/500 [00:18<02:14,  3.36it/s] 10%|█         | 50/500 [00:18<02:14,  3.36it/s] 10%|█         | 51/500 [00:18<02:13,  3.35it/s] 10%|█         | 52/500 [00:19<02:13,  3.35it/s] 11%|█         | 53/500 [00:19<02:13,  3.36it/s] 11%|█         | 54/500 [00:19<02:13,  3.35it/s] 11%|█         | 55/500 [00:20<02:12,  3.35it/s] 11%|█         | 56/500 [00:20<02:12,  3.36it/s] 11%|█▏        | 57/500 [00:20<02:12,  3.35it/s] 12%|█▏        | 58/500 [00:20<02:11,  3.35it/s] 12%|█▏        | 59/500 [00:21<02:11,  3.35it/s] 12%|█▏        | 60/500 [00:21<02:11,  3.35it/s] 12%|█▏        | 61/500 [00:21<02:10,  3.35it/s] 12%|█▏        | 62/500 [00:22<02:10,  3.35it/s] 13%|█▎        | 63/500 [00:22<02:10,  3.36it/s] 13%|█▎        | 64/500 [00:22<02:09,  3.36it/s] 13%|█▎        | 65/500 [00:23<02:09,  3.36it/s] 13%|█▎        | 66/500 [00:23<02:09,  3.36it/s] 13%|█▎        | 67/500 [00:23<02:08,  3.36it/s] 14%|█▎        | 68/500 [00:23<02:08,  3.36it/s] 14%|█▍        | 69/500 [00:24<02:08,  3.36it/s] 14%|█▍        | 70/500 [00:24<02:07,  3.36it/s] 14%|█▍        | 71/500 [00:24<02:07,  3.36it/s] 14%|█▍        | 72/500 [00:25<02:07,  3.36it/s] 15%|█▍        | 73/500 [00:25<02:07,  3.36it/s] 15%|█▍        | 74/500 [00:25<02:06,  3.36it/s] 15%|█▌        | 75/500 [00:26<02:07,  3.35it/s] 15%|█▌        | 76/500 [00:26<02:06,  3.34it/s] 15%|█▌        | 77/500 [00:26<02:06,  3.34it/s] 16%|█▌        | 78/500 [00:26<02:06,  3.35it/s] 16%|█▌        | 79/500 [00:27<02:05,  3.35it/s] 16%|█▌        | 80/500 [00:27<02:05,  3.35it/s] 16%|█▌        | 81/500 [00:27<02:05,  3.35it/s] 16%|█▋        | 82/500 [00:28<02:04,  3.35it/s] 17%|█▋        | 83/500 [00:28<02:04,  3.35it/s] 17%|█▋        | 84/500 [00:28<02:04,  3.35it/s] 17%|█▋        | 85/500 [00:29<02:03,  3.35it/s] 17%|█▋        | 86/500 [00:29<02:03,  3.35it/s] 17%|█▋        | 87/500 [00:29<02:03,  3.35it/s] 18%|█▊        | 88/500 [00:29<02:03,  3.35it/s] 18%|█▊        | 89/500 [00:30<02:02,  3.35it/s] 18%|█▊        | 90/500 [00:30<02:02,  3.35it/s] 18%|█▊        | 91/500 [00:30<02:02,  3.35it/s] 18%|█▊        | 92/500 [00:31<02:01,  3.35it/s] 19%|█▊        | 93/500 [00:31<02:01,  3.35it/s] 19%|█▉        | 94/500 [00:31<02:01,  3.34it/s] 19%|█▉        | 95/500 [00:31<02:01,  3.33it/s] 19%|█▉        | 96/500 [00:32<02:01,  3.34it/s] 19%|█▉        | 97/500 [00:32<02:00,  3.34it/s] 20%|█▉        | 98/500 [00:32<02:00,  3.35it/s] 20%|█▉        | 99/500 [00:33<01:59,  3.35it/s] 20%|██        | 100/500 [00:33<01:59,  3.35it/s] 20%|██        | 101/500 [00:33<01:59,  3.34it/s] 20%|██        | 102/500 [00:34<01:59,  3.34it/s] 21%|██        | 103/500 [00:34<01:58,  3.34it/s] 21%|██        | 104/500 [00:34<01:58,  3.34it/s] 21%|██        | 105/500 [00:34<01:58,  3.34it/s] 21%|██        | 106/500 [00:35<01:57,  3.35it/s] 21%|██▏       | 107/500 [00:35<01:57,  3.35it/s] 22%|██▏       | 108/500 [00:35<01:57,  3.35it/s] 22%|██▏       | 109/500 [00:36<01:56,  3.35it/s] 22%|██▏       | 110/500 [00:36<01:56,  3.35it/s] 22%|██▏       | 111/500 [00:36<01:56,  3.35it/s] 22%|██▏       | 112/500 [00:37<01:55,  3.35it/s] 23%|██▎       | 113/500 [00:37<01:55,  3.34it/s] 23%|██▎       | 114/500 [00:37<01:55,  3.34it/s] 23%|██▎       | 115/500 [00:37<01:55,  3.35it/s] 23%|██▎       | 116/500 [00:38<01:54,  3.34it/s] 23%|██▎       | 117/500 [00:38<01:54,  3.35it/s] 24%|██▎       | 118/500 [00:38<01:54,  3.34it/s] 24%|██▍       | 119/500 [00:39<01:53,  3.34it/s] 24%|██▍       | 120/500 [00:39<01:53,  3.34it/s] 24%|██▍       | 121/500 [00:39<01:53,  3.34it/s] 24%|██▍       | 122/500 [00:40<01:53,  3.34it/s] 25%|██▍       | 123/500 [00:40<01:52,  3.35it/s] 25%|██▍       | 124/500 [00:40<01:52,  3.34it/s] 25%|██▌       | 125/500 [00:40<01:52,  3.35it/s] 25%|██▌       | 126/500 [00:41<01:51,  3.35it/s] 25%|██▌       | 127/500 [00:41<01:51,  3.35it/s] 26%|██▌       | 128/500 [00:41<01:51,  3.35it/s] 26%|██▌       | 129/500 [00:42<01:50,  3.35it/s] 26%|██▌       | 130/500 [00:42<01:50,  3.35it/s] 26%|██▌       | 131/500 [00:42<01:50,  3.35it/s] 26%|██▋       | 132/500 [00:43<01:49,  3.35it/s] 27%|██▋       | 133/500 [00:43<01:49,  3.35it/s] 27%|██▋       | 134/500 [00:43<01:49,  3.35it/s] 27%|██▋       | 135/500 [00:43<01:49,  3.35it/s] 27%|██▋       | 136/500 [00:44<01:48,  3.34it/s] 27%|██▋       | 137/500 [00:44<01:48,  3.34it/s] 28%|██▊       | 138/500 [00:44<01:48,  3.34it/s] 28%|██▊       | 139/500 [00:45<01:47,  3.34it/s] 28%|██▊       | 140/500 [00:45<01:47,  3.34it/s] 28%|██▊       | 141/500 [00:45<01:47,  3.35it/s] 28%|██▊       | 142/500 [00:46<01:46,  3.35it/s] 29%|██▊       | 143/500 [00:46<01:46,  3.35it/s] 29%|██▉       | 144/500 [00:46<01:46,  3.35it/s] 29%|██▉       | 145/500 [00:46<01:46,  3.35it/s] 29%|██▉       | 146/500 [00:47<01:45,  3.35it/s] 29%|██▉       | 147/500 [00:47<01:45,  3.34it/s] 30%|██▉       | 148/500 [00:47<01:45,  3.34it/s] 30%|██▉       | 149/500 [00:48<01:44,  3.35it/s] 30%|███       | 150/500 [00:48<01:44,  3.35it/s] 30%|███       | 151/500 [00:48<01:44,  3.35it/s] 30%|███       | 152/500 [00:49<01:43,  3.35it/s] 31%|███       | 153/500 [00:49<01:43,  3.35it/s] 31%|███       | 154/500 [00:49<01:43,  3.34it/s] 31%|███       | 155/500 [00:49<01:43,  3.34it/s] 31%|███       | 156/500 [00:50<01:42,  3.34it/s] 31%|███▏      | 157/500 [00:50<01:42,  3.34it/s] 32%|███▏      | 158/500 [00:50<01:42,  3.34it/s] 32%|███▏      | 159/500 [00:51<01:41,  3.34it/s] 32%|███▏      | 160/500 [00:51<01:41,  3.34it/s] 32%|███▏      | 161/500 [00:51<01:41,  3.34it/s] 32%|███▏      | 162/500 [00:52<01:41,  3.35it/s] 33%|███▎      | 163/500 [00:52<01:40,  3.35it/s] 33%|███▎      | 164/500 [00:52<01:40,  3.34it/s] 33%|███▎      | 165/500 [00:52<01:40,  3.35it/s] 33%|███▎      | 166/500 [00:53<01:39,  3.35it/s] 33%|███▎      | 167/500 [00:53<01:39,  3.35it/s] 34%|███▎      | 168/500 [00:53<01:39,  3.35it/s] 34%|███▍      | 169/500 [00:54<01:38,  3.35it/s] 34%|███▍      | 170/500 [00:54<01:38,  3.35it/s] 34%|███▍      | 171/500 [00:54<01:38,  3.35it/s] 34%|███▍      | 172/500 [00:55<01:38,  3.35it/s] 35%|███▍      | 173/500 [00:55<01:37,  3.35it/s] 35%|███▍      | 174/500 [00:55<01:37,  3.35it/s] 35%|███▌      | 175/500 [00:55<01:37,  3.34it/s] 35%|███▌      | 176/500 [00:56<01:36,  3.34it/s] 35%|███▌      | 177/500 [00:56<01:36,  3.34it/s] 36%|███▌      | 178/500 [00:56<01:36,  3.34it/s] 36%|███▌      | 179/500 [00:57<01:35,  3.34it/s] 36%|███▌      | 180/500 [00:57<01:35,  3.34it/s] 36%|███▌      | 181/500 [00:57<01:35,  3.35it/s] 36%|███▋      | 182/500 [00:57<01:35,  3.34it/s] 37%|███▋      | 183/500 [00:58<01:34,  3.35it/s] 37%|███▋      | 184/500 [00:58<01:34,  3.35it/s] 37%|███▋      | 185/500 [00:58<01:34,  3.35it/s] 37%|███▋      | 186/500 [00:59<01:33,  3.35it/s] 37%|███▋      | 187/500 [00:59<01:33,  3.35it/s] 38%|███▊      | 188/500 [00:59<01:33,  3.35it/s] 38%|███▊      | 189/500 [01:00<01:32,  3.35it/s] 38%|███▊      | 190/500 [01:00<01:32,  3.35it/s] 38%|███▊      | 191/500 [01:00<01:32,  3.35it/s] 38%|███▊      | 192/500 [01:00<01:31,  3.35it/s] 39%|███▊      | 193/500 [01:01<01:31,  3.35it/s] 39%|███▉      | 194/500 [01:01<01:31,  3.35it/s] 39%|███▉      | 195/500 [01:01<01:31,  3.35it/s] 39%|███▉      | 196/500 [01:02<01:30,  3.35it/s] 39%|███▉      | 197/500 [01:02<01:30,  3.35it/s] 40%|███▉      | 198/500 [01:02<01:30,  3.35it/s] 40%|███▉      | 199/500 [01:03<01:30,  3.34it/s] 40%|████      | 200/500 [01:03<01:29,  3.35it/s] 40%|████      | 201/500 [01:03<01:29,  3.35it/s] 40%|████      | 202/500 [01:03<01:29,  3.34it/s] 41%|████      | 203/500 [01:04<01:28,  3.34it/s] 41%|████      | 204/500 [01:04<01:28,  3.34it/s] 41%|████      | 205/500 [01:04<01:28,  3.35it/s] 41%|████      | 206/500 [01:05<01:27,  3.35it/s] 41%|████▏     | 207/500 [01:05<01:27,  3.35it/s] 42%|████▏     | 208/500 [01:05<01:27,  3.34it/s] 42%|████▏     | 209/500 [01:06<01:26,  3.35it/s] 42%|████▏     | 210/500 [01:06<01:26,  3.35it/s] 42%|████▏     | 211/500 [01:06<01:26,  3.35it/s] 42%|████▏     | 212/500 [01:06<01:26,  3.35it/s] 43%|████▎     | 213/500 [01:07<01:25,  3.34it/s] 43%|████▎     | 214/500 [01:07<01:25,  3.34it/s] 43%|████▎     | 215/500 [01:07<01:25,  3.34it/s] 43%|████▎     | 216/500 [01:08<01:24,  3.34it/s] 43%|████▎     | 217/500 [01:08<01:24,  3.34it/s] 44%|████▎     | 218/500 [01:08<01:24,  3.34it/s] 44%|████▍     | 219/500 [01:09<01:24,  3.34it/s] 44%|████▍     | 220/500 [01:09<01:23,  3.34it/s] 44%|████▍     | 221/500 [01:09<01:23,  3.34it/s] 44%|████▍     | 222/500 [01:09<01:23,  3.34it/s] 45%|████▍     | 223/500 [01:10<01:22,  3.34it/s] 45%|████▍     | 224/500 [01:10<01:22,  3.34it/s] 45%|████▌     | 225/500 [01:10<01:22,  3.34it/s] 45%|████▌     | 226/500 [01:11<01:22,  3.34it/s] 45%|████▌     | 227/500 [01:11<01:21,  3.34it/s] 46%|████▌     | 228/500 [01:11<01:21,  3.34it/s] 46%|████▌     | 229/500 [01:12<01:21,  3.34it/s] 46%|████▌     | 230/500 [01:12<01:20,  3.34it/s] 46%|████▌     | 231/500 [01:12<01:20,  3.34it/s] 46%|████▋     | 232/500 [01:12<01:20,  3.34it/s] 47%|████▋     | 233/500 [01:13<01:19,  3.34it/s] 47%|████▋     | 234/500 [01:13<01:19,  3.34it/s] 47%|████▋     | 235/500 [01:13<01:19,  3.34it/s] 47%|████▋     | 236/500 [01:14<01:19,  3.34it/s] 47%|████▋     | 237/500 [01:14<01:18,  3.34it/s] 48%|████▊     | 238/500 [01:14<01:18,  3.34it/s] 48%|████▊     | 239/500 [01:15<01:18,  3.34it/s] 48%|████▊     | 240/500 [01:15<01:17,  3.34it/s] 48%|████▊     | 241/500 [01:15<01:17,  3.34it/s] 48%|████▊     | 242/500 [01:15<01:17,  3.34it/s] 49%|████▊     | 243/500 [01:16<01:17,  3.33it/s] 49%|████▉     | 244/500 [01:16<01:16,  3.34it/s] 49%|████▉     | 245/500 [01:16<01:16,  3.34it/s] 49%|████▉     | 246/500 [01:17<01:16,  3.34it/s] 49%|████▉     | 247/500 [01:17<01:15,  3.34it/s] 50%|████▉     | 248/500 [01:17<01:15,  3.34it/s] 50%|████▉     | 249/500 [01:18<01:15,  3.34it/s] 50%|█████     | 250/500 [01:18<01:14,  3.34it/s] 50%|█████     | 251/500 [01:18<01:14,  3.34it/s] 50%|█████     | 252/500 [01:18<01:14,  3.34it/s] 51%|█████     | 253/500 [01:19<01:14,  3.34it/s] 51%|█████     | 254/500 [01:19<01:13,  3.34it/s] 51%|█████     | 255/500 [01:19<01:13,  3.34it/s] 51%|█████     | 256/500 [01:20<01:13,  3.34it/s] 51%|█████▏    | 257/500 [01:20<01:12,  3.34it/s] 52%|█████▏    | 258/500 [01:20<01:12,  3.34it/s] 52%|█████▏    | 259/500 [01:21<01:12,  3.34it/s] 52%|█████▏    | 260/500 [01:21<01:11,  3.34it/s] 52%|█████▏    | 261/500 [01:21<01:11,  3.34it/s] 52%|█████▏    | 262/500 [01:21<01:11,  3.34it/s] 53%|█████▎    | 263/500 [01:22<01:10,  3.34it/s] 53%|█████▎    | 264/500 [01:22<01:10,  3.34it/s] 53%|█████▎    | 265/500 [01:22<01:10,  3.34it/s] 53%|█████▎    | 266/500 [01:23<01:10,  3.34it/s] 53%|█████▎    | 267/500 [01:23<01:09,  3.34it/s] 54%|█████▎    | 268/500 [01:23<01:09,  3.34it/s] 54%|█████▍    | 269/500 [01:24<01:09,  3.33it/s] 54%|█████▍    | 270/500 [01:24<01:09,  3.33it/s] 54%|█████▍    | 271/500 [01:24<01:08,  3.33it/s] 54%|█████▍    | 272/500 [01:24<01:08,  3.33it/s] 55%|█████▍    | 273/500 [01:25<01:08,  3.34it/s] 55%|█████▍    | 274/500 [01:25<01:07,  3.34it/s] 55%|█████▌    | 275/500 [01:25<01:07,  3.34it/s] 55%|█████▌    | 276/500 [01:26<01:07,  3.34it/s] 55%|█████▌    | 277/500 [01:26<01:06,  3.34it/s] 56%|█████▌    | 278/500 [01:26<01:06,  3.34it/s] 56%|█████▌    | 279/500 [01:27<01:06,  3.34it/s] 56%|█████▌    | 280/500 [01:27<01:05,  3.34it/s] 56%|█████▌    | 281/500 [01:27<01:05,  3.34it/s] 56%|█████▋    | 282/500 [01:27<01:05,  3.34it/s] 57%|█████▋    | 283/500 [01:28<01:04,  3.34it/s] 57%|█████▋    | 284/500 [01:28<01:04,  3.34it/s] 57%|█████▋    | 285/500 [01:28<01:04,  3.34it/s] 57%|█████▋    | 286/500 [01:29<01:04,  3.34it/s] 57%|█████▋    | 287/500 [01:29<01:03,  3.34it/s] 58%|█████▊    | 288/500 [01:29<01:03,  3.34it/s] 58%|█████▊    | 289/500 [01:30<01:03,  3.34it/s] 58%|█████▊    | 290/500 [01:30<01:02,  3.34it/s] 58%|█████▊    | 291/500 [01:30<01:02,  3.34it/s] 58%|█████▊    | 292/500 [01:30<01:02,  3.34it/s] 59%|█████▊    | 293/500 [01:31<01:02,  3.34it/s] 59%|█████▉    | 294/500 [01:31<01:01,  3.34it/s] 59%|█████▉    | 295/500 [01:31<01:01,  3.34it/s] 59%|█████▉    | 296/500 [01:32<01:01,  3.34it/s] 59%|█████▉    | 297/500 [01:32<01:00,  3.34it/s] 60%|█████▉    | 298/500 [01:32<01:00,  3.34it/s] 60%|█████▉    | 299/500 [01:33<01:00,  3.34it/s] 60%|██████    | 300/500 [01:33<00:59,  3.34it/s] 60%|██████    | 301/500 [01:33<00:59,  3.34it/s] 60%|██████    | 302/500 [01:33<00:59,  3.34it/s] 61%|██████    | 303/500 [01:34<00:58,  3.34it/s] 61%|██████    | 304/500 [01:34<00:58,  3.35it/s] 61%|██████    | 305/500 [01:34<00:58,  3.35it/s] 61%|██████    | 306/500 [01:35<00:57,  3.35it/s] 61%|██████▏   | 307/500 [01:35<00:57,  3.35it/s] 62%|██████▏   | 308/500 [01:35<00:57,  3.35it/s] 62%|██████▏   | 309/500 [01:35<00:56,  3.35it/s] 62%|██████▏   | 310/500 [01:36<00:56,  3.35it/s] 62%|██████▏   | 311/500 [01:36<00:56,  3.35it/s] 62%|██████▏   | 312/500 [01:36<00:56,  3.35it/s] 63%|██████▎   | 313/500 [01:37<00:55,  3.35it/s] 63%|██████▎   | 314/500 [01:37<00:55,  3.35it/s] 63%|██████▎   | 315/500 [01:37<00:55,  3.35it/s] 63%|██████▎   | 316/500 [01:38<00:54,  3.35it/s] 63%|██████▎   | 317/500 [01:38<00:54,  3.35it/s] 64%|██████▎   | 318/500 [01:38<00:54,  3.35it/s] 64%|██████▍   | 319/500 [01:38<00:54,  3.35it/s] 64%|██████▍   | 320/500 [01:39<00:53,  3.34it/s] 64%|██████▍   | 321/500 [01:39<00:53,  3.35it/s] 64%|██████▍   | 322/500 [01:39<00:53,  3.35it/s] 65%|██████▍   | 323/500 [01:40<00:52,  3.35it/s] 65%|██████▍   | 324/500 [01:40<00:52,  3.35it/s] 65%|██████▌   | 325/500 [01:40<00:52,  3.35it/s] 65%|██████▌   | 326/500 [01:41<00:51,  3.35it/s] 65%|██████▌   | 327/500 [01:41<00:51,  3.35it/s] 66%|██████▌   | 328/500 [01:41<00:51,  3.35it/s] 66%|██████▌   | 329/500 [01:41<00:51,  3.34it/s] 66%|██████▌   | 330/500 [01:42<00:50,  3.35it/s] 66%|██████▌   | 331/500 [01:42<00:50,  3.34it/s] 66%|██████▋   | 332/500 [01:42<00:50,  3.34it/s] 67%|██████▋   | 333/500 [01:43<00:49,  3.34it/s] 67%|██████▋   | 334/500 [01:43<00:49,  3.34it/s] 67%|██████▋   | 335/500 [01:43<00:49,  3.34it/s] 67%|██████▋   | 336/500 [01:44<00:48,  3.35it/s] 67%|██████▋   | 337/500 [01:44<00:48,  3.35it/s] 68%|██████▊   | 338/500 [01:44<00:48,  3.35it/s] 68%|██████▊   | 339/500 [01:44<00:48,  3.34it/s] 68%|██████▊   | 340/500 [01:45<00:47,  3.34it/s] 68%|██████▊   | 341/500 [01:45<00:47,  3.34it/s] 68%|██████▊   | 342/500 [01:45<00:47,  3.34it/s] 69%|██████▊   | 343/500 [01:46<00:47,  3.34it/s] 69%|██████▉   | 344/500 [01:46<00:46,  3.34it/s] 69%|██████▉   | 345/500 [01:46<00:46,  3.34it/s] 69%|██████▉   | 346/500 [01:47<00:46,  3.34it/s] 69%|██████▉   | 347/500 [01:47<00:45,  3.34it/s] 70%|██████▉   | 348/500 [01:47<00:45,  3.34it/s] 70%|██████▉   | 349/500 [01:47<00:45,  3.34it/s] 70%|███████   | 350/500 [01:48<00:44,  3.34it/s] 70%|███████   | 351/500 [01:48<00:44,  3.34it/s] 70%|███████   | 352/500 [01:48<00:44,  3.34it/s] 71%|███████   | 353/500 [01:49<00:43,  3.34it/s] 71%|███████   | 354/500 [01:49<00:43,  3.34it/s] 71%|███████   | 355/500 [01:49<00:43,  3.35it/s] 71%|███████   | 356/500 [01:50<00:43,  3.35it/s] 71%|███████▏  | 357/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 358/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 359/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 360/500 [01:51<00:41,  3.35it/s] 72%|███████▏  | 361/500 [01:51<00:41,  3.35it/s] 72%|███████▏  | 362/500 [01:51<00:41,  3.35it/s] 73%|███████▎  | 363/500 [01:52<00:40,  3.34it/s] 73%|███████▎  | 364/500 [01:52<00:40,  3.34it/s] 73%|███████▎  | 365/500 [01:52<00:40,  3.34it/s] 73%|███████▎  | 366/500 [01:53<00:40,  3.34it/s] 73%|███████▎  | 367/500 [01:53<00:39,  3.34it/s] 74%|███████▎  | 368/500 [01:53<00:39,  3.34it/s] 74%|███████▍  | 369/500 [01:53<00:39,  3.34it/s] 74%|███████▍  | 370/500 [01:54<00:38,  3.33it/s] 74%|███████▍  | 371/500 [01:54<00:38,  3.33it/s] 74%|███████▍  | 372/500 [01:54<00:38,  3.34it/s] 75%|███████▍  | 373/500 [01:55<00:38,  3.34it/s] 75%|███████▍  | 374/500 [01:55<00:37,  3.34it/s] 75%|███████▌  | 375/500 [01:55<00:37,  3.34it/s] 75%|███████▌  | 376/500 [01:56<00:37,  3.34it/s] 75%|███████▌  | 377/500 [01:56<00:36,  3.34it/s] 76%|███████▌  | 378/500 [01:56<00:36,  3.33it/s] 76%|███████▌  | 379/500 [01:56<00:36,  3.33it/s] 76%|███████▌  | 380/500 [01:57<00:36,  3.33it/s] 76%|███████▌  | 381/500 [01:57<00:35,  3.34it/s] 76%|███████▋  | 382/500 [01:57<00:35,  3.34it/s] 77%|███████▋  | 383/500 [01:58<00:35,  3.34it/s] 77%|███████▋  | 384/500 [01:58<00:34,  3.34it/s] 77%|███████▋  | 385/500 [01:58<00:34,  3.34it/s] 77%|███████▋  | 386/500 [01:59<00:34,  3.34it/s] 77%|███████▋  | 387/500 [01:59<00:33,  3.33it/s] 78%|███████▊  | 388/500 [01:59<00:33,  3.33it/s] 78%|███████▊  | 389/500 [01:59<00:33,  3.34it/s] 78%|███████▊  | 390/500 [02:00<00:32,  3.34it/s] 78%|███████▊  | 391/500 [02:00<00:32,  3.34it/s] 78%|███████▊  | 392/500 [02:00<00:32,  3.34it/s] 79%|███████▊  | 393/500 [02:01<00:32,  3.34it/s] 79%|███████▉  | 394/500 [02:01<00:31,  3.34it/s] 79%|███████▉  | 395/500 [02:01<00:31,  3.34it/s] 79%|███████▉  | 396/500 [02:02<00:31,  3.34it/s] 79%|███████▉  | 397/500 [02:02<00:30,  3.35it/s] 80%|███████▉  | 398/500 [02:02<00:30,  3.34it/s] 80%|███████▉  | 399/500 [02:02<00:30,  3.34it/s] 80%|████████  | 400/500 [02:03<00:29,  3.34it/s] 80%|████████  | 401/500 [02:03<00:29,  3.34it/s] 80%|████████  | 402/500 [02:03<00:29,  3.34it/s] 81%|████████  | 403/500 [02:04<00:29,  3.34it/s] 81%|████████  | 404/500 [02:04<00:28,  3.34it/s] 81%|████████  | 405/500 [02:04<00:28,  3.34it/s] 81%|████████  | 406/500 [02:05<00:28,  3.34it/s] 81%|████████▏ | 407/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 408/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 409/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 410/500 [02:06<00:27,  3.33it/s] 82%|████████▏ | 411/500 [02:06<00:26,  3.33it/s] 82%|████████▏ | 412/500 [02:06<00:26,  3.33it/s] 83%|████████▎ | 413/500 [02:07<00:26,  3.34it/s] 83%|████████▎ | 414/500 [02:07<00:25,  3.34it/s] 83%|████████▎ | 415/500 [02:07<00:25,  3.34it/s] 83%|████████▎ | 416/500 [02:08<00:25,  3.34it/s] 83%|████████▎ | 417/500 [02:08<00:24,  3.34it/s] 84%|████████▎ | 418/500 [02:08<00:24,  3.34it/s] 84%|████████▍ | 419/500 [02:08<00:24,  3.34it/s] 84%|████████▍ | 420/500 [02:09<00:23,  3.34it/s] 84%|████████▍ | 421/500 [02:09<00:23,  3.34it/s] 84%|████████▍ | 422/500 [02:09<00:23,  3.34it/s] 85%|████████▍ | 423/500 [02:10<00:23,  3.34it/s] 85%|████████▍ | 424/500 [02:10<00:22,  3.34it/s] 85%|████████▌ | 425/500 [02:10<00:22,  3.34it/s] 85%|████████▌ | 426/500 [02:11<00:22,  3.34it/s] 85%|████████▌ | 427/500 [02:11<00:21,  3.34it/s] 86%|████████▌ | 428/500 [02:11<00:21,  3.34it/s] 86%|████████▌ | 429/500 [02:11<00:21,  3.34it/s] 86%|████████▌ | 430/500 [02:12<00:20,  3.34it/s] 86%|████████▌ | 431/500 [02:12<00:20,  3.34it/s] 86%|████████▋ | 432/500 [02:12<00:20,  3.34it/s] 87%|████████▋ | 433/500 [02:13<00:20,  3.34it/s] 87%|████████▋ | 434/500 [02:13<00:19,  3.34it/s] 87%|████████▋ | 435/500 [02:13<00:19,  3.34it/s] 87%|████████▋ | 436/500 [02:14<00:19,  3.34it/s] 87%|████████▋ | 437/500 [02:14<00:18,  3.34it/s] 88%|████████▊ | 438/500 [02:14<00:18,  3.34it/s] 88%|████████▊ | 439/500 [02:14<00:18,  3.34it/s] 88%|████████▊ | 440/500 [02:15<00:17,  3.34it/s] 88%|████████▊ | 441/500 [02:15<00:17,  3.34it/s] 88%|████████▊ | 442/500 [02:15<00:17,  3.34it/s] 89%|████████▊ | 443/500 [02:16<00:17,  3.34it/s] 89%|████████▉ | 444/500 [02:16<00:16,  3.34it/s] 89%|████████▉ | 445/500 [02:16<00:16,  3.34it/s] 89%|████████▉ | 446/500 [02:17<00:16,  3.34it/s] 89%|████████▉ | 447/500 [02:17<00:15,  3.34it/s] 90%|████████▉ | 448/500 [02:17<00:15,  3.34it/s] 90%|████████▉ | 449/500 [02:17<00:15,  3.34it/s] 90%|█████████ | 450/500 [02:18<00:14,  3.34it/s] 90%|█████████ | 451/500 [02:18<00:14,  3.34it/s] 90%|█████████ | 452/500 [02:18<00:14,  3.34it/s] 91%|█████████ | 453/500 [02:19<00:14,  3.34it/s] 91%|█████████ | 454/500 [02:19<00:13,  3.34it/s] 91%|█████████ | 455/500 [02:19<00:13,  3.34it/s] 91%|█████████ | 456/500 [02:19<00:13,  3.34it/s] 91%|█████████▏| 457/500 [02:20<00:12,  3.34it/s] 92%|█████████▏| 458/500 [02:20<00:12,  3.34it/s] 92%|█████████▏| 459/500 [02:20<00:12,  3.34it/s] 92%|█████████▏| 460/500 [02:21<00:11,  3.34it/s] 92%|█████████▏| 461/500 [02:21<00:11,  3.34it/s] 92%|█████████▏| 462/500 [02:21<00:11,  3.33it/s] 93%|█████████▎| 463/500 [02:22<00:11,  3.33it/s] 93%|█████████▎| 464/500 [02:22<00:10,  3.34it/s] 93%|█████████▎| 465/500 [02:22<00:10,  3.34it/s] 93%|█████████▎| 466/500 [02:22<00:10,  3.33it/s] 93%|█████████▎| 467/500 [02:23<00:09,  3.34it/s] 94%|█████████▎| 468/500 [02:23<00:09,  3.34it/s] 94%|█████████▍| 469/500 [02:23<00:09,  3.34it/s] 94%|█████████▍| 470/500 [02:24<00:09,  3.33it/s] 94%|█████████▍| 471/500 [02:24<00:08,  3.33it/s] 94%|█████████▍| 472/500 [02:24<00:08,  3.33it/s] 95%|█████████▍| 473/500 [02:25<00:08,  3.33it/s] 95%|█████████▍| 474/500 [02:25<00:07,  3.34it/s] 95%|█████████▌| 475/500 [02:25<00:07,  3.34it/s] 95%|█████████▌| 476/500 [02:25<00:07,  3.34it/s] 95%|█████████▌| 477/500 [02:26<00:06,  3.34it/s] 96%|█████████▌| 478/500 [02:26<00:06,  3.34it/s] 96%|█████████▌| 479/500 [02:26<00:06,  3.34it/s] 96%|█████████▌| 480/500 [02:27<00:05,  3.34it/s] 96%|█████████▌| 481/500 [02:27<00:05,  3.34it/s] 96%|█████████▋| 482/500 [02:27<00:05,  3.34it/s] 97%|█████████▋| 483/500 [02:28<00:05,  3.34it/s] 97%|█████████▋| 484/500 [02:28<00:04,  3.34it/s] 97%|█████████▋| 485/500 [02:28<00:04,  3.35it/s] 97%|█████████▋| 486/500 [02:28<00:04,  3.35it/s] 97%|█████████▋| 487/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 488/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 489/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 490/500 [02:30<00:02,  3.36it/s] 98%|█████████▊| 491/500 [02:30<00:02,  3.36it/s] 98%|█████████▊| 492/500 [02:30<00:02,  3.35it/s] 99%|█████████▊| 493/500 [02:31<00:02,  3.35it/s] 99%|█████████▉| 494/500 [02:31<00:01,  3.35it/s] 99%|█████████▉| 495/500 [02:31<00:01,  3.35it/s] 99%|█████████▉| 496/500 [02:31<00:01,  3.35it/s] 99%|█████████▉| 497/500 [02:32<00:00,  3.35it/s]100%|█████████▉| 498/500 [02:32<00:00,  3.35it/s]100%|█████████▉| 499/500 [02:32<00:00,  3.35it/s]100%|██████████| 500/500 [02:33<00:00,  3.35it/s]100%|██████████| 500/500 [02:33<00:00,  3.26it/s]
=> result
* total: 50,000
* correct: 18,724
* accuracy: 37.4%
* error: 62.6%
* macro_f1: 33.3%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers imagenet 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/imagenet/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/imagenet/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:ImageNet
Loading dataset: ImageNet
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ImageNet/split_fewshot_taesup/shot_16-seed_3.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:04<33:27,  4.02s/it]  0%|          | 2/500 [00:04<15:11,  1.83s/it]  1%|          | 3/500 [00:04<09:21,  1.13s/it]  1%|          | 4/500 [00:04<06:36,  1.25it/s]  1%|          | 5/500 [00:05<05:06,  1.62it/s]  1%|          | 6/500 [00:05<04:11,  1.97it/s]  1%|▏         | 7/500 [00:05<03:36,  2.28it/s]  2%|▏         | 8/500 [00:06<03:13,  2.54it/s]  2%|▏         | 9/500 [00:06<02:58,  2.76it/s]  2%|▏         | 10/500 [00:06<02:47,  2.92it/s]  2%|▏         | 11/500 [00:06<02:40,  3.05it/s]  2%|▏         | 12/500 [00:07<02:35,  3.14it/s]  3%|▎         | 13/500 [00:07<02:31,  3.21it/s]  3%|▎         | 14/500 [00:07<02:29,  3.26it/s]  3%|▎         | 15/500 [00:08<02:27,  3.29it/s]  3%|▎         | 16/500 [00:08<02:25,  3.32it/s]  3%|▎         | 17/500 [00:08<02:24,  3.34it/s]  4%|▎         | 18/500 [00:09<02:24,  3.35it/s]  4%|▍         | 19/500 [00:09<02:23,  3.35it/s]  4%|▍         | 20/500 [00:09<02:22,  3.36it/s]  4%|▍         | 21/500 [00:09<02:22,  3.36it/s]  4%|▍         | 22/500 [00:10<02:22,  3.37it/s]  5%|▍         | 23/500 [00:10<02:22,  3.35it/s]  5%|▍         | 24/500 [00:10<02:21,  3.36it/s]  5%|▌         | 25/500 [00:11<02:21,  3.35it/s]  5%|▌         | 26/500 [00:11<02:21,  3.36it/s]  5%|▌         | 27/500 [00:11<02:20,  3.36it/s]  6%|▌         | 28/500 [00:12<02:20,  3.36it/s]  6%|▌         | 29/500 [00:12<02:20,  3.36it/s]  6%|▌         | 30/500 [00:12<02:19,  3.36it/s]  6%|▌         | 31/500 [00:12<02:19,  3.36it/s]  6%|▋         | 32/500 [00:13<02:19,  3.36it/s]  7%|▋         | 33/500 [00:13<02:18,  3.36it/s]  7%|▋         | 34/500 [00:13<02:18,  3.36it/s]  7%|▋         | 35/500 [00:14<02:18,  3.36it/s]  7%|▋         | 36/500 [00:14<02:17,  3.36it/s]  7%|▋         | 37/500 [00:14<02:17,  3.36it/s]  8%|▊         | 38/500 [00:15<02:17,  3.36it/s]  8%|▊         | 39/500 [00:15<02:17,  3.36it/s]  8%|▊         | 40/500 [00:15<02:16,  3.36it/s]  8%|▊         | 41/500 [00:15<02:16,  3.36it/s]  8%|▊         | 42/500 [00:16<02:16,  3.36it/s]  9%|▊         | 43/500 [00:16<02:16,  3.36it/s]  9%|▉         | 44/500 [00:16<02:16,  3.35it/s]  9%|▉         | 45/500 [00:17<02:15,  3.35it/s]  9%|▉         | 46/500 [00:17<02:15,  3.35it/s]  9%|▉         | 47/500 [00:17<02:14,  3.36it/s] 10%|▉         | 48/500 [00:17<02:14,  3.36it/s] 10%|▉         | 49/500 [00:18<02:14,  3.36it/s] 10%|█         | 50/500 [00:18<02:14,  3.36it/s] 10%|█         | 51/500 [00:18<02:13,  3.36it/s] 10%|█         | 52/500 [00:19<02:13,  3.36it/s] 11%|█         | 53/500 [00:19<02:12,  3.36it/s] 11%|█         | 54/500 [00:19<02:12,  3.36it/s] 11%|█         | 55/500 [00:20<02:12,  3.36it/s] 11%|█         | 56/500 [00:20<02:12,  3.36it/s] 11%|█▏        | 57/500 [00:20<02:11,  3.36it/s] 12%|█▏        | 58/500 [00:20<02:11,  3.36it/s] 12%|█▏        | 59/500 [00:21<02:11,  3.36it/s] 12%|█▏        | 60/500 [00:21<02:10,  3.36it/s] 12%|█▏        | 61/500 [00:21<02:10,  3.36it/s] 12%|█▏        | 62/500 [00:22<02:10,  3.36it/s] 13%|█▎        | 63/500 [00:22<02:10,  3.35it/s] 13%|█▎        | 64/500 [00:22<02:09,  3.36it/s] 13%|█▎        | 65/500 [00:23<02:09,  3.36it/s] 13%|█▎        | 66/500 [00:23<02:09,  3.36it/s] 13%|█▎        | 67/500 [00:23<02:08,  3.36it/s] 14%|█▎        | 68/500 [00:23<02:08,  3.36it/s] 14%|█▍        | 69/500 [00:24<02:08,  3.35it/s] 14%|█▍        | 70/500 [00:24<02:08,  3.35it/s] 14%|█▍        | 71/500 [00:24<02:08,  3.34it/s] 14%|█▍        | 72/500 [00:25<02:07,  3.35it/s] 15%|█▍        | 73/500 [00:25<02:07,  3.35it/s] 15%|█▍        | 74/500 [00:25<02:07,  3.35it/s] 15%|█▌        | 75/500 [00:26<02:06,  3.35it/s] 15%|█▌        | 76/500 [00:26<02:06,  3.35it/s] 15%|█▌        | 77/500 [00:26<02:06,  3.35it/s] 16%|█▌        | 78/500 [00:26<02:05,  3.35it/s] 16%|█▌        | 79/500 [00:27<02:05,  3.35it/s] 16%|█▌        | 80/500 [00:27<02:05,  3.35it/s] 16%|█▌        | 81/500 [00:27<02:04,  3.35it/s] 16%|█▋        | 82/500 [00:28<02:04,  3.35it/s] 17%|█▋        | 83/500 [00:28<02:04,  3.35it/s] 17%|█▋        | 84/500 [00:28<02:03,  3.36it/s] 17%|█▋        | 85/500 [00:29<02:03,  3.35it/s] 17%|█▋        | 86/500 [00:29<02:03,  3.35it/s] 17%|█▋        | 87/500 [00:29<02:03,  3.35it/s] 18%|█▊        | 88/500 [00:29<02:02,  3.35it/s] 18%|█▊        | 89/500 [00:30<02:02,  3.35it/s] 18%|█▊        | 90/500 [00:30<02:02,  3.35it/s] 18%|█▊        | 91/500 [00:30<02:01,  3.35it/s] 18%|█▊        | 92/500 [00:31<02:01,  3.35it/s] 19%|█▊        | 93/500 [00:31<02:01,  3.35it/s] 19%|█▉        | 94/500 [00:31<02:01,  3.35it/s] 19%|█▉        | 95/500 [00:31<02:01,  3.34it/s] 19%|█▉        | 96/500 [00:32<02:00,  3.35it/s] 19%|█▉        | 97/500 [00:32<02:00,  3.35it/s] 20%|█▉        | 98/500 [00:32<02:00,  3.32it/s] 20%|█▉        | 99/500 [00:33<02:00,  3.33it/s] 20%|██        | 100/500 [00:33<01:59,  3.34it/s] 20%|██        | 101/500 [00:33<01:59,  3.34it/s] 20%|██        | 102/500 [00:34<01:59,  3.34it/s] 21%|██        | 103/500 [00:34<01:58,  3.34it/s] 21%|██        | 104/500 [00:34<01:58,  3.34it/s] 21%|██        | 105/500 [00:34<01:58,  3.34it/s] 21%|██        | 106/500 [00:35<01:57,  3.34it/s] 21%|██▏       | 107/500 [00:35<01:57,  3.35it/s] 22%|██▏       | 108/500 [00:35<01:57,  3.35it/s] 22%|██▏       | 109/500 [00:36<01:56,  3.35it/s] 22%|██▏       | 110/500 [00:36<01:56,  3.35it/s] 22%|██▏       | 111/500 [00:36<01:56,  3.34it/s] 22%|██▏       | 112/500 [00:37<01:56,  3.34it/s] 23%|██▎       | 113/500 [00:37<01:55,  3.35it/s] 23%|██▎       | 114/500 [00:37<01:55,  3.34it/s] 23%|██▎       | 115/500 [00:37<01:55,  3.35it/s] 23%|██▎       | 116/500 [00:38<01:54,  3.34it/s] 23%|██▎       | 117/500 [00:38<01:54,  3.34it/s] 24%|██▎       | 118/500 [00:38<01:54,  3.34it/s] 24%|██▍       | 119/500 [00:39<01:54,  3.34it/s] 24%|██▍       | 120/500 [00:39<01:53,  3.34it/s] 24%|██▍       | 121/500 [00:39<01:53,  3.35it/s] 24%|██▍       | 122/500 [00:40<01:52,  3.35it/s] 25%|██▍       | 123/500 [00:40<01:52,  3.35it/s] 25%|██▍       | 124/500 [00:40<01:52,  3.36it/s] 25%|██▌       | 125/500 [00:40<01:51,  3.35it/s] 25%|██▌       | 126/500 [00:41<01:51,  3.35it/s] 25%|██▌       | 127/500 [00:41<01:51,  3.35it/s] 26%|██▌       | 128/500 [00:41<01:51,  3.35it/s] 26%|██▌       | 129/500 [00:42<01:50,  3.34it/s] 26%|██▌       | 130/500 [00:42<01:50,  3.35it/s] 26%|██▌       | 131/500 [00:42<01:50,  3.34it/s] 26%|██▋       | 132/500 [00:43<01:50,  3.35it/s] 27%|██▋       | 133/500 [00:43<01:49,  3.35it/s] 27%|██▋       | 134/500 [00:43<01:49,  3.35it/s] 27%|██▋       | 135/500 [00:43<01:49,  3.34it/s] 27%|██▋       | 136/500 [00:44<01:48,  3.34it/s] 27%|██▋       | 137/500 [00:44<01:48,  3.34it/s] 28%|██▊       | 138/500 [00:44<01:48,  3.33it/s] 28%|██▊       | 139/500 [00:45<01:48,  3.33it/s] 28%|██▊       | 140/500 [00:45<01:47,  3.33it/s] 28%|██▊       | 141/500 [00:45<01:47,  3.34it/s] 28%|██▊       | 142/500 [00:46<01:47,  3.34it/s] 29%|██▊       | 143/500 [00:46<01:46,  3.34it/s] 29%|██▉       | 144/500 [00:46<01:46,  3.34it/s] 29%|██▉       | 145/500 [00:46<01:46,  3.34it/s] 29%|██▉       | 146/500 [00:47<01:45,  3.35it/s] 29%|██▉       | 147/500 [00:47<01:45,  3.34it/s] 30%|██▉       | 148/500 [00:47<01:45,  3.35it/s] 30%|██▉       | 149/500 [00:48<01:44,  3.35it/s] 30%|███       | 150/500 [00:48<01:44,  3.35it/s] 30%|███       | 151/500 [00:48<01:44,  3.35it/s] 30%|███       | 152/500 [00:49<01:43,  3.35it/s] 31%|███       | 153/500 [00:49<01:43,  3.34it/s] 31%|███       | 154/500 [00:49<01:43,  3.34it/s] 31%|███       | 155/500 [00:49<01:43,  3.34it/s] 31%|███       | 156/500 [00:50<01:42,  3.34it/s] 31%|███▏      | 157/500 [00:50<01:42,  3.34it/s] 32%|███▏      | 158/500 [00:50<01:42,  3.34it/s] 32%|███▏      | 159/500 [00:51<01:41,  3.35it/s] 32%|███▏      | 160/500 [00:51<01:41,  3.35it/s] 32%|███▏      | 161/500 [00:51<01:41,  3.35it/s] 32%|███▏      | 162/500 [00:52<01:40,  3.35it/s] 33%|███▎      | 163/500 [00:52<01:40,  3.35it/s] 33%|███▎      | 164/500 [00:52<01:40,  3.35it/s] 33%|███▎      | 165/500 [00:52<01:40,  3.35it/s] 33%|███▎      | 166/500 [00:53<01:39,  3.35it/s] 33%|███▎      | 167/500 [00:53<01:39,  3.34it/s] 34%|███▎      | 168/500 [00:53<01:39,  3.34it/s] 34%|███▍      | 169/500 [00:54<01:38,  3.35it/s] 34%|███▍      | 170/500 [00:54<01:38,  3.35it/s] 34%|███▍      | 171/500 [00:54<01:38,  3.35it/s] 34%|███▍      | 172/500 [00:55<01:37,  3.35it/s] 35%|███▍      | 173/500 [00:55<01:37,  3.35it/s] 35%|███▍      | 174/500 [00:55<01:37,  3.34it/s] 35%|███▌      | 175/500 [00:55<01:37,  3.35it/s] 35%|███▌      | 176/500 [00:56<01:36,  3.34it/s] 35%|███▌      | 177/500 [00:56<01:36,  3.34it/s] 36%|███▌      | 178/500 [00:56<01:36,  3.34it/s] 36%|███▌      | 179/500 [00:57<01:36,  3.33it/s] 36%|███▌      | 180/500 [00:57<01:36,  3.33it/s] 36%|███▌      | 181/500 [00:57<01:35,  3.34it/s] 36%|███▋      | 182/500 [00:58<01:35,  3.34it/s] 37%|███▋      | 183/500 [00:58<01:34,  3.35it/s] 37%|███▋      | 184/500 [00:58<01:34,  3.34it/s] 37%|███▋      | 185/500 [00:58<01:34,  3.34it/s] 37%|███▋      | 186/500 [00:59<01:34,  3.34it/s] 37%|███▋      | 187/500 [00:59<01:33,  3.34it/s] 38%|███▊      | 188/500 [00:59<01:33,  3.34it/s] 38%|███▊      | 189/500 [01:00<01:33,  3.34it/s] 38%|███▊      | 190/500 [01:00<01:32,  3.34it/s] 38%|███▊      | 191/500 [01:00<01:32,  3.35it/s] 38%|███▊      | 192/500 [01:01<01:32,  3.35it/s] 39%|███▊      | 193/500 [01:01<01:31,  3.34it/s] 39%|███▉      | 194/500 [01:01<01:31,  3.34it/s] 39%|███▉      | 195/500 [01:01<01:31,  3.34it/s] 39%|███▉      | 196/500 [01:02<01:30,  3.34it/s] 39%|███▉      | 197/500 [01:02<01:30,  3.34it/s] 40%|███▉      | 198/500 [01:02<01:30,  3.34it/s] 40%|███▉      | 199/500 [01:03<01:30,  3.34it/s] 40%|████      | 200/500 [01:03<01:29,  3.34it/s] 40%|████      | 201/500 [01:03<01:29,  3.34it/s] 40%|████      | 202/500 [01:03<01:29,  3.34it/s] 41%|████      | 203/500 [01:04<01:28,  3.34it/s] 41%|████      | 204/500 [01:04<01:28,  3.34it/s] 41%|████      | 205/500 [01:04<01:28,  3.34it/s] 41%|████      | 206/500 [01:05<01:27,  3.34it/s] 41%|████▏     | 207/500 [01:05<01:27,  3.34it/s] 42%|████▏     | 208/500 [01:05<01:27,  3.34it/s] 42%|████▏     | 209/500 [01:06<01:27,  3.33it/s] 42%|████▏     | 210/500 [01:06<01:26,  3.34it/s] 42%|████▏     | 211/500 [01:06<01:26,  3.34it/s] 42%|████▏     | 212/500 [01:06<01:26,  3.34it/s] 43%|████▎     | 213/500 [01:07<01:25,  3.34it/s] 43%|████▎     | 214/500 [01:07<01:25,  3.34it/s] 43%|████▎     | 215/500 [01:07<01:25,  3.34it/s] 43%|████▎     | 216/500 [01:08<01:25,  3.34it/s] 43%|████▎     | 217/500 [01:08<01:24,  3.34it/s] 44%|████▎     | 218/500 [01:08<01:24,  3.34it/s] 44%|████▍     | 219/500 [01:09<01:24,  3.34it/s] 44%|████▍     | 220/500 [01:09<01:23,  3.34it/s] 44%|████▍     | 221/500 [01:09<01:23,  3.34it/s] 44%|████▍     | 222/500 [01:09<01:23,  3.33it/s] 45%|████▍     | 223/500 [01:10<01:23,  3.34it/s] 45%|████▍     | 224/500 [01:10<01:22,  3.34it/s] 45%|████▌     | 225/500 [01:10<01:22,  3.33it/s] 45%|████▌     | 226/500 [01:11<01:22,  3.33it/s] 45%|████▌     | 227/500 [01:11<01:21,  3.33it/s] 46%|████▌     | 228/500 [01:11<01:21,  3.34it/s] 46%|████▌     | 229/500 [01:12<01:21,  3.34it/s] 46%|████▌     | 230/500 [01:12<01:20,  3.34it/s] 46%|████▌     | 231/500 [01:12<01:20,  3.34it/s] 46%|████▋     | 232/500 [01:12<01:20,  3.34it/s] 47%|████▋     | 233/500 [01:13<01:19,  3.34it/s] 47%|████▋     | 234/500 [01:13<01:19,  3.34it/s] 47%|████▋     | 235/500 [01:13<01:19,  3.34it/s] 47%|████▋     | 236/500 [01:14<01:18,  3.34it/s] 47%|████▋     | 237/500 [01:14<01:18,  3.34it/s] 48%|████▊     | 238/500 [01:14<01:18,  3.34it/s] 48%|████▊     | 239/500 [01:15<01:18,  3.34it/s] 48%|████▊     | 240/500 [01:15<01:17,  3.34it/s] 48%|████▊     | 241/500 [01:15<01:17,  3.34it/s] 48%|████▊     | 242/500 [01:15<01:17,  3.34it/s] 49%|████▊     | 243/500 [01:16<01:16,  3.34it/s] 49%|████▉     | 244/500 [01:16<01:16,  3.34it/s] 49%|████▉     | 245/500 [01:16<01:16,  3.34it/s] 49%|████▉     | 246/500 [01:17<01:16,  3.34it/s] 49%|████▉     | 247/500 [01:17<01:15,  3.34it/s] 50%|████▉     | 248/500 [01:17<01:15,  3.34it/s] 50%|████▉     | 249/500 [01:18<01:15,  3.34it/s] 50%|█████     | 250/500 [01:18<01:14,  3.34it/s] 50%|█████     | 251/500 [01:18<01:14,  3.34it/s] 50%|█████     | 252/500 [01:18<01:14,  3.34it/s] 51%|█████     | 253/500 [01:19<01:13,  3.34it/s] 51%|█████     | 254/500 [01:19<01:13,  3.34it/s] 51%|█████     | 255/500 [01:19<01:13,  3.34it/s] 51%|█████     | 256/500 [01:20<01:13,  3.34it/s] 51%|█████▏    | 257/500 [01:20<01:12,  3.34it/s] 52%|█████▏    | 258/500 [01:20<01:12,  3.34it/s] 52%|█████▏    | 259/500 [01:21<01:12,  3.34it/s] 52%|█████▏    | 260/500 [01:21<01:11,  3.34it/s] 52%|█████▏    | 261/500 [01:21<01:11,  3.34it/s] 52%|█████▏    | 262/500 [01:21<01:11,  3.34it/s] 53%|█████▎    | 263/500 [01:22<01:10,  3.34it/s] 53%|█████▎    | 264/500 [01:22<01:10,  3.34it/s] 53%|█████▎    | 265/500 [01:22<01:10,  3.34it/s] 53%|█████▎    | 266/500 [01:23<01:10,  3.34it/s] 53%|█████▎    | 267/500 [01:23<01:09,  3.34it/s] 54%|█████▎    | 268/500 [01:23<01:09,  3.34it/s] 54%|█████▍    | 269/500 [01:24<01:09,  3.34it/s] 54%|█████▍    | 270/500 [01:24<01:08,  3.34it/s] 54%|█████▍    | 271/500 [01:24<01:08,  3.34it/s] 54%|█████▍    | 272/500 [01:24<01:08,  3.34it/s] 55%|█████▍    | 273/500 [01:25<01:07,  3.34it/s] 55%|█████▍    | 274/500 [01:25<01:07,  3.34it/s] 55%|█████▌    | 275/500 [01:25<01:07,  3.34it/s] 55%|█████▌    | 276/500 [01:26<01:06,  3.34it/s] 55%|█████▌    | 277/500 [01:26<01:06,  3.35it/s] 56%|█████▌    | 278/500 [01:26<01:06,  3.34it/s] 56%|█████▌    | 279/500 [01:27<01:06,  3.34it/s] 56%|█████▌    | 280/500 [01:27<01:05,  3.34it/s] 56%|█████▌    | 281/500 [01:27<01:05,  3.34it/s] 56%|█████▋    | 282/500 [01:27<01:05,  3.34it/s] 57%|█████▋    | 283/500 [01:28<01:04,  3.35it/s] 57%|█████▋    | 284/500 [01:28<01:04,  3.33it/s] 57%|█████▋    | 285/500 [01:28<01:04,  3.33it/s] 57%|█████▋    | 286/500 [01:29<01:04,  3.33it/s] 57%|█████▋    | 287/500 [01:29<01:03,  3.34it/s] 58%|█████▊    | 288/500 [01:29<01:03,  3.34it/s] 58%|█████▊    | 289/500 [01:30<01:03,  3.34it/s] 58%|█████▊    | 290/500 [01:30<01:02,  3.34it/s] 58%|█████▊    | 291/500 [01:30<01:02,  3.34it/s] 58%|█████▊    | 292/500 [01:30<01:02,  3.34it/s] 59%|█████▊    | 293/500 [01:31<01:01,  3.34it/s] 59%|█████▉    | 294/500 [01:31<01:01,  3.34it/s] 59%|█████▉    | 295/500 [01:31<01:01,  3.34it/s] 59%|█████▉    | 296/500 [01:32<01:00,  3.34it/s] 59%|█████▉    | 297/500 [01:32<01:00,  3.35it/s] 60%|█████▉    | 298/500 [01:32<01:00,  3.35it/s] 60%|█████▉    | 299/500 [01:33<01:00,  3.35it/s] 60%|██████    | 300/500 [01:33<00:59,  3.35it/s] 60%|██████    | 301/500 [01:33<00:59,  3.34it/s] 60%|██████    | 302/500 [01:33<00:59,  3.34it/s] 61%|██████    | 303/500 [01:34<00:58,  3.34it/s] 61%|██████    | 304/500 [01:34<00:58,  3.34it/s] 61%|██████    | 305/500 [01:34<00:58,  3.34it/s] 61%|██████    | 306/500 [01:35<00:58,  3.34it/s] 61%|██████▏   | 307/500 [01:35<00:57,  3.34it/s] 62%|██████▏   | 308/500 [01:35<00:57,  3.34it/s] 62%|██████▏   | 309/500 [01:36<00:57,  3.34it/s] 62%|██████▏   | 310/500 [01:36<00:56,  3.34it/s] 62%|██████▏   | 311/500 [01:36<00:56,  3.34it/s] 62%|██████▏   | 312/500 [01:36<00:56,  3.34it/s] 63%|██████▎   | 313/500 [01:37<00:55,  3.34it/s] 63%|██████▎   | 314/500 [01:37<00:55,  3.34it/s] 63%|██████▎   | 315/500 [01:37<00:55,  3.35it/s] 63%|██████▎   | 316/500 [01:38<00:55,  3.34it/s] 63%|██████▎   | 317/500 [01:38<00:54,  3.34it/s] 64%|██████▎   | 318/500 [01:38<00:54,  3.34it/s] 64%|██████▍   | 319/500 [01:39<00:54,  3.33it/s] 64%|██████▍   | 320/500 [01:39<00:54,  3.33it/s] 64%|██████▍   | 321/500 [01:39<00:53,  3.34it/s] 64%|██████▍   | 322/500 [01:39<00:53,  3.34it/s] 65%|██████▍   | 323/500 [01:40<00:53,  3.34it/s] 65%|██████▍   | 324/500 [01:40<00:52,  3.34it/s] 65%|██████▌   | 325/500 [01:40<00:52,  3.33it/s] 65%|██████▌   | 326/500 [01:41<00:52,  3.33it/s] 65%|██████▌   | 327/500 [01:41<00:51,  3.33it/s] 66%|██████▌   | 328/500 [01:41<00:51,  3.34it/s] 66%|██████▌   | 329/500 [01:42<00:51,  3.34it/s] 66%|██████▌   | 330/500 [01:42<00:50,  3.34it/s] 66%|██████▌   | 331/500 [01:42<00:50,  3.34it/s] 66%|██████▋   | 332/500 [01:42<00:50,  3.34it/s] 67%|██████▋   | 333/500 [01:43<00:49,  3.34it/s] 67%|██████▋   | 334/500 [01:43<00:49,  3.34it/s] 67%|██████▋   | 335/500 [01:43<00:49,  3.34it/s] 67%|██████▋   | 336/500 [01:44<00:49,  3.34it/s] 67%|██████▋   | 337/500 [01:44<00:48,  3.33it/s] 68%|██████▊   | 338/500 [01:44<00:48,  3.33it/s] 68%|██████▊   | 339/500 [01:45<00:48,  3.33it/s] 68%|██████▊   | 340/500 [01:45<00:48,  3.32it/s] 68%|██████▊   | 341/500 [01:45<00:47,  3.33it/s] 68%|██████▊   | 342/500 [01:45<00:47,  3.34it/s] 69%|██████▊   | 343/500 [01:46<00:47,  3.34it/s] 69%|██████▉   | 344/500 [01:46<00:46,  3.34it/s] 69%|██████▉   | 345/500 [01:46<00:46,  3.34it/s] 69%|██████▉   | 346/500 [01:47<00:46,  3.34it/s] 69%|██████▉   | 347/500 [01:47<00:45,  3.34it/s] 70%|██████▉   | 348/500 [01:47<00:45,  3.34it/s] 70%|██████▉   | 349/500 [01:48<00:45,  3.34it/s] 70%|███████   | 350/500 [01:48<00:44,  3.34it/s] 70%|███████   | 351/500 [01:48<00:44,  3.34it/s] 70%|███████   | 352/500 [01:48<00:44,  3.34it/s] 71%|███████   | 353/500 [01:49<00:44,  3.31it/s] 71%|███████   | 354/500 [01:49<00:44,  3.31it/s] 71%|███████   | 355/500 [01:49<00:43,  3.31it/s] 71%|███████   | 356/500 [01:50<00:43,  3.31it/s] 71%|███████▏  | 357/500 [01:50<00:43,  3.31it/s] 72%|███████▏  | 358/500 [01:50<00:42,  3.32it/s] 72%|███████▏  | 359/500 [01:51<00:42,  3.33it/s] 72%|███████▏  | 360/500 [01:51<00:41,  3.33it/s] 72%|███████▏  | 361/500 [01:51<00:41,  3.34it/s] 72%|███████▏  | 362/500 [01:51<00:41,  3.34it/s] 73%|███████▎  | 363/500 [01:52<00:41,  3.34it/s] 73%|███████▎  | 364/500 [01:52<00:40,  3.34it/s] 73%|███████▎  | 365/500 [01:52<00:40,  3.34it/s] 73%|███████▎  | 366/500 [01:53<00:40,  3.34it/s] 73%|███████▎  | 367/500 [01:53<00:39,  3.34it/s] 74%|███████▎  | 368/500 [01:53<00:39,  3.34it/s] 74%|███████▍  | 369/500 [01:54<00:39,  3.34it/s] 74%|███████▍  | 370/500 [01:54<00:38,  3.34it/s] 74%|███████▍  | 371/500 [01:54<00:38,  3.34it/s] 74%|███████▍  | 372/500 [01:54<00:38,  3.34it/s] 75%|███████▍  | 373/500 [01:55<00:37,  3.34it/s] 75%|███████▍  | 374/500 [01:55<00:37,  3.34it/s] 75%|███████▌  | 375/500 [01:55<00:37,  3.34it/s] 75%|███████▌  | 376/500 [01:56<00:37,  3.34it/s] 75%|███████▌  | 377/500 [01:56<00:36,  3.34it/s] 76%|███████▌  | 378/500 [01:56<00:36,  3.34it/s] 76%|███████▌  | 379/500 [01:57<00:36,  3.34it/s] 76%|███████▌  | 380/500 [01:57<00:35,  3.34it/s] 76%|███████▌  | 381/500 [01:57<00:35,  3.34it/s] 76%|███████▋  | 382/500 [01:57<00:35,  3.34it/s] 77%|███████▋  | 383/500 [01:58<00:34,  3.34it/s] 77%|███████▋  | 384/500 [01:58<00:34,  3.34it/s] 77%|███████▋  | 385/500 [01:58<00:34,  3.34it/s] 77%|███████▋  | 386/500 [01:59<00:34,  3.34it/s] 77%|███████▋  | 387/500 [01:59<00:33,  3.34it/s] 78%|███████▊  | 388/500 [01:59<00:33,  3.34it/s] 78%|███████▊  | 389/500 [02:00<00:33,  3.35it/s] 78%|███████▊  | 390/500 [02:00<00:32,  3.35it/s] 78%|███████▊  | 391/500 [02:00<00:32,  3.35it/s] 78%|███████▊  | 392/500 [02:00<00:32,  3.35it/s] 79%|███████▊  | 393/500 [02:01<00:31,  3.35it/s] 79%|███████▉  | 394/500 [02:01<00:31,  3.34it/s] 79%|███████▉  | 395/500 [02:01<00:31,  3.35it/s] 79%|███████▉  | 396/500 [02:02<00:31,  3.34it/s] 79%|███████▉  | 397/500 [02:02<00:30,  3.34it/s] 80%|███████▉  | 398/500 [02:02<00:30,  3.34it/s] 80%|███████▉  | 399/500 [02:02<00:30,  3.34it/s] 80%|████████  | 400/500 [02:03<00:29,  3.34it/s] 80%|████████  | 401/500 [02:03<00:29,  3.34it/s] 80%|████████  | 402/500 [02:03<00:29,  3.34it/s] 81%|████████  | 403/500 [02:04<00:29,  3.34it/s] 81%|████████  | 404/500 [02:04<00:28,  3.34it/s] 81%|████████  | 405/500 [02:04<00:28,  3.33it/s] 81%|████████  | 406/500 [02:05<00:28,  3.34it/s] 81%|████████▏ | 407/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 408/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 409/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 410/500 [02:06<00:26,  3.34it/s] 82%|████████▏ | 411/500 [02:06<00:26,  3.34it/s] 82%|████████▏ | 412/500 [02:06<00:26,  3.34it/s] 83%|████████▎ | 413/500 [02:07<00:26,  3.34it/s] 83%|████████▎ | 414/500 [02:07<00:25,  3.34it/s] 83%|████████▎ | 415/500 [02:07<00:25,  3.34it/s] 83%|████████▎ | 416/500 [02:08<00:25,  3.34it/s] 83%|████████▎ | 417/500 [02:08<00:24,  3.34it/s] 84%|████████▎ | 418/500 [02:08<00:24,  3.33it/s] 84%|████████▍ | 419/500 [02:08<00:24,  3.33it/s] 84%|████████▍ | 420/500 [02:09<00:23,  3.34it/s] 84%|████████▍ | 421/500 [02:09<00:23,  3.33it/s] 84%|████████▍ | 422/500 [02:09<00:23,  3.33it/s] 85%|████████▍ | 423/500 [02:10<00:23,  3.33it/s] 85%|████████▍ | 424/500 [02:10<00:22,  3.33it/s] 85%|████████▌ | 425/500 [02:10<00:22,  3.33it/s] 85%|████████▌ | 426/500 [02:11<00:22,  3.34it/s] 85%|████████▌ | 427/500 [02:11<00:21,  3.34it/s] 86%|████████▌ | 428/500 [02:11<00:21,  3.34it/s] 86%|████████▌ | 429/500 [02:11<00:21,  3.34it/s] 86%|████████▌ | 430/500 [02:12<00:20,  3.34it/s] 86%|████████▌ | 431/500 [02:12<00:20,  3.33it/s] 86%|████████▋ | 432/500 [02:12<00:20,  3.33it/s] 87%|████████▋ | 433/500 [02:13<00:20,  3.33it/s] 87%|████████▋ | 434/500 [02:13<00:19,  3.33it/s] 87%|████████▋ | 435/500 [02:13<00:19,  3.33it/s] 87%|████████▋ | 436/500 [02:14<00:19,  3.33it/s] 87%|████████▋ | 437/500 [02:14<00:18,  3.33it/s] 88%|████████▊ | 438/500 [02:14<00:18,  3.33it/s] 88%|████████▊ | 439/500 [02:14<00:18,  3.34it/s] 88%|████████▊ | 440/500 [02:15<00:17,  3.34it/s] 88%|████████▊ | 441/500 [02:15<00:17,  3.34it/s] 88%|████████▊ | 442/500 [02:15<00:17,  3.34it/s] 89%|████████▊ | 443/500 [02:16<00:17,  3.34it/s] 89%|████████▉ | 444/500 [02:16<00:16,  3.34it/s] 89%|████████▉ | 445/500 [02:16<00:16,  3.34it/s] 89%|████████▉ | 446/500 [02:17<00:16,  3.35it/s] 89%|████████▉ | 447/500 [02:17<00:15,  3.35it/s] 90%|████████▉ | 448/500 [02:17<00:15,  3.35it/s] 90%|████████▉ | 449/500 [02:17<00:15,  3.35it/s] 90%|█████████ | 450/500 [02:18<00:14,  3.35it/s] 90%|█████████ | 451/500 [02:18<00:14,  3.35it/s] 90%|█████████ | 452/500 [02:18<00:14,  3.35it/s] 91%|█████████ | 453/500 [02:19<00:14,  3.35it/s] 91%|█████████ | 454/500 [02:19<00:13,  3.34it/s] 91%|█████████ | 455/500 [02:19<00:13,  3.35it/s] 91%|█████████ | 456/500 [02:20<00:13,  3.34it/s] 91%|█████████▏| 457/500 [02:20<00:12,  3.34it/s] 92%|█████████▏| 458/500 [02:20<00:12,  3.34it/s] 92%|█████████▏| 459/500 [02:20<00:12,  3.34it/s] 92%|█████████▏| 460/500 [02:21<00:11,  3.34it/s] 92%|█████████▏| 461/500 [02:21<00:11,  3.34it/s] 92%|█████████▏| 462/500 [02:21<00:11,  3.34it/s] 93%|█████████▎| 463/500 [02:22<00:11,  3.34it/s] 93%|█████████▎| 464/500 [02:22<00:10,  3.34it/s] 93%|█████████▎| 465/500 [02:22<00:10,  3.34it/s] 93%|█████████▎| 466/500 [02:23<00:10,  3.34it/s] 93%|█████████▎| 467/500 [02:23<00:09,  3.34it/s] 94%|█████████▎| 468/500 [02:23<00:09,  3.34it/s] 94%|█████████▍| 469/500 [02:23<00:09,  3.34it/s] 94%|█████████▍| 470/500 [02:24<00:08,  3.34it/s] 94%|█████████▍| 471/500 [02:24<00:08,  3.34it/s] 94%|█████████▍| 472/500 [02:24<00:08,  3.34it/s] 95%|█████████▍| 473/500 [02:25<00:08,  3.34it/s] 95%|█████████▍| 474/500 [02:25<00:07,  3.34it/s] 95%|█████████▌| 475/500 [02:25<00:07,  3.34it/s] 95%|█████████▌| 476/500 [02:26<00:07,  3.34it/s] 95%|█████████▌| 477/500 [02:26<00:06,  3.34it/s] 96%|█████████▌| 478/500 [02:26<00:06,  3.34it/s] 96%|█████████▌| 479/500 [02:26<00:06,  3.34it/s] 96%|█████████▌| 480/500 [02:27<00:05,  3.34it/s] 96%|█████████▌| 481/500 [02:27<00:05,  3.34it/s] 96%|█████████▋| 482/500 [02:27<00:05,  3.34it/s] 97%|█████████▋| 483/500 [02:28<00:05,  3.34it/s] 97%|█████████▋| 484/500 [02:28<00:04,  3.34it/s] 97%|█████████▋| 485/500 [02:28<00:04,  3.34it/s] 97%|█████████▋| 486/500 [02:29<00:04,  3.34it/s] 97%|█████████▋| 487/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 488/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 489/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 490/500 [02:30<00:02,  3.35it/s] 98%|█████████▊| 491/500 [02:30<00:02,  3.35it/s] 98%|█████████▊| 492/500 [02:30<00:02,  3.35it/s] 99%|█████████▊| 493/500 [02:31<00:02,  3.35it/s] 99%|█████████▉| 494/500 [02:31<00:01,  3.36it/s] 99%|█████████▉| 495/500 [02:31<00:01,  3.35it/s] 99%|█████████▉| 496/500 [02:32<00:01,  3.35it/s] 99%|█████████▉| 497/500 [02:32<00:00,  3.35it/s]100%|█████████▉| 498/500 [02:32<00:00,  3.35it/s]100%|█████████▉| 499/500 [02:32<00:00,  3.35it/s]100%|██████████| 500/500 [02:33<00:00,  3.36it/s]100%|██████████| 500/500 [02:33<00:00,  3.26it/s]
=> result
* total: 50,000
* correct: 17,647
* accuracy: 35.3%
* error: 64.7%
* macro_f1: 30.6%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers caltech101 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/caltech101/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/caltech101/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_1.pkl
1600 1649 2465
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      1,649
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:16,  3.17s/it]  8%|▊         | 2/25 [00:03<00:31,  1.38s/it] 12%|█▏        | 3/25 [00:03<00:17,  1.24it/s] 16%|█▌        | 4/25 [00:03<00:11,  1.87it/s] 20%|██        | 5/25 [00:03<00:07,  2.59it/s] 24%|██▍       | 6/25 [00:03<00:05,  3.38it/s] 28%|██▊       | 7/25 [00:03<00:04,  4.18it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.96it/s] 36%|███▌      | 9/25 [00:04<00:02,  5.66it/s] 40%|████      | 10/25 [00:04<00:02,  6.27it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.77it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.16it/s] 52%|█████▏    | 13/25 [00:04<00:01,  7.46it/s] 56%|█████▌    | 14/25 [00:04<00:01,  7.69it/s] 60%|██████    | 15/25 [00:04<00:01,  7.86it/s] 64%|██████▍   | 16/25 [00:04<00:01,  7.98it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.07it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.13it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.17it/s] 80%|████████  | 20/25 [00:05<00:00,  8.20it/s] 84%|████████▍ | 21/25 [00:05<00:00,  8.21it/s] 88%|████████▊ | 22/25 [00:05<00:00,  8.22it/s] 92%|█████████▏| 23/25 [00:05<00:00,  8.23it/s] 96%|█████████▌| 24/25 [00:05<00:00,  8.24it/s]100%|██████████| 25/25 [00:06<00:00,  4.08it/s]
=> result
* total: 2,465
* correct: 1,688
* accuracy: 68.5%
* error: 31.5%
* macro_f1: 59.2%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers caltech101 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/caltech101/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/caltech101/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_2.pkl
1600 1649 2465
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      1,649
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:13,  3.06s/it]  8%|▊         | 2/25 [00:03<00:30,  1.33s/it] 12%|█▏        | 3/25 [00:03<00:17,  1.28it/s] 16%|█▌        | 4/25 [00:03<00:10,  1.92it/s] 20%|██        | 5/25 [00:03<00:07,  2.65it/s] 24%|██▍       | 6/25 [00:03<00:05,  3.45it/s] 28%|██▊       | 7/25 [00:03<00:04,  4.25it/s] 32%|███▏      | 8/25 [00:03<00:03,  5.03it/s] 36%|███▌      | 9/25 [00:04<00:02,  5.72it/s] 40%|████      | 10/25 [00:04<00:02,  6.32it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.80it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.19it/s] 52%|█████▏    | 13/25 [00:04<00:01,  7.49it/s] 56%|█████▌    | 14/25 [00:04<00:01,  7.71it/s] 60%|██████    | 15/25 [00:04<00:01,  7.88it/s] 64%|██████▍   | 16/25 [00:04<00:01,  7.99it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.07it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.13it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.17it/s] 80%|████████  | 20/25 [00:05<00:00,  8.19it/s] 84%|████████▍ | 21/25 [00:05<00:00,  8.21it/s] 88%|████████▊ | 22/25 [00:05<00:00,  8.24it/s] 92%|█████████▏| 23/25 [00:05<00:00,  8.25it/s] 96%|█████████▌| 24/25 [00:05<00:00,  8.25it/s]100%|██████████| 25/25 [00:06<00:00,  4.15it/s]
=> result
* total: 2,465
* correct: 1,714
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 63.6%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers caltech101 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/caltech101/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/caltech101/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_3.pkl
1600 1649 2465
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      1,649
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:02<01:10,  2.95s/it]  8%|▊         | 2/25 [00:03<00:29,  1.29s/it] 12%|█▏        | 3/25 [00:03<00:16,  1.32it/s] 16%|█▌        | 4/25 [00:03<00:10,  1.98it/s] 20%|██        | 5/25 [00:03<00:07,  2.73it/s] 24%|██▍       | 6/25 [00:03<00:05,  3.53it/s] 28%|██▊       | 7/25 [00:03<00:04,  4.34it/s] 32%|███▏      | 8/25 [00:03<00:03,  5.11it/s] 36%|███▌      | 9/25 [00:03<00:02,  5.80it/s] 40%|████      | 10/25 [00:04<00:02,  6.38it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.85it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.23it/s] 52%|█████▏    | 13/25 [00:04<00:01,  7.52it/s] 56%|█████▌    | 14/25 [00:04<00:01,  7.74it/s] 60%|██████    | 15/25 [00:04<00:01,  7.88it/s] 64%|██████▍   | 16/25 [00:04<00:01,  8.00it/s] 68%|██████▊   | 17/25 [00:04<00:00,  8.09it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.15it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.19it/s] 80%|████████  | 20/25 [00:05<00:00,  8.22it/s] 84%|████████▍ | 21/25 [00:05<00:00,  8.18it/s] 88%|████████▊ | 22/25 [00:05<00:00,  8.21it/s] 92%|█████████▏| 23/25 [00:05<00:00,  8.23it/s] 96%|█████████▌| 24/25 [00:05<00:00,  8.24it/s]100%|██████████| 25/25 [00:05<00:00,  4.24it/s]
=> result
* total: 2,465
* correct: 1,718
* accuracy: 69.7%
* error: 30.3%
* macro_f1: 59.5%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers oxford_pets 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_pets/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_pets/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_1.pkl
592 736 3669
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      736
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/37 [00:00<?, ?it/s]  3%|▎         | 1/37 [00:03<02:08,  3.58s/it]  5%|▌         | 2/37 [00:03<00:53,  1.54s/it]  8%|▊         | 3/37 [00:03<00:30,  1.13it/s] 11%|█         | 4/37 [00:03<00:19,  1.73it/s] 14%|█▎        | 5/37 [00:04<00:13,  2.44it/s] 16%|█▌        | 6/37 [00:04<00:09,  3.25it/s] 19%|█▉        | 7/37 [00:04<00:07,  4.12it/s] 22%|██▏       | 8/37 [00:04<00:05,  4.99it/s] 24%|██▍       | 9/37 [00:04<00:04,  5.82it/s] 27%|██▋       | 10/37 [00:04<00:04,  6.55it/s] 30%|██▉       | 11/37 [00:04<00:03,  7.17it/s] 32%|███▏      | 12/37 [00:04<00:03,  7.66it/s] 35%|███▌      | 13/37 [00:04<00:03,  7.99it/s] 38%|███▊      | 14/37 [00:05<00:02,  8.31it/s] 41%|████      | 15/37 [00:05<00:02,  8.54it/s] 43%|████▎     | 16/37 [00:05<00:02,  8.71it/s] 46%|████▌     | 17/37 [00:05<00:02,  8.82it/s] 49%|████▊     | 18/37 [00:05<00:02,  8.90it/s] 51%|█████▏    | 19/37 [00:05<00:02,  8.97it/s] 54%|█████▍    | 20/37 [00:05<00:01,  9.02it/s] 57%|█████▋    | 21/37 [00:05<00:01,  9.04it/s] 59%|█████▉    | 22/37 [00:05<00:01,  9.04it/s] 62%|██████▏   | 23/37 [00:05<00:01,  9.07it/s] 65%|██████▍   | 24/37 [00:06<00:01,  9.05it/s] 68%|██████▊   | 25/37 [00:06<00:01,  9.07it/s] 70%|███████   | 26/37 [00:06<00:01,  9.09it/s] 73%|███████▎  | 27/37 [00:06<00:01,  9.10it/s] 76%|███████▌  | 28/37 [00:06<00:00,  9.13it/s] 78%|███████▊  | 29/37 [00:06<00:00,  9.14it/s] 81%|████████  | 30/37 [00:06<00:00,  9.12it/s] 84%|████████▍ | 31/37 [00:06<00:00,  9.13it/s] 86%|████████▋ | 32/37 [00:06<00:00,  9.15it/s] 89%|████████▉ | 33/37 [00:07<00:00,  9.17it/s] 92%|█████████▏| 34/37 [00:07<00:00,  9.16it/s] 95%|█████████▍| 35/37 [00:07<00:00,  9.17it/s] 97%|█████████▋| 36/37 [00:07<00:00,  9.19it/s]100%|██████████| 37/37 [00:07<00:00,  4.89it/s]
=> result
* total: 3,669
* correct: 2,288
* accuracy: 62.4%
* error: 37.6%
* macro_f1: 53.3%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers oxford_pets 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_pets/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_pets/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_2.pkl
592 736 3669
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      736
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/37 [00:00<?, ?it/s]  3%|▎         | 1/37 [00:03<01:55,  3.20s/it]  5%|▌         | 2/37 [00:03<00:48,  1.38s/it]  8%|▊         | 3/37 [00:03<00:27,  1.25it/s] 11%|█         | 4/37 [00:03<00:17,  1.89it/s] 14%|█▎        | 5/37 [00:03<00:12,  2.65it/s] 16%|█▌        | 6/37 [00:03<00:08,  3.50it/s] 19%|█▉        | 7/37 [00:03<00:06,  4.38it/s] 22%|██▏       | 8/37 [00:03<00:05,  5.25it/s] 24%|██▍       | 9/37 [00:04<00:04,  6.04it/s] 27%|██▋       | 10/37 [00:04<00:04,  6.75it/s] 30%|██▉       | 11/37 [00:04<00:03,  7.33it/s] 32%|███▏      | 12/37 [00:04<00:03,  7.78it/s] 35%|███▌      | 13/37 [00:04<00:02,  8.09it/s] 38%|███▊      | 14/37 [00:04<00:02,  8.35it/s] 41%|████      | 15/37 [00:04<00:02,  8.56it/s] 43%|████▎     | 16/37 [00:04<00:02,  8.72it/s] 46%|████▌     | 17/37 [00:04<00:02,  8.83it/s] 49%|████▊     | 18/37 [00:05<00:02,  8.92it/s] 51%|█████▏    | 19/37 [00:05<00:02,  8.95it/s] 54%|█████▍    | 20/37 [00:05<00:01,  9.00it/s] 57%|█████▋    | 21/37 [00:05<00:01,  9.03it/s] 59%|█████▉    | 22/37 [00:05<00:01,  9.01it/s] 62%|██████▏   | 23/37 [00:05<00:01,  9.04it/s] 65%|██████▍   | 24/37 [00:05<00:01,  9.07it/s] 68%|██████▊   | 25/37 [00:05<00:01,  9.08it/s] 70%|███████   | 26/37 [00:05<00:01,  9.08it/s] 73%|███████▎  | 27/37 [00:06<00:01,  9.09it/s] 76%|███████▌  | 28/37 [00:06<00:00,  9.12it/s] 78%|███████▊  | 29/37 [00:06<00:00,  9.15it/s] 81%|████████  | 30/37 [00:06<00:00,  9.16it/s] 84%|████████▍ | 31/37 [00:06<00:00,  9.18it/s] 86%|████████▋ | 32/37 [00:06<00:00,  9.20it/s] 89%|████████▉ | 33/37 [00:06<00:00,  9.22it/s] 92%|█████████▏| 34/37 [00:06<00:00,  9.22it/s] 95%|█████████▍| 35/37 [00:06<00:00,  9.23it/s] 97%|█████████▋| 36/37 [00:07<00:00,  9.24it/s]100%|██████████| 37/37 [00:07<00:00,  5.15it/s]
=> result
* total: 3,669
* correct: 1,937
* accuracy: 52.8%
* error: 47.2%
* macro_f1: 45.5%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers oxford_pets 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_pets/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_pets/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_3.pkl
592 736 3669
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      736
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/37 [00:00<?, ?it/s]  3%|▎         | 1/37 [00:03<02:01,  3.38s/it]  5%|▌         | 2/37 [00:03<00:50,  1.45s/it]  8%|▊         | 3/37 [00:03<00:28,  1.19it/s] 11%|█         | 4/37 [00:03<00:18,  1.82it/s] 14%|█▎        | 5/37 [00:03<00:12,  2.56it/s] 16%|█▌        | 6/37 [00:03<00:09,  3.39it/s] 19%|█▉        | 7/37 [00:04<00:07,  4.27it/s] 22%|██▏       | 8/37 [00:04<00:05,  5.15it/s] 24%|██▍       | 9/37 [00:04<00:04,  5.97it/s] 27%|██▋       | 10/37 [00:04<00:04,  6.69it/s] 30%|██▉       | 11/37 [00:04<00:03,  7.29it/s] 32%|███▏      | 12/37 [00:04<00:03,  7.78it/s] 35%|███▌      | 13/37 [00:04<00:02,  8.15it/s] 38%|███▊      | 14/37 [00:04<00:02,  8.44it/s] 41%|████      | 15/37 [00:04<00:02,  8.65it/s] 43%|████▎     | 16/37 [00:05<00:02,  8.79it/s] 46%|████▌     | 17/37 [00:05<00:02,  8.91it/s] 49%|████▊     | 18/37 [00:05<00:02,  8.99it/s] 51%|█████▏    | 19/37 [00:05<00:01,  9.04it/s] 54%|█████▍    | 20/37 [00:05<00:01,  9.08it/s] 57%|█████▋    | 21/37 [00:05<00:01,  9.12it/s] 59%|█████▉    | 22/37 [00:05<00:01,  9.12it/s] 62%|██████▏   | 23/37 [00:05<00:01,  9.13it/s] 65%|██████▍   | 24/37 [00:05<00:01,  9.15it/s] 68%|██████▊   | 25/37 [00:05<00:01,  9.07it/s] 70%|███████   | 26/37 [00:06<00:01,  9.13it/s] 73%|███████▎  | 27/37 [00:06<00:01,  9.16it/s] 76%|███████▌  | 28/37 [00:06<00:00,  9.19it/s] 78%|███████▊  | 29/37 [00:06<00:00,  9.21it/s] 81%|████████  | 30/37 [00:06<00:00,  9.23it/s] 84%|████████▍ | 31/37 [00:06<00:00,  9.15it/s] 86%|████████▋ | 32/37 [00:06<00:00,  9.18it/s] 89%|████████▉ | 33/37 [00:06<00:00,  9.20it/s] 92%|█████████▏| 34/37 [00:06<00:00,  9.21it/s] 95%|█████████▍| 35/37 [00:07<00:00,  9.22it/s] 97%|█████████▋| 36/37 [00:07<00:00,  9.23it/s]100%|██████████| 37/37 [00:07<00:00,  5.05it/s]
=> result
* total: 3,669
* correct: 1,645
* accuracy: 44.8%
* error: 55.2%
* macro_f1: 35.9%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers stanford_cars 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/stanford_cars/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/stanford_cars/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_1.pkl
3136 1635 8041
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  196
# train_x  3,136
# val      1,635
# test     8,041
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:04<05:38,  4.23s/it]  2%|▏         | 2/81 [00:04<02:24,  1.83s/it]  4%|▎         | 3/81 [00:04<01:22,  1.06s/it]  5%|▍         | 4/81 [00:04<00:53,  1.44it/s]  6%|▌         | 5/81 [00:04<00:37,  2.02it/s]  7%|▋         | 6/81 [00:04<00:28,  2.68it/s]  9%|▊         | 7/81 [00:05<00:22,  3.36it/s] 10%|▉         | 8/81 [00:05<00:18,  4.04it/s] 11%|█         | 9/81 [00:05<00:15,  4.67it/s] 12%|█▏        | 10/81 [00:05<00:13,  5.23it/s] 14%|█▎        | 11/81 [00:05<00:12,  5.70it/s] 15%|█▍        | 12/81 [00:05<00:11,  6.08it/s] 16%|█▌        | 13/81 [00:05<00:10,  6.35it/s] 17%|█▋        | 14/81 [00:06<00:10,  6.58it/s] 19%|█▊        | 15/81 [00:06<00:09,  6.74it/s] 20%|█▉        | 16/81 [00:06<00:09,  6.85it/s] 21%|██        | 17/81 [00:06<00:09,  6.90it/s] 22%|██▏       | 18/81 [00:06<00:09,  6.97it/s] 23%|██▎       | 19/81 [00:06<00:08,  7.01it/s] 25%|██▍       | 20/81 [00:06<00:08,  7.04it/s] 26%|██▌       | 21/81 [00:07<00:08,  7.05it/s] 27%|██▋       | 22/81 [00:07<00:08,  7.07it/s] 28%|██▊       | 23/81 [00:07<00:08,  7.09it/s] 30%|██▉       | 24/81 [00:07<00:08,  7.09it/s] 31%|███       | 25/81 [00:07<00:07,  7.08it/s] 32%|███▏      | 26/81 [00:07<00:07,  7.09it/s] 33%|███▎      | 27/81 [00:07<00:07,  7.10it/s] 35%|███▍      | 28/81 [00:08<00:07,  7.08it/s] 36%|███▌      | 29/81 [00:08<00:07,  7.09it/s] 37%|███▋      | 30/81 [00:08<00:07,  7.10it/s] 38%|███▊      | 31/81 [00:08<00:07,  7.09it/s] 40%|███▉      | 32/81 [00:08<00:06,  7.10it/s] 41%|████      | 33/81 [00:09<00:13,  3.69it/s] 42%|████▏     | 34/81 [00:09<00:10,  4.31it/s] 43%|████▎     | 35/81 [00:09<00:09,  4.88it/s] 44%|████▍     | 36/81 [00:09<00:08,  5.39it/s] 46%|████▌     | 37/81 [00:09<00:07,  5.80it/s] 47%|████▋     | 38/81 [00:09<00:07,  6.14it/s] 48%|████▊     | 39/81 [00:10<00:06,  6.40it/s] 49%|████▉     | 40/81 [00:10<00:06,  6.59it/s] 51%|█████     | 41/81 [00:10<00:10,  3.79it/s] 52%|█████▏    | 42/81 [00:10<00:08,  4.40it/s] 53%|█████▎    | 43/81 [00:11<00:08,  4.25it/s] 54%|█████▍    | 44/81 [00:11<00:07,  4.84it/s] 56%|█████▌    | 45/81 [00:11<00:06,  5.34it/s] 57%|█████▋    | 46/81 [00:11<00:06,  5.76it/s] 58%|█████▊    | 47/81 [00:11<00:05,  6.08it/s] 59%|█████▉    | 48/81 [00:12<00:09,  3.31it/s] 60%|██████    | 49/81 [00:12<00:08,  3.94it/s] 62%|██████▏   | 50/81 [00:12<00:06,  4.55it/s] 63%|██████▎   | 51/81 [00:12<00:05,  5.09it/s] 64%|██████▍   | 52/81 [00:12<00:05,  5.57it/s] 65%|██████▌   | 53/81 [00:12<00:04,  5.96it/s] 67%|██████▋   | 54/81 [00:13<00:04,  6.26it/s] 68%|██████▊   | 55/81 [00:13<00:04,  6.48it/s] 69%|██████▉   | 56/81 [00:13<00:06,  3.72it/s] 70%|███████   | 57/81 [00:13<00:05,  4.34it/s] 72%|███████▏  | 58/81 [00:14<00:04,  4.90it/s] 73%|███████▎  | 59/81 [00:14<00:04,  5.40it/s] 74%|███████▍  | 60/81 [00:14<00:03,  5.81it/s] 75%|███████▌  | 61/81 [00:14<00:03,  6.14it/s] 77%|███████▋  | 62/81 [00:14<00:02,  6.39it/s] 78%|███████▊  | 63/81 [00:14<00:02,  6.57it/s] 79%|███████▉  | 64/81 [00:15<00:03,  4.31it/s] 80%|████████  | 65/81 [00:15<00:03,  4.15it/s] 81%|████████▏ | 66/81 [00:15<00:03,  4.74it/s] 83%|████████▎ | 67/81 [00:15<00:02,  5.26it/s] 84%|████████▍ | 68/81 [00:15<00:02,  5.69it/s] 85%|████████▌ | 69/81 [00:16<00:01,  6.04it/s] 86%|████████▋ | 70/81 [00:16<00:01,  6.32it/s] 88%|████████▊ | 71/81 [00:16<00:01,  6.51it/s] 89%|████████▉ | 72/81 [00:16<00:01,  6.63it/s] 90%|█████████ | 73/81 [00:16<00:01,  6.77it/s] 91%|█████████▏| 74/81 [00:16<00:01,  6.88it/s] 93%|█████████▎| 75/81 [00:17<00:01,  4.72it/s] 94%|█████████▍| 76/81 [00:17<00:00,  5.25it/s] 95%|█████████▌| 77/81 [00:17<00:00,  5.71it/s] 96%|█████████▋| 78/81 [00:17<00:00,  6.08it/s] 98%|█████████▊| 79/81 [00:17<00:00,  6.37it/s] 99%|█████████▉| 80/81 [00:17<00:00,  6.59it/s]100%|██████████| 81/81 [00:17<00:00,  4.51it/s]
=> result
* total: 8,041
* correct: 3,470
* accuracy: 43.2%
* error: 56.8%
* macro_f1: 38.7%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers stanford_cars 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/stanford_cars/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/stanford_cars/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_2.pkl
3136 1635 8041
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  196
# train_x  3,136
# val      1,635
# test     8,041
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:04<05:22,  4.03s/it]  2%|▏         | 2/81 [00:04<02:17,  1.74s/it]  4%|▎         | 3/81 [00:04<01:18,  1.01s/it]  5%|▍         | 4/81 [00:04<00:51,  1.50it/s]  6%|▌         | 5/81 [00:04<00:36,  2.10it/s]  7%|▋         | 6/81 [00:04<00:27,  2.76it/s]  9%|▊         | 7/81 [00:04<00:21,  3.46it/s] 10%|▉         | 8/81 [00:05<00:17,  4.12it/s] 11%|█         | 9/81 [00:05<00:15,  4.75it/s] 12%|█▏        | 10/81 [00:05<00:13,  5.29it/s] 14%|█▎        | 11/81 [00:05<00:12,  5.74it/s] 15%|█▍        | 12/81 [00:05<00:11,  6.10it/s] 16%|█▌        | 13/81 [00:05<00:10,  6.38it/s] 17%|█▋        | 14/81 [00:05<00:10,  6.58it/s] 19%|█▊        | 15/81 [00:05<00:09,  6.73it/s] 20%|█▉        | 16/81 [00:06<00:09,  6.83it/s] 21%|██        | 17/81 [00:06<00:09,  6.90it/s] 22%|██▏       | 18/81 [00:06<00:09,  6.95it/s] 23%|██▎       | 19/81 [00:06<00:08,  6.97it/s] 25%|██▍       | 20/81 [00:06<00:08,  6.98it/s] 26%|██▌       | 21/81 [00:06<00:08,  7.00it/s] 27%|██▋       | 22/81 [00:06<00:08,  7.04it/s] 28%|██▊       | 23/81 [00:07<00:08,  7.06it/s] 30%|██▉       | 24/81 [00:07<00:08,  7.07it/s] 31%|███       | 25/81 [00:07<00:07,  7.08it/s] 32%|███▏      | 26/81 [00:07<00:07,  7.08it/s] 33%|███▎      | 27/81 [00:07<00:07,  7.08it/s] 35%|███▍      | 28/81 [00:07<00:07,  7.08it/s] 36%|███▌      | 29/81 [00:07<00:07,  7.08it/s] 37%|███▋      | 30/81 [00:08<00:10,  4.83it/s] 38%|███▊      | 31/81 [00:08<00:09,  5.33it/s] 40%|███▉      | 32/81 [00:08<00:08,  5.75it/s] 41%|████      | 33/81 [00:08<00:07,  6.08it/s] 42%|████▏     | 34/81 [00:08<00:07,  6.33it/s] 43%|████▎     | 35/81 [00:09<00:07,  6.53it/s] 44%|████▍     | 36/81 [00:09<00:06,  6.69it/s] 46%|████▌     | 37/81 [00:09<00:06,  6.79it/s] 47%|████▋     | 38/81 [00:09<00:08,  5.37it/s] 48%|████▊     | 39/81 [00:09<00:07,  5.78it/s] 49%|████▉     | 40/81 [00:09<00:06,  6.10it/s] 51%|█████     | 41/81 [00:10<00:06,  6.36it/s] 52%|█████▏    | 42/81 [00:10<00:05,  6.55it/s] 53%|█████▎    | 43/81 [00:10<00:05,  6.68it/s] 54%|█████▍    | 44/81 [00:10<00:05,  6.78it/s] 56%|█████▌    | 45/81 [00:10<00:05,  6.85it/s] 57%|█████▋    | 46/81 [00:10<00:05,  6.92it/s] 58%|█████▊    | 47/81 [00:10<00:04,  6.98it/s] 59%|█████▉    | 48/81 [00:11<00:04,  6.96it/s] 60%|██████    | 49/81 [00:11<00:04,  7.00it/s] 62%|██████▏   | 50/81 [00:11<00:04,  7.03it/s] 63%|██████▎   | 51/81 [00:11<00:04,  7.03it/s] 64%|██████▍   | 52/81 [00:11<00:04,  7.05it/s] 65%|██████▌   | 53/81 [00:11<00:03,  7.06it/s] 67%|██████▋   | 54/81 [00:12<00:08,  3.07it/s] 68%|██████▊   | 55/81 [00:12<00:07,  3.69it/s] 69%|██████▉   | 56/81 [00:12<00:05,  4.31it/s] 70%|███████   | 57/81 [00:12<00:04,  4.88it/s] 72%|███████▏  | 58/81 [00:13<00:04,  5.39it/s] 73%|███████▎  | 59/81 [00:13<00:03,  5.81it/s] 74%|███████▍  | 60/81 [00:13<00:03,  6.13it/s] 75%|███████▌  | 61/81 [00:13<00:03,  6.38it/s] 77%|███████▋  | 62/81 [00:13<00:04,  3.94it/s] 78%|███████▊  | 63/81 [00:14<00:03,  4.50it/s] 79%|███████▉  | 64/81 [00:14<00:03,  5.05it/s] 80%|████████  | 65/81 [00:14<00:02,  5.53it/s] 81%|████████▏ | 66/81 [00:14<00:02,  5.91it/s] 83%|████████▎ | 67/81 [00:14<00:02,  6.22it/s] 84%|████████▍ | 68/81 [00:14<00:02,  6.46it/s] 85%|████████▌ | 69/81 [00:14<00:01,  6.64it/s] 86%|████████▋ | 70/81 [00:15<00:01,  6.76it/s] 88%|████████▊ | 71/81 [00:15<00:01,  6.86it/s] 89%|████████▉ | 72/81 [00:15<00:01,  6.94it/s] 90%|█████████ | 73/81 [00:15<00:01,  6.99it/s] 91%|█████████▏| 74/81 [00:15<00:00,  7.02it/s] 93%|█████████▎| 75/81 [00:15<00:00,  7.06it/s] 94%|█████████▍| 76/81 [00:15<00:00,  7.09it/s] 95%|█████████▌| 77/81 [00:16<00:00,  7.11it/s] 96%|█████████▋| 78/81 [00:16<00:00,  7.12it/s] 98%|█████████▊| 79/81 [00:16<00:00,  7.12it/s] 99%|█████████▉| 80/81 [00:16<00:00,  7.13it/s]100%|██████████| 81/81 [00:16<00:00,  4.86it/s]
=> result
* total: 8,041
* correct: 4,068
* accuracy: 50.6%
* error: 49.4%
* macro_f1: 46.6%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers stanford_cars 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/stanford_cars/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/stanford_cars/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_3.pkl
3136 1635 8041
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  196
# train_x  3,136
# val      1,635
# test     8,041
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:03<05:12,  3.90s/it]  2%|▏         | 2/81 [00:04<02:13,  1.69s/it]  4%|▎         | 3/81 [00:04<01:16,  1.02it/s]  5%|▍         | 4/81 [00:04<00:50,  1.54it/s]  6%|▌         | 5/81 [00:04<00:35,  2.14it/s]  7%|▋         | 6/81 [00:04<00:26,  2.81it/s]  9%|▊         | 7/81 [00:04<00:21,  3.51it/s] 10%|▉         | 8/81 [00:04<00:17,  4.18it/s] 11%|█         | 9/81 [00:05<00:15,  4.79it/s] 12%|█▏        | 10/81 [00:05<00:13,  5.32it/s] 14%|█▎        | 11/81 [00:05<00:12,  5.76it/s] 15%|█▍        | 12/81 [00:05<00:11,  6.11it/s] 16%|█▌        | 13/81 [00:05<00:10,  6.35it/s] 17%|█▋        | 14/81 [00:05<00:10,  6.56it/s] 19%|█▊        | 15/81 [00:05<00:09,  6.71it/s] 20%|█▉        | 16/81 [00:06<00:09,  6.82it/s] 21%|██        | 17/81 [00:06<00:09,  6.90it/s] 22%|██▏       | 18/81 [00:06<00:09,  6.95it/s] 23%|██▎       | 19/81 [00:06<00:08,  6.98it/s] 25%|██▍       | 20/81 [00:06<00:08,  7.01it/s] 26%|██▌       | 21/81 [00:06<00:08,  7.04it/s] 27%|██▋       | 22/81 [00:06<00:08,  7.06it/s] 28%|██▊       | 23/81 [00:07<00:08,  7.08it/s] 30%|██▉       | 24/81 [00:07<00:08,  7.08it/s] 31%|███       | 25/81 [00:07<00:07,  7.08it/s] 32%|███▏      | 26/81 [00:07<00:07,  7.08it/s] 33%|███▎      | 27/81 [00:07<00:07,  7.07it/s] 35%|███▍      | 28/81 [00:07<00:07,  7.03it/s] 36%|███▌      | 29/81 [00:07<00:07,  7.04it/s] 37%|███▋      | 30/81 [00:07<00:07,  7.04it/s] 38%|███▊      | 31/81 [00:08<00:07,  7.05it/s] 40%|███▉      | 32/81 [00:08<00:06,  7.07it/s] 41%|████      | 33/81 [00:08<00:06,  7.06it/s] 42%|████▏     | 34/81 [00:08<00:06,  7.08it/s] 43%|████▎     | 35/81 [00:08<00:06,  7.07it/s] 44%|████▍     | 36/81 [00:08<00:06,  7.07it/s] 46%|████▌     | 37/81 [00:08<00:06,  7.07it/s] 47%|████▋     | 38/81 [00:09<00:06,  7.07it/s] 48%|████▊     | 39/81 [00:09<00:05,  7.07it/s] 49%|████▉     | 40/81 [00:09<00:05,  6.86it/s] 51%|█████     | 41/81 [00:09<00:05,  6.92it/s] 52%|█████▏    | 42/81 [00:09<00:05,  6.96it/s] 53%|█████▎    | 43/81 [00:09<00:05,  6.98it/s] 54%|█████▍    | 44/81 [00:09<00:05,  7.02it/s] 56%|█████▌    | 45/81 [00:10<00:05,  7.04it/s] 57%|█████▋    | 46/81 [00:10<00:04,  7.03it/s] 58%|█████▊    | 47/81 [00:10<00:05,  6.55it/s] 59%|█████▉    | 48/81 [00:11<00:16,  1.96it/s] 60%|██████    | 49/81 [00:11<00:12,  2.50it/s] 62%|██████▏   | 50/81 [00:12<00:09,  3.11it/s] 63%|██████▎   | 51/81 [00:12<00:08,  3.74it/s] 64%|██████▍   | 52/81 [00:12<00:06,  4.36it/s] 65%|██████▌   | 53/81 [00:12<00:05,  4.92it/s] 67%|██████▋   | 54/81 [00:12<00:04,  5.41it/s] 68%|██████▊   | 55/81 [00:12<00:04,  5.81it/s] 69%|██████▉   | 56/81 [00:12<00:04,  6.13it/s] 70%|███████   | 57/81 [00:13<00:03,  6.38it/s] 72%|███████▏  | 58/81 [00:13<00:03,  6.57it/s] 73%|███████▎  | 59/81 [00:13<00:03,  6.71it/s] 74%|███████▍  | 60/81 [00:13<00:03,  6.81it/s] 75%|███████▌  | 61/81 [00:13<00:02,  6.86it/s] 77%|███████▋  | 62/81 [00:13<00:02,  6.92it/s] 78%|███████▊  | 63/81 [00:13<00:02,  6.98it/s] 79%|███████▉  | 64/81 [00:14<00:03,  5.48it/s] 80%|████████  | 65/81 [00:14<00:02,  5.88it/s] 81%|████████▏ | 66/81 [00:14<00:02,  6.17it/s] 83%|████████▎ | 67/81 [00:14<00:02,  6.42it/s] 84%|████████▍ | 68/81 [00:14<00:01,  6.61it/s] 85%|████████▌ | 69/81 [00:14<00:01,  6.75it/s] 86%|████████▋ | 70/81 [00:15<00:01,  6.84it/s] 88%|████████▊ | 71/81 [00:15<00:01,  6.92it/s] 89%|████████▉ | 72/81 [00:15<00:01,  6.55it/s] 90%|█████████ | 73/81 [00:15<00:01,  6.71it/s] 91%|█████████▏| 74/81 [00:15<00:01,  6.83it/s] 93%|█████████▎| 75/81 [00:15<00:00,  6.92it/s] 94%|█████████▍| 76/81 [00:15<00:00,  6.99it/s] 95%|█████████▌| 77/81 [00:16<00:00,  7.04it/s] 96%|█████████▋| 78/81 [00:16<00:00,  7.06it/s] 98%|█████████▊| 79/81 [00:16<00:00,  7.08it/s] 99%|█████████▉| 80/81 [00:16<00:00,  7.09it/s]100%|██████████| 81/81 [00:16<00:00,  4.87it/s]
=> result
* total: 8,041
* correct: 3,854
* accuracy: 47.9%
* error: 52.1%
* macro_f1: 43.6%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers oxford_flowers 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_flowers/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_flowers/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_1.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:29,  3.74s/it]  8%|▊         | 2/25 [00:03<00:37,  1.61s/it] 12%|█▏        | 3/25 [00:03<00:20,  1.07it/s] 16%|█▌        | 4/25 [00:04<00:12,  1.63it/s] 20%|██        | 5/25 [00:04<00:08,  2.29it/s] 24%|██▍       | 6/25 [00:04<00:06,  3.04it/s] 28%|██▊       | 7/25 [00:04<00:04,  3.82it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.60it/s] 36%|███▌      | 9/25 [00:04<00:03,  5.32it/s] 40%|████      | 10/25 [00:04<00:02,  5.97it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.50it/s] 48%|████▊     | 12/25 [00:05<00:01,  6.94it/s] 52%|█████▏    | 13/25 [00:05<00:01,  7.27it/s] 56%|█████▌    | 14/25 [00:05<00:01,  7.53it/s] 60%|██████    | 15/25 [00:05<00:01,  7.72it/s] 64%|██████▍   | 16/25 [00:05<00:01,  7.87it/s] 68%|██████▊   | 17/25 [00:05<00:01,  7.97it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.04it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.10it/s] 80%|████████  | 20/25 [00:06<00:00,  8.08it/s] 84%|████████▍ | 21/25 [00:06<00:00,  8.13it/s] 88%|████████▊ | 22/25 [00:06<00:00,  8.17it/s] 92%|█████████▏| 23/25 [00:06<00:00,  8.19it/s] 96%|█████████▌| 24/25 [00:06<00:00,  8.20it/s]100%|██████████| 25/25 [00:06<00:00,  3.73it/s]
=> result
* total: 2,463
* correct: 2,370
* accuracy: 96.2%
* error: 3.8%
* macro_f1: 96.0%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers oxford_flowers 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_flowers/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_flowers/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_2.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:25,  3.57s/it]  8%|▊         | 2/25 [00:03<00:35,  1.54s/it] 12%|█▏        | 3/25 [00:03<00:19,  1.12it/s] 16%|█▌        | 4/25 [00:03<00:12,  1.70it/s] 20%|██        | 5/25 [00:04<00:08,  2.38it/s] 24%|██▍       | 6/25 [00:04<00:06,  3.13it/s] 28%|██▊       | 7/25 [00:04<00:04,  3.93it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.70it/s] 36%|███▌      | 9/25 [00:04<00:02,  5.41it/s] 40%|████      | 10/25 [00:04<00:02,  6.03it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.55it/s] 48%|████▊     | 12/25 [00:04<00:01,  6.96it/s] 52%|█████▏    | 13/25 [00:05<00:01,  7.30it/s] 56%|█████▌    | 14/25 [00:05<00:01,  7.50it/s] 60%|██████    | 15/25 [00:05<00:01,  7.72it/s] 64%|██████▍   | 16/25 [00:05<00:01,  7.87it/s] 68%|██████▊   | 17/25 [00:05<00:01,  7.98it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.06it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.11it/s] 80%|████████  | 20/25 [00:05<00:00,  8.14it/s] 84%|████████▍ | 21/25 [00:06<00:00,  8.16it/s] 88%|████████▊ | 22/25 [00:06<00:00,  8.19it/s] 92%|█████████▏| 23/25 [00:06<00:00,  8.21it/s] 96%|█████████▌| 24/25 [00:06<00:00,  8.23it/s]100%|██████████| 25/25 [00:06<00:00,  3.82it/s]
=> result
* total: 2,463
* correct: 2,374
* accuracy: 96.4%
* error: 3.6%
* macro_f1: 96.4%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers oxford_flowers 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_flowers/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/oxford_flowers/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_3.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:22,  3.45s/it]  8%|▊         | 2/25 [00:03<00:34,  1.49s/it] 12%|█▏        | 3/25 [00:03<00:19,  1.15it/s] 16%|█▌        | 4/25 [00:03<00:12,  1.75it/s] 20%|██        | 5/25 [00:03<00:08,  2.44it/s] 24%|██▍       | 6/25 [00:04<00:05,  3.20it/s] 28%|██▊       | 7/25 [00:04<00:04,  4.00it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.77it/s] 36%|███▌      | 9/25 [00:04<00:02,  5.48it/s] 40%|████      | 10/25 [00:04<00:02,  6.09it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.61it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.01it/s] 52%|█████▏    | 13/25 [00:04<00:01,  7.32it/s] 56%|█████▌    | 14/25 [00:05<00:01,  7.57it/s] 60%|██████    | 15/25 [00:05<00:01,  7.73it/s] 64%|██████▍   | 16/25 [00:05<00:01,  7.86it/s] 68%|██████▊   | 17/25 [00:05<00:01,  7.96it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.02it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.07it/s] 80%|████████  | 20/25 [00:05<00:00,  8.11it/s] 84%|████████▍ | 21/25 [00:05<00:00,  8.13it/s] 88%|████████▊ | 22/25 [00:06<00:00,  8.15it/s] 92%|█████████▏| 23/25 [00:06<00:00,  8.17it/s] 96%|█████████▌| 24/25 [00:06<00:00,  8.19it/s]100%|██████████| 25/25 [00:06<00:00,  3.89it/s]
=> result
* total: 2,463
* correct: 2,367
* accuracy: 96.1%
* error: 3.9%
* macro_f1: 95.8%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers food101 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/food101/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/food101/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_1.pkl
1616 20200 30300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  101
# train_x  1,616
# val      20,200
# test     30,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/303 [00:00<?, ?it/s]  0%|          | 1/303 [00:03<17:04,  3.39s/it]  1%|          | 2/303 [00:03<07:22,  1.47s/it]  1%|          | 3/303 [00:03<04:16,  1.17it/s]  1%|▏         | 4/303 [00:03<02:48,  1.77it/s]  2%|▏         | 5/303 [00:03<02:00,  2.47it/s]  2%|▏         | 6/303 [00:04<01:31,  3.24it/s]  2%|▏         | 7/303 [00:04<01:13,  4.04it/s]  3%|▎         | 8/303 [00:04<01:01,  4.81it/s]  3%|▎         | 9/303 [00:04<00:53,  5.53it/s]  3%|▎         | 10/303 [00:04<00:47,  6.14it/s]  4%|▎         | 11/303 [00:04<00:43,  6.66it/s]  4%|▍         | 12/303 [00:04<00:41,  7.06it/s]  4%|▍         | 13/303 [00:04<00:39,  7.36it/s]  5%|▍         | 14/303 [00:04<00:38,  7.58it/s]  5%|▍         | 15/303 [00:05<00:37,  7.75it/s]  5%|▌         | 16/303 [00:05<00:36,  7.89it/s]  6%|▌         | 17/303 [00:05<00:35,  7.96it/s]  6%|▌         | 18/303 [00:05<00:35,  8.02it/s]  6%|▋         | 19/303 [00:05<00:35,  8.06it/s]  7%|▋         | 20/303 [00:05<00:34,  8.11it/s]  7%|▋         | 21/303 [00:05<00:34,  8.13it/s]  7%|▋         | 22/303 [00:05<00:34,  8.14it/s]  8%|▊         | 23/303 [00:06<00:34,  8.18it/s]  8%|▊         | 24/303 [00:06<00:34,  8.19it/s]  8%|▊         | 25/303 [00:06<00:33,  8.22it/s]  9%|▊         | 26/303 [00:06<00:33,  8.22it/s]  9%|▉         | 27/303 [00:06<00:33,  8.22it/s]  9%|▉         | 28/303 [00:06<00:33,  8.23it/s] 10%|▉         | 29/303 [00:06<00:33,  8.20it/s] 10%|▉         | 30/303 [00:06<00:33,  8.20it/s] 10%|█         | 31/303 [00:07<00:33,  8.21it/s] 11%|█         | 32/303 [00:07<00:33,  8.20it/s] 11%|█         | 33/303 [00:07<00:32,  8.20it/s] 11%|█         | 34/303 [00:07<00:32,  8.19it/s] 12%|█▏        | 35/303 [00:07<00:32,  8.20it/s] 12%|█▏        | 36/303 [00:07<00:32,  8.20it/s] 12%|█▏        | 37/303 [00:07<00:32,  8.20it/s] 13%|█▎        | 38/303 [00:07<00:32,  8.20it/s] 13%|█▎        | 39/303 [00:08<00:32,  8.21it/s] 13%|█▎        | 40/303 [00:08<00:32,  8.21it/s] 14%|█▎        | 41/303 [00:08<00:31,  8.22it/s] 14%|█▍        | 42/303 [00:08<00:31,  8.21it/s] 14%|█▍        | 43/303 [00:08<00:31,  8.20it/s] 15%|█▍        | 44/303 [00:08<00:31,  8.19it/s] 15%|█▍        | 45/303 [00:08<00:31,  8.20it/s] 15%|█▌        | 46/303 [00:08<00:31,  8.22it/s] 16%|█▌        | 47/303 [00:09<00:31,  8.22it/s] 16%|█▌        | 48/303 [00:09<00:31,  8.22it/s] 16%|█▌        | 49/303 [00:09<00:30,  8.21it/s] 17%|█▋        | 50/303 [00:09<00:30,  8.20it/s] 17%|█▋        | 51/303 [00:09<00:30,  8.21it/s] 17%|█▋        | 52/303 [00:09<00:30,  8.22it/s] 17%|█▋        | 53/303 [00:09<00:30,  8.22it/s] 18%|█▊        | 54/303 [00:09<00:30,  8.22it/s] 18%|█▊        | 55/303 [00:09<00:30,  8.21it/s] 18%|█▊        | 56/303 [00:10<00:30,  8.22it/s] 19%|█▉        | 57/303 [00:10<00:29,  8.22it/s] 19%|█▉        | 58/303 [00:10<00:29,  8.22it/s] 19%|█▉        | 59/303 [00:10<00:29,  8.22it/s] 20%|█▉        | 60/303 [00:10<00:29,  8.23it/s] 20%|██        | 61/303 [00:10<00:29,  8.20it/s] 20%|██        | 62/303 [00:10<00:29,  8.19it/s] 21%|██        | 63/303 [00:10<00:29,  8.20it/s] 21%|██        | 64/303 [00:11<00:29,  8.20it/s] 21%|██▏       | 65/303 [00:11<00:28,  8.21it/s] 22%|██▏       | 66/303 [00:11<00:28,  8.19it/s] 22%|██▏       | 67/303 [00:11<00:28,  8.20it/s] 22%|██▏       | 68/303 [00:11<00:28,  8.20it/s] 23%|██▎       | 69/303 [00:11<00:28,  8.21it/s] 23%|██▎       | 70/303 [00:11<00:28,  8.22it/s] 23%|██▎       | 71/303 [00:11<00:28,  8.22it/s] 24%|██▍       | 72/303 [00:12<00:28,  8.21it/s] 24%|██▍       | 73/303 [00:12<00:28,  8.20it/s] 24%|██▍       | 74/303 [00:12<00:27,  8.20it/s] 25%|██▍       | 75/303 [00:12<00:27,  8.20it/s] 25%|██▌       | 76/303 [00:12<00:27,  8.21it/s] 25%|██▌       | 77/303 [00:12<00:27,  8.20it/s] 26%|██▌       | 78/303 [00:12<00:27,  8.21it/s] 26%|██▌       | 79/303 [00:12<00:27,  8.21it/s] 26%|██▋       | 80/303 [00:13<00:27,  8.20it/s] 27%|██▋       | 81/303 [00:13<00:27,  8.20it/s] 27%|██▋       | 82/303 [00:13<00:26,  8.19it/s] 27%|██▋       | 83/303 [00:13<00:26,  8.20it/s] 28%|██▊       | 84/303 [00:13<00:26,  8.14it/s] 28%|██▊       | 85/303 [00:13<00:26,  8.14it/s] 28%|██▊       | 86/303 [00:13<00:26,  8.15it/s] 29%|██▊       | 87/303 [00:13<00:26,  8.16it/s] 29%|██▉       | 88/303 [00:14<00:26,  8.17it/s] 29%|██▉       | 89/303 [00:14<00:26,  8.18it/s] 30%|██▉       | 90/303 [00:14<00:26,  8.18it/s] 30%|███       | 91/303 [00:14<00:25,  8.19it/s] 30%|███       | 92/303 [00:14<00:25,  8.18it/s] 31%|███       | 93/303 [00:14<00:25,  8.18it/s] 31%|███       | 94/303 [00:14<00:25,  8.17it/s] 31%|███▏      | 95/303 [00:14<00:25,  8.17it/s] 32%|███▏      | 96/303 [00:14<00:25,  8.19it/s] 32%|███▏      | 97/303 [00:15<00:25,  8.16it/s] 32%|███▏      | 98/303 [00:15<00:25,  8.15it/s] 33%|███▎      | 99/303 [00:15<00:25,  8.16it/s] 33%|███▎      | 100/303 [00:15<00:24,  8.15it/s] 33%|███▎      | 101/303 [00:15<00:24,  8.16it/s] 34%|███▎      | 102/303 [00:15<00:24,  8.16it/s] 34%|███▍      | 103/303 [00:15<00:24,  8.15it/s] 34%|███▍      | 104/303 [00:15<00:24,  8.12it/s] 35%|███▍      | 105/303 [00:16<00:24,  8.13it/s] 35%|███▍      | 106/303 [00:16<00:24,  8.14it/s] 35%|███▌      | 107/303 [00:16<00:24,  8.16it/s] 36%|███▌      | 108/303 [00:16<00:23,  8.16it/s] 36%|███▌      | 109/303 [00:16<00:23,  8.16it/s] 36%|███▋      | 110/303 [00:16<00:23,  8.17it/s] 37%|███▋      | 111/303 [00:16<00:23,  8.16it/s] 37%|███▋      | 112/303 [00:16<00:23,  8.14it/s] 37%|███▋      | 113/303 [00:17<00:23,  8.13it/s] 38%|███▊      | 114/303 [00:17<00:23,  8.15it/s] 38%|███▊      | 115/303 [00:17<00:23,  8.16it/s] 38%|███▊      | 116/303 [00:17<00:22,  8.16it/s] 39%|███▊      | 117/303 [00:17<00:22,  8.17it/s] 39%|███▉      | 118/303 [00:17<00:22,  8.17it/s] 39%|███▉      | 119/303 [00:17<00:22,  8.18it/s] 40%|███▉      | 120/303 [00:17<00:22,  8.18it/s] 40%|███▉      | 121/303 [00:18<00:22,  8.19it/s] 40%|████      | 122/303 [00:18<00:22,  8.18it/s] 41%|████      | 123/303 [00:18<00:22,  8.18it/s] 41%|████      | 124/303 [00:18<00:21,  8.17it/s] 41%|████▏     | 125/303 [00:18<00:21,  8.17it/s] 42%|████▏     | 126/303 [00:18<00:21,  8.18it/s] 42%|████▏     | 127/303 [00:18<00:21,  8.18it/s] 42%|████▏     | 128/303 [00:18<00:21,  8.18it/s] 43%|████▎     | 129/303 [00:19<00:21,  8.16it/s] 43%|████▎     | 130/303 [00:19<00:21,  8.16it/s] 43%|████▎     | 131/303 [00:19<00:21,  8.14it/s] 44%|████▎     | 132/303 [00:19<00:20,  8.15it/s] 44%|████▍     | 133/303 [00:19<00:20,  8.16it/s] 44%|████▍     | 134/303 [00:19<00:20,  8.16it/s] 45%|████▍     | 135/303 [00:19<00:20,  8.15it/s] 45%|████▍     | 136/303 [00:19<00:20,  8.14it/s] 45%|████▌     | 137/303 [00:20<00:20,  8.15it/s] 46%|████▌     | 138/303 [00:20<00:20,  8.15it/s] 46%|████▌     | 139/303 [00:20<00:20,  8.14it/s] 46%|████▌     | 140/303 [00:20<00:20,  8.12it/s] 47%|████▋     | 141/303 [00:20<00:19,  8.11it/s] 47%|████▋     | 142/303 [00:20<00:19,  8.11it/s] 47%|████▋     | 143/303 [00:20<00:19,  8.11it/s] 48%|████▊     | 144/303 [00:20<00:19,  8.11it/s] 48%|████▊     | 145/303 [00:20<00:19,  8.11it/s] 48%|████▊     | 146/303 [00:21<00:19,  8.11it/s] 49%|████▊     | 147/303 [00:21<00:19,  8.11it/s] 49%|████▉     | 148/303 [00:21<00:19,  8.10it/s] 49%|████▉     | 149/303 [00:21<00:19,  8.10it/s] 50%|████▉     | 150/303 [00:21<00:18,  8.11it/s] 50%|████▉     | 151/303 [00:21<00:18,  8.10it/s] 50%|█████     | 152/303 [00:21<00:18,  8.13it/s] 50%|█████     | 153/303 [00:21<00:18,  8.12it/s] 51%|█████     | 154/303 [00:22<00:18,  8.10it/s] 51%|█████     | 155/303 [00:22<00:18,  8.11it/s] 51%|█████▏    | 156/303 [00:22<00:18,  8.13it/s] 52%|█████▏    | 157/303 [00:22<00:17,  8.14it/s] 52%|█████▏    | 158/303 [00:22<00:17,  8.14it/s] 52%|█████▏    | 159/303 [00:22<00:17,  8.14it/s] 53%|█████▎    | 160/303 [00:22<00:17,  8.04it/s] 53%|█████▎    | 161/303 [00:22<00:17,  8.08it/s] 53%|█████▎    | 162/303 [00:23<00:17,  8.11it/s] 54%|█████▍    | 163/303 [00:23<00:17,  8.12it/s] 54%|█████▍    | 164/303 [00:23<00:17,  8.13it/s] 54%|█████▍    | 165/303 [00:23<00:16,  8.14it/s] 55%|█████▍    | 166/303 [00:23<00:16,  8.15it/s] 55%|█████▌    | 167/303 [00:23<00:16,  8.14it/s] 55%|█████▌    | 168/303 [00:23<00:16,  8.15it/s] 56%|█████▌    | 169/303 [00:23<00:16,  8.15it/s] 56%|█████▌    | 170/303 [00:24<00:16,  8.15it/s] 56%|█████▋    | 171/303 [00:24<00:16,  8.15it/s] 57%|█████▋    | 172/303 [00:24<00:16,  8.16it/s] 57%|█████▋    | 173/303 [00:24<00:15,  8.17it/s] 57%|█████▋    | 174/303 [00:24<00:15,  8.17it/s] 58%|█████▊    | 175/303 [00:24<00:15,  8.17it/s] 58%|█████▊    | 176/303 [00:24<00:15,  8.17it/s] 58%|█████▊    | 177/303 [00:24<00:15,  8.14it/s] 59%|█████▊    | 178/303 [00:25<00:15,  8.12it/s] 59%|█████▉    | 179/303 [00:25<00:15,  8.13it/s] 59%|█████▉    | 180/303 [00:25<00:15,  8.13it/s] 60%|█████▉    | 181/303 [00:25<00:15,  8.11it/s] 60%|██████    | 182/303 [00:25<00:14,  8.10it/s] 60%|██████    | 183/303 [00:25<00:14,  8.13it/s] 61%|██████    | 184/303 [00:25<00:14,  8.14it/s] 61%|██████    | 185/303 [00:25<00:14,  8.15it/s] 61%|██████▏   | 186/303 [00:26<00:14,  8.15it/s] 62%|██████▏   | 187/303 [00:26<00:14,  8.15it/s] 62%|██████▏   | 188/303 [00:26<00:14,  8.14it/s] 62%|██████▏   | 189/303 [00:26<00:13,  8.14it/s] 63%|██████▎   | 190/303 [00:26<00:13,  8.15it/s] 63%|██████▎   | 191/303 [00:26<00:13,  8.15it/s] 63%|██████▎   | 192/303 [00:26<00:13,  8.15it/s] 64%|██████▎   | 193/303 [00:26<00:13,  8.16it/s] 64%|██████▍   | 194/303 [00:27<00:13,  8.17it/s] 64%|██████▍   | 195/303 [00:27<00:13,  8.16it/s] 65%|██████▍   | 196/303 [00:27<00:13,  8.16it/s] 65%|██████▌   | 197/303 [00:27<00:12,  8.17it/s] 65%|██████▌   | 198/303 [00:27<00:12,  8.16it/s] 66%|██████▌   | 199/303 [00:27<00:12,  8.15it/s] 66%|██████▌   | 200/303 [00:27<00:12,  8.15it/s] 66%|██████▋   | 201/303 [00:27<00:12,  8.16it/s] 67%|██████▋   | 202/303 [00:27<00:12,  8.17it/s] 67%|██████▋   | 203/303 [00:28<00:12,  8.17it/s] 67%|██████▋   | 204/303 [00:28<00:12,  8.15it/s] 68%|██████▊   | 205/303 [00:28<00:12,  8.14it/s] 68%|██████▊   | 206/303 [00:28<00:11,  8.14it/s] 68%|██████▊   | 207/303 [00:28<00:11,  8.12it/s] 69%|██████▊   | 208/303 [00:28<00:11,  8.13it/s] 69%|██████▉   | 209/303 [00:28<00:11,  8.15it/s] 69%|██████▉   | 210/303 [00:28<00:11,  8.15it/s] 70%|██████▉   | 211/303 [00:29<00:11,  8.16it/s] 70%|██████▉   | 212/303 [00:29<00:11,  8.12it/s] 70%|███████   | 213/303 [00:29<00:11,  8.13it/s] 71%|███████   | 214/303 [00:29<00:10,  8.13it/s] 71%|███████   | 215/303 [00:29<00:10,  8.15it/s] 71%|███████▏  | 216/303 [00:29<00:10,  8.15it/s] 72%|███████▏  | 217/303 [00:29<00:10,  8.14it/s] 72%|███████▏  | 218/303 [00:29<00:10,  8.12it/s] 72%|███████▏  | 219/303 [00:30<00:10,  8.13it/s] 73%|███████▎  | 220/303 [00:30<00:10,  8.13it/s] 73%|███████▎  | 221/303 [00:30<00:10,  8.11it/s] 73%|███████▎  | 222/303 [00:30<00:09,  8.14it/s] 74%|███████▎  | 223/303 [00:30<00:09,  8.15it/s] 74%|███████▍  | 224/303 [00:30<00:09,  8.14it/s] 74%|███████▍  | 225/303 [00:30<00:09,  8.14it/s] 75%|███████▍  | 226/303 [00:30<00:09,  8.14it/s] 75%|███████▍  | 227/303 [00:31<00:09,  8.12it/s] 75%|███████▌  | 228/303 [00:31<00:09,  8.14it/s] 76%|███████▌  | 229/303 [00:31<00:09,  8.15it/s] 76%|███████▌  | 230/303 [00:31<00:08,  8.15it/s] 76%|███████▌  | 231/303 [00:31<00:08,  8.13it/s] 77%|███████▋  | 232/303 [00:31<00:08,  8.13it/s] 77%|███████▋  | 233/303 [00:31<00:08,  8.12it/s] 77%|███████▋  | 234/303 [00:31<00:08,  8.12it/s] 78%|███████▊  | 235/303 [00:32<00:08,  8.14it/s] 78%|███████▊  | 236/303 [00:32<00:08,  8.15it/s] 78%|███████▊  | 237/303 [00:32<00:08,  8.15it/s] 79%|███████▊  | 238/303 [00:32<00:07,  8.15it/s] 79%|███████▉  | 239/303 [00:32<00:07,  8.16it/s] 79%|███████▉  | 240/303 [00:32<00:07,  8.16it/s] 80%|███████▉  | 241/303 [00:32<00:07,  8.16it/s] 80%|███████▉  | 242/303 [00:32<00:07,  8.16it/s] 80%|████████  | 243/303 [00:33<00:07,  8.16it/s] 81%|████████  | 244/303 [00:33<00:07,  8.15it/s] 81%|████████  | 245/303 [00:33<00:07,  8.15it/s] 81%|████████  | 246/303 [00:33<00:07,  8.09it/s] 82%|████████▏ | 247/303 [00:33<00:06,  8.11it/s] 82%|████████▏ | 248/303 [00:33<00:06,  8.11it/s] 82%|████████▏ | 249/303 [00:33<00:06,  8.11it/s] 83%|████████▎ | 250/303 [00:33<00:06,  8.12it/s] 83%|████████▎ | 251/303 [00:34<00:06,  8.12it/s] 83%|████████▎ | 252/303 [00:34<00:07,  6.59it/s] 83%|████████▎ | 253/303 [00:34<00:07,  6.99it/s] 84%|████████▍ | 254/303 [00:34<00:06,  7.30it/s] 84%|████████▍ | 255/303 [00:34<00:06,  7.52it/s] 84%|████████▍ | 256/303 [00:34<00:06,  7.70it/s] 85%|████████▍ | 257/303 [00:34<00:05,  7.83it/s] 85%|████████▌ | 258/303 [00:34<00:05,  7.89it/s] 85%|████████▌ | 259/303 [00:35<00:05,  7.96it/s] 86%|████████▌ | 260/303 [00:35<00:05,  8.02it/s] 86%|████████▌ | 261/303 [00:35<00:05,  8.05it/s] 86%|████████▋ | 262/303 [00:35<00:05,  8.06it/s] 87%|████████▋ | 263/303 [00:35<00:04,  8.09it/s] 87%|████████▋ | 264/303 [00:35<00:04,  8.11it/s] 87%|████████▋ | 265/303 [00:35<00:04,  8.10it/s] 88%|████████▊ | 266/303 [00:35<00:04,  8.10it/s] 88%|████████▊ | 267/303 [00:36<00:04,  8.09it/s] 88%|████████▊ | 268/303 [00:36<00:04,  8.09it/s] 89%|████████▉ | 269/303 [00:36<00:04,  8.10it/s] 89%|████████▉ | 270/303 [00:36<00:04,  8.07it/s] 89%|████████▉ | 271/303 [00:36<00:03,  8.06it/s] 90%|████████▉ | 272/303 [00:36<00:03,  8.08it/s] 90%|█████████ | 273/303 [00:36<00:03,  8.09it/s] 90%|█████████ | 274/303 [00:36<00:03,  8.11it/s] 91%|█████████ | 275/303 [00:37<00:03,  8.11it/s] 91%|█████████ | 276/303 [00:37<00:03,  8.10it/s] 91%|█████████▏| 277/303 [00:37<00:03,  8.10it/s] 92%|█████████▏| 278/303 [00:37<00:03,  8.11it/s] 92%|█████████▏| 279/303 [00:37<00:02,  8.10it/s] 92%|█████████▏| 280/303 [00:37<00:02,  8.11it/s] 93%|█████████▎| 281/303 [00:37<00:02,  8.11it/s] 93%|█████████▎| 282/303 [00:37<00:02,  8.10it/s] 93%|█████████▎| 283/303 [00:38<00:02,  8.09it/s] 94%|█████████▎| 284/303 [00:38<00:02,  8.08it/s] 94%|█████████▍| 285/303 [00:38<00:02,  8.09it/s] 94%|█████████▍| 286/303 [00:38<00:02,  8.08it/s] 95%|█████████▍| 287/303 [00:38<00:01,  8.09it/s] 95%|█████████▌| 288/303 [00:38<00:01,  8.09it/s] 95%|█████████▌| 289/303 [00:38<00:01,  8.11it/s] 96%|█████████▌| 290/303 [00:38<00:01,  8.12it/s] 96%|█████████▌| 291/303 [00:39<00:01,  8.13it/s] 96%|█████████▋| 292/303 [00:39<00:01,  8.15it/s] 97%|█████████▋| 293/303 [00:39<00:01,  8.15it/s] 97%|█████████▋| 294/303 [00:39<00:01,  8.16it/s] 97%|█████████▋| 295/303 [00:39<00:00,  8.17it/s] 98%|█████████▊| 296/303 [00:39<00:00,  8.18it/s] 98%|█████████▊| 297/303 [00:39<00:00,  8.19it/s] 98%|█████████▊| 298/303 [00:39<00:00,  8.19it/s] 99%|█████████▊| 299/303 [00:40<00:00,  8.19it/s] 99%|█████████▉| 300/303 [00:40<00:00,  8.19it/s] 99%|█████████▉| 301/303 [00:40<00:00,  8.19it/s]100%|█████████▉| 302/303 [00:40<00:00,  8.19it/s]100%|██████████| 303/303 [00:40<00:00,  8.20it/s]100%|██████████| 303/303 [00:40<00:00,  7.47it/s]
=> result
* total: 30,300
* correct: 19,675
* accuracy: 64.9%
* error: 35.1%
* macro_f1: 61.5%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers food101 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/food101/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/food101/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_2.pkl
1616 20200 30300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  101
# train_x  1,616
# val      20,200
# test     30,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/303 [00:00<?, ?it/s]  0%|          | 1/303 [00:03<16:50,  3.35s/it]  1%|          | 2/303 [00:03<07:16,  1.45s/it]  1%|          | 3/303 [00:03<04:12,  1.19it/s]  1%|▏         | 4/303 [00:03<02:46,  1.79it/s]  2%|▏         | 5/303 [00:03<01:59,  2.50it/s]  2%|▏         | 6/303 [00:03<01:30,  3.27it/s]  2%|▏         | 7/303 [00:04<01:12,  4.08it/s]  3%|▎         | 8/303 [00:04<01:00,  4.85it/s]  3%|▎         | 9/303 [00:04<00:52,  5.56it/s]  3%|▎         | 10/303 [00:04<00:47,  6.18it/s]  4%|▎         | 11/303 [00:04<00:43,  6.65it/s]  4%|▍         | 12/303 [00:04<00:41,  7.06it/s]  4%|▍         | 13/303 [00:04<00:39,  7.37it/s]  5%|▍         | 14/303 [00:04<00:38,  7.59it/s]  5%|▍         | 15/303 [00:05<00:37,  7.75it/s]  5%|▌         | 16/303 [00:05<00:36,  7.88it/s]  6%|▌         | 17/303 [00:05<00:35,  7.97it/s]  6%|▌         | 18/303 [00:05<00:35,  8.04it/s]  6%|▋         | 19/303 [00:05<00:35,  8.09it/s]  7%|▋         | 20/303 [00:05<00:34,  8.11it/s]  7%|▋         | 21/303 [00:05<00:34,  8.14it/s]  7%|▋         | 22/303 [00:05<00:34,  8.16it/s]  8%|▊         | 23/303 [00:06<00:34,  8.17it/s]  8%|▊         | 24/303 [00:06<00:34,  8.19it/s]  8%|▊         | 25/303 [00:06<00:34,  8.14it/s]  9%|▊         | 26/303 [00:06<00:33,  8.17it/s]  9%|▉         | 27/303 [00:06<00:33,  8.17it/s]  9%|▉         | 28/303 [00:06<00:33,  8.18it/s] 10%|▉         | 29/303 [00:06<00:33,  8.18it/s] 10%|▉         | 30/303 [00:06<00:33,  8.17it/s] 10%|█         | 31/303 [00:07<00:33,  8.18it/s] 11%|█         | 32/303 [00:07<00:33,  8.18it/s] 11%|█         | 33/303 [00:07<00:32,  8.19it/s] 11%|█         | 34/303 [00:07<00:32,  8.17it/s] 12%|█▏        | 35/303 [00:07<00:32,  8.17it/s] 12%|█▏        | 36/303 [00:07<00:32,  8.16it/s] 12%|█▏        | 37/303 [00:07<00:32,  8.15it/s] 13%|█▎        | 38/303 [00:07<00:32,  8.17it/s] 13%|█▎        | 39/303 [00:07<00:32,  8.14it/s] 13%|█▎        | 40/303 [00:08<00:32,  8.16it/s] 14%|█▎        | 41/303 [00:08<00:32,  8.17it/s] 14%|█▍        | 42/303 [00:08<00:31,  8.18it/s] 14%|█▍        | 43/303 [00:08<00:31,  8.18it/s] 15%|█▍        | 44/303 [00:08<00:31,  8.18it/s] 15%|█▍        | 45/303 [00:08<00:31,  8.17it/s] 15%|█▌        | 46/303 [00:08<00:31,  8.18it/s] 16%|█▌        | 47/303 [00:08<00:31,  8.19it/s] 16%|█▌        | 48/303 [00:09<00:31,  8.20it/s] 16%|█▌        | 49/303 [00:09<00:30,  8.20it/s] 17%|█▋        | 50/303 [00:09<00:30,  8.19it/s] 17%|█▋        | 51/303 [00:09<00:30,  8.18it/s] 17%|█▋        | 52/303 [00:09<00:30,  8.19it/s] 17%|█▋        | 53/303 [00:09<00:30,  8.19it/s] 18%|█▊        | 54/303 [00:09<00:30,  8.18it/s] 18%|█▊        | 55/303 [00:09<00:30,  8.19it/s] 18%|█▊        | 56/303 [00:10<00:30,  8.19it/s] 19%|█▉        | 57/303 [00:10<00:30,  8.19it/s] 19%|█▉        | 58/303 [00:10<00:29,  8.19it/s] 19%|█▉        | 59/303 [00:10<00:29,  8.18it/s] 20%|█▉        | 60/303 [00:10<00:29,  8.18it/s] 20%|██        | 61/303 [00:10<00:29,  8.19it/s] 20%|██        | 62/303 [00:10<00:29,  8.19it/s] 21%|██        | 63/303 [00:10<00:29,  8.19it/s] 21%|██        | 64/303 [00:11<00:29,  8.18it/s] 21%|██▏       | 65/303 [00:11<00:29,  8.19it/s] 22%|██▏       | 66/303 [00:11<00:28,  8.19it/s] 22%|██▏       | 67/303 [00:11<00:28,  8.19it/s] 22%|██▏       | 68/303 [00:11<00:28,  8.18it/s] 23%|██▎       | 69/303 [00:11<00:28,  8.18it/s] 23%|██▎       | 70/303 [00:11<00:28,  8.17it/s] 23%|██▎       | 71/303 [00:11<00:28,  8.17it/s] 24%|██▍       | 72/303 [00:12<00:28,  8.17it/s] 24%|██▍       | 73/303 [00:12<00:28,  8.16it/s] 24%|██▍       | 74/303 [00:12<00:28,  8.16it/s] 25%|██▍       | 75/303 [00:12<00:27,  8.17it/s] 25%|██▌       | 76/303 [00:12<00:27,  8.17it/s] 25%|██▌       | 77/303 [00:12<00:27,  8.17it/s] 26%|██▌       | 78/303 [00:12<00:27,  8.17it/s] 26%|██▌       | 79/303 [00:12<00:27,  8.17it/s] 26%|██▋       | 80/303 [00:12<00:27,  8.17it/s] 27%|██▋       | 81/303 [00:13<00:27,  8.16it/s] 27%|██▋       | 82/303 [00:13<00:27,  8.16it/s] 27%|██▋       | 83/303 [00:13<00:26,  8.16it/s] 28%|██▊       | 84/303 [00:13<00:26,  8.16it/s] 28%|██▊       | 85/303 [00:13<00:26,  8.17it/s] 28%|██▊       | 86/303 [00:13<00:26,  8.17it/s] 29%|██▊       | 87/303 [00:13<00:26,  8.17it/s] 29%|██▉       | 88/303 [00:13<00:26,  8.16it/s] 29%|██▉       | 89/303 [00:14<00:26,  8.12it/s] 30%|██▉       | 90/303 [00:14<00:26,  8.14it/s] 30%|███       | 91/303 [00:14<00:25,  8.16it/s] 30%|███       | 92/303 [00:14<00:25,  8.16it/s] 31%|███       | 93/303 [00:14<00:25,  8.15it/s] 31%|███       | 94/303 [00:14<00:25,  8.14it/s] 31%|███▏      | 95/303 [00:14<00:25,  8.15it/s] 32%|███▏      | 96/303 [00:14<00:25,  8.14it/s] 32%|███▏      | 97/303 [00:15<00:25,  8.16it/s] 32%|███▏      | 98/303 [00:15<00:25,  8.17it/s] 33%|███▎      | 99/303 [00:15<00:24,  8.18it/s] 33%|███▎      | 100/303 [00:15<00:24,  8.18it/s] 33%|███▎      | 101/303 [00:15<00:24,  8.17it/s] 34%|███▎      | 102/303 [00:15<00:24,  8.17it/s] 34%|███▍      | 103/303 [00:15<00:24,  8.17it/s] 34%|███▍      | 104/303 [00:15<00:24,  8.17it/s] 35%|███▍      | 105/303 [00:16<00:24,  8.16it/s] 35%|███▍      | 106/303 [00:16<00:24,  8.17it/s] 35%|███▌      | 107/303 [00:16<00:24,  8.15it/s] 36%|███▌      | 108/303 [00:16<00:23,  8.15it/s] 36%|███▌      | 109/303 [00:16<00:23,  8.16it/s] 36%|███▋      | 110/303 [00:16<00:23,  8.15it/s] 37%|███▋      | 111/303 [00:16<00:23,  8.15it/s] 37%|███▋      | 112/303 [00:16<00:23,  8.15it/s] 37%|███▋      | 113/303 [00:17<00:23,  8.15it/s] 38%|███▊      | 114/303 [00:17<00:23,  8.16it/s] 38%|███▊      | 115/303 [00:17<00:23,  8.16it/s] 38%|███▊      | 116/303 [00:17<00:22,  8.16it/s] 39%|███▊      | 117/303 [00:17<00:22,  8.17it/s] 39%|███▉      | 118/303 [00:17<00:22,  8.16it/s] 39%|███▉      | 119/303 [00:17<00:22,  8.16it/s] 40%|███▉      | 120/303 [00:17<00:22,  8.15it/s] 40%|███▉      | 121/303 [00:18<00:22,  8.14it/s] 40%|████      | 122/303 [00:18<00:22,  8.14it/s] 41%|████      | 123/303 [00:18<00:22,  8.13it/s] 41%|████      | 124/303 [00:18<00:21,  8.15it/s] 41%|████▏     | 125/303 [00:18<00:21,  8.16it/s] 42%|████▏     | 126/303 [00:18<00:21,  8.16it/s] 42%|████▏     | 127/303 [00:18<00:21,  8.16it/s] 42%|████▏     | 128/303 [00:18<00:21,  8.16it/s] 43%|████▎     | 129/303 [00:19<00:21,  8.16it/s] 43%|████▎     | 130/303 [00:19<00:21,  8.15it/s] 43%|████▎     | 131/303 [00:19<00:21,  8.14it/s] 44%|████▎     | 132/303 [00:19<00:20,  8.15it/s] 44%|████▍     | 133/303 [00:19<00:20,  8.14it/s] 44%|████▍     | 134/303 [00:19<00:20,  8.13it/s] 45%|████▍     | 135/303 [00:19<00:20,  8.14it/s] 45%|████▍     | 136/303 [00:19<00:20,  8.15it/s] 45%|████▌     | 137/303 [00:19<00:20,  8.15it/s] 46%|████▌     | 138/303 [00:20<00:20,  8.16it/s] 46%|████▌     | 139/303 [00:20<00:20,  8.16it/s] 46%|████▌     | 140/303 [00:20<00:20,  8.14it/s] 47%|████▋     | 141/303 [00:20<00:19,  8.13it/s] 47%|████▋     | 142/303 [00:20<00:19,  8.12it/s] 47%|████▋     | 143/303 [00:20<00:19,  8.13it/s] 48%|████▊     | 144/303 [00:20<00:19,  8.12it/s] 48%|████▊     | 145/303 [00:20<00:19,  8.12it/s] 48%|████▊     | 146/303 [00:21<00:19,  8.13it/s] 49%|████▊     | 147/303 [00:21<00:19,  8.13it/s] 49%|████▉     | 148/303 [00:21<00:19,  8.15it/s] 49%|████▉     | 149/303 [00:21<00:18,  8.14it/s] 50%|████▉     | 150/303 [00:21<00:18,  8.14it/s] 50%|████▉     | 151/303 [00:21<00:18,  8.14it/s] 50%|█████     | 152/303 [00:21<00:18,  8.15it/s] 50%|█████     | 153/303 [00:21<00:18,  8.14it/s] 51%|█████     | 154/303 [00:22<00:18,  8.13it/s] 51%|█████     | 155/303 [00:22<00:18,  8.13it/s] 51%|█████▏    | 156/303 [00:22<00:18,  8.14it/s] 52%|█████▏    | 157/303 [00:22<00:17,  8.12it/s] 52%|█████▏    | 158/303 [00:22<00:17,  8.11it/s] 52%|█████▏    | 159/303 [00:22<00:17,  8.12it/s] 53%|█████▎    | 160/303 [00:22<00:17,  8.13it/s] 53%|█████▎    | 161/303 [00:22<00:17,  8.13it/s] 53%|█████▎    | 162/303 [00:23<00:17,  8.13it/s] 54%|█████▍    | 163/303 [00:23<00:17,  8.14it/s] 54%|█████▍    | 164/303 [00:23<00:17,  8.14it/s] 54%|█████▍    | 165/303 [00:23<00:16,  8.13it/s] 55%|█████▍    | 166/303 [00:23<00:16,  8.13it/s] 55%|█████▌    | 167/303 [00:23<00:16,  8.12it/s] 55%|█████▌    | 168/303 [00:23<00:16,  8.11it/s] 56%|█████▌    | 169/303 [00:23<00:16,  8.10it/s] 56%|█████▌    | 170/303 [00:24<00:16,  8.10it/s] 56%|█████▋    | 171/303 [00:24<00:16,  8.10it/s] 57%|█████▋    | 172/303 [00:24<00:16,  8.12it/s] 57%|█████▋    | 173/303 [00:24<00:15,  8.14it/s] 57%|█████▋    | 174/303 [00:24<00:15,  8.08it/s] 58%|█████▊    | 175/303 [00:24<00:15,  8.10it/s] 58%|█████▊    | 176/303 [00:24<00:15,  8.11it/s] 58%|█████▊    | 177/303 [00:24<00:15,  8.12it/s] 59%|█████▊    | 178/303 [00:25<00:15,  8.14it/s] 59%|█████▉    | 179/303 [00:25<00:15,  8.15it/s] 59%|█████▉    | 180/303 [00:25<00:15,  8.15it/s] 60%|█████▉    | 181/303 [00:25<00:14,  8.15it/s] 60%|██████    | 182/303 [00:25<00:14,  8.14it/s] 60%|██████    | 183/303 [00:25<00:14,  8.14it/s] 61%|██████    | 184/303 [00:25<00:14,  8.15it/s] 61%|██████    | 185/303 [00:25<00:14,  8.15it/s] 61%|██████▏   | 186/303 [00:26<00:14,  8.15it/s] 62%|██████▏   | 187/303 [00:26<00:14,  8.16it/s] 62%|██████▏   | 188/303 [00:26<00:14,  8.15it/s] 62%|██████▏   | 189/303 [00:26<00:13,  8.16it/s] 63%|██████▎   | 190/303 [00:26<00:13,  8.16it/s] 63%|██████▎   | 191/303 [00:26<00:13,  8.15it/s] 63%|██████▎   | 192/303 [00:26<00:13,  8.15it/s] 64%|██████▎   | 193/303 [00:26<00:13,  8.13it/s] 64%|██████▍   | 194/303 [00:26<00:13,  8.14it/s] 64%|██████▍   | 195/303 [00:27<00:13,  8.11it/s] 65%|██████▍   | 196/303 [00:27<00:13,  8.12it/s] 65%|██████▌   | 197/303 [00:27<00:13,  8.13it/s] 65%|██████▌   | 198/303 [00:27<00:12,  8.14it/s] 66%|██████▌   | 199/303 [00:27<00:12,  8.14it/s] 66%|██████▌   | 200/303 [00:27<00:12,  8.14it/s] 66%|██████▋   | 201/303 [00:27<00:12,  8.15it/s] 67%|██████▋   | 202/303 [00:27<00:12,  8.15it/s] 67%|██████▋   | 203/303 [00:28<00:12,  8.15it/s] 67%|██████▋   | 204/303 [00:28<00:12,  8.15it/s] 68%|██████▊   | 205/303 [00:28<00:12,  8.15it/s] 68%|██████▊   | 206/303 [00:28<00:11,  8.15it/s] 68%|██████▊   | 207/303 [00:28<00:11,  8.13it/s] 69%|██████▊   | 208/303 [00:28<00:11,  8.13it/s] 69%|██████▉   | 209/303 [00:28<00:11,  8.13it/s] 69%|██████▉   | 210/303 [00:28<00:11,  8.13it/s] 70%|██████▉   | 211/303 [00:29<00:11,  8.13it/s] 70%|██████▉   | 212/303 [00:29<00:11,  8.14it/s] 70%|███████   | 213/303 [00:29<00:11,  8.14it/s] 71%|███████   | 214/303 [00:29<00:10,  8.13it/s] 71%|███████   | 215/303 [00:29<00:10,  8.12it/s] 71%|███████▏  | 216/303 [00:29<00:10,  8.12it/s] 72%|███████▏  | 217/303 [00:29<00:10,  8.13it/s] 72%|███████▏  | 218/303 [00:29<00:10,  8.13it/s] 72%|███████▏  | 219/303 [00:30<00:10,  8.12it/s] 73%|███████▎  | 220/303 [00:30<00:10,  8.13it/s] 73%|███████▎  | 221/303 [00:30<00:10,  8.14it/s] 73%|███████▎  | 222/303 [00:30<00:09,  8.13it/s] 74%|███████▎  | 223/303 [00:30<00:09,  8.14it/s] 74%|███████▍  | 224/303 [00:30<00:09,  8.14it/s] 74%|███████▍  | 225/303 [00:30<00:09,  8.14it/s] 75%|███████▍  | 226/303 [00:30<00:09,  8.14it/s] 75%|███████▍  | 227/303 [00:31<00:09,  8.14it/s] 75%|███████▌  | 228/303 [00:31<00:09,  8.13it/s] 76%|███████▌  | 229/303 [00:31<00:09,  8.12it/s] 76%|███████▌  | 230/303 [00:31<00:08,  8.12it/s] 76%|███████▌  | 231/303 [00:31<00:08,  8.12it/s] 77%|███████▋  | 232/303 [00:31<00:08,  8.12it/s] 77%|███████▋  | 233/303 [00:31<00:08,  8.13it/s] 77%|███████▋  | 234/303 [00:31<00:08,  8.12it/s] 78%|███████▊  | 235/303 [00:32<00:08,  8.12it/s] 78%|███████▊  | 236/303 [00:32<00:08,  8.12it/s] 78%|███████▊  | 237/303 [00:32<00:08,  8.11it/s] 79%|███████▊  | 238/303 [00:32<00:08,  8.12it/s] 79%|███████▉  | 239/303 [00:32<00:07,  8.12it/s] 79%|███████▉  | 240/303 [00:32<00:07,  8.12it/s] 80%|███████▉  | 241/303 [00:32<00:07,  8.13it/s] 80%|███████▉  | 242/303 [00:32<00:07,  8.12it/s] 80%|████████  | 243/303 [00:33<00:07,  8.10it/s] 81%|████████  | 244/303 [00:33<00:07,  8.10it/s] 81%|████████  | 245/303 [00:33<00:07,  8.11it/s] 81%|████████  | 246/303 [00:33<00:07,  8.11it/s] 82%|████████▏ | 247/303 [00:33<00:06,  8.11it/s] 82%|████████▏ | 248/303 [00:33<00:06,  8.10it/s] 82%|████████▏ | 249/303 [00:33<00:06,  8.10it/s] 83%|████████▎ | 250/303 [00:33<00:06,  8.11it/s] 83%|████████▎ | 251/303 [00:34<00:06,  8.10it/s] 83%|████████▎ | 252/303 [00:34<00:06,  8.10it/s] 83%|████████▎ | 253/303 [00:34<00:06,  8.11it/s] 84%|████████▍ | 254/303 [00:34<00:06,  8.11it/s] 84%|████████▍ | 255/303 [00:34<00:05,  8.12it/s] 84%|████████▍ | 256/303 [00:34<00:05,  8.09it/s] 85%|████████▍ | 257/303 [00:34<00:05,  8.10it/s] 85%|████████▌ | 258/303 [00:34<00:05,  8.11it/s] 85%|████████▌ | 259/303 [00:34<00:05,  8.12it/s] 86%|████████▌ | 260/303 [00:35<00:05,  8.12it/s] 86%|████████▌ | 261/303 [00:35<00:05,  8.10it/s] 86%|████████▋ | 262/303 [00:35<00:05,  8.11it/s] 87%|████████▋ | 263/303 [00:35<00:04,  8.11it/s] 87%|████████▋ | 264/303 [00:35<00:04,  8.10it/s] 87%|████████▋ | 265/303 [00:35<00:04,  8.11it/s] 88%|████████▊ | 266/303 [00:35<00:04,  8.11it/s] 88%|████████▊ | 267/303 [00:35<00:04,  8.12it/s] 88%|████████▊ | 268/303 [00:36<00:04,  8.12it/s] 89%|████████▉ | 269/303 [00:36<00:04,  8.12it/s] 89%|████████▉ | 270/303 [00:36<00:04,  8.10it/s] 89%|████████▉ | 271/303 [00:36<00:03,  8.11it/s] 90%|████████▉ | 272/303 [00:36<00:03,  8.12it/s] 90%|█████████ | 273/303 [00:36<00:03,  8.13it/s] 90%|█████████ | 274/303 [00:36<00:03,  8.13it/s] 91%|█████████ | 275/303 [00:36<00:03,  8.12it/s] 91%|█████████ | 276/303 [00:37<00:03,  8.13it/s] 91%|█████████▏| 277/303 [00:37<00:03,  8.13it/s] 92%|█████████▏| 278/303 [00:37<00:03,  8.14it/s] 92%|█████████▏| 279/303 [00:37<00:02,  8.14it/s] 92%|█████████▏| 280/303 [00:37<00:02,  8.14it/s] 93%|█████████▎| 281/303 [00:37<00:02,  8.12it/s] 93%|█████████▎| 282/303 [00:37<00:02,  8.12it/s] 93%|█████████▎| 283/303 [00:37<00:02,  8.13it/s] 94%|█████████▎| 284/303 [00:38<00:02,  8.14it/s] 94%|█████████▍| 285/303 [00:38<00:02,  8.14it/s] 94%|█████████▍| 286/303 [00:38<00:02,  8.14it/s] 95%|█████████▍| 287/303 [00:38<00:01,  8.14it/s] 95%|█████████▌| 288/303 [00:38<00:01,  8.15it/s] 95%|█████████▌| 289/303 [00:38<00:01,  8.14it/s] 96%|█████████▌| 290/303 [00:38<00:01,  8.13it/s] 96%|█████████▌| 291/303 [00:38<00:01,  8.15it/s] 96%|█████████▋| 292/303 [00:39<00:01,  8.16it/s] 97%|█████████▋| 293/303 [00:39<00:01,  8.16it/s] 97%|█████████▋| 294/303 [00:39<00:01,  8.18it/s] 97%|█████████▋| 295/303 [00:39<00:00,  8.18it/s] 98%|█████████▊| 296/303 [00:39<00:00,  8.18it/s] 98%|█████████▊| 297/303 [00:39<00:00,  8.18it/s] 98%|█████████▊| 298/303 [00:39<00:00,  8.17it/s] 99%|█████████▊| 299/303 [00:39<00:00,  8.17it/s] 99%|█████████▉| 300/303 [00:40<00:00,  8.18it/s] 99%|█████████▉| 301/303 [00:40<00:00,  8.19it/s]100%|█████████▉| 302/303 [00:40<00:00,  8.19it/s]100%|██████████| 303/303 [00:40<00:00,  8.19it/s]100%|██████████| 303/303 [00:40<00:00,  7.49it/s]
=> result
* total: 30,300
* correct: 18,160
* accuracy: 59.9%
* error: 40.1%
* macro_f1: 56.2%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers food101 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/food101/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/food101/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_3.pkl
1616 20200 30300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  101
# train_x  1,616
# val      20,200
# test     30,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/303 [00:00<?, ?it/s]  0%|          | 1/303 [00:03<16:53,  3.36s/it]  1%|          | 2/303 [00:03<07:17,  1.45s/it]  1%|          | 3/303 [00:03<04:13,  1.18it/s]  1%|▏         | 4/303 [00:03<02:47,  1.79it/s]  2%|▏         | 5/303 [00:03<01:59,  2.49it/s]  2%|▏         | 6/303 [00:03<01:30,  3.27it/s]  2%|▏         | 7/303 [00:04<01:12,  4.07it/s]  3%|▎         | 8/303 [00:04<01:00,  4.85it/s]  3%|▎         | 9/303 [00:04<00:52,  5.56it/s]  3%|▎         | 10/303 [00:04<00:47,  6.18it/s]  4%|▎         | 11/303 [00:04<00:43,  6.69it/s]  4%|▍         | 12/303 [00:04<00:41,  7.10it/s]  4%|▍         | 13/303 [00:04<00:39,  7.40it/s]  5%|▍         | 14/303 [00:04<00:37,  7.63it/s]  5%|▍         | 15/303 [00:05<00:36,  7.80it/s]  5%|▌         | 16/303 [00:05<00:36,  7.92it/s]  6%|▌         | 17/303 [00:05<00:35,  8.01it/s]  6%|▌         | 18/303 [00:05<00:35,  8.07it/s]  6%|▋         | 19/303 [00:05<00:35,  8.11it/s]  7%|▋         | 20/303 [00:05<00:34,  8.14it/s]  7%|▋         | 21/303 [00:05<00:34,  8.16it/s]  7%|▋         | 22/303 [00:05<00:34,  8.18it/s]  8%|▊         | 23/303 [00:06<00:34,  8.19it/s]  8%|▊         | 24/303 [00:06<00:34,  8.20it/s]  8%|▊         | 25/303 [00:06<00:33,  8.21it/s]  9%|▊         | 26/303 [00:06<00:33,  8.20it/s]  9%|▉         | 27/303 [00:06<00:33,  8.20it/s]  9%|▉         | 28/303 [00:06<00:33,  8.20it/s] 10%|▉         | 29/303 [00:06<00:33,  8.20it/s] 10%|▉         | 30/303 [00:06<00:33,  8.19it/s] 10%|█         | 31/303 [00:07<00:33,  8.18it/s] 11%|█         | 32/303 [00:07<00:33,  8.18it/s] 11%|█         | 33/303 [00:07<00:32,  8.18it/s] 11%|█         | 34/303 [00:07<00:32,  8.16it/s] 12%|█▏        | 35/303 [00:07<00:32,  8.14it/s] 12%|█▏        | 36/303 [00:07<00:32,  8.14it/s] 12%|█▏        | 37/303 [00:07<00:32,  8.16it/s] 13%|█▎        | 38/303 [00:07<00:32,  8.17it/s] 13%|█▎        | 39/303 [00:07<00:32,  8.18it/s] 13%|█▎        | 40/303 [00:08<00:32,  8.18it/s] 14%|█▎        | 41/303 [00:08<00:31,  8.19it/s] 14%|█▍        | 42/303 [00:08<00:31,  8.19it/s] 14%|█▍        | 43/303 [00:08<00:31,  8.19it/s] 15%|█▍        | 44/303 [00:08<00:31,  8.18it/s] 15%|█▍        | 45/303 [00:08<00:31,  8.19it/s] 15%|█▌        | 46/303 [00:08<00:31,  8.17it/s] 16%|█▌        | 47/303 [00:08<00:31,  8.17it/s] 16%|█▌        | 48/303 [00:09<00:31,  8.17it/s] 16%|█▌        | 49/303 [00:09<00:31,  8.13it/s] 17%|█▋        | 50/303 [00:09<00:31,  8.16it/s] 17%|█▋        | 51/303 [00:09<00:30,  8.17it/s] 17%|█▋        | 52/303 [00:09<00:30,  8.17it/s] 17%|█▋        | 53/303 [00:09<00:30,  8.18it/s] 18%|█▊        | 54/303 [00:09<00:30,  8.18it/s] 18%|█▊        | 55/303 [00:09<00:30,  8.18it/s] 18%|█▊        | 56/303 [00:10<00:30,  8.17it/s] 19%|█▉        | 57/303 [00:10<00:30,  8.18it/s] 19%|█▉        | 58/303 [00:10<00:29,  8.19it/s] 19%|█▉        | 59/303 [00:10<00:29,  8.19it/s] 20%|█▉        | 60/303 [00:10<00:29,  8.19it/s] 20%|██        | 61/303 [00:10<00:29,  8.19it/s] 20%|██        | 62/303 [00:10<00:29,  8.18it/s] 21%|██        | 63/303 [00:10<00:29,  8.18it/s] 21%|██        | 64/303 [00:11<00:29,  8.18it/s] 21%|██▏       | 65/303 [00:11<00:29,  8.18it/s] 22%|██▏       | 66/303 [00:11<00:28,  8.18it/s] 22%|██▏       | 67/303 [00:11<00:28,  8.17it/s] 22%|██▏       | 68/303 [00:11<00:28,  8.17it/s] 23%|██▎       | 69/303 [00:11<00:28,  8.17it/s] 23%|██▎       | 70/303 [00:11<00:28,  8.17it/s] 23%|██▎       | 71/303 [00:11<00:28,  8.16it/s] 24%|██▍       | 72/303 [00:12<00:28,  8.16it/s] 24%|██▍       | 73/303 [00:12<00:28,  8.16it/s] 24%|██▍       | 74/303 [00:12<00:28,  8.15it/s] 25%|██▍       | 75/303 [00:12<00:27,  8.15it/s] 25%|██▌       | 76/303 [00:12<00:27,  8.15it/s] 25%|██▌       | 77/303 [00:12<00:27,  8.14it/s] 26%|██▌       | 78/303 [00:12<00:27,  8.14it/s] 26%|██▌       | 79/303 [00:12<00:27,  8.14it/s] 26%|██▋       | 80/303 [00:13<00:27,  8.15it/s] 27%|██▋       | 81/303 [00:13<00:27,  8.15it/s] 27%|██▋       | 82/303 [00:13<00:27,  8.16it/s] 27%|██▋       | 83/303 [00:13<00:26,  8.18it/s] 28%|██▊       | 84/303 [00:13<00:26,  8.18it/s] 28%|██▊       | 85/303 [00:13<00:26,  8.18it/s] 28%|██▊       | 86/303 [00:13<00:26,  8.18it/s] 29%|██▊       | 87/303 [00:13<00:26,  8.18it/s] 29%|██▉       | 88/303 [00:13<00:26,  8.16it/s] 29%|██▉       | 89/303 [00:14<00:26,  8.17it/s] 30%|██▉       | 90/303 [00:14<00:26,  8.18it/s] 30%|███       | 91/303 [00:14<00:25,  8.18it/s] 30%|███       | 92/303 [00:14<00:25,  8.17it/s] 31%|███       | 93/303 [00:14<00:25,  8.17it/s] 31%|███       | 94/303 [00:14<00:25,  8.17it/s] 31%|███▏      | 95/303 [00:14<00:25,  8.16it/s] 32%|███▏      | 96/303 [00:14<00:25,  8.15it/s] 32%|███▏      | 97/303 [00:15<00:25,  8.15it/s] 32%|███▏      | 98/303 [00:15<00:25,  8.15it/s] 33%|███▎      | 99/303 [00:15<00:24,  8.16it/s] 33%|███▎      | 100/303 [00:15<00:24,  8.17it/s] 33%|███▎      | 101/303 [00:15<00:24,  8.16it/s] 34%|███▎      | 102/303 [00:15<00:24,  8.15it/s] 34%|███▍      | 103/303 [00:15<00:24,  8.15it/s] 34%|███▍      | 104/303 [00:15<00:24,  8.14it/s] 35%|███▍      | 105/303 [00:16<00:24,  8.12it/s] 35%|███▍      | 106/303 [00:16<00:24,  8.13it/s] 35%|███▌      | 107/303 [00:16<00:24,  8.14it/s] 36%|███▌      | 108/303 [00:16<00:24,  8.10it/s] 36%|███▌      | 109/303 [00:16<00:23,  8.13it/s] 36%|███▋      | 110/303 [00:16<00:23,  8.12it/s] 37%|███▋      | 111/303 [00:16<00:23,  8.12it/s] 37%|███▋      | 112/303 [00:16<00:23,  8.14it/s] 37%|███▋      | 113/303 [00:17<00:23,  8.15it/s] 38%|███▊      | 114/303 [00:17<00:23,  8.15it/s] 38%|███▊      | 115/303 [00:17<00:23,  8.15it/s] 38%|███▊      | 116/303 [00:17<00:22,  8.16it/s] 39%|███▊      | 117/303 [00:17<00:22,  8.16it/s] 39%|███▉      | 118/303 [00:17<00:22,  8.15it/s] 39%|███▉      | 119/303 [00:17<00:22,  8.14it/s] 40%|███▉      | 120/303 [00:17<00:22,  8.15it/s] 40%|███▉      | 121/303 [00:18<00:22,  8.14it/s] 40%|████      | 122/303 [00:18<00:22,  8.16it/s] 41%|████      | 123/303 [00:18<00:22,  8.17it/s] 41%|████      | 124/303 [00:18<00:21,  8.15it/s] 41%|████▏     | 125/303 [00:18<00:21,  8.16it/s] 42%|████▏     | 126/303 [00:18<00:21,  8.16it/s] 42%|████▏     | 127/303 [00:18<00:21,  8.15it/s] 42%|████▏     | 128/303 [00:18<00:21,  8.16it/s] 43%|████▎     | 129/303 [00:19<00:21,  8.15it/s] 43%|████▎     | 130/303 [00:19<00:21,  8.15it/s] 43%|████▎     | 131/303 [00:19<00:21,  8.15it/s] 44%|████▎     | 132/303 [00:19<00:21,  8.14it/s] 44%|████▍     | 133/303 [00:19<00:20,  8.13it/s] 44%|████▍     | 134/303 [00:19<00:20,  8.12it/s] 45%|████▍     | 135/303 [00:19<00:20,  8.12it/s] 45%|████▍     | 136/303 [00:19<00:20,  8.12it/s] 45%|████▌     | 137/303 [00:19<00:20,  8.14it/s] 46%|████▌     | 138/303 [00:20<00:20,  8.14it/s] 46%|████▌     | 139/303 [00:20<00:20,  8.13it/s] 46%|████▌     | 140/303 [00:20<00:20,  8.13it/s] 47%|████▋     | 141/303 [00:20<00:19,  8.14it/s] 47%|████▋     | 142/303 [00:20<00:19,  8.15it/s] 47%|████▋     | 143/303 [00:20<00:19,  8.16it/s] 48%|████▊     | 144/303 [00:20<00:19,  8.16it/s] 48%|████▊     | 145/303 [00:20<00:19,  8.16it/s] 48%|████▊     | 146/303 [00:21<00:19,  8.16it/s] 49%|████▊     | 147/303 [00:21<00:19,  8.16it/s] 49%|████▉     | 148/303 [00:21<00:18,  8.16it/s] 49%|████▉     | 149/303 [00:21<00:18,  8.15it/s] 50%|████▉     | 150/303 [00:21<00:18,  8.15it/s] 50%|████▉     | 151/303 [00:21<00:18,  8.15it/s] 50%|█████     | 152/303 [00:21<00:18,  8.16it/s] 50%|█████     | 153/303 [00:21<00:18,  8.15it/s] 51%|█████     | 154/303 [00:22<00:18,  8.15it/s] 51%|█████     | 155/303 [00:22<00:18,  8.16it/s] 51%|█████▏    | 156/303 [00:22<00:18,  8.15it/s] 52%|█████▏    | 157/303 [00:22<00:17,  8.15it/s] 52%|█████▏    | 158/303 [00:22<00:17,  8.16it/s] 52%|█████▏    | 159/303 [00:22<00:17,  8.16it/s] 53%|█████▎    | 160/303 [00:22<00:17,  8.16it/s] 53%|█████▎    | 161/303 [00:22<00:17,  8.15it/s] 53%|█████▎    | 162/303 [00:23<00:17,  8.14it/s] 54%|█████▍    | 163/303 [00:23<00:17,  8.15it/s] 54%|█████▍    | 164/303 [00:23<00:17,  8.15it/s] 54%|█████▍    | 165/303 [00:23<00:16,  8.15it/s] 55%|█████▍    | 166/303 [00:23<00:16,  8.15it/s] 55%|█████▌    | 167/303 [00:23<00:16,  8.14it/s] 55%|█████▌    | 168/303 [00:23<00:16,  8.14it/s] 56%|█████▌    | 169/303 [00:23<00:16,  8.14it/s] 56%|█████▌    | 170/303 [00:24<00:16,  8.13it/s] 56%|█████▋    | 171/303 [00:24<00:16,  8.13it/s] 57%|█████▋    | 172/303 [00:24<00:16,  8.13it/s] 57%|█████▋    | 173/303 [00:24<00:15,  8.14it/s] 57%|█████▋    | 174/303 [00:24<00:15,  8.14it/s] 58%|█████▊    | 175/303 [00:24<00:15,  8.14it/s] 58%|█████▊    | 176/303 [00:24<00:15,  8.15it/s] 58%|█████▊    | 177/303 [00:24<00:15,  8.15it/s] 59%|█████▊    | 178/303 [00:25<00:15,  8.14it/s] 59%|█████▉    | 179/303 [00:25<00:15,  8.13it/s] 59%|█████▉    | 180/303 [00:25<00:15,  8.15it/s] 60%|█████▉    | 181/303 [00:25<00:14,  8.14it/s] 60%|██████    | 182/303 [00:25<00:14,  8.14it/s] 60%|██████    | 183/303 [00:25<00:14,  8.14it/s] 61%|██████    | 184/303 [00:25<00:14,  8.14it/s] 61%|██████    | 185/303 [00:25<00:14,  8.13it/s] 61%|██████▏   | 186/303 [00:26<00:14,  8.12it/s] 62%|██████▏   | 187/303 [00:26<00:14,  8.13it/s] 62%|██████▏   | 188/303 [00:26<00:14,  8.13it/s] 62%|██████▏   | 189/303 [00:26<00:14,  8.13it/s] 63%|██████▎   | 190/303 [00:26<00:13,  8.14it/s] 63%|██████▎   | 191/303 [00:26<00:13,  8.15it/s] 63%|██████▎   | 192/303 [00:26<00:13,  8.15it/s] 64%|██████▎   | 193/303 [00:26<00:13,  8.14it/s] 64%|██████▍   | 194/303 [00:26<00:13,  8.12it/s] 64%|██████▍   | 195/303 [00:27<00:13,  8.11it/s] 65%|██████▍   | 196/303 [00:27<00:13,  8.12it/s] 65%|██████▌   | 197/303 [00:27<00:13,  8.12it/s] 65%|██████▌   | 198/303 [00:27<00:12,  8.12it/s] 66%|██████▌   | 199/303 [00:27<00:12,  8.14it/s] 66%|██████▌   | 200/303 [00:27<00:12,  8.14it/s] 66%|██████▋   | 201/303 [00:27<00:12,  8.14it/s] 67%|██████▋   | 202/303 [00:27<00:12,  8.12it/s] 67%|██████▋   | 203/303 [00:28<00:12,  8.13it/s] 67%|██████▋   | 204/303 [00:28<00:12,  8.14it/s] 68%|██████▊   | 205/303 [00:28<00:12,  8.13it/s] 68%|██████▊   | 206/303 [00:28<00:11,  8.14it/s] 68%|██████▊   | 207/303 [00:28<00:11,  8.14it/s] 69%|██████▊   | 208/303 [00:28<00:11,  8.14it/s] 69%|██████▉   | 209/303 [00:28<00:11,  8.14it/s] 69%|██████▉   | 210/303 [00:28<00:11,  8.13it/s] 70%|██████▉   | 211/303 [00:29<00:11,  8.13it/s] 70%|██████▉   | 212/303 [00:29<00:11,  8.14it/s] 70%|███████   | 213/303 [00:29<00:11,  8.14it/s] 71%|███████   | 214/303 [00:29<00:10,  8.15it/s] 71%|███████   | 215/303 [00:29<00:10,  8.15it/s] 71%|███████▏  | 216/303 [00:29<00:10,  8.14it/s] 72%|███████▏  | 217/303 [00:29<00:10,  8.15it/s] 72%|███████▏  | 218/303 [00:29<00:10,  8.14it/s] 72%|███████▏  | 219/303 [00:30<00:10,  8.14it/s] 73%|███████▎  | 220/303 [00:30<00:10,  8.15it/s] 73%|███████▎  | 221/303 [00:30<00:10,  8.14it/s] 73%|███████▎  | 222/303 [00:30<00:09,  8.12it/s] 74%|███████▎  | 223/303 [00:30<00:09,  8.11it/s] 74%|███████▍  | 224/303 [00:30<00:09,  8.12it/s] 74%|███████▍  | 225/303 [00:30<00:09,  8.14it/s] 75%|███████▍  | 226/303 [00:30<00:09,  8.15it/s] 75%|███████▍  | 227/303 [00:31<00:09,  8.15it/s] 75%|███████▌  | 228/303 [00:31<00:09,  8.15it/s] 76%|███████▌  | 229/303 [00:31<00:09,  8.15it/s] 76%|███████▌  | 230/303 [00:31<00:08,  8.16it/s] 76%|███████▌  | 231/303 [00:31<00:08,  8.16it/s] 77%|███████▋  | 232/303 [00:31<00:08,  8.15it/s] 77%|███████▋  | 233/303 [00:31<00:08,  8.15it/s] 77%|███████▋  | 234/303 [00:31<00:08,  8.15it/s] 78%|███████▊  | 235/303 [00:32<00:08,  8.14it/s] 78%|███████▊  | 236/303 [00:32<00:08,  8.14it/s] 78%|███████▊  | 237/303 [00:32<00:08,  8.13it/s] 79%|███████▊  | 238/303 [00:32<00:07,  8.13it/s] 79%|███████▉  | 239/303 [00:32<00:07,  8.12it/s] 79%|███████▉  | 240/303 [00:32<00:07,  8.13it/s] 80%|███████▉  | 241/303 [00:32<00:07,  8.12it/s] 80%|███████▉  | 242/303 [00:32<00:07,  8.11it/s] 80%|████████  | 243/303 [00:33<00:07,  8.12it/s] 81%|████████  | 244/303 [00:33<00:07,  8.12it/s] 81%|████████  | 245/303 [00:33<00:07,  8.12it/s] 81%|████████  | 246/303 [00:33<00:07,  8.12it/s] 82%|████████▏ | 247/303 [00:33<00:06,  8.12it/s] 82%|████████▏ | 248/303 [00:33<00:06,  8.12it/s] 82%|████████▏ | 249/303 [00:33<00:06,  8.13it/s] 83%|████████▎ | 250/303 [00:33<00:06,  8.13it/s] 83%|████████▎ | 251/303 [00:34<00:06,  8.13it/s] 83%|████████▎ | 252/303 [00:34<00:06,  8.11it/s] 83%|████████▎ | 253/303 [00:34<00:06,  8.13it/s] 84%|████████▍ | 254/303 [00:34<00:06,  8.13it/s] 84%|████████▍ | 255/303 [00:34<00:05,  8.13it/s] 84%|████████▍ | 256/303 [00:34<00:05,  8.13it/s] 85%|████████▍ | 257/303 [00:34<00:05,  8.13it/s] 85%|████████▌ | 258/303 [00:34<00:05,  8.13it/s] 85%|████████▌ | 259/303 [00:34<00:05,  8.13it/s] 86%|████████▌ | 260/303 [00:35<00:05,  8.14it/s] 86%|████████▌ | 261/303 [00:35<00:05,  8.12it/s] 86%|████████▋ | 262/303 [00:35<00:05,  8.12it/s] 87%|████████▋ | 263/303 [00:35<00:04,  8.13it/s] 87%|████████▋ | 264/303 [00:35<00:04,  8.13it/s] 87%|████████▋ | 265/303 [00:35<00:04,  8.12it/s] 88%|████████▊ | 266/303 [00:35<00:04,  8.11it/s] 88%|████████▊ | 267/303 [00:35<00:04,  8.10it/s] 88%|████████▊ | 268/303 [00:36<00:04,  8.09it/s] 89%|████████▉ | 269/303 [00:36<00:04,  8.11it/s] 89%|████████▉ | 270/303 [00:36<00:04,  8.12it/s] 89%|████████▉ | 271/303 [00:36<00:03,  8.10it/s] 90%|████████▉ | 272/303 [00:36<00:03,  8.11it/s] 90%|█████████ | 273/303 [00:36<00:03,  8.12it/s] 90%|█████████ | 274/303 [00:36<00:03,  8.12it/s] 91%|█████████ | 275/303 [00:36<00:03,  8.13it/s] 91%|█████████ | 276/303 [00:37<00:03,  8.13it/s] 91%|█████████▏| 277/303 [00:37<00:03,  8.14it/s] 92%|█████████▏| 278/303 [00:37<00:03,  8.14it/s] 92%|█████████▏| 279/303 [00:37<00:02,  8.12it/s] 92%|█████████▏| 280/303 [00:37<00:02,  8.11it/s] 93%|█████████▎| 281/303 [00:37<00:02,  8.12it/s] 93%|█████████▎| 282/303 [00:37<00:02,  8.13it/s] 93%|█████████▎| 283/303 [00:37<00:02,  8.13it/s] 94%|█████████▎| 284/303 [00:38<00:02,  8.12it/s] 94%|█████████▍| 285/303 [00:38<00:02,  8.13it/s] 94%|█████████▍| 286/303 [00:38<00:02,  8.13it/s] 95%|█████████▍| 287/303 [00:38<00:01,  8.13it/s] 95%|█████████▌| 288/303 [00:38<00:01,  8.13it/s] 95%|█████████▌| 289/303 [00:38<00:01,  8.14it/s] 96%|█████████▌| 290/303 [00:38<00:01,  8.14it/s] 96%|█████████▌| 291/303 [00:38<00:01,  8.14it/s] 96%|█████████▋| 292/303 [00:39<00:01,  8.15it/s] 97%|█████████▋| 293/303 [00:39<00:01,  8.15it/s] 97%|█████████▋| 294/303 [00:39<00:01,  8.16it/s] 97%|█████████▋| 295/303 [00:39<00:00,  8.17it/s] 98%|█████████▊| 296/303 [00:39<00:00,  8.18it/s] 98%|█████████▊| 297/303 [00:39<00:00,  8.18it/s] 98%|█████████▊| 298/303 [00:39<00:00,  8.18it/s] 99%|█████████▊| 299/303 [00:39<00:00,  8.19it/s] 99%|█████████▉| 300/303 [00:40<00:00,  8.18it/s] 99%|█████████▉| 301/303 [00:40<00:00,  8.19it/s]100%|█████████▉| 302/303 [00:40<00:00,  8.18it/s]100%|██████████| 303/303 [00:40<00:00,  8.18it/s]100%|██████████| 303/303 [00:40<00:00,  7.49it/s]
=> result
* total: 30,300
* correct: 18,059
* accuracy: 59.6%
* error: 40.4%
* macro_f1: 56.7%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers ucf101 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/ucf101/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/ucf101/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_1.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:03<02:11,  3.55s/it]  5%|▌         | 2/38 [00:03<00:55,  1.54s/it]  8%|▊         | 3/38 [00:03<00:31,  1.12it/s] 11%|█         | 4/38 [00:03<00:19,  1.70it/s] 13%|█▎        | 5/38 [00:04<00:13,  2.38it/s] 16%|█▌        | 6/38 [00:04<00:10,  3.14it/s] 18%|█▊        | 7/38 [00:04<00:07,  3.93it/s] 21%|██        | 8/38 [00:04<00:06,  4.72it/s] 24%|██▎       | 9/38 [00:04<00:05,  5.44it/s] 26%|██▋       | 10/38 [00:04<00:04,  6.06it/s] 29%|██▉       | 11/38 [00:04<00:04,  6.59it/s] 32%|███▏      | 12/38 [00:04<00:03,  7.01it/s] 34%|███▍      | 13/38 [00:05<00:03,  7.32it/s] 37%|███▋      | 14/38 [00:05<00:03,  7.57it/s] 39%|███▉      | 15/38 [00:05<00:02,  7.75it/s] 42%|████▏     | 16/38 [00:05<00:02,  7.88it/s] 45%|████▍     | 17/38 [00:05<00:02,  7.97it/s] 47%|████▋     | 18/38 [00:05<00:02,  8.05it/s] 50%|█████     | 19/38 [00:05<00:02,  8.09it/s] 53%|█████▎    | 20/38 [00:05<00:02,  8.12it/s] 55%|█████▌    | 21/38 [00:05<00:02,  8.14it/s] 58%|█████▊    | 22/38 [00:06<00:01,  8.15it/s] 61%|██████    | 23/38 [00:06<00:01,  8.16it/s] 63%|██████▎   | 24/38 [00:06<00:01,  8.16it/s] 66%|██████▌   | 25/38 [00:06<00:01,  8.18it/s] 68%|██████▊   | 26/38 [00:06<00:01,  8.19it/s] 71%|███████   | 27/38 [00:06<00:01,  8.21it/s] 74%|███████▎  | 28/38 [00:06<00:01,  8.18it/s] 76%|███████▋  | 29/38 [00:06<00:01,  8.20it/s] 79%|███████▉  | 30/38 [00:07<00:00,  8.21it/s] 82%|████████▏ | 31/38 [00:07<00:00,  8.23it/s] 84%|████████▍ | 32/38 [00:07<00:00,  8.24it/s] 87%|████████▋ | 33/38 [00:07<00:00,  8.24it/s] 89%|████████▉ | 34/38 [00:07<00:00,  8.24it/s] 92%|█████████▏| 35/38 [00:07<00:00,  8.24it/s] 95%|█████████▍| 36/38 [00:07<00:00,  8.25it/s] 97%|█████████▋| 37/38 [00:07<00:00,  8.24it/s]100%|██████████| 38/38 [00:08<00:00,  8.60it/s]100%|██████████| 38/38 [00:08<00:00,  4.68it/s]
=> result
* total: 3,783
* correct: 1,655
* accuracy: 43.7%
* error: 56.3%
* macro_f1: 37.2%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers ucf101 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/ucf101/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/ucf101/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_2.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:02<01:46,  2.89s/it]  5%|▌         | 2/38 [00:03<00:45,  1.26s/it]  8%|▊         | 3/38 [00:03<00:25,  1.35it/s] 11%|█         | 4/38 [00:03<00:16,  2.01it/s] 13%|█▎        | 5/38 [00:03<00:11,  2.76it/s] 16%|█▌        | 6/38 [00:03<00:08,  3.57it/s] 18%|█▊        | 7/38 [00:03<00:07,  4.37it/s] 21%|██        | 8/38 [00:03<00:05,  5.13it/s] 24%|██▎       | 9/38 [00:03<00:05,  5.79it/s] 26%|██▋       | 10/38 [00:03<00:04,  6.36it/s] 29%|██▉       | 11/38 [00:04<00:03,  6.83it/s] 32%|███▏      | 12/38 [00:04<00:03,  7.21it/s] 34%|███▍      | 13/38 [00:04<00:03,  7.49it/s] 37%|███▋      | 14/38 [00:04<00:03,  7.69it/s] 39%|███▉      | 15/38 [00:04<00:02,  7.85it/s] 42%|████▏     | 16/38 [00:04<00:02,  7.95it/s] 45%|████▍     | 17/38 [00:04<00:02,  8.02it/s] 47%|████▋     | 18/38 [00:04<00:02,  8.07it/s] 50%|█████     | 19/38 [00:05<00:02,  8.11it/s] 53%|█████▎    | 20/38 [00:05<00:02,  8.14it/s] 55%|█████▌    | 21/38 [00:05<00:02,  8.16it/s] 58%|█████▊    | 22/38 [00:05<00:01,  8.17it/s] 61%|██████    | 23/38 [00:05<00:01,  8.17it/s] 63%|██████▎   | 24/38 [00:05<00:01,  8.19it/s] 66%|██████▌   | 25/38 [00:05<00:01,  8.22it/s] 68%|██████▊   | 26/38 [00:05<00:01,  8.23it/s] 71%|███████   | 27/38 [00:06<00:01,  8.20it/s] 74%|███████▎  | 28/38 [00:06<00:01,  8.21it/s] 76%|███████▋  | 29/38 [00:06<00:01,  8.23it/s] 79%|███████▉  | 30/38 [00:06<00:00,  8.22it/s] 82%|████████▏ | 31/38 [00:06<00:00,  8.23it/s] 84%|████████▍ | 32/38 [00:06<00:00,  8.23it/s] 87%|████████▋ | 33/38 [00:06<00:00,  8.23it/s] 89%|████████▉ | 34/38 [00:06<00:00,  8.24it/s] 92%|█████████▏| 35/38 [00:07<00:00,  8.24it/s] 95%|█████████▍| 36/38 [00:07<00:00,  8.24it/s] 97%|█████████▋| 37/38 [00:07<00:00,  8.23it/s]100%|██████████| 38/38 [00:07<00:00,  8.59it/s]100%|██████████| 38/38 [00:07<00:00,  5.10it/s]
=> result
* total: 3,783
* correct: 1,390
* accuracy: 36.7%
* error: 63.3%
* macro_f1: 29.6%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers ucf101 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/ucf101/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/ucf101/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_3.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:02<01:44,  2.84s/it]  5%|▌         | 2/38 [00:02<00:44,  1.24s/it]  8%|▊         | 3/38 [00:03<00:25,  1.37it/s] 11%|█         | 4/38 [00:03<00:16,  2.04it/s] 13%|█▎        | 5/38 [00:03<00:11,  2.80it/s] 16%|█▌        | 6/38 [00:03<00:08,  3.61it/s] 18%|█▊        | 7/38 [00:03<00:07,  4.41it/s] 21%|██        | 8/38 [00:03<00:05,  5.17it/s] 24%|██▎       | 9/38 [00:03<00:04,  5.84it/s] 26%|██▋       | 10/38 [00:03<00:04,  6.40it/s] 29%|██▉       | 11/38 [00:04<00:03,  6.86it/s] 32%|███▏      | 12/38 [00:04<00:03,  7.22it/s] 34%|███▍      | 13/38 [00:04<00:03,  7.49it/s] 37%|███▋      | 14/38 [00:04<00:03,  7.69it/s] 39%|███▉      | 15/38 [00:04<00:02,  7.83it/s] 42%|████▏     | 16/38 [00:04<00:02,  7.95it/s] 45%|████▍     | 17/38 [00:04<00:02,  8.02it/s] 47%|████▋     | 18/38 [00:04<00:02,  8.08it/s] 50%|█████     | 19/38 [00:05<00:02,  8.11it/s] 53%|█████▎    | 20/38 [00:05<00:02,  8.14it/s] 55%|█████▌    | 21/38 [00:05<00:02,  8.16it/s] 58%|█████▊    | 22/38 [00:05<00:01,  8.17it/s] 61%|██████    | 23/38 [00:05<00:01,  8.19it/s] 63%|██████▎   | 24/38 [00:05<00:01,  8.20it/s] 66%|██████▌   | 25/38 [00:05<00:01,  8.20it/s] 68%|██████▊   | 26/38 [00:05<00:01,  8.21it/s] 71%|███████   | 27/38 [00:06<00:01,  8.21it/s] 74%|███████▎  | 28/38 [00:06<00:01,  8.23it/s] 76%|███████▋  | 29/38 [00:06<00:01,  8.23it/s] 79%|███████▉  | 30/38 [00:06<00:00,  8.24it/s] 82%|████████▏ | 31/38 [00:06<00:00,  8.24it/s] 84%|████████▍ | 32/38 [00:06<00:00,  8.24it/s] 87%|████████▋ | 33/38 [00:06<00:00,  8.24it/s] 89%|████████▉ | 34/38 [00:06<00:00,  8.24it/s] 92%|█████████▏| 35/38 [00:06<00:00,  8.23it/s] 95%|█████████▍| 36/38 [00:07<00:00,  8.24it/s] 97%|█████████▋| 37/38 [00:07<00:00,  8.25it/s]100%|██████████| 38/38 [00:07<00:00,  8.60it/s]100%|██████████| 38/38 [00:07<00:00,  5.14it/s]
=> result
* total: 3,783
* correct: 1,491
* accuracy: 39.4%
* error: 60.6%
* macro_f1: 31.1%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers sun397 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/sun397/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/sun397/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_1.pkl
6352 3970 19850
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  397
# train_x  6,352
# val      3,970
# test     19,850
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/199 [00:00<?, ?it/s]  1%|          | 1/199 [00:05<18:31,  5.61s/it]  1%|          | 2/199 [00:05<07:56,  2.42s/it]  2%|▏         | 3/199 [00:05<04:33,  1.40s/it]  2%|▏         | 4/199 [00:06<02:59,  1.09it/s]  3%|▎         | 5/199 [00:06<02:06,  1.53it/s]  3%|▎         | 6/199 [00:06<01:35,  2.03it/s]  4%|▎         | 7/199 [00:06<01:15,  2.55it/s]  4%|▍         | 8/199 [00:06<01:02,  3.08it/s]  5%|▍         | 9/199 [00:07<01:36,  1.96it/s]  5%|▌         | 10/199 [00:08<01:22,  2.30it/s]  6%|▌         | 11/199 [00:09<02:19,  1.35it/s]  6%|▌         | 12/199 [00:09<01:46,  1.75it/s]  7%|▋         | 13/199 [00:09<01:24,  2.21it/s]  7%|▋         | 14/199 [00:10<01:08,  2.70it/s]  8%|▊         | 15/199 [00:10<00:57,  3.18it/s]  8%|▊         | 16/199 [00:10<00:50,  3.64it/s]  9%|▊         | 17/199 [00:10<00:44,  4.05it/s]  9%|▉         | 18/199 [00:10<00:41,  4.40it/s] 10%|▉         | 19/199 [00:11<01:17,  2.31it/s] 10%|█         | 20/199 [00:11<01:03,  2.80it/s] 11%|█         | 21/199 [00:12<00:54,  3.28it/s] 11%|█         | 22/199 [00:12<00:47,  3.73it/s] 12%|█▏        | 23/199 [00:12<00:42,  4.13it/s] 12%|█▏        | 24/199 [00:12<00:39,  4.47it/s] 13%|█▎        | 25/199 [00:13<01:15,  2.31it/s] 13%|█▎        | 26/199 [00:13<01:01,  2.80it/s] 14%|█▎        | 27/199 [00:15<01:58,  1.45it/s] 14%|█▍        | 28/199 [00:15<01:31,  1.86it/s] 15%|█▍        | 29/199 [00:15<01:13,  2.32it/s] 15%|█▌        | 30/199 [00:15<01:00,  2.81it/s] 16%|█▌        | 31/199 [00:15<00:50,  3.30it/s] 16%|█▌        | 32/199 [00:16<00:44,  3.76it/s] 17%|█▋        | 33/199 [00:16<00:39,  4.16it/s] 17%|█▋        | 34/199 [00:16<00:36,  4.49it/s] 18%|█▊        | 35/199 [00:18<01:49,  1.50it/s] 18%|█▊        | 36/199 [00:18<01:34,  1.73it/s] 19%|█▊        | 37/199 [00:19<01:29,  1.80it/s] 19%|█▉        | 38/199 [00:19<01:11,  2.26it/s] 20%|█▉        | 39/199 [00:19<00:58,  2.75it/s] 20%|██        | 40/199 [00:19<00:49,  3.24it/s] 21%|██        | 41/199 [00:19<00:42,  3.71it/s] 21%|██        | 42/199 [00:19<00:38,  4.11it/s] 22%|██▏       | 43/199 [00:23<03:02,  1.17s/it] 22%|██▏       | 44/199 [00:24<03:22,  1.31s/it] 23%|██▎       | 45/199 [00:25<02:29,  1.03it/s] 23%|██▎       | 46/199 [00:25<01:52,  1.36it/s] 24%|██▎       | 47/199 [00:25<01:26,  1.76it/s] 24%|██▍       | 48/199 [00:25<01:08,  2.22it/s] 25%|██▍       | 49/199 [00:25<00:55,  2.70it/s] 25%|██▌       | 50/199 [00:25<00:46,  3.18it/s] 26%|██▌       | 51/199 [00:26<01:12,  2.04it/s] 26%|██▌       | 52/199 [00:28<01:50,  1.33it/s] 27%|██▋       | 53/199 [00:28<01:24,  1.73it/s] 27%|██▋       | 54/199 [00:28<01:06,  2.18it/s] 28%|██▊       | 55/199 [00:28<00:54,  2.66it/s] 28%|██▊       | 56/199 [00:28<00:45,  3.15it/s] 29%|██▊       | 57/199 [00:29<00:39,  3.61it/s] 29%|██▉       | 58/199 [00:29<00:34,  4.03it/s] 30%|██▉       | 59/199 [00:29<00:31,  4.39it/s] 30%|███       | 60/199 [00:31<01:56,  1.19it/s] 31%|███       | 61/199 [00:31<01:28,  1.56it/s] 31%|███       | 62/199 [00:32<01:08,  1.99it/s] 32%|███▏      | 63/199 [00:32<00:55,  2.46it/s] 32%|███▏      | 64/199 [00:32<00:45,  2.95it/s] 33%|███▎      | 65/199 [00:32<00:38,  3.44it/s] 33%|███▎      | 66/199 [00:32<00:34,  3.88it/s] 34%|███▎      | 67/199 [00:33<00:30,  4.26it/s] 34%|███▍      | 68/199 [00:35<02:07,  1.03it/s] 35%|███▍      | 69/199 [00:35<01:35,  1.36it/s] 35%|███▌      | 70/199 [00:36<01:13,  1.76it/s] 36%|███▌      | 71/199 [00:36<00:57,  2.21it/s] 36%|███▌      | 72/199 [00:36<00:47,  2.70it/s] 37%|███▋      | 73/199 [00:36<00:39,  3.19it/s] 37%|███▋      | 74/199 [00:36<00:34,  3.65it/s] 38%|███▊      | 75/199 [00:36<00:30,  4.06it/s] 38%|███▊      | 76/199 [00:37<00:50,  2.43it/s] 39%|███▊      | 77/199 [00:37<00:41,  2.91it/s] 39%|███▉      | 78/199 [00:38<00:35,  3.39it/s] 40%|███▉      | 79/199 [00:38<00:31,  3.83it/s] 40%|████      | 80/199 [00:38<00:28,  4.21it/s] 41%|████      | 81/199 [00:38<00:26,  4.53it/s] 41%|████      | 82/199 [00:38<00:24,  4.79it/s] 42%|████▏     | 83/199 [00:39<00:27,  4.29it/s] 42%|████▏     | 84/199 [00:40<01:04,  1.78it/s] 43%|████▎     | 85/199 [00:40<00:50,  2.24it/s] 43%|████▎     | 86/199 [00:40<00:41,  2.72it/s] 44%|████▎     | 87/199 [00:41<00:34,  3.21it/s] 44%|████▍     | 88/199 [00:41<00:30,  3.67it/s] 45%|████▍     | 89/199 [00:41<00:26,  4.08it/s] 45%|████▌     | 90/199 [00:43<01:15,  1.44it/s] 46%|████▌     | 91/199 [00:43<00:58,  1.84it/s] 46%|████▌     | 92/199 [00:45<01:55,  1.08s/it] 47%|████▋     | 93/199 [00:45<01:25,  1.24it/s] 47%|████▋     | 94/199 [00:46<01:05,  1.61it/s] 48%|████▊     | 95/199 [00:46<00:50,  2.05it/s] 48%|████▊     | 96/199 [00:46<00:40,  2.52it/s] 49%|████▊     | 97/199 [00:46<00:33,  3.01it/s] 49%|████▉     | 98/199 [00:46<00:28,  3.49it/s] 50%|████▉     | 99/199 [00:46<00:25,  3.92it/s] 50%|█████     | 100/199 [00:50<01:52,  1.13s/it] 51%|█████     | 101/199 [00:50<01:22,  1.18it/s] 51%|█████▏    | 102/199 [00:50<01:02,  1.55it/s] 52%|█████▏    | 103/199 [00:50<00:48,  1.97it/s] 52%|█████▏    | 104/199 [00:50<00:38,  2.45it/s] 53%|█████▎    | 105/199 [00:50<00:31,  2.94it/s] 53%|█████▎    | 106/199 [00:51<00:27,  3.42it/s] 54%|█████▍    | 107/199 [00:51<00:23,  3.86it/s] 54%|█████▍    | 108/199 [00:54<01:41,  1.12s/it] 55%|█████▍    | 109/199 [00:54<01:15,  1.20it/s] 55%|█████▌    | 110/199 [00:54<00:56,  1.57it/s] 56%|█████▌    | 111/199 [00:55<00:44,  1.99it/s] 56%|█████▋    | 112/199 [00:55<00:35,  2.47it/s] 57%|█████▋    | 113/199 [00:55<00:29,  2.96it/s] 57%|█████▋    | 114/199 [00:55<00:24,  3.43it/s] 58%|█████▊    | 115/199 [00:55<00:21,  3.87it/s] 58%|█████▊    | 116/199 [00:58<01:11,  1.16it/s] 59%|█████▉    | 117/199 [00:58<00:54,  1.51it/s] 59%|█████▉    | 118/199 [00:58<00:41,  1.94it/s] 60%|█████▉    | 119/199 [00:58<00:33,  2.41it/s] 60%|██████    | 120/199 [00:58<00:27,  2.90it/s] 61%|██████    | 121/199 [00:58<00:23,  3.37it/s] 61%|██████▏   | 122/199 [00:59<00:20,  3.81it/s] 62%|██████▏   | 123/199 [00:59<00:18,  4.20it/s] 62%|██████▏   | 124/199 [01:01<00:55,  1.35it/s] 63%|██████▎   | 125/199 [01:01<00:42,  1.74it/s] 63%|██████▎   | 126/199 [01:01<00:33,  2.20it/s] 64%|██████▍   | 127/199 [01:01<00:26,  2.68it/s] 64%|██████▍   | 128/199 [01:01<00:22,  3.17it/s] 65%|██████▍   | 129/199 [01:02<00:19,  3.63it/s] 65%|██████▌   | 130/199 [01:02<00:17,  4.05it/s] 66%|██████▌   | 131/199 [01:02<00:15,  4.40it/s] 66%|██████▋   | 132/199 [01:03<00:36,  1.81it/s] 67%|██████▋   | 133/199 [01:03<00:29,  2.27it/s] 67%|██████▋   | 134/199 [01:04<00:23,  2.76it/s] 68%|██████▊   | 135/199 [01:04<00:19,  3.24it/s] 68%|██████▊   | 136/199 [01:04<00:17,  3.70it/s] 69%|██████▉   | 137/199 [01:04<00:15,  4.10it/s] 69%|██████▉   | 138/199 [01:04<00:13,  4.44it/s] 70%|██████▉   | 139/199 [01:05<00:12,  4.72it/s] 70%|███████   | 140/199 [01:07<00:49,  1.19it/s] 71%|███████   | 141/199 [01:07<00:37,  1.56it/s] 71%|███████▏  | 142/199 [01:07<00:28,  1.98it/s] 72%|███████▏  | 143/199 [01:07<00:22,  2.46it/s] 72%|███████▏  | 144/199 [01:08<00:18,  2.95it/s] 73%|███████▎  | 145/199 [01:08<00:15,  3.43it/s] 73%|███████▎  | 146/199 [01:08<00:17,  3.09it/s] 74%|███████▍  | 147/199 [01:08<00:14,  3.54it/s] 74%|███████▍  | 148/199 [01:09<00:22,  2.30it/s] 75%|███████▍  | 149/199 [01:09<00:17,  2.79it/s] 75%|███████▌  | 150/199 [01:09<00:14,  3.27it/s] 76%|███████▌  | 151/199 [01:10<00:12,  3.73it/s] 76%|███████▋  | 152/199 [01:10<00:11,  4.13it/s] 77%|███████▋  | 153/199 [01:10<00:10,  4.47it/s] 77%|███████▋  | 154/199 [01:12<00:36,  1.23it/s] 78%|███████▊  | 155/199 [01:12<00:27,  1.61it/s] 78%|███████▊  | 156/199 [01:14<00:38,  1.11it/s] 79%|███████▉  | 157/199 [01:14<00:28,  1.45it/s] 79%|███████▉  | 158/199 [01:14<00:21,  1.87it/s] 80%|███████▉  | 159/199 [01:15<00:17,  2.33it/s] 80%|████████  | 160/199 [01:15<00:13,  2.82it/s] 81%|████████  | 161/199 [01:15<00:11,  3.30it/s] 81%|████████▏ | 162/199 [01:15<00:09,  3.75it/s] 82%|████████▏ | 163/199 [01:15<00:08,  4.14it/s] 82%|████████▏ | 164/199 [01:16<00:14,  2.43it/s] 83%|████████▎ | 165/199 [01:16<00:11,  2.92it/s] 83%|████████▎ | 166/199 [01:16<00:09,  3.40it/s] 84%|████████▍ | 167/199 [01:17<00:08,  3.84it/s] 84%|████████▍ | 168/199 [01:17<00:07,  4.22it/s] 85%|████████▍ | 169/199 [01:17<00:06,  4.53it/s] 85%|████████▌ | 170/199 [01:17<00:06,  4.77it/s] 86%|████████▌ | 171/199 [01:17<00:05,  4.97it/s] 86%|████████▋ | 172/199 [01:20<00:24,  1.09it/s] 87%|████████▋ | 173/199 [01:20<00:18,  1.43it/s] 87%|████████▋ | 174/199 [01:20<00:13,  1.84it/s] 88%|████████▊ | 175/199 [01:20<00:10,  2.30it/s] 88%|████████▊ | 176/199 [01:21<00:08,  2.79it/s] 89%|████████▉ | 177/199 [01:21<00:06,  3.28it/s] 89%|████████▉ | 178/199 [01:21<00:05,  3.73it/s] 90%|████████▉ | 179/199 [01:21<00:04,  4.14it/s] 90%|█████████ | 180/199 [01:22<00:10,  1.85it/s] 91%|█████████ | 181/199 [01:23<00:07,  2.31it/s] 91%|█████████▏| 182/199 [01:23<00:06,  2.80it/s] 92%|█████████▏| 183/199 [01:23<00:04,  3.28it/s] 92%|█████████▏| 184/199 [01:23<00:04,  3.73it/s] 93%|█████████▎| 185/199 [01:23<00:03,  4.13it/s] 93%|█████████▎| 186/199 [01:23<00:02,  4.47it/s] 94%|█████████▍| 187/199 [01:24<00:02,  4.74it/s] 94%|█████████▍| 188/199 [01:24<00:02,  4.96it/s] 95%|█████████▍| 189/199 [01:24<00:02,  3.97it/s] 95%|█████████▌| 190/199 [01:26<00:05,  1.71it/s] 96%|█████████▌| 191/199 [01:26<00:03,  2.16it/s] 96%|█████████▋| 192/199 [01:26<00:02,  2.64it/s] 97%|█████████▋| 193/199 [01:26<00:01,  3.14it/s] 97%|█████████▋| 194/199 [01:26<00:01,  3.61it/s] 98%|█████████▊| 195/199 [01:26<00:00,  4.04it/s] 98%|█████████▊| 196/199 [01:27<00:00,  3.05it/s] 99%|█████████▉| 197/199 [01:27<00:00,  3.53it/s] 99%|█████████▉| 198/199 [01:29<00:00,  1.12it/s]100%|██████████| 199/199 [01:30<00:00,  1.51it/s]100%|██████████| 199/199 [01:30<00:00,  2.21it/s]
=> result
* total: 19,850
* correct: 6,253
* accuracy: 31.5%
* error: 68.5%
* macro_f1: 25.5%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers sun397 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/sun397/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/sun397/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_2.pkl
6352 3970 19850
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  397
# train_x  6,352
# val      3,970
# test     19,850
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/199 [00:00<?, ?it/s]  1%|          | 1/199 [00:05<18:09,  5.50s/it]  1%|          | 2/199 [00:05<07:47,  2.37s/it]  2%|▏         | 3/199 [00:05<04:28,  1.37s/it]  2%|▏         | 4/199 [00:06<02:55,  1.11it/s]  3%|▎         | 5/199 [00:06<02:04,  1.56it/s]  3%|▎         | 6/199 [00:06<01:33,  2.06it/s]  4%|▎         | 7/199 [00:06<01:14,  2.59it/s]  4%|▍         | 8/199 [00:07<01:17,  2.46it/s]  5%|▍         | 9/199 [00:08<02:33,  1.24it/s]  5%|▌         | 10/199 [00:08<01:56,  1.63it/s]  6%|▌         | 11/199 [00:10<02:34,  1.22it/s]  6%|▌         | 12/199 [00:10<01:57,  1.60it/s]  7%|▋         | 13/199 [00:10<01:31,  2.03it/s]  7%|▋         | 14/199 [00:10<01:13,  2.50it/s]  8%|▊         | 15/199 [00:10<01:01,  3.00it/s]  8%|▊         | 16/199 [00:11<00:52,  3.48it/s]  9%|▊         | 17/199 [00:11<00:56,  3.21it/s]  9%|▉         | 18/199 [00:11<00:49,  3.68it/s] 10%|▉         | 19/199 [00:12<01:15,  2.38it/s] 10%|█         | 20/199 [00:12<01:02,  2.88it/s] 11%|█         | 21/199 [00:12<00:52,  3.36it/s] 11%|█         | 22/199 [00:12<00:46,  3.81it/s] 12%|█▏        | 23/199 [00:13<00:41,  4.20it/s] 12%|█▏        | 24/199 [00:13<00:38,  4.52it/s] 13%|█▎        | 25/199 [00:14<01:15,  2.30it/s] 13%|█▎        | 26/199 [00:14<01:01,  2.79it/s] 14%|█▎        | 27/199 [00:15<02:02,  1.40it/s] 14%|█▍        | 28/199 [00:16<01:34,  1.81it/s] 15%|█▍        | 29/199 [00:16<01:15,  2.26it/s] 15%|█▌        | 30/199 [00:16<01:01,  2.75it/s] 16%|█▌        | 31/199 [00:16<00:51,  3.23it/s] 16%|█▌        | 32/199 [00:16<00:45,  3.69it/s] 17%|█▋        | 33/199 [00:17<00:40,  4.10it/s] 17%|█▋        | 34/199 [00:17<00:37,  4.45it/s] 18%|█▊        | 35/199 [00:18<01:29,  1.84it/s] 18%|█▊        | 36/199 [00:18<01:10,  2.30it/s] 19%|█▊        | 37/199 [00:18<00:58,  2.78it/s] 19%|█▉        | 38/199 [00:19<00:49,  3.26it/s] 20%|█▉        | 39/199 [00:19<00:43,  3.72it/s] 20%|██        | 40/199 [00:19<00:38,  4.12it/s] 21%|██        | 41/199 [00:19<00:35,  4.46it/s] 21%|██        | 42/199 [00:19<00:33,  4.73it/s] 22%|██▏       | 43/199 [00:21<01:34,  1.65it/s] 22%|██▏       | 44/199 [00:21<01:14,  2.09it/s] 23%|██▎       | 45/199 [00:21<00:59,  2.57it/s] 23%|██▎       | 46/199 [00:21<00:49,  3.06it/s] 24%|██▎       | 47/199 [00:22<00:43,  3.53it/s] 24%|██▍       | 48/199 [00:22<00:38,  3.97it/s] 25%|██▍       | 49/199 [00:22<00:34,  4.33it/s] 25%|██▌       | 50/199 [00:22<00:32,  4.64it/s] 26%|██▌       | 51/199 [00:24<01:44,  1.42it/s] 26%|██▌       | 52/199 [00:24<01:20,  1.83it/s] 27%|██▋       | 53/199 [00:24<01:03,  2.29it/s] 27%|██▋       | 54/199 [00:24<00:52,  2.78it/s] 28%|██▊       | 55/199 [00:25<00:44,  3.27it/s] 28%|██▊       | 56/199 [00:25<00:38,  3.72it/s] 29%|██▊       | 57/199 [00:25<00:34,  4.13it/s] 29%|██▉       | 58/199 [00:26<01:17,  1.81it/s] 30%|██▉       | 59/199 [00:26<01:01,  2.26it/s] 30%|███       | 60/199 [00:27<00:59,  2.33it/s] 31%|███       | 61/199 [00:27<00:49,  2.81it/s] 31%|███       | 62/199 [00:27<00:41,  3.30it/s] 32%|███▏      | 63/199 [00:27<00:36,  3.75it/s] 32%|███▏      | 64/199 [00:28<00:32,  4.14it/s] 33%|███▎      | 65/199 [00:28<00:29,  4.48it/s] 33%|███▎      | 66/199 [00:30<01:40,  1.32it/s] 34%|███▎      | 67/199 [00:30<01:17,  1.71it/s] 34%|███▍      | 68/199 [00:31<01:27,  1.50it/s] 35%|███▍      | 69/199 [00:31<01:07,  1.92it/s] 35%|███▌      | 70/199 [00:31<00:54,  2.39it/s] 36%|███▌      | 71/199 [00:31<00:44,  2.88it/s] 36%|███▌      | 72/199 [00:32<00:37,  3.36it/s] 37%|███▋      | 73/199 [00:32<00:33,  3.80it/s] 37%|███▋      | 74/199 [00:33<01:21,  1.53it/s] 38%|███▊      | 75/199 [00:34<01:03,  1.96it/s] 38%|███▊      | 76/199 [00:34<00:50,  2.43it/s] 39%|███▊      | 77/199 [00:34<00:41,  2.92it/s] 39%|███▉      | 78/199 [00:34<00:35,  3.40it/s] 40%|███▉      | 79/199 [00:34<00:31,  3.85it/s] 40%|████      | 80/199 [00:34<00:28,  4.23it/s] 41%|████      | 81/199 [00:35<00:25,  4.55it/s] 41%|████      | 82/199 [00:36<01:24,  1.39it/s] 42%|████▏     | 83/199 [00:37<01:04,  1.79it/s] 42%|████▏     | 84/199 [00:37<00:51,  2.24it/s] 43%|████▎     | 85/199 [00:37<00:41,  2.73it/s] 43%|████▎     | 86/199 [00:37<00:35,  3.21it/s] 44%|████▎     | 87/199 [00:37<00:30,  3.67it/s] 44%|████▍     | 88/199 [00:38<00:27,  4.08it/s] 45%|████▍     | 89/199 [00:38<00:24,  4.43it/s] 45%|████▌     | 90/199 [00:42<02:23,  1.32s/it] 46%|████▌     | 91/199 [00:42<01:45,  1.02it/s] 46%|████▌     | 92/199 [00:42<01:18,  1.36it/s] 47%|████▋     | 93/199 [00:42<01:00,  1.75it/s] 47%|████▋     | 94/199 [00:42<00:47,  2.21it/s] 48%|████▊     | 95/199 [00:43<00:38,  2.69it/s] 48%|████▊     | 96/199 [00:43<00:32,  3.18it/s] 49%|████▊     | 97/199 [00:43<00:28,  3.64it/s] 49%|████▉     | 98/199 [00:44<00:56,  1.79it/s] 50%|████▉     | 99/199 [00:44<00:44,  2.24it/s] 50%|█████     | 100/199 [00:44<00:36,  2.73it/s] 51%|█████     | 101/199 [00:45<00:30,  3.22it/s] 51%|█████▏    | 102/199 [00:45<00:26,  3.68it/s] 52%|█████▏    | 103/199 [00:45<00:23,  4.08it/s] 52%|█████▏    | 104/199 [00:45<00:21,  4.43it/s] 53%|█████▎    | 105/199 [00:45<00:19,  4.70it/s] 53%|█████▎    | 106/199 [00:48<01:24,  1.10it/s] 54%|█████▍    | 107/199 [00:48<01:03,  1.45it/s] 54%|█████▍    | 108/199 [00:49<00:58,  1.56it/s] 55%|█████▍    | 109/199 [00:49<00:45,  1.99it/s] 55%|█████▌    | 110/199 [00:49<00:36,  2.45it/s] 56%|█████▌    | 111/199 [00:49<00:29,  2.94it/s] 56%|█████▋    | 112/199 [00:49<00:25,  3.42it/s] 57%|█████▋    | 113/199 [00:50<00:22,  3.85it/s] 57%|█████▋    | 114/199 [00:51<00:56,  1.51it/s] 58%|█████▊    | 115/199 [00:51<00:43,  1.93it/s] 58%|█████▊    | 116/199 [00:52<00:48,  1.71it/s] 59%|█████▉    | 117/199 [00:52<00:37,  2.16it/s] 59%|█████▉    | 118/199 [00:52<00:30,  2.64it/s] 60%|█████▉    | 119/199 [00:53<00:25,  3.13it/s] 60%|██████    | 120/199 [00:53<00:22,  3.59it/s] 61%|██████    | 121/199 [00:53<00:19,  4.01it/s] 61%|██████▏   | 122/199 [00:56<01:15,  1.02it/s] 62%|██████▏   | 123/199 [00:56<00:56,  1.34it/s] 62%|██████▏   | 124/199 [00:56<00:43,  1.74it/s] 63%|██████▎   | 125/199 [00:56<00:33,  2.19it/s] 63%|██████▎   | 126/199 [00:56<00:27,  2.67it/s] 64%|██████▍   | 127/199 [00:57<00:22,  3.17it/s] 64%|██████▍   | 128/199 [00:57<00:19,  3.63it/s] 65%|██████▍   | 129/199 [00:57<00:17,  4.04it/s] 65%|██████▌   | 130/199 [00:58<00:36,  1.91it/s] 66%|██████▌   | 131/199 [00:58<00:28,  2.37it/s] 66%|██████▋   | 132/199 [00:58<00:23,  2.86it/s] 67%|██████▋   | 133/199 [00:59<00:19,  3.34it/s] 67%|██████▋   | 134/199 [00:59<00:17,  3.79it/s] 68%|██████▊   | 135/199 [00:59<00:15,  4.18it/s] 68%|██████▊   | 136/199 [00:59<00:13,  4.51it/s] 69%|██████▉   | 137/199 [00:59<00:12,  4.77it/s] 69%|██████▉   | 138/199 [01:03<01:08,  1.12s/it] 70%|██████▉   | 139/199 [01:03<00:50,  1.19it/s] 70%|███████   | 140/199 [01:03<00:37,  1.56it/s] 71%|███████   | 141/199 [01:03<00:29,  1.99it/s] 71%|███████▏  | 142/199 [01:03<00:23,  2.47it/s] 72%|███████▏  | 143/199 [01:03<00:18,  2.96it/s] 72%|███████▏  | 144/199 [01:04<00:16,  3.43it/s] 73%|███████▎  | 145/199 [01:04<00:13,  3.87it/s] 73%|███████▎  | 146/199 [01:06<00:43,  1.21it/s] 74%|███████▍  | 147/199 [01:06<00:33,  1.57it/s] 74%|███████▍  | 148/199 [01:06<00:25,  2.00it/s] 75%|███████▍  | 149/199 [01:07<00:20,  2.48it/s] 75%|███████▌  | 150/199 [01:07<00:16,  2.97it/s] 76%|███████▌  | 151/199 [01:07<00:13,  3.44it/s] 76%|███████▋  | 152/199 [01:07<00:12,  3.87it/s] 77%|███████▋  | 153/199 [01:07<00:10,  4.25it/s] 77%|███████▋  | 154/199 [01:10<00:41,  1.08it/s] 78%|███████▊  | 155/199 [01:10<00:30,  1.43it/s] 78%|███████▊  | 156/199 [01:10<00:23,  1.84it/s] 79%|███████▉  | 157/199 [01:10<00:18,  2.30it/s] 79%|███████▉  | 158/199 [01:11<00:14,  2.78it/s] 80%|███████▉  | 159/199 [01:11<00:12,  3.27it/s] 80%|████████  | 160/199 [01:11<00:10,  3.72it/s] 81%|████████  | 161/199 [01:11<00:09,  4.12it/s] 81%|████████▏ | 162/199 [01:12<00:13,  2.75it/s] 82%|████████▏ | 163/199 [01:12<00:11,  3.24it/s] 82%|████████▏ | 164/199 [01:12<00:09,  3.69it/s] 83%|████████▎ | 165/199 [01:12<00:08,  4.10it/s] 83%|████████▎ | 166/199 [01:12<00:07,  4.43it/s] 84%|████████▍ | 167/199 [01:13<00:06,  4.70it/s] 84%|████████▍ | 168/199 [01:13<00:06,  4.91it/s] 85%|████████▍ | 169/199 [01:13<00:05,  5.06it/s] 85%|████████▌ | 170/199 [01:13<00:07,  4.03it/s] 86%|████████▌ | 171/199 [01:14<00:06,  4.38it/s] 86%|████████▋ | 172/199 [01:14<00:05,  4.66it/s] 87%|████████▋ | 173/199 [01:14<00:05,  4.88it/s] 87%|████████▋ | 174/199 [01:14<00:04,  5.05it/s] 88%|████████▊ | 175/199 [01:14<00:04,  5.17it/s] 88%|████████▊ | 176/199 [01:15<00:05,  4.31it/s] 89%|████████▉ | 177/199 [01:15<00:04,  4.61it/s] 89%|████████▉ | 178/199 [01:16<00:10,  1.98it/s] 90%|████████▉ | 179/199 [01:16<00:08,  2.45it/s] 90%|█████████ | 180/199 [01:16<00:06,  2.93it/s] 91%|█████████ | 181/199 [01:17<00:05,  3.41it/s] 91%|█████████▏| 182/199 [01:17<00:04,  3.85it/s] 92%|█████████▏| 183/199 [01:17<00:06,  2.63it/s] 92%|█████████▏| 184/199 [01:18<00:04,  3.11it/s] 93%|█████████▎| 185/199 [01:18<00:03,  3.57it/s] 93%|█████████▎| 186/199 [01:19<00:08,  1.57it/s] 94%|█████████▍| 187/199 [01:19<00:05,  2.00it/s] 94%|█████████▍| 188/199 [01:20<00:04,  2.48it/s] 95%|█████████▍| 189/199 [01:20<00:03,  2.97it/s] 95%|█████████▌| 190/199 [01:20<00:02,  3.30it/s] 96%|█████████▌| 191/199 [01:20<00:02,  3.19it/s] 96%|█████████▋| 192/199 [01:20<00:01,  3.66it/s] 97%|█████████▋| 193/199 [01:21<00:01,  4.07it/s] 97%|█████████▋| 194/199 [01:22<00:02,  1.94it/s] 98%|█████████▊| 195/199 [01:22<00:01,  2.41it/s] 98%|█████████▊| 196/199 [01:22<00:01,  2.90it/s] 99%|█████████▉| 197/199 [01:22<00:00,  3.39it/s] 99%|█████████▉| 198/199 [01:24<00:00,  1.60it/s]100%|██████████| 199/199 [01:24<00:00,  2.10it/s]100%|██████████| 199/199 [01:24<00:00,  2.36it/s]
=> result
* total: 19,850
* correct: 6,239
* accuracy: 31.4%
* error: 68.6%
* macro_f1: 25.3%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers sun397 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/sun397/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/sun397/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_3.pkl
6352 3970 19850
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  397
# train_x  6,352
# val      3,970
# test     19,850
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/199 [00:00<?, ?it/s]  1%|          | 1/199 [00:05<18:28,  5.60s/it]  1%|          | 2/199 [00:05<07:55,  2.41s/it]  2%|▏         | 3/199 [00:05<04:33,  1.39s/it]  2%|▏         | 4/199 [00:06<02:58,  1.09it/s]  3%|▎         | 5/199 [00:06<02:05,  1.54it/s]  3%|▎         | 6/199 [00:06<01:34,  2.04it/s]  4%|▎         | 7/199 [00:06<01:14,  2.57it/s]  4%|▍         | 8/199 [00:06<01:01,  3.11it/s]  5%|▍         | 9/199 [00:07<01:46,  1.78it/s]  5%|▌         | 10/199 [00:08<01:38,  1.93it/s]  6%|▌         | 11/199 [00:09<02:40,  1.17it/s]  6%|▌         | 12/199 [00:10<02:01,  1.54it/s]  7%|▋         | 13/199 [00:10<01:34,  1.97it/s]  7%|▋         | 14/199 [00:10<01:15,  2.45it/s]  8%|▊         | 15/199 [00:10<01:02,  2.94it/s]  8%|▊         | 16/199 [00:10<00:53,  3.42it/s]  9%|▊         | 17/199 [00:11<00:47,  3.86it/s]  9%|▉         | 18/199 [00:11<00:42,  4.24it/s] 10%|▉         | 19/199 [00:12<01:25,  2.10it/s] 10%|█         | 20/199 [00:12<01:09,  2.59it/s] 11%|█         | 21/199 [00:12<00:57,  3.08it/s] 11%|█         | 22/199 [00:12<00:49,  3.55it/s] 12%|█▏        | 23/199 [00:13<00:44,  3.98it/s] 12%|█▏        | 24/199 [00:13<00:40,  4.35it/s] 13%|█▎        | 25/199 [00:13<00:51,  3.39it/s] 13%|█▎        | 26/199 [00:13<00:45,  3.82it/s] 14%|█▎        | 27/199 [00:15<02:23,  1.20it/s] 14%|█▍        | 28/199 [00:16<01:49,  1.56it/s] 15%|█▍        | 29/199 [00:16<01:25,  1.99it/s] 15%|█▌        | 30/199 [00:16<01:08,  2.47it/s] 16%|█▌        | 31/199 [00:16<00:56,  2.96it/s] 16%|█▌        | 32/199 [00:16<00:48,  3.43it/s] 17%|█▋        | 33/199 [00:17<00:43,  3.85it/s] 17%|█▋        | 34/199 [00:17<00:38,  4.23it/s] 18%|█▊        | 35/199 [00:18<01:36,  1.70it/s] 18%|█▊        | 36/199 [00:18<01:16,  2.14it/s] 19%|█▊        | 37/199 [00:19<01:02,  2.58it/s] 19%|█▉        | 38/199 [00:19<00:52,  3.08it/s] 20%|█▉        | 39/199 [00:19<00:45,  3.55it/s] 20%|██        | 40/199 [00:19<00:39,  3.98it/s] 21%|██        | 41/199 [00:19<00:36,  4.35it/s] 21%|██        | 42/199 [00:19<00:33,  4.65it/s] 22%|██▏       | 43/199 [00:22<02:11,  1.19it/s] 22%|██▏       | 44/199 [00:22<01:39,  1.55it/s] 23%|██▎       | 45/199 [00:22<01:17,  1.98it/s] 23%|██▎       | 46/199 [00:22<01:02,  2.45it/s] 24%|██▎       | 47/199 [00:22<00:51,  2.94it/s] 24%|██▍       | 48/199 [00:23<00:44,  3.42it/s] 25%|██▍       | 49/199 [00:23<00:38,  3.86it/s] 25%|██▌       | 50/199 [00:23<00:35,  4.25it/s] 26%|██▌       | 51/199 [00:25<02:06,  1.17it/s] 26%|██▌       | 52/199 [00:26<01:36,  1.53it/s] 27%|██▋       | 53/199 [00:26<01:14,  1.95it/s] 27%|██▋       | 54/199 [00:26<00:59,  2.42it/s] 28%|██▊       | 55/199 [00:26<00:49,  2.91it/s] 28%|██▊       | 56/199 [00:26<00:42,  3.40it/s] 29%|██▊       | 57/199 [00:26<00:37,  3.84it/s] 29%|██▉       | 58/199 [00:27<00:42,  3.28it/s] 30%|██▉       | 59/199 [00:28<00:57,  2.42it/s] 30%|███       | 60/199 [00:28<01:18,  1.76it/s] 31%|███       | 61/199 [00:29<01:02,  2.21it/s] 31%|███       | 62/199 [00:29<00:50,  2.70it/s] 32%|███▏      | 63/199 [00:29<00:42,  3.19it/s] 32%|███▏      | 64/199 [00:29<00:36,  3.65it/s] 33%|███▎      | 65/199 [00:29<00:32,  4.07it/s] 33%|███▎      | 66/199 [00:30<01:06,  2.01it/s] 34%|███▎      | 67/199 [00:31<00:53,  2.48it/s] 34%|███▍      | 68/199 [00:32<01:39,  1.32it/s] 35%|███▍      | 69/199 [00:32<01:16,  1.71it/s] 35%|███▌      | 70/199 [00:33<00:59,  2.16it/s] 36%|███▌      | 71/199 [00:33<00:48,  2.64it/s] 36%|███▌      | 72/199 [00:33<00:40,  3.13it/s] 37%|███▋      | 73/199 [00:33<00:34,  3.60it/s] 37%|███▋      | 74/199 [00:34<00:48,  2.57it/s] 38%|███▊      | 75/199 [00:34<00:47,  2.59it/s] 38%|███▊      | 76/199 [00:34<00:39,  3.08it/s] 39%|███▊      | 77/199 [00:34<00:34,  3.55it/s] 39%|███▉      | 78/199 [00:35<00:30,  3.98it/s] 40%|███▉      | 79/199 [00:35<00:27,  4.35it/s] 40%|████      | 80/199 [00:35<00:25,  4.65it/s] 41%|████      | 81/199 [00:35<00:24,  4.88it/s] 41%|████      | 82/199 [00:37<01:13,  1.60it/s] 42%|████▏     | 83/199 [00:38<01:24,  1.37it/s] 42%|████▏     | 84/199 [00:38<01:05,  1.77it/s] 43%|████▎     | 85/199 [00:38<00:51,  2.22it/s] 43%|████▎     | 86/199 [00:38<00:41,  2.71it/s] 44%|████▎     | 87/199 [00:39<00:35,  3.20it/s] 44%|████▍     | 88/199 [00:39<00:30,  3.66it/s] 45%|████▍     | 89/199 [00:39<00:27,  4.07it/s] 45%|████▌     | 90/199 [00:42<01:59,  1.10s/it] 46%|████▌     | 91/199 [00:42<01:28,  1.22it/s] 46%|████▌     | 92/199 [00:42<01:07,  1.59it/s] 47%|████▋     | 93/199 [00:42<00:52,  2.03it/s] 47%|████▋     | 94/199 [00:43<00:41,  2.50it/s] 48%|████▊     | 95/199 [00:43<00:34,  3.00it/s] 48%|████▊     | 96/199 [00:43<00:29,  3.47it/s] 49%|████▊     | 97/199 [00:43<00:26,  3.91it/s] 49%|████▉     | 98/199 [00:44<00:54,  1.85it/s] 50%|████▉     | 99/199 [00:45<00:43,  2.31it/s] 50%|█████     | 100/199 [00:46<01:08,  1.45it/s] 51%|█████     | 101/199 [00:46<00:52,  1.86it/s] 51%|█████▏    | 102/199 [00:46<00:41,  2.32it/s] 52%|█████▏    | 103/199 [00:46<00:34,  2.81it/s] 52%|█████▏    | 104/199 [00:47<00:28,  3.30it/s] 53%|█████▎    | 105/199 [00:47<00:25,  3.75it/s] 53%|█████▎    | 106/199 [00:49<01:05,  1.41it/s] 54%|█████▍    | 107/199 [00:49<00:50,  1.82it/s] 54%|█████▍    | 108/199 [00:50<01:11,  1.28it/s] 55%|█████▍    | 109/199 [00:50<00:54,  1.66it/s] 55%|█████▌    | 110/199 [00:50<00:42,  2.10it/s] 56%|█████▌    | 111/199 [00:51<00:34,  2.58it/s] 56%|█████▋    | 112/199 [00:51<00:28,  3.08it/s] 57%|█████▋    | 113/199 [00:51<00:24,  3.55it/s] 57%|█████▋    | 114/199 [00:52<00:36,  2.36it/s] 58%|█████▊    | 115/199 [00:52<00:29,  2.85it/s] 58%|█████▊    | 116/199 [00:53<00:59,  1.40it/s] 59%|█████▉    | 117/199 [00:54<00:45,  1.81it/s] 59%|█████▉    | 118/199 [00:54<00:35,  2.26it/s] 60%|█████▉    | 119/199 [00:54<00:29,  2.75it/s] 60%|██████    | 120/199 [00:54<00:24,  3.24it/s] 61%|██████    | 121/199 [00:54<00:21,  3.69it/s] 61%|██████▏   | 122/199 [00:56<00:56,  1.37it/s] 62%|██████▏   | 123/199 [00:56<00:42,  1.77it/s] 62%|██████▏   | 124/199 [00:57<00:35,  2.14it/s] 63%|██████▎   | 125/199 [00:57<00:28,  2.62it/s] 63%|██████▎   | 126/199 [00:57<00:23,  3.11it/s] 64%|██████▍   | 127/199 [00:57<00:20,  3.58it/s] 64%|██████▍   | 128/199 [00:57<00:17,  4.00it/s] 65%|██████▍   | 129/199 [00:57<00:16,  4.35it/s] 65%|██████▌   | 130/199 [00:58<00:28,  2.42it/s] 66%|██████▌   | 131/199 [00:58<00:23,  2.90it/s] 66%|██████▋   | 132/199 [00:59<00:30,  2.18it/s] 67%|██████▋   | 133/199 [00:59<00:24,  2.66it/s] 67%|██████▋   | 134/199 [01:00<00:20,  3.14it/s] 68%|██████▊   | 135/199 [01:00<00:17,  3.60it/s] 68%|██████▊   | 136/199 [01:00<00:15,  4.02it/s] 69%|██████▉   | 137/199 [01:00<00:14,  4.37it/s] 69%|██████▉   | 138/199 [01:03<01:07,  1.10s/it] 70%|██████▉   | 139/199 [01:03<00:49,  1.21it/s] 70%|███████   | 140/199 [01:04<00:37,  1.58it/s] 71%|███████   | 141/199 [01:04<00:28,  2.01it/s] 71%|███████▏  | 142/199 [01:04<00:22,  2.49it/s] 72%|███████▏  | 143/199 [01:04<00:18,  2.98it/s] 72%|███████▏  | 144/199 [01:04<00:15,  3.46it/s] 73%|███████▎  | 145/199 [01:05<00:13,  3.90it/s] 73%|███████▎  | 146/199 [01:07<00:46,  1.14it/s] 74%|███████▍  | 147/199 [01:07<00:34,  1.49it/s] 74%|███████▍  | 148/199 [01:07<00:26,  1.91it/s] 75%|███████▍  | 149/199 [01:07<00:21,  2.38it/s] 75%|███████▌  | 150/199 [01:08<00:17,  2.87it/s] 76%|███████▌  | 151/199 [01:08<00:14,  3.35it/s] 76%|███████▋  | 152/199 [01:08<00:12,  3.80it/s] 77%|███████▋  | 153/199 [01:08<00:10,  4.19it/s] 77%|███████▋  | 154/199 [01:11<00:41,  1.08it/s] 78%|███████▊  | 155/199 [01:11<00:30,  1.43it/s] 78%|███████▊  | 156/199 [01:11<00:23,  1.84it/s] 79%|███████▉  | 157/199 [01:11<00:18,  2.30it/s] 79%|███████▉  | 158/199 [01:11<00:14,  2.79it/s] 80%|███████▉  | 159/199 [01:12<00:12,  3.27it/s] 80%|████████  | 160/199 [01:12<00:10,  3.73it/s] 81%|████████  | 161/199 [01:12<00:09,  4.13it/s] 81%|████████▏ | 162/199 [01:13<00:13,  2.72it/s] 82%|████████▏ | 163/199 [01:13<00:11,  3.20it/s] 82%|████████▏ | 164/199 [01:13<00:09,  3.67it/s] 83%|████████▎ | 165/199 [01:13<00:08,  4.08it/s] 83%|████████▎ | 166/199 [01:13<00:07,  4.43it/s] 84%|████████▍ | 167/199 [01:13<00:06,  4.69it/s] 84%|████████▍ | 168/199 [01:14<00:06,  4.91it/s] 85%|████████▍ | 169/199 [01:14<00:05,  5.08it/s] 85%|████████▌ | 170/199 [01:14<00:07,  4.04it/s] 86%|████████▌ | 171/199 [01:14<00:06,  4.39it/s] 86%|████████▋ | 172/199 [01:15<00:05,  4.68it/s] 87%|████████▋ | 173/199 [01:15<00:05,  4.90it/s] 87%|████████▋ | 174/199 [01:15<00:04,  5.07it/s] 88%|████████▊ | 175/199 [01:15<00:04,  5.20it/s] 88%|████████▊ | 176/199 [01:15<00:04,  5.30it/s] 89%|████████▉ | 177/199 [01:16<00:07,  3.09it/s] 89%|████████▉ | 178/199 [01:17<00:09,  2.10it/s] 90%|████████▉ | 179/199 [01:17<00:10,  1.90it/s] 90%|█████████ | 180/199 [01:18<00:08,  2.37it/s] 91%|█████████ | 181/199 [01:18<00:06,  2.85it/s] 91%|█████████▏| 182/199 [01:18<00:05,  3.33it/s] 92%|█████████▏| 183/199 [01:19<00:07,  2.20it/s] 92%|█████████▏| 184/199 [01:19<00:05,  2.69it/s] 93%|█████████▎| 185/199 [01:19<00:04,  3.17it/s] 93%|█████████▎| 186/199 [01:20<00:05,  2.20it/s] 94%|█████████▍| 187/199 [01:20<00:04,  2.51it/s] 94%|█████████▍| 188/199 [01:20<00:03,  3.00it/s] 95%|█████████▍| 189/199 [01:21<00:02,  3.47it/s] 95%|█████████▌| 190/199 [01:21<00:02,  3.12it/s] 96%|█████████▌| 191/199 [01:22<00:03,  2.22it/s] 96%|█████████▋| 192/199 [01:22<00:02,  2.71it/s] 97%|█████████▋| 193/199 [01:22<00:01,  3.20it/s] 97%|█████████▋| 194/199 [01:23<00:01,  2.84it/s] 98%|█████████▊| 195/199 [01:23<00:01,  2.19it/s] 98%|█████████▊| 196/199 [01:23<00:01,  2.68it/s] 99%|█████████▉| 197/199 [01:24<00:00,  3.17it/s] 99%|█████████▉| 198/199 [01:25<00:00,  1.77it/s]100%|██████████| 199/199 [01:25<00:00,  2.30it/s]100%|██████████| 199/199 [01:25<00:00,  2.33it/s]
=> result
* total: 19,850
* correct: 5,794
* accuracy: 29.2%
* error: 70.8%
* macro_f1: 23.9%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers dtd 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/dtd/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/dtd/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_1.pkl
752 1128 1692
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  47
# train_x  752
# val      1,128
# test     1,692
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:03<00:55,  3.47s/it] 12%|█▏        | 2/17 [00:03<00:22,  1.49s/it] 18%|█▊        | 3/17 [00:03<00:12,  1.16it/s] 24%|██▎       | 4/17 [00:03<00:07,  1.77it/s] 29%|██▉       | 5/17 [00:03<00:04,  2.49it/s] 35%|███▌      | 6/17 [00:04<00:03,  3.31it/s] 41%|████      | 7/17 [00:04<00:02,  4.18it/s] 47%|████▋     | 8/17 [00:04<00:01,  5.04it/s] 53%|█████▎    | 9/17 [00:04<00:01,  5.86it/s] 59%|█████▉    | 10/17 [00:04<00:01,  6.57it/s] 65%|██████▍   | 11/17 [00:04<00:00,  7.18it/s] 71%|███████   | 12/17 [00:04<00:00,  7.66it/s] 76%|███████▋  | 13/17 [00:04<00:00,  8.04it/s] 82%|████████▏ | 14/17 [00:04<00:00,  8.32it/s] 88%|████████▊ | 15/17 [00:05<00:00,  8.53it/s] 94%|█████████▍| 16/17 [00:05<00:00,  8.68it/s]100%|██████████| 17/17 [00:05<00:00,  8.97it/s]100%|██████████| 17/17 [00:05<00:00,  3.21it/s]
=> result
* total: 1,692
* correct: 426
* accuracy: 25.2%
* error: 74.8%
* macro_f1: 19.9%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers dtd 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/dtd/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/dtd/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_2.pkl
752 1128 1692
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  47
# train_x  752
# val      1,128
# test     1,692
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:03<00:53,  3.33s/it] 12%|█▏        | 2/17 [00:03<00:21,  1.44s/it] 18%|█▊        | 3/17 [00:03<00:11,  1.20it/s] 24%|██▎       | 4/17 [00:03<00:07,  1.83it/s] 29%|██▉       | 5/17 [00:03<00:04,  2.56it/s] 35%|███▌      | 6/17 [00:03<00:03,  3.39it/s] 41%|████      | 7/17 [00:03<00:02,  4.26it/s] 47%|████▋     | 8/17 [00:04<00:01,  5.12it/s] 53%|█████▎    | 9/17 [00:04<00:01,  5.92it/s] 59%|█████▉    | 10/17 [00:04<00:01,  6.63it/s] 65%|██████▍   | 11/17 [00:04<00:00,  7.18it/s] 71%|███████   | 12/17 [00:04<00:00,  7.67it/s] 76%|███████▋  | 13/17 [00:04<00:00,  8.05it/s] 82%|████████▏ | 14/17 [00:04<00:00,  8.33it/s] 88%|████████▊ | 15/17 [00:04<00:00,  8.54it/s] 94%|█████████▍| 16/17 [00:04<00:00,  8.69it/s]100%|██████████| 17/17 [00:05<00:00,  8.98it/s]100%|██████████| 17/17 [00:05<00:00,  3.27it/s]
=> result
* total: 1,692
* correct: 380
* accuracy: 22.5%
* error: 77.5%
* macro_f1: 17.7%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers dtd 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/dtd/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/dtd/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_3.pkl
752 1128 1692
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  47
# train_x  752
# val      1,128
# test     1,692
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:03<00:54,  3.42s/it] 12%|█▏        | 2/17 [00:03<00:22,  1.47s/it] 18%|█▊        | 3/17 [00:03<00:11,  1.17it/s] 24%|██▎       | 4/17 [00:03<00:07,  1.79it/s] 29%|██▉       | 5/17 [00:03<00:04,  2.52it/s] 35%|███▌      | 6/17 [00:03<00:03,  3.34it/s] 41%|████      | 7/17 [00:04<00:02,  4.20it/s] 47%|████▋     | 8/17 [00:04<00:01,  5.07it/s] 53%|█████▎    | 9/17 [00:04<00:01,  5.87it/s] 59%|█████▉    | 10/17 [00:04<00:01,  6.58it/s] 65%|██████▍   | 11/17 [00:04<00:00,  7.17it/s] 71%|███████   | 12/17 [00:04<00:00,  7.64it/s] 76%|███████▋  | 13/17 [00:04<00:00,  8.01it/s] 82%|████████▏ | 14/17 [00:04<00:00,  8.29it/s] 88%|████████▊ | 15/17 [00:04<00:00,  8.50it/s] 94%|█████████▍| 16/17 [00:05<00:00,  8.66it/s]100%|██████████| 17/17 [00:05<00:00,  8.95it/s]100%|██████████| 17/17 [00:05<00:00,  3.24it/s]
=> result
* total: 1,692
* correct: 401
* accuracy: 23.7%
* error: 76.3%
* macro_f1: 17.4%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers eurosat 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/eurosat/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/eurosat/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_1.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:02<03:51,  2.89s/it]  2%|▏         | 2/81 [00:02<01:38,  1.25s/it]  4%|▎         | 3/81 [00:03<00:56,  1.37it/s]  5%|▍         | 4/81 [00:03<00:37,  2.06it/s]  6%|▌         | 5/81 [00:03<00:26,  2.87it/s]  7%|▋         | 6/81 [00:03<00:19,  3.76it/s]  9%|▊         | 7/81 [00:03<00:15,  4.68it/s] 10%|▉         | 8/81 [00:03<00:13,  5.58it/s] 11%|█         | 9/81 [00:03<00:11,  6.38it/s] 12%|█▏        | 10/81 [00:03<00:10,  7.10it/s] 14%|█▎        | 11/81 [00:03<00:09,  7.67it/s] 15%|█▍        | 12/81 [00:04<00:08,  8.13it/s] 16%|█▌        | 13/81 [00:04<00:07,  8.50it/s] 17%|█▋        | 14/81 [00:04<00:07,  8.78it/s] 19%|█▊        | 15/81 [00:04<00:07,  8.97it/s] 20%|█▉        | 16/81 [00:04<00:07,  9.12it/s] 21%|██        | 17/81 [00:04<00:06,  9.21it/s] 22%|██▏       | 18/81 [00:04<00:06,  9.29it/s] 23%|██▎       | 19/81 [00:04<00:06,  9.34it/s] 25%|██▍       | 20/81 [00:04<00:06,  9.38it/s] 26%|██▌       | 21/81 [00:05<00:06,  9.39it/s] 27%|██▋       | 22/81 [00:05<00:06,  9.42it/s] 28%|██▊       | 23/81 [00:05<00:06,  9.43it/s] 30%|██▉       | 24/81 [00:05<00:06,  9.44it/s] 31%|███       | 25/81 [00:05<00:05,  9.44it/s] 32%|███▏      | 26/81 [00:05<00:05,  9.45it/s] 33%|███▎      | 27/81 [00:05<00:05,  9.45it/s] 35%|███▍      | 28/81 [00:05<00:05,  9.45it/s] 36%|███▌      | 29/81 [00:05<00:05,  9.43it/s] 37%|███▋      | 30/81 [00:05<00:05,  9.44it/s] 38%|███▊      | 31/81 [00:06<00:05,  9.43it/s] 40%|███▉      | 32/81 [00:06<00:05,  9.44it/s] 41%|████      | 33/81 [00:06<00:05,  9.44it/s] 42%|████▏     | 34/81 [00:06<00:04,  9.44it/s] 43%|████▎     | 35/81 [00:06<00:04,  9.44it/s] 44%|████▍     | 36/81 [00:06<00:04,  9.45it/s] 46%|████▌     | 37/81 [00:06<00:04,  9.44it/s] 47%|████▋     | 38/81 [00:06<00:04,  9.45it/s] 48%|████▊     | 39/81 [00:06<00:04,  9.39it/s] 49%|████▉     | 40/81 [00:07<00:04,  9.38it/s] 51%|█████     | 41/81 [00:07<00:04,  9.41it/s] 52%|█████▏    | 42/81 [00:07<00:04,  9.43it/s] 53%|█████▎    | 43/81 [00:07<00:04,  9.43it/s] 54%|█████▍    | 44/81 [00:07<00:03,  9.45it/s] 56%|█████▌    | 45/81 [00:07<00:03,  9.44it/s] 57%|█████▋    | 46/81 [00:07<00:03,  9.44it/s] 58%|█████▊    | 47/81 [00:07<00:03,  9.48it/s] 59%|█████▉    | 48/81 [00:07<00:03,  9.49it/s] 60%|██████    | 49/81 [00:07<00:03,  9.47it/s] 62%|██████▏   | 50/81 [00:08<00:03,  9.46it/s] 63%|██████▎   | 51/81 [00:08<00:03,  9.45it/s] 64%|██████▍   | 52/81 [00:08<00:03,  9.46it/s] 65%|██████▌   | 53/81 [00:08<00:02,  9.46it/s] 67%|██████▋   | 54/81 [00:08<00:02,  9.46it/s] 68%|██████▊   | 55/81 [00:08<00:02,  9.41it/s] 69%|██████▉   | 56/81 [00:08<00:02,  9.43it/s] 70%|███████   | 57/81 [00:08<00:02,  9.44it/s] 72%|███████▏  | 58/81 [00:08<00:02,  9.44it/s] 73%|███████▎  | 59/81 [00:09<00:02,  9.43it/s] 74%|███████▍  | 60/81 [00:09<00:02,  9.44it/s] 75%|███████▌  | 61/81 [00:09<00:02,  9.44it/s] 77%|███████▋  | 62/81 [00:09<00:02,  9.45it/s] 78%|███████▊  | 63/81 [00:09<00:01,  9.45it/s] 79%|███████▉  | 64/81 [00:09<00:01,  9.48it/s] 80%|████████  | 65/81 [00:09<00:01,  9.48it/s] 81%|████████▏ | 66/81 [00:09<00:01,  9.49it/s] 83%|████████▎ | 67/81 [00:09<00:01,  9.49it/s] 84%|████████▍ | 68/81 [00:09<00:01,  9.50it/s] 85%|████████▌ | 69/81 [00:10<00:01,  9.51it/s] 86%|████████▋ | 70/81 [00:10<00:01,  9.52it/s] 88%|████████▊ | 71/81 [00:10<00:01,  9.52it/s] 89%|████████▉ | 72/81 [00:10<00:00,  9.52it/s] 90%|█████████ | 73/81 [00:10<00:00,  9.52it/s] 91%|█████████▏| 74/81 [00:10<00:00,  9.52it/s] 93%|█████████▎| 75/81 [00:10<00:00,  9.53it/s] 94%|█████████▍| 76/81 [00:10<00:00,  9.54it/s] 95%|█████████▌| 77/81 [00:10<00:00,  9.53it/s] 96%|█████████▋| 78/81 [00:11<00:00,  9.52it/s] 98%|█████████▊| 79/81 [00:11<00:00,  9.52it/s] 99%|█████████▉| 80/81 [00:11<00:00,  9.53it/s]100%|██████████| 81/81 [00:11<00:00,  9.52it/s]100%|██████████| 81/81 [00:11<00:00,  7.10it/s]
=> result
* total: 8,100
* correct: 1,616
* accuracy: 20.0%
* error: 80.0%
* macro_f1: 14.4%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers eurosat 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/eurosat/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/eurosat/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_2.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:02<03:44,  2.80s/it]  2%|▏         | 2/81 [00:02<01:36,  1.22s/it]  4%|▎         | 3/81 [00:03<00:55,  1.41it/s]  5%|▍         | 4/81 [00:03<00:36,  2.12it/s]  6%|▌         | 5/81 [00:03<00:25,  2.94it/s]  7%|▋         | 6/81 [00:03<00:19,  3.84it/s]  9%|▊         | 7/81 [00:03<00:15,  4.76it/s] 10%|▉         | 8/81 [00:03<00:12,  5.66it/s] 11%|█         | 9/81 [00:03<00:11,  6.46it/s] 12%|█▏        | 10/81 [00:03<00:09,  7.15it/s] 14%|█▎        | 11/81 [00:03<00:09,  7.71it/s] 15%|█▍        | 12/81 [00:03<00:08,  8.16it/s] 16%|█▌        | 13/81 [00:04<00:08,  8.50it/s] 17%|█▋        | 14/81 [00:04<00:07,  8.75it/s] 19%|█▊        | 15/81 [00:04<00:07,  8.94it/s] 20%|█▉        | 16/81 [00:04<00:07,  9.07it/s] 21%|██        | 17/81 [00:04<00:06,  9.17it/s] 22%|██▏       | 18/81 [00:04<00:06,  9.24it/s] 23%|██▎       | 19/81 [00:04<00:06,  9.30it/s] 25%|██▍       | 20/81 [00:04<00:06,  9.36it/s] 26%|██▌       | 21/81 [00:04<00:06,  9.39it/s] 27%|██▋       | 22/81 [00:05<00:06,  9.41it/s] 28%|██▊       | 23/81 [00:05<00:06,  9.42it/s] 30%|██▉       | 24/81 [00:05<00:06,  9.43it/s] 31%|███       | 25/81 [00:05<00:05,  9.43it/s] 32%|███▏      | 26/81 [00:05<00:05,  9.43it/s] 33%|███▎      | 27/81 [00:05<00:05,  9.44it/s] 35%|███▍      | 28/81 [00:05<00:05,  9.43it/s] 36%|███▌      | 29/81 [00:05<00:05,  9.41it/s] 37%|███▋      | 30/81 [00:05<00:05,  9.43it/s] 38%|███▊      | 31/81 [00:05<00:05,  9.43it/s] 40%|███▉      | 32/81 [00:06<00:05,  9.44it/s] 41%|████      | 33/81 [00:06<00:05,  9.44it/s] 42%|████▏     | 34/81 [00:06<00:04,  9.44it/s] 43%|████▎     | 35/81 [00:06<00:04,  9.44it/s] 44%|████▍     | 36/81 [00:06<00:04,  9.45it/s] 46%|████▌     | 37/81 [00:06<00:04,  9.46it/s] 47%|████▋     | 38/81 [00:06<00:04,  9.46it/s] 48%|████▊     | 39/81 [00:06<00:04,  9.46it/s] 49%|████▉     | 40/81 [00:06<00:04,  9.45it/s] 51%|█████     | 41/81 [00:07<00:04,  9.45it/s] 52%|█████▏    | 42/81 [00:07<00:04,  9.45it/s] 53%|█████▎    | 43/81 [00:07<00:04,  9.45it/s] 54%|█████▍    | 44/81 [00:07<00:03,  9.45it/s] 56%|█████▌    | 45/81 [00:07<00:03,  9.46it/s] 57%|█████▋    | 46/81 [00:07<00:03,  9.46it/s] 58%|█████▊    | 47/81 [00:07<00:03,  9.45it/s] 59%|█████▉    | 48/81 [00:07<00:03,  9.45it/s] 60%|██████    | 49/81 [00:07<00:03,  9.45it/s] 62%|██████▏   | 50/81 [00:07<00:03,  9.44it/s] 63%|██████▎   | 51/81 [00:08<00:03,  9.44it/s] 64%|██████▍   | 52/81 [00:08<00:03,  9.43it/s] 65%|██████▌   | 53/81 [00:08<00:02,  9.43it/s] 67%|██████▋   | 54/81 [00:08<00:02,  9.44it/s] 68%|██████▊   | 55/81 [00:08<00:02,  9.43it/s] 69%|██████▉   | 56/81 [00:08<00:02,  9.42it/s] 70%|███████   | 57/81 [00:08<00:02,  9.43it/s] 72%|███████▏  | 58/81 [00:08<00:02,  9.43it/s] 73%|███████▎  | 59/81 [00:08<00:02,  9.43it/s] 74%|███████▍  | 60/81 [00:09<00:02,  9.44it/s] 75%|███████▌  | 61/81 [00:09<00:02,  9.44it/s] 77%|███████▋  | 62/81 [00:09<00:02,  9.44it/s] 78%|███████▊  | 63/81 [00:09<00:01,  9.43it/s] 79%|███████▉  | 64/81 [00:09<00:01,  9.44it/s] 80%|████████  | 65/81 [00:09<00:01,  9.44it/s] 81%|████████▏ | 66/81 [00:09<00:01,  9.43it/s] 83%|████████▎ | 67/81 [00:09<00:01,  9.45it/s] 84%|████████▍ | 68/81 [00:09<00:01,  9.47it/s] 85%|████████▌ | 69/81 [00:10<00:01,  9.49it/s] 86%|████████▋ | 70/81 [00:10<00:01,  9.51it/s] 88%|████████▊ | 71/81 [00:10<00:01,  9.51it/s] 89%|████████▉ | 72/81 [00:10<00:00,  9.52it/s] 90%|█████████ | 73/81 [00:10<00:00,  9.52it/s] 91%|█████████▏| 74/81 [00:10<00:00,  9.52it/s] 93%|█████████▎| 75/81 [00:10<00:00,  9.53it/s] 94%|█████████▍| 76/81 [00:10<00:00,  9.53it/s] 95%|█████████▌| 77/81 [00:10<00:00,  9.53it/s] 96%|█████████▋| 78/81 [00:10<00:00,  9.53it/s] 98%|█████████▊| 79/81 [00:11<00:00,  9.54it/s] 99%|█████████▉| 80/81 [00:11<00:00,  9.52it/s]100%|██████████| 81/81 [00:11<00:00,  9.52it/s]100%|██████████| 81/81 [00:11<00:00,  7.14it/s]
=> result
* total: 8,100
* correct: 2,258
* accuracy: 27.9%
* error: 72.1%
* macro_f1: 21.1%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh oxford_flowers eurosat 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_oxford_flowers/eurosat/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_oxford_flowers/eurosat/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_3.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/oxford_flowers/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:02<03:39,  2.74s/it]  2%|▏         | 2/81 [00:02<01:34,  1.19s/it]  4%|▎         | 3/81 [00:02<00:54,  1.44it/s]  5%|▍         | 4/81 [00:03<00:35,  2.16it/s]  6%|▌         | 5/81 [00:03<00:25,  2.99it/s]  7%|▋         | 6/81 [00:03<00:19,  3.90it/s]  9%|▊         | 7/81 [00:03<00:15,  4.82it/s] 10%|▉         | 8/81 [00:03<00:12,  5.70it/s] 11%|█         | 9/81 [00:03<00:11,  6.50it/s] 12%|█▏        | 10/81 [00:03<00:09,  7.19it/s] 14%|█▎        | 11/81 [00:03<00:09,  7.76it/s] 15%|█▍        | 12/81 [00:03<00:08,  8.21it/s] 16%|█▌        | 13/81 [00:04<00:07,  8.56it/s] 17%|█▋        | 14/81 [00:04<00:07,  8.81it/s] 19%|█▊        | 15/81 [00:04<00:07,  8.99it/s] 20%|█▉        | 16/81 [00:04<00:07,  9.13it/s] 21%|██        | 17/81 [00:04<00:06,  9.22it/s] 22%|██▏       | 18/81 [00:04<00:06,  9.27it/s] 23%|██▎       | 19/81 [00:04<00:06,  9.31it/s] 25%|██▍       | 20/81 [00:04<00:06,  9.36it/s] 26%|██▌       | 21/81 [00:04<00:06,  9.40it/s] 27%|██▋       | 22/81 [00:04<00:06,  9.41it/s] 28%|██▊       | 23/81 [00:05<00:06,  9.42it/s] 30%|██▉       | 24/81 [00:05<00:06,  9.41it/s] 31%|███       | 25/81 [00:05<00:05,  9.41it/s] 32%|███▏      | 26/81 [00:05<00:05,  9.42it/s] 33%|███▎      | 27/81 [00:05<00:05,  9.43it/s] 35%|███▍      | 28/81 [00:05<00:05,  9.41it/s] 36%|███▌      | 29/81 [00:05<00:05,  9.44it/s] 37%|███▋      | 30/81 [00:05<00:05,  9.45it/s] 38%|███▊      | 31/81 [00:05<00:05,  9.44it/s] 40%|███▉      | 32/81 [00:06<00:05,  9.44it/s] 41%|████      | 33/81 [00:06<00:05,  9.44it/s] 42%|████▏     | 34/81 [00:06<00:04,  9.43it/s] 43%|████▎     | 35/81 [00:06<00:04,  9.43it/s] 44%|████▍     | 36/81 [00:06<00:04,  9.43it/s] 46%|████▌     | 37/81 [00:06<00:04,  9.46it/s] 47%|████▋     | 38/81 [00:06<00:04,  9.46it/s] 48%|████▊     | 39/81 [00:06<00:04,  9.45it/s] 49%|████▉     | 40/81 [00:06<00:04,  9.44it/s] 51%|█████     | 41/81 [00:06<00:04,  9.43it/s] 52%|█████▏    | 42/81 [00:07<00:04,  9.43it/s] 53%|█████▎    | 43/81 [00:07<00:04,  9.43it/s] 54%|█████▍    | 44/81 [00:07<00:03,  9.42it/s] 56%|█████▌    | 45/81 [00:07<00:03,  9.44it/s] 57%|█████▋    | 46/81 [00:07<00:03,  9.45it/s] 58%|█████▊    | 47/81 [00:07<00:03,  9.45it/s] 59%|█████▉    | 48/81 [00:07<00:03,  9.44it/s] 60%|██████    | 49/81 [00:07<00:03,  9.44it/s] 62%|██████▏   | 50/81 [00:07<00:03,  9.43it/s] 63%|██████▎   | 51/81 [00:08<00:03,  9.43it/s] 64%|██████▍   | 52/81 [00:08<00:03,  9.42it/s] 65%|██████▌   | 53/81 [00:08<00:02,  9.45it/s] 67%|██████▋   | 54/81 [00:08<00:02,  9.44it/s] 68%|██████▊   | 55/81 [00:08<00:02,  9.42it/s] 69%|██████▉   | 56/81 [00:08<00:02,  9.43it/s] 70%|███████   | 57/81 [00:08<00:02,  9.43it/s] 72%|███████▏  | 58/81 [00:08<00:02,  9.43it/s] 73%|███████▎  | 59/81 [00:08<00:02,  9.42it/s] 74%|███████▍  | 60/81 [00:08<00:02,  9.42it/s] 75%|███████▌  | 61/81 [00:09<00:02,  9.44it/s] 77%|███████▋  | 62/81 [00:09<00:02,  9.43it/s] 78%|███████▊  | 63/81 [00:09<00:01,  9.44it/s] 79%|███████▉  | 64/81 [00:09<00:01,  9.42it/s] 80%|████████  | 65/81 [00:09<00:01,  9.41it/s] 81%|████████▏ | 66/81 [00:09<00:01,  9.42it/s] 83%|████████▎ | 67/81 [00:09<00:01,  9.44it/s] 84%|████████▍ | 68/81 [00:09<00:01,  9.46it/s] 85%|████████▌ | 69/81 [00:09<00:01,  9.49it/s] 86%|████████▋ | 70/81 [00:10<00:01,  9.49it/s] 88%|████████▊ | 71/81 [00:10<00:01,  9.49it/s] 89%|████████▉ | 72/81 [00:10<00:00,  9.49it/s] 90%|█████████ | 73/81 [00:10<00:00,  9.48it/s] 91%|█████████▏| 74/81 [00:10<00:00,  9.48it/s] 93%|█████████▎| 75/81 [00:10<00:00,  9.49it/s] 94%|█████████▍| 76/81 [00:10<00:00,  9.50it/s] 95%|█████████▌| 77/81 [00:10<00:00,  9.51it/s] 96%|█████████▋| 78/81 [00:10<00:00,  9.51it/s] 98%|█████████▊| 79/81 [00:10<00:00,  9.52it/s] 99%|█████████▉| 80/81 [00:11<00:00,  9.52it/s]100%|██████████| 81/81 [00:11<00:00,  9.52it/s]100%|██████████| 81/81 [00:11<00:00,  7.18it/s]
=> result
* total: 8,100
* correct: 2,364
* accuracy: 29.2%
* error: 70.8%
* macro_f1: 20.8%

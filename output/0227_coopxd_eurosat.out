set -e
set -x

eval "$(conda shell.bash hook)"
++ conda shell.bash hook
+ eval 'export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We're not allowing PS1 to be unbound. It must at least be set.
    # However, we're not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi
++ '[' -z x ']'

conda activate base
++ conda activate base
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate base
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate base
+++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate base
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(base) '
+++ PS1='(base) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
+++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
+++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda'
+++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda
+++ CONDA_PREFIX=/home/s2/mjoolee/anaconda
export CONDA_SHLVL='3'
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
export CONDA_DEFAULT_ENV='base'
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
export CONDA_PROMPT_MODIFIER='(base) '
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
export CONDA_PREFIX_2='/home/s2/mjoolee/anaconda/envs/dassl'
+++ export CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
+++ CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
+++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
+++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
+++ export _CE_M=
+++ _CE_M=
export _CE_CONDA=''
+++ export _CE_CONDA=
+++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
+++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
conda activate dassl
+ conda activate dassl
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate dassl
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate dassl
++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate dassl
+ ask_conda='PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
+ eval 'PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(dassl) '
++ PS1='(dassl) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda/envs/dassl'
++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
++ CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_SHLVL='4'
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
export CONDA_DEFAULT_ENV='dassl'
++ export CONDA_DEFAULT_ENV=dassl
++ CONDA_DEFAULT_ENV=dassl
export CONDA_PROMPT_MODIFIER='(dassl) '
++ export 'CONDA_PROMPT_MODIFIER=(dassl) '
++ CONDA_PROMPT_MODIFIER='(dassl) '
export CONDA_PREFIX_3='/home/s2/mjoolee/anaconda'
++ export CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
++ CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r

GPU=0
+ GPU=0
SHOT=16
+ SHOT=16
EPOCH=200
+ EPOCH=200
cfg=vit_b16_ctxv1
+ cfg=vit_b16_ctxv1
TRAINER=CoOp
+ TRAINER=CoOp


for seed in 1 2 3
 do
     #training
     sh scripts/coop/crossdataset_train.sh eurosat ${seed} ${GPU} ${cfg} ${SHOT} ${TRAINER}
 done         
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_train.sh eurosat 1 0 vit_b16_ctxv1 16 CoOp
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_1.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/200] batch [5/5] time 0.055 (0.492) data 0.000 (0.155) loss 2.1211 (1.9850) acc 34.3750 (33.7500) lr 2.0000e-03 eta 0:08:09
epoch [2/200] batch [5/5] time 0.048 (0.148) data 0.000 (0.100) loss 1.6025 (1.8098) acc 40.6250 (34.3750) lr 1.9999e-03 eta 0:02:26
epoch [3/200] batch [5/5] time 0.056 (0.144) data 0.000 (0.093) loss 1.6855 (1.6207) acc 37.5000 (43.1250) lr 1.9995e-03 eta 0:02:22
epoch [4/200] batch [5/5] time 0.047 (0.152) data 0.000 (0.102) loss 1.6738 (1.6711) acc 50.0000 (44.3750) lr 1.9989e-03 eta 0:02:29
epoch [5/200] batch [5/5] time 0.047 (0.144) data 0.000 (0.094) loss 1.4385 (1.4984) acc 59.3750 (52.5000) lr 1.9980e-03 eta 0:02:20
epoch [6/200] batch [5/5] time 0.051 (0.145) data 0.000 (0.094) loss 1.3877 (1.5109) acc 50.0000 (46.8750) lr 1.9969e-03 eta 0:02:20
epoch [7/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.096) loss 1.4346 (1.4596) acc 56.2500 (50.6250) lr 1.9956e-03 eta 0:02:21
epoch [8/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.092) loss 1.0967 (1.4395) acc 65.6250 (48.7500) lr 1.9940e-03 eta 0:02:17
epoch [9/200] batch [5/5] time 0.055 (0.146) data 0.000 (0.094) loss 1.3926 (1.3816) acc 59.3750 (53.1250) lr 1.9921e-03 eta 0:02:19
epoch [10/200] batch [5/5] time 0.055 (0.147) data 0.000 (0.093) loss 1.5000 (1.4569) acc 46.8750 (47.5000) lr 1.9900e-03 eta 0:02:20
epoch [11/200] batch [5/5] time 0.048 (0.145) data 0.000 (0.094) loss 1.4268 (1.2447) acc 53.1250 (60.6250) lr 1.9877e-03 eta 0:02:16
epoch [12/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.092) loss 1.6357 (1.2838) acc 34.3750 (53.1250) lr 1.9851e-03 eta 0:02:15
epoch [13/200] batch [5/5] time 0.053 (0.148) data 0.000 (0.096) loss 1.0000 (1.1531) acc 65.6250 (63.7500) lr 1.9823e-03 eta 0:02:18
epoch [14/200] batch [5/5] time 0.047 (0.149) data 0.000 (0.096) loss 1.4834 (1.1883) acc 53.1250 (64.3750) lr 1.9792e-03 eta 0:02:18
epoch [15/200] batch [5/5] time 0.050 (0.147) data 0.000 (0.097) loss 0.8608 (1.1349) acc 78.1250 (63.1250) lr 1.9759e-03 eta 0:02:15
epoch [16/200] batch [5/5] time 0.051 (0.143) data 0.000 (0.091) loss 1.0820 (1.1467) acc 71.8750 (62.5000) lr 1.9724e-03 eta 0:02:11
epoch [17/200] batch [5/5] time 0.047 (0.148) data 0.000 (0.097) loss 1.1328 (1.1035) acc 56.2500 (63.7500) lr 1.9686e-03 eta 0:02:15
epoch [18/200] batch [5/5] time 0.055 (0.148) data 0.000 (0.097) loss 1.0117 (1.0040) acc 65.6250 (71.2500) lr 1.9646e-03 eta 0:02:14
epoch [19/200] batch [5/5] time 0.052 (0.146) data 0.000 (0.093) loss 0.8267 (0.9741) acc 65.6250 (65.0000) lr 1.9603e-03 eta 0:02:12
epoch [20/200] batch [5/5] time 0.055 (0.149) data 0.000 (0.097) loss 1.0566 (0.9430) acc 59.3750 (68.7500) lr 1.9558e-03 eta 0:02:14
epoch [21/200] batch [5/5] time 0.052 (0.151) data 0.000 (0.097) loss 0.9243 (0.9241) acc 78.1250 (70.0000) lr 1.9511e-03 eta 0:02:14
epoch [22/200] batch [5/5] time 0.055 (0.148) data 0.000 (0.095) loss 0.7798 (1.0195) acc 81.2500 (66.2500) lr 1.9461e-03 eta 0:02:11
epoch [23/200] batch [5/5] time 0.053 (0.151) data 0.000 (0.098) loss 0.9688 (0.9544) acc 68.7500 (73.1250) lr 1.9409e-03 eta 0:02:13
epoch [24/200] batch [5/5] time 0.049 (0.148) data 0.000 (0.096) loss 0.9038 (0.8794) acc 65.6250 (69.3750) lr 1.9354e-03 eta 0:02:09
epoch [25/200] batch [5/5] time 0.050 (0.148) data 0.000 (0.097) loss 1.1006 (1.0108) acc 59.3750 (65.6250) lr 1.9298e-03 eta 0:02:09
epoch [26/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.095) loss 0.7852 (0.9241) acc 71.8750 (69.3750) lr 1.9239e-03 eta 0:02:07
epoch [27/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.098) loss 0.9185 (0.8771) acc 71.8750 (71.2500) lr 1.9178e-03 eta 0:02:09
epoch [28/200] batch [5/5] time 0.053 (0.143) data 0.000 (0.091) loss 0.9185 (0.8874) acc 71.8750 (69.3750) lr 1.9114e-03 eta 0:02:02
epoch [29/200] batch [5/5] time 0.052 (0.146) data 0.000 (0.093) loss 1.0557 (0.8524) acc 65.6250 (76.8750) lr 1.9048e-03 eta 0:02:04
epoch [30/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.095) loss 0.8213 (0.8016) acc 68.7500 (71.8750) lr 1.8980e-03 eta 0:02:06
epoch [31/200] batch [5/5] time 0.052 (0.142) data 0.000 (0.091) loss 0.7812 (0.7687) acc 75.0000 (75.0000) lr 1.8910e-03 eta 0:01:59
epoch [32/200] batch [5/5] time 0.052 (0.143) data 0.000 (0.091) loss 0.7334 (0.7293) acc 75.0000 (79.3750) lr 1.8838e-03 eta 0:02:00
epoch [33/200] batch [5/5] time 0.054 (0.151) data 0.000 (0.099) loss 0.7349 (0.8657) acc 75.0000 (71.8750) lr 1.8763e-03 eta 0:02:06
epoch [34/200] batch [5/5] time 0.053 (0.150) data 0.000 (0.098) loss 0.9023 (0.8841) acc 75.0000 (71.8750) lr 1.8686e-03 eta 0:02:04
epoch [35/200] batch [5/5] time 0.052 (0.146) data 0.000 (0.094) loss 0.6641 (0.7899) acc 81.2500 (73.1250) lr 1.8607e-03 eta 0:02:00
epoch [36/200] batch [5/5] time 0.048 (0.145) data 0.000 (0.094) loss 0.7827 (0.7376) acc 71.8750 (75.0000) lr 1.8526e-03 eta 0:01:59
epoch [37/200] batch [5/5] time 0.051 (0.145) data 0.000 (0.093) loss 0.6045 (0.6875) acc 90.6250 (80.6250) lr 1.8443e-03 eta 0:01:58
epoch [38/200] batch [5/5] time 0.047 (0.146) data 0.000 (0.097) loss 0.8535 (0.7795) acc 68.7500 (74.3750) lr 1.8358e-03 eta 0:01:58
epoch [39/200] batch [5/5] time 0.053 (0.150) data 0.000 (0.097) loss 0.8955 (0.6898) acc 71.8750 (75.6250) lr 1.8271e-03 eta 0:02:00
epoch [40/200] batch [5/5] time 0.054 (0.147) data 0.000 (0.093) loss 0.8228 (0.6896) acc 75.0000 (79.3750) lr 1.8181e-03 eta 0:01:57
epoch [41/200] batch [5/5] time 0.051 (0.147) data 0.000 (0.095) loss 0.6528 (0.5716) acc 84.3750 (83.7500) lr 1.8090e-03 eta 0:01:56
epoch [42/200] batch [5/5] time 0.054 (0.153) data 0.000 (0.099) loss 0.6987 (0.7309) acc 68.7500 (71.8750) lr 1.7997e-03 eta 0:02:00
epoch [43/200] batch [5/5] time 0.048 (0.145) data 0.000 (0.096) loss 0.5146 (0.6895) acc 81.2500 (71.8750) lr 1.7902e-03 eta 0:01:53
epoch [44/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.097) loss 0.6841 (0.6726) acc 68.7500 (75.0000) lr 1.7804e-03 eta 0:01:56
epoch [45/200] batch [5/5] time 0.052 (0.144) data 0.000 (0.093) loss 0.8628 (0.6371) acc 68.7500 (80.0000) lr 1.7705e-03 eta 0:01:51
epoch [46/200] batch [5/5] time 0.051 (0.149) data 0.000 (0.098) loss 0.4648 (0.6033) acc 87.5000 (80.0000) lr 1.7604e-03 eta 0:01:54
epoch [47/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.092) loss 0.7363 (0.6089) acc 78.1250 (82.5000) lr 1.7501e-03 eta 0:01:51
epoch [48/200] batch [5/5] time 0.051 (0.140) data 0.000 (0.090) loss 0.6411 (0.6758) acc 87.5000 (78.1250) lr 1.7396e-03 eta 0:01:46
epoch [49/200] batch [5/5] time 0.054 (0.155) data 0.000 (0.102) loss 0.4851 (0.6238) acc 87.5000 (81.2500) lr 1.7290e-03 eta 0:01:56
epoch [50/200] batch [5/5] time 0.049 (0.146) data 0.000 (0.094) loss 0.4077 (0.5528) acc 90.6250 (79.3750) lr 1.7181e-03 eta 0:01:49
epoch [51/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.095) loss 0.6030 (0.6244) acc 87.5000 (81.2500) lr 1.7071e-03 eta 0:01:49
epoch [52/200] batch [5/5] time 0.051 (0.144) data 0.000 (0.093) loss 0.6812 (0.6034) acc 81.2500 (79.3750) lr 1.6959e-03 eta 0:01:46
epoch [53/200] batch [5/5] time 0.051 (0.151) data 0.000 (0.100) loss 0.5049 (0.5641) acc 75.0000 (78.7500) lr 1.6845e-03 eta 0:01:51
epoch [54/200] batch [5/5] time 0.047 (0.145) data 0.000 (0.094) loss 0.3718 (0.5472) acc 84.3750 (81.8750) lr 1.6730e-03 eta 0:01:45
epoch [55/200] batch [5/5] time 0.051 (0.143) data 0.000 (0.092) loss 0.4497 (0.6069) acc 84.3750 (78.1250) lr 1.6613e-03 eta 0:01:43
epoch [56/200] batch [5/5] time 0.047 (0.142) data 0.000 (0.092) loss 0.6294 (0.6112) acc 71.8750 (77.5000) lr 1.6494e-03 eta 0:01:42
epoch [57/200] batch [5/5] time 0.049 (0.142) data 0.000 (0.093) loss 0.5220 (0.5199) acc 75.0000 (81.2500) lr 1.6374e-03 eta 0:01:41
epoch [58/200] batch [5/5] time 0.053 (0.146) data 0.000 (0.091) loss 0.5942 (0.5381) acc 87.5000 (86.2500) lr 1.6252e-03 eta 0:01:43
epoch [59/200] batch [5/5] time 0.054 (0.147) data 0.000 (0.094) loss 0.4500 (0.5447) acc 78.1250 (80.0000) lr 1.6129e-03 eta 0:01:43
epoch [60/200] batch [5/5] time 0.048 (0.143) data 0.000 (0.091) loss 0.5312 (0.5083) acc 84.3750 (85.6250) lr 1.6004e-03 eta 0:01:40
epoch [61/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.092) loss 0.6504 (0.5093) acc 71.8750 (82.5000) lr 1.5878e-03 eta 0:01:40
epoch [62/200] batch [5/5] time 0.048 (0.153) data 0.000 (0.102) loss 0.4854 (0.5307) acc 84.3750 (82.5000) lr 1.5750e-03 eta 0:01:45
epoch [63/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.094) loss 0.6108 (0.5641) acc 75.0000 (82.5000) lr 1.5621e-03 eta 0:01:39
epoch [64/200] batch [5/5] time 0.055 (0.152) data 0.000 (0.099) loss 0.4258 (0.4476) acc 90.6250 (86.2500) lr 1.5490e-03 eta 0:01:43
epoch [65/200] batch [5/5] time 0.057 (0.149) data 0.000 (0.096) loss 0.2366 (0.5073) acc 96.8750 (83.7500) lr 1.5358e-03 eta 0:01:40
epoch [66/200] batch [5/5] time 0.054 (0.147) data 0.000 (0.094) loss 0.4758 (0.4699) acc 87.5000 (86.2500) lr 1.5225e-03 eta 0:01:38
epoch [67/200] batch [5/5] time 0.049 (0.148) data 0.000 (0.096) loss 0.5684 (0.4751) acc 75.0000 (82.5000) lr 1.5090e-03 eta 0:01:38
epoch [68/200] batch [5/5] time 0.053 (0.148) data 0.000 (0.096) loss 0.5005 (0.3999) acc 84.3750 (87.5000) lr 1.4955e-03 eta 0:01:37
epoch [69/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.095) loss 0.5210 (0.5375) acc 81.2500 (83.1250) lr 1.4818e-03 eta 0:01:35
epoch [70/200] batch [5/5] time 0.047 (0.151) data 0.000 (0.101) loss 0.4158 (0.4304) acc 87.5000 (85.0000) lr 1.4679e-03 eta 0:01:38
epoch [71/200] batch [5/5] time 0.053 (0.146) data 0.000 (0.094) loss 0.3726 (0.4207) acc 87.5000 (85.6250) lr 1.4540e-03 eta 0:01:34
epoch [72/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.101) loss 0.4810 (0.5162) acc 87.5000 (82.5000) lr 1.4399e-03 eta 0:01:37
epoch [73/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.096) loss 0.4905 (0.4579) acc 87.5000 (87.5000) lr 1.4258e-03 eta 0:01:34
epoch [74/200] batch [5/5] time 0.050 (0.143) data 0.000 (0.092) loss 0.4128 (0.5328) acc 87.5000 (81.2500) lr 1.4115e-03 eta 0:01:30
epoch [75/200] batch [5/5] time 0.053 (0.150) data 0.000 (0.098) loss 0.6143 (0.4820) acc 75.0000 (83.1250) lr 1.3971e-03 eta 0:01:33
epoch [76/200] batch [5/5] time 0.049 (0.147) data 0.000 (0.097) loss 0.2769 (0.4148) acc 93.7500 (86.2500) lr 1.3827e-03 eta 0:01:31
epoch [77/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.094) loss 0.4517 (0.5151) acc 87.5000 (83.7500) lr 1.3681e-03 eta 0:01:29
epoch [78/200] batch [5/5] time 0.051 (0.145) data 0.000 (0.094) loss 0.2639 (0.4072) acc 93.7500 (88.7500) lr 1.3535e-03 eta 0:01:28
epoch [79/200] batch [5/5] time 0.047 (0.148) data 0.000 (0.098) loss 0.7031 (0.5385) acc 75.0000 (81.8750) lr 1.3387e-03 eta 0:01:29
epoch [80/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.098) loss 0.4080 (0.3834) acc 90.6250 (91.2500) lr 1.3239e-03 eta 0:01:29
epoch [81/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.093) loss 0.4475 (0.4903) acc 90.6250 (86.2500) lr 1.3090e-03 eta 0:01:25
epoch [82/200] batch [5/5] time 0.048 (0.138) data 0.000 (0.090) loss 0.5933 (0.4610) acc 81.2500 (84.3750) lr 1.2940e-03 eta 0:01:21
epoch [83/200] batch [5/5] time 0.054 (0.145) data 0.000 (0.093) loss 0.4773 (0.4639) acc 84.3750 (86.2500) lr 1.2790e-03 eta 0:01:24
epoch [84/200] batch [5/5] time 0.054 (0.140) data 0.000 (0.089) loss 0.5723 (0.4940) acc 81.2500 (83.7500) lr 1.2639e-03 eta 0:01:21
epoch [85/200] batch [5/5] time 0.047 (0.149) data 0.000 (0.099) loss 0.5767 (0.4985) acc 81.2500 (85.0000) lr 1.2487e-03 eta 0:01:25
epoch [86/200] batch [5/5] time 0.050 (0.151) data 0.000 (0.100) loss 0.4937 (0.4965) acc 81.2500 (84.3750) lr 1.2334e-03 eta 0:01:26
epoch [87/200] batch [5/5] time 0.053 (0.146) data 0.000 (0.092) loss 0.5957 (0.4217) acc 78.1250 (85.6250) lr 1.2181e-03 eta 0:01:22
epoch [88/200] batch [5/5] time 0.051 (0.148) data 0.000 (0.098) loss 0.2749 (0.4479) acc 90.6250 (86.8750) lr 1.2028e-03 eta 0:01:23
epoch [89/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.097) loss 0.4949 (0.3828) acc 81.2500 (89.3750) lr 1.1874e-03 eta 0:01:22
epoch [90/200] batch [5/5] time 0.051 (0.147) data 0.000 (0.095) loss 0.4087 (0.3769) acc 90.6250 (88.7500) lr 1.1719e-03 eta 0:01:20
epoch [91/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.100) loss 0.3926 (0.3532) acc 87.5000 (88.1250) lr 1.1564e-03 eta 0:01:22
epoch [92/200] batch [5/5] time 0.054 (0.151) data 0.000 (0.098) loss 0.4265 (0.4818) acc 87.5000 (84.3750) lr 1.1409e-03 eta 0:01:21
epoch [93/200] batch [5/5] time 0.054 (0.154) data 0.000 (0.099) loss 0.4617 (0.4846) acc 84.3750 (85.6250) lr 1.1253e-03 eta 0:01:22
epoch [94/200] batch [5/5] time 0.052 (0.149) data 0.000 (0.095) loss 0.5693 (0.3961) acc 71.8750 (85.0000) lr 1.1097e-03 eta 0:01:19
epoch [95/200] batch [5/5] time 0.047 (0.148) data 0.000 (0.095) loss 0.3872 (0.4841) acc 90.6250 (85.6250) lr 1.0941e-03 eta 0:01:17
epoch [96/200] batch [5/5] time 0.049 (0.150) data 0.000 (0.100) loss 0.3838 (0.3675) acc 81.2500 (87.5000) lr 1.0785e-03 eta 0:01:17
epoch [97/200] batch [5/5] time 0.051 (0.141) data 0.000 (0.092) loss 0.5200 (0.4198) acc 81.2500 (86.8750) lr 1.0628e-03 eta 0:01:12
epoch [98/200] batch [5/5] time 0.051 (0.148) data 0.000 (0.097) loss 0.3591 (0.4204) acc 93.7500 (88.7500) lr 1.0471e-03 eta 0:01:15
epoch [99/200] batch [5/5] time 0.051 (0.149) data 0.000 (0.097) loss 0.4800 (0.4901) acc 81.2500 (84.3750) lr 1.0314e-03 eta 0:01:15
epoch [100/200] batch [5/5] time 0.050 (0.141) data 0.000 (0.089) loss 0.4897 (0.4309) acc 78.1250 (86.2500) lr 1.0157e-03 eta 0:01:10
epoch [101/200] batch [5/5] time 0.047 (0.145) data 0.000 (0.095) loss 0.5615 (0.4002) acc 87.5000 (88.7500) lr 1.0000e-03 eta 0:01:11
epoch [102/200] batch [5/5] time 0.053 (0.148) data 0.000 (0.093) loss 0.3503 (0.3853) acc 87.5000 (88.1250) lr 9.8429e-04 eta 0:01:12
epoch [103/200] batch [5/5] time 0.052 (0.152) data 0.000 (0.100) loss 0.5078 (0.4812) acc 90.6250 (85.6250) lr 9.6859e-04 eta 0:01:13
epoch [104/200] batch [5/5] time 0.053 (0.143) data 0.000 (0.091) loss 0.3831 (0.4570) acc 84.3750 (81.8750) lr 9.5289e-04 eta 0:01:08
epoch [105/200] batch [5/5] time 0.053 (0.150) data 0.000 (0.098) loss 0.2656 (0.4341) acc 93.7500 (85.0000) lr 9.3721e-04 eta 0:01:11
epoch [106/200] batch [5/5] time 0.052 (0.152) data 0.000 (0.100) loss 0.6001 (0.4315) acc 78.1250 (86.2500) lr 9.2154e-04 eta 0:01:11
epoch [107/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.093) loss 0.4221 (0.4713) acc 87.5000 (86.8750) lr 9.0589e-04 eta 0:01:07
epoch [108/200] batch [5/5] time 0.051 (0.141) data 0.000 (0.090) loss 0.5215 (0.4394) acc 87.5000 (86.8750) lr 8.9027e-04 eta 0:01:04
epoch [109/200] batch [5/5] time 0.048 (0.143) data 0.000 (0.092) loss 0.6187 (0.4137) acc 78.1250 (88.7500) lr 8.7467e-04 eta 0:01:04
epoch [110/200] batch [5/5] time 0.048 (0.140) data 0.000 (0.091) loss 0.4136 (0.3740) acc 87.5000 (91.2500) lr 8.5910e-04 eta 0:01:03
epoch [111/200] batch [5/5] time 0.047 (0.147) data 0.000 (0.095) loss 0.4497 (0.3738) acc 81.2500 (90.0000) lr 8.4357e-04 eta 0:01:05
epoch [112/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.097) loss 0.3525 (0.3808) acc 87.5000 (88.7500) lr 8.2807e-04 eta 0:01:05
epoch [113/200] batch [5/5] time 0.055 (0.147) data 0.000 (0.095) loss 0.4136 (0.3798) acc 90.6250 (91.2500) lr 8.1262e-04 eta 0:01:04
epoch [114/200] batch [5/5] time 0.050 (0.152) data 0.000 (0.099) loss 0.3428 (0.3236) acc 84.3750 (90.6250) lr 7.9721e-04 eta 0:01:05
epoch [115/200] batch [5/5] time 0.049 (0.151) data 0.000 (0.102) loss 0.5688 (0.3535) acc 84.3750 (89.3750) lr 7.8186e-04 eta 0:01:04
epoch [116/200] batch [5/5] time 0.049 (0.142) data 0.000 (0.091) loss 0.5137 (0.3867) acc 78.1250 (85.6250) lr 7.6655e-04 eta 0:00:59
epoch [117/200] batch [5/5] time 0.048 (0.145) data 0.000 (0.093) loss 0.8516 (0.3824) acc 65.6250 (88.1250) lr 7.5131e-04 eta 0:01:00
epoch [118/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.092) loss 0.7070 (0.4819) acc 75.0000 (86.2500) lr 7.3613e-04 eta 0:00:59
epoch [119/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.098) loss 0.2952 (0.3686) acc 90.6250 (88.7500) lr 7.2101e-04 eta 0:01:01
epoch [120/200] batch [5/5] time 0.050 (0.145) data 0.000 (0.092) loss 0.3660 (0.3875) acc 87.5000 (87.5000) lr 7.0596e-04 eta 0:00:58
epoch [121/200] batch [5/5] time 0.047 (0.141) data 0.000 (0.089) loss 0.1764 (0.3990) acc 96.8750 (86.8750) lr 6.9098e-04 eta 0:00:55
epoch [122/200] batch [5/5] time 0.047 (0.144) data 0.000 (0.093) loss 0.3420 (0.3108) acc 100.0000 (95.6250) lr 6.7608e-04 eta 0:00:56
epoch [123/200] batch [5/5] time 0.053 (0.151) data 0.000 (0.097) loss 0.4192 (0.4187) acc 81.2500 (86.2500) lr 6.6126e-04 eta 0:00:57
epoch [124/200] batch [5/5] time 0.050 (0.145) data 0.000 (0.094) loss 0.3867 (0.3838) acc 84.3750 (88.1250) lr 6.4653e-04 eta 0:00:55
epoch [125/200] batch [5/5] time 0.055 (0.147) data 0.000 (0.092) loss 0.5303 (0.3565) acc 81.2500 (90.0000) lr 6.3188e-04 eta 0:00:55
epoch [126/200] batch [5/5] time 0.048 (0.149) data 0.000 (0.096) loss 0.6025 (0.4372) acc 71.8750 (85.6250) lr 6.1732e-04 eta 0:00:55
epoch [127/200] batch [5/5] time 0.054 (0.153) data 0.000 (0.098) loss 0.2246 (0.3701) acc 96.8750 (89.3750) lr 6.0285e-04 eta 0:00:55
epoch [128/200] batch [5/5] time 0.047 (0.138) data 0.000 (0.090) loss 0.1449 (0.3410) acc 100.0000 (91.2500) lr 5.8849e-04 eta 0:00:49
epoch [129/200] batch [5/5] time 0.050 (0.142) data 0.000 (0.091) loss 0.3010 (0.4589) acc 87.5000 (86.2500) lr 5.7422e-04 eta 0:00:50
epoch [130/200] batch [5/5] time 0.050 (0.146) data 0.000 (0.095) loss 0.3103 (0.3241) acc 93.7500 (90.6250) lr 5.6006e-04 eta 0:00:51
epoch [131/200] batch [5/5] time 0.052 (0.151) data 0.000 (0.100) loss 0.5034 (0.3601) acc 81.2500 (90.0000) lr 5.4601e-04 eta 0:00:52
epoch [132/200] batch [5/5] time 0.051 (0.156) data 0.000 (0.104) loss 0.3069 (0.3920) acc 93.7500 (87.5000) lr 5.3207e-04 eta 0:00:53
epoch [133/200] batch [5/5] time 0.052 (0.152) data 0.000 (0.098) loss 0.3308 (0.3226) acc 90.6250 (90.0000) lr 5.1825e-04 eta 0:00:50
epoch [134/200] batch [5/5] time 0.053 (0.150) data 0.000 (0.097) loss 0.4880 (0.4030) acc 84.3750 (86.2500) lr 5.0454e-04 eta 0:00:49
epoch [135/200] batch [5/5] time 0.054 (0.149) data 0.000 (0.094) loss 0.3000 (0.2850) acc 90.6250 (91.8750) lr 4.9096e-04 eta 0:00:48
epoch [136/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.091) loss 0.3457 (0.4169) acc 90.6250 (88.7500) lr 4.7750e-04 eta 0:00:46
epoch [137/200] batch [5/5] time 0.047 (0.148) data 0.000 (0.099) loss 0.2771 (0.3725) acc 90.6250 (90.0000) lr 4.6417e-04 eta 0:00:46
epoch [138/200] batch [5/5] time 0.056 (0.150) data 0.000 (0.095) loss 0.4536 (0.3774) acc 84.3750 (88.1250) lr 4.5098e-04 eta 0:00:46
epoch [139/200] batch [5/5] time 0.047 (0.145) data 0.000 (0.092) loss 0.3660 (0.3367) acc 90.6250 (88.7500) lr 4.3792e-04 eta 0:00:44
epoch [140/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.092) loss 0.4119 (0.3857) acc 87.5000 (90.0000) lr 4.2499e-04 eta 0:00:43
epoch [141/200] batch [5/5] time 0.054 (0.145) data 0.000 (0.090) loss 0.4927 (0.3870) acc 81.2500 (87.5000) lr 4.1221e-04 eta 0:00:42
epoch [142/200] batch [5/5] time 0.054 (0.152) data 0.000 (0.098) loss 0.4949 (0.3573) acc 81.2500 (90.6250) lr 3.9958e-04 eta 0:00:44
epoch [143/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.099) loss 0.3726 (0.3246) acc 84.3750 (91.2500) lr 3.8709e-04 eta 0:00:43
epoch [144/200] batch [5/5] time 0.048 (0.144) data 0.000 (0.092) loss 0.2507 (0.3321) acc 93.7500 (92.5000) lr 3.7476e-04 eta 0:00:40
epoch [145/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.095) loss 0.2588 (0.3958) acc 90.6250 (89.3750) lr 3.6258e-04 eta 0:00:40
epoch [146/200] batch [5/5] time 0.048 (0.145) data 0.000 (0.094) loss 0.2299 (0.4414) acc 93.7500 (88.7500) lr 3.5055e-04 eta 0:00:39
epoch [147/200] batch [5/5] time 0.055 (0.147) data 0.000 (0.093) loss 0.5088 (0.3848) acc 78.1250 (85.6250) lr 3.3869e-04 eta 0:00:38
epoch [148/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.094) loss 0.2681 (0.4091) acc 93.7500 (88.7500) lr 3.2699e-04 eta 0:00:37
epoch [149/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.097) loss 0.4297 (0.3426) acc 90.6250 (88.7500) lr 3.1545e-04 eta 0:00:37
epoch [150/200] batch [5/5] time 0.049 (0.147) data 0.000 (0.096) loss 0.2345 (0.3271) acc 96.8750 (94.3750) lr 3.0409e-04 eta 0:00:36
epoch [151/200] batch [5/5] time 0.054 (0.150) data 0.000 (0.098) loss 0.3252 (0.3619) acc 87.5000 (90.6250) lr 2.9289e-04 eta 0:00:36
epoch [152/200] batch [5/5] time 0.050 (0.147) data 0.000 (0.096) loss 0.2563 (0.3427) acc 93.7500 (90.6250) lr 2.8187e-04 eta 0:00:35
epoch [153/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.092) loss 0.4304 (0.3759) acc 81.2500 (88.7500) lr 2.7103e-04 eta 0:00:33
epoch [154/200] batch [5/5] time 0.049 (0.147) data 0.000 (0.096) loss 0.4199 (0.3531) acc 84.3750 (90.0000) lr 2.6037e-04 eta 0:00:33
epoch [155/200] batch [5/5] time 0.052 (0.144) data 0.000 (0.092) loss 0.3462 (0.3667) acc 90.6250 (89.3750) lr 2.4989e-04 eta 0:00:32
epoch [156/200] batch [5/5] time 0.048 (0.150) data 0.000 (0.098) loss 0.4202 (0.3820) acc 84.3750 (88.7500) lr 2.3959e-04 eta 0:00:32
epoch [157/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.095) loss 0.1710 (0.2981) acc 96.8750 (91.2500) lr 2.2949e-04 eta 0:00:31
epoch [158/200] batch [5/5] time 0.048 (0.144) data 0.000 (0.092) loss 0.1947 (0.2804) acc 96.8750 (91.8750) lr 2.1957e-04 eta 0:00:30
epoch [159/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.092) loss 0.4487 (0.3770) acc 81.2500 (86.2500) lr 2.0984e-04 eta 0:00:29
epoch [160/200] batch [5/5] time 0.053 (0.141) data 0.000 (0.090) loss 0.4451 (0.3134) acc 87.5000 (88.7500) lr 2.0032e-04 eta 0:00:28
epoch [161/200] batch [5/5] time 0.051 (0.145) data 0.000 (0.094) loss 0.3008 (0.4309) acc 93.7500 (88.1250) lr 1.9098e-04 eta 0:00:28
epoch [162/200] batch [5/5] time 0.054 (0.147) data 0.000 (0.097) loss 0.2954 (0.3163) acc 93.7500 (94.3750) lr 1.8185e-04 eta 0:00:28
epoch [163/200] batch [5/5] time 0.054 (0.149) data 0.000 (0.096) loss 0.2507 (0.2860) acc 87.5000 (91.2500) lr 1.7292e-04 eta 0:00:27
epoch [164/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.095) loss 0.3765 (0.2495) acc 87.5000 (93.7500) lr 1.6419e-04 eta 0:00:26
epoch [165/200] batch [5/5] time 0.049 (0.147) data 0.000 (0.098) loss 0.3677 (0.3514) acc 87.5000 (88.7500) lr 1.5567e-04 eta 0:00:25
epoch [166/200] batch [5/5] time 0.052 (0.145) data 0.000 (0.094) loss 0.3247 (0.3150) acc 93.7500 (94.3750) lr 1.4736e-04 eta 0:00:24
epoch [167/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.092) loss 0.3772 (0.3043) acc 90.6250 (90.0000) lr 1.3926e-04 eta 0:00:23
epoch [168/200] batch [5/5] time 0.051 (0.143) data 0.000 (0.092) loss 0.3650 (0.3156) acc 93.7500 (91.2500) lr 1.3137e-04 eta 0:00:22
epoch [169/200] batch [5/5] time 0.047 (0.147) data 0.000 (0.096) loss 0.4434 (0.2974) acc 87.5000 (92.5000) lr 1.2369e-04 eta 0:00:22
epoch [170/200] batch [5/5] time 0.051 (0.141) data 0.000 (0.091) loss 0.4561 (0.3136) acc 84.3750 (91.8750) lr 1.1623e-04 eta 0:00:21
epoch [171/200] batch [5/5] time 0.048 (0.152) data 0.000 (0.100) loss 0.3289 (0.3971) acc 87.5000 (87.5000) lr 1.0899e-04 eta 0:00:22
epoch [172/200] batch [5/5] time 0.051 (0.149) data 0.000 (0.099) loss 0.2212 (0.2611) acc 96.8750 (95.0000) lr 1.0197e-04 eta 0:00:20
epoch [173/200] batch [5/5] time 0.052 (0.142) data 0.000 (0.091) loss 0.2510 (0.3502) acc 90.6250 (91.2500) lr 9.5173e-05 eta 0:00:19
epoch [174/200] batch [5/5] time 0.050 (0.144) data 0.000 (0.094) loss 0.3335 (0.2867) acc 93.7500 (91.8750) lr 8.8597e-05 eta 0:00:18
epoch [175/200] batch [5/5] time 0.051 (0.143) data 0.000 (0.091) loss 0.2081 (0.3085) acc 96.8750 (91.2500) lr 8.2245e-05 eta 0:00:17
epoch [176/200] batch [5/5] time 0.052 (0.149) data 0.000 (0.097) loss 0.3665 (0.3831) acc 87.5000 (90.0000) lr 7.6120e-05 eta 0:00:17
epoch [177/200] batch [5/5] time 0.054 (0.149) data 0.000 (0.097) loss 0.2079 (0.3248) acc 96.8750 (90.6250) lr 7.0224e-05 eta 0:00:17
epoch [178/200] batch [5/5] time 0.048 (0.149) data 0.000 (0.098) loss 0.3608 (0.3330) acc 87.5000 (91.2500) lr 6.4556e-05 eta 0:00:16
epoch [179/200] batch [5/5] time 0.055 (0.150) data 0.000 (0.098) loss 0.4126 (0.3683) acc 90.6250 (91.2500) lr 5.9119e-05 eta 0:00:15
epoch [180/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.096) loss 0.4451 (0.3518) acc 84.3750 (89.3750) lr 5.3915e-05 eta 0:00:14
epoch [181/200] batch [5/5] time 0.048 (0.148) data 0.000 (0.098) loss 0.2776 (0.2971) acc 96.8750 (92.5000) lr 4.8943e-05 eta 0:00:14
epoch [182/200] batch [5/5] time 0.048 (0.148) data 0.000 (0.098) loss 0.3701 (0.3663) acc 87.5000 (88.1250) lr 4.4207e-05 eta 0:00:13
epoch [183/200] batch [5/5] time 0.053 (0.151) data 0.000 (0.099) loss 0.6382 (0.3709) acc 84.3750 (91.8750) lr 3.9706e-05 eta 0:00:12
epoch [184/200] batch [5/5] time 0.048 (0.146) data 0.000 (0.094) loss 0.3401 (0.4124) acc 87.5000 (85.6250) lr 3.5443e-05 eta 0:00:11
epoch [185/200] batch [5/5] time 0.052 (0.148) data 0.000 (0.096) loss 0.1948 (0.3201) acc 93.7500 (89.3750) lr 3.1417e-05 eta 0:00:11
epoch [186/200] batch [5/5] time 0.049 (0.144) data 0.000 (0.095) loss 0.2805 (0.3226) acc 93.7500 (88.7500) lr 2.7630e-05 eta 0:00:10
epoch [187/200] batch [5/5] time 0.054 (0.151) data 0.000 (0.097) loss 0.3672 (0.3255) acc 90.6250 (91.8750) lr 2.4083e-05 eta 0:00:09
epoch [188/200] batch [5/5] time 0.049 (0.145) data 0.000 (0.092) loss 0.2043 (0.3146) acc 93.7500 (90.0000) lr 2.0777e-05 eta 0:00:08
epoch [189/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.095) loss 0.2029 (0.2877) acc 100.0000 (95.0000) lr 1.7713e-05 eta 0:00:08
epoch [190/200] batch [5/5] time 0.053 (0.148) data 0.000 (0.094) loss 0.3633 (0.3599) acc 90.6250 (90.0000) lr 1.4891e-05 eta 0:00:07
epoch [191/200] batch [5/5] time 0.053 (0.151) data 0.000 (0.098) loss 0.3135 (0.3335) acc 87.5000 (91.2500) lr 1.2312e-05 eta 0:00:06
epoch [192/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.097) loss 0.3435 (0.3171) acc 84.3750 (91.2500) lr 9.9763e-06 eta 0:00:05
epoch [193/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.096) loss 0.4568 (0.3985) acc 93.7500 (86.8750) lr 7.8853e-06 eta 0:00:05
epoch [194/200] batch [5/5] time 0.052 (0.152) data 0.000 (0.100) loss 0.2825 (0.2789) acc 90.6250 (91.2500) lr 6.0390e-06 eta 0:00:04
epoch [195/200] batch [5/5] time 0.056 (0.153) data 0.000 (0.098) loss 0.3750 (0.3916) acc 81.2500 (88.1250) lr 4.4380e-06 eta 0:00:03
epoch [196/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.098) loss 0.3838 (0.3742) acc 87.5000 (88.1250) lr 3.0827e-06 eta 0:00:03
epoch [197/200] batch [5/5] time 0.052 (0.150) data 0.000 (0.098) loss 0.2952 (0.3195) acc 93.7500 (91.8750) lr 1.9733e-06 eta 0:00:02
epoch [198/200] batch [5/5] time 0.054 (0.148) data 0.000 (0.096) loss 0.2095 (0.2621) acc 100.0000 (93.7500) lr 1.1101e-06 eta 0:00:01
epoch [199/200] batch [5/5] time 0.050 (0.148) data 0.000 (0.097) loss 0.2266 (0.3937) acc 93.7500 (88.1250) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [5/5] time 0.048 (0.148) data 0.000 (0.096) loss 0.3628 (0.3375) acc 84.3750 (90.0000) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:01<01:27,  1.09s/it]  2%|▏         | 2/81 [00:01<00:40,  1.96it/s]  4%|▎         | 3/81 [00:01<00:25,  3.07it/s]  5%|▍         | 4/81 [00:01<00:18,  4.18it/s]  6%|▌         | 5/81 [00:01<00:15,  4.92it/s]  7%|▋         | 6/81 [00:01<00:12,  5.88it/s]  9%|▊         | 7/81 [00:01<00:11,  6.70it/s] 10%|▉         | 8/81 [00:01<00:09,  7.38it/s] 11%|█         | 9/81 [00:01<00:09,  7.92it/s] 12%|█▏        | 10/81 [00:02<00:08,  8.35it/s] 14%|█▎        | 11/81 [00:02<00:08,  8.66it/s] 15%|█▍        | 12/81 [00:02<00:07,  8.88it/s] 16%|█▌        | 13/81 [00:02<00:07,  9.08it/s] 17%|█▋        | 14/81 [00:02<00:07,  9.20it/s] 19%|█▊        | 15/81 [00:02<00:07,  9.27it/s] 20%|█▉        | 16/81 [00:02<00:06,  9.32it/s] 21%|██        | 17/81 [00:02<00:06,  9.35it/s] 22%|██▏       | 18/81 [00:02<00:06,  9.39it/s] 23%|██▎       | 19/81 [00:03<00:06,  9.41it/s] 25%|██▍       | 20/81 [00:03<00:06,  9.42it/s] 26%|██▌       | 21/81 [00:03<00:06,  9.42it/s] 27%|██▋       | 22/81 [00:03<00:06,  9.39it/s] 28%|██▊       | 23/81 [00:03<00:06,  9.41it/s] 30%|██▉       | 24/81 [00:03<00:06,  9.42it/s] 31%|███       | 25/81 [00:03<00:05,  9.43it/s] 32%|███▏      | 26/81 [00:03<00:05,  9.44it/s] 33%|███▎      | 27/81 [00:03<00:05,  9.45it/s] 35%|███▍      | 28/81 [00:03<00:05,  9.39it/s] 36%|███▌      | 29/81 [00:04<00:05,  9.44it/s] 37%|███▋      | 30/81 [00:04<00:05,  9.44it/s] 38%|███▊      | 31/81 [00:04<00:05,  9.40it/s] 40%|███▉      | 32/81 [00:04<00:05,  9.41it/s] 41%|████      | 33/81 [00:04<00:05,  9.42it/s] 42%|████▏     | 34/81 [00:04<00:04,  9.42it/s] 43%|████▎     | 35/81 [00:04<00:04,  9.43it/s] 44%|████▍     | 36/81 [00:04<00:04,  9.45it/s] 46%|████▌     | 37/81 [00:04<00:04,  9.49it/s] 47%|████▋     | 38/81 [00:05<00:04,  9.49it/s] 48%|████▊     | 39/81 [00:05<00:04,  9.49it/s] 49%|████▉     | 40/81 [00:05<00:04,  9.49it/s] 51%|█████     | 41/81 [00:05<00:04,  9.48it/s] 52%|█████▏    | 42/81 [00:05<00:04,  9.47it/s] 53%|█████▎    | 43/81 [00:05<00:04,  9.48it/s] 54%|█████▍    | 44/81 [00:05<00:03,  9.47it/s] 56%|█████▌    | 45/81 [00:05<00:03,  9.50it/s] 57%|█████▋    | 46/81 [00:05<00:03,  9.50it/s] 58%|█████▊    | 47/81 [00:05<00:03,  9.45it/s] 59%|█████▉    | 48/81 [00:06<00:03,  9.43it/s] 60%|██████    | 49/81 [00:06<00:03,  9.41it/s] 62%|██████▏   | 50/81 [00:06<00:03,  9.43it/s] 63%|██████▎   | 51/81 [00:06<00:03,  9.47it/s] 64%|██████▍   | 52/81 [00:06<00:03,  9.50it/s] 65%|██████▌   | 53/81 [00:06<00:02,  9.52it/s] 67%|██████▋   | 54/81 [00:06<00:02,  9.49it/s] 68%|██████▊   | 55/81 [00:06<00:02,  9.48it/s] 69%|██████▉   | 56/81 [00:06<00:02,  9.47it/s] 70%|███████   | 57/81 [00:07<00:02,  9.46it/s] 72%|███████▏  | 58/81 [00:07<00:02,  9.45it/s] 73%|███████▎  | 59/81 [00:07<00:02,  9.46it/s] 74%|███████▍  | 60/81 [00:07<00:02,  9.47it/s] 75%|███████▌  | 61/81 [00:07<00:02,  9.45it/s] 77%|███████▋  | 62/81 [00:07<00:02,  9.47it/s] 78%|███████▊  | 63/81 [00:07<00:01,  9.46it/s] 79%|███████▉  | 64/81 [00:07<00:01,  9.46it/s] 80%|████████  | 65/81 [00:07<00:01,  9.43it/s] 81%|████████▏ | 66/81 [00:07<00:01,  9.43it/s] 83%|████████▎ | 67/81 [00:08<00:01,  9.45it/s] 84%|████████▍ | 68/81 [00:08<00:01,  9.44it/s] 85%|████████▌ | 69/81 [00:08<00:01,  9.45it/s] 86%|████████▋ | 70/81 [00:08<00:01,  9.48it/s] 88%|████████▊ | 71/81 [00:08<00:01,  9.51it/s] 89%|████████▉ | 72/81 [00:08<00:00,  9.52it/s] 90%|█████████ | 73/81 [00:08<00:00,  9.54it/s] 91%|█████████▏| 74/81 [00:08<00:00,  9.53it/s] 93%|█████████▎| 75/81 [00:08<00:00,  9.55it/s] 94%|█████████▍| 76/81 [00:09<00:00,  9.56it/s] 95%|█████████▌| 77/81 [00:09<00:00,  9.56it/s] 96%|█████████▋| 78/81 [00:09<00:00,  9.57it/s] 98%|█████████▊| 79/81 [00:09<00:00,  9.58it/s] 99%|█████████▉| 80/81 [00:09<00:00,  9.59it/s]100%|██████████| 81/81 [00:09<00:00,  9.59it/s]100%|██████████| 81/81 [00:09<00:00,  8.38it/s]
=> result
* total: 8,100
* correct: 6,913
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 85.1%
Elapsed: 0:02:57
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_train.sh eurosat 2 0 vit_b16_ctxv1 16 CoOp
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_2.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/200] batch [5/5] time 0.054 (0.502) data 0.000 (0.162) loss 2.2324 (2.0641) acc 15.6250 (27.5000) lr 2.0000e-03 eta 0:08:19
epoch [2/200] batch [5/5] time 0.052 (0.148) data 0.000 (0.096) loss 1.9805 (1.9596) acc 28.1250 (26.8750) lr 1.9999e-03 eta 0:02:26
epoch [3/200] batch [5/5] time 0.052 (0.146) data 0.000 (0.095) loss 1.7285 (1.7213) acc 40.6250 (36.2500) lr 1.9995e-03 eta 0:02:23
epoch [4/200] batch [5/5] time 0.049 (0.150) data 0.000 (0.099) loss 1.7490 (1.6568) acc 46.8750 (42.5000) lr 1.9989e-03 eta 0:02:26
epoch [5/200] batch [5/5] time 0.048 (0.145) data 0.000 (0.094) loss 1.3945 (1.5658) acc 62.5000 (44.3750) lr 1.9980e-03 eta 0:02:21
epoch [6/200] batch [5/5] time 0.051 (0.144) data 0.000 (0.093) loss 1.6240 (1.5352) acc 50.0000 (50.6250) lr 1.9969e-03 eta 0:02:19
epoch [7/200] batch [5/5] time 0.048 (0.151) data 0.000 (0.101) loss 1.5518 (1.5379) acc 34.3750 (40.6250) lr 1.9956e-03 eta 0:02:26
epoch [8/200] batch [5/5] time 0.048 (0.143) data 0.000 (0.091) loss 1.7266 (1.4486) acc 34.3750 (48.7500) lr 1.9940e-03 eta 0:02:17
epoch [9/200] batch [5/5] time 0.052 (0.142) data 0.000 (0.090) loss 1.3525 (1.2439) acc 40.6250 (55.0000) lr 1.9921e-03 eta 0:02:15
epoch [10/200] batch [5/5] time 0.054 (0.143) data 0.000 (0.090) loss 1.0762 (1.2371) acc 56.2500 (58.7500) lr 1.9900e-03 eta 0:02:15
epoch [11/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.093) loss 1.3496 (1.3830) acc 53.1250 (55.6250) lr 1.9877e-03 eta 0:02:15
epoch [12/200] batch [5/5] time 0.057 (0.148) data 0.000 (0.095) loss 1.3877 (1.3480) acc 56.2500 (55.0000) lr 1.9851e-03 eta 0:02:18
epoch [13/200] batch [5/5] time 0.051 (0.151) data 0.000 (0.100) loss 1.3662 (1.3492) acc 56.2500 (55.0000) lr 1.9823e-03 eta 0:02:21
epoch [14/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.101) loss 0.9868 (1.1485) acc 71.8750 (60.6250) lr 1.9792e-03 eta 0:02:21
epoch [15/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.092) loss 1.1416 (1.1352) acc 65.6250 (65.0000) lr 1.9759e-03 eta 0:02:13
epoch [16/200] batch [5/5] time 0.053 (0.150) data 0.000 (0.099) loss 1.2344 (1.0646) acc 56.2500 (64.3750) lr 1.9724e-03 eta 0:02:18
epoch [17/200] batch [5/5] time 0.047 (0.142) data 0.000 (0.092) loss 0.9429 (1.1202) acc 68.7500 (65.0000) lr 1.9686e-03 eta 0:02:10
epoch [18/200] batch [5/5] time 0.050 (0.143) data 0.000 (0.092) loss 1.0332 (1.1232) acc 68.7500 (60.0000) lr 1.9646e-03 eta 0:02:09
epoch [19/200] batch [5/5] time 0.047 (0.146) data 0.000 (0.095) loss 1.3564 (1.1958) acc 53.1250 (61.2500) lr 1.9603e-03 eta 0:02:12
epoch [20/200] batch [5/5] time 0.047 (0.146) data 0.000 (0.095) loss 1.1787 (1.0996) acc 65.6250 (61.8750) lr 1.9558e-03 eta 0:02:11
epoch [21/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.093) loss 1.2246 (1.0147) acc 59.3750 (70.0000) lr 1.9511e-03 eta 0:02:09
epoch [22/200] batch [5/5] time 0.054 (0.145) data 0.000 (0.093) loss 1.0762 (1.0034) acc 62.5000 (70.6250) lr 1.9461e-03 eta 0:02:09
epoch [23/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.099) loss 1.0586 (0.9686) acc 71.8750 (68.1250) lr 1.9409e-03 eta 0:02:14
epoch [24/200] batch [5/5] time 0.049 (0.146) data 0.000 (0.095) loss 1.1035 (0.9999) acc 59.3750 (64.3750) lr 1.9354e-03 eta 0:02:08
epoch [25/200] batch [5/5] time 0.048 (0.147) data 0.000 (0.096) loss 0.8599 (0.9996) acc 81.2500 (70.6250) lr 1.9298e-03 eta 0:02:08
epoch [26/200] batch [5/5] time 0.048 (0.149) data 0.000 (0.098) loss 0.8193 (0.9896) acc 87.5000 (69.3750) lr 1.9239e-03 eta 0:02:09
epoch [27/200] batch [5/5] time 0.052 (0.145) data 0.000 (0.094) loss 0.8394 (0.9309) acc 81.2500 (71.2500) lr 1.9178e-03 eta 0:02:05
epoch [28/200] batch [5/5] time 0.048 (0.149) data 0.000 (0.098) loss 0.9790 (0.8855) acc 65.6250 (73.1250) lr 1.9114e-03 eta 0:02:08
epoch [29/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.094) loss 0.9263 (0.8736) acc 71.8750 (74.3750) lr 1.9048e-03 eta 0:02:04
epoch [30/200] batch [5/5] time 0.052 (0.142) data 0.000 (0.090) loss 0.6206 (0.8256) acc 84.3750 (73.7500) lr 1.8980e-03 eta 0:02:00
epoch [31/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.095) loss 0.7261 (0.8991) acc 75.0000 (70.0000) lr 1.8910e-03 eta 0:02:03
epoch [32/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.093) loss 1.1279 (0.7762) acc 56.2500 (76.8750) lr 1.8838e-03 eta 0:02:01
epoch [33/200] batch [5/5] time 0.048 (0.148) data 0.000 (0.097) loss 0.8052 (0.7988) acc 78.1250 (75.6250) lr 1.8763e-03 eta 0:02:03
epoch [34/200] batch [5/5] time 0.049 (0.150) data 0.000 (0.100) loss 0.9756 (0.8021) acc 71.8750 (74.3750) lr 1.8686e-03 eta 0:02:04
epoch [35/200] batch [5/5] time 0.048 (0.150) data 0.000 (0.099) loss 0.8945 (0.8016) acc 65.6250 (73.7500) lr 1.8607e-03 eta 0:02:04
epoch [36/200] batch [5/5] time 0.054 (0.143) data 0.000 (0.093) loss 0.5640 (0.7304) acc 84.3750 (76.2500) lr 1.8526e-03 eta 0:01:57
epoch [37/200] batch [5/5] time 0.053 (0.150) data 0.000 (0.096) loss 1.0059 (0.8059) acc 68.7500 (74.3750) lr 1.8443e-03 eta 0:02:02
epoch [38/200] batch [5/5] time 0.047 (0.151) data 0.000 (0.099) loss 0.8027 (0.8448) acc 68.7500 (74.3750) lr 1.8358e-03 eta 0:02:02
epoch [39/200] batch [5/5] time 0.055 (0.151) data 0.000 (0.099) loss 0.8672 (0.7930) acc 68.7500 (73.1250) lr 1.8271e-03 eta 0:02:01
epoch [40/200] batch [5/5] time 0.055 (0.144) data 0.000 (0.092) loss 0.8604 (0.8853) acc 71.8750 (71.8750) lr 1.8181e-03 eta 0:01:55
epoch [41/200] batch [5/5] time 0.051 (0.143) data 0.000 (0.091) loss 0.9170 (0.8596) acc 71.8750 (74.3750) lr 1.8090e-03 eta 0:01:53
epoch [42/200] batch [5/5] time 0.048 (0.145) data 0.000 (0.094) loss 0.7944 (0.8372) acc 75.0000 (75.0000) lr 1.7997e-03 eta 0:01:54
epoch [43/200] batch [5/5] time 0.050 (0.148) data 0.000 (0.097) loss 0.7944 (0.7270) acc 68.7500 (74.3750) lr 1.7902e-03 eta 0:01:56
epoch [44/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.095) loss 0.8208 (0.7664) acc 75.0000 (76.8750) lr 1.7804e-03 eta 0:01:54
epoch [45/200] batch [5/5] time 0.052 (0.145) data 0.000 (0.092) loss 0.8906 (0.6853) acc 59.3750 (76.2500) lr 1.7705e-03 eta 0:01:52
epoch [46/200] batch [5/5] time 0.048 (0.150) data 0.000 (0.098) loss 0.7275 (0.7370) acc 78.1250 (76.8750) lr 1.7604e-03 eta 0:01:55
epoch [47/200] batch [5/5] time 0.049 (0.151) data 0.000 (0.099) loss 0.8447 (0.7182) acc 75.0000 (77.5000) lr 1.7501e-03 eta 0:01:55
epoch [48/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.094) loss 0.7573 (0.6942) acc 71.8750 (76.2500) lr 1.7396e-03 eta 0:01:50
epoch [49/200] batch [5/5] time 0.057 (0.151) data 0.000 (0.099) loss 0.7593 (0.6825) acc 78.1250 (77.5000) lr 1.7290e-03 eta 0:01:54
epoch [50/200] batch [5/5] time 0.048 (0.147) data 0.000 (0.095) loss 0.5776 (0.6797) acc 81.2500 (78.1250) lr 1.7181e-03 eta 0:01:50
epoch [51/200] batch [5/5] time 0.053 (0.141) data 0.000 (0.090) loss 0.6846 (0.7573) acc 65.6250 (71.8750) lr 1.7071e-03 eta 0:01:45
epoch [52/200] batch [5/5] time 0.055 (0.150) data 0.000 (0.095) loss 0.8345 (0.7474) acc 68.7500 (75.0000) lr 1.6959e-03 eta 0:01:50
epoch [53/200] batch [5/5] time 0.051 (0.148) data 0.000 (0.096) loss 0.6880 (0.6784) acc 78.1250 (78.1250) lr 1.6845e-03 eta 0:01:48
epoch [54/200] batch [5/5] time 0.051 (0.143) data 0.000 (0.092) loss 0.7300 (0.6427) acc 71.8750 (79.3750) lr 1.6730e-03 eta 0:01:44
epoch [55/200] batch [5/5] time 0.048 (0.142) data 0.000 (0.090) loss 0.6855 (0.6588) acc 75.0000 (77.5000) lr 1.6613e-03 eta 0:01:42
epoch [56/200] batch [5/5] time 0.051 (0.149) data 0.000 (0.098) loss 0.9189 (0.6684) acc 71.8750 (81.8750) lr 1.6494e-03 eta 0:01:47
epoch [57/200] batch [5/5] time 0.055 (0.151) data 0.000 (0.096) loss 0.7651 (0.6621) acc 75.0000 (77.5000) lr 1.6374e-03 eta 0:01:47
epoch [58/200] batch [5/5] time 0.051 (0.153) data 0.000 (0.101) loss 0.6655 (0.6160) acc 84.3750 (83.7500) lr 1.6252e-03 eta 0:01:48
epoch [59/200] batch [5/5] time 0.049 (0.150) data 0.000 (0.098) loss 0.5737 (0.6231) acc 84.3750 (81.2500) lr 1.6129e-03 eta 0:01:45
epoch [60/200] batch [5/5] time 0.047 (0.144) data 0.000 (0.093) loss 0.6050 (0.6428) acc 71.8750 (74.3750) lr 1.6004e-03 eta 0:01:40
epoch [61/200] batch [5/5] time 0.054 (0.149) data 0.000 (0.097) loss 1.0576 (0.7175) acc 75.0000 (76.8750) lr 1.5878e-03 eta 0:01:43
epoch [62/200] batch [5/5] time 0.047 (0.149) data 0.000 (0.098) loss 0.7251 (0.6971) acc 75.0000 (78.7500) lr 1.5750e-03 eta 0:01:42
epoch [63/200] batch [5/5] time 0.055 (0.148) data 0.000 (0.095) loss 0.4924 (0.5435) acc 87.5000 (85.0000) lr 1.5621e-03 eta 0:01:41
epoch [64/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.094) loss 0.6338 (0.6079) acc 68.7500 (78.7500) lr 1.5490e-03 eta 0:01:39
epoch [65/200] batch [5/5] time 0.054 (0.154) data 0.000 (0.099) loss 0.5039 (0.5247) acc 84.3750 (84.3750) lr 1.5358e-03 eta 0:01:43
epoch [66/200] batch [5/5] time 0.048 (0.143) data 0.000 (0.091) loss 0.7090 (0.6070) acc 84.3750 (81.8750) lr 1.5225e-03 eta 0:01:35
epoch [67/200] batch [5/5] time 0.051 (0.143) data 0.000 (0.091) loss 0.4824 (0.4681) acc 84.3750 (86.8750) lr 1.5090e-03 eta 0:01:35
epoch [68/200] batch [5/5] time 0.054 (0.150) data 0.000 (0.095) loss 0.5181 (0.6476) acc 87.5000 (80.6250) lr 1.4955e-03 eta 0:01:38
epoch [69/200] batch [5/5] time 0.051 (0.145) data 0.000 (0.093) loss 0.4683 (0.6472) acc 84.3750 (78.7500) lr 1.4818e-03 eta 0:01:34
epoch [70/200] batch [5/5] time 0.048 (0.149) data 0.000 (0.096) loss 0.6489 (0.6029) acc 84.3750 (77.5000) lr 1.4679e-03 eta 0:01:36
epoch [71/200] batch [5/5] time 0.051 (0.148) data 0.000 (0.096) loss 0.4727 (0.5703) acc 87.5000 (80.0000) lr 1.4540e-03 eta 0:01:35
epoch [72/200] batch [5/5] time 0.052 (0.153) data 0.000 (0.100) loss 0.6304 (0.5834) acc 84.3750 (83.7500) lr 1.4399e-03 eta 0:01:38
epoch [73/200] batch [5/5] time 0.051 (0.144) data 0.000 (0.092) loss 0.5332 (0.4777) acc 81.2500 (86.8750) lr 1.4258e-03 eta 0:01:31
epoch [74/200] batch [5/5] time 0.050 (0.146) data 0.000 (0.096) loss 0.5464 (0.6162) acc 75.0000 (78.7500) lr 1.4115e-03 eta 0:01:32
epoch [75/200] batch [5/5] time 0.050 (0.147) data 0.000 (0.096) loss 0.4297 (0.4775) acc 90.6250 (87.5000) lr 1.3971e-03 eta 0:01:32
epoch [76/200] batch [5/5] time 0.051 (0.144) data 0.000 (0.092) loss 0.4722 (0.6465) acc 84.3750 (80.0000) lr 1.3827e-03 eta 0:01:29
epoch [77/200] batch [5/5] time 0.051 (0.144) data 0.000 (0.092) loss 0.4509 (0.5273) acc 90.6250 (86.2500) lr 1.3681e-03 eta 0:01:28
epoch [78/200] batch [5/5] time 0.048 (0.145) data 0.000 (0.094) loss 0.6299 (0.6012) acc 75.0000 (79.3750) lr 1.3535e-03 eta 0:01:28
epoch [79/200] batch [5/5] time 0.052 (0.142) data 0.000 (0.090) loss 0.4578 (0.5183) acc 87.5000 (83.1250) lr 1.3387e-03 eta 0:01:25
epoch [80/200] batch [5/5] time 0.047 (0.147) data 0.000 (0.096) loss 0.4192 (0.5677) acc 84.3750 (81.8750) lr 1.3239e-03 eta 0:01:28
epoch [81/200] batch [5/5] time 0.048 (0.142) data 0.000 (0.094) loss 0.9038 (0.6392) acc 78.1250 (79.3750) lr 1.3090e-03 eta 0:01:24
epoch [82/200] batch [5/5] time 0.047 (0.152) data 0.000 (0.100) loss 0.3330 (0.5230) acc 90.6250 (83.1250) lr 1.2940e-03 eta 0:01:29
epoch [83/200] batch [5/5] time 0.051 (0.147) data 0.000 (0.095) loss 0.5073 (0.5326) acc 84.3750 (83.7500) lr 1.2790e-03 eta 0:01:25
epoch [84/200] batch [5/5] time 0.055 (0.150) data 0.000 (0.097) loss 0.5488 (0.6034) acc 81.2500 (81.2500) lr 1.2639e-03 eta 0:01:26
epoch [85/200] batch [5/5] time 0.049 (0.148) data 0.000 (0.096) loss 0.4302 (0.4945) acc 90.6250 (88.1250) lr 1.2487e-03 eta 0:01:25
epoch [86/200] batch [5/5] time 0.055 (0.146) data 0.000 (0.093) loss 0.3933 (0.4734) acc 90.6250 (87.5000) lr 1.2334e-03 eta 0:01:23
epoch [87/200] batch [5/5] time 0.051 (0.145) data 0.000 (0.093) loss 0.3752 (0.5278) acc 93.7500 (85.6250) lr 1.2181e-03 eta 0:01:21
epoch [88/200] batch [5/5] time 0.048 (0.147) data 0.000 (0.096) loss 0.3462 (0.4773) acc 87.5000 (86.8750) lr 1.2028e-03 eta 0:01:22
epoch [89/200] batch [5/5] time 0.049 (0.144) data 0.000 (0.094) loss 0.5264 (0.5010) acc 87.5000 (85.6250) lr 1.1874e-03 eta 0:01:20
epoch [90/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.095) loss 0.5337 (0.4805) acc 81.2500 (84.3750) lr 1.1719e-03 eta 0:01:20
epoch [91/200] batch [5/5] time 0.054 (0.148) data 0.000 (0.096) loss 0.3826 (0.4616) acc 93.7500 (85.6250) lr 1.1564e-03 eta 0:01:20
epoch [92/200] batch [5/5] time 0.054 (0.149) data 0.000 (0.096) loss 0.5801 (0.5112) acc 78.1250 (80.6250) lr 1.1409e-03 eta 0:01:20
epoch [93/200] batch [5/5] time 0.050 (0.148) data 0.000 (0.096) loss 0.5044 (0.5206) acc 84.3750 (83.7500) lr 1.1253e-03 eta 0:01:19
epoch [94/200] batch [5/5] time 0.049 (0.152) data 0.000 (0.099) loss 0.7114 (0.5265) acc 78.1250 (85.0000) lr 1.1097e-03 eta 0:01:20
epoch [95/200] batch [5/5] time 0.047 (0.141) data 0.000 (0.093) loss 0.6865 (0.5087) acc 84.3750 (83.1250) lr 1.0941e-03 eta 0:01:14
epoch [96/200] batch [5/5] time 0.052 (0.146) data 0.000 (0.096) loss 0.5942 (0.5408) acc 81.2500 (81.2500) lr 1.0785e-03 eta 0:01:15
epoch [97/200] batch [5/5] time 0.051 (0.149) data 0.000 (0.097) loss 0.5220 (0.5042) acc 81.2500 (86.2500) lr 1.0628e-03 eta 0:01:16
epoch [98/200] batch [5/5] time 0.053 (0.142) data 0.000 (0.091) loss 0.4053 (0.4642) acc 84.3750 (80.6250) lr 1.0471e-03 eta 0:01:12
epoch [99/200] batch [5/5] time 0.048 (0.148) data 0.000 (0.096) loss 0.5000 (0.5192) acc 81.2500 (84.3750) lr 1.0314e-03 eta 0:01:14
epoch [100/200] batch [5/5] time 0.053 (0.143) data 0.000 (0.091) loss 0.3987 (0.4079) acc 90.6250 (88.1250) lr 1.0157e-03 eta 0:01:11
epoch [101/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.094) loss 0.8569 (0.5767) acc 59.3750 (80.0000) lr 1.0000e-03 eta 0:01:10
epoch [102/200] batch [5/5] time 0.053 (0.148) data 0.000 (0.095) loss 0.7529 (0.5021) acc 75.0000 (85.0000) lr 9.8429e-04 eta 0:01:12
epoch [103/200] batch [5/5] time 0.048 (0.142) data 0.000 (0.091) loss 0.6729 (0.5370) acc 84.3750 (83.7500) lr 9.6859e-04 eta 0:01:08
epoch [104/200] batch [5/5] time 0.047 (0.152) data 0.000 (0.101) loss 0.5718 (0.5088) acc 78.1250 (82.5000) lr 9.5289e-04 eta 0:01:12
epoch [105/200] batch [5/5] time 0.054 (0.150) data 0.000 (0.098) loss 0.5957 (0.4618) acc 78.1250 (86.8750) lr 9.3721e-04 eta 0:01:11
epoch [106/200] batch [5/5] time 0.055 (0.147) data 0.000 (0.095) loss 0.3489 (0.4581) acc 93.7500 (88.7500) lr 9.2154e-04 eta 0:01:09
epoch [107/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.092) loss 0.4246 (0.4921) acc 90.6250 (81.2500) lr 9.0589e-04 eta 0:01:07
epoch [108/200] batch [5/5] time 0.053 (0.143) data 0.000 (0.090) loss 0.3464 (0.4104) acc 96.8750 (90.0000) lr 8.9027e-04 eta 0:01:05
epoch [109/200] batch [5/5] time 0.054 (0.151) data 0.000 (0.097) loss 0.5820 (0.4344) acc 81.2500 (87.5000) lr 8.7467e-04 eta 0:01:08
epoch [110/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.097) loss 0.6143 (0.5210) acc 81.2500 (81.8750) lr 8.5910e-04 eta 0:01:07
epoch [111/200] batch [5/5] time 0.048 (0.147) data 0.000 (0.094) loss 0.2856 (0.4447) acc 90.6250 (88.1250) lr 8.4357e-04 eta 0:01:05
epoch [112/200] batch [5/5] time 0.048 (0.146) data 0.000 (0.094) loss 0.5483 (0.4901) acc 87.5000 (86.8750) lr 8.2807e-04 eta 0:01:04
epoch [113/200] batch [5/5] time 0.052 (0.153) data 0.000 (0.099) loss 0.4844 (0.4776) acc 90.6250 (86.2500) lr 8.1262e-04 eta 0:01:06
epoch [114/200] batch [5/5] time 0.051 (0.148) data 0.000 (0.098) loss 0.3997 (0.4314) acc 87.5000 (86.8750) lr 7.9721e-04 eta 0:01:03
epoch [115/200] batch [5/5] time 0.049 (0.140) data 0.000 (0.090) loss 0.3901 (0.5248) acc 84.3750 (81.2500) lr 7.8186e-04 eta 0:00:59
epoch [116/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.091) loss 0.4714 (0.4924) acc 87.5000 (84.3750) lr 7.6655e-04 eta 0:01:00
epoch [117/200] batch [5/5] time 0.048 (0.144) data 0.000 (0.093) loss 0.7266 (0.4800) acc 68.7500 (84.3750) lr 7.5131e-04 eta 0:00:59
epoch [118/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.097) loss 0.5493 (0.4834) acc 81.2500 (83.1250) lr 7.3613e-04 eta 0:01:01
epoch [119/200] batch [5/5] time 0.054 (0.152) data 0.000 (0.101) loss 0.8330 (0.5417) acc 71.8750 (83.1250) lr 7.2101e-04 eta 0:01:01
epoch [120/200] batch [5/5] time 0.049 (0.141) data 0.000 (0.092) loss 0.5928 (0.5054) acc 78.1250 (86.2500) lr 7.0596e-04 eta 0:00:56
epoch [121/200] batch [5/5] time 0.053 (0.153) data 0.000 (0.102) loss 0.6582 (0.5761) acc 75.0000 (80.0000) lr 6.9098e-04 eta 0:01:00
epoch [122/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.095) loss 0.4199 (0.5003) acc 87.5000 (84.3750) lr 6.7608e-04 eta 0:00:57
epoch [123/200] batch [5/5] time 0.051 (0.147) data 0.000 (0.095) loss 0.6318 (0.5143) acc 84.3750 (83.7500) lr 6.6126e-04 eta 0:00:56
epoch [124/200] batch [5/5] time 0.048 (0.141) data 0.000 (0.089) loss 0.6821 (0.4470) acc 78.1250 (85.6250) lr 6.4653e-04 eta 0:00:53
epoch [125/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.095) loss 0.4292 (0.4781) acc 87.5000 (83.1250) lr 6.3188e-04 eta 0:00:54
epoch [126/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.091) loss 0.5210 (0.5062) acc 78.1250 (81.8750) lr 6.1732e-04 eta 0:00:53
epoch [127/200] batch [5/5] time 0.050 (0.144) data 0.000 (0.092) loss 0.7534 (0.4840) acc 81.2500 (90.0000) lr 6.0285e-04 eta 0:00:52
epoch [128/200] batch [5/5] time 0.048 (0.144) data 0.000 (0.092) loss 0.3943 (0.4158) acc 90.6250 (87.5000) lr 5.8849e-04 eta 0:00:51
epoch [129/200] batch [5/5] time 0.047 (0.147) data 0.000 (0.096) loss 0.5864 (0.4333) acc 87.5000 (88.1250) lr 5.7422e-04 eta 0:00:52
epoch [130/200] batch [5/5] time 0.056 (0.147) data 0.000 (0.093) loss 0.4373 (0.3574) acc 87.5000 (92.5000) lr 5.6006e-04 eta 0:00:51
epoch [131/200] batch [5/5] time 0.055 (0.147) data 0.000 (0.092) loss 0.4092 (0.4172) acc 87.5000 (86.2500) lr 5.4601e-04 eta 0:00:50
epoch [132/200] batch [5/5] time 0.054 (0.148) data 0.000 (0.094) loss 0.5703 (0.5005) acc 84.3750 (84.3750) lr 5.3207e-04 eta 0:00:50
epoch [133/200] batch [5/5] time 0.050 (0.151) data 0.000 (0.100) loss 0.3384 (0.3629) acc 90.6250 (87.5000) lr 5.1825e-04 eta 0:00:50
epoch [134/200] batch [5/5] time 0.054 (0.149) data 0.000 (0.097) loss 0.5596 (0.4984) acc 84.3750 (85.0000) lr 5.0454e-04 eta 0:00:49
epoch [135/200] batch [5/5] time 0.050 (0.149) data 0.000 (0.099) loss 0.3379 (0.3892) acc 90.6250 (89.3750) lr 4.9096e-04 eta 0:00:48
epoch [136/200] batch [5/5] time 0.053 (0.151) data 0.000 (0.096) loss 0.7056 (0.5118) acc 81.2500 (85.0000) lr 4.7750e-04 eta 0:00:48
epoch [137/200] batch [5/5] time 0.048 (0.151) data 0.000 (0.099) loss 0.3762 (0.4304) acc 93.7500 (86.8750) lr 4.6417e-04 eta 0:00:47
epoch [138/200] batch [5/5] time 0.051 (0.151) data 0.000 (0.100) loss 0.4424 (0.4468) acc 81.2500 (83.7500) lr 4.5098e-04 eta 0:00:46
epoch [139/200] batch [5/5] time 0.055 (0.149) data 0.000 (0.097) loss 0.4473 (0.4015) acc 78.1250 (88.1250) lr 4.3792e-04 eta 0:00:45
epoch [140/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.097) loss 0.4448 (0.4476) acc 84.3750 (86.2500) lr 4.2499e-04 eta 0:00:45
epoch [141/200] batch [5/5] time 0.048 (0.147) data 0.000 (0.095) loss 0.6987 (0.3951) acc 75.0000 (88.7500) lr 4.1221e-04 eta 0:00:43
epoch [142/200] batch [5/5] time 0.048 (0.141) data 0.000 (0.089) loss 0.3484 (0.4025) acc 90.6250 (87.5000) lr 3.9958e-04 eta 0:00:40
epoch [143/200] batch [5/5] time 0.052 (0.151) data 0.000 (0.100) loss 0.4609 (0.4488) acc 84.3750 (86.2500) lr 3.8709e-04 eta 0:00:42
epoch [144/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.092) loss 0.5376 (0.4515) acc 84.3750 (85.0000) lr 3.7476e-04 eta 0:00:40
epoch [145/200] batch [5/5] time 0.052 (0.144) data 0.000 (0.092) loss 0.3997 (0.5263) acc 84.3750 (80.6250) lr 3.6258e-04 eta 0:00:39
epoch [146/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.092) loss 0.5547 (0.4344) acc 71.8750 (85.6250) lr 3.5055e-04 eta 0:00:39
epoch [147/200] batch [5/5] time 0.052 (0.148) data 0.000 (0.096) loss 0.4858 (0.4398) acc 75.0000 (86.2500) lr 3.3869e-04 eta 0:00:39
epoch [148/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.093) loss 0.4111 (0.4308) acc 87.5000 (88.7500) lr 3.2699e-04 eta 0:00:37
epoch [149/200] batch [5/5] time 0.052 (0.147) data 0.000 (0.094) loss 0.6143 (0.4967) acc 81.2500 (84.3750) lr 3.1545e-04 eta 0:00:37
epoch [150/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.092) loss 0.5522 (0.4227) acc 87.5000 (89.3750) lr 3.0409e-04 eta 0:00:36
epoch [151/200] batch [5/5] time 0.052 (0.153) data 0.000 (0.101) loss 0.4900 (0.4395) acc 90.6250 (88.7500) lr 2.9289e-04 eta 0:00:37
epoch [152/200] batch [5/5] time 0.054 (0.148) data 0.000 (0.096) loss 0.4353 (0.4167) acc 87.5000 (86.8750) lr 2.8187e-04 eta 0:00:35
epoch [153/200] batch [5/5] time 0.050 (0.142) data 0.000 (0.093) loss 0.5557 (0.4574) acc 81.2500 (85.0000) lr 2.7103e-04 eta 0:00:33
epoch [154/200] batch [5/5] time 0.050 (0.148) data 0.000 (0.097) loss 0.2986 (0.3767) acc 90.6250 (90.0000) lr 2.6037e-04 eta 0:00:34
epoch [155/200] batch [5/5] time 0.054 (0.147) data 0.000 (0.094) loss 0.5967 (0.4629) acc 84.3750 (88.1250) lr 2.4989e-04 eta 0:00:33
epoch [156/200] batch [5/5] time 0.047 (0.146) data 0.000 (0.095) loss 0.4543 (0.4064) acc 81.2500 (86.8750) lr 2.3959e-04 eta 0:00:32
epoch [157/200] batch [5/5] time 0.052 (0.146) data 0.000 (0.095) loss 0.4258 (0.4469) acc 90.6250 (85.0000) lr 2.2949e-04 eta 0:00:31
epoch [158/200] batch [5/5] time 0.052 (0.144) data 0.000 (0.093) loss 0.3806 (0.4593) acc 93.7500 (85.0000) lr 2.1957e-04 eta 0:00:30
epoch [159/200] batch [5/5] time 0.047 (0.146) data 0.000 (0.095) loss 0.3118 (0.4064) acc 96.8750 (88.7500) lr 2.0984e-04 eta 0:00:29
epoch [160/200] batch [5/5] time 0.049 (0.146) data 0.000 (0.097) loss 0.4897 (0.4821) acc 87.5000 (85.0000) lr 2.0032e-04 eta 0:00:29
epoch [161/200] batch [5/5] time 0.051 (0.144) data 0.000 (0.093) loss 0.4641 (0.4005) acc 81.2500 (86.2500) lr 1.9098e-04 eta 0:00:27
epoch [162/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.098) loss 0.3835 (0.4236) acc 90.6250 (85.0000) lr 1.8185e-04 eta 0:00:28
epoch [163/200] batch [5/5] time 0.051 (0.144) data 0.000 (0.093) loss 0.2512 (0.3552) acc 96.8750 (91.2500) lr 1.7292e-04 eta 0:00:26
epoch [164/200] batch [5/5] time 0.053 (0.151) data 0.000 (0.097) loss 0.3284 (0.3894) acc 93.7500 (90.0000) lr 1.6419e-04 eta 0:00:27
epoch [165/200] batch [5/5] time 0.055 (0.148) data 0.000 (0.095) loss 0.2937 (0.4328) acc 93.7500 (87.5000) lr 1.5567e-04 eta 0:00:25
epoch [166/200] batch [5/5] time 0.047 (0.140) data 0.000 (0.092) loss 0.6606 (0.4100) acc 81.2500 (90.0000) lr 1.4736e-04 eta 0:00:23
epoch [167/200] batch [5/5] time 0.050 (0.144) data 0.000 (0.093) loss 0.4941 (0.4157) acc 87.5000 (90.0000) lr 1.3926e-04 eta 0:00:23
epoch [168/200] batch [5/5] time 0.048 (0.152) data 0.000 (0.101) loss 0.4224 (0.4264) acc 87.5000 (88.7500) lr 1.3137e-04 eta 0:00:24
epoch [169/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.096) loss 0.4148 (0.4033) acc 93.7500 (89.3750) lr 1.2369e-04 eta 0:00:22
epoch [170/200] batch [5/5] time 0.049 (0.141) data 0.000 (0.091) loss 0.3860 (0.3647) acc 93.7500 (91.8750) lr 1.1623e-04 eta 0:00:21
epoch [171/200] batch [5/5] time 0.047 (0.145) data 0.000 (0.094) loss 0.2866 (0.3164) acc 93.7500 (91.8750) lr 1.0899e-04 eta 0:00:20
epoch [172/200] batch [5/5] time 0.047 (0.144) data 0.000 (0.096) loss 0.3862 (0.3308) acc 87.5000 (90.0000) lr 1.0197e-04 eta 0:00:20
epoch [173/200] batch [5/5] time 0.052 (0.149) data 0.000 (0.097) loss 0.2307 (0.3103) acc 93.7500 (93.1250) lr 9.5173e-05 eta 0:00:20
epoch [174/200] batch [5/5] time 0.049 (0.147) data 0.000 (0.098) loss 0.2317 (0.4137) acc 96.8750 (86.2500) lr 8.8597e-05 eta 0:00:19
epoch [175/200] batch [5/5] time 0.050 (0.147) data 0.000 (0.097) loss 0.2595 (0.4524) acc 96.8750 (87.5000) lr 8.2245e-05 eta 0:00:18
epoch [176/200] batch [5/5] time 0.050 (0.144) data 0.000 (0.093) loss 0.3845 (0.3693) acc 87.5000 (88.7500) lr 7.6120e-05 eta 0:00:17
epoch [177/200] batch [5/5] time 0.048 (0.147) data 0.000 (0.096) loss 0.4360 (0.4122) acc 81.2500 (86.8750) lr 7.0224e-05 eta 0:00:16
epoch [178/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.095) loss 0.4409 (0.3816) acc 84.3750 (90.0000) lr 6.4556e-05 eta 0:00:16
epoch [179/200] batch [5/5] time 0.054 (0.145) data 0.000 (0.093) loss 0.3491 (0.4026) acc 90.6250 (89.3750) lr 5.9119e-05 eta 0:00:15
epoch [180/200] batch [5/5] time 0.053 (0.153) data 0.000 (0.102) loss 0.3257 (0.4221) acc 93.7500 (90.6250) lr 5.3915e-05 eta 0:00:15
epoch [181/200] batch [5/5] time 0.052 (0.147) data 0.000 (0.096) loss 0.3745 (0.4843) acc 90.6250 (86.2500) lr 4.8943e-05 eta 0:00:13
epoch [182/200] batch [5/5] time 0.054 (0.153) data 0.000 (0.098) loss 0.2917 (0.3646) acc 93.7500 (90.6250) lr 4.4207e-05 eta 0:00:13
epoch [183/200] batch [5/5] time 0.051 (0.143) data 0.000 (0.092) loss 0.4739 (0.3777) acc 90.6250 (88.7500) lr 3.9706e-05 eta 0:00:12
epoch [184/200] batch [5/5] time 0.052 (0.146) data 0.000 (0.093) loss 0.2771 (0.3971) acc 93.7500 (88.1250) lr 3.5443e-05 eta 0:00:11
epoch [185/200] batch [5/5] time 0.049 (0.146) data 0.000 (0.094) loss 0.3599 (0.3616) acc 93.7500 (90.6250) lr 3.1417e-05 eta 0:00:10
epoch [186/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.097) loss 0.3972 (0.4327) acc 84.3750 (88.1250) lr 2.7630e-05 eta 0:00:10
epoch [187/200] batch [5/5] time 0.050 (0.149) data 0.000 (0.099) loss 0.5386 (0.4142) acc 78.1250 (86.8750) lr 2.4083e-05 eta 0:00:09
epoch [188/200] batch [5/5] time 0.048 (0.149) data 0.000 (0.099) loss 0.4089 (0.3760) acc 87.5000 (89.3750) lr 2.0777e-05 eta 0:00:08
epoch [189/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.092) loss 0.3208 (0.4185) acc 90.6250 (89.3750) lr 1.7713e-05 eta 0:00:07
epoch [190/200] batch [5/5] time 0.052 (0.142) data 0.000 (0.092) loss 0.3889 (0.3532) acc 90.6250 (90.6250) lr 1.4891e-05 eta 0:00:07
epoch [191/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.099) loss 0.5537 (0.4440) acc 84.3750 (89.3750) lr 1.2312e-05 eta 0:00:06
epoch [192/200] batch [5/5] time 0.054 (0.148) data 0.000 (0.094) loss 0.3560 (0.4115) acc 90.6250 (86.2500) lr 9.9763e-06 eta 0:00:05
epoch [193/200] batch [5/5] time 0.048 (0.152) data 0.000 (0.101) loss 0.3828 (0.4132) acc 87.5000 (85.6250) lr 7.8853e-06 eta 0:00:05
epoch [194/200] batch [5/5] time 0.048 (0.151) data 0.000 (0.099) loss 0.4473 (0.4407) acc 87.5000 (86.8750) lr 6.0390e-06 eta 0:00:04
epoch [195/200] batch [5/5] time 0.048 (0.146) data 0.000 (0.094) loss 0.3879 (0.4458) acc 87.5000 (88.1250) lr 4.4380e-06 eta 0:00:03
epoch [196/200] batch [5/5] time 0.048 (0.147) data 0.000 (0.095) loss 0.2220 (0.3973) acc 100.0000 (88.7500) lr 3.0827e-06 eta 0:00:02
epoch [197/200] batch [5/5] time 0.047 (0.147) data 0.000 (0.096) loss 0.2847 (0.4523) acc 93.7500 (84.3750) lr 1.9733e-06 eta 0:00:02
epoch [198/200] batch [5/5] time 0.048 (0.153) data 0.000 (0.102) loss 0.2981 (0.3559) acc 96.8750 (90.0000) lr 1.1101e-06 eta 0:00:01
epoch [199/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.093) loss 0.3418 (0.4662) acc 96.8750 (87.5000) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [5/5] time 0.047 (0.140) data 0.000 (0.090) loss 0.3333 (0.4229) acc 87.5000 (86.8750) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:01<01:23,  1.04s/it]  2%|▏         | 2/81 [00:01<00:40,  1.97it/s]  4%|▎         | 3/81 [00:01<00:25,  3.02it/s]  5%|▍         | 4/81 [00:01<00:18,  4.13it/s]  6%|▌         | 5/81 [00:01<00:14,  5.18it/s]  7%|▋         | 6/81 [00:01<00:12,  6.12it/s]  9%|▊         | 7/81 [00:01<00:10,  6.94it/s] 10%|▉         | 8/81 [00:01<00:09,  7.59it/s] 11%|█         | 9/81 [00:01<00:08,  8.09it/s] 12%|█▏        | 10/81 [00:02<00:08,  8.47it/s] 14%|█▎        | 11/81 [00:02<00:07,  8.76it/s] 15%|█▍        | 12/81 [00:02<00:07,  8.96it/s] 16%|█▌        | 13/81 [00:02<00:07,  9.11it/s] 17%|█▋        | 14/81 [00:02<00:07,  9.21it/s] 19%|█▊        | 15/81 [00:02<00:07,  9.28it/s] 20%|█▉        | 16/81 [00:02<00:06,  9.34it/s] 21%|██        | 17/81 [00:02<00:06,  9.38it/s] 22%|██▏       | 18/81 [00:02<00:06,  9.40it/s] 23%|██▎       | 19/81 [00:02<00:06,  9.42it/s] 25%|██▍       | 20/81 [00:03<00:06,  9.43it/s] 26%|██▌       | 21/81 [00:03<00:06,  9.44it/s] 27%|██▋       | 22/81 [00:03<00:06,  9.45it/s] 28%|██▊       | 23/81 [00:03<00:06,  9.46it/s] 30%|██▉       | 24/81 [00:03<00:06,  9.46it/s] 31%|███       | 25/81 [00:03<00:05,  9.48it/s] 32%|███▏      | 26/81 [00:03<00:05,  9.47it/s] 33%|███▎      | 27/81 [00:03<00:05,  9.42it/s] 35%|███▍      | 28/81 [00:03<00:06,  8.66it/s] 36%|███▌      | 29/81 [00:04<00:05,  8.92it/s] 37%|███▋      | 30/81 [00:04<00:05,  9.10it/s] 38%|███▊      | 31/81 [00:04<00:05,  9.20it/s] 40%|███▉      | 32/81 [00:04<00:05,  9.28it/s] 41%|████      | 33/81 [00:04<00:05,  9.33it/s] 42%|████▏     | 34/81 [00:04<00:05,  9.38it/s] 43%|████▎     | 35/81 [00:04<00:04,  9.41it/s] 44%|████▍     | 36/81 [00:04<00:04,  9.40it/s] 46%|████▌     | 37/81 [00:04<00:04,  9.42it/s] 47%|████▋     | 38/81 [00:05<00:04,  9.44it/s] 48%|████▊     | 39/81 [00:05<00:04,  9.44it/s] 49%|████▉     | 40/81 [00:05<00:04,  9.44it/s] 51%|█████     | 41/81 [00:05<00:04,  9.46it/s] 52%|█████▏    | 42/81 [00:05<00:04,  9.45it/s] 53%|█████▎    | 43/81 [00:05<00:04,  9.45it/s] 54%|█████▍    | 44/81 [00:05<00:03,  9.45it/s] 56%|█████▌    | 45/81 [00:05<00:03,  9.46it/s] 57%|█████▋    | 46/81 [00:05<00:03,  9.46it/s] 58%|█████▊    | 47/81 [00:05<00:03,  9.46it/s] 59%|█████▉    | 48/81 [00:06<00:03,  9.48it/s] 60%|██████    | 49/81 [00:06<00:03,  9.47it/s] 62%|██████▏   | 50/81 [00:06<00:03,  9.47it/s] 63%|██████▎   | 51/81 [00:06<00:03,  9.48it/s] 64%|██████▍   | 52/81 [00:06<00:03,  9.48it/s] 65%|██████▌   | 53/81 [00:06<00:02,  9.47it/s] 67%|██████▋   | 54/81 [00:06<00:02,  9.48it/s] 68%|██████▊   | 55/81 [00:06<00:02,  9.47it/s] 69%|██████▉   | 56/81 [00:06<00:02,  9.47it/s] 70%|███████   | 57/81 [00:07<00:02,  9.47it/s] 72%|███████▏  | 58/81 [00:07<00:02,  9.45it/s] 73%|███████▎  | 59/81 [00:07<00:02,  9.46it/s] 74%|███████▍  | 60/81 [00:07<00:02,  9.46it/s] 75%|███████▌  | 61/81 [00:07<00:02,  9.46it/s] 77%|███████▋  | 62/81 [00:07<00:02,  9.46it/s] 78%|███████▊  | 63/81 [00:07<00:01,  9.47it/s] 79%|███████▉  | 64/81 [00:07<00:01,  9.46it/s] 80%|████████  | 65/81 [00:07<00:01,  9.47it/s] 81%|████████▏ | 66/81 [00:07<00:01,  9.48it/s] 83%|████████▎ | 67/81 [00:08<00:01,  9.48it/s] 84%|████████▍ | 68/81 [00:08<00:01,  9.47it/s] 85%|████████▌ | 69/81 [00:08<00:01,  9.50it/s] 86%|████████▋ | 70/81 [00:08<00:01,  9.53it/s] 88%|████████▊ | 71/81 [00:08<00:01,  9.54it/s] 89%|████████▉ | 72/81 [00:08<00:00,  9.56it/s] 90%|█████████ | 73/81 [00:08<00:00,  9.57it/s] 91%|█████████▏| 74/81 [00:08<00:00,  9.58it/s] 93%|█████████▎| 75/81 [00:08<00:00,  9.58it/s] 94%|█████████▍| 76/81 [00:09<00:00,  9.58it/s] 95%|█████████▌| 77/81 [00:09<00:00,  9.58it/s] 96%|█████████▋| 78/81 [00:09<00:00,  9.59it/s] 98%|█████████▊| 79/81 [00:09<00:00,  9.58it/s] 99%|█████████▉| 80/81 [00:09<00:00,  9.59it/s]100%|██████████| 81/81 [00:09<00:00,  9.59it/s]100%|██████████| 81/81 [00:09<00:00,  8.38it/s]
=> result
* total: 8,100
* correct: 6,788
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 83.6%
Elapsed: 0:02:57
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_train.sh eurosat 3 0 vit_b16_ctxv1 16 CoOp
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_3.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/200] batch [5/5] time 0.056 (0.497) data 0.000 (0.162) loss 2.6582 (2.1090) acc 12.5000 (22.5000) lr 2.0000e-03 eta 0:08:14
epoch [2/200] batch [5/5] time 0.054 (0.150) data 0.000 (0.098) loss 1.8945 (1.9369) acc 31.2500 (31.8750) lr 1.9999e-03 eta 0:02:28
epoch [3/200] batch [5/5] time 0.049 (0.143) data 0.000 (0.091) loss 1.7266 (1.6373) acc 40.6250 (47.5000) lr 1.9995e-03 eta 0:02:20
epoch [4/200] batch [5/5] time 0.051 (0.144) data 0.000 (0.093) loss 1.6152 (1.7240) acc 43.7500 (37.5000) lr 1.9989e-03 eta 0:02:21
epoch [5/200] batch [5/5] time 0.048 (0.150) data 0.000 (0.099) loss 1.5811 (1.5621) acc 53.1250 (47.5000) lr 1.9980e-03 eta 0:02:25
epoch [6/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.094) loss 1.4150 (1.4627) acc 50.0000 (51.2500) lr 1.9969e-03 eta 0:02:21
epoch [7/200] batch [5/5] time 0.048 (0.153) data 0.000 (0.101) loss 1.6191 (1.5008) acc 50.0000 (51.2500) lr 1.9956e-03 eta 0:02:27
epoch [8/200] batch [5/5] time 0.051 (0.147) data 0.000 (0.096) loss 1.1738 (1.4199) acc 65.6250 (55.0000) lr 1.9940e-03 eta 0:02:21
epoch [9/200] batch [5/5] time 0.047 (0.144) data 0.000 (0.093) loss 1.3750 (1.3465) acc 65.6250 (60.0000) lr 1.9921e-03 eta 0:02:17
epoch [10/200] batch [5/5] time 0.050 (0.143) data 0.000 (0.094) loss 1.2686 (1.1840) acc 68.7500 (65.0000) lr 1.9900e-03 eta 0:02:16
epoch [11/200] batch [5/5] time 0.052 (0.153) data 0.000 (0.101) loss 1.3857 (1.2986) acc 53.1250 (56.8750) lr 1.9877e-03 eta 0:02:24
epoch [12/200] batch [5/5] time 0.047 (0.150) data 0.000 (0.099) loss 1.2881 (1.1633) acc 62.5000 (62.5000) lr 1.9851e-03 eta 0:02:21
epoch [13/200] batch [5/5] time 0.052 (0.142) data 0.000 (0.090) loss 1.0654 (1.1252) acc 62.5000 (66.8750) lr 1.9823e-03 eta 0:02:12
epoch [14/200] batch [5/5] time 0.054 (0.150) data 0.000 (0.097) loss 1.0479 (1.1533) acc 65.6250 (63.1250) lr 1.9792e-03 eta 0:02:19
epoch [15/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.095) loss 1.1328 (1.0119) acc 62.5000 (68.1250) lr 1.9759e-03 eta 0:02:17
epoch [16/200] batch [5/5] time 0.051 (0.147) data 0.000 (0.098) loss 1.1113 (1.1267) acc 71.8750 (67.5000) lr 1.9724e-03 eta 0:02:15
epoch [17/200] batch [5/5] time 0.052 (0.147) data 0.000 (0.094) loss 0.8726 (0.9938) acc 75.0000 (68.1250) lr 1.9686e-03 eta 0:02:14
epoch [18/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.092) loss 1.1895 (1.0165) acc 59.3750 (67.5000) lr 1.9646e-03 eta 0:02:11
epoch [19/200] batch [5/5] time 0.055 (0.148) data 0.000 (0.095) loss 1.1943 (1.0755) acc 56.2500 (64.3750) lr 1.9603e-03 eta 0:02:14
epoch [20/200] batch [5/5] time 0.047 (0.150) data 0.000 (0.102) loss 1.2930 (1.1355) acc 59.3750 (65.0000) lr 1.9558e-03 eta 0:02:15
epoch [21/200] batch [5/5] time 0.052 (0.151) data 0.000 (0.098) loss 0.8896 (1.0068) acc 75.0000 (70.0000) lr 1.9511e-03 eta 0:02:15
epoch [22/200] batch [5/5] time 0.052 (0.147) data 0.000 (0.095) loss 1.1172 (1.0430) acc 56.2500 (65.6250) lr 1.9461e-03 eta 0:02:10
epoch [23/200] batch [5/5] time 0.054 (0.145) data 0.000 (0.090) loss 0.9243 (0.9750) acc 71.8750 (70.6250) lr 1.9409e-03 eta 0:02:07
epoch [24/200] batch [5/5] time 0.048 (0.146) data 0.000 (0.095) loss 0.9795 (0.9956) acc 71.8750 (68.1250) lr 1.9354e-03 eta 0:02:08
epoch [25/200] batch [5/5] time 0.052 (0.149) data 0.000 (0.096) loss 0.9360 (1.0224) acc 71.8750 (62.5000) lr 1.9298e-03 eta 0:02:10
epoch [26/200] batch [5/5] time 0.053 (0.142) data 0.000 (0.091) loss 0.8027 (0.9491) acc 81.2500 (70.6250) lr 1.9239e-03 eta 0:02:03
epoch [27/200] batch [5/5] time 0.049 (0.143) data 0.000 (0.092) loss 0.7915 (0.9060) acc 78.1250 (71.2500) lr 1.9178e-03 eta 0:02:03
epoch [28/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.095) loss 0.5859 (0.8274) acc 87.5000 (74.3750) lr 1.9114e-03 eta 0:02:03
epoch [29/200] batch [5/5] time 0.050 (0.145) data 0.000 (0.094) loss 0.7314 (0.8673) acc 71.8750 (72.5000) lr 1.9048e-03 eta 0:02:04
epoch [30/200] batch [5/5] time 0.051 (0.147) data 0.000 (0.095) loss 1.1221 (0.8669) acc 50.0000 (73.1250) lr 1.8980e-03 eta 0:02:04
epoch [31/200] batch [5/5] time 0.047 (0.144) data 0.000 (0.093) loss 0.9482 (0.7275) acc 68.7500 (75.0000) lr 1.8910e-03 eta 0:02:01
epoch [32/200] batch [5/5] time 0.047 (0.144) data 0.000 (0.096) loss 0.8711 (0.8384) acc 68.7500 (75.6250) lr 1.8838e-03 eta 0:02:00
epoch [33/200] batch [5/5] time 0.050 (0.150) data 0.000 (0.099) loss 0.7178 (0.7388) acc 81.2500 (76.2500) lr 1.8763e-03 eta 0:02:04
epoch [34/200] batch [5/5] time 0.048 (0.144) data 0.000 (0.092) loss 0.8701 (0.8602) acc 65.6250 (70.0000) lr 1.8686e-03 eta 0:01:59
epoch [35/200] batch [5/5] time 0.052 (0.145) data 0.000 (0.092) loss 0.8862 (0.8128) acc 75.0000 (71.8750) lr 1.8607e-03 eta 0:01:59
epoch [36/200] batch [5/5] time 0.053 (0.151) data 0.000 (0.100) loss 0.9048 (0.8075) acc 75.0000 (75.0000) lr 1.8526e-03 eta 0:02:04
epoch [37/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.095) loss 0.6963 (0.7201) acc 84.3750 (77.5000) lr 1.8443e-03 eta 0:01:59
epoch [38/200] batch [5/5] time 0.048 (0.149) data 0.000 (0.100) loss 0.5913 (0.7734) acc 78.1250 (73.1250) lr 1.8358e-03 eta 0:02:01
epoch [39/200] batch [5/5] time 0.051 (0.144) data 0.000 (0.092) loss 0.6123 (0.6562) acc 84.3750 (80.0000) lr 1.8271e-03 eta 0:01:56
epoch [40/200] batch [5/5] time 0.047 (0.145) data 0.000 (0.094) loss 0.5869 (0.6918) acc 84.3750 (79.3750) lr 1.8181e-03 eta 0:01:56
epoch [41/200] batch [5/5] time 0.050 (0.152) data 0.000 (0.102) loss 0.6982 (0.6864) acc 78.1250 (80.0000) lr 1.8090e-03 eta 0:02:00
epoch [42/200] batch [5/5] time 0.048 (0.151) data 0.000 (0.099) loss 0.9194 (0.7375) acc 65.6250 (78.1250) lr 1.7997e-03 eta 0:01:59
epoch [43/200] batch [5/5] time 0.048 (0.142) data 0.000 (0.092) loss 0.7256 (0.7120) acc 75.0000 (76.8750) lr 1.7902e-03 eta 0:01:51
epoch [44/200] batch [5/5] time 0.053 (0.156) data 0.000 (0.102) loss 0.9404 (0.8289) acc 68.7500 (75.6250) lr 1.7804e-03 eta 0:02:01
epoch [45/200] batch [5/5] time 0.054 (0.145) data 0.000 (0.092) loss 0.7114 (0.6607) acc 71.8750 (80.0000) lr 1.7705e-03 eta 0:01:52
epoch [46/200] batch [5/5] time 0.047 (0.147) data 0.000 (0.096) loss 0.4043 (0.6562) acc 87.5000 (77.5000) lr 1.7604e-03 eta 0:01:52
epoch [47/200] batch [5/5] time 0.051 (0.149) data 0.000 (0.098) loss 0.8140 (0.6812) acc 71.8750 (75.6250) lr 1.7501e-03 eta 0:01:54
epoch [48/200] batch [5/5] time 0.048 (0.149) data 0.000 (0.098) loss 0.6685 (0.6931) acc 81.2500 (79.3750) lr 1.7396e-03 eta 0:01:53
epoch [49/200] batch [5/5] time 0.049 (0.154) data 0.000 (0.103) loss 0.9150 (0.6769) acc 68.7500 (76.8750) lr 1.7290e-03 eta 0:01:56
epoch [50/200] batch [5/5] time 0.049 (0.147) data 0.000 (0.095) loss 0.9780 (0.6877) acc 68.7500 (78.1250) lr 1.7181e-03 eta 0:01:49
epoch [51/200] batch [5/5] time 0.050 (0.142) data 0.000 (0.092) loss 0.7944 (0.6507) acc 78.1250 (79.3750) lr 1.7071e-03 eta 0:01:46
epoch [52/200] batch [5/5] time 0.053 (0.146) data 0.000 (0.094) loss 0.7021 (0.6565) acc 75.0000 (80.6250) lr 1.6959e-03 eta 0:01:48
epoch [53/200] batch [5/5] time 0.050 (0.152) data 0.000 (0.101) loss 0.4785 (0.6045) acc 87.5000 (83.7500) lr 1.6845e-03 eta 0:01:51
epoch [54/200] batch [5/5] time 0.047 (0.145) data 0.000 (0.095) loss 0.5801 (0.7741) acc 78.1250 (73.1250) lr 1.6730e-03 eta 0:01:46
epoch [55/200] batch [5/5] time 0.047 (0.147) data 0.000 (0.096) loss 0.6567 (0.6873) acc 78.1250 (77.5000) lr 1.6613e-03 eta 0:01:46
epoch [56/200] batch [5/5] time 0.047 (0.152) data 0.000 (0.101) loss 0.4485 (0.7043) acc 87.5000 (74.3750) lr 1.6494e-03 eta 0:01:49
epoch [57/200] batch [5/5] time 0.050 (0.142) data 0.000 (0.091) loss 0.5083 (0.5804) acc 84.3750 (83.1250) lr 1.6374e-03 eta 0:01:41
epoch [58/200] batch [5/5] time 0.055 (0.147) data 0.000 (0.095) loss 0.6299 (0.6738) acc 78.1250 (75.6250) lr 1.6252e-03 eta 0:01:44
epoch [59/200] batch [5/5] time 0.059 (0.147) data 0.000 (0.094) loss 0.5898 (0.6246) acc 75.0000 (81.8750) lr 1.6129e-03 eta 0:01:43
epoch [60/200] batch [5/5] time 0.051 (0.143) data 0.000 (0.092) loss 0.6738 (0.5129) acc 84.3750 (85.6250) lr 1.6004e-03 eta 0:01:40
epoch [61/200] batch [5/5] time 0.052 (0.150) data 0.000 (0.099) loss 0.5093 (0.5851) acc 84.3750 (81.2500) lr 1.5878e-03 eta 0:01:44
epoch [62/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.092) loss 0.4653 (0.6439) acc 87.5000 (78.7500) lr 1.5750e-03 eta 0:01:38
epoch [63/200] batch [5/5] time 0.051 (0.142) data 0.000 (0.090) loss 0.5259 (0.5980) acc 81.2500 (79.3750) lr 1.5621e-03 eta 0:01:37
epoch [64/200] batch [5/5] time 0.052 (0.142) data 0.000 (0.090) loss 0.6226 (0.5906) acc 78.1250 (77.5000) lr 1.5490e-03 eta 0:01:36
epoch [65/200] batch [5/5] time 0.053 (0.150) data 0.000 (0.095) loss 0.7275 (0.6423) acc 78.1250 (82.5000) lr 1.5358e-03 eta 0:01:40
epoch [66/200] batch [5/5] time 0.051 (0.145) data 0.000 (0.094) loss 0.3359 (0.4984) acc 93.7500 (88.1250) lr 1.5225e-03 eta 0:01:36
epoch [67/200] batch [5/5] time 0.052 (0.153) data 0.000 (0.101) loss 0.5757 (0.6660) acc 75.0000 (75.6250) lr 1.5090e-03 eta 0:01:41
epoch [68/200] batch [5/5] time 0.049 (0.150) data 0.000 (0.098) loss 0.6299 (0.5405) acc 84.3750 (84.3750) lr 1.4955e-03 eta 0:01:38
epoch [69/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.091) loss 0.5015 (0.5305) acc 81.2500 (86.2500) lr 1.4818e-03 eta 0:01:34
epoch [70/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.095) loss 0.3037 (0.5320) acc 96.8750 (88.1250) lr 1.4679e-03 eta 0:01:35
epoch [71/200] batch [5/5] time 0.047 (0.148) data 0.000 (0.096) loss 0.8481 (0.6091) acc 71.8750 (79.3750) lr 1.4540e-03 eta 0:01:35
epoch [72/200] batch [5/5] time 0.050 (0.150) data 0.000 (0.100) loss 0.7207 (0.5525) acc 71.8750 (81.2500) lr 1.4399e-03 eta 0:01:36
epoch [73/200] batch [5/5] time 0.049 (0.145) data 0.000 (0.094) loss 0.7568 (0.6555) acc 78.1250 (77.5000) lr 1.4258e-03 eta 0:01:32
epoch [74/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.092) loss 0.6509 (0.6467) acc 81.2500 (80.6250) lr 1.4115e-03 eta 0:01:31
epoch [75/200] batch [5/5] time 0.051 (0.147) data 0.000 (0.095) loss 0.2197 (0.5584) acc 100.0000 (81.8750) lr 1.3971e-03 eta 0:01:31
epoch [76/200] batch [5/5] time 0.051 (0.148) data 0.000 (0.098) loss 0.7314 (0.6003) acc 75.0000 (82.5000) lr 1.3827e-03 eta 0:01:31
epoch [77/200] batch [5/5] time 0.054 (0.145) data 0.000 (0.092) loss 0.5024 (0.5528) acc 84.3750 (80.6250) lr 1.3681e-03 eta 0:01:29
epoch [78/200] batch [5/5] time 0.053 (0.146) data 0.000 (0.094) loss 0.7061 (0.4881) acc 71.8750 (85.0000) lr 1.3535e-03 eta 0:01:28
epoch [79/200] batch [5/5] time 0.054 (0.149) data 0.000 (0.096) loss 0.6519 (0.5527) acc 75.0000 (81.8750) lr 1.3387e-03 eta 0:01:30
epoch [80/200] batch [5/5] time 0.050 (0.151) data 0.000 (0.101) loss 0.6167 (0.5370) acc 75.0000 (81.8750) lr 1.3239e-03 eta 0:01:30
epoch [81/200] batch [5/5] time 0.053 (0.154) data 0.000 (0.102) loss 0.4910 (0.5699) acc 87.5000 (84.3750) lr 1.3090e-03 eta 0:01:31
epoch [82/200] batch [5/5] time 0.053 (0.150) data 0.000 (0.098) loss 0.6021 (0.5824) acc 75.0000 (81.2500) lr 1.2940e-03 eta 0:01:28
epoch [83/200] batch [5/5] time 0.058 (0.147) data 0.000 (0.093) loss 0.5396 (0.5070) acc 87.5000 (88.7500) lr 1.2790e-03 eta 0:01:25
epoch [84/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.093) loss 0.3735 (0.5214) acc 87.5000 (81.2500) lr 1.2639e-03 eta 0:01:24
epoch [85/200] batch [5/5] time 0.054 (0.145) data 0.000 (0.093) loss 0.5210 (0.4877) acc 81.2500 (87.5000) lr 1.2487e-03 eta 0:01:23
epoch [86/200] batch [5/5] time 0.053 (0.154) data 0.000 (0.103) loss 0.5708 (0.5343) acc 90.6250 (85.6250) lr 1.2334e-03 eta 0:01:27
epoch [87/200] batch [5/5] time 0.051 (0.148) data 0.000 (0.097) loss 0.6001 (0.5544) acc 78.1250 (84.3750) lr 1.2181e-03 eta 0:01:23
epoch [88/200] batch [5/5] time 0.050 (0.149) data 0.000 (0.099) loss 0.6255 (0.4518) acc 81.2500 (86.2500) lr 1.2028e-03 eta 0:01:23
epoch [89/200] batch [5/5] time 0.048 (0.149) data 0.000 (0.097) loss 0.5044 (0.5252) acc 84.3750 (82.5000) lr 1.1874e-03 eta 0:01:22
epoch [90/200] batch [5/5] time 0.047 (0.148) data 0.000 (0.097) loss 0.5337 (0.4358) acc 78.1250 (85.6250) lr 1.1719e-03 eta 0:01:21
epoch [91/200] batch [5/5] time 0.055 (0.152) data 0.000 (0.101) loss 0.7007 (0.5744) acc 78.1250 (82.5000) lr 1.1564e-03 eta 0:01:23
epoch [92/200] batch [5/5] time 0.048 (0.142) data 0.000 (0.090) loss 0.5830 (0.4508) acc 81.2500 (85.6250) lr 1.1409e-03 eta 0:01:16
epoch [93/200] batch [5/5] time 0.054 (0.153) data 0.000 (0.099) loss 0.7300 (0.5776) acc 71.8750 (80.6250) lr 1.1253e-03 eta 0:01:21
epoch [94/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.092) loss 0.6797 (0.4592) acc 84.3750 (88.1250) lr 1.1097e-03 eta 0:01:17
epoch [95/200] batch [5/5] time 0.049 (0.144) data 0.000 (0.091) loss 0.6069 (0.5763) acc 78.1250 (81.2500) lr 1.0941e-03 eta 0:01:15
epoch [96/200] batch [5/5] time 0.054 (0.150) data 0.000 (0.098) loss 0.4204 (0.4624) acc 87.5000 (86.8750) lr 1.0785e-03 eta 0:01:18
epoch [97/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.092) loss 0.5234 (0.4688) acc 87.5000 (88.7500) lr 1.0628e-03 eta 0:01:15
epoch [98/200] batch [5/5] time 0.054 (0.154) data 0.000 (0.099) loss 0.7510 (0.5499) acc 75.0000 (84.3750) lr 1.0471e-03 eta 0:01:18
epoch [99/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.095) loss 0.4639 (0.5041) acc 90.6250 (85.6250) lr 1.0314e-03 eta 0:01:15
epoch [100/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.091) loss 0.5635 (0.5063) acc 84.3750 (86.8750) lr 1.0157e-03 eta 0:01:12
epoch [101/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.094) loss 0.3142 (0.5169) acc 93.7500 (83.7500) lr 1.0000e-03 eta 0:01:12
epoch [102/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.098) loss 0.5425 (0.4895) acc 87.5000 (86.2500) lr 9.8429e-04 eta 0:01:14
epoch [103/200] batch [5/5] time 0.054 (0.145) data 0.000 (0.091) loss 0.4207 (0.4072) acc 87.5000 (86.2500) lr 9.6859e-04 eta 0:01:10
epoch [104/200] batch [5/5] time 0.054 (0.149) data 0.000 (0.097) loss 0.5020 (0.4626) acc 78.1250 (85.0000) lr 9.5289e-04 eta 0:01:11
epoch [105/200] batch [5/5] time 0.050 (0.148) data 0.000 (0.098) loss 0.5205 (0.5803) acc 87.5000 (81.8750) lr 9.3721e-04 eta 0:01:10
epoch [106/200] batch [5/5] time 0.048 (0.148) data 0.000 (0.097) loss 0.6450 (0.5277) acc 75.0000 (81.8750) lr 9.2154e-04 eta 0:01:09
epoch [107/200] batch [5/5] time 0.050 (0.147) data 0.000 (0.095) loss 0.4116 (0.4304) acc 87.5000 (88.7500) lr 9.0589e-04 eta 0:01:08
epoch [108/200] batch [5/5] time 0.052 (0.145) data 0.000 (0.093) loss 0.5078 (0.4887) acc 84.3750 (85.6250) lr 8.9027e-04 eta 0:01:06
epoch [109/200] batch [5/5] time 0.047 (0.148) data 0.000 (0.097) loss 0.4353 (0.4690) acc 81.2500 (85.0000) lr 8.7467e-04 eta 0:01:07
epoch [110/200] batch [5/5] time 0.048 (0.144) data 0.000 (0.093) loss 0.4824 (0.4637) acc 84.3750 (84.3750) lr 8.5910e-04 eta 0:01:05
epoch [111/200] batch [5/5] time 0.047 (0.144) data 0.000 (0.093) loss 0.4136 (0.4386) acc 90.6250 (88.7500) lr 8.4357e-04 eta 0:01:03
epoch [112/200] batch [5/5] time 0.054 (0.150) data 0.000 (0.098) loss 0.4492 (0.3736) acc 84.3750 (90.0000) lr 8.2807e-04 eta 0:01:05
epoch [113/200] batch [5/5] time 0.055 (0.151) data 0.000 (0.097) loss 0.4082 (0.4709) acc 90.6250 (85.6250) lr 8.1262e-04 eta 0:01:05
epoch [114/200] batch [5/5] time 0.054 (0.152) data 0.000 (0.100) loss 0.4104 (0.4948) acc 90.6250 (85.6250) lr 7.9721e-04 eta 0:01:05
epoch [115/200] batch [5/5] time 0.053 (0.150) data 0.000 (0.098) loss 0.3179 (0.3551) acc 90.6250 (90.6250) lr 7.8186e-04 eta 0:01:03
epoch [116/200] batch [5/5] time 0.048 (0.146) data 0.000 (0.094) loss 0.4214 (0.5174) acc 87.5000 (84.3750) lr 7.6655e-04 eta 0:01:01
epoch [117/200] batch [5/5] time 0.047 (0.151) data 0.000 (0.102) loss 0.2905 (0.3382) acc 90.6250 (90.0000) lr 7.5131e-04 eta 0:01:02
epoch [118/200] batch [5/5] time 0.054 (0.144) data 0.000 (0.091) loss 0.7256 (0.5518) acc 78.1250 (80.0000) lr 7.3613e-04 eta 0:00:59
epoch [119/200] batch [5/5] time 0.052 (0.154) data 0.000 (0.102) loss 0.3972 (0.4100) acc 90.6250 (87.5000) lr 7.2101e-04 eta 0:01:02
epoch [120/200] batch [5/5] time 0.048 (0.147) data 0.000 (0.094) loss 0.4561 (0.3483) acc 84.3750 (90.6250) lr 7.0596e-04 eta 0:00:58
epoch [121/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.093) loss 0.3472 (0.4124) acc 93.7500 (88.1250) lr 6.9098e-04 eta 0:00:57
epoch [122/200] batch [5/5] time 0.047 (0.150) data 0.000 (0.098) loss 0.3796 (0.4856) acc 87.5000 (85.0000) lr 6.7608e-04 eta 0:00:58
epoch [123/200] batch [5/5] time 0.051 (0.141) data 0.000 (0.090) loss 0.5479 (0.4087) acc 90.6250 (88.7500) lr 6.6126e-04 eta 0:00:54
epoch [124/200] batch [5/5] time 0.052 (0.157) data 0.000 (0.103) loss 0.2379 (0.3621) acc 96.8750 (92.5000) lr 6.4653e-04 eta 0:00:59
epoch [125/200] batch [5/5] time 0.053 (0.146) data 0.000 (0.094) loss 0.2446 (0.3142) acc 96.8750 (90.0000) lr 6.3188e-04 eta 0:00:54
epoch [126/200] batch [5/5] time 0.051 (0.148) data 0.000 (0.096) loss 0.4053 (0.4625) acc 90.6250 (88.1250) lr 6.1732e-04 eta 0:00:54
epoch [127/200] batch [5/5] time 0.049 (0.151) data 0.000 (0.101) loss 0.7202 (0.4665) acc 75.0000 (86.8750) lr 6.0285e-04 eta 0:00:55
epoch [128/200] batch [5/5] time 0.053 (0.143) data 0.000 (0.092) loss 0.2896 (0.4125) acc 96.8750 (89.3750) lr 5.8849e-04 eta 0:00:51
epoch [129/200] batch [5/5] time 0.052 (0.148) data 0.000 (0.096) loss 0.6216 (0.4137) acc 78.1250 (90.0000) lr 5.7422e-04 eta 0:00:52
epoch [130/200] batch [5/5] time 0.054 (0.147) data 0.000 (0.093) loss 0.3901 (0.4049) acc 90.6250 (90.0000) lr 5.6006e-04 eta 0:00:51
epoch [131/200] batch [5/5] time 0.054 (0.152) data 0.000 (0.098) loss 0.7300 (0.5231) acc 71.8750 (78.1250) lr 5.4601e-04 eta 0:00:52
epoch [132/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.092) loss 0.5298 (0.3947) acc 84.3750 (89.3750) lr 5.3207e-04 eta 0:00:49
epoch [133/200] batch [5/5] time 0.054 (0.147) data 0.000 (0.094) loss 0.3079 (0.4101) acc 90.6250 (87.5000) lr 5.1825e-04 eta 0:00:49
epoch [134/200] batch [5/5] time 0.048 (0.150) data 0.000 (0.097) loss 0.2776 (0.3534) acc 96.8750 (90.0000) lr 5.0454e-04 eta 0:00:49
epoch [135/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.095) loss 0.3855 (0.4365) acc 87.5000 (86.8750) lr 4.9096e-04 eta 0:00:48
epoch [136/200] batch [5/5] time 0.053 (0.148) data 0.000 (0.094) loss 0.4985 (0.4264) acc 87.5000 (89.3750) lr 4.7750e-04 eta 0:00:47
epoch [137/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.092) loss 0.8525 (0.5836) acc 75.0000 (83.1250) lr 4.6417e-04 eta 0:00:45
epoch [138/200] batch [5/5] time 0.054 (0.151) data 0.000 (0.098) loss 0.4790 (0.4294) acc 87.5000 (88.1250) lr 4.5098e-04 eta 0:00:46
epoch [139/200] batch [5/5] time 0.055 (0.144) data 0.000 (0.092) loss 0.5557 (0.3402) acc 81.2500 (90.0000) lr 4.3792e-04 eta 0:00:43
epoch [140/200] batch [5/5] time 0.052 (0.153) data 0.000 (0.101) loss 0.3633 (0.4363) acc 90.6250 (88.1250) lr 4.2499e-04 eta 0:00:45
epoch [141/200] batch [5/5] time 0.051 (0.150) data 0.000 (0.098) loss 0.2791 (0.2695) acc 90.6250 (93.7500) lr 4.1221e-04 eta 0:00:44
epoch [142/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.093) loss 0.6973 (0.4725) acc 81.2500 (89.3750) lr 3.9958e-04 eta 0:00:41
epoch [143/200] batch [5/5] time 0.049 (0.143) data 0.000 (0.093) loss 0.5205 (0.4325) acc 84.3750 (86.2500) lr 3.8709e-04 eta 0:00:40
epoch [144/200] batch [5/5] time 0.053 (0.146) data 0.000 (0.094) loss 0.2998 (0.4448) acc 96.8750 (85.6250) lr 3.7476e-04 eta 0:00:40
epoch [145/200] batch [5/5] time 0.048 (0.149) data 0.000 (0.097) loss 0.4695 (0.4102) acc 81.2500 (87.5000) lr 3.6258e-04 eta 0:00:40
epoch [146/200] batch [5/5] time 0.055 (0.145) data 0.000 (0.093) loss 0.4812 (0.3872) acc 81.2500 (90.0000) lr 3.5055e-04 eta 0:00:39
epoch [147/200] batch [5/5] time 0.051 (0.147) data 0.000 (0.093) loss 0.3291 (0.3677) acc 93.7500 (90.0000) lr 3.3869e-04 eta 0:00:38
epoch [148/200] batch [5/5] time 0.055 (0.148) data 0.000 (0.094) loss 0.4360 (0.4500) acc 84.3750 (84.3750) lr 3.2699e-04 eta 0:00:38
epoch [149/200] batch [5/5] time 0.048 (0.142) data 0.000 (0.092) loss 0.5259 (0.3743) acc 87.5000 (91.8750) lr 3.1545e-04 eta 0:00:36
epoch [150/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.093) loss 0.4968 (0.4313) acc 84.3750 (86.8750) lr 3.0409e-04 eta 0:00:35
epoch [151/200] batch [5/5] time 0.052 (0.145) data 0.000 (0.091) loss 0.2158 (0.3224) acc 100.0000 (93.7500) lr 2.9289e-04 eta 0:00:35
epoch [152/200] batch [5/5] time 0.054 (0.149) data 0.000 (0.096) loss 0.5244 (0.4218) acc 75.0000 (86.2500) lr 2.8187e-04 eta 0:00:35
epoch [153/200] batch [5/5] time 0.052 (0.148) data 0.000 (0.096) loss 0.5532 (0.4655) acc 78.1250 (86.8750) lr 2.7103e-04 eta 0:00:34
epoch [154/200] batch [5/5] time 0.053 (0.153) data 0.000 (0.098) loss 0.2214 (0.4218) acc 93.7500 (86.2500) lr 2.6037e-04 eta 0:00:35
epoch [155/200] batch [5/5] time 0.051 (0.151) data 0.000 (0.098) loss 0.4136 (0.3656) acc 84.3750 (88.7500) lr 2.4989e-04 eta 0:00:33
epoch [156/200] batch [5/5] time 0.056 (0.149) data 0.000 (0.094) loss 0.4932 (0.4801) acc 84.3750 (82.5000) lr 2.3959e-04 eta 0:00:32
epoch [157/200] batch [5/5] time 0.053 (0.151) data 0.000 (0.097) loss 0.4985 (0.3771) acc 84.3750 (91.2500) lr 2.2949e-04 eta 0:00:32
epoch [158/200] batch [5/5] time 0.054 (0.146) data 0.000 (0.095) loss 0.3579 (0.3851) acc 96.8750 (91.8750) lr 2.1957e-04 eta 0:00:30
epoch [159/200] batch [5/5] time 0.052 (0.149) data 0.000 (0.095) loss 0.3831 (0.4157) acc 90.6250 (89.3750) lr 2.0984e-04 eta 0:00:30
epoch [160/200] batch [5/5] time 0.053 (0.154) data 0.000 (0.100) loss 0.4243 (0.4317) acc 87.5000 (83.7500) lr 2.0032e-04 eta 0:00:30
epoch [161/200] batch [5/5] time 0.053 (0.149) data 0.000 (0.097) loss 0.5854 (0.4239) acc 84.3750 (90.0000) lr 1.9098e-04 eta 0:00:29
epoch [162/200] batch [5/5] time 0.053 (0.151) data 0.000 (0.096) loss 0.2393 (0.3890) acc 93.7500 (88.7500) lr 1.8185e-04 eta 0:00:28
epoch [163/200] batch [5/5] time 0.052 (0.145) data 0.000 (0.091) loss 0.3254 (0.3798) acc 87.5000 (87.5000) lr 1.7292e-04 eta 0:00:26
epoch [164/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.095) loss 0.2627 (0.3647) acc 96.8750 (91.8750) lr 1.6419e-04 eta 0:00:25
epoch [165/200] batch [5/5] time 0.054 (0.148) data 0.000 (0.094) loss 0.4819 (0.3706) acc 90.6250 (91.8750) lr 1.5567e-04 eta 0:00:25
epoch [166/200] batch [5/5] time 0.047 (0.147) data 0.000 (0.096) loss 0.2274 (0.3882) acc 96.8750 (90.6250) lr 1.4736e-04 eta 0:00:25
epoch [167/200] batch [5/5] time 0.053 (0.147) data 0.000 (0.092) loss 0.5469 (0.4314) acc 84.3750 (88.7500) lr 1.3926e-04 eta 0:00:24
epoch [168/200] batch [5/5] time 0.047 (0.143) data 0.000 (0.092) loss 0.3152 (0.3145) acc 93.7500 (92.5000) lr 1.3137e-04 eta 0:00:22
epoch [169/200] batch [5/5] time 0.052 (0.152) data 0.000 (0.100) loss 0.3035 (0.3731) acc 93.7500 (90.6250) lr 1.2369e-04 eta 0:00:23
epoch [170/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.095) loss 0.4927 (0.4532) acc 87.5000 (89.3750) lr 1.1623e-04 eta 0:00:21
epoch [171/200] batch [5/5] time 0.047 (0.149) data 0.000 (0.101) loss 0.4172 (0.3862) acc 93.7500 (87.5000) lr 1.0899e-04 eta 0:00:21
epoch [172/200] batch [5/5] time 0.059 (0.148) data 0.000 (0.095) loss 0.3179 (0.3452) acc 90.6250 (90.0000) lr 1.0197e-04 eta 0:00:20
epoch [173/200] batch [5/5] time 0.051 (0.140) data 0.000 (0.089) loss 0.5825 (0.3701) acc 81.2500 (90.0000) lr 9.5173e-05 eta 0:00:18
epoch [174/200] batch [5/5] time 0.052 (0.151) data 0.000 (0.100) loss 0.2881 (0.3575) acc 100.0000 (89.3750) lr 8.8597e-05 eta 0:00:19
epoch [175/200] batch [5/5] time 0.048 (0.143) data 0.000 (0.091) loss 0.5728 (0.3677) acc 78.1250 (87.5000) lr 8.2245e-05 eta 0:00:17
epoch [176/200] batch [5/5] time 0.052 (0.143) data 0.000 (0.090) loss 0.7559 (0.4201) acc 71.8750 (87.5000) lr 7.6120e-05 eta 0:00:17
epoch [177/200] batch [5/5] time 0.054 (0.144) data 0.000 (0.092) loss 0.4055 (0.3602) acc 84.3750 (88.7500) lr 7.0224e-05 eta 0:00:16
epoch [178/200] batch [5/5] time 0.049 (0.147) data 0.000 (0.095) loss 0.5830 (0.3739) acc 78.1250 (87.5000) lr 6.4556e-05 eta 0:00:16
epoch [179/200] batch [5/5] time 0.048 (0.144) data 0.000 (0.095) loss 0.4353 (0.3627) acc 90.6250 (90.0000) lr 5.9119e-05 eta 0:00:15
epoch [180/200] batch [5/5] time 0.053 (0.144) data 0.000 (0.092) loss 0.5366 (0.4090) acc 78.1250 (87.5000) lr 5.3915e-05 eta 0:00:14
epoch [181/200] batch [5/5] time 0.054 (0.148) data 0.000 (0.095) loss 0.3083 (0.3362) acc 93.7500 (89.3750) lr 4.8943e-05 eta 0:00:14
epoch [182/200] batch [5/5] time 0.054 (0.149) data 0.000 (0.095) loss 0.3899 (0.4504) acc 87.5000 (85.0000) lr 4.4207e-05 eta 0:00:13
epoch [183/200] batch [5/5] time 0.048 (0.151) data 0.000 (0.099) loss 0.2944 (0.4046) acc 93.7500 (91.2500) lr 3.9706e-05 eta 0:00:12
epoch [184/200] batch [5/5] time 0.052 (0.151) data 0.000 (0.100) loss 0.4385 (0.4319) acc 84.3750 (88.1250) lr 3.5443e-05 eta 0:00:12
epoch [185/200] batch [5/5] time 0.053 (0.146) data 0.000 (0.094) loss 0.4746 (0.4529) acc 90.6250 (85.6250) lr 3.1417e-05 eta 0:00:10
epoch [186/200] batch [5/5] time 0.052 (0.144) data 0.000 (0.092) loss 0.3643 (0.3929) acc 90.6250 (90.0000) lr 2.7630e-05 eta 0:00:10
epoch [187/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.097) loss 0.4075 (0.3785) acc 87.5000 (91.2500) lr 2.4083e-05 eta 0:00:09
epoch [188/200] batch [5/5] time 0.051 (0.149) data 0.000 (0.098) loss 0.5283 (0.4121) acc 81.2500 (87.5000) lr 2.0777e-05 eta 0:00:08
epoch [189/200] batch [5/5] time 0.052 (0.147) data 0.000 (0.097) loss 0.3284 (0.3879) acc 87.5000 (90.0000) lr 1.7713e-05 eta 0:00:08
epoch [190/200] batch [5/5] time 0.053 (0.148) data 0.000 (0.096) loss 0.2954 (0.3672) acc 87.5000 (88.7500) lr 1.4891e-05 eta 0:00:07
epoch [191/200] batch [5/5] time 0.053 (0.145) data 0.000 (0.093) loss 0.4822 (0.4269) acc 84.3750 (86.8750) lr 1.2312e-05 eta 0:00:06
epoch [192/200] batch [5/5] time 0.053 (0.152) data 0.000 (0.097) loss 0.4001 (0.4143) acc 81.2500 (86.8750) lr 9.9763e-06 eta 0:00:06
epoch [193/200] batch [5/5] time 0.051 (0.144) data 0.000 (0.093) loss 0.5220 (0.3415) acc 87.5000 (92.5000) lr 7.8853e-06 eta 0:00:05
epoch [194/200] batch [5/5] time 0.051 (0.143) data 0.000 (0.092) loss 0.4260 (0.3430) acc 87.5000 (90.6250) lr 6.0390e-06 eta 0:00:04
epoch [195/200] batch [5/5] time 0.047 (0.149) data 0.000 (0.098) loss 0.3308 (0.4211) acc 93.7500 (88.7500) lr 4.4380e-06 eta 0:00:03
epoch [196/200] batch [5/5] time 0.048 (0.144) data 0.000 (0.094) loss 0.3743 (0.3541) acc 87.5000 (92.5000) lr 3.0827e-06 eta 0:00:02
epoch [197/200] batch [5/5] time 0.051 (0.146) data 0.000 (0.095) loss 0.2729 (0.3800) acc 93.7500 (90.6250) lr 1.9733e-06 eta 0:00:02
epoch [198/200] batch [5/5] time 0.051 (0.150) data 0.000 (0.099) loss 0.3962 (0.3927) acc 87.5000 (90.6250) lr 1.1101e-06 eta 0:00:01
epoch [199/200] batch [5/5] time 0.048 (0.147) data 0.000 (0.095) loss 0.3086 (0.3671) acc 96.8750 (91.8750) lr 4.9344e-07 eta 0:00:00
epoch [200/200] batch [5/5] time 0.054 (0.151) data 0.000 (0.099) loss 0.3511 (0.3160) acc 90.6250 (91.8750) lr 1.2337e-07 eta 0:00:00
Checkpoint saved to output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:01<01:21,  1.01s/it]  2%|▏         | 2/81 [00:01<00:39,  2.02it/s]  4%|▎         | 3/81 [00:01<00:25,  3.10it/s]  5%|▍         | 4/81 [00:01<00:18,  4.22it/s]  6%|▌         | 5/81 [00:01<00:14,  5.15it/s]  7%|▋         | 6/81 [00:01<00:12,  5.87it/s]  9%|▊         | 7/81 [00:01<00:11,  6.72it/s] 10%|▉         | 8/81 [00:01<00:09,  7.41it/s] 11%|█         | 9/81 [00:01<00:09,  7.91it/s] 12%|█▏        | 10/81 [00:02<00:08,  8.33it/s] 14%|█▎        | 11/81 [00:02<00:08,  8.65it/s] 15%|█▍        | 12/81 [00:02<00:07,  8.88it/s] 16%|█▌        | 13/81 [00:02<00:07,  9.06it/s] 17%|█▋        | 14/81 [00:02<00:07,  9.18it/s] 19%|█▊        | 15/81 [00:02<00:07,  9.30it/s] 20%|█▉        | 16/81 [00:02<00:06,  9.36it/s] 21%|██        | 17/81 [00:02<00:06,  9.41it/s] 22%|██▏       | 18/81 [00:02<00:06,  9.43it/s] 23%|██▎       | 19/81 [00:02<00:06,  9.45it/s] 25%|██▍       | 20/81 [00:03<00:06,  9.46it/s] 26%|██▌       | 21/81 [00:03<00:06,  9.46it/s] 27%|██▋       | 22/81 [00:03<00:06,  9.49it/s] 28%|██▊       | 23/81 [00:03<00:06,  9.52it/s] 30%|██▉       | 24/81 [00:03<00:05,  9.54it/s] 31%|███       | 25/81 [00:03<00:05,  9.53it/s] 32%|███▏      | 26/81 [00:03<00:05,  9.51it/s] 33%|███▎      | 27/81 [00:03<00:05,  9.50it/s] 35%|███▍      | 28/81 [00:03<00:05,  9.49it/s] 36%|███▌      | 29/81 [00:04<00:05,  9.51it/s] 37%|███▋      | 30/81 [00:04<00:05,  9.53it/s] 38%|███▊      | 31/81 [00:04<00:05,  9.55it/s] 40%|███▉      | 32/81 [00:04<00:05,  9.54it/s] 41%|████      | 33/81 [00:04<00:05,  9.52it/s] 42%|████▏     | 34/81 [00:04<00:04,  9.51it/s] 43%|████▎     | 35/81 [00:04<00:04,  9.50it/s] 44%|████▍     | 36/81 [00:04<00:04,  9.48it/s] 46%|████▌     | 37/81 [00:04<00:04,  9.50it/s] 47%|████▋     | 38/81 [00:04<00:04,  9.53it/s] 48%|████▊     | 39/81 [00:05<00:04,  9.55it/s] 49%|████▉     | 40/81 [00:05<00:04,  9.56it/s] 51%|█████     | 41/81 [00:05<00:04,  9.50it/s] 52%|█████▏    | 42/81 [00:05<00:04,  9.47it/s] 53%|█████▎    | 43/81 [00:05<00:04,  9.48it/s] 54%|█████▍    | 44/81 [00:05<00:03,  9.47it/s] 56%|█████▌    | 45/81 [00:05<00:03,  9.47it/s] 57%|█████▋    | 46/81 [00:05<00:03,  9.47it/s] 58%|█████▊    | 47/81 [00:05<00:03,  9.45it/s] 59%|█████▉    | 48/81 [00:06<00:03,  9.45it/s] 60%|██████    | 49/81 [00:06<00:03,  9.45it/s] 62%|██████▏   | 50/81 [00:06<00:03,  9.46it/s] 63%|██████▎   | 51/81 [00:06<00:03,  9.46it/s] 64%|██████▍   | 52/81 [00:06<00:03,  9.45it/s] 65%|██████▌   | 53/81 [00:06<00:02,  9.48it/s] 67%|██████▋   | 54/81 [00:06<00:02,  9.49it/s] 68%|██████▊   | 55/81 [00:06<00:02,  9.52it/s] 69%|██████▉   | 56/81 [00:06<00:02,  9.53it/s] 70%|███████   | 57/81 [00:06<00:02,  9.52it/s] 72%|███████▏  | 58/81 [00:07<00:02,  9.46it/s] 73%|███████▎  | 59/81 [00:07<00:02,  9.46it/s] 74%|███████▍  | 60/81 [00:07<00:02,  9.46it/s] 75%|███████▌  | 61/81 [00:07<00:02,  9.47it/s] 77%|███████▋  | 62/81 [00:07<00:02,  9.47it/s] 78%|███████▊  | 63/81 [00:07<00:01,  9.47it/s] 79%|███████▉  | 64/81 [00:07<00:01,  9.47it/s] 80%|████████  | 65/81 [00:07<00:01,  9.47it/s] 81%|████████▏ | 66/81 [00:07<00:01,  9.48it/s] 83%|████████▎ | 67/81 [00:08<00:01,  9.47it/s] 84%|████████▍ | 68/81 [00:08<00:01,  9.47it/s] 85%|████████▌ | 69/81 [00:08<00:01,  9.50it/s] 86%|████████▋ | 70/81 [00:08<00:01,  9.52it/s] 88%|████████▊ | 71/81 [00:08<00:01,  9.53it/s] 89%|████████▉ | 72/81 [00:08<00:00,  9.55it/s] 90%|█████████ | 73/81 [00:08<00:00,  9.57it/s] 91%|█████████▏| 74/81 [00:08<00:00,  9.57it/s] 93%|█████████▎| 75/81 [00:08<00:00,  9.58it/s] 94%|█████████▍| 76/81 [00:08<00:00,  9.57it/s] 95%|█████████▌| 77/81 [00:09<00:00,  9.56it/s] 96%|█████████▋| 78/81 [00:09<00:00,  9.53it/s] 98%|█████████▊| 79/81 [00:09<00:00,  9.54it/s] 99%|█████████▉| 80/81 [00:09<00:00,  9.56it/s]100%|██████████| 81/81 [00:09<00:00,  9.57it/s]100%|██████████| 81/81 [00:09<00:00,  8.44it/s]
=> result
* total: 8,100
* correct: 6,841
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 84.3%
Elapsed: 0:02:58

for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat 
do
    for seed in 1 2 3
    do
        # evaluation
        sh scripts/coop/crossdataset_test.sh eurosat ${dataset} ${seed} ${GPU} ${cfg} ${SHOT} ${EPOCH} ${TRAINER}
    done
done
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat imagenet 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/imagenet/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/imagenet/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:ImageNet
Loading dataset: ImageNet
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ImageNet/split_fewshot_taesup/shot_16-seed_1.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:04<34:33,  4.16s/it]  0%|          | 2/500 [00:04<15:37,  1.88s/it]  1%|          | 3/500 [00:04<09:34,  1.16s/it]  1%|          | 4/500 [00:05<06:44,  1.23it/s]  1%|          | 5/500 [00:05<05:10,  1.60it/s]  1%|          | 6/500 [00:05<04:13,  1.95it/s]  1%|▏         | 7/500 [00:05<03:37,  2.27it/s]  2%|▏         | 8/500 [00:06<03:14,  2.54it/s]  2%|▏         | 9/500 [00:06<02:58,  2.76it/s]  2%|▏         | 10/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:07<02:39,  3.06it/s]  2%|▏         | 12/500 [00:07<02:35,  3.14it/s]  3%|▎         | 13/500 [00:07<02:31,  3.21it/s]  3%|▎         | 14/500 [00:07<02:28,  3.27it/s]  3%|▎         | 15/500 [00:08<02:26,  3.31it/s]  3%|▎         | 16/500 [00:08<02:25,  3.34it/s]  3%|▎         | 17/500 [00:08<02:24,  3.35it/s]  4%|▎         | 18/500 [00:09<02:23,  3.37it/s]  4%|▍         | 19/500 [00:09<02:22,  3.38it/s]  4%|▍         | 20/500 [00:09<02:21,  3.38it/s]  4%|▍         | 21/500 [00:10<02:21,  3.39it/s]  4%|▍         | 22/500 [00:10<02:20,  3.39it/s]  5%|▍         | 23/500 [00:10<02:20,  3.39it/s]  5%|▍         | 24/500 [00:10<02:20,  3.39it/s]  5%|▌         | 25/500 [00:11<02:19,  3.39it/s]  5%|▌         | 26/500 [00:11<02:19,  3.40it/s]  5%|▌         | 27/500 [00:11<02:19,  3.39it/s]  6%|▌         | 28/500 [00:12<02:19,  3.40it/s]  6%|▌         | 29/500 [00:12<02:18,  3.40it/s]  6%|▌         | 30/500 [00:12<02:18,  3.40it/s]  6%|▌         | 31/500 [00:12<02:18,  3.40it/s]  6%|▋         | 32/500 [00:13<02:17,  3.41it/s]  7%|▋         | 33/500 [00:13<02:17,  3.41it/s]  7%|▋         | 34/500 [00:13<02:16,  3.40it/s]  7%|▋         | 35/500 [00:14<02:16,  3.40it/s]  7%|▋         | 36/500 [00:14<02:16,  3.40it/s]  7%|▋         | 37/500 [00:14<02:16,  3.40it/s]  8%|▊         | 38/500 [00:15<02:16,  3.40it/s]  8%|▊         | 39/500 [00:15<02:16,  3.39it/s]  8%|▊         | 40/500 [00:15<02:15,  3.39it/s]  8%|▊         | 41/500 [00:15<02:15,  3.40it/s]  8%|▊         | 42/500 [00:16<02:14,  3.40it/s]  9%|▊         | 43/500 [00:16<02:14,  3.40it/s]  9%|▉         | 44/500 [00:16<02:14,  3.39it/s]  9%|▉         | 45/500 [00:17<02:13,  3.40it/s]  9%|▉         | 46/500 [00:17<02:13,  3.40it/s]  9%|▉         | 47/500 [00:17<02:13,  3.39it/s] 10%|▉         | 48/500 [00:17<02:13,  3.39it/s] 10%|▉         | 49/500 [00:18<02:12,  3.39it/s] 10%|█         | 50/500 [00:18<02:12,  3.38it/s] 10%|█         | 51/500 [00:18<02:12,  3.38it/s] 10%|█         | 52/500 [00:19<02:12,  3.38it/s] 11%|█         | 53/500 [00:19<02:12,  3.38it/s] 11%|█         | 54/500 [00:19<02:11,  3.38it/s] 11%|█         | 55/500 [00:20<02:11,  3.38it/s] 11%|█         | 56/500 [00:20<02:11,  3.39it/s] 11%|█▏        | 57/500 [00:20<02:10,  3.39it/s] 12%|█▏        | 58/500 [00:20<02:10,  3.39it/s] 12%|█▏        | 59/500 [00:21<02:10,  3.39it/s] 12%|█▏        | 60/500 [00:21<02:09,  3.39it/s] 12%|█▏        | 61/500 [00:21<02:09,  3.40it/s] 12%|█▏        | 62/500 [00:22<02:09,  3.39it/s] 13%|█▎        | 63/500 [00:22<02:08,  3.39it/s] 13%|█▎        | 64/500 [00:22<02:08,  3.39it/s] 13%|█▎        | 65/500 [00:22<02:08,  3.39it/s] 13%|█▎        | 66/500 [00:23<02:08,  3.39it/s] 13%|█▎        | 67/500 [00:23<02:07,  3.39it/s] 14%|█▎        | 68/500 [00:23<02:07,  3.39it/s] 14%|█▍        | 69/500 [00:24<02:07,  3.39it/s] 14%|█▍        | 70/500 [00:24<02:06,  3.39it/s] 14%|█▍        | 71/500 [00:24<02:06,  3.39it/s] 14%|█▍        | 72/500 [00:25<02:06,  3.40it/s] 15%|█▍        | 73/500 [00:25<02:05,  3.39it/s] 15%|█▍        | 74/500 [00:25<02:05,  3.39it/s] 15%|█▌        | 75/500 [00:25<02:05,  3.38it/s] 15%|█▌        | 76/500 [00:26<02:05,  3.37it/s] 15%|█▌        | 77/500 [00:26<02:05,  3.38it/s] 16%|█▌        | 78/500 [00:26<02:04,  3.38it/s] 16%|█▌        | 79/500 [00:27<02:04,  3.38it/s] 16%|█▌        | 80/500 [00:27<02:04,  3.38it/s] 16%|█▌        | 81/500 [00:27<02:03,  3.38it/s] 16%|█▋        | 82/500 [00:28<02:03,  3.38it/s] 17%|█▋        | 83/500 [00:28<02:03,  3.38it/s] 17%|█▋        | 84/500 [00:28<02:03,  3.38it/s] 17%|█▋        | 85/500 [00:28<02:02,  3.38it/s] 17%|█▋        | 86/500 [00:29<02:02,  3.38it/s] 17%|█▋        | 87/500 [00:29<02:02,  3.38it/s] 18%|█▊        | 88/500 [00:29<02:01,  3.38it/s] 18%|█▊        | 89/500 [00:30<02:01,  3.38it/s] 18%|█▊        | 90/500 [00:30<02:01,  3.38it/s] 18%|█▊        | 91/500 [00:30<02:00,  3.38it/s] 18%|█▊        | 92/500 [00:30<02:00,  3.39it/s] 19%|█▊        | 93/500 [00:31<02:00,  3.39it/s] 19%|█▉        | 94/500 [00:31<01:59,  3.39it/s] 19%|█▉        | 95/500 [00:31<01:59,  3.39it/s] 19%|█▉        | 96/500 [00:32<01:59,  3.39it/s] 19%|█▉        | 97/500 [00:32<01:58,  3.39it/s] 20%|█▉        | 98/500 [00:32<01:59,  3.37it/s] 20%|█▉        | 99/500 [00:33<01:58,  3.38it/s] 20%|██        | 100/500 [00:33<01:58,  3.38it/s] 20%|██        | 101/500 [00:33<01:58,  3.37it/s] 20%|██        | 102/500 [00:33<01:57,  3.38it/s] 21%|██        | 103/500 [00:34<01:57,  3.38it/s] 21%|██        | 104/500 [00:34<01:57,  3.37it/s] 21%|██        | 105/500 [00:34<01:57,  3.37it/s] 21%|██        | 106/500 [00:35<01:56,  3.38it/s] 21%|██▏       | 107/500 [00:35<01:56,  3.38it/s] 22%|██▏       | 108/500 [00:35<01:56,  3.38it/s] 22%|██▏       | 109/500 [00:36<01:55,  3.38it/s] 22%|██▏       | 110/500 [00:36<01:55,  3.38it/s] 22%|██▏       | 111/500 [00:36<01:55,  3.38it/s] 22%|██▏       | 112/500 [00:36<01:55,  3.37it/s] 23%|██▎       | 113/500 [00:37<01:54,  3.37it/s] 23%|██▎       | 114/500 [00:37<01:54,  3.37it/s] 23%|██▎       | 115/500 [00:37<01:54,  3.38it/s] 23%|██▎       | 116/500 [00:38<01:53,  3.37it/s] 23%|██▎       | 117/500 [00:38<01:53,  3.37it/s] 24%|██▎       | 118/500 [00:38<01:53,  3.37it/s] 24%|██▍       | 119/500 [00:38<01:52,  3.38it/s] 24%|██▍       | 120/500 [00:39<01:52,  3.38it/s] 24%|██▍       | 121/500 [00:39<01:52,  3.38it/s] 24%|██▍       | 122/500 [00:39<01:51,  3.38it/s] 25%|██▍       | 123/500 [00:40<01:51,  3.37it/s] 25%|██▍       | 124/500 [00:40<01:51,  3.38it/s] 25%|██▌       | 125/500 [00:40<01:51,  3.38it/s] 25%|██▌       | 126/500 [00:41<01:50,  3.37it/s] 25%|██▌       | 127/500 [00:41<01:50,  3.37it/s] 26%|██▌       | 128/500 [00:41<01:50,  3.37it/s] 26%|██▌       | 129/500 [00:41<01:49,  3.37it/s] 26%|██▌       | 130/500 [00:42<01:49,  3.38it/s] 26%|██▌       | 131/500 [00:42<01:49,  3.38it/s] 26%|██▋       | 132/500 [00:42<01:48,  3.38it/s] 27%|██▋       | 133/500 [00:43<01:48,  3.38it/s] 27%|██▋       | 134/500 [00:43<01:48,  3.38it/s] 27%|██▋       | 135/500 [00:43<01:48,  3.37it/s] 27%|██▋       | 136/500 [00:44<01:48,  3.37it/s] 27%|██▋       | 137/500 [00:44<01:47,  3.36it/s] 28%|██▊       | 138/500 [00:44<01:47,  3.36it/s] 28%|██▊       | 139/500 [00:44<01:47,  3.36it/s] 28%|██▊       | 140/500 [00:45<01:47,  3.35it/s] 28%|██▊       | 141/500 [00:45<01:46,  3.36it/s] 28%|██▊       | 142/500 [00:45<01:46,  3.36it/s] 29%|██▊       | 143/500 [00:46<01:46,  3.37it/s] 29%|██▉       | 144/500 [00:46<01:45,  3.36it/s] 29%|██▉       | 145/500 [00:46<01:45,  3.36it/s] 29%|██▉       | 146/500 [00:46<01:45,  3.36it/s] 29%|██▉       | 147/500 [00:47<01:44,  3.36it/s] 30%|██▉       | 148/500 [00:47<01:44,  3.36it/s] 30%|██▉       | 149/500 [00:47<01:44,  3.37it/s] 30%|███       | 150/500 [00:48<01:43,  3.37it/s] 30%|███       | 151/500 [00:48<01:43,  3.37it/s] 30%|███       | 152/500 [00:48<01:43,  3.37it/s] 31%|███       | 153/500 [00:49<01:43,  3.37it/s] 31%|███       | 154/500 [00:49<01:43,  3.36it/s] 31%|███       | 155/500 [00:49<01:42,  3.36it/s] 31%|███       | 156/500 [00:49<01:42,  3.36it/s] 31%|███▏      | 157/500 [00:50<01:42,  3.36it/s] 32%|███▏      | 158/500 [00:50<01:41,  3.36it/s] 32%|███▏      | 159/500 [00:50<01:41,  3.37it/s] 32%|███▏      | 160/500 [00:51<01:40,  3.37it/s] 32%|███▏      | 161/500 [00:51<01:40,  3.37it/s] 32%|███▏      | 162/500 [00:51<01:40,  3.36it/s] 33%|███▎      | 163/500 [00:52<01:40,  3.36it/s] 33%|███▎      | 164/500 [00:52<01:39,  3.36it/s] 33%|███▎      | 165/500 [00:52<01:39,  3.36it/s] 33%|███▎      | 166/500 [00:52<01:39,  3.36it/s] 33%|███▎      | 167/500 [00:53<01:39,  3.36it/s] 34%|███▎      | 168/500 [00:53<01:38,  3.36it/s] 34%|███▍      | 169/500 [00:53<01:38,  3.36it/s] 34%|███▍      | 170/500 [00:54<01:38,  3.36it/s] 34%|███▍      | 171/500 [00:54<01:37,  3.36it/s] 34%|███▍      | 172/500 [00:54<01:37,  3.36it/s] 35%|███▍      | 173/500 [00:55<01:37,  3.36it/s] 35%|███▍      | 174/500 [00:55<01:37,  3.36it/s] 35%|███▌      | 175/500 [00:55<01:36,  3.36it/s] 35%|███▌      | 176/500 [00:55<01:36,  3.36it/s] 35%|███▌      | 177/500 [00:56<01:36,  3.36it/s] 36%|███▌      | 178/500 [00:56<01:35,  3.36it/s] 36%|███▌      | 179/500 [00:56<01:35,  3.36it/s] 36%|███▌      | 180/500 [00:57<01:35,  3.36it/s] 36%|███▌      | 181/500 [00:57<01:35,  3.36it/s] 36%|███▋      | 182/500 [00:57<01:34,  3.36it/s] 37%|███▋      | 183/500 [00:57<01:34,  3.36it/s] 37%|███▋      | 184/500 [00:58<01:33,  3.36it/s] 37%|███▋      | 185/500 [00:58<01:33,  3.36it/s] 37%|███▋      | 186/500 [00:58<01:33,  3.36it/s] 37%|███▋      | 187/500 [00:59<01:33,  3.36it/s] 38%|███▊      | 188/500 [00:59<01:32,  3.36it/s] 38%|███▊      | 189/500 [00:59<01:32,  3.36it/s] 38%|███▊      | 190/500 [01:00<01:32,  3.36it/s] 38%|███▊      | 191/500 [01:00<01:31,  3.36it/s] 38%|███▊      | 192/500 [01:00<01:31,  3.36it/s] 39%|███▊      | 193/500 [01:00<01:31,  3.36it/s] 39%|███▉      | 194/500 [01:01<01:31,  3.36it/s] 39%|███▉      | 195/500 [01:01<01:30,  3.36it/s] 39%|███▉      | 196/500 [01:01<01:30,  3.36it/s] 39%|███▉      | 197/500 [01:02<01:30,  3.36it/s] 40%|███▉      | 198/500 [01:02<01:29,  3.36it/s] 40%|███▉      | 199/500 [01:02<01:29,  3.36it/s] 40%|████      | 200/500 [01:03<01:29,  3.36it/s] 40%|████      | 201/500 [01:03<01:29,  3.36it/s] 40%|████      | 202/500 [01:03<01:28,  3.36it/s] 41%|████      | 203/500 [01:03<01:28,  3.36it/s] 41%|████      | 204/500 [01:04<01:28,  3.36it/s] 41%|████      | 205/500 [01:04<01:27,  3.36it/s] 41%|████      | 206/500 [01:04<01:27,  3.36it/s] 41%|████▏     | 207/500 [01:05<01:27,  3.36it/s] 42%|████▏     | 208/500 [01:05<01:26,  3.36it/s] 42%|████▏     | 209/500 [01:05<01:26,  3.37it/s] 42%|████▏     | 210/500 [01:06<01:26,  3.35it/s] 42%|████▏     | 211/500 [01:06<01:26,  3.36it/s] 42%|████▏     | 212/500 [01:06<01:25,  3.36it/s] 43%|████▎     | 213/500 [01:06<01:25,  3.35it/s] 43%|████▎     | 214/500 [01:07<01:25,  3.35it/s] 43%|████▎     | 215/500 [01:07<01:24,  3.35it/s] 43%|████▎     | 216/500 [01:07<01:24,  3.35it/s] 43%|████▎     | 217/500 [01:08<01:24,  3.35it/s] 44%|████▎     | 218/500 [01:08<01:24,  3.35it/s] 44%|████▍     | 219/500 [01:08<01:23,  3.35it/s] 44%|████▍     | 220/500 [01:09<01:23,  3.35it/s] 44%|████▍     | 221/500 [01:09<01:23,  3.35it/s] 44%|████▍     | 222/500 [01:09<01:23,  3.35it/s] 45%|████▍     | 223/500 [01:09<01:22,  3.35it/s] 45%|████▍     | 224/500 [01:10<01:22,  3.36it/s] 45%|████▌     | 225/500 [01:10<01:21,  3.36it/s] 45%|████▌     | 226/500 [01:10<01:21,  3.36it/s] 45%|████▌     | 227/500 [01:11<01:21,  3.36it/s] 46%|████▌     | 228/500 [01:11<01:20,  3.36it/s] 46%|████▌     | 229/500 [01:11<01:20,  3.36it/s] 46%|████▌     | 230/500 [01:11<01:20,  3.36it/s] 46%|████▌     | 231/500 [01:12<01:20,  3.36it/s] 46%|████▋     | 232/500 [01:12<01:19,  3.35it/s] 47%|████▋     | 233/500 [01:12<01:19,  3.35it/s] 47%|████▋     | 234/500 [01:13<01:19,  3.36it/s] 47%|████▋     | 235/500 [01:13<01:18,  3.36it/s] 47%|████▋     | 236/500 [01:13<01:18,  3.36it/s] 47%|████▋     | 237/500 [01:14<01:18,  3.36it/s] 48%|████▊     | 238/500 [01:14<01:17,  3.36it/s] 48%|████▊     | 239/500 [01:14<01:17,  3.35it/s] 48%|████▊     | 240/500 [01:14<01:17,  3.35it/s] 48%|████▊     | 241/500 [01:15<01:17,  3.36it/s] 48%|████▊     | 242/500 [01:15<01:17,  3.35it/s] 49%|████▊     | 243/500 [01:15<01:16,  3.35it/s] 49%|████▉     | 244/500 [01:16<01:16,  3.35it/s] 49%|████▉     | 245/500 [01:16<01:15,  3.36it/s] 49%|████▉     | 246/500 [01:16<01:15,  3.36it/s] 49%|████▉     | 247/500 [01:17<01:15,  3.36it/s] 50%|████▉     | 248/500 [01:17<01:15,  3.36it/s] 50%|████▉     | 249/500 [01:17<01:14,  3.36it/s] 50%|█████     | 250/500 [01:17<01:14,  3.35it/s] 50%|█████     | 251/500 [01:18<01:14,  3.35it/s] 50%|█████     | 252/500 [01:18<01:13,  3.36it/s] 51%|█████     | 253/500 [01:18<01:13,  3.36it/s] 51%|█████     | 254/500 [01:19<01:13,  3.36it/s] 51%|█████     | 255/500 [01:19<01:12,  3.36it/s] 51%|█████     | 256/500 [01:19<01:12,  3.36it/s] 51%|█████▏    | 257/500 [01:20<01:12,  3.36it/s] 52%|█████▏    | 258/500 [01:20<01:12,  3.36it/s] 52%|█████▏    | 259/500 [01:20<01:11,  3.36it/s] 52%|█████▏    | 260/500 [01:20<01:11,  3.36it/s] 52%|█████▏    | 261/500 [01:21<01:11,  3.35it/s] 52%|█████▏    | 262/500 [01:21<01:11,  3.35it/s] 53%|█████▎    | 263/500 [01:21<01:10,  3.35it/s] 53%|█████▎    | 264/500 [01:22<01:10,  3.35it/s] 53%|█████▎    | 265/500 [01:22<01:10,  3.35it/s] 53%|█████▎    | 266/500 [01:22<01:09,  3.36it/s] 53%|█████▎    | 267/500 [01:23<01:09,  3.36it/s] 54%|█████▎    | 268/500 [01:23<01:09,  3.36it/s] 54%|█████▍    | 269/500 [01:23<01:08,  3.35it/s] 54%|█████▍    | 270/500 [01:23<01:08,  3.35it/s] 54%|█████▍    | 271/500 [01:24<01:08,  3.35it/s] 54%|█████▍    | 272/500 [01:24<01:07,  3.36it/s] 55%|█████▍    | 273/500 [01:24<01:07,  3.36it/s] 55%|█████▍    | 274/500 [01:25<01:07,  3.36it/s] 55%|█████▌    | 275/500 [01:25<01:07,  3.36it/s] 55%|█████▌    | 276/500 [01:25<01:06,  3.35it/s] 55%|█████▌    | 277/500 [01:25<01:06,  3.35it/s] 56%|█████▌    | 278/500 [01:26<01:06,  3.35it/s] 56%|█████▌    | 279/500 [01:26<01:05,  3.35it/s] 56%|█████▌    | 280/500 [01:26<01:05,  3.36it/s] 56%|█████▌    | 281/500 [01:27<01:05,  3.35it/s] 56%|█████▋    | 282/500 [01:27<01:04,  3.36it/s] 57%|█████▋    | 283/500 [01:27<01:04,  3.35it/s] 57%|█████▋    | 284/500 [01:28<01:04,  3.35it/s] 57%|█████▋    | 285/500 [01:28<01:04,  3.35it/s] 57%|█████▋    | 286/500 [01:28<01:03,  3.35it/s] 57%|█████▋    | 287/500 [01:28<01:03,  3.35it/s] 58%|█████▊    | 288/500 [01:29<01:03,  3.34it/s] 58%|█████▊    | 289/500 [01:29<01:03,  3.35it/s] 58%|█████▊    | 290/500 [01:29<01:02,  3.34it/s] 58%|█████▊    | 291/500 [01:30<01:02,  3.35it/s] 58%|█████▊    | 292/500 [01:30<01:02,  3.35it/s] 59%|█████▊    | 293/500 [01:30<01:01,  3.35it/s] 59%|█████▉    | 294/500 [01:31<01:01,  3.35it/s] 59%|█████▉    | 295/500 [01:31<01:01,  3.35it/s] 59%|█████▉    | 296/500 [01:31<01:00,  3.35it/s] 59%|█████▉    | 297/500 [01:31<01:00,  3.36it/s] 60%|█████▉    | 298/500 [01:32<01:00,  3.36it/s] 60%|█████▉    | 299/500 [01:32<00:59,  3.36it/s] 60%|██████    | 300/500 [01:32<00:59,  3.36it/s] 60%|██████    | 301/500 [01:33<00:59,  3.36it/s] 60%|██████    | 302/500 [01:33<00:58,  3.37it/s] 61%|██████    | 303/500 [01:33<00:58,  3.37it/s] 61%|██████    | 304/500 [01:34<00:58,  3.37it/s] 61%|██████    | 305/500 [01:34<00:57,  3.37it/s] 61%|██████    | 306/500 [01:34<00:57,  3.36it/s] 61%|██████▏   | 307/500 [01:34<00:57,  3.36it/s] 62%|██████▏   | 308/500 [01:35<00:57,  3.36it/s] 62%|██████▏   | 309/500 [01:35<00:56,  3.36it/s] 62%|██████▏   | 310/500 [01:35<00:56,  3.35it/s] 62%|██████▏   | 311/500 [01:36<00:56,  3.35it/s] 62%|██████▏   | 312/500 [01:36<00:56,  3.35it/s] 63%|██████▎   | 313/500 [01:36<00:55,  3.35it/s] 63%|██████▎   | 314/500 [01:37<00:55,  3.36it/s] 63%|██████▎   | 315/500 [01:37<00:55,  3.35it/s] 63%|██████▎   | 316/500 [01:37<00:54,  3.36it/s] 63%|██████▎   | 317/500 [01:37<00:54,  3.36it/s] 64%|██████▎   | 318/500 [01:38<00:54,  3.36it/s] 64%|██████▍   | 319/500 [01:38<00:53,  3.36it/s] 64%|██████▍   | 320/500 [01:38<00:53,  3.36it/s] 64%|██████▍   | 321/500 [01:39<00:53,  3.35it/s] 64%|██████▍   | 322/500 [01:39<00:53,  3.36it/s] 65%|██████▍   | 323/500 [01:39<00:52,  3.36it/s] 65%|██████▍   | 324/500 [01:40<00:52,  3.36it/s] 65%|██████▌   | 325/500 [01:40<00:52,  3.36it/s] 65%|██████▌   | 326/500 [01:40<00:51,  3.35it/s] 65%|██████▌   | 327/500 [01:40<00:51,  3.35it/s] 66%|██████▌   | 328/500 [01:41<00:51,  3.35it/s] 66%|██████▌   | 329/500 [01:41<00:50,  3.36it/s] 66%|██████▌   | 330/500 [01:41<00:50,  3.35it/s] 66%|██████▌   | 331/500 [01:42<00:50,  3.35it/s] 66%|██████▋   | 332/500 [01:42<00:50,  3.35it/s] 67%|██████▋   | 333/500 [01:42<00:49,  3.36it/s] 67%|██████▋   | 334/500 [01:42<00:49,  3.36it/s] 67%|██████▋   | 335/500 [01:43<00:49,  3.36it/s] 67%|██████▋   | 336/500 [01:43<00:48,  3.36it/s] 67%|██████▋   | 337/500 [01:43<00:48,  3.36it/s] 68%|██████▊   | 338/500 [01:44<00:48,  3.36it/s] 68%|██████▊   | 339/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 340/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 341/500 [01:45<00:47,  3.36it/s] 68%|██████▊   | 342/500 [01:45<00:47,  3.36it/s] 69%|██████▊   | 343/500 [01:45<00:46,  3.36it/s] 69%|██████▉   | 344/500 [01:45<00:46,  3.36it/s] 69%|██████▉   | 345/500 [01:46<00:46,  3.35it/s] 69%|██████▉   | 346/500 [01:46<00:45,  3.35it/s] 69%|██████▉   | 347/500 [01:46<00:45,  3.35it/s] 70%|██████▉   | 348/500 [01:47<00:45,  3.35it/s] 70%|██████▉   | 349/500 [01:47<00:45,  3.35it/s] 70%|███████   | 350/500 [01:47<00:44,  3.36it/s] 70%|███████   | 351/500 [01:48<00:44,  3.36it/s] 70%|███████   | 352/500 [01:48<00:44,  3.36it/s] 71%|███████   | 353/500 [01:48<00:43,  3.36it/s] 71%|███████   | 354/500 [01:48<00:43,  3.35it/s] 71%|███████   | 355/500 [01:49<00:43,  3.35it/s] 71%|███████   | 356/500 [01:49<00:43,  3.35it/s] 71%|███████▏  | 357/500 [01:49<00:42,  3.35it/s] 72%|███████▏  | 358/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 359/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 360/500 [01:50<00:41,  3.35it/s] 72%|███████▏  | 361/500 [01:51<00:41,  3.35it/s] 72%|███████▏  | 362/500 [01:51<00:41,  3.35it/s] 73%|███████▎  | 363/500 [01:51<00:40,  3.35it/s] 73%|███████▎  | 364/500 [01:51<00:40,  3.35it/s] 73%|███████▎  | 365/500 [01:52<00:40,  3.35it/s] 73%|███████▎  | 366/500 [01:52<00:39,  3.35it/s] 73%|███████▎  | 367/500 [01:52<00:39,  3.36it/s] 74%|███████▎  | 368/500 [01:53<00:39,  3.35it/s] 74%|███████▍  | 369/500 [01:53<00:39,  3.35it/s] 74%|███████▍  | 370/500 [01:53<00:38,  3.35it/s] 74%|███████▍  | 371/500 [01:54<00:38,  3.35it/s] 74%|███████▍  | 372/500 [01:54<00:38,  3.35it/s] 75%|███████▍  | 373/500 [01:54<00:37,  3.35it/s] 75%|███████▍  | 374/500 [01:54<00:37,  3.35it/s] 75%|███████▌  | 375/500 [01:55<00:37,  3.35it/s] 75%|███████▌  | 376/500 [01:55<00:37,  3.35it/s] 75%|███████▌  | 377/500 [01:55<00:36,  3.34it/s] 76%|███████▌  | 378/500 [01:56<00:36,  3.34it/s] 76%|███████▌  | 379/500 [01:56<00:36,  3.32it/s] 76%|███████▌  | 380/500 [01:56<00:36,  3.32it/s] 76%|███████▌  | 381/500 [01:57<00:35,  3.32it/s] 76%|███████▋  | 382/500 [01:57<00:35,  3.33it/s] 77%|███████▋  | 383/500 [01:57<00:35,  3.33it/s] 77%|███████▋  | 384/500 [01:57<00:34,  3.34it/s] 77%|███████▋  | 385/500 [01:58<00:34,  3.35it/s] 77%|███████▋  | 386/500 [01:58<00:34,  3.35it/s] 77%|███████▋  | 387/500 [01:58<00:33,  3.35it/s] 78%|███████▊  | 388/500 [01:59<00:33,  3.36it/s] 78%|███████▊  | 389/500 [01:59<00:33,  3.36it/s] 78%|███████▊  | 390/500 [01:59<00:32,  3.36it/s] 78%|███████▊  | 391/500 [01:59<00:32,  3.36it/s] 78%|███████▊  | 392/500 [02:00<00:32,  3.36it/s] 79%|███████▊  | 393/500 [02:00<00:31,  3.36it/s] 79%|███████▉  | 394/500 [02:00<00:31,  3.35it/s] 79%|███████▉  | 395/500 [02:01<00:31,  3.35it/s] 79%|███████▉  | 396/500 [02:01<00:30,  3.36it/s] 79%|███████▉  | 397/500 [02:01<00:30,  3.36it/s] 80%|███████▉  | 398/500 [02:02<00:30,  3.36it/s] 80%|███████▉  | 399/500 [02:02<00:30,  3.36it/s] 80%|████████  | 400/500 [02:02<00:29,  3.36it/s] 80%|████████  | 401/500 [02:02<00:29,  3.36it/s] 80%|████████  | 402/500 [02:03<00:29,  3.36it/s] 81%|████████  | 403/500 [02:03<00:28,  3.35it/s] 81%|████████  | 404/500 [02:03<00:28,  3.36it/s] 81%|████████  | 405/500 [02:04<00:28,  3.36it/s] 81%|████████  | 406/500 [02:04<00:28,  3.34it/s] 81%|████████▏ | 407/500 [02:04<00:27,  3.35it/s] 82%|████████▏ | 408/500 [02:05<00:27,  3.35it/s] 82%|████████▏ | 409/500 [02:05<00:27,  3.35it/s] 82%|████████▏ | 410/500 [02:05<00:26,  3.35it/s] 82%|████████▏ | 411/500 [02:05<00:26,  3.36it/s] 82%|████████▏ | 412/500 [02:06<00:26,  3.36it/s] 83%|████████▎ | 413/500 [02:06<00:25,  3.36it/s] 83%|████████▎ | 414/500 [02:06<00:25,  3.36it/s] 83%|████████▎ | 415/500 [02:07<00:25,  3.36it/s] 83%|████████▎ | 416/500 [02:07<00:24,  3.36it/s] 83%|████████▎ | 417/500 [02:07<00:24,  3.36it/s] 84%|████████▎ | 418/500 [02:08<00:24,  3.36it/s] 84%|████████▍ | 419/500 [02:08<00:24,  3.36it/s] 84%|████████▍ | 420/500 [02:08<00:23,  3.36it/s] 84%|████████▍ | 421/500 [02:08<00:23,  3.35it/s] 84%|████████▍ | 422/500 [02:09<00:23,  3.35it/s] 85%|████████▍ | 423/500 [02:09<00:22,  3.35it/s] 85%|████████▍ | 424/500 [02:09<00:22,  3.35it/s] 85%|████████▌ | 425/500 [02:10<00:22,  3.35it/s] 85%|████████▌ | 426/500 [02:10<00:22,  3.35it/s] 85%|████████▌ | 427/500 [02:10<00:21,  3.35it/s] 86%|████████▌ | 428/500 [02:11<00:21,  3.35it/s] 86%|████████▌ | 429/500 [02:11<00:21,  3.36it/s] 86%|████████▌ | 430/500 [02:11<00:20,  3.35it/s] 86%|████████▌ | 431/500 [02:11<00:20,  3.35it/s] 86%|████████▋ | 432/500 [02:12<00:20,  3.35it/s] 87%|████████▋ | 433/500 [02:12<00:19,  3.36it/s] 87%|████████▋ | 434/500 [02:12<00:19,  3.36it/s] 87%|████████▋ | 435/500 [02:13<00:19,  3.36it/s] 87%|████████▋ | 436/500 [02:13<00:19,  3.34it/s] 87%|████████▋ | 437/500 [02:13<00:18,  3.35it/s] 88%|████████▊ | 438/500 [02:14<00:18,  3.35it/s] 88%|████████▊ | 439/500 [02:14<00:18,  3.34it/s] 88%|████████▊ | 440/500 [02:14<00:17,  3.35it/s] 88%|████████▊ | 441/500 [02:14<00:17,  3.35it/s] 88%|████████▊ | 442/500 [02:15<00:17,  3.35it/s] 89%|████████▊ | 443/500 [02:15<00:17,  3.35it/s] 89%|████████▉ | 444/500 [02:15<00:16,  3.35it/s] 89%|████████▉ | 445/500 [02:16<00:16,  3.35it/s] 89%|████████▉ | 446/500 [02:16<00:16,  3.34it/s] 89%|████████▉ | 447/500 [02:16<00:15,  3.34it/s] 90%|████████▉ | 448/500 [02:17<00:15,  3.34it/s] 90%|████████▉ | 449/500 [02:17<00:15,  3.35it/s] 90%|█████████ | 450/500 [02:17<00:14,  3.34it/s] 90%|█████████ | 451/500 [02:17<00:14,  3.35it/s] 90%|█████████ | 452/500 [02:18<00:14,  3.33it/s] 91%|█████████ | 453/500 [02:18<00:14,  3.34it/s] 91%|█████████ | 454/500 [02:18<00:13,  3.34it/s] 91%|█████████ | 455/500 [02:19<00:13,  3.34it/s] 91%|█████████ | 456/500 [02:19<00:13,  3.35it/s] 91%|█████████▏| 457/500 [02:19<00:12,  3.35it/s] 92%|█████████▏| 458/500 [02:19<00:12,  3.35it/s] 92%|█████████▏| 459/500 [02:20<00:12,  3.35it/s] 92%|█████████▏| 460/500 [02:20<00:11,  3.35it/s] 92%|█████████▏| 461/500 [02:20<00:11,  3.35it/s] 92%|█████████▏| 462/500 [02:21<00:11,  3.35it/s] 93%|█████████▎| 463/500 [02:21<00:11,  3.35it/s] 93%|█████████▎| 464/500 [02:21<00:10,  3.35it/s] 93%|█████████▎| 465/500 [02:22<00:10,  3.35it/s] 93%|█████████▎| 466/500 [02:22<00:10,  3.35it/s] 93%|█████████▎| 467/500 [02:22<00:09,  3.35it/s] 94%|█████████▎| 468/500 [02:22<00:09,  3.36it/s] 94%|█████████▍| 469/500 [02:23<00:09,  3.36it/s] 94%|█████████▍| 470/500 [02:23<00:08,  3.34it/s] 94%|█████████▍| 471/500 [02:23<00:08,  3.35it/s] 94%|█████████▍| 472/500 [02:24<00:08,  3.35it/s] 95%|█████████▍| 473/500 [02:24<00:08,  3.35it/s] 95%|█████████▍| 474/500 [02:24<00:07,  3.36it/s] 95%|█████████▌| 475/500 [02:25<00:07,  3.36it/s] 95%|█████████▌| 476/500 [02:25<00:07,  3.36it/s] 95%|█████████▌| 477/500 [02:25<00:06,  3.36it/s] 96%|█████████▌| 478/500 [02:25<00:06,  3.36it/s] 96%|█████████▌| 479/500 [02:26<00:06,  3.36it/s] 96%|█████████▌| 480/500 [02:26<00:05,  3.36it/s] 96%|█████████▌| 481/500 [02:26<00:05,  3.36it/s] 96%|█████████▋| 482/500 [02:27<00:05,  3.36it/s] 97%|█████████▋| 483/500 [02:27<00:05,  3.36it/s] 97%|█████████▋| 484/500 [02:27<00:04,  3.36it/s] 97%|█████████▋| 485/500 [02:28<00:04,  3.36it/s] 97%|█████████▋| 486/500 [02:28<00:04,  3.36it/s] 97%|█████████▋| 487/500 [02:28<00:03,  3.37it/s] 98%|█████████▊| 488/500 [02:28<00:03,  3.37it/s] 98%|█████████▊| 489/500 [02:29<00:03,  3.37it/s] 98%|█████████▊| 490/500 [02:29<00:02,  3.37it/s] 98%|█████████▊| 491/500 [02:29<00:02,  3.37it/s] 98%|█████████▊| 492/500 [02:30<00:02,  3.37it/s] 99%|█████████▊| 493/500 [02:30<00:02,  3.37it/s] 99%|█████████▉| 494/500 [02:30<00:01,  3.37it/s] 99%|█████████▉| 495/500 [02:31<00:01,  3.38it/s] 99%|█████████▉| 496/500 [02:31<00:01,  3.38it/s] 99%|█████████▉| 497/500 [02:31<00:00,  3.38it/s]100%|█████████▉| 498/500 [02:31<00:00,  3.38it/s]100%|█████████▉| 499/500 [02:32<00:00,  3.38it/s]100%|██████████| 500/500 [02:32<00:00,  3.38it/s]100%|██████████| 500/500 [02:32<00:00,  3.28it/s]
=> result
* total: 50,000
* correct: 18,752
* accuracy: 37.5%
* error: 62.5%
* macro_f1: 33.9%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat imagenet 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/imagenet/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/imagenet/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:ImageNet
Loading dataset: ImageNet
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ImageNet/split_fewshot_taesup/shot_16-seed_2.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:03<31:31,  3.79s/it]  0%|          | 2/500 [00:04<14:23,  1.73s/it]  1%|          | 3/500 [00:04<09:03,  1.09s/it]  1%|          | 4/500 [00:04<06:29,  1.27it/s]  1%|          | 5/500 [00:05<05:00,  1.65it/s]  1%|          | 6/500 [00:05<04:07,  2.00it/s]  1%|▏         | 7/500 [00:05<03:33,  2.31it/s]  2%|▏         | 8/500 [00:05<03:11,  2.57it/s]  2%|▏         | 9/500 [00:06<02:56,  2.78it/s]  2%|▏         | 10/500 [00:06<02:46,  2.94it/s]  2%|▏         | 11/500 [00:06<02:39,  3.06it/s]  2%|▏         | 12/500 [00:07<02:34,  3.15it/s]  3%|▎         | 13/500 [00:07<02:31,  3.22it/s]  3%|▎         | 14/500 [00:07<02:32,  3.19it/s]  3%|▎         | 15/500 [00:07<02:29,  3.25it/s]  3%|▎         | 16/500 [00:08<02:30,  3.22it/s]  3%|▎         | 17/500 [00:08<02:27,  3.27it/s]  4%|▎         | 18/500 [00:08<02:25,  3.31it/s]  4%|▍         | 19/500 [00:09<02:24,  3.33it/s]  4%|▍         | 20/500 [00:09<02:23,  3.35it/s]  4%|▍         | 21/500 [00:09<02:22,  3.35it/s]  4%|▍         | 22/500 [00:10<02:22,  3.36it/s]  5%|▍         | 23/500 [00:10<02:21,  3.37it/s]  5%|▍         | 24/500 [00:10<02:20,  3.38it/s]  5%|▌         | 25/500 [00:10<02:20,  3.38it/s]  5%|▌         | 26/500 [00:11<02:20,  3.39it/s]  5%|▌         | 27/500 [00:11<02:19,  3.39it/s]  6%|▌         | 28/500 [00:11<02:19,  3.39it/s]  6%|▌         | 29/500 [00:12<02:19,  3.39it/s]  6%|▌         | 30/500 [00:12<02:18,  3.38it/s]  6%|▌         | 31/500 [00:12<02:18,  3.39it/s]  6%|▋         | 32/500 [00:13<02:18,  3.38it/s]  7%|▋         | 33/500 [00:13<02:18,  3.38it/s]  7%|▋         | 34/500 [00:13<02:17,  3.39it/s]  7%|▋         | 35/500 [00:13<02:17,  3.39it/s]  7%|▋         | 36/500 [00:14<02:16,  3.39it/s]  7%|▋         | 37/500 [00:14<02:16,  3.39it/s]  8%|▊         | 38/500 [00:14<02:17,  3.36it/s]  8%|▊         | 39/500 [00:15<02:16,  3.37it/s]  8%|▊         | 40/500 [00:15<02:16,  3.38it/s]  8%|▊         | 41/500 [00:15<02:15,  3.38it/s]  8%|▊         | 42/500 [00:16<02:19,  3.29it/s]  9%|▊         | 43/500 [00:16<02:17,  3.33it/s]  9%|▉         | 44/500 [00:16<02:16,  3.35it/s]  9%|▉         | 45/500 [00:16<02:15,  3.36it/s]  9%|▉         | 46/500 [00:17<02:15,  3.36it/s]  9%|▉         | 47/500 [00:17<02:14,  3.37it/s] 10%|▉         | 48/500 [00:17<02:14,  3.37it/s] 10%|▉         | 49/500 [00:18<02:13,  3.37it/s] 10%|█         | 50/500 [00:18<02:13,  3.37it/s] 10%|█         | 51/500 [00:18<02:13,  3.37it/s] 10%|█         | 52/500 [00:18<02:12,  3.38it/s] 11%|█         | 53/500 [00:19<02:12,  3.38it/s] 11%|█         | 54/500 [00:19<02:12,  3.37it/s] 11%|█         | 55/500 [00:19<02:11,  3.38it/s] 11%|█         | 56/500 [00:20<02:11,  3.38it/s] 11%|█▏        | 57/500 [00:20<02:10,  3.38it/s] 12%|█▏        | 58/500 [00:20<02:10,  3.38it/s] 12%|█▏        | 59/500 [00:21<02:10,  3.38it/s] 12%|█▏        | 60/500 [00:21<02:10,  3.38it/s] 12%|█▏        | 61/500 [00:21<02:09,  3.38it/s] 12%|█▏        | 62/500 [00:21<02:09,  3.38it/s] 13%|█▎        | 63/500 [00:22<02:09,  3.38it/s] 13%|█▎        | 64/500 [00:22<02:08,  3.38it/s] 13%|█▎        | 65/500 [00:22<02:08,  3.38it/s] 13%|█▎        | 66/500 [00:23<02:08,  3.38it/s] 13%|█▎        | 67/500 [00:23<02:08,  3.38it/s] 14%|█▎        | 68/500 [00:23<02:07,  3.38it/s] 14%|█▍        | 69/500 [00:24<02:07,  3.38it/s] 14%|█▍        | 70/500 [00:24<02:07,  3.38it/s] 14%|█▍        | 71/500 [00:24<02:06,  3.38it/s] 14%|█▍        | 72/500 [00:24<02:06,  3.38it/s] 15%|█▍        | 73/500 [00:25<02:06,  3.37it/s] 15%|█▍        | 74/500 [00:25<02:06,  3.37it/s] 15%|█▌        | 75/500 [00:25<02:05,  3.37it/s] 15%|█▌        | 76/500 [00:26<02:05,  3.37it/s] 15%|█▌        | 77/500 [00:26<02:05,  3.37it/s] 16%|█▌        | 78/500 [00:26<02:04,  3.38it/s] 16%|█▌        | 79/500 [00:26<02:04,  3.38it/s] 16%|█▌        | 80/500 [00:27<02:04,  3.37it/s] 16%|█▌        | 81/500 [00:27<02:04,  3.37it/s] 16%|█▋        | 82/500 [00:27<02:03,  3.37it/s] 17%|█▋        | 83/500 [00:28<02:03,  3.37it/s] 17%|█▋        | 84/500 [00:28<02:03,  3.37it/s] 17%|█▋        | 85/500 [00:28<02:02,  3.38it/s] 17%|█▋        | 86/500 [00:29<02:02,  3.38it/s] 17%|█▋        | 87/500 [00:29<02:02,  3.38it/s] 18%|█▊        | 88/500 [00:29<02:02,  3.38it/s] 18%|█▊        | 89/500 [00:29<02:01,  3.37it/s] 18%|█▊        | 90/500 [00:30<02:01,  3.37it/s] 18%|█▊        | 91/500 [00:30<02:01,  3.37it/s] 18%|█▊        | 92/500 [00:30<02:01,  3.37it/s] 19%|█▊        | 93/500 [00:31<02:00,  3.37it/s] 19%|█▉        | 94/500 [00:31<02:00,  3.37it/s] 19%|█▉        | 95/500 [00:31<02:00,  3.37it/s] 19%|█▉        | 96/500 [00:32<01:59,  3.37it/s] 19%|█▉        | 97/500 [00:32<01:59,  3.36it/s] 20%|█▉        | 98/500 [00:32<01:59,  3.37it/s] 20%|█▉        | 99/500 [00:32<01:58,  3.37it/s] 20%|██        | 100/500 [00:33<01:58,  3.37it/s] 20%|██        | 101/500 [00:33<01:58,  3.36it/s] 20%|██        | 102/500 [00:33<01:58,  3.36it/s] 21%|██        | 103/500 [00:34<01:57,  3.36it/s] 21%|██        | 104/500 [00:34<01:57,  3.36it/s] 21%|██        | 105/500 [00:34<01:57,  3.37it/s] 21%|██        | 106/500 [00:34<01:57,  3.36it/s] 21%|██▏       | 107/500 [00:35<01:56,  3.36it/s] 22%|██▏       | 108/500 [00:35<01:56,  3.37it/s] 22%|██▏       | 109/500 [00:35<01:56,  3.36it/s] 22%|██▏       | 110/500 [00:36<01:55,  3.36it/s] 22%|██▏       | 111/500 [00:36<01:55,  3.37it/s] 22%|██▏       | 112/500 [00:36<01:55,  3.36it/s] 23%|██▎       | 113/500 [00:37<01:55,  3.36it/s] 23%|██▎       | 114/500 [00:37<01:54,  3.37it/s] 23%|██▎       | 115/500 [00:37<01:54,  3.37it/s] 23%|██▎       | 116/500 [00:37<01:54,  3.37it/s] 23%|██▎       | 117/500 [00:38<01:53,  3.37it/s] 24%|██▎       | 118/500 [00:38<01:53,  3.37it/s] 24%|██▍       | 119/500 [00:38<01:53,  3.37it/s] 24%|██▍       | 120/500 [00:39<01:52,  3.36it/s] 24%|██▍       | 121/500 [00:39<01:52,  3.36it/s] 24%|██▍       | 122/500 [00:39<01:52,  3.36it/s] 25%|██▍       | 123/500 [00:40<01:52,  3.36it/s] 25%|██▍       | 124/500 [00:40<01:51,  3.36it/s] 25%|██▌       | 125/500 [00:40<01:51,  3.36it/s] 25%|██▌       | 126/500 [00:40<01:51,  3.36it/s] 25%|██▌       | 127/500 [00:41<01:51,  3.36it/s] 26%|██▌       | 128/500 [00:41<01:50,  3.36it/s] 26%|██▌       | 129/500 [00:41<01:50,  3.36it/s] 26%|██▌       | 130/500 [00:42<01:50,  3.36it/s] 26%|██▌       | 131/500 [00:42<01:49,  3.36it/s] 26%|██▋       | 132/500 [00:42<01:49,  3.36it/s] 27%|██▋       | 133/500 [00:43<01:49,  3.35it/s] 27%|██▋       | 134/500 [00:43<01:49,  3.35it/s] 27%|██▋       | 135/500 [00:43<01:48,  3.36it/s] 27%|██▋       | 136/500 [00:43<01:48,  3.35it/s] 27%|██▋       | 137/500 [00:44<01:48,  3.35it/s] 28%|██▊       | 138/500 [00:44<01:47,  3.35it/s] 28%|██▊       | 139/500 [00:44<01:47,  3.36it/s] 28%|██▊       | 140/500 [00:45<01:47,  3.36it/s] 28%|██▊       | 141/500 [00:45<01:46,  3.36it/s] 28%|██▊       | 142/500 [00:45<01:46,  3.36it/s] 29%|██▊       | 143/500 [00:45<01:46,  3.35it/s] 29%|██▉       | 144/500 [00:46<01:46,  3.35it/s] 29%|██▉       | 145/500 [00:46<01:45,  3.35it/s] 29%|██▉       | 146/500 [00:46<01:45,  3.35it/s] 29%|██▉       | 147/500 [00:47<01:45,  3.35it/s] 30%|██▉       | 148/500 [00:47<01:44,  3.35it/s] 30%|██▉       | 149/500 [00:47<01:44,  3.36it/s] 30%|███       | 150/500 [00:48<01:44,  3.36it/s] 30%|███       | 151/500 [00:48<01:43,  3.36it/s] 30%|███       | 152/500 [00:48<01:43,  3.36it/s] 31%|███       | 153/500 [00:48<01:43,  3.36it/s] 31%|███       | 154/500 [00:49<01:43,  3.36it/s] 31%|███       | 155/500 [00:49<01:42,  3.36it/s] 31%|███       | 156/500 [00:49<01:42,  3.36it/s] 31%|███▏      | 157/500 [00:50<01:42,  3.34it/s] 32%|███▏      | 158/500 [00:50<01:42,  3.35it/s] 32%|███▏      | 159/500 [00:50<01:41,  3.35it/s] 32%|███▏      | 160/500 [00:51<01:41,  3.35it/s] 32%|███▏      | 161/500 [00:51<01:41,  3.35it/s] 32%|███▏      | 162/500 [00:51<01:40,  3.36it/s] 33%|███▎      | 163/500 [00:51<01:40,  3.36it/s] 33%|███▎      | 164/500 [00:52<01:40,  3.35it/s] 33%|███▎      | 165/500 [00:52<01:39,  3.35it/s] 33%|███▎      | 166/500 [00:52<01:39,  3.35it/s] 33%|███▎      | 167/500 [00:53<01:39,  3.35it/s] 34%|███▎      | 168/500 [00:53<01:39,  3.35it/s] 34%|███▍      | 169/500 [00:53<01:38,  3.35it/s] 34%|███▍      | 170/500 [00:54<01:38,  3.35it/s] 34%|███▍      | 171/500 [00:54<01:38,  3.35it/s] 34%|███▍      | 172/500 [00:54<01:37,  3.35it/s] 35%|███▍      | 173/500 [00:54<01:37,  3.36it/s] 35%|███▍      | 174/500 [00:55<01:37,  3.35it/s] 35%|███▌      | 175/500 [00:55<01:36,  3.35it/s] 35%|███▌      | 176/500 [00:55<01:36,  3.35it/s] 35%|███▌      | 177/500 [00:56<01:36,  3.35it/s] 36%|███▌      | 178/500 [00:56<01:36,  3.35it/s] 36%|███▌      | 179/500 [00:56<01:35,  3.35it/s] 36%|███▌      | 180/500 [00:57<01:35,  3.35it/s] 36%|███▌      | 181/500 [00:57<01:35,  3.35it/s] 36%|███▋      | 182/500 [00:57<01:34,  3.35it/s] 37%|███▋      | 183/500 [00:57<01:34,  3.36it/s] 37%|███▋      | 184/500 [00:58<01:34,  3.35it/s] 37%|███▋      | 185/500 [00:58<01:34,  3.35it/s] 37%|███▋      | 186/500 [00:58<01:33,  3.35it/s] 37%|███▋      | 187/500 [00:59<01:33,  3.35it/s] 38%|███▊      | 188/500 [00:59<01:33,  3.35it/s] 38%|███▊      | 189/500 [00:59<01:32,  3.35it/s] 38%|███▊      | 190/500 [01:00<01:32,  3.35it/s] 38%|███▊      | 191/500 [01:00<01:32,  3.34it/s] 38%|███▊      | 192/500 [01:00<01:32,  3.35it/s] 39%|███▊      | 193/500 [01:00<01:31,  3.35it/s] 39%|███▉      | 194/500 [01:01<01:31,  3.35it/s] 39%|███▉      | 195/500 [01:01<01:30,  3.35it/s] 39%|███▉      | 196/500 [01:01<01:30,  3.35it/s] 39%|███▉      | 197/500 [01:02<01:30,  3.35it/s] 40%|███▉      | 198/500 [01:02<01:30,  3.35it/s] 40%|███▉      | 199/500 [01:02<01:29,  3.35it/s] 40%|████      | 200/500 [01:03<01:29,  3.34it/s] 40%|████      | 201/500 [01:03<01:29,  3.34it/s] 40%|████      | 202/500 [01:03<01:29,  3.35it/s] 41%|████      | 203/500 [01:03<01:28,  3.35it/s] 41%|████      | 204/500 [01:04<01:28,  3.35it/s] 41%|████      | 205/500 [01:04<01:28,  3.35it/s] 41%|████      | 206/500 [01:04<01:27,  3.35it/s] 41%|████▏     | 207/500 [01:05<01:27,  3.35it/s] 42%|████▏     | 208/500 [01:05<01:27,  3.35it/s] 42%|████▏     | 209/500 [01:05<01:26,  3.35it/s] 42%|████▏     | 210/500 [01:05<01:26,  3.34it/s] 42%|████▏     | 211/500 [01:06<01:26,  3.34it/s] 42%|████▏     | 212/500 [01:06<01:26,  3.33it/s] 43%|████▎     | 213/500 [01:06<01:26,  3.33it/s] 43%|████▎     | 214/500 [01:07<01:25,  3.33it/s] 43%|████▎     | 215/500 [01:07<01:25,  3.33it/s] 43%|████▎     | 216/500 [01:07<01:25,  3.33it/s] 43%|████▎     | 217/500 [01:08<01:25,  3.33it/s] 44%|████▎     | 218/500 [01:08<01:24,  3.33it/s] 44%|████▍     | 219/500 [01:08<01:24,  3.33it/s] 44%|████▍     | 220/500 [01:09<01:24,  3.33it/s] 44%|████▍     | 221/500 [01:09<01:23,  3.33it/s] 44%|████▍     | 222/500 [01:09<01:23,  3.34it/s] 45%|████▍     | 223/500 [01:09<01:22,  3.34it/s] 45%|████▍     | 224/500 [01:10<01:22,  3.35it/s] 45%|████▌     | 225/500 [01:10<01:22,  3.34it/s] 45%|████▌     | 226/500 [01:10<01:21,  3.35it/s] 45%|████▌     | 227/500 [01:11<01:21,  3.35it/s] 46%|████▌     | 228/500 [01:11<01:21,  3.35it/s] 46%|████▌     | 229/500 [01:11<01:20,  3.35it/s] 46%|████▌     | 230/500 [01:11<01:20,  3.34it/s] 46%|████▌     | 231/500 [01:12<01:20,  3.35it/s] 46%|████▋     | 232/500 [01:12<01:20,  3.35it/s] 47%|████▋     | 233/500 [01:12<01:19,  3.35it/s] 47%|████▋     | 234/500 [01:13<01:19,  3.35it/s] 47%|████▋     | 235/500 [01:13<01:19,  3.33it/s] 47%|████▋     | 236/500 [01:13<01:19,  3.33it/s] 47%|████▋     | 237/500 [01:14<01:18,  3.34it/s] 48%|████▊     | 238/500 [01:14<01:18,  3.34it/s] 48%|████▊     | 239/500 [01:14<01:18,  3.34it/s] 48%|████▊     | 240/500 [01:14<01:17,  3.34it/s] 48%|████▊     | 241/500 [01:15<01:17,  3.35it/s] 48%|████▊     | 242/500 [01:15<01:17,  3.34it/s] 49%|████▊     | 243/500 [01:15<01:16,  3.34it/s] 49%|████▉     | 244/500 [01:16<01:16,  3.34it/s] 49%|████▉     | 245/500 [01:16<01:16,  3.34it/s] 49%|████▉     | 246/500 [01:16<01:15,  3.35it/s] 49%|████▉     | 247/500 [01:17<01:15,  3.34it/s] 50%|████▉     | 248/500 [01:17<01:15,  3.35it/s] 50%|████▉     | 249/500 [01:17<01:14,  3.35it/s] 50%|█████     | 250/500 [01:17<01:14,  3.35it/s] 50%|█████     | 251/500 [01:18<01:14,  3.35it/s] 50%|█████     | 252/500 [01:18<01:14,  3.35it/s] 51%|█████     | 253/500 [01:18<01:13,  3.35it/s] 51%|█████     | 254/500 [01:19<01:13,  3.36it/s] 51%|█████     | 255/500 [01:19<01:12,  3.36it/s] 51%|█████     | 256/500 [01:19<01:12,  3.37it/s] 51%|█████▏    | 257/500 [01:20<01:12,  3.36it/s] 52%|█████▏    | 258/500 [01:20<01:12,  3.36it/s] 52%|█████▏    | 259/500 [01:20<01:11,  3.35it/s] 52%|█████▏    | 260/500 [01:20<01:11,  3.34it/s] 52%|█████▏    | 261/500 [01:21<01:11,  3.35it/s] 52%|█████▏    | 262/500 [01:21<01:10,  3.35it/s] 53%|█████▎    | 263/500 [01:21<01:10,  3.36it/s] 53%|█████▎    | 264/500 [01:22<01:10,  3.36it/s] 53%|█████▎    | 265/500 [01:22<01:09,  3.36it/s] 53%|█████▎    | 266/500 [01:22<01:09,  3.36it/s] 53%|█████▎    | 267/500 [01:23<01:09,  3.35it/s] 54%|█████▎    | 268/500 [01:23<01:09,  3.35it/s] 54%|█████▍    | 269/500 [01:23<01:08,  3.35it/s] 54%|█████▍    | 270/500 [01:23<01:08,  3.35it/s] 54%|█████▍    | 271/500 [01:24<01:08,  3.35it/s] 54%|█████▍    | 272/500 [01:24<01:07,  3.35it/s] 55%|█████▍    | 273/500 [01:24<01:07,  3.35it/s] 55%|█████▍    | 274/500 [01:25<01:07,  3.35it/s] 55%|█████▌    | 275/500 [01:25<01:07,  3.35it/s] 55%|█████▌    | 276/500 [01:25<01:06,  3.35it/s] 55%|█████▌    | 277/500 [01:26<01:06,  3.35it/s] 56%|█████▌    | 278/500 [01:26<01:06,  3.35it/s] 56%|█████▌    | 279/500 [01:26<01:05,  3.35it/s] 56%|█████▌    | 280/500 [01:26<01:05,  3.35it/s] 56%|█████▌    | 281/500 [01:27<01:05,  3.34it/s] 56%|█████▋    | 282/500 [01:27<01:05,  3.35it/s] 57%|█████▋    | 283/500 [01:27<01:04,  3.34it/s] 57%|█████▋    | 284/500 [01:28<01:04,  3.35it/s] 57%|█████▋    | 285/500 [01:28<01:04,  3.35it/s] 57%|█████▋    | 286/500 [01:28<01:03,  3.35it/s] 57%|█████▋    | 287/500 [01:29<01:03,  3.35it/s] 58%|█████▊    | 288/500 [01:29<01:03,  3.35it/s] 58%|█████▊    | 289/500 [01:29<01:03,  3.35it/s] 58%|█████▊    | 290/500 [01:29<01:02,  3.35it/s] 58%|█████▊    | 291/500 [01:30<01:02,  3.35it/s] 58%|█████▊    | 292/500 [01:30<01:01,  3.36it/s] 59%|█████▊    | 293/500 [01:30<01:01,  3.36it/s] 59%|█████▉    | 294/500 [01:31<01:01,  3.35it/s] 59%|█████▉    | 295/500 [01:31<01:01,  3.34it/s] 59%|█████▉    | 296/500 [01:31<01:01,  3.34it/s] 59%|█████▉    | 297/500 [01:31<01:00,  3.35it/s] 60%|█████▉    | 298/500 [01:32<01:00,  3.33it/s] 60%|█████▉    | 299/500 [01:32<01:00,  3.34it/s] 60%|██████    | 300/500 [01:32<00:59,  3.34it/s] 60%|██████    | 301/500 [01:33<00:59,  3.35it/s] 60%|██████    | 302/500 [01:33<00:59,  3.35it/s] 61%|██████    | 303/500 [01:33<00:58,  3.35it/s] 61%|██████    | 304/500 [01:34<00:58,  3.35it/s] 61%|██████    | 305/500 [01:34<00:58,  3.34it/s] 61%|██████    | 306/500 [01:34<00:58,  3.34it/s] 61%|██████▏   | 307/500 [01:34<00:57,  3.35it/s] 62%|██████▏   | 308/500 [01:35<00:57,  3.35it/s] 62%|██████▏   | 309/500 [01:35<00:57,  3.35it/s] 62%|██████▏   | 310/500 [01:35<00:56,  3.35it/s] 62%|██████▏   | 311/500 [01:36<00:56,  3.35it/s] 62%|██████▏   | 312/500 [01:36<00:56,  3.35it/s] 63%|██████▎   | 313/500 [01:36<00:55,  3.35it/s] 63%|██████▎   | 314/500 [01:37<00:55,  3.35it/s] 63%|██████▎   | 315/500 [01:37<00:55,  3.34it/s] 63%|██████▎   | 316/500 [01:37<00:55,  3.34it/s] 63%|██████▎   | 317/500 [01:37<00:54,  3.35it/s] 64%|██████▎   | 318/500 [01:38<00:54,  3.34it/s] 64%|██████▍   | 319/500 [01:38<00:54,  3.34it/s] 64%|██████▍   | 320/500 [01:38<00:53,  3.34it/s] 64%|██████▍   | 321/500 [01:39<00:53,  3.35it/s] 64%|██████▍   | 322/500 [01:39<00:53,  3.34it/s] 65%|██████▍   | 323/500 [01:39<00:52,  3.34it/s] 65%|██████▍   | 324/500 [01:40<00:52,  3.35it/s] 65%|██████▌   | 325/500 [01:40<00:52,  3.35it/s] 65%|██████▌   | 326/500 [01:40<00:51,  3.35it/s] 65%|██████▌   | 327/500 [01:40<00:51,  3.35it/s] 66%|██████▌   | 328/500 [01:41<00:51,  3.36it/s] 66%|██████▌   | 329/500 [01:41<00:50,  3.35it/s] 66%|██████▌   | 330/500 [01:41<00:50,  3.35it/s] 66%|██████▌   | 331/500 [01:42<00:50,  3.35it/s] 66%|██████▋   | 332/500 [01:42<00:50,  3.35it/s] 67%|██████▋   | 333/500 [01:42<00:49,  3.35it/s] 67%|██████▋   | 334/500 [01:43<00:49,  3.35it/s] 67%|██████▋   | 335/500 [01:43<00:49,  3.35it/s] 67%|██████▋   | 336/500 [01:43<00:48,  3.35it/s] 67%|██████▋   | 337/500 [01:43<00:48,  3.35it/s] 68%|██████▊   | 338/500 [01:44<00:48,  3.35it/s] 68%|██████▊   | 339/500 [01:44<00:48,  3.35it/s] 68%|██████▊   | 340/500 [01:44<00:47,  3.36it/s] 68%|██████▊   | 341/500 [01:45<00:47,  3.36it/s] 68%|██████▊   | 342/500 [01:45<00:47,  3.36it/s] 69%|██████▊   | 343/500 [01:45<00:46,  3.35it/s] 69%|██████▉   | 344/500 [01:46<00:46,  3.33it/s] 69%|██████▉   | 345/500 [01:46<00:46,  3.34it/s] 69%|██████▉   | 346/500 [01:46<00:46,  3.34it/s] 69%|██████▉   | 347/500 [01:46<00:45,  3.34it/s] 70%|██████▉   | 348/500 [01:47<00:45,  3.35it/s] 70%|██████▉   | 349/500 [01:47<00:45,  3.35it/s] 70%|███████   | 350/500 [01:47<00:44,  3.35it/s] 70%|███████   | 351/500 [01:48<00:44,  3.35it/s] 70%|███████   | 352/500 [01:48<00:44,  3.35it/s] 71%|███████   | 353/500 [01:48<00:43,  3.35it/s] 71%|███████   | 354/500 [01:49<00:43,  3.35it/s] 71%|███████   | 355/500 [01:49<00:43,  3.35it/s] 71%|███████   | 356/500 [01:49<00:42,  3.35it/s] 71%|███████▏  | 357/500 [01:49<00:42,  3.36it/s] 72%|███████▏  | 358/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 359/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 360/500 [01:50<00:41,  3.35it/s] 72%|███████▏  | 361/500 [01:51<00:41,  3.36it/s] 72%|███████▏  | 362/500 [01:51<00:41,  3.35it/s] 73%|███████▎  | 363/500 [01:51<00:40,  3.35it/s] 73%|███████▎  | 364/500 [01:52<00:40,  3.35it/s] 73%|███████▎  | 365/500 [01:52<00:40,  3.35it/s] 73%|███████▎  | 366/500 [01:52<00:40,  3.35it/s] 73%|███████▎  | 367/500 [01:52<00:39,  3.34it/s] 74%|███████▎  | 368/500 [01:53<00:39,  3.34it/s] 74%|███████▍  | 369/500 [01:53<00:39,  3.34it/s] 74%|███████▍  | 370/500 [01:53<00:38,  3.35it/s] 74%|███████▍  | 371/500 [01:54<00:38,  3.35it/s] 74%|███████▍  | 372/500 [01:54<00:38,  3.35it/s] 75%|███████▍  | 373/500 [01:54<00:37,  3.35it/s] 75%|███████▍  | 374/500 [01:54<00:37,  3.34it/s] 75%|███████▌  | 375/500 [01:55<00:37,  3.34it/s] 75%|███████▌  | 376/500 [01:55<00:37,  3.34it/s] 75%|███████▌  | 377/500 [01:55<00:36,  3.34it/s] 76%|███████▌  | 378/500 [01:56<00:36,  3.34it/s] 76%|███████▌  | 379/500 [01:56<00:36,  3.34it/s] 76%|███████▌  | 380/500 [01:56<00:35,  3.34it/s] 76%|███████▌  | 381/500 [01:57<00:35,  3.34it/s] 76%|███████▋  | 382/500 [01:57<00:35,  3.34it/s] 77%|███████▋  | 383/500 [01:57<00:34,  3.34it/s] 77%|███████▋  | 384/500 [01:57<00:34,  3.35it/s] 77%|███████▋  | 385/500 [01:58<00:34,  3.35it/s] 77%|███████▋  | 386/500 [01:58<00:34,  3.35it/s] 77%|███████▋  | 387/500 [01:58<00:33,  3.35it/s] 78%|███████▊  | 388/500 [01:59<00:33,  3.35it/s] 78%|███████▊  | 389/500 [01:59<00:33,  3.35it/s] 78%|███████▊  | 390/500 [01:59<00:32,  3.35it/s] 78%|███████▊  | 391/500 [02:00<00:32,  3.35it/s] 78%|███████▊  | 392/500 [02:00<00:32,  3.34it/s] 79%|███████▊  | 393/500 [02:00<00:32,  3.34it/s] 79%|███████▉  | 394/500 [02:00<00:31,  3.34it/s] 79%|███████▉  | 395/500 [02:01<00:31,  3.34it/s] 79%|███████▉  | 396/500 [02:01<00:31,  3.34it/s] 79%|███████▉  | 397/500 [02:01<00:30,  3.35it/s] 80%|███████▉  | 398/500 [02:02<00:30,  3.35it/s] 80%|███████▉  | 399/500 [02:02<00:30,  3.35it/s] 80%|████████  | 400/500 [02:02<00:29,  3.35it/s] 80%|████████  | 401/500 [02:03<00:29,  3.35it/s] 80%|████████  | 402/500 [02:03<00:29,  3.35it/s] 81%|████████  | 403/500 [02:03<00:28,  3.35it/s] 81%|████████  | 404/500 [02:03<00:28,  3.35it/s] 81%|████████  | 405/500 [02:04<00:28,  3.34it/s] 81%|████████  | 406/500 [02:04<00:28,  3.34it/s] 81%|████████▏ | 407/500 [02:04<00:27,  3.34it/s] 82%|████████▏ | 408/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 409/500 [02:05<00:27,  3.34it/s] 82%|████████▏ | 410/500 [02:05<00:26,  3.35it/s] 82%|████████▏ | 411/500 [02:06<00:26,  3.35it/s] 82%|████████▏ | 412/500 [02:06<00:26,  3.35it/s] 83%|████████▎ | 413/500 [02:06<00:25,  3.35it/s] 83%|████████▎ | 414/500 [02:06<00:25,  3.35it/s] 83%|████████▎ | 415/500 [02:07<00:25,  3.35it/s] 83%|████████▎ | 416/500 [02:07<00:25,  3.34it/s] 83%|████████▎ | 417/500 [02:07<00:24,  3.34it/s] 84%|████████▎ | 418/500 [02:08<00:24,  3.34it/s] 84%|████████▍ | 419/500 [02:08<00:24,  3.34it/s] 84%|████████▍ | 420/500 [02:08<00:23,  3.34it/s] 84%|████████▍ | 421/500 [02:09<00:23,  3.34it/s] 84%|████████▍ | 422/500 [02:09<00:23,  3.33it/s] 85%|████████▍ | 423/500 [02:09<00:23,  3.34it/s] 85%|████████▍ | 424/500 [02:09<00:22,  3.34it/s] 85%|████████▌ | 425/500 [02:10<00:22,  3.34it/s] 85%|████████▌ | 426/500 [02:10<00:22,  3.35it/s] 85%|████████▌ | 427/500 [02:10<00:21,  3.35it/s] 86%|████████▌ | 428/500 [02:11<00:21,  3.35it/s] 86%|████████▌ | 429/500 [02:11<00:21,  3.35it/s] 86%|████████▌ | 430/500 [02:11<00:20,  3.35it/s] 86%|████████▌ | 431/500 [02:12<00:20,  3.36it/s] 86%|████████▋ | 432/500 [02:12<00:20,  3.35it/s] 87%|████████▋ | 433/500 [02:12<00:20,  3.35it/s] 87%|████████▋ | 434/500 [02:12<00:19,  3.35it/s] 87%|████████▋ | 435/500 [02:13<00:19,  3.35it/s] 87%|████████▋ | 436/500 [02:13<00:19,  3.35it/s] 87%|████████▋ | 437/500 [02:13<00:18,  3.35it/s] 88%|████████▊ | 438/500 [02:14<00:18,  3.34it/s] 88%|████████▊ | 439/500 [02:14<00:18,  3.34it/s] 88%|████████▊ | 440/500 [02:14<00:17,  3.35it/s] 88%|████████▊ | 441/500 [02:15<00:17,  3.35it/s] 88%|████████▊ | 442/500 [02:15<00:17,  3.35it/s] 89%|████████▊ | 443/500 [02:15<00:17,  3.35it/s] 89%|████████▉ | 444/500 [02:15<00:16,  3.35it/s] 89%|████████▉ | 445/500 [02:16<00:16,  3.35it/s] 89%|████████▉ | 446/500 [02:16<00:16,  3.35it/s] 89%|████████▉ | 447/500 [02:16<00:15,  3.35it/s] 90%|████████▉ | 448/500 [02:17<00:15,  3.35it/s] 90%|████████▉ | 449/500 [02:17<00:15,  3.35it/s] 90%|█████████ | 450/500 [02:17<00:14,  3.35it/s] 90%|█████████ | 451/500 [02:17<00:14,  3.35it/s] 90%|█████████ | 452/500 [02:18<00:14,  3.35it/s] 91%|█████████ | 453/500 [02:18<00:14,  3.35it/s] 91%|█████████ | 454/500 [02:18<00:13,  3.35it/s] 91%|█████████ | 455/500 [02:19<00:13,  3.35it/s] 91%|█████████ | 456/500 [02:19<00:13,  3.35it/s] 91%|█████████▏| 457/500 [02:19<00:12,  3.34it/s] 92%|█████████▏| 458/500 [02:20<00:12,  3.34it/s] 92%|█████████▏| 459/500 [02:20<00:12,  3.34it/s] 92%|█████████▏| 460/500 [02:20<00:11,  3.35it/s] 92%|█████████▏| 461/500 [02:20<00:11,  3.35it/s] 92%|█████████▏| 462/500 [02:21<00:11,  3.35it/s] 93%|█████████▎| 463/500 [02:21<00:11,  3.35it/s] 93%|█████████▎| 464/500 [02:21<00:10,  3.35it/s] 93%|█████████▎| 465/500 [02:22<00:10,  3.35it/s] 93%|█████████▎| 466/500 [02:22<00:10,  3.35it/s] 93%|█████████▎| 467/500 [02:22<00:09,  3.35it/s] 94%|█████████▎| 468/500 [02:23<00:09,  3.35it/s] 94%|█████████▍| 469/500 [02:23<00:09,  3.35it/s] 94%|█████████▍| 470/500 [02:23<00:08,  3.35it/s] 94%|█████████▍| 471/500 [02:23<00:08,  3.35it/s] 94%|█████████▍| 472/500 [02:24<00:08,  3.33it/s] 95%|█████████▍| 473/500 [02:24<00:08,  3.34it/s] 95%|█████████▍| 474/500 [02:24<00:07,  3.34it/s] 95%|█████████▌| 475/500 [02:25<00:07,  3.34it/s] 95%|█████████▌| 476/500 [02:25<00:07,  3.34it/s] 95%|█████████▌| 477/500 [02:25<00:06,  3.34it/s] 96%|█████████▌| 478/500 [02:26<00:06,  3.34it/s] 96%|█████████▌| 479/500 [02:26<00:06,  3.34it/s] 96%|█████████▌| 480/500 [02:26<00:05,  3.34it/s] 96%|█████████▌| 481/500 [02:26<00:05,  3.34it/s] 96%|█████████▋| 482/500 [02:27<00:05,  3.34it/s] 97%|█████████▋| 483/500 [02:27<00:05,  3.34it/s] 97%|█████████▋| 484/500 [02:27<00:04,  3.34it/s] 97%|█████████▋| 485/500 [02:28<00:04,  3.34it/s] 97%|█████████▋| 486/500 [02:28<00:04,  3.35it/s] 97%|█████████▋| 487/500 [02:28<00:03,  3.35it/s] 98%|█████████▊| 488/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 489/500 [02:29<00:03,  3.36it/s] 98%|█████████▊| 490/500 [02:29<00:02,  3.36it/s] 98%|█████████▊| 491/500 [02:29<00:02,  3.36it/s] 98%|█████████▊| 492/500 [02:30<00:02,  3.36it/s] 99%|█████████▊| 493/500 [02:30<00:02,  3.37it/s] 99%|█████████▉| 494/500 [02:30<00:01,  3.37it/s] 99%|█████████▉| 495/500 [02:31<00:01,  3.37it/s] 99%|█████████▉| 496/500 [02:31<00:01,  3.37it/s] 99%|█████████▉| 497/500 [02:31<00:00,  3.37it/s]100%|█████████▉| 498/500 [02:32<00:00,  3.37it/s]100%|█████████▉| 499/500 [02:32<00:00,  3.37it/s]100%|██████████| 500/500 [02:32<00:00,  3.37it/s]100%|██████████| 500/500 [02:32<00:00,  3.27it/s]
=> result
* total: 50,000
* correct: 16,776
* accuracy: 33.6%
* error: 66.4%
* macro_f1: 29.4%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat imagenet 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/imagenet/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/imagenet/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:ImageNet
Loading dataset: ImageNet
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ImageNet/split_fewshot_taesup/shot_16-seed_3.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:04<35:34,  4.28s/it]  0%|          | 2/500 [00:04<16:03,  1.93s/it]  1%|          | 3/500 [00:04<09:48,  1.19s/it]  1%|          | 4/500 [00:05<06:53,  1.20it/s]  1%|          | 5/500 [00:05<05:16,  1.56it/s]  1%|          | 6/500 [00:05<04:18,  1.91it/s]  1%|▏         | 7/500 [00:06<03:41,  2.23it/s]  2%|▏         | 8/500 [00:06<03:16,  2.50it/s]  2%|▏         | 9/500 [00:06<03:00,  2.73it/s]  2%|▏         | 10/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:07<02:41,  3.03it/s]  2%|▏         | 12/500 [00:07<02:35,  3.13it/s]  3%|▎         | 13/500 [00:07<02:32,  3.20it/s]  3%|▎         | 14/500 [00:08<02:29,  3.26it/s]  3%|▎         | 15/500 [00:08<02:27,  3.30it/s]  3%|▎         | 16/500 [00:08<02:25,  3.32it/s]  3%|▎         | 17/500 [00:09<02:24,  3.33it/s]  4%|▎         | 18/500 [00:09<02:23,  3.35it/s]  4%|▍         | 19/500 [00:09<02:23,  3.36it/s]  4%|▍         | 20/500 [00:09<02:22,  3.36it/s]  4%|▍         | 21/500 [00:10<02:22,  3.36it/s]  4%|▍         | 22/500 [00:10<02:21,  3.37it/s]  5%|▍         | 23/500 [00:10<02:21,  3.38it/s]  5%|▍         | 24/500 [00:11<02:20,  3.38it/s]  5%|▌         | 25/500 [00:11<02:20,  3.38it/s]  5%|▌         | 26/500 [00:11<02:20,  3.39it/s]  5%|▌         | 27/500 [00:11<02:20,  3.38it/s]  6%|▌         | 28/500 [00:12<02:19,  3.38it/s]  6%|▌         | 29/500 [00:12<02:19,  3.37it/s]  6%|▌         | 30/500 [00:12<02:19,  3.38it/s]  6%|▌         | 31/500 [00:13<02:19,  3.36it/s]  6%|▋         | 32/500 [00:13<02:18,  3.37it/s]  7%|▋         | 33/500 [00:13<02:18,  3.37it/s]  7%|▋         | 34/500 [00:14<02:18,  3.38it/s]  7%|▋         | 35/500 [00:14<02:17,  3.37it/s]  7%|▋         | 36/500 [00:14<02:17,  3.37it/s]  7%|▋         | 37/500 [00:14<02:17,  3.37it/s]  8%|▊         | 38/500 [00:15<02:16,  3.37it/s]  8%|▊         | 39/500 [00:15<02:16,  3.37it/s]  8%|▊         | 40/500 [00:15<02:16,  3.38it/s]  8%|▊         | 41/500 [00:16<02:15,  3.38it/s]  8%|▊         | 42/500 [00:16<02:15,  3.38it/s]  9%|▊         | 43/500 [00:16<02:15,  3.38it/s]  9%|▉         | 44/500 [00:16<02:15,  3.38it/s]  9%|▉         | 45/500 [00:17<02:14,  3.38it/s]  9%|▉         | 46/500 [00:17<02:14,  3.38it/s]  9%|▉         | 47/500 [00:17<02:14,  3.37it/s] 10%|▉         | 48/500 [00:18<02:13,  3.37it/s] 10%|▉         | 49/500 [00:18<02:13,  3.37it/s] 10%|█         | 50/500 [00:18<02:13,  3.37it/s] 10%|█         | 51/500 [00:19<02:13,  3.37it/s] 10%|█         | 52/500 [00:19<02:12,  3.37it/s] 11%|█         | 53/500 [00:19<02:12,  3.37it/s] 11%|█         | 54/500 [00:19<02:12,  3.37it/s] 11%|█         | 55/500 [00:20<02:11,  3.37it/s] 11%|█         | 56/500 [00:20<02:11,  3.38it/s] 11%|█▏        | 57/500 [00:20<02:11,  3.38it/s] 12%|█▏        | 58/500 [00:21<02:10,  3.38it/s] 12%|█▏        | 59/500 [00:21<02:10,  3.38it/s] 12%|█▏        | 60/500 [00:21<02:09,  3.39it/s] 12%|█▏        | 61/500 [00:22<02:09,  3.39it/s] 12%|█▏        | 62/500 [00:22<02:09,  3.39it/s] 13%|█▎        | 63/500 [00:22<02:09,  3.39it/s] 13%|█▎        | 64/500 [00:22<02:08,  3.39it/s] 13%|█▎        | 65/500 [00:23<02:08,  3.38it/s] 13%|█▎        | 66/500 [00:23<02:08,  3.38it/s] 13%|█▎        | 67/500 [00:23<02:08,  3.37it/s] 14%|█▎        | 68/500 [00:24<02:08,  3.36it/s] 14%|█▍        | 69/500 [00:24<02:08,  3.37it/s] 14%|█▍        | 70/500 [00:24<02:07,  3.37it/s] 14%|█▍        | 71/500 [00:24<02:07,  3.37it/s] 14%|█▍        | 72/500 [00:25<02:07,  3.37it/s] 15%|█▍        | 73/500 [00:25<02:06,  3.37it/s] 15%|█▍        | 74/500 [00:25<02:06,  3.38it/s] 15%|█▌        | 75/500 [00:26<02:06,  3.36it/s] 15%|█▌        | 76/500 [00:26<02:05,  3.37it/s] 15%|█▌        | 77/500 [00:26<02:05,  3.36it/s] 16%|█▌        | 78/500 [00:27<02:05,  3.36it/s] 16%|█▌        | 79/500 [00:27<02:05,  3.36it/s] 16%|█▌        | 80/500 [00:27<02:04,  3.36it/s] 16%|█▌        | 81/500 [00:27<02:04,  3.36it/s] 16%|█▋        | 82/500 [00:28<02:04,  3.36it/s] 17%|█▋        | 83/500 [00:28<02:03,  3.36it/s] 17%|█▋        | 84/500 [00:28<02:03,  3.36it/s] 17%|█▋        | 85/500 [00:29<02:03,  3.36it/s] 17%|█▋        | 86/500 [00:29<02:03,  3.37it/s] 17%|█▋        | 87/500 [00:29<02:02,  3.36it/s] 18%|█▊        | 88/500 [00:30<02:02,  3.35it/s] 18%|█▊        | 89/500 [00:30<02:02,  3.36it/s] 18%|█▊        | 90/500 [00:30<02:02,  3.35it/s] 18%|█▊        | 91/500 [00:30<02:02,  3.35it/s] 18%|█▊        | 92/500 [00:31<02:01,  3.35it/s] 19%|█▊        | 93/500 [00:31<02:01,  3.35it/s] 19%|█▉        | 94/500 [00:31<02:01,  3.35it/s] 19%|█▉        | 95/500 [00:32<02:01,  3.34it/s] 19%|█▉        | 96/500 [00:32<02:00,  3.35it/s] 19%|█▉        | 97/500 [00:32<02:00,  3.35it/s] 20%|█▉        | 98/500 [00:33<01:59,  3.36it/s] 20%|█▉        | 99/500 [00:33<01:59,  3.36it/s] 20%|██        | 100/500 [00:33<01:58,  3.36it/s] 20%|██        | 101/500 [00:33<01:58,  3.36it/s] 20%|██        | 102/500 [00:34<01:58,  3.36it/s] 21%|██        | 103/500 [00:34<01:58,  3.36it/s] 21%|██        | 104/500 [00:34<01:57,  3.37it/s] 21%|██        | 105/500 [00:35<01:57,  3.37it/s] 21%|██        | 106/500 [00:35<01:56,  3.37it/s] 21%|██▏       | 107/500 [00:35<01:56,  3.37it/s] 22%|██▏       | 108/500 [00:36<01:56,  3.37it/s] 22%|██▏       | 109/500 [00:36<01:56,  3.36it/s] 22%|██▏       | 110/500 [00:36<01:55,  3.37it/s] 22%|██▏       | 111/500 [00:36<01:55,  3.37it/s] 22%|██▏       | 112/500 [00:37<01:55,  3.37it/s] 23%|██▎       | 113/500 [00:37<01:54,  3.37it/s] 23%|██▎       | 114/500 [00:37<01:54,  3.36it/s] 23%|██▎       | 115/500 [00:38<01:54,  3.36it/s] 23%|██▎       | 116/500 [00:38<01:54,  3.37it/s] 23%|██▎       | 117/500 [00:38<01:53,  3.37it/s] 24%|██▎       | 118/500 [00:38<01:53,  3.37it/s] 24%|██▍       | 119/500 [00:39<01:53,  3.37it/s] 24%|██▍       | 120/500 [00:39<01:52,  3.37it/s] 24%|██▍       | 121/500 [00:39<01:52,  3.37it/s] 24%|██▍       | 122/500 [00:40<01:52,  3.37it/s] 25%|██▍       | 123/500 [00:40<01:52,  3.36it/s] 25%|██▍       | 124/500 [00:40<01:51,  3.36it/s] 25%|██▌       | 125/500 [00:41<01:51,  3.36it/s] 25%|██▌       | 126/500 [00:41<01:51,  3.36it/s] 25%|██▌       | 127/500 [00:41<01:50,  3.36it/s] 26%|██▌       | 128/500 [00:41<01:50,  3.36it/s] 26%|██▌       | 129/500 [00:42<01:50,  3.36it/s] 26%|██▌       | 130/500 [00:42<01:50,  3.36it/s] 26%|██▌       | 131/500 [00:42<01:49,  3.36it/s] 26%|██▋       | 132/500 [00:43<01:49,  3.36it/s] 27%|██▋       | 133/500 [00:43<01:49,  3.36it/s] 27%|██▋       | 134/500 [00:43<01:48,  3.36it/s] 27%|██▋       | 135/500 [00:44<01:48,  3.36it/s] 27%|██▋       | 136/500 [00:44<01:48,  3.37it/s] 27%|██▋       | 137/500 [00:44<01:47,  3.36it/s] 28%|██▊       | 138/500 [00:44<01:47,  3.36it/s] 28%|██▊       | 139/500 [00:45<01:47,  3.36it/s] 28%|██▊       | 140/500 [00:45<01:47,  3.36it/s] 28%|██▊       | 141/500 [00:45<01:46,  3.37it/s] 28%|██▊       | 142/500 [00:46<01:46,  3.37it/s] 29%|██▊       | 143/500 [00:46<01:45,  3.37it/s] 29%|██▉       | 144/500 [00:46<01:45,  3.37it/s] 29%|██▉       | 145/500 [00:47<01:45,  3.37it/s] 29%|██▉       | 146/500 [00:47<01:45,  3.36it/s] 29%|██▉       | 147/500 [00:47<01:45,  3.36it/s] 30%|██▉       | 148/500 [00:47<01:44,  3.37it/s] 30%|██▉       | 149/500 [00:48<01:44,  3.37it/s] 30%|███       | 150/500 [00:48<01:43,  3.37it/s] 30%|███       | 151/500 [00:48<01:43,  3.37it/s] 30%|███       | 152/500 [00:49<01:43,  3.37it/s] 31%|███       | 153/500 [00:49<01:43,  3.36it/s] 31%|███       | 154/500 [00:49<01:42,  3.37it/s] 31%|███       | 155/500 [00:49<01:42,  3.36it/s] 31%|███       | 156/500 [00:50<01:42,  3.36it/s] 31%|███▏      | 157/500 [00:50<01:41,  3.37it/s] 32%|███▏      | 158/500 [00:50<01:41,  3.37it/s] 32%|███▏      | 159/500 [00:51<01:41,  3.37it/s] 32%|███▏      | 160/500 [00:51<01:40,  3.37it/s] 32%|███▏      | 161/500 [00:51<01:40,  3.37it/s] 32%|███▏      | 162/500 [00:52<01:40,  3.36it/s] 33%|███▎      | 163/500 [00:52<01:40,  3.36it/s] 33%|███▎      | 164/500 [00:52<01:39,  3.37it/s] 33%|███▎      | 165/500 [00:52<01:39,  3.37it/s] 33%|███▎      | 166/500 [00:53<01:39,  3.36it/s] 33%|███▎      | 167/500 [00:53<01:38,  3.37it/s] 34%|███▎      | 168/500 [00:53<01:38,  3.37it/s] 34%|███▍      | 169/500 [00:54<01:38,  3.36it/s] 34%|███▍      | 170/500 [00:54<01:38,  3.36it/s] 34%|███▍      | 171/500 [00:54<01:37,  3.36it/s] 34%|███▍      | 172/500 [00:55<01:37,  3.36it/s] 35%|███▍      | 173/500 [00:55<01:37,  3.36it/s] 35%|███▍      | 174/500 [00:55<01:37,  3.36it/s] 35%|███▌      | 175/500 [00:55<01:36,  3.36it/s] 35%|███▌      | 176/500 [00:56<01:36,  3.36it/s] 35%|███▌      | 177/500 [00:56<01:36,  3.36it/s] 36%|███▌      | 178/500 [00:56<01:35,  3.36it/s] 36%|███▌      | 179/500 [00:57<01:35,  3.36it/s] 36%|███▌      | 180/500 [00:57<01:35,  3.36it/s] 36%|███▌      | 181/500 [00:57<01:35,  3.35it/s] 36%|███▋      | 182/500 [00:58<01:34,  3.35it/s] 37%|███▋      | 183/500 [00:58<01:34,  3.36it/s] 37%|███▋      | 184/500 [00:58<01:34,  3.36it/s] 37%|███▋      | 185/500 [00:58<01:34,  3.35it/s] 37%|███▋      | 186/500 [00:59<01:33,  3.35it/s] 37%|███▋      | 187/500 [00:59<01:33,  3.35it/s] 38%|███▊      | 188/500 [00:59<01:32,  3.36it/s] 38%|███▊      | 189/500 [01:00<01:32,  3.36it/s] 38%|███▊      | 190/500 [01:00<01:32,  3.36it/s] 38%|███▊      | 191/500 [01:00<01:31,  3.36it/s] 38%|███▊      | 192/500 [01:00<01:31,  3.36it/s] 39%|███▊      | 193/500 [01:01<01:31,  3.36it/s] 39%|███▉      | 194/500 [01:01<01:31,  3.36it/s] 39%|███▉      | 195/500 [01:01<01:30,  3.36it/s] 39%|███▉      | 196/500 [01:02<01:30,  3.36it/s] 39%|███▉      | 197/500 [01:02<01:30,  3.37it/s] 40%|███▉      | 198/500 [01:02<01:29,  3.37it/s] 40%|███▉      | 199/500 [01:03<01:29,  3.36it/s] 40%|████      | 200/500 [01:03<01:29,  3.36it/s] 40%|████      | 201/500 [01:03<01:29,  3.36it/s] 40%|████      | 202/500 [01:03<01:28,  3.36it/s] 41%|████      | 203/500 [01:04<01:28,  3.36it/s] 41%|████      | 204/500 [01:04<01:28,  3.36it/s] 41%|████      | 205/500 [01:04<01:27,  3.37it/s] 41%|████      | 206/500 [01:05<01:27,  3.37it/s] 41%|████▏     | 207/500 [01:05<01:27,  3.37it/s] 42%|████▏     | 208/500 [01:05<01:26,  3.36it/s] 42%|████▏     | 209/500 [01:06<01:26,  3.37it/s] 42%|████▏     | 210/500 [01:06<01:26,  3.37it/s] 42%|████▏     | 211/500 [01:06<01:26,  3.36it/s] 42%|████▏     | 212/500 [01:06<01:25,  3.36it/s] 43%|████▎     | 213/500 [01:07<01:25,  3.36it/s] 43%|████▎     | 214/500 [01:07<01:25,  3.36it/s] 43%|████▎     | 215/500 [01:07<01:25,  3.34it/s] 43%|████▎     | 216/500 [01:08<01:24,  3.35it/s] 43%|████▎     | 217/500 [01:08<01:24,  3.34it/s] 44%|████▎     | 218/500 [01:08<01:24,  3.35it/s] 44%|████▍     | 219/500 [01:09<01:23,  3.35it/s] 44%|████▍     | 220/500 [01:09<01:23,  3.35it/s] 44%|████▍     | 221/500 [01:09<01:23,  3.35it/s] 44%|████▍     | 222/500 [01:09<01:23,  3.35it/s] 45%|████▍     | 223/500 [01:10<01:22,  3.35it/s] 45%|████▍     | 224/500 [01:10<01:22,  3.36it/s] 45%|████▌     | 225/500 [01:10<01:21,  3.36it/s] 45%|████▌     | 226/500 [01:11<01:21,  3.36it/s] 45%|████▌     | 227/500 [01:11<01:21,  3.35it/s] 46%|████▌     | 228/500 [01:11<01:21,  3.35it/s] 46%|████▌     | 229/500 [01:12<01:20,  3.35it/s] 46%|████▌     | 230/500 [01:12<01:20,  3.36it/s] 46%|████▌     | 231/500 [01:12<01:20,  3.36it/s] 46%|████▋     | 232/500 [01:12<01:19,  3.35it/s] 47%|████▋     | 233/500 [01:13<01:19,  3.35it/s] 47%|████▋     | 234/500 [01:13<01:19,  3.35it/s] 47%|████▋     | 235/500 [01:13<01:18,  3.36it/s] 47%|████▋     | 236/500 [01:14<01:18,  3.36it/s] 47%|████▋     | 237/500 [01:14<01:18,  3.36it/s] 48%|████▊     | 238/500 [01:14<01:17,  3.36it/s] 48%|████▊     | 239/500 [01:14<01:17,  3.36it/s] 48%|████▊     | 240/500 [01:15<01:17,  3.36it/s] 48%|████▊     | 241/500 [01:15<01:17,  3.36it/s] 48%|████▊     | 242/500 [01:15<01:16,  3.36it/s] 49%|████▊     | 243/500 [01:16<01:16,  3.36it/s] 49%|████▉     | 244/500 [01:16<01:16,  3.36it/s] 49%|████▉     | 245/500 [01:16<01:15,  3.36it/s] 49%|████▉     | 246/500 [01:17<01:15,  3.36it/s] 49%|████▉     | 247/500 [01:17<01:15,  3.36it/s] 50%|████▉     | 248/500 [01:17<01:15,  3.36it/s] 50%|████▉     | 249/500 [01:17<01:14,  3.35it/s] 50%|█████     | 250/500 [01:18<01:14,  3.35it/s] 50%|█████     | 251/500 [01:18<01:14,  3.35it/s] 50%|█████     | 252/500 [01:18<01:13,  3.35it/s] 51%|█████     | 253/500 [01:19<01:13,  3.36it/s] 51%|█████     | 254/500 [01:19<01:13,  3.36it/s] 51%|█████     | 255/500 [01:19<01:13,  3.36it/s] 51%|█████     | 256/500 [01:20<01:12,  3.35it/s] 51%|█████▏    | 257/500 [01:20<01:12,  3.36it/s] 52%|█████▏    | 258/500 [01:20<01:12,  3.36it/s] 52%|█████▏    | 259/500 [01:20<01:11,  3.36it/s] 52%|█████▏    | 260/500 [01:21<01:11,  3.35it/s] 52%|█████▏    | 261/500 [01:21<01:11,  3.36it/s] 52%|█████▏    | 262/500 [01:21<01:10,  3.36it/s] 53%|█████▎    | 263/500 [01:22<01:10,  3.35it/s] 53%|█████▎    | 264/500 [01:22<01:10,  3.36it/s] 53%|█████▎    | 265/500 [01:22<01:09,  3.36it/s] 53%|█████▎    | 266/500 [01:23<01:09,  3.36it/s] 53%|█████▎    | 267/500 [01:23<01:09,  3.36it/s] 54%|█████▎    | 268/500 [01:23<01:08,  3.36it/s] 54%|█████▍    | 269/500 [01:23<01:08,  3.37it/s] 54%|█████▍    | 270/500 [01:24<01:08,  3.37it/s] 54%|█████▍    | 271/500 [01:24<01:08,  3.36it/s] 54%|█████▍    | 272/500 [01:24<01:07,  3.36it/s] 55%|█████▍    | 273/500 [01:25<01:07,  3.36it/s] 55%|█████▍    | 274/500 [01:25<01:07,  3.36it/s] 55%|█████▌    | 275/500 [01:25<01:07,  3.35it/s] 55%|█████▌    | 276/500 [01:26<01:06,  3.35it/s] 55%|█████▌    | 277/500 [01:26<01:06,  3.35it/s] 56%|█████▌    | 278/500 [01:26<01:06,  3.35it/s] 56%|█████▌    | 279/500 [01:26<01:05,  3.35it/s] 56%|█████▌    | 280/500 [01:27<01:05,  3.35it/s] 56%|█████▌    | 281/500 [01:27<01:05,  3.36it/s] 56%|█████▋    | 282/500 [01:27<01:04,  3.36it/s] 57%|█████▋    | 283/500 [01:28<01:04,  3.36it/s] 57%|█████▋    | 284/500 [01:28<01:04,  3.36it/s] 57%|█████▋    | 285/500 [01:28<01:04,  3.36it/s] 57%|█████▋    | 286/500 [01:28<01:03,  3.36it/s] 57%|█████▋    | 287/500 [01:29<01:31,  2.32it/s] 58%|█████▊    | 288/500 [01:30<01:22,  2.56it/s] 58%|█████▊    | 289/500 [01:30<01:16,  2.74it/s] 58%|█████▊    | 290/500 [01:30<01:12,  2.90it/s] 58%|█████▊    | 291/500 [01:30<01:09,  3.02it/s] 58%|█████▊    | 292/500 [01:31<01:06,  3.11it/s] 59%|█████▊    | 293/500 [01:31<01:05,  3.16it/s] 59%|█████▉    | 294/500 [01:31<01:04,  3.21it/s] 59%|█████▉    | 295/500 [01:32<01:03,  3.24it/s] 59%|█████▉    | 296/500 [01:32<01:02,  3.26it/s] 59%|█████▉    | 297/500 [01:32<01:01,  3.28it/s] 60%|█████▉    | 298/500 [01:33<01:01,  3.30it/s] 60%|█████▉    | 299/500 [01:33<01:00,  3.32it/s] 60%|██████    | 300/500 [01:33<01:00,  3.33it/s] 60%|██████    | 301/500 [01:33<00:59,  3.34it/s] 60%|██████    | 302/500 [01:34<00:59,  3.34it/s] 61%|██████    | 303/500 [01:34<00:58,  3.34it/s] 61%|██████    | 304/500 [01:34<00:58,  3.35it/s] 61%|██████    | 305/500 [01:35<00:58,  3.35it/s] 61%|██████    | 306/500 [01:35<00:57,  3.35it/s] 61%|██████▏   | 307/500 [01:35<00:57,  3.35it/s] 62%|██████▏   | 308/500 [01:36<00:57,  3.36it/s] 62%|██████▏   | 309/500 [01:36<00:56,  3.35it/s] 62%|██████▏   | 310/500 [01:36<00:56,  3.35it/s] 62%|██████▏   | 311/500 [01:36<00:56,  3.35it/s] 62%|██████▏   | 312/500 [01:37<00:56,  3.35it/s] 63%|██████▎   | 313/500 [01:37<00:55,  3.35it/s] 63%|██████▎   | 314/500 [01:37<00:55,  3.35it/s] 63%|██████▎   | 315/500 [01:38<00:55,  3.35it/s] 63%|██████▎   | 316/500 [01:38<00:54,  3.35it/s] 63%|██████▎   | 317/500 [01:38<00:54,  3.35it/s] 64%|██████▎   | 318/500 [01:38<00:54,  3.35it/s] 64%|██████▍   | 319/500 [01:39<00:54,  3.35it/s] 64%|██████▍   | 320/500 [01:39<00:53,  3.35it/s] 64%|██████▍   | 321/500 [01:39<00:53,  3.35it/s] 64%|██████▍   | 322/500 [01:40<00:53,  3.35it/s] 65%|██████▍   | 323/500 [01:40<00:52,  3.35it/s] 65%|██████▍   | 324/500 [01:40<00:52,  3.35it/s] 65%|██████▌   | 325/500 [01:41<00:52,  3.35it/s] 65%|██████▌   | 326/500 [01:41<00:51,  3.35it/s] 65%|██████▌   | 327/500 [01:41<00:51,  3.36it/s] 66%|██████▌   | 328/500 [01:41<00:51,  3.36it/s] 66%|██████▌   | 329/500 [01:42<00:50,  3.36it/s] 66%|██████▌   | 330/500 [01:42<00:50,  3.35it/s] 66%|██████▌   | 331/500 [01:42<00:50,  3.35it/s] 66%|██████▋   | 332/500 [01:43<00:50,  3.35it/s] 67%|██████▋   | 333/500 [01:43<00:49,  3.35it/s] 67%|██████▋   | 334/500 [01:43<00:49,  3.35it/s] 67%|██████▋   | 335/500 [01:44<00:49,  3.35it/s] 67%|██████▋   | 336/500 [01:44<00:48,  3.35it/s] 67%|██████▋   | 337/500 [01:44<00:48,  3.35it/s] 68%|██████▊   | 338/500 [01:44<00:48,  3.35it/s] 68%|██████▊   | 339/500 [01:45<00:48,  3.35it/s] 68%|██████▊   | 340/500 [01:45<00:47,  3.35it/s] 68%|██████▊   | 341/500 [01:45<00:47,  3.35it/s] 68%|██████▊   | 342/500 [01:46<00:47,  3.35it/s] 69%|██████▊   | 343/500 [01:46<00:46,  3.35it/s] 69%|██████▉   | 344/500 [01:46<00:46,  3.35it/s] 69%|██████▉   | 345/500 [01:47<00:46,  3.35it/s] 69%|██████▉   | 346/500 [01:47<00:45,  3.35it/s] 69%|██████▉   | 347/500 [01:47<00:45,  3.35it/s] 70%|██████▉   | 348/500 [01:47<00:45,  3.35it/s] 70%|██████▉   | 349/500 [01:48<00:45,  3.35it/s] 70%|███████   | 350/500 [01:48<00:44,  3.35it/s] 70%|███████   | 351/500 [01:48<00:44,  3.35it/s] 70%|███████   | 352/500 [01:49<00:44,  3.35it/s] 71%|███████   | 353/500 [01:49<00:43,  3.35it/s] 71%|███████   | 354/500 [01:49<00:43,  3.36it/s] 71%|███████   | 355/500 [01:50<00:43,  3.35it/s] 71%|███████   | 356/500 [01:50<00:42,  3.35it/s] 71%|███████▏  | 357/500 [01:50<00:42,  3.35it/s] 72%|███████▏  | 358/500 [01:50<00:42,  3.36it/s] 72%|███████▏  | 359/500 [01:51<00:42,  3.36it/s] 72%|███████▏  | 360/500 [01:51<00:41,  3.35it/s] 72%|███████▏  | 361/500 [01:51<00:41,  3.35it/s] 72%|███████▏  | 362/500 [01:52<00:41,  3.35it/s] 73%|███████▎  | 363/500 [01:52<00:40,  3.35it/s] 73%|███████▎  | 364/500 [01:52<00:40,  3.35it/s] 73%|███████▎  | 365/500 [01:53<00:40,  3.35it/s] 73%|███████▎  | 366/500 [01:53<00:39,  3.35it/s] 73%|███████▎  | 367/500 [01:53<00:39,  3.36it/s] 74%|███████▎  | 368/500 [01:53<00:39,  3.36it/s] 74%|███████▍  | 369/500 [01:54<00:39,  3.36it/s] 74%|███████▍  | 370/500 [01:54<00:38,  3.36it/s] 74%|███████▍  | 371/500 [01:54<00:38,  3.36it/s] 74%|███████▍  | 372/500 [01:55<00:38,  3.35it/s] 75%|███████▍  | 373/500 [01:55<00:37,  3.35it/s] 75%|███████▍  | 374/500 [01:55<00:37,  3.35it/s] 75%|███████▌  | 375/500 [01:56<00:37,  3.35it/s] 75%|███████▌  | 376/500 [01:56<00:37,  3.35it/s] 75%|███████▌  | 377/500 [01:56<00:36,  3.35it/s] 76%|███████▌  | 378/500 [01:56<00:36,  3.35it/s] 76%|███████▌  | 379/500 [01:57<00:36,  3.34it/s] 76%|███████▌  | 380/500 [01:57<00:35,  3.34it/s] 76%|███████▌  | 381/500 [01:57<00:35,  3.34it/s] 76%|███████▋  | 382/500 [01:58<00:35,  3.35it/s] 77%|███████▋  | 383/500 [01:58<00:34,  3.36it/s] 77%|███████▋  | 384/500 [01:58<00:34,  3.36it/s] 77%|███████▋  | 385/500 [01:58<00:34,  3.36it/s] 77%|███████▋  | 386/500 [01:59<00:33,  3.36it/s] 77%|███████▋  | 387/500 [01:59<00:33,  3.34it/s] 78%|███████▊  | 388/500 [01:59<00:33,  3.34it/s] 78%|███████▊  | 389/500 [02:00<00:33,  3.34it/s] 78%|███████▊  | 390/500 [02:00<00:32,  3.35it/s] 78%|███████▊  | 391/500 [02:00<00:32,  3.35it/s] 78%|███████▊  | 392/500 [02:01<00:32,  3.35it/s] 79%|███████▊  | 393/500 [02:01<00:31,  3.35it/s] 79%|███████▉  | 394/500 [02:01<00:31,  3.35it/s] 79%|███████▉  | 395/500 [02:01<00:31,  3.35it/s] 79%|███████▉  | 396/500 [02:02<00:31,  3.35it/s] 79%|███████▉  | 397/500 [02:02<00:30,  3.35it/s] 80%|███████▉  | 398/500 [02:02<00:30,  3.35it/s] 80%|███████▉  | 399/500 [02:03<00:30,  3.36it/s] 80%|████████  | 400/500 [02:03<00:29,  3.36it/s] 80%|████████  | 401/500 [02:03<00:29,  3.36it/s] 80%|████████  | 402/500 [02:04<00:29,  3.36it/s] 81%|████████  | 403/500 [02:04<00:28,  3.36it/s] 81%|████████  | 404/500 [02:04<00:28,  3.36it/s] 81%|████████  | 405/500 [02:04<00:28,  3.35it/s] 81%|████████  | 406/500 [02:05<00:28,  3.36it/s] 81%|████████▏ | 407/500 [02:05<00:27,  3.36it/s] 82%|████████▏ | 408/500 [02:05<00:27,  3.36it/s] 82%|████████▏ | 409/500 [02:06<00:27,  3.36it/s] 82%|████████▏ | 410/500 [02:06<00:26,  3.36it/s] 82%|████████▏ | 411/500 [02:06<00:26,  3.36it/s] 82%|████████▏ | 412/500 [02:07<00:26,  3.36it/s] 83%|████████▎ | 413/500 [02:07<00:25,  3.36it/s] 83%|████████▎ | 414/500 [02:07<00:25,  3.35it/s] 83%|████████▎ | 415/500 [02:07<00:25,  3.34it/s] 83%|████████▎ | 416/500 [02:08<00:25,  3.34it/s] 83%|████████▎ | 417/500 [02:08<00:24,  3.34it/s] 84%|████████▎ | 418/500 [02:08<00:24,  3.34it/s] 84%|████████▍ | 419/500 [02:09<00:24,  3.34it/s] 84%|████████▍ | 420/500 [02:09<00:23,  3.34it/s] 84%|████████▍ | 421/500 [02:09<00:23,  3.35it/s] 84%|████████▍ | 422/500 [02:10<00:23,  3.34it/s] 85%|████████▍ | 423/500 [02:10<00:23,  3.35it/s] 85%|████████▍ | 424/500 [02:10<00:22,  3.35it/s] 85%|████████▌ | 425/500 [02:10<00:22,  3.35it/s] 85%|████████▌ | 426/500 [02:11<00:22,  3.34it/s] 85%|████████▌ | 427/500 [02:11<00:21,  3.35it/s] 86%|████████▌ | 428/500 [02:11<00:21,  3.35it/s] 86%|████████▌ | 429/500 [02:12<00:21,  3.35it/s] 86%|████████▌ | 430/500 [02:12<00:20,  3.35it/s] 86%|████████▌ | 431/500 [02:12<00:20,  3.35it/s] 86%|████████▋ | 432/500 [02:13<00:20,  3.35it/s] 87%|████████▋ | 433/500 [02:13<00:20,  3.35it/s] 87%|████████▋ | 434/500 [02:13<00:19,  3.34it/s] 87%|████████▋ | 435/500 [02:13<00:19,  3.34it/s] 87%|████████▋ | 436/500 [02:14<00:19,  3.34it/s] 87%|████████▋ | 437/500 [02:14<00:18,  3.35it/s] 88%|████████▊ | 438/500 [02:14<00:18,  3.34it/s] 88%|████████▊ | 439/500 [02:15<00:18,  3.35it/s] 88%|████████▊ | 440/500 [02:15<00:17,  3.34it/s] 88%|████████▊ | 441/500 [02:15<00:17,  3.34it/s] 88%|████████▊ | 442/500 [02:16<00:17,  3.35it/s] 89%|████████▊ | 443/500 [02:16<00:17,  3.35it/s] 89%|████████▉ | 444/500 [02:16<00:16,  3.35it/s] 89%|████████▉ | 445/500 [02:16<00:16,  3.35it/s] 89%|████████▉ | 446/500 [02:17<00:16,  3.35it/s] 89%|████████▉ | 447/500 [02:17<00:15,  3.35it/s] 90%|████████▉ | 448/500 [02:17<00:15,  3.35it/s] 90%|████████▉ | 449/500 [02:18<00:15,  3.35it/s] 90%|█████████ | 450/500 [02:18<00:14,  3.36it/s] 90%|█████████ | 451/500 [02:18<00:14,  3.36it/s] 90%|█████████ | 452/500 [02:18<00:14,  3.36it/s] 91%|█████████ | 453/500 [02:19<00:14,  3.36it/s] 91%|█████████ | 454/500 [02:19<00:13,  3.36it/s] 91%|█████████ | 455/500 [02:19<00:13,  3.36it/s] 91%|█████████ | 456/500 [02:20<00:13,  3.36it/s] 91%|█████████▏| 457/500 [02:20<00:12,  3.35it/s] 92%|█████████▏| 458/500 [02:20<00:12,  3.35it/s] 92%|█████████▏| 459/500 [02:21<00:12,  3.35it/s] 92%|█████████▏| 460/500 [02:21<00:11,  3.35it/s] 92%|█████████▏| 461/500 [02:21<00:11,  3.34it/s] 92%|█████████▏| 462/500 [02:21<00:11,  3.34it/s] 93%|█████████▎| 463/500 [02:22<00:11,  3.35it/s] 93%|█████████▎| 464/500 [02:22<00:10,  3.36it/s] 93%|█████████▎| 465/500 [02:22<00:10,  3.35it/s] 93%|█████████▎| 466/500 [02:23<00:10,  3.35it/s] 93%|█████████▎| 467/500 [02:23<00:09,  3.34it/s] 94%|█████████▎| 468/500 [02:23<00:09,  3.34it/s] 94%|█████████▍| 469/500 [02:24<00:09,  3.34it/s] 94%|█████████▍| 470/500 [02:24<00:08,  3.34it/s] 94%|█████████▍| 471/500 [02:24<00:08,  3.35it/s] 94%|█████████▍| 472/500 [02:24<00:08,  3.35it/s] 95%|█████████▍| 473/500 [02:25<00:08,  3.36it/s] 95%|█████████▍| 474/500 [02:25<00:07,  3.36it/s] 95%|█████████▌| 475/500 [02:25<00:07,  3.36it/s] 95%|█████████▌| 476/500 [02:26<00:07,  3.36it/s] 95%|█████████▌| 477/500 [02:26<00:06,  3.35it/s] 96%|█████████▌| 478/500 [02:26<00:06,  3.35it/s] 96%|█████████▌| 479/500 [02:27<00:06,  3.35it/s] 96%|█████████▌| 480/500 [02:27<00:05,  3.35it/s] 96%|█████████▌| 481/500 [02:27<00:05,  3.35it/s] 96%|█████████▋| 482/500 [02:27<00:05,  3.35it/s] 97%|█████████▋| 483/500 [02:28<00:05,  3.34it/s] 97%|█████████▋| 484/500 [02:28<00:04,  3.34it/s] 97%|█████████▋| 485/500 [02:28<00:04,  3.34it/s] 97%|█████████▋| 486/500 [02:29<00:04,  3.34it/s] 97%|█████████▋| 487/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 488/500 [02:29<00:03,  3.35it/s] 98%|█████████▊| 489/500 [02:30<00:03,  3.36it/s] 98%|█████████▊| 490/500 [02:30<00:02,  3.36it/s] 98%|█████████▊| 491/500 [02:30<00:02,  3.37it/s] 98%|█████████▊| 492/500 [02:30<00:02,  3.37it/s] 99%|█████████▊| 493/500 [02:31<00:02,  3.37it/s] 99%|█████████▉| 494/500 [02:31<00:01,  3.37it/s] 99%|█████████▉| 495/500 [02:31<00:01,  3.37it/s] 99%|█████████▉| 496/500 [02:32<00:01,  3.37it/s] 99%|█████████▉| 497/500 [02:32<00:00,  3.37it/s]100%|█████████▉| 498/500 [02:32<00:00,  3.38it/s]100%|█████████▉| 499/500 [02:32<00:00,  3.38it/s]100%|██████████| 500/500 [02:33<00:00,  3.38it/s]100%|██████████| 500/500 [02:33<00:00,  3.26it/s]
=> result
* total: 50,000
* correct: 22,930
* accuracy: 45.9%
* error: 54.1%
* macro_f1: 42.1%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat caltech101 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/caltech101/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/caltech101/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_1.pkl
1600 1649 2465
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      1,649
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:04<01:49,  4.57s/it]  8%|▊         | 2/25 [00:04<00:45,  1.96s/it] 12%|█▏        | 3/25 [00:04<00:24,  1.13s/it] 16%|█▌        | 4/25 [00:04<00:15,  1.36it/s] 20%|██        | 5/25 [00:05<00:10,  1.95it/s] 24%|██▍       | 6/25 [00:05<00:07,  2.64it/s] 28%|██▊       | 7/25 [00:05<00:05,  3.38it/s] 32%|███▏      | 8/25 [00:05<00:04,  4.16it/s] 36%|███▌      | 9/25 [00:05<00:03,  4.92it/s] 40%|████      | 10/25 [00:05<00:02,  5.62it/s] 44%|████▍     | 11/25 [00:05<00:02,  6.22it/s] 48%|████▊     | 12/25 [00:05<00:01,  6.71it/s] 52%|█████▏    | 13/25 [00:06<00:01,  7.10it/s] 56%|█████▌    | 14/25 [00:06<00:01,  7.39it/s] 60%|██████    | 15/25 [00:06<00:01,  7.63it/s] 64%|██████▍   | 16/25 [00:06<00:01,  7.81it/s] 68%|██████▊   | 17/25 [00:06<00:01,  7.90it/s] 72%|███████▏  | 18/25 [00:06<00:00,  8.02it/s] 76%|███████▌  | 19/25 [00:06<00:00,  8.10it/s] 80%|████████  | 20/25 [00:06<00:00,  8.17it/s] 84%|████████▍ | 21/25 [00:07<00:00,  8.20it/s] 88%|████████▊ | 22/25 [00:07<00:00,  8.24it/s] 92%|█████████▏| 23/25 [00:07<00:00,  8.26it/s] 96%|█████████▌| 24/25 [00:07<00:00,  8.28it/s]100%|██████████| 25/25 [00:07<00:00,  3.31it/s]
=> result
* total: 2,465
* correct: 1,774
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 64.7%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat caltech101 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/caltech101/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/caltech101/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_2.pkl
1600 1649 2465
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      1,649
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:16,  3.20s/it]  8%|▊         | 2/25 [00:03<00:31,  1.39s/it] 12%|█▏        | 3/25 [00:03<00:17,  1.24it/s] 16%|█▌        | 4/25 [00:03<00:11,  1.86it/s] 20%|██        | 5/25 [00:03<00:07,  2.59it/s] 24%|██▍       | 6/25 [00:03<00:05,  3.38it/s] 28%|██▊       | 7/25 [00:03<00:04,  4.19it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.97it/s] 36%|███▌      | 9/25 [00:04<00:02,  5.69it/s] 40%|████      | 10/25 [00:04<00:02,  6.29it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.80it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.21it/s] 52%|█████▏    | 13/25 [00:04<00:01,  7.51it/s] 56%|█████▌    | 14/25 [00:04<00:01,  7.74it/s] 60%|██████    | 15/25 [00:04<00:01,  7.91it/s] 64%|██████▍   | 16/25 [00:04<00:01,  8.03it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.12it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.19it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.24it/s] 80%|████████  | 20/25 [00:05<00:00,  8.26it/s] 84%|████████▍ | 21/25 [00:05<00:00,  8.28it/s] 88%|████████▊ | 22/25 [00:05<00:00,  8.29it/s] 92%|█████████▏| 23/25 [00:05<00:00,  8.30it/s] 96%|█████████▌| 24/25 [00:05<00:00,  8.32it/s]100%|██████████| 25/25 [00:06<00:00,  4.08it/s]
=> result
* total: 2,465
* correct: 1,530
* accuracy: 62.1%
* error: 37.9%
* macro_f1: 53.4%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat caltech101 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/caltech101/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/caltech101/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_3.pkl
1600 1649 2465
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      1,649
# test     2,465
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:15,  3.14s/it]  8%|▊         | 2/25 [00:03<00:31,  1.36s/it] 12%|█▏        | 3/25 [00:03<00:17,  1.26it/s] 16%|█▌        | 4/25 [00:03<00:11,  1.89it/s] 20%|██        | 5/25 [00:03<00:07,  2.62it/s] 24%|██▍       | 6/25 [00:03<00:05,  3.42it/s] 28%|██▊       | 7/25 [00:03<00:04,  4.23it/s] 32%|███▏      | 8/25 [00:03<00:03,  5.01it/s] 36%|███▌      | 9/25 [00:04<00:02,  5.71it/s] 40%|████      | 10/25 [00:04<00:02,  6.31it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.82it/s] 48%|████▊     | 12/25 [00:04<00:01,  7.23it/s] 52%|█████▏    | 13/25 [00:04<00:01,  7.54it/s] 56%|█████▌    | 14/25 [00:04<00:01,  7.76it/s] 60%|██████    | 15/25 [00:04<00:01,  7.93it/s] 64%|██████▍   | 16/25 [00:04<00:01,  8.05it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.14it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.20it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.24it/s] 80%|████████  | 20/25 [00:05<00:00,  8.27it/s] 84%|████████▍ | 21/25 [00:05<00:00,  8.29it/s] 88%|████████▊ | 22/25 [00:05<00:00,  8.31it/s] 92%|█████████▏| 23/25 [00:05<00:00,  8.32it/s] 96%|█████████▌| 24/25 [00:05<00:00,  8.33it/s]100%|██████████| 25/25 [00:06<00:00,  4.12it/s]
=> result
* total: 2,465
* correct: 1,887
* accuracy: 76.6%
* error: 23.4%
* macro_f1: 69.6%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat oxford_pets 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/oxford_pets/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/oxford_pets/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_1.pkl
592 736 3669
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      736
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/37 [00:00<?, ?it/s]  3%|▎         | 1/37 [00:03<02:13,  3.70s/it]  5%|▌         | 2/37 [00:03<00:55,  1.59s/it]  8%|▊         | 3/37 [00:03<00:31,  1.10it/s] 11%|█         | 4/37 [00:04<00:19,  1.68it/s] 14%|█▎        | 5/37 [00:04<00:13,  2.39it/s] 16%|█▌        | 6/37 [00:04<00:09,  3.19it/s] 19%|█▉        | 7/37 [00:04<00:07,  4.07it/s] 22%|██▏       | 8/37 [00:04<00:05,  4.95it/s] 24%|██▍       | 9/37 [00:04<00:04,  5.80it/s] 27%|██▋       | 10/37 [00:04<00:04,  6.55it/s] 30%|██▉       | 11/37 [00:04<00:03,  7.19it/s] 32%|███▏      | 12/37 [00:04<00:03,  7.71it/s] 35%|███▌      | 13/37 [00:04<00:02,  8.11it/s] 38%|███▊      | 14/37 [00:05<00:02,  8.42it/s] 41%|████      | 15/37 [00:05<00:02,  8.66it/s] 43%|████▎     | 16/37 [00:05<00:02,  8.83it/s] 46%|████▌     | 17/37 [00:05<00:02,  8.95it/s] 49%|████▊     | 18/37 [00:05<00:02,  9.03it/s] 51%|█████▏    | 19/37 [00:05<00:01,  9.08it/s] 54%|█████▍    | 20/37 [00:05<00:01,  9.10it/s] 57%|█████▋    | 21/37 [00:05<00:01,  9.14it/s] 59%|█████▉    | 22/37 [00:05<00:01,  9.18it/s] 62%|██████▏   | 23/37 [00:06<00:01,  9.19it/s] 65%|██████▍   | 24/37 [00:06<00:01,  9.21it/s] 68%|██████▊   | 25/37 [00:06<00:01,  9.17it/s] 70%|███████   | 26/37 [00:06<00:01,  9.18it/s] 73%|███████▎  | 27/37 [00:06<00:01,  9.16it/s] 76%|███████▌  | 28/37 [00:06<00:00,  9.18it/s] 78%|███████▊  | 29/37 [00:06<00:00,  9.19it/s] 81%|████████  | 30/37 [00:06<00:00,  9.20it/s] 84%|████████▍ | 31/37 [00:06<00:00,  9.19it/s] 86%|████████▋ | 32/37 [00:07<00:00,  9.20it/s] 89%|████████▉ | 33/37 [00:07<00:00,  9.21it/s] 92%|█████████▏| 34/37 [00:07<00:00,  9.22it/s] 95%|█████████▍| 35/37 [00:07<00:00,  7.50it/s] 97%|█████████▋| 36/37 [00:07<00:00,  7.97it/s]100%|██████████| 37/37 [00:07<00:00,  4.78it/s]
=> result
* total: 3,669
* correct: 1,877
* accuracy: 51.2%
* error: 48.8%
* macro_f1: 41.7%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat oxford_pets 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/oxford_pets/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/oxford_pets/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_2.pkl
592 736 3669
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      736
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/37 [00:00<?, ?it/s]  3%|▎         | 1/37 [00:03<02:10,  3.62s/it]  5%|▌         | 2/37 [00:03<00:54,  1.56s/it]  8%|▊         | 3/37 [00:03<00:30,  1.12it/s] 11%|█         | 4/37 [00:03<00:19,  1.71it/s] 14%|█▎        | 5/37 [00:04<00:13,  2.43it/s] 16%|█▌        | 6/37 [00:04<00:09,  3.24it/s] 19%|█▉        | 7/37 [00:04<00:07,  4.11it/s] 22%|██▏       | 8/37 [00:04<00:05,  5.00it/s] 24%|██▍       | 9/37 [00:04<00:04,  5.84it/s] 27%|██▋       | 10/37 [00:04<00:04,  6.60it/s] 30%|██▉       | 11/37 [00:04<00:03,  7.24it/s] 32%|███▏      | 12/37 [00:04<00:03,  7.75it/s] 35%|███▌      | 13/37 [00:04<00:02,  8.13it/s] 38%|███▊      | 14/37 [00:05<00:02,  8.44it/s] 41%|████      | 15/37 [00:05<00:02,  8.66it/s] 43%|████▎     | 16/37 [00:05<00:02,  8.82it/s] 46%|████▌     | 17/37 [00:05<00:02,  8.94it/s] 49%|████▊     | 18/37 [00:05<00:02,  9.04it/s] 51%|█████▏    | 19/37 [00:05<00:01,  9.08it/s] 54%|█████▍    | 20/37 [00:05<00:01,  9.13it/s] 57%|█████▋    | 21/37 [00:05<00:01,  9.15it/s] 59%|█████▉    | 22/37 [00:05<00:01,  9.17it/s] 62%|██████▏   | 23/37 [00:06<00:01,  9.19it/s] 65%|██████▍   | 24/37 [00:06<00:01,  9.21it/s] 68%|██████▊   | 25/37 [00:06<00:01,  9.20it/s] 70%|███████   | 26/37 [00:06<00:01,  9.21it/s] 73%|███████▎  | 27/37 [00:06<00:01,  9.22it/s] 76%|███████▌  | 28/37 [00:06<00:00,  9.23it/s] 78%|███████▊  | 29/37 [00:06<00:00,  9.25it/s] 81%|████████  | 30/37 [00:06<00:00,  9.28it/s] 84%|████████▍ | 31/37 [00:06<00:00,  9.29it/s] 86%|████████▋ | 32/37 [00:06<00:00,  9.29it/s] 89%|████████▉ | 33/37 [00:07<00:00,  9.31it/s] 92%|█████████▏| 34/37 [00:07<00:00,  9.31it/s] 95%|█████████▍| 35/37 [00:07<00:00,  9.30it/s] 97%|█████████▋| 36/37 [00:07<00:00,  9.31it/s]100%|██████████| 37/37 [00:07<00:00,  4.89it/s]
=> result
* total: 3,669
* correct: 1,980
* accuracy: 54.0%
* error: 46.0%
* macro_f1: 45.2%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat oxford_pets 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/oxford_pets/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/oxford_pets/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_3.pkl
592 736 3669
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      736
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/37 [00:00<?, ?it/s]  3%|▎         | 1/37 [00:03<02:02,  3.41s/it]  5%|▌         | 2/37 [00:03<00:51,  1.47s/it]  8%|▊         | 3/37 [00:03<00:28,  1.18it/s] 11%|█         | 4/37 [00:03<00:18,  1.80it/s] 14%|█▎        | 5/37 [00:03<00:12,  2.54it/s] 16%|█▌        | 6/37 [00:03<00:09,  3.37it/s] 19%|█▉        | 7/37 [00:04<00:07,  4.26it/s] 22%|██▏       | 8/37 [00:04<00:05,  5.14it/s] 24%|██▍       | 9/37 [00:04<00:04,  5.97it/s] 27%|██▋       | 10/37 [00:04<00:04,  6.69it/s] 30%|██▉       | 11/37 [00:04<00:03,  7.29it/s] 32%|███▏      | 12/37 [00:04<00:03,  7.79it/s] 35%|███▌      | 13/37 [00:04<00:02,  8.18it/s] 38%|███▊      | 14/37 [00:04<00:02,  8.47it/s] 41%|████      | 15/37 [00:04<00:02,  8.65it/s] 43%|████▎     | 16/37 [00:05<00:02,  8.80it/s] 46%|████▌     | 17/37 [00:05<00:02,  8.81it/s] 49%|████▊     | 18/37 [00:05<00:02,  8.94it/s] 51%|█████▏    | 19/37 [00:05<00:02,  9.00it/s] 54%|█████▍    | 20/37 [00:05<00:01,  9.04it/s] 57%|█████▋    | 21/37 [00:05<00:01,  9.11it/s] 59%|█████▉    | 22/37 [00:05<00:01,  9.15it/s] 62%|██████▏   | 23/37 [00:05<00:01,  9.18it/s] 65%|██████▍   | 24/37 [00:05<00:01,  9.20it/s] 68%|██████▊   | 25/37 [00:06<00:01,  9.22it/s] 70%|███████   | 26/37 [00:06<00:01,  9.20it/s] 73%|███████▎  | 27/37 [00:06<00:01,  9.23it/s] 76%|███████▌  | 28/37 [00:06<00:00,  9.26it/s] 78%|███████▊  | 29/37 [00:06<00:00,  9.28it/s] 81%|████████  | 30/37 [00:06<00:00,  9.30it/s] 84%|████████▍ | 31/37 [00:06<00:00,  9.31it/s] 86%|████████▋ | 32/37 [00:06<00:00,  9.32it/s] 89%|████████▉ | 33/37 [00:06<00:00,  9.31it/s] 92%|█████████▏| 34/37 [00:06<00:00,  9.31it/s] 95%|█████████▍| 35/37 [00:07<00:00,  9.31it/s] 97%|█████████▋| 36/37 [00:07<00:00,  9.31it/s]100%|██████████| 37/37 [00:07<00:00,  5.02it/s]
=> result
* total: 3,669
* correct: 1,982
* accuracy: 54.0%
* error: 46.0%
* macro_f1: 46.2%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat stanford_cars 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/stanford_cars/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/stanford_cars/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_1.pkl
3136 1635 8041
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  196
# train_x  3,136
# val      1,635
# test     8,041
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:04<05:35,  4.20s/it]  2%|▏         | 2/81 [00:04<02:23,  1.81s/it]  4%|▎         | 3/81 [00:04<01:21,  1.05s/it]  5%|▍         | 4/81 [00:04<00:53,  1.45it/s]  6%|▌         | 5/81 [00:04<00:37,  2.04it/s]  7%|▋         | 6/81 [00:04<00:27,  2.70it/s]  9%|▊         | 7/81 [00:05<00:21,  3.40it/s] 10%|▉         | 8/81 [00:05<00:17,  4.08it/s] 11%|█         | 9/81 [00:05<00:15,  4.72it/s] 12%|█▏        | 10/81 [00:05<00:13,  5.28it/s] 14%|█▎        | 11/81 [00:05<00:12,  5.75it/s] 15%|█▍        | 12/81 [00:05<00:11,  6.12it/s] 16%|█▌        | 13/81 [00:05<00:10,  6.40it/s] 17%|█▋        | 14/81 [00:06<00:10,  6.62it/s] 19%|█▊        | 15/81 [00:06<00:09,  6.78it/s] 20%|█▉        | 16/81 [00:06<00:09,  6.89it/s] 21%|██        | 17/81 [00:06<00:09,  6.95it/s] 22%|██▏       | 18/81 [00:06<00:08,  7.02it/s] 23%|██▎       | 19/81 [00:06<00:08,  7.06it/s] 25%|██▍       | 20/81 [00:06<00:08,  7.10it/s] 26%|██▌       | 21/81 [00:06<00:08,  7.12it/s] 27%|██▋       | 22/81 [00:07<00:08,  7.13it/s] 28%|██▊       | 23/81 [00:07<00:08,  7.14it/s] 30%|██▉       | 24/81 [00:07<00:07,  7.16it/s] 31%|███       | 25/81 [00:07<00:07,  7.16it/s] 32%|███▏      | 26/81 [00:07<00:07,  7.16it/s] 33%|███▎      | 27/81 [00:07<00:07,  7.17it/s] 35%|███▍      | 28/81 [00:07<00:07,  7.11it/s] 36%|███▌      | 29/81 [00:08<00:07,  7.11it/s] 37%|███▋      | 30/81 [00:08<00:13,  3.90it/s] 38%|███▊      | 31/81 [00:08<00:11,  4.52it/s] 40%|███▉      | 32/81 [00:08<00:09,  5.07it/s] 41%|████      | 33/81 [00:09<00:11,  4.11it/s] 42%|████▏     | 34/81 [00:09<00:09,  4.70it/s] 43%|████▎     | 35/81 [00:09<00:08,  5.24it/s] 44%|████▍     | 36/81 [00:09<00:07,  5.70it/s] 46%|████▌     | 37/81 [00:09<00:07,  6.06it/s] 47%|████▋     | 38/81 [00:10<00:09,  4.45it/s] 48%|████▊     | 39/81 [00:10<00:08,  5.02it/s] 49%|████▉     | 40/81 [00:10<00:07,  5.51it/s] 51%|█████     | 41/81 [00:10<00:09,  4.39it/s] 52%|█████▏    | 42/81 [00:10<00:07,  4.96it/s] 53%|█████▎    | 43/81 [00:11<00:06,  5.47it/s] 54%|█████▍    | 44/81 [00:11<00:06,  5.88it/s] 56%|█████▌    | 45/81 [00:11<00:05,  6.22it/s] 57%|█████▋    | 46/81 [00:11<00:09,  3.68it/s] 58%|█████▊    | 47/81 [00:12<00:07,  4.30it/s] 59%|█████▉    | 48/81 [00:12<00:06,  4.88it/s] 60%|██████    | 49/81 [00:12<00:08,  3.89it/s] 62%|██████▏   | 50/81 [00:12<00:06,  4.51it/s] 63%|██████▎   | 51/81 [00:12<00:05,  5.06it/s] 64%|██████▍   | 52/81 [00:12<00:05,  5.55it/s] 65%|██████▌   | 53/81 [00:13<00:04,  5.95it/s] 67%|██████▋   | 54/81 [00:13<00:08,  3.01it/s] 68%|██████▊   | 55/81 [00:13<00:07,  3.63it/s] 69%|██████▉   | 56/81 [00:14<00:05,  4.26it/s] 70%|███████   | 57/81 [00:14<00:04,  4.84it/s] 72%|███████▏  | 58/81 [00:14<00:04,  5.36it/s] 73%|███████▎  | 59/81 [00:14<00:04,  5.28it/s] 74%|███████▍  | 60/81 [00:14<00:03,  5.72it/s] 75%|███████▌  | 61/81 [00:14<00:03,  6.08it/s] 77%|███████▋  | 62/81 [00:15<00:04,  4.53it/s] 78%|███████▊  | 63/81 [00:15<00:03,  5.09it/s] 79%|███████▉  | 64/81 [00:15<00:03,  5.57it/s] 80%|████████  | 65/81 [00:16<00:04,  3.45it/s] 81%|████████▏ | 66/81 [00:16<00:03,  4.09it/s] 83%|████████▎ | 67/81 [00:16<00:02,  4.68it/s] 84%|████████▍ | 68/81 [00:16<00:02,  5.22it/s] 85%|████████▌ | 69/81 [00:16<00:02,  5.68it/s] 86%|████████▋ | 70/81 [00:16<00:01,  6.06it/s] 88%|████████▊ | 71/81 [00:16<00:01,  6.30it/s] 89%|████████▉ | 72/81 [00:17<00:01,  6.54it/s] 90%|█████████ | 73/81 [00:17<00:01,  6.02it/s] 91%|█████████▏| 74/81 [00:17<00:01,  6.33it/s] 93%|█████████▎| 75/81 [00:17<00:01,  4.43it/s] 94%|█████████▍| 76/81 [00:17<00:00,  5.01it/s] 95%|█████████▌| 77/81 [00:18<00:00,  5.52it/s] 96%|█████████▋| 78/81 [00:18<00:00,  5.94it/s] 98%|█████████▊| 79/81 [00:18<00:00,  6.28it/s] 99%|█████████▉| 80/81 [00:18<00:00,  6.54it/s]100%|██████████| 81/81 [00:18<00:00,  4.35it/s]
=> result
* total: 8,041
* correct: 3,777
* accuracy: 47.0%
* error: 53.0%
* macro_f1: 42.0%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat stanford_cars 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/stanford_cars/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/stanford_cars/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_2.pkl
3136 1635 8041
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  196
# train_x  3,136
# val      1,635
# test     8,041
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:04<05:31,  4.14s/it]  2%|▏         | 2/81 [00:04<02:21,  1.79s/it]  4%|▎         | 3/81 [00:04<01:20,  1.03s/it]  5%|▍         | 4/81 [00:04<00:52,  1.47it/s]  6%|▌         | 5/81 [00:04<00:36,  2.06it/s]  7%|▋         | 6/81 [00:04<00:27,  2.72it/s]  9%|▊         | 7/81 [00:04<00:21,  3.41it/s] 10%|▉         | 8/81 [00:05<00:17,  4.10it/s] 11%|█         | 9/81 [00:05<00:15,  4.73it/s] 12%|█▏        | 10/81 [00:05<00:13,  5.28it/s] 14%|█▎        | 11/81 [00:05<00:12,  5.73it/s] 15%|█▍        | 12/81 [00:05<00:11,  6.10it/s] 16%|█▌        | 13/81 [00:05<00:10,  6.38it/s] 17%|█▋        | 14/81 [00:05<00:10,  6.59it/s] 19%|█▊        | 15/81 [00:06<00:09,  6.75it/s] 20%|█▉        | 16/81 [00:06<00:09,  6.74it/s] 21%|██        | 17/81 [00:06<00:09,  6.85it/s] 22%|██▏       | 18/81 [00:06<00:09,  6.93it/s] 23%|██▎       | 19/81 [00:06<00:08,  6.98it/s] 25%|██▍       | 20/81 [00:06<00:08,  7.01it/s] 26%|██▌       | 21/81 [00:06<00:08,  7.03it/s] 27%|██▋       | 22/81 [00:07<00:08,  7.05it/s] 28%|██▊       | 23/81 [00:07<00:08,  7.05it/s] 30%|██▉       | 24/81 [00:07<00:08,  7.06it/s] 31%|███       | 25/81 [00:07<00:07,  7.07it/s] 32%|███▏      | 26/81 [00:07<00:07,  7.08it/s] 33%|███▎      | 27/81 [00:07<00:07,  7.03it/s] 35%|███▍      | 28/81 [00:07<00:07,  7.06it/s] 36%|███▌      | 29/81 [00:08<00:07,  7.08it/s] 37%|███▋      | 30/81 [00:08<00:10,  4.92it/s] 38%|███▊      | 31/81 [00:08<00:09,  5.42it/s] 40%|███▉      | 32/81 [00:08<00:08,  5.84it/s] 41%|████      | 33/81 [00:08<00:07,  6.17it/s] 42%|████▏     | 34/81 [00:08<00:07,  6.44it/s] 43%|████▎     | 35/81 [00:09<00:06,  6.63it/s] 44%|████▍     | 36/81 [00:09<00:06,  6.77it/s] 46%|████▌     | 37/81 [00:09<00:06,  6.87it/s] 47%|████▋     | 38/81 [00:09<00:08,  5.28it/s] 48%|████▊     | 39/81 [00:09<00:07,  5.72it/s] 49%|████▉     | 40/81 [00:09<00:06,  6.08it/s] 51%|█████     | 41/81 [00:10<00:06,  6.34it/s] 52%|█████▏    | 42/81 [00:10<00:05,  6.56it/s] 53%|█████▎    | 43/81 [00:10<00:05,  6.71it/s] 54%|█████▍    | 44/81 [00:10<00:05,  6.84it/s] 56%|█████▌    | 45/81 [00:10<00:05,  6.92it/s] 57%|█████▋    | 46/81 [00:10<00:05,  6.99it/s] 58%|█████▊    | 47/81 [00:10<00:04,  7.01it/s] 59%|█████▉    | 48/81 [00:11<00:05,  5.60it/s] 60%|██████    | 49/81 [00:11<00:05,  5.98it/s] 62%|██████▏   | 50/81 [00:11<00:04,  6.29it/s] 63%|██████▎   | 51/81 [00:11<00:04,  6.52it/s] 64%|██████▍   | 52/81 [00:11<00:04,  6.69it/s] 65%|██████▌   | 53/81 [00:11<00:04,  6.82it/s] 67%|██████▋   | 54/81 [00:12<00:06,  4.01it/s] 68%|██████▊   | 55/81 [00:12<00:05,  4.61it/s] 69%|██████▉   | 56/81 [00:12<00:04,  5.16it/s] 70%|███████   | 57/81 [00:12<00:04,  5.63it/s] 72%|███████▏  | 58/81 [00:12<00:03,  6.01it/s] 73%|███████▎  | 59/81 [00:13<00:03,  6.26it/s] 74%|███████▍  | 60/81 [00:13<00:03,  6.50it/s] 75%|███████▌  | 61/81 [00:13<00:03,  6.66it/s] 77%|███████▋  | 62/81 [00:13<00:02,  6.66it/s] 78%|███████▊  | 63/81 [00:13<00:02,  6.80it/s] 79%|███████▉  | 64/81 [00:13<00:02,  6.90it/s] 80%|████████  | 65/81 [00:14<00:02,  6.57it/s] 81%|████████▏ | 66/81 [00:14<00:02,  6.74it/s] 83%|████████▎ | 67/81 [00:14<00:03,  3.67it/s] 84%|████████▍ | 68/81 [00:14<00:03,  4.30it/s] 85%|████████▌ | 69/81 [00:14<00:02,  4.89it/s] 86%|████████▋ | 70/81 [00:15<00:02,  5.40it/s] 88%|████████▊ | 71/81 [00:15<00:01,  5.83it/s] 89%|████████▉ | 72/81 [00:15<00:01,  6.18it/s] 90%|█████████ | 73/81 [00:15<00:01,  6.45it/s] 91%|█████████▏| 74/81 [00:15<00:01,  6.66it/s] 93%|█████████▎| 75/81 [00:16<00:01,  4.14it/s] 94%|█████████▍| 76/81 [00:16<00:01,  4.75it/s] 95%|█████████▌| 77/81 [00:16<00:00,  5.30it/s] 96%|█████████▋| 78/81 [00:16<00:00,  5.76it/s] 98%|█████████▊| 79/81 [00:16<00:00,  6.13it/s] 99%|█████████▉| 80/81 [00:16<00:00,  6.42it/s]100%|██████████| 81/81 [00:16<00:00,  4.77it/s]
=> result
* total: 8,041
* correct: 4,004
* accuracy: 49.8%
* error: 50.2%
* macro_f1: 45.9%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat stanford_cars 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/stanford_cars/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/stanford_cars/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_3.pkl
3136 1635 8041
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  196
# train_x  3,136
# val      1,635
# test     8,041
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:04<05:23,  4.05s/it]  2%|▏         | 2/81 [00:04<02:18,  1.75s/it]  4%|▎         | 3/81 [00:04<01:19,  1.01s/it]  5%|▍         | 4/81 [00:04<00:51,  1.50it/s]  6%|▌         | 5/81 [00:04<00:36,  2.09it/s]  7%|▋         | 6/81 [00:04<00:27,  2.75it/s]  9%|▊         | 7/81 [00:04<00:21,  3.45it/s] 10%|▉         | 8/81 [00:05<00:17,  4.13it/s] 11%|█         | 9/81 [00:05<00:15,  4.75it/s] 12%|█▏        | 10/81 [00:05<00:13,  5.29it/s] 14%|█▎        | 11/81 [00:05<00:12,  5.73it/s] 15%|█▍        | 12/81 [00:05<00:11,  6.10it/s] 16%|█▌        | 13/81 [00:05<00:10,  6.38it/s] 17%|█▋        | 14/81 [00:05<00:10,  6.58it/s] 19%|█▊        | 15/81 [00:06<00:09,  6.73it/s] 20%|█▉        | 16/81 [00:06<00:09,  6.86it/s] 21%|██        | 17/81 [00:06<00:09,  6.95it/s] 22%|██▏       | 18/81 [00:06<00:09,  7.00it/s] 23%|██▎       | 19/81 [00:06<00:08,  7.02it/s] 25%|██▍       | 20/81 [00:06<00:08,  7.02it/s] 26%|██▌       | 21/81 [00:06<00:08,  7.03it/s] 27%|██▋       | 22/81 [00:06<00:08,  7.07it/s] 28%|██▊       | 23/81 [00:07<00:08,  7.09it/s] 30%|██▉       | 24/81 [00:07<00:08,  7.12it/s] 31%|███       | 25/81 [00:07<00:07,  7.11it/s] 32%|███▏      | 26/81 [00:07<00:07,  7.12it/s] 33%|███▎      | 27/81 [00:07<00:07,  7.13it/s] 35%|███▍      | 28/81 [00:07<00:07,  7.14it/s] 36%|███▌      | 29/81 [00:07<00:07,  7.13it/s] 37%|███▋      | 30/81 [00:08<00:07,  7.13it/s] 38%|███▊      | 31/81 [00:08<00:07,  7.12it/s] 40%|███▉      | 32/81 [00:08<00:06,  7.12it/s] 41%|████      | 33/81 [00:08<00:06,  7.12it/s] 42%|████▏     | 34/81 [00:08<00:06,  7.10it/s] 43%|████▎     | 35/81 [00:08<00:06,  7.11it/s] 44%|████▍     | 36/81 [00:08<00:06,  7.12it/s] 46%|████▌     | 37/81 [00:09<00:06,  7.12it/s] 47%|████▋     | 38/81 [00:09<00:06,  7.11it/s] 48%|████▊     | 39/81 [00:09<00:05,  7.10it/s] 49%|████▉     | 40/81 [00:09<00:05,  7.11it/s] 51%|█████     | 41/81 [00:09<00:05,  7.12it/s] 52%|█████▏    | 42/81 [00:09<00:07,  5.26it/s] 53%|█████▎    | 43/81 [00:10<00:06,  5.70it/s] 54%|█████▍    | 44/81 [00:10<00:06,  6.06it/s] 56%|█████▌    | 45/81 [00:10<00:05,  6.33it/s] 57%|█████▋    | 46/81 [00:10<00:05,  6.54it/s] 58%|█████▊    | 47/81 [00:10<00:05,  6.70it/s] 59%|█████▉    | 48/81 [00:10<00:04,  6.81it/s] 60%|██████    | 49/81 [00:10<00:04,  6.89it/s] 62%|██████▏   | 50/81 [00:11<00:05,  5.96it/s] 63%|██████▎   | 51/81 [00:11<00:04,  6.25it/s] 64%|██████▍   | 52/81 [00:11<00:04,  6.49it/s] 65%|██████▌   | 53/81 [00:11<00:04,  6.67it/s] 67%|██████▋   | 54/81 [00:11<00:03,  6.80it/s] 68%|██████▊   | 55/81 [00:11<00:03,  6.86it/s] 69%|██████▉   | 56/81 [00:12<00:03,  6.94it/s] 70%|███████   | 57/81 [00:12<00:03,  7.00it/s] 72%|███████▏  | 58/81 [00:12<00:04,  5.63it/s] 73%|███████▎  | 59/81 [00:12<00:03,  5.97it/s] 74%|███████▍  | 60/81 [00:12<00:03,  6.25it/s] 75%|███████▌  | 61/81 [00:12<00:03,  6.48it/s] 77%|███████▋  | 62/81 [00:12<00:02,  6.65it/s] 78%|███████▊  | 63/81 [00:13<00:02,  6.78it/s] 79%|███████▉  | 64/81 [00:13<00:02,  6.88it/s] 80%|████████  | 65/81 [00:13<00:03,  4.69it/s] 81%|████████▏ | 66/81 [00:13<00:02,  5.21it/s] 83%|████████▎ | 67/81 [00:13<00:02,  5.67it/s] 84%|████████▍ | 68/81 [00:14<00:02,  6.04it/s] 85%|████████▌ | 69/81 [00:14<00:01,  6.33it/s] 86%|████████▋ | 70/81 [00:14<00:01,  6.55it/s] 88%|████████▊ | 71/81 [00:14<00:01,  6.70it/s] 89%|████████▉ | 72/81 [00:14<00:01,  6.83it/s] 90%|█████████ | 73/81 [00:14<00:01,  6.92it/s] 91%|█████████▏| 74/81 [00:15<00:02,  3.29it/s] 93%|█████████▎| 75/81 [00:15<00:01,  3.93it/s] 94%|█████████▍| 76/81 [00:15<00:01,  4.55it/s] 95%|█████████▌| 77/81 [00:15<00:00,  5.11it/s] 96%|█████████▋| 78/81 [00:15<00:00,  5.60it/s] 98%|█████████▊| 79/81 [00:16<00:00,  6.00it/s] 99%|█████████▉| 80/81 [00:16<00:00,  6.32it/s]100%|██████████| 81/81 [00:16<00:00,  4.92it/s]
=> result
* total: 8,041
* correct: 4,238
* accuracy: 52.7%
* error: 47.3%
* macro_f1: 49.7%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat oxford_flowers 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/oxford_flowers/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/oxford_flowers/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_1.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:33,  3.92s/it]  8%|▊         | 2/25 [00:04<00:38,  1.68s/it] 12%|█▏        | 3/25 [00:04<00:21,  1.03it/s] 16%|█▌        | 4/25 [00:04<00:13,  1.58it/s] 20%|██        | 5/25 [00:04<00:08,  2.23it/s] 24%|██▍       | 6/25 [00:04<00:06,  2.96it/s] 28%|██▊       | 7/25 [00:04<00:04,  3.75it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.54it/s] 36%|███▌      | 9/25 [00:04<00:03,  5.27it/s] 40%|████      | 10/25 [00:05<00:02,  5.93it/s] 44%|████▍     | 11/25 [00:05<00:02,  6.49it/s] 48%|████▊     | 12/25 [00:05<00:01,  6.95it/s] 52%|█████▏    | 13/25 [00:05<00:01,  7.30it/s] 56%|█████▌    | 14/25 [00:05<00:01,  7.55it/s] 60%|██████    | 15/25 [00:05<00:01,  7.75it/s] 64%|██████▍   | 16/25 [00:05<00:01,  7.92it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.01it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.09it/s] 76%|███████▌  | 19/25 [00:06<00:00,  8.15it/s] 80%|████████  | 20/25 [00:06<00:00,  8.20it/s] 84%|████████▍ | 21/25 [00:06<00:00,  8.24it/s] 88%|████████▊ | 22/25 [00:06<00:00,  8.26it/s] 92%|█████████▏| 23/25 [00:06<00:00,  8.27it/s] 96%|█████████▌| 24/25 [00:06<00:00,  8.29it/s]100%|██████████| 25/25 [00:06<00:00,  3.64it/s]
=> result
* total: 2,463
* correct: 617
* accuracy: 25.1%
* error: 74.9%
* macro_f1: 18.4%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat oxford_flowers 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/oxford_flowers/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/oxford_flowers/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_2.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:32,  3.86s/it]  8%|▊         | 2/25 [00:03<00:38,  1.66s/it] 12%|█▏        | 3/25 [00:04<00:21,  1.05it/s] 16%|█▌        | 4/25 [00:04<00:13,  1.60it/s] 20%|██        | 5/25 [00:04<00:08,  2.25it/s] 24%|██▍       | 6/25 [00:04<00:06,  2.99it/s] 28%|██▊       | 7/25 [00:04<00:04,  3.78it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.56it/s] 36%|███▌      | 9/25 [00:04<00:03,  5.30it/s] 40%|████      | 10/25 [00:04<00:02,  5.95it/s] 44%|████▍     | 11/25 [00:05<00:02,  6.51it/s] 48%|████▊     | 12/25 [00:05<00:01,  6.97it/s] 52%|█████▏    | 13/25 [00:05<00:01,  7.30it/s] 56%|█████▌    | 14/25 [00:05<00:01,  7.56it/s] 60%|██████    | 15/25 [00:05<00:01,  7.77it/s] 64%|██████▍   | 16/25 [00:05<00:01,  7.92it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.04it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.13it/s] 76%|███████▌  | 19/25 [00:06<00:00,  8.19it/s] 80%|████████  | 20/25 [00:06<00:00,  8.23it/s] 84%|████████▍ | 21/25 [00:06<00:00,  8.25it/s] 88%|████████▊ | 22/25 [00:06<00:00,  8.27it/s] 92%|█████████▏| 23/25 [00:06<00:00,  8.29it/s] 96%|█████████▌| 24/25 [00:06<00:00,  8.30it/s]100%|██████████| 25/25 [00:06<00:00,  3.68it/s]
=> result
* total: 2,463
* correct: 545
* accuracy: 22.1%
* error: 77.9%
* macro_f1: 14.3%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat oxford_flowers 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/oxford_flowers/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/oxford_flowers/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_3.pkl
1632 1633 2463
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  102
# train_x  1,632
# val      1,633
# test     2,463
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:03<01:30,  3.77s/it]  8%|▊         | 2/25 [00:03<00:37,  1.62s/it] 12%|█▏        | 3/25 [00:04<00:20,  1.07it/s] 16%|█▌        | 4/25 [00:04<00:12,  1.63it/s] 20%|██        | 5/25 [00:04<00:08,  2.29it/s] 24%|██▍       | 6/25 [00:04<00:06,  3.03it/s] 28%|██▊       | 7/25 [00:04<00:04,  3.82it/s] 32%|███▏      | 8/25 [00:04<00:03,  4.61it/s] 36%|███▌      | 9/25 [00:04<00:02,  5.34it/s] 40%|████      | 10/25 [00:04<00:02,  6.00it/s] 44%|████▍     | 11/25 [00:04<00:02,  6.55it/s] 48%|████▊     | 12/25 [00:05<00:01,  7.00it/s] 52%|█████▏    | 13/25 [00:05<00:01,  7.35it/s] 56%|█████▌    | 14/25 [00:05<00:01,  7.60it/s] 60%|██████    | 15/25 [00:05<00:01,  7.80it/s] 64%|██████▍   | 16/25 [00:05<00:01,  7.96it/s] 68%|██████▊   | 17/25 [00:05<00:00,  8.07it/s] 72%|███████▏  | 18/25 [00:05<00:00,  8.14it/s] 76%|███████▌  | 19/25 [00:05<00:00,  8.20it/s] 80%|████████  | 20/25 [00:06<00:00,  8.18it/s] 84%|████████▍ | 21/25 [00:06<00:00,  8.23it/s] 88%|████████▊ | 22/25 [00:06<00:00,  8.26it/s] 92%|█████████▏| 23/25 [00:06<00:00,  8.28it/s] 96%|█████████▌| 24/25 [00:06<00:00,  8.30it/s]100%|██████████| 25/25 [00:06<00:00,  3.73it/s]
=> result
* total: 2,463
* correct: 870
* accuracy: 35.3%
* error: 64.7%
* macro_f1: 25.3%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat food101 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/food101/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/food101/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_1.pkl
1616 20200 30300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  101
# train_x  1,616
# val      20,200
# test     30,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/303 [00:00<?, ?it/s]  0%|          | 1/303 [00:03<17:53,  3.55s/it]  1%|          | 2/303 [00:03<07:41,  1.53s/it]  1%|          | 3/303 [00:03<04:26,  1.12it/s]  1%|▏         | 4/303 [00:03<02:55,  1.71it/s]  2%|▏         | 5/303 [00:04<02:04,  2.39it/s]  2%|▏         | 6/303 [00:04<01:34,  3.16it/s]  2%|▏         | 7/303 [00:04<01:14,  3.96it/s]  3%|▎         | 8/303 [00:04<01:02,  4.74it/s]  3%|▎         | 9/303 [00:04<00:53,  5.47it/s]  3%|▎         | 10/303 [00:04<00:48,  6.10it/s]  4%|▎         | 11/303 [00:04<00:44,  6.63it/s]  4%|▍         | 12/303 [00:04<00:41,  7.07it/s]  4%|▍         | 13/303 [00:05<00:39,  7.41it/s]  5%|▍         | 14/303 [00:05<00:37,  7.66it/s]  5%|▍         | 15/303 [00:05<00:36,  7.84it/s]  5%|▌         | 16/303 [00:05<00:35,  7.98it/s]  6%|▌         | 17/303 [00:05<00:35,  8.06it/s]  6%|▌         | 18/303 [00:05<00:35,  8.13it/s]  6%|▋         | 19/303 [00:05<00:34,  8.19it/s]  7%|▋         | 20/303 [00:05<00:34,  8.22it/s]  7%|▋         | 21/303 [00:05<00:34,  8.25it/s]  7%|▋         | 22/303 [00:06<00:33,  8.27it/s]  8%|▊         | 23/303 [00:06<00:33,  8.28it/s]  8%|▊         | 24/303 [00:06<00:33,  8.26it/s]  8%|▊         | 25/303 [00:06<00:33,  8.27it/s]  9%|▊         | 26/303 [00:06<00:33,  8.26it/s]  9%|▉         | 27/303 [00:06<00:33,  8.28it/s]  9%|▉         | 28/303 [00:06<00:33,  8.28it/s] 10%|▉         | 29/303 [00:06<00:33,  8.28it/s] 10%|▉         | 30/303 [00:07<00:32,  8.29it/s] 10%|█         | 31/303 [00:07<00:32,  8.28it/s] 11%|█         | 32/303 [00:07<00:32,  8.26it/s] 11%|█         | 33/303 [00:07<00:32,  8.27it/s] 11%|█         | 34/303 [00:07<00:32,  8.27it/s] 12%|█▏        | 35/303 [00:07<00:32,  8.28it/s] 12%|█▏        | 36/303 [00:07<00:32,  8.28it/s] 12%|█▏        | 37/303 [00:07<00:32,  8.28it/s] 13%|█▎        | 38/303 [00:08<00:32,  8.28it/s] 13%|█▎        | 39/303 [00:08<00:31,  8.27it/s] 13%|█▎        | 40/303 [00:08<00:31,  8.27it/s] 14%|█▎        | 41/303 [00:08<00:31,  8.28it/s] 14%|█▍        | 42/303 [00:08<00:31,  8.28it/s] 14%|█▍        | 43/303 [00:08<00:31,  8.29it/s] 15%|█▍        | 44/303 [00:08<00:31,  8.29it/s] 15%|█▍        | 45/303 [00:08<00:31,  8.28it/s] 15%|█▌        | 46/303 [00:08<00:31,  8.28it/s] 16%|█▌        | 47/303 [00:09<00:30,  8.28it/s] 16%|█▌        | 48/303 [00:09<00:30,  8.27it/s] 16%|█▌        | 49/303 [00:09<00:30,  8.26it/s] 17%|█▋        | 50/303 [00:09<00:30,  8.25it/s] 17%|█▋        | 51/303 [00:09<00:30,  8.25it/s] 17%|█▋        | 52/303 [00:09<00:30,  8.26it/s] 17%|█▋        | 53/303 [00:09<00:30,  8.27it/s] 18%|█▊        | 54/303 [00:09<00:30,  8.27it/s] 18%|█▊        | 55/303 [00:10<00:29,  8.27it/s] 18%|█▊        | 56/303 [00:10<00:29,  8.26it/s] 19%|█▉        | 57/303 [00:10<00:29,  8.27it/s] 19%|█▉        | 58/303 [00:10<00:29,  8.26it/s] 19%|█▉        | 59/303 [00:10<00:29,  8.27it/s] 20%|█▉        | 60/303 [00:10<00:29,  8.29it/s] 20%|██        | 61/303 [00:10<00:29,  8.28it/s] 20%|██        | 62/303 [00:10<00:29,  8.28it/s] 21%|██        | 63/303 [00:11<00:29,  8.27it/s] 21%|██        | 64/303 [00:11<00:28,  8.25it/s] 21%|██▏       | 65/303 [00:11<00:28,  8.26it/s] 22%|██▏       | 66/303 [00:11<00:28,  8.25it/s] 22%|██▏       | 67/303 [00:11<00:28,  8.25it/s] 22%|██▏       | 68/303 [00:11<00:28,  8.26it/s] 23%|██▎       | 69/303 [00:11<00:28,  8.27it/s] 23%|██▎       | 70/303 [00:11<00:28,  8.27it/s] 23%|██▎       | 71/303 [00:12<00:28,  8.26it/s] 24%|██▍       | 72/303 [00:12<00:27,  8.26it/s] 24%|██▍       | 73/303 [00:12<00:27,  8.26it/s] 24%|██▍       | 74/303 [00:12<00:27,  8.26it/s] 25%|██▍       | 75/303 [00:12<00:27,  8.24it/s] 25%|██▌       | 76/303 [00:12<00:27,  8.26it/s] 25%|██▌       | 77/303 [00:12<00:27,  8.27it/s] 26%|██▌       | 78/303 [00:12<00:27,  8.27it/s] 26%|██▌       | 79/303 [00:12<00:27,  8.28it/s] 26%|██▋       | 80/303 [00:13<00:26,  8.28it/s] 27%|██▋       | 81/303 [00:13<00:26,  8.25it/s] 27%|██▋       | 82/303 [00:13<00:26,  8.24it/s] 27%|██▋       | 83/303 [00:13<00:26,  8.25it/s] 28%|██▊       | 84/303 [00:13<00:26,  8.25it/s] 28%|██▊       | 85/303 [00:13<00:31,  6.88it/s] 28%|██▊       | 86/303 [00:13<00:29,  7.24it/s] 29%|██▊       | 87/303 [00:14<00:28,  7.52it/s] 29%|██▉       | 88/303 [00:14<00:27,  7.71it/s] 29%|██▉       | 89/303 [00:14<00:27,  7.85it/s] 30%|██▉       | 90/303 [00:14<00:26,  7.96it/s] 30%|███       | 91/303 [00:14<00:26,  8.04it/s] 30%|███       | 92/303 [00:14<00:26,  8.10it/s] 31%|███       | 93/303 [00:14<00:29,  7.06it/s] 31%|███       | 94/303 [00:14<00:28,  7.36it/s] 31%|███▏      | 95/303 [00:15<00:27,  7.60it/s] 32%|███▏      | 96/303 [00:15<00:27,  7.52it/s] 32%|███▏      | 97/303 [00:15<00:26,  7.71it/s] 32%|███▏      | 98/303 [00:15<00:26,  7.85it/s] 33%|███▎      | 99/303 [00:15<00:25,  7.97it/s] 33%|███▎      | 100/303 [00:15<00:25,  8.05it/s] 33%|███▎      | 101/303 [00:15<00:25,  7.79it/s] 34%|███▎      | 102/303 [00:15<00:25,  7.90it/s] 34%|███▍      | 103/303 [00:16<00:25,  7.99it/s] 34%|███▍      | 104/303 [00:16<00:26,  7.55it/s] 35%|███▍      | 105/303 [00:16<00:25,  7.75it/s] 35%|███▍      | 106/303 [00:16<00:25,  7.87it/s] 35%|███▌      | 107/303 [00:16<00:24,  7.97it/s] 36%|███▌      | 108/303 [00:16<00:24,  8.05it/s] 36%|███▌      | 109/303 [00:16<00:24,  7.76it/s] 36%|███▋      | 110/303 [00:16<00:24,  7.90it/s] 37%|███▋      | 111/303 [00:17<00:24,  7.99it/s] 37%|███▋      | 112/303 [00:17<00:24,  7.82it/s] 37%|███▋      | 113/303 [00:17<00:23,  7.94it/s] 38%|███▊      | 114/303 [00:17<00:23,  8.02it/s] 38%|███▊      | 115/303 [00:17<00:23,  8.08it/s] 38%|███▊      | 116/303 [00:17<00:22,  8.13it/s] 39%|███▊      | 117/303 [00:17<00:22,  8.16it/s] 39%|███▉      | 118/303 [00:17<00:22,  8.16it/s] 39%|███▉      | 119/303 [00:18<00:22,  8.18it/s] 40%|███▉      | 120/303 [00:18<00:28,  6.42it/s] 40%|███▉      | 121/303 [00:18<00:26,  6.87it/s] 40%|████      | 122/303 [00:18<00:25,  7.22it/s] 41%|████      | 123/303 [00:18<00:24,  7.50it/s] 41%|████      | 124/303 [00:18<00:23,  7.70it/s] 41%|████▏     | 125/303 [00:18<00:22,  7.85it/s] 42%|████▏     | 126/303 [00:19<00:22,  7.96it/s] 42%|████▏     | 127/303 [00:19<00:21,  8.04it/s] 42%|████▏     | 128/303 [00:19<00:21,  8.08it/s] 43%|████▎     | 129/303 [00:19<00:21,  8.13it/s] 43%|████▎     | 130/303 [00:19<00:21,  8.14it/s] 43%|████▎     | 131/303 [00:19<00:21,  8.16it/s] 44%|████▎     | 132/303 [00:19<00:21,  8.14it/s] 44%|████▍     | 133/303 [00:20<00:26,  6.35it/s] 44%|████▍     | 134/303 [00:20<00:24,  6.82it/s] 45%|████▍     | 135/303 [00:20<00:23,  7.19it/s] 45%|████▍     | 136/303 [00:20<00:22,  7.46it/s] 45%|████▌     | 137/303 [00:20<00:21,  7.68it/s] 46%|████▌     | 138/303 [00:20<00:21,  7.83it/s] 46%|████▌     | 139/303 [00:20<00:20,  7.94it/s] 46%|████▌     | 140/303 [00:20<00:20,  8.03it/s] 47%|████▋     | 141/303 [00:21<00:37,  4.27it/s] 47%|████▋     | 142/303 [00:21<00:32,  4.97it/s] 47%|████▋     | 143/303 [00:21<00:28,  5.65it/s] 48%|████▊     | 144/303 [00:21<00:25,  6.24it/s] 48%|████▊     | 145/303 [00:21<00:23,  6.73it/s] 48%|████▊     | 146/303 [00:21<00:22,  7.11it/s] 49%|████▊     | 147/303 [00:22<00:21,  7.42it/s] 49%|████▉     | 148/303 [00:22<00:20,  7.64it/s] 49%|████▉     | 149/303 [00:22<00:36,  4.21it/s] 50%|████▉     | 150/303 [00:22<00:30,  4.94it/s] 50%|████▉     | 151/303 [00:22<00:27,  5.61it/s] 50%|█████     | 152/303 [00:23<00:24,  6.19it/s] 50%|█████     | 153/303 [00:23<00:22,  6.69it/s] 51%|█████     | 154/303 [00:23<00:21,  7.07it/s] 51%|█████     | 155/303 [00:23<00:20,  7.38it/s] 51%|█████▏    | 156/303 [00:23<00:19,  7.61it/s] 52%|█████▏    | 157/303 [00:23<00:32,  4.46it/s] 52%|█████▏    | 158/303 [00:24<00:28,  5.17it/s] 52%|█████▏    | 159/303 [00:24<00:24,  5.82it/s] 53%|█████▎    | 160/303 [00:24<00:22,  6.37it/s] 53%|█████▎    | 161/303 [00:24<00:20,  6.83it/s] 53%|█████▎    | 162/303 [00:24<00:19,  7.19it/s] 54%|█████▍    | 163/303 [00:24<00:18,  7.48it/s] 54%|█████▍    | 164/303 [00:24<00:18,  7.69it/s] 54%|█████▍    | 165/303 [00:26<01:36,  1.43it/s] 55%|█████▍    | 166/303 [00:26<01:11,  1.90it/s] 55%|█████▌    | 167/303 [00:27<00:54,  2.47it/s] 55%|█████▌    | 168/303 [00:27<00:46,  2.90it/s] 56%|█████▌    | 169/303 [00:27<00:37,  3.60it/s] 56%|█████▌    | 170/303 [00:27<00:30,  4.32it/s] 56%|█████▋    | 171/303 [00:27<00:26,  5.04it/s] 57%|█████▋    | 172/303 [00:28<00:36,  3.54it/s] 57%|█████▋    | 173/303 [00:29<01:19,  1.63it/s] 57%|█████▋    | 174/303 [00:29<01:00,  2.14it/s] 58%|█████▊    | 175/303 [00:29<00:46,  2.75it/s] 58%|█████▊    | 176/303 [00:29<00:36,  3.43it/s] 58%|█████▊    | 177/303 [00:30<00:30,  4.16it/s] 59%|█████▊    | 178/303 [00:30<00:25,  4.88it/s] 59%|█████▉    | 179/303 [00:30<00:22,  5.55it/s] 59%|█████▉    | 180/303 [00:30<00:20,  6.14it/s] 60%|█████▉    | 181/303 [00:30<00:18,  6.63it/s] 60%|██████    | 182/303 [00:30<00:17,  7.03it/s] 60%|██████    | 183/303 [00:30<00:16,  7.32it/s] 61%|██████    | 184/303 [00:30<00:15,  7.54it/s] 61%|██████    | 185/303 [00:31<00:15,  7.71it/s] 61%|██████▏   | 186/303 [00:31<00:14,  7.84it/s] 62%|██████▏   | 187/303 [00:31<00:14,  7.94it/s] 62%|██████▏   | 188/303 [00:31<00:14,  8.01it/s] 62%|██████▏   | 189/303 [00:31<00:14,  8.05it/s] 63%|██████▎   | 190/303 [00:31<00:13,  8.11it/s] 63%|██████▎   | 191/303 [00:31<00:13,  8.13it/s] 63%|██████▎   | 192/303 [00:31<00:13,  8.15it/s] 64%|██████▎   | 193/303 [00:31<00:13,  8.17it/s] 64%|██████▍   | 194/303 [00:32<00:13,  8.17it/s] 64%|██████▍   | 195/303 [00:32<00:13,  8.19it/s] 65%|██████▍   | 196/303 [00:32<00:13,  8.17it/s] 65%|██████▌   | 197/303 [00:32<00:13,  8.15it/s] 65%|██████▌   | 198/303 [00:32<00:12,  8.17it/s] 66%|██████▌   | 199/303 [00:32<00:12,  8.18it/s] 66%|██████▌   | 200/303 [00:32<00:12,  8.19it/s] 66%|██████▋   | 201/303 [00:32<00:12,  8.18it/s] 67%|██████▋   | 202/303 [00:33<00:12,  8.17it/s] 67%|██████▋   | 203/303 [00:33<00:12,  8.19it/s] 67%|██████▋   | 204/303 [00:33<00:12,  8.19it/s] 68%|██████▊   | 205/303 [00:33<00:11,  8.19it/s] 68%|██████▊   | 206/303 [00:33<00:11,  8.19it/s] 68%|██████▊   | 207/303 [00:33<00:11,  8.18it/s] 69%|██████▊   | 208/303 [00:33<00:11,  8.18it/s] 69%|██████▉   | 209/303 [00:33<00:11,  8.19it/s] 69%|██████▉   | 210/303 [00:34<00:11,  8.19it/s] 70%|██████▉   | 211/303 [00:34<00:11,  8.18it/s] 70%|██████▉   | 212/303 [00:34<00:11,  8.17it/s] 70%|███████   | 213/303 [00:34<00:11,  8.17it/s] 71%|███████   | 214/303 [00:34<00:10,  8.18it/s] 71%|███████   | 215/303 [00:34<00:10,  8.18it/s] 71%|███████▏  | 216/303 [00:34<00:10,  8.18it/s] 72%|███████▏  | 217/303 [00:34<00:10,  8.17it/s] 72%|███████▏  | 218/303 [00:35<00:10,  8.16it/s] 72%|███████▏  | 219/303 [00:35<00:10,  8.15it/s] 73%|███████▎  | 220/303 [00:35<00:10,  8.16it/s] 73%|███████▎  | 221/303 [00:35<00:10,  8.17it/s] 73%|███████▎  | 222/303 [00:35<00:09,  8.17it/s] 74%|███████▎  | 223/303 [00:35<00:09,  8.18it/s] 74%|███████▍  | 224/303 [00:35<00:09,  8.17it/s] 74%|███████▍  | 225/303 [00:35<00:09,  8.17it/s] 75%|███████▍  | 226/303 [00:36<00:09,  8.16it/s] 75%|███████▍  | 227/303 [00:36<00:09,  8.17it/s] 75%|███████▌  | 228/303 [00:36<00:09,  8.18it/s] 76%|███████▌  | 229/303 [00:36<00:09,  8.18it/s] 76%|███████▌  | 230/303 [00:36<00:08,  8.19it/s] 76%|███████▌  | 231/303 [00:36<00:08,  8.20it/s] 77%|███████▋  | 232/303 [00:36<00:08,  8.19it/s] 77%|███████▋  | 233/303 [00:36<00:08,  8.18it/s] 77%|███████▋  | 234/303 [00:37<00:08,  8.19it/s] 78%|███████▊  | 235/303 [00:37<00:08,  8.20it/s] 78%|███████▊  | 236/303 [00:37<00:08,  8.19it/s] 78%|███████▊  | 237/303 [00:37<00:08,  8.19it/s] 79%|███████▊  | 238/303 [00:37<00:07,  8.20it/s] 79%|███████▉  | 239/303 [00:37<00:07,  8.20it/s] 79%|███████▉  | 240/303 [00:37<00:07,  8.20it/s] 80%|███████▉  | 241/303 [00:37<00:07,  8.19it/s] 80%|███████▉  | 242/303 [00:37<00:07,  8.21it/s] 80%|████████  | 243/303 [00:38<00:07,  8.21it/s] 81%|████████  | 244/303 [00:38<00:07,  8.20it/s] 81%|████████  | 245/303 [00:38<00:07,  8.19it/s] 81%|████████  | 246/303 [00:38<00:06,  8.18it/s] 82%|████████▏ | 247/303 [00:38<00:06,  8.16it/s] 82%|████████▏ | 248/303 [00:38<00:06,  8.17it/s] 82%|████████▏ | 249/303 [00:38<00:06,  8.17it/s] 83%|████████▎ | 250/303 [00:38<00:06,  8.18it/s] 83%|████████▎ | 251/303 [00:39<00:06,  8.16it/s] 83%|████████▎ | 252/303 [00:39<00:06,  8.17it/s] 83%|████████▎ | 253/303 [00:39<00:06,  8.18it/s] 84%|████████▍ | 254/303 [00:39<00:05,  8.17it/s] 84%|████████▍ | 255/303 [00:39<00:05,  8.17it/s] 84%|████████▍ | 256/303 [00:39<00:05,  8.17it/s] 85%|████████▍ | 257/303 [00:39<00:05,  8.17it/s] 85%|████████▌ | 258/303 [00:39<00:05,  8.16it/s] 85%|████████▌ | 259/303 [00:40<00:05,  8.14it/s] 86%|████████▌ | 260/303 [00:40<00:05,  8.16it/s] 86%|████████▌ | 261/303 [00:40<00:05,  8.18it/s] 86%|████████▋ | 262/303 [00:40<00:05,  8.18it/s] 87%|████████▋ | 263/303 [00:40<00:04,  8.19it/s] 87%|████████▋ | 264/303 [00:40<00:04,  8.20it/s] 87%|████████▋ | 265/303 [00:40<00:04,  8.20it/s] 88%|████████▊ | 266/303 [00:40<00:04,  8.19it/s] 88%|████████▊ | 267/303 [00:41<00:04,  8.18it/s] 88%|████████▊ | 268/303 [00:41<00:04,  8.18it/s] 89%|████████▉ | 269/303 [00:41<00:04,  8.18it/s] 89%|████████▉ | 270/303 [00:41<00:04,  8.16it/s] 89%|████████▉ | 271/303 [00:41<00:03,  8.17it/s] 90%|████████▉ | 272/303 [00:41<00:03,  8.16it/s] 90%|█████████ | 273/303 [00:41<00:03,  8.18it/s] 90%|█████████ | 274/303 [00:41<00:03,  8.18it/s] 91%|█████████ | 275/303 [00:42<00:03,  8.19it/s] 91%|█████████ | 276/303 [00:42<00:03,  8.18it/s] 91%|█████████▏| 277/303 [00:42<00:03,  8.19it/s] 92%|█████████▏| 278/303 [00:42<00:03,  8.18it/s] 92%|█████████▏| 279/303 [00:42<00:02,  8.19it/s] 92%|█████████▏| 280/303 [00:42<00:02,  8.19it/s] 93%|█████████▎| 281/303 [00:42<00:02,  8.17it/s] 93%|█████████▎| 282/303 [00:42<00:02,  8.11it/s] 93%|█████████▎| 283/303 [00:42<00:02,  8.14it/s] 94%|█████████▎| 284/303 [00:43<00:02,  8.15it/s] 94%|█████████▍| 285/303 [00:43<00:02,  8.16it/s] 94%|█████████▍| 286/303 [00:43<00:02,  8.17it/s] 95%|█████████▍| 287/303 [00:43<00:01,  8.17it/s] 95%|█████████▌| 288/303 [00:43<00:01,  8.18it/s] 95%|█████████▌| 289/303 [00:43<00:01,  8.17it/s] 96%|█████████▌| 290/303 [00:43<00:01,  8.19it/s] 96%|█████████▌| 291/303 [00:43<00:01,  8.21it/s] 96%|█████████▋| 292/303 [00:44<00:01,  8.20it/s] 97%|█████████▋| 293/303 [00:44<00:01,  8.21it/s] 97%|█████████▋| 294/303 [00:44<00:01,  8.18it/s] 97%|█████████▋| 295/303 [00:44<00:00,  8.19it/s] 98%|█████████▊| 296/303 [00:44<00:00,  8.20it/s] 98%|█████████▊| 297/303 [00:44<00:00,  8.20it/s] 98%|█████████▊| 298/303 [00:44<00:00,  8.20it/s] 99%|█████████▊| 299/303 [00:44<00:00,  8.22it/s] 99%|█████████▉| 300/303 [00:45<00:00,  8.23it/s] 99%|█████████▉| 301/303 [00:45<00:00,  8.24it/s]100%|█████████▉| 302/303 [00:45<00:00,  8.25it/s]100%|██████████| 303/303 [00:45<00:00,  8.25it/s]100%|██████████| 303/303 [00:45<00:00,  6.66it/s]
=> result
* total: 30,300
* correct: 18,696
* accuracy: 61.7%
* error: 38.3%
* macro_f1: 59.4%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat food101 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/food101/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/food101/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_2.pkl
1616 20200 30300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  101
# train_x  1,616
# val      20,200
# test     30,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/303 [00:00<?, ?it/s]  0%|          | 1/303 [00:03<17:42,  3.52s/it]  1%|          | 2/303 [00:03<07:37,  1.52s/it]  1%|          | 3/303 [00:03<04:24,  1.14it/s]  1%|▏         | 4/303 [00:03<02:53,  1.72it/s]  2%|▏         | 5/303 [00:04<02:03,  2.41it/s]  2%|▏         | 6/303 [00:04<01:33,  3.18it/s]  2%|▏         | 7/303 [00:04<01:14,  3.98it/s]  3%|▎         | 8/303 [00:04<01:01,  4.77it/s]  3%|▎         | 9/303 [00:04<00:53,  5.50it/s]  3%|▎         | 10/303 [00:04<00:47,  6.12it/s]  4%|▎         | 11/303 [00:04<00:43,  6.65it/s]  4%|▍         | 12/303 [00:04<00:41,  7.07it/s]  4%|▍         | 13/303 [00:04<00:39,  7.40it/s]  5%|▍         | 14/303 [00:05<00:37,  7.64it/s]  5%|▍         | 15/303 [00:05<00:36,  7.81it/s]  5%|▌         | 16/303 [00:05<00:36,  7.93it/s]  6%|▌         | 17/303 [00:05<00:35,  8.04it/s]  6%|▌         | 18/303 [00:05<00:35,  8.11it/s]  6%|▋         | 19/303 [00:05<00:34,  8.15it/s]  7%|▋         | 20/303 [00:05<00:34,  8.17it/s]  7%|▋         | 21/303 [00:05<00:34,  8.19it/s]  7%|▋         | 22/303 [00:06<00:34,  8.21it/s]  8%|▊         | 23/303 [00:06<00:34,  8.22it/s]  8%|▊         | 24/303 [00:06<00:34,  8.15it/s]  8%|▊         | 25/303 [00:06<00:33,  8.20it/s]  9%|▊         | 26/303 [00:06<00:33,  8.22it/s]  9%|▉         | 27/303 [00:06<00:33,  8.22it/s]  9%|▉         | 28/303 [00:06<00:33,  8.22it/s] 10%|▉         | 29/303 [00:06<00:33,  8.23it/s] 10%|▉         | 30/303 [00:07<00:33,  8.24it/s] 10%|█         | 31/303 [00:07<00:33,  8.24it/s] 11%|█         | 32/303 [00:07<00:32,  8.23it/s] 11%|█         | 33/303 [00:07<00:32,  8.21it/s] 11%|█         | 34/303 [00:07<00:32,  8.19it/s] 12%|█▏        | 35/303 [00:07<00:32,  8.19it/s] 12%|█▏        | 36/303 [00:07<00:32,  8.22it/s] 12%|█▏        | 37/303 [00:07<00:32,  8.23it/s] 13%|█▎        | 38/303 [00:08<00:32,  8.23it/s] 13%|█▎        | 39/303 [00:08<00:32,  8.20it/s] 13%|█▎        | 40/303 [00:08<00:32,  8.21it/s] 14%|█▎        | 41/303 [00:08<00:31,  8.21it/s] 14%|█▍        | 42/303 [00:08<00:31,  8.22it/s] 14%|█▍        | 43/303 [00:08<00:31,  8.23it/s] 15%|█▍        | 44/303 [00:08<00:31,  8.23it/s] 15%|█▍        | 45/303 [00:08<00:31,  8.21it/s] 15%|█▌        | 46/303 [00:08<00:31,  8.22it/s] 16%|█▌        | 47/303 [00:09<00:31,  8.22it/s] 16%|█▌        | 48/303 [00:09<00:31,  8.22it/s] 16%|█▌        | 49/303 [00:09<00:30,  8.20it/s] 17%|█▋        | 50/303 [00:09<00:30,  8.19it/s] 17%|█▋        | 51/303 [00:09<00:30,  8.18it/s] 17%|█▋        | 52/303 [00:09<00:30,  8.18it/s] 17%|█▋        | 53/303 [00:09<00:30,  8.17it/s] 18%|█▊        | 54/303 [00:09<00:30,  8.18it/s] 18%|█▊        | 55/303 [00:10<00:30,  8.19it/s] 18%|█▊        | 56/303 [00:10<00:30,  8.20it/s] 19%|█▉        | 57/303 [00:10<00:29,  8.21it/s] 19%|█▉        | 58/303 [00:10<00:29,  8.22it/s] 19%|█▉        | 59/303 [00:10<00:29,  8.20it/s] 20%|█▉        | 60/303 [00:10<00:29,  8.21it/s] 20%|██        | 61/303 [00:10<00:29,  8.21it/s] 20%|██        | 62/303 [00:10<00:29,  8.22it/s] 21%|██        | 63/303 [00:11<00:29,  8.22it/s] 21%|██        | 64/303 [00:11<00:29,  8.23it/s] 21%|██▏       | 65/303 [00:11<00:28,  8.23it/s] 22%|██▏       | 66/303 [00:11<00:28,  8.23it/s] 22%|██▏       | 67/303 [00:11<00:28,  8.21it/s] 22%|██▏       | 68/303 [00:11<00:28,  8.21it/s] 23%|██▎       | 69/303 [00:11<00:28,  8.21it/s] 23%|██▎       | 70/303 [00:11<00:28,  8.21it/s] 23%|██▎       | 71/303 [00:12<00:28,  8.21it/s] 24%|██▍       | 72/303 [00:12<00:28,  8.20it/s] 24%|██▍       | 73/303 [00:12<00:28,  8.21it/s] 24%|██▍       | 74/303 [00:12<00:27,  8.20it/s] 25%|██▍       | 75/303 [00:12<00:27,  8.21it/s] 25%|██▌       | 76/303 [00:12<00:27,  8.20it/s] 25%|██▌       | 77/303 [00:12<00:27,  8.20it/s] 26%|██▌       | 78/303 [00:12<00:27,  8.21it/s] 26%|██▌       | 79/303 [00:13<00:27,  8.22it/s] 26%|██▋       | 80/303 [00:13<00:27,  8.22it/s] 27%|██▋       | 81/303 [00:13<00:26,  8.23it/s] 27%|██▋       | 82/303 [00:13<00:26,  8.22it/s] 27%|██▋       | 83/303 [00:13<00:26,  8.21it/s] 28%|██▊       | 84/303 [00:13<00:26,  8.19it/s] 28%|██▊       | 85/303 [00:13<00:26,  8.19it/s] 28%|██▊       | 86/303 [00:13<00:26,  8.18it/s] 29%|██▊       | 87/303 [00:13<00:26,  8.20it/s] 29%|██▉       | 88/303 [00:14<00:26,  8.20it/s] 29%|██▉       | 89/303 [00:14<00:26,  8.19it/s] 30%|██▉       | 90/303 [00:14<00:26,  8.19it/s] 30%|███       | 91/303 [00:14<00:25,  8.19it/s] 30%|███       | 92/303 [00:14<00:25,  8.20it/s] 31%|███       | 93/303 [00:14<00:25,  8.20it/s] 31%|███       | 94/303 [00:14<00:25,  8.19it/s] 31%|███▏      | 95/303 [00:14<00:25,  8.18it/s] 32%|███▏      | 96/303 [00:15<00:25,  8.19it/s] 32%|███▏      | 97/303 [00:15<00:25,  8.19it/s] 32%|███▏      | 98/303 [00:15<00:25,  8.18it/s] 33%|███▎      | 99/303 [00:15<00:24,  8.20it/s] 33%|███▎      | 100/303 [00:15<00:24,  8.21it/s] 33%|███▎      | 101/303 [00:15<00:24,  8.19it/s] 34%|███▎      | 102/303 [00:15<00:24,  8.17it/s] 34%|███▍      | 103/303 [00:15<00:24,  8.16it/s] 34%|███▍      | 104/303 [00:16<00:24,  8.15it/s] 35%|███▍      | 105/303 [00:16<00:24,  8.15it/s] 35%|███▍      | 106/303 [00:16<00:24,  8.17it/s] 35%|███▌      | 107/303 [00:16<00:23,  8.17it/s] 36%|███▌      | 108/303 [00:16<00:23,  8.18it/s] 36%|███▌      | 109/303 [00:16<00:23,  8.18it/s] 36%|███▋      | 110/303 [00:16<00:23,  8.18it/s] 37%|███▋      | 111/303 [00:16<00:23,  8.19it/s] 37%|███▋      | 112/303 [00:17<00:23,  8.19it/s] 37%|███▋      | 113/303 [00:17<00:23,  8.18it/s] 38%|███▊      | 114/303 [00:17<00:23,  8.18it/s] 38%|███▊      | 115/303 [00:17<00:22,  8.19it/s] 38%|███▊      | 116/303 [00:17<00:22,  8.19it/s] 39%|███▊      | 117/303 [00:17<00:22,  8.16it/s] 39%|███▉      | 118/303 [00:17<00:22,  8.15it/s] 39%|███▉      | 119/303 [00:17<00:22,  8.15it/s] 40%|███▉      | 120/303 [00:18<00:22,  8.17it/s] 40%|███▉      | 121/303 [00:18<00:22,  8.18it/s] 40%|████      | 122/303 [00:18<00:22,  8.19it/s] 41%|████      | 123/303 [00:18<00:22,  8.18it/s] 41%|████      | 124/303 [00:18<00:21,  8.17it/s] 41%|████▏     | 125/303 [00:18<00:21,  8.19it/s] 42%|████▏     | 126/303 [00:18<00:21,  8.18it/s] 42%|████▏     | 127/303 [00:18<00:21,  8.20it/s] 42%|████▏     | 128/303 [00:18<00:21,  8.20it/s] 43%|████▎     | 129/303 [00:19<00:21,  8.19it/s] 43%|████▎     | 130/303 [00:19<00:21,  8.18it/s] 43%|████▎     | 131/303 [00:19<00:20,  8.20it/s] 44%|████▎     | 132/303 [00:19<00:20,  8.20it/s] 44%|████▍     | 133/303 [00:19<00:20,  8.20it/s] 44%|████▍     | 134/303 [00:19<00:20,  8.20it/s] 45%|████▍     | 135/303 [00:19<00:20,  8.20it/s] 45%|████▍     | 136/303 [00:19<00:20,  8.21it/s] 45%|████▌     | 137/303 [00:20<00:20,  8.19it/s] 46%|████▌     | 138/303 [00:20<00:20,  8.18it/s] 46%|████▌     | 139/303 [00:20<00:20,  8.19it/s] 46%|████▌     | 140/303 [00:20<00:19,  8.19it/s] 47%|████▋     | 141/303 [00:20<00:19,  8.20it/s] 47%|████▋     | 142/303 [00:20<00:19,  8.20it/s] 47%|████▋     | 143/303 [00:20<00:19,  8.20it/s] 48%|████▊     | 144/303 [00:20<00:19,  8.21it/s] 48%|████▊     | 145/303 [00:21<00:19,  8.20it/s] 48%|████▊     | 146/303 [00:21<00:19,  8.18it/s] 49%|████▊     | 147/303 [00:21<00:19,  8.19it/s] 49%|████▉     | 148/303 [00:21<00:18,  8.20it/s] 49%|████▉     | 149/303 [00:21<00:18,  8.19it/s] 50%|████▉     | 150/303 [00:21<00:18,  8.17it/s] 50%|████▉     | 151/303 [00:21<00:18,  8.17it/s] 50%|█████     | 152/303 [00:21<00:18,  8.19it/s] 50%|█████     | 153/303 [00:22<00:18,  8.18it/s] 51%|█████     | 154/303 [00:22<00:18,  8.20it/s] 51%|█████     | 155/303 [00:22<00:18,  8.19it/s] 51%|█████▏    | 156/303 [00:22<00:17,  8.19it/s] 52%|█████▏    | 157/303 [00:22<00:17,  8.19it/s] 52%|█████▏    | 158/303 [00:22<00:17,  8.18it/s] 52%|█████▏    | 159/303 [00:22<00:17,  8.16it/s] 53%|█████▎    | 160/303 [00:22<00:17,  8.17it/s] 53%|█████▎    | 161/303 [00:23<00:17,  8.18it/s] 53%|█████▎    | 162/303 [00:23<00:17,  8.20it/s] 54%|█████▍    | 163/303 [00:23<00:17,  8.20it/s] 54%|█████▍    | 164/303 [00:23<00:16,  8.20it/s] 54%|█████▍    | 165/303 [00:23<00:16,  8.19it/s] 55%|█████▍    | 166/303 [00:23<00:16,  8.18it/s] 55%|█████▌    | 167/303 [00:23<00:16,  8.18it/s] 55%|█████▌    | 168/303 [00:23<00:16,  8.18it/s] 56%|█████▌    | 169/303 [00:23<00:16,  8.16it/s] 56%|█████▌    | 170/303 [00:24<00:16,  8.13it/s] 56%|█████▋    | 171/303 [00:24<00:16,  8.16it/s] 57%|█████▋    | 172/303 [00:24<00:16,  8.18it/s] 57%|█████▋    | 173/303 [00:24<00:16,  8.12it/s] 57%|█████▋    | 174/303 [00:24<00:15,  8.15it/s] 58%|█████▊    | 175/303 [00:24<00:15,  8.15it/s] 58%|█████▊    | 176/303 [00:24<00:15,  8.17it/s] 58%|█████▊    | 177/303 [00:24<00:15,  8.17it/s] 59%|█████▊    | 178/303 [00:25<00:15,  8.17it/s] 59%|█████▉    | 179/303 [00:25<00:15,  8.16it/s] 59%|█████▉    | 180/303 [00:25<00:15,  8.14it/s] 60%|█████▉    | 181/303 [00:25<00:14,  8.15it/s] 60%|██████    | 182/303 [00:25<00:14,  8.17it/s] 60%|██████    | 183/303 [00:25<00:14,  8.17it/s] 61%|██████    | 184/303 [00:25<00:14,  8.16it/s] 61%|██████    | 185/303 [00:25<00:14,  8.10it/s] 61%|██████▏   | 186/303 [00:26<00:14,  8.13it/s] 62%|██████▏   | 187/303 [00:26<00:14,  8.16it/s] 62%|██████▏   | 188/303 [00:26<00:14,  8.17it/s] 62%|██████▏   | 189/303 [00:26<00:13,  8.18it/s] 63%|██████▎   | 190/303 [00:26<00:13,  8.14it/s] 63%|██████▎   | 191/303 [00:26<00:13,  8.15it/s] 63%|██████▎   | 192/303 [00:26<00:13,  8.16it/s] 64%|██████▎   | 193/303 [00:26<00:13,  8.17it/s] 64%|██████▍   | 194/303 [00:27<00:13,  8.18it/s] 64%|██████▍   | 195/303 [00:27<00:13,  8.18it/s] 65%|██████▍   | 196/303 [00:27<00:13,  8.19it/s] 65%|██████▌   | 197/303 [00:27<00:12,  8.19it/s] 65%|██████▌   | 198/303 [00:27<00:12,  8.19it/s] 66%|██████▌   | 199/303 [00:27<00:12,  8.18it/s] 66%|██████▌   | 200/303 [00:27<00:12,  8.18it/s] 66%|██████▋   | 201/303 [00:27<00:12,  8.18it/s] 67%|██████▋   | 202/303 [00:28<00:12,  8.17it/s] 67%|██████▋   | 203/303 [00:28<00:12,  8.17it/s] 67%|██████▋   | 204/303 [00:28<00:12,  8.18it/s] 68%|██████▊   | 205/303 [00:28<00:11,  8.18it/s] 68%|██████▊   | 206/303 [00:28<00:11,  8.18it/s] 68%|██████▊   | 207/303 [00:28<00:11,  8.17it/s] 69%|██████▊   | 208/303 [00:28<00:11,  8.17it/s] 69%|██████▉   | 209/303 [00:28<00:11,  8.17it/s] 69%|██████▉   | 210/303 [00:29<00:11,  8.18it/s] 70%|██████▉   | 211/303 [00:29<00:11,  8.17it/s] 70%|██████▉   | 212/303 [00:29<00:11,  8.17it/s] 70%|███████   | 213/303 [00:29<00:11,  8.18it/s] 71%|███████   | 214/303 [00:29<00:10,  8.17it/s] 71%|███████   | 215/303 [00:29<00:10,  8.17it/s] 71%|███████▏  | 216/303 [00:29<00:10,  8.17it/s] 72%|███████▏  | 217/303 [00:29<00:10,  8.15it/s] 72%|███████▏  | 218/303 [00:29<00:10,  8.17it/s] 72%|███████▏  | 219/303 [00:30<00:10,  8.18it/s] 73%|███████▎  | 220/303 [00:30<00:10,  8.17it/s] 73%|███████▎  | 221/303 [00:30<00:10,  8.17it/s] 73%|███████▎  | 222/303 [00:30<00:09,  8.16it/s] 74%|███████▎  | 223/303 [00:30<00:09,  8.15it/s] 74%|███████▍  | 224/303 [00:30<00:09,  8.15it/s] 74%|███████▍  | 225/303 [00:30<00:09,  8.16it/s] 75%|███████▍  | 226/303 [00:30<00:09,  8.17it/s] 75%|███████▍  | 227/303 [00:31<00:09,  8.18it/s] 75%|███████▌  | 228/303 [00:31<00:09,  8.18it/s] 76%|███████▌  | 229/303 [00:31<00:09,  8.17it/s] 76%|███████▌  | 230/303 [00:31<00:08,  8.17it/s] 76%|███████▌  | 231/303 [00:31<00:08,  8.17it/s] 77%|███████▋  | 232/303 [00:31<00:08,  8.18it/s] 77%|███████▋  | 233/303 [00:31<00:08,  8.19it/s] 77%|███████▋  | 234/303 [00:31<00:08,  8.19it/s] 78%|███████▊  | 235/303 [00:32<00:08,  8.19it/s] 78%|███████▊  | 236/303 [00:32<00:08,  8.19it/s] 78%|███████▊  | 237/303 [00:32<00:08,  8.16it/s] 79%|███████▊  | 238/303 [00:32<00:07,  8.15it/s] 79%|███████▉  | 239/303 [00:32<00:07,  8.14it/s] 79%|███████▉  | 240/303 [00:32<00:07,  8.14it/s] 80%|███████▉  | 241/303 [00:32<00:07,  8.13it/s] 80%|███████▉  | 242/303 [00:32<00:07,  8.14it/s] 80%|████████  | 243/303 [00:33<00:07,  8.14it/s] 81%|████████  | 244/303 [00:33<00:07,  8.15it/s] 81%|████████  | 245/303 [00:33<00:07,  8.15it/s] 81%|████████  | 246/303 [00:33<00:06,  8.16it/s] 82%|████████▏ | 247/303 [00:33<00:06,  8.16it/s] 82%|████████▏ | 248/303 [00:33<00:06,  8.16it/s] 82%|████████▏ | 249/303 [00:33<00:06,  8.15it/s] 83%|████████▎ | 250/303 [00:33<00:06,  8.16it/s] 83%|████████▎ | 251/303 [00:34<00:06,  8.15it/s] 83%|████████▎ | 252/303 [00:34<00:06,  8.15it/s] 83%|████████▎ | 253/303 [00:34<00:06,  8.13it/s] 84%|████████▍ | 254/303 [00:34<00:06,  8.13it/s] 84%|████████▍ | 255/303 [00:34<00:05,  8.14it/s] 84%|████████▍ | 256/303 [00:34<00:05,  8.14it/s] 85%|████████▍ | 257/303 [00:34<00:05,  8.15it/s] 85%|████████▌ | 258/303 [00:34<00:05,  8.16it/s] 85%|████████▌ | 259/303 [00:35<00:05,  8.16it/s] 86%|████████▌ | 260/303 [00:35<00:05,  8.14it/s] 86%|████████▌ | 261/303 [00:35<00:05,  8.13it/s] 86%|████████▋ | 262/303 [00:35<00:05,  8.13it/s] 87%|████████▋ | 263/303 [00:35<00:04,  8.13it/s] 87%|████████▋ | 264/303 [00:35<00:04,  8.14it/s] 87%|████████▋ | 265/303 [00:35<00:04,  8.15it/s] 88%|████████▊ | 266/303 [00:35<00:04,  8.15it/s] 88%|████████▊ | 267/303 [00:36<00:04,  8.14it/s] 88%|████████▊ | 268/303 [00:36<00:04,  8.10it/s] 89%|████████▉ | 269/303 [00:36<00:04,  8.12it/s] 89%|████████▉ | 270/303 [00:36<00:04,  8.13it/s] 89%|████████▉ | 271/303 [00:36<00:03,  8.11it/s] 90%|████████▉ | 272/303 [00:36<00:03,  8.12it/s] 90%|█████████ | 273/303 [00:36<00:03,  8.14it/s] 90%|█████████ | 274/303 [00:36<00:03,  8.16it/s] 91%|█████████ | 275/303 [00:36<00:03,  8.17it/s] 91%|█████████ | 276/303 [00:37<00:03,  8.16it/s] 91%|█████████▏| 277/303 [00:37<00:03,  8.17it/s] 92%|█████████▏| 278/303 [00:37<00:03,  8.17it/s] 92%|█████████▏| 279/303 [00:37<00:02,  8.18it/s] 92%|█████████▏| 280/303 [00:37<00:02,  8.18it/s] 93%|█████████▎| 281/303 [00:37<00:02,  8.18it/s] 93%|█████████▎| 282/303 [00:37<00:02,  8.19it/s] 93%|█████████▎| 283/303 [00:37<00:02,  8.19it/s] 94%|█████████▎| 284/303 [00:38<00:02,  8.17it/s] 94%|█████████▍| 285/303 [00:38<00:02,  8.17it/s] 94%|█████████▍| 286/303 [00:38<00:02,  8.17it/s] 95%|█████████▍| 287/303 [00:38<00:01,  8.15it/s] 95%|█████████▌| 288/303 [00:38<00:01,  8.16it/s] 95%|█████████▌| 289/303 [00:38<00:01,  8.17it/s] 96%|█████████▌| 290/303 [00:38<00:01,  8.18it/s] 96%|█████████▌| 291/303 [00:38<00:01,  8.17it/s] 96%|█████████▋| 292/303 [00:39<00:01,  8.19it/s] 97%|█████████▋| 293/303 [00:39<00:01,  8.20it/s] 97%|█████████▋| 294/303 [00:39<00:01,  8.21it/s] 97%|█████████▋| 295/303 [00:39<00:00,  8.22it/s] 98%|█████████▊| 296/303 [00:39<00:00,  8.23it/s] 98%|█████████▊| 297/303 [00:39<00:00,  8.24it/s] 98%|█████████▊| 298/303 [00:39<00:00,  8.23it/s] 99%|█████████▊| 299/303 [00:39<00:00,  8.23it/s] 99%|█████████▉| 300/303 [00:40<00:00,  8.18it/s] 99%|█████████▉| 301/303 [00:40<00:00,  8.20it/s]100%|█████████▉| 302/303 [00:40<00:00,  8.21it/s]100%|██████████| 303/303 [00:40<00:00,  8.23it/s]100%|██████████| 303/303 [00:40<00:00,  7.48it/s]
=> result
* total: 30,300
* correct: 17,119
* accuracy: 56.5%
* error: 43.5%
* macro_f1: 52.7%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat food101 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/food101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/food101/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Food101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/food101/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:Food101
Loading dataset: Food101
Reading split from /shared/s2/lab01/dataset/clip/food-101/split_zhou_Food101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/food-101/split_fewshot_taesup/shot_16-seed_3.pkl
1616 20200 30300
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    Food101
# classes  101
# train_x  1,616
# val      20,200
# test     30,300
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/303 [00:00<?, ?it/s]  0%|          | 1/303 [00:03<18:12,  3.62s/it]  1%|          | 2/303 [00:03<07:49,  1.56s/it]  1%|          | 3/303 [00:03<04:31,  1.11it/s]  1%|▏         | 4/303 [00:03<02:57,  1.68it/s]  2%|▏         | 5/303 [00:04<02:06,  2.36it/s]  2%|▏         | 6/303 [00:04<01:35,  3.12it/s]  2%|▏         | 7/303 [00:04<01:15,  3.91it/s]  3%|▎         | 8/303 [00:04<01:02,  4.70it/s]  3%|▎         | 9/303 [00:04<00:54,  5.43it/s]  3%|▎         | 10/303 [00:04<00:48,  6.07it/s]  4%|▎         | 11/303 [00:04<00:44,  6.61it/s]  4%|▍         | 12/303 [00:04<00:41,  7.03it/s]  4%|▍         | 13/303 [00:05<00:39,  7.36it/s]  5%|▍         | 14/303 [00:05<00:38,  7.60it/s]  5%|▍         | 15/303 [00:05<00:37,  7.77it/s]  5%|▌         | 16/303 [00:05<00:36,  7.91it/s]  6%|▌         | 17/303 [00:05<00:35,  7.99it/s]  6%|▌         | 18/303 [00:05<00:35,  8.05it/s]  6%|▋         | 19/303 [00:05<00:35,  8.11it/s]  7%|▋         | 20/303 [00:05<00:34,  8.14it/s]  7%|▋         | 21/303 [00:06<00:34,  8.15it/s]  7%|▋         | 22/303 [00:06<00:34,  8.17it/s]  8%|▊         | 23/303 [00:06<00:34,  8.19it/s]  8%|▊         | 24/303 [00:06<00:34,  8.19it/s]  8%|▊         | 25/303 [00:06<00:33,  8.21it/s]  9%|▊         | 26/303 [00:06<00:33,  8.21it/s]  9%|▉         | 27/303 [00:06<00:33,  8.22it/s]  9%|▉         | 28/303 [00:06<00:33,  8.14it/s] 10%|▉         | 29/303 [00:07<00:33,  8.17it/s] 10%|▉         | 30/303 [00:07<00:33,  8.17it/s] 10%|█         | 31/303 [00:07<00:33,  8.17it/s] 11%|█         | 32/303 [00:07<00:33,  8.17it/s] 11%|█         | 33/303 [00:07<00:33,  8.17it/s] 11%|█         | 34/303 [00:07<00:32,  8.18it/s] 12%|█▏        | 35/303 [00:07<00:32,  8.18it/s] 12%|█▏        | 36/303 [00:07<00:32,  8.18it/s] 12%|█▏        | 37/303 [00:07<00:32,  8.20it/s] 13%|█▎        | 38/303 [00:08<00:32,  8.18it/s] 13%|█▎        | 39/303 [00:08<00:32,  8.17it/s] 13%|█▎        | 40/303 [00:08<00:32,  8.17it/s] 14%|█▎        | 41/303 [00:08<00:32,  8.19it/s] 14%|█▍        | 42/303 [00:08<00:31,  8.20it/s] 14%|█▍        | 43/303 [00:08<00:31,  8.21it/s] 15%|█▍        | 44/303 [00:08<00:31,  8.22it/s] 15%|█▍        | 45/303 [00:08<00:31,  8.22it/s] 15%|█▌        | 46/303 [00:09<00:31,  8.19it/s] 16%|█▌        | 47/303 [00:09<00:31,  8.19it/s] 16%|█▌        | 48/303 [00:09<00:31,  8.20it/s] 16%|█▌        | 49/303 [00:09<00:30,  8.20it/s] 17%|█▋        | 50/303 [00:09<00:30,  8.19it/s] 17%|█▋        | 51/303 [00:09<00:30,  8.18it/s] 17%|█▋        | 52/303 [00:09<00:30,  8.19it/s] 17%|█▋        | 53/303 [00:09<00:30,  8.18it/s] 18%|█▊        | 54/303 [00:10<00:30,  8.17it/s] 18%|█▊        | 55/303 [00:10<00:30,  8.17it/s] 18%|█▊        | 56/303 [00:10<00:30,  8.17it/s] 19%|█▉        | 57/303 [00:10<00:30,  8.18it/s] 19%|█▉        | 58/303 [00:10<00:29,  8.18it/s] 19%|█▉        | 59/303 [00:10<00:29,  8.18it/s] 20%|█▉        | 60/303 [00:10<00:29,  8.19it/s] 20%|██        | 61/303 [00:10<00:29,  8.19it/s] 20%|██        | 62/303 [00:11<00:29,  8.18it/s] 21%|██        | 63/303 [00:11<00:29,  8.18it/s] 21%|██        | 64/303 [00:11<00:29,  8.18it/s] 21%|██▏       | 65/303 [00:11<00:29,  8.18it/s] 22%|██▏       | 66/303 [00:11<00:29,  8.17it/s] 22%|██▏       | 67/303 [00:11<00:28,  8.16it/s] 22%|██▏       | 68/303 [00:11<00:28,  8.17it/s] 23%|██▎       | 69/303 [00:11<00:28,  8.18it/s] 23%|██▎       | 70/303 [00:12<00:28,  8.17it/s] 23%|██▎       | 71/303 [00:12<00:28,  8.16it/s] 24%|██▍       | 72/303 [00:12<00:28,  8.16it/s] 24%|██▍       | 73/303 [00:12<00:28,  8.16it/s] 24%|██▍       | 74/303 [00:12<00:28,  8.17it/s] 25%|██▍       | 75/303 [00:12<00:27,  8.17it/s] 25%|██▌       | 76/303 [00:12<00:27,  8.18it/s] 25%|██▌       | 77/303 [00:12<00:27,  8.19it/s] 26%|██▌       | 78/303 [00:13<00:27,  8.19it/s] 26%|██▌       | 79/303 [00:13<00:27,  8.19it/s] 26%|██▋       | 80/303 [00:13<00:27,  8.19it/s] 27%|██▋       | 81/303 [00:13<00:27,  8.19it/s] 27%|██▋       | 82/303 [00:13<00:27,  8.16it/s] 27%|██▋       | 83/303 [00:13<00:26,  8.16it/s] 28%|██▊       | 84/303 [00:13<00:26,  8.15it/s] 28%|██▊       | 85/303 [00:13<00:26,  8.14it/s] 28%|██▊       | 86/303 [00:13<00:26,  8.16it/s] 29%|██▊       | 87/303 [00:14<00:26,  8.15it/s] 29%|██▉       | 88/303 [00:14<00:26,  8.10it/s] 29%|██▉       | 89/303 [00:14<00:26,  8.13it/s] 30%|██▉       | 90/303 [00:14<00:26,  8.14it/s] 30%|███       | 91/303 [00:14<00:25,  8.16it/s] 30%|███       | 92/303 [00:14<00:25,  8.18it/s] 31%|███       | 93/303 [00:14<00:25,  8.18it/s] 31%|███       | 94/303 [00:14<00:25,  8.19it/s] 31%|███▏      | 95/303 [00:15<00:25,  8.20it/s] 32%|███▏      | 96/303 [00:15<00:25,  8.19it/s] 32%|███▏      | 97/303 [00:15<00:25,  8.20it/s] 32%|███▏      | 98/303 [00:15<00:24,  8.20it/s] 33%|███▎      | 99/303 [00:15<00:24,  8.18it/s] 33%|███▎      | 100/303 [00:15<00:24,  8.18it/s] 33%|███▎      | 101/303 [00:15<00:24,  8.18it/s] 34%|███▎      | 102/303 [00:15<00:24,  8.17it/s] 34%|███▍      | 103/303 [00:16<00:24,  8.16it/s] 34%|███▍      | 104/303 [00:16<00:24,  8.17it/s] 35%|███▍      | 105/303 [00:16<00:24,  8.18it/s] 35%|███▍      | 106/303 [00:16<00:24,  8.18it/s] 35%|███▌      | 107/303 [00:16<00:23,  8.18it/s] 36%|███▌      | 108/303 [00:16<00:23,  8.19it/s] 36%|███▌      | 109/303 [00:16<00:23,  8.18it/s] 36%|███▋      | 110/303 [00:16<00:23,  8.18it/s] 37%|███▋      | 111/303 [00:17<00:23,  8.17it/s] 37%|███▋      | 112/303 [00:17<00:23,  8.17it/s] 37%|███▋      | 113/303 [00:17<00:23,  8.17it/s] 38%|███▊      | 114/303 [00:17<00:23,  8.19it/s] 38%|███▊      | 115/303 [00:17<00:22,  8.18it/s] 38%|███▊      | 116/303 [00:17<00:22,  8.17it/s] 39%|███▊      | 117/303 [00:17<00:22,  8.16it/s] 39%|███▉      | 118/303 [00:17<00:22,  8.16it/s] 39%|███▉      | 119/303 [00:18<00:22,  8.16it/s] 40%|███▉      | 120/303 [00:18<00:22,  8.14it/s] 40%|███▉      | 121/303 [00:18<00:22,  8.13it/s] 40%|████      | 122/303 [00:18<00:22,  8.14it/s] 41%|████      | 123/303 [00:18<00:22,  8.15it/s] 41%|████      | 124/303 [00:18<00:21,  8.15it/s] 41%|████▏     | 125/303 [00:18<00:21,  8.13it/s] 42%|████▏     | 126/303 [00:18<00:21,  8.15it/s] 42%|████▏     | 127/303 [00:19<00:21,  8.15it/s] 42%|████▏     | 128/303 [00:19<00:21,  8.15it/s] 43%|████▎     | 129/303 [00:19<00:21,  8.17it/s] 43%|████▎     | 130/303 [00:19<00:21,  8.17it/s] 43%|████▎     | 131/303 [00:19<00:21,  8.17it/s] 44%|████▎     | 132/303 [00:19<00:20,  8.18it/s] 44%|████▍     | 133/303 [00:19<00:20,  8.16it/s] 44%|████▍     | 134/303 [00:19<00:20,  8.17it/s] 45%|████▍     | 135/303 [00:19<00:20,  8.17it/s] 45%|████▍     | 136/303 [00:20<00:20,  8.14it/s] 45%|████▌     | 137/303 [00:20<00:20,  8.12it/s] 46%|████▌     | 138/303 [00:20<00:20,  8.14it/s] 46%|████▌     | 139/303 [00:20<00:20,  8.13it/s] 46%|████▌     | 140/303 [00:20<00:20,  8.13it/s] 47%|████▋     | 141/303 [00:20<00:19,  8.13it/s] 47%|████▋     | 142/303 [00:20<00:19,  8.12it/s] 47%|████▋     | 143/303 [00:20<00:19,  8.14it/s] 48%|████▊     | 144/303 [00:21<00:19,  8.12it/s] 48%|████▊     | 145/303 [00:21<00:19,  8.14it/s] 48%|████▊     | 146/303 [00:21<00:19,  8.15it/s] 49%|████▊     | 147/303 [00:21<00:19,  8.15it/s] 49%|████▉     | 148/303 [00:21<00:19,  8.08it/s] 49%|████▉     | 149/303 [00:21<00:19,  8.10it/s] 50%|████▉     | 150/303 [00:21<00:18,  8.11it/s] 50%|████▉     | 151/303 [00:21<00:18,  8.12it/s] 50%|█████     | 152/303 [00:22<00:18,  8.10it/s] 50%|█████     | 153/303 [00:22<00:18,  8.11it/s] 51%|█████     | 154/303 [00:22<00:18,  8.12it/s] 51%|█████     | 155/303 [00:22<00:18,  8.14it/s] 51%|█████▏    | 156/303 [00:22<00:18,  8.15it/s] 52%|█████▏    | 157/303 [00:22<00:17,  8.17it/s] 52%|█████▏    | 158/303 [00:22<00:17,  8.17it/s] 52%|█████▏    | 159/303 [00:22<00:17,  8.18it/s] 53%|█████▎    | 160/303 [00:23<00:17,  8.19it/s] 53%|█████▎    | 161/303 [00:23<00:17,  8.19it/s] 53%|█████▎    | 162/303 [00:23<00:17,  8.19it/s] 54%|█████▍    | 163/303 [00:23<00:17,  8.17it/s] 54%|█████▍    | 164/303 [00:23<00:17,  8.17it/s] 54%|█████▍    | 165/303 [00:23<00:16,  8.18it/s] 55%|█████▍    | 166/303 [00:23<00:16,  8.19it/s] 55%|█████▌    | 167/303 [00:23<00:16,  8.17it/s] 55%|█████▌    | 168/303 [00:24<00:16,  8.17it/s] 56%|█████▌    | 169/303 [00:24<00:16,  8.16it/s] 56%|█████▌    | 170/303 [00:24<00:16,  8.16it/s] 56%|█████▋    | 171/303 [00:24<00:16,  8.17it/s] 57%|█████▋    | 172/303 [00:24<00:16,  8.16it/s] 57%|█████▋    | 173/303 [00:24<00:15,  8.16it/s] 57%|█████▋    | 174/303 [00:24<00:15,  8.16it/s] 58%|█████▊    | 175/303 [00:24<00:15,  8.17it/s] 58%|█████▊    | 176/303 [00:25<00:15,  8.17it/s] 58%|█████▊    | 177/303 [00:25<00:15,  8.17it/s] 59%|█████▊    | 178/303 [00:25<00:15,  8.16it/s] 59%|█████▉    | 179/303 [00:25<00:15,  8.17it/s] 59%|█████▉    | 180/303 [00:25<00:15,  8.17it/s] 60%|█████▉    | 181/303 [00:25<00:14,  8.18it/s] 60%|██████    | 182/303 [00:25<00:14,  8.18it/s] 60%|██████    | 183/303 [00:25<00:14,  8.17it/s] 61%|██████    | 184/303 [00:26<00:14,  8.17it/s] 61%|██████    | 185/303 [00:26<00:14,  8.17it/s] 61%|██████▏   | 186/303 [00:26<00:14,  8.17it/s] 62%|██████▏   | 187/303 [00:26<00:14,  8.18it/s] 62%|██████▏   | 188/303 [00:26<00:14,  8.16it/s] 62%|██████▏   | 189/303 [00:26<00:13,  8.15it/s] 63%|██████▎   | 190/303 [00:26<00:13,  8.16it/s] 63%|██████▎   | 191/303 [00:26<00:13,  8.16it/s] 63%|██████▎   | 192/303 [00:26<00:13,  8.17it/s] 64%|██████▎   | 193/303 [00:27<00:13,  8.17it/s] 64%|██████▍   | 194/303 [00:27<00:13,  8.16it/s] 64%|██████▍   | 195/303 [00:27<00:13,  8.16it/s] 65%|██████▍   | 196/303 [00:27<00:13,  8.17it/s] 65%|██████▌   | 197/303 [00:27<00:12,  8.17it/s] 65%|██████▌   | 198/303 [00:27<00:12,  8.16it/s] 66%|██████▌   | 199/303 [00:27<00:12,  8.15it/s] 66%|██████▌   | 200/303 [00:27<00:12,  8.16it/s] 66%|██████▋   | 201/303 [00:28<00:12,  8.16it/s] 67%|██████▋   | 202/303 [00:28<00:12,  8.16it/s] 67%|██████▋   | 203/303 [00:28<00:12,  8.15it/s] 67%|██████▋   | 204/303 [00:28<00:12,  8.14it/s] 68%|██████▊   | 205/303 [00:28<00:12,  8.15it/s] 68%|██████▊   | 206/303 [00:28<00:11,  8.14it/s] 68%|██████▊   | 207/303 [00:28<00:11,  8.14it/s] 69%|██████▊   | 208/303 [00:28<00:11,  8.14it/s] 69%|██████▉   | 209/303 [00:29<00:11,  8.14it/s] 69%|██████▉   | 210/303 [00:29<00:11,  8.14it/s] 70%|██████▉   | 211/303 [00:29<00:11,  8.15it/s] 70%|██████▉   | 212/303 [00:29<00:11,  8.17it/s] 70%|███████   | 213/303 [00:29<00:11,  8.17it/s] 71%|███████   | 214/303 [00:29<00:10,  8.15it/s] 71%|███████   | 215/303 [00:29<00:10,  8.16it/s] 71%|███████▏  | 216/303 [00:29<00:10,  8.15it/s] 72%|███████▏  | 217/303 [00:30<00:10,  8.16it/s] 72%|███████▏  | 218/303 [00:30<00:10,  8.15it/s] 72%|███████▏  | 219/303 [00:30<00:10,  8.14it/s] 73%|███████▎  | 220/303 [00:30<00:10,  8.14it/s] 73%|███████▎  | 221/303 [00:30<00:10,  8.14it/s] 73%|███████▎  | 222/303 [00:30<00:09,  8.13it/s] 74%|███████▎  | 223/303 [00:30<00:09,  8.15it/s] 74%|███████▍  | 224/303 [00:30<00:09,  8.15it/s] 74%|███████▍  | 225/303 [00:31<00:09,  8.15it/s] 75%|███████▍  | 226/303 [00:31<00:09,  8.16it/s] 75%|███████▍  | 227/303 [00:31<00:09,  8.11it/s] 75%|███████▌  | 228/303 [00:31<00:09,  8.14it/s] 76%|███████▌  | 229/303 [00:31<00:09,  8.15it/s] 76%|███████▌  | 230/303 [00:31<00:08,  8.16it/s] 76%|███████▌  | 231/303 [00:31<00:08,  8.17it/s] 77%|███████▋  | 232/303 [00:31<00:08,  8.16it/s] 77%|███████▋  | 233/303 [00:32<00:08,  8.17it/s] 77%|███████▋  | 234/303 [00:32<00:08,  8.16it/s] 78%|███████▊  | 235/303 [00:32<00:08,  8.15it/s] 78%|███████▊  | 236/303 [00:32<00:08,  8.17it/s] 78%|███████▊  | 237/303 [00:32<00:08,  8.17it/s] 79%|███████▊  | 238/303 [00:32<00:07,  8.18it/s] 79%|███████▉  | 239/303 [00:32<00:07,  8.18it/s] 79%|███████▉  | 240/303 [00:32<00:07,  8.18it/s] 80%|███████▉  | 241/303 [00:32<00:07,  8.16it/s] 80%|███████▉  | 242/303 [00:33<00:07,  8.15it/s] 80%|████████  | 243/303 [00:33<00:07,  8.15it/s] 81%|████████  | 244/303 [00:33<00:07,  8.14it/s] 81%|████████  | 245/303 [00:33<00:07,  8.13it/s] 81%|████████  | 246/303 [00:33<00:07,  8.13it/s] 82%|████████▏ | 247/303 [00:33<00:06,  8.14it/s] 82%|████████▏ | 248/303 [00:33<00:06,  8.14it/s] 82%|████████▏ | 249/303 [00:33<00:06,  8.13it/s] 83%|████████▎ | 250/303 [00:34<00:06,  8.14it/s] 83%|████████▎ | 251/303 [00:34<00:06,  8.15it/s] 83%|████████▎ | 252/303 [00:34<00:06,  8.17it/s] 83%|████████▎ | 253/303 [00:34<00:06,  8.16it/s] 84%|████████▍ | 254/303 [00:34<00:06,  8.16it/s] 84%|████████▍ | 255/303 [00:34<00:05,  8.16it/s] 84%|████████▍ | 256/303 [00:34<00:05,  8.16it/s] 85%|████████▍ | 257/303 [00:34<00:05,  8.15it/s] 85%|████████▌ | 258/303 [00:35<00:05,  8.13it/s] 85%|████████▌ | 259/303 [00:35<00:05,  8.14it/s] 86%|████████▌ | 260/303 [00:35<00:05,  8.15it/s] 86%|████████▌ | 261/303 [00:35<00:05,  8.14it/s] 86%|████████▋ | 262/303 [00:35<00:05,  8.13it/s] 87%|████████▋ | 263/303 [00:35<00:04,  8.14it/s] 87%|████████▋ | 264/303 [00:35<00:04,  8.15it/s] 87%|████████▋ | 265/303 [00:35<00:04,  8.14it/s] 88%|████████▊ | 266/303 [00:36<00:04,  8.13it/s] 88%|████████▊ | 267/303 [00:36<00:04,  8.14it/s] 88%|████████▊ | 268/303 [00:36<00:04,  8.11it/s] 89%|████████▉ | 269/303 [00:36<00:04,  8.12it/s] 89%|████████▉ | 270/303 [00:36<00:04,  8.13it/s] 89%|████████▉ | 271/303 [00:36<00:03,  8.13it/s] 90%|████████▉ | 272/303 [00:36<00:03,  8.15it/s] 90%|█████████ | 273/303 [00:36<00:03,  8.15it/s] 90%|█████████ | 274/303 [00:37<00:03,  8.15it/s] 91%|█████████ | 275/303 [00:37<00:03,  8.16it/s] 91%|█████████ | 276/303 [00:37<00:03,  8.15it/s] 91%|█████████▏| 277/303 [00:37<00:03,  8.15it/s] 92%|█████████▏| 278/303 [00:37<00:03,  8.15it/s] 92%|█████████▏| 279/303 [00:37<00:02,  8.14it/s] 92%|█████████▏| 280/303 [00:37<00:02,  8.15it/s] 93%|█████████▎| 281/303 [00:37<00:02,  8.14it/s] 93%|█████████▎| 282/303 [00:38<00:02,  8.13it/s] 93%|█████████▎| 283/303 [00:38<00:02,  8.12it/s] 94%|█████████▎| 284/303 [00:38<00:02,  8.12it/s] 94%|█████████▍| 285/303 [00:38<00:02,  8.12it/s] 94%|█████████▍| 286/303 [00:38<00:02,  8.11it/s] 95%|█████████▍| 287/303 [00:38<00:01,  8.12it/s] 95%|█████████▌| 288/303 [00:38<00:01,  8.13it/s] 95%|█████████▌| 289/303 [00:38<00:01,  8.14it/s] 96%|█████████▌| 290/303 [00:39<00:01,  8.14it/s] 96%|█████████▌| 291/303 [00:39<00:01,  8.15it/s] 96%|█████████▋| 292/303 [00:39<00:01,  8.16it/s] 97%|█████████▋| 293/303 [00:39<00:01,  8.17it/s] 97%|█████████▋| 294/303 [00:39<00:01,  8.19it/s] 97%|█████████▋| 295/303 [00:39<00:00,  8.20it/s] 98%|█████████▊| 296/303 [00:39<00:00,  8.21it/s] 98%|█████████▊| 297/303 [00:39<00:00,  8.22it/s] 98%|█████████▊| 298/303 [00:39<00:00,  8.22it/s] 99%|█████████▊| 299/303 [00:40<00:00,  8.23it/s] 99%|█████████▉| 300/303 [00:40<00:00,  8.23it/s] 99%|█████████▉| 301/303 [00:40<00:00,  8.23it/s]100%|█████████▉| 302/303 [00:40<00:00,  8.23it/s]100%|██████████| 303/303 [00:40<00:00,  8.23it/s]100%|██████████| 303/303 [00:40<00:00,  7.45it/s]
=> result
* total: 30,300
* correct: 19,874
* accuracy: 65.6%
* error: 34.4%
* macro_f1: 63.9%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat ucf101 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/ucf101/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/ucf101/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_1.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:03<02:18,  3.74s/it]  5%|▌         | 2/38 [00:03<00:58,  1.61s/it]  8%|▊         | 3/38 [00:03<00:32,  1.07it/s] 11%|█         | 4/38 [00:04<00:20,  1.63it/s] 13%|█▎        | 5/38 [00:04<00:14,  2.30it/s] 16%|█▌        | 6/38 [00:04<00:10,  3.05it/s] 18%|█▊        | 7/38 [00:04<00:08,  3.84it/s] 21%|██        | 8/38 [00:04<00:06,  4.62it/s] 24%|██▎       | 9/38 [00:04<00:05,  5.35it/s] 26%|██▋       | 10/38 [00:04<00:04,  6.00it/s] 29%|██▉       | 11/38 [00:04<00:04,  6.54it/s] 32%|███▏      | 12/38 [00:05<00:03,  6.98it/s] 34%|███▍      | 13/38 [00:05<00:03,  7.32it/s] 37%|███▋      | 14/38 [00:05<00:03,  7.57it/s] 39%|███▉      | 15/38 [00:05<00:02,  7.76it/s] 42%|████▏     | 16/38 [00:05<00:02,  7.89it/s] 45%|████▍     | 17/38 [00:05<00:02,  7.96it/s] 47%|████▋     | 18/38 [00:05<00:02,  8.05it/s] 50%|█████     | 19/38 [00:05<00:02,  8.10it/s] 53%|█████▎    | 20/38 [00:06<00:02,  8.14it/s] 55%|█████▌    | 21/38 [00:06<00:02,  8.18it/s] 58%|█████▊    | 22/38 [00:06<00:01,  8.20it/s] 61%|██████    | 23/38 [00:06<00:01,  8.21it/s] 63%|██████▎   | 24/38 [00:06<00:01,  8.22it/s] 66%|██████▌   | 25/38 [00:06<00:01,  8.24it/s] 68%|██████▊   | 26/38 [00:06<00:01,  8.24it/s] 71%|███████   | 27/38 [00:06<00:01,  8.26it/s] 74%|███████▎  | 28/38 [00:07<00:01,  8.28it/s] 76%|███████▋  | 29/38 [00:07<00:01,  8.28it/s] 79%|███████▉  | 30/38 [00:07<00:00,  8.29it/s] 82%|████████▏ | 31/38 [00:07<00:00,  8.30it/s] 84%|████████▍ | 32/38 [00:07<00:00,  8.30it/s] 87%|████████▋ | 33/38 [00:07<00:00,  8.30it/s] 89%|████████▉ | 34/38 [00:07<00:00,  8.30it/s] 92%|█████████▏| 35/38 [00:07<00:00,  8.30it/s] 95%|█████████▍| 36/38 [00:07<00:00,  8.31it/s] 97%|█████████▋| 37/38 [00:08<00:00,  8.31it/s]100%|██████████| 38/38 [00:08<00:00,  8.66it/s]100%|██████████| 38/38 [00:08<00:00,  4.59it/s]
=> result
* total: 3,783
* correct: 1,189
* accuracy: 31.4%
* error: 68.6%
* macro_f1: 26.8%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat ucf101 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/ucf101/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/ucf101/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_2.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:03<01:53,  3.08s/it]  5%|▌         | 2/38 [00:03<00:48,  1.34s/it]  8%|▊         | 3/38 [00:03<00:27,  1.28it/s] 11%|█         | 4/38 [00:03<00:17,  1.92it/s] 13%|█▎        | 5/38 [00:03<00:12,  2.65it/s] 16%|█▌        | 6/38 [00:03<00:09,  3.44it/s] 18%|█▊        | 7/38 [00:03<00:07,  4.26it/s] 21%|██        | 8/38 [00:03<00:05,  5.03it/s] 24%|██▎       | 9/38 [00:04<00:05,  5.73it/s] 26%|██▋       | 10/38 [00:04<00:04,  6.33it/s] 29%|██▉       | 11/38 [00:04<00:03,  6.82it/s] 32%|███▏      | 12/38 [00:04<00:03,  7.20it/s] 34%|███▍      | 13/38 [00:04<00:03,  7.49it/s] 37%|███▋      | 14/38 [00:04<00:03,  7.71it/s] 39%|███▉      | 15/38 [00:04<00:02,  7.87it/s] 42%|████▏     | 16/38 [00:04<00:02,  7.98it/s] 45%|████▍     | 17/38 [00:05<00:02,  8.06it/s] 47%|████▋     | 18/38 [00:05<00:02,  8.01it/s] 50%|█████     | 19/38 [00:05<00:02,  8.09it/s] 53%|█████▎    | 20/38 [00:05<00:02,  8.14it/s] 55%|█████▌    | 21/38 [00:05<00:02,  8.17it/s] 58%|█████▊    | 22/38 [00:05<00:01,  8.18it/s] 61%|██████    | 23/38 [00:05<00:01,  8.20it/s] 63%|██████▎   | 24/38 [00:05<00:01,  8.22it/s] 66%|██████▌   | 25/38 [00:05<00:01,  8.24it/s] 68%|██████▊   | 26/38 [00:06<00:01,  8.26it/s] 71%|███████   | 27/38 [00:06<00:01,  8.27it/s] 74%|███████▎  | 28/38 [00:06<00:01,  8.28it/s] 76%|███████▋  | 29/38 [00:06<00:01,  8.22it/s] 79%|███████▉  | 30/38 [00:06<00:00,  8.25it/s] 82%|████████▏ | 31/38 [00:06<00:00,  8.27it/s] 84%|████████▍ | 32/38 [00:06<00:00,  8.29it/s] 87%|████████▋ | 33/38 [00:06<00:00,  8.30it/s] 89%|████████▉ | 34/38 [00:07<00:00,  8.30it/s] 92%|█████████▏| 35/38 [00:07<00:00,  8.30it/s] 95%|█████████▍| 36/38 [00:07<00:00,  8.31it/s] 97%|█████████▋| 37/38 [00:07<00:00,  8.32it/s]100%|██████████| 38/38 [00:07<00:00,  8.67it/s]100%|██████████| 38/38 [00:07<00:00,  4.99it/s]
=> result
* total: 3,783
* correct: 1,446
* accuracy: 38.2%
* error: 61.8%
* macro_f1: 32.1%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat ucf101 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/ucf101.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/ucf101/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: UCF101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/ucf101/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:UCF101
Loading dataset: UCF101
Reading split from /shared/s2/lab01/dataset/clip/ucf101/split_zhou_UCF101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ucf101/split_fewshot_taesup/shot_16-seed_3.pkl
1616 1898 3783
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    UCF101
# classes  101
# train_x  1,616
# val      1,898
# test     3,783
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/38 [00:00<?, ?it/s]  3%|▎         | 1/38 [00:03<01:54,  3.10s/it]  5%|▌         | 2/38 [00:03<00:48,  1.35s/it]  8%|▊         | 3/38 [00:03<00:27,  1.27it/s] 11%|█         | 4/38 [00:03<00:17,  1.90it/s] 13%|█▎        | 5/38 [00:03<00:12,  2.64it/s] 16%|█▌        | 6/38 [00:03<00:09,  3.43it/s] 18%|█▊        | 7/38 [00:03<00:07,  4.24it/s] 21%|██        | 8/38 [00:03<00:05,  5.01it/s] 24%|██▎       | 9/38 [00:04<00:05,  5.71it/s] 26%|██▋       | 10/38 [00:04<00:04,  6.31it/s] 29%|██▉       | 11/38 [00:04<00:03,  6.80it/s] 32%|███▏      | 12/38 [00:04<00:03,  7.19it/s] 34%|███▍      | 13/38 [00:04<00:03,  7.47it/s] 37%|███▋      | 14/38 [00:04<00:03,  7.68it/s] 39%|███▉      | 15/38 [00:04<00:02,  7.85it/s] 42%|████▏     | 16/38 [00:04<00:02,  7.98it/s] 45%|████▍     | 17/38 [00:05<00:02,  8.06it/s] 47%|████▋     | 18/38 [00:05<00:02,  8.12it/s] 50%|█████     | 19/38 [00:05<00:02,  8.09it/s] 53%|█████▎    | 20/38 [00:05<00:02,  8.15it/s] 55%|█████▌    | 21/38 [00:05<00:02,  8.18it/s] 58%|█████▊    | 22/38 [00:05<00:01,  8.20it/s] 61%|██████    | 23/38 [00:05<00:01,  8.22it/s] 63%|██████▎   | 24/38 [00:05<00:01,  8.24it/s] 66%|██████▌   | 25/38 [00:06<00:01,  8.25it/s] 68%|██████▊   | 26/38 [00:06<00:01,  8.28it/s] 71%|███████   | 27/38 [00:06<00:01,  8.29it/s] 74%|███████▎  | 28/38 [00:06<00:01,  8.30it/s] 76%|███████▋  | 29/38 [00:06<00:01,  8.22it/s] 79%|███████▉  | 30/38 [00:06<00:00,  8.26it/s] 82%|████████▏ | 31/38 [00:06<00:00,  8.28it/s] 84%|████████▍ | 32/38 [00:06<00:00,  8.29it/s] 87%|████████▋ | 33/38 [00:06<00:00,  8.30it/s] 89%|████████▉ | 34/38 [00:07<00:00,  8.31it/s] 92%|█████████▏| 35/38 [00:07<00:00,  8.31it/s] 95%|█████████▍| 36/38 [00:07<00:00,  8.31it/s] 97%|█████████▋| 37/38 [00:07<00:00,  8.31it/s]100%|██████████| 38/38 [00:07<00:00,  8.53it/s]100%|██████████| 38/38 [00:07<00:00,  4.97it/s]
=> result
* total: 3,783
* correct: 1,961
* accuracy: 51.8%
* error: 48.2%
* macro_f1: 47.3%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat sun397 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/sun397/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/sun397/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_1.pkl
6352 3970 19850
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  397
# train_x  6,352
# val      3,970
# test     19,850
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/199 [00:00<?, ?it/s]  1%|          | 1/199 [00:05<18:50,  5.71s/it]  1%|          | 2/199 [00:05<08:04,  2.46s/it]  2%|▏         | 3/199 [00:06<04:37,  1.42s/it]  2%|▏         | 4/199 [00:06<03:00,  1.08it/s]  3%|▎         | 5/199 [00:06<02:07,  1.52it/s]  3%|▎         | 6/199 [00:06<01:35,  2.02it/s]  4%|▎         | 7/199 [00:06<01:15,  2.56it/s]  4%|▍         | 8/199 [00:06<01:01,  3.10it/s]  5%|▍         | 9/199 [00:08<01:46,  1.78it/s]  5%|▌         | 10/199 [00:08<01:38,  1.91it/s]  6%|▌         | 11/199 [00:10<02:44,  1.14it/s]  6%|▌         | 12/199 [00:10<02:04,  1.50it/s]  7%|▋         | 13/199 [00:10<01:36,  1.93it/s]  7%|▋         | 14/199 [00:10<01:16,  2.41it/s]  8%|▊         | 15/199 [00:10<01:03,  2.91it/s]  8%|▊         | 16/199 [00:11<00:53,  3.40it/s]  9%|▊         | 17/199 [00:11<00:47,  3.85it/s]  9%|▉         | 18/199 [00:11<00:42,  4.26it/s] 10%|▉         | 19/199 [00:12<01:43,  1.73it/s] 10%|█         | 20/199 [00:12<01:22,  2.18it/s] 11%|█         | 21/199 [00:13<01:06,  2.67it/s] 11%|█         | 22/199 [00:13<00:55,  3.17it/s] 12%|█▏        | 23/199 [00:13<00:48,  3.65it/s] 12%|█▏        | 24/199 [00:13<00:42,  4.07it/s] 13%|█▎        | 25/199 [00:13<00:39,  4.44it/s] 13%|█▎        | 26/199 [00:14<00:38,  4.53it/s] 14%|█▎        | 27/199 [00:16<02:43,  1.05it/s] 14%|█▍        | 28/199 [00:16<02:03,  1.39it/s] 15%|█▍        | 29/199 [00:17<01:34,  1.79it/s] 15%|█▌        | 30/199 [00:17<01:15,  2.25it/s] 16%|█▌        | 31/199 [00:17<01:01,  2.74it/s] 16%|█▌        | 32/199 [00:17<00:51,  3.24it/s] 17%|█▋        | 33/199 [00:17<00:44,  3.71it/s] 17%|█▋        | 34/199 [00:17<00:40,  4.12it/s] 18%|█▊        | 35/199 [00:19<01:47,  1.53it/s] 18%|█▊        | 36/199 [00:19<01:23,  1.95it/s] 19%|█▊        | 37/199 [00:20<01:14,  2.17it/s] 19%|█▉        | 38/199 [00:20<01:00,  2.66it/s] 20%|█▉        | 39/199 [00:20<00:50,  3.16it/s] 20%|██        | 40/199 [00:20<00:43,  3.63it/s] 21%|██        | 41/199 [00:20<00:38,  4.06it/s] 21%|██        | 42/199 [00:21<00:35,  4.43it/s] 22%|██▏       | 43/199 [00:23<01:59,  1.31it/s] 22%|██▏       | 44/199 [00:23<01:31,  1.70it/s] 23%|██▎       | 45/199 [00:23<01:11,  2.15it/s] 23%|██▎       | 46/199 [00:23<00:58,  2.63it/s] 24%|██▎       | 47/199 [00:23<00:48,  3.13it/s] 24%|██▍       | 48/199 [00:23<00:41,  3.61it/s] 25%|██▍       | 49/199 [00:24<00:37,  4.03it/s] 25%|██▌       | 50/199 [00:24<00:33,  4.40it/s] 26%|██▌       | 51/199 [00:26<02:09,  1.14it/s] 26%|██▌       | 52/199 [00:26<01:37,  1.50it/s] 27%|██▋       | 53/199 [00:27<01:15,  1.92it/s] 27%|██▋       | 54/199 [00:27<01:00,  2.40it/s] 28%|██▊       | 55/199 [00:27<00:49,  2.89it/s] 28%|██▊       | 56/199 [00:27<00:42,  3.38it/s] 29%|██▊       | 57/199 [00:27<00:37,  3.83it/s] 29%|██▉       | 58/199 [00:27<00:33,  4.23it/s] 30%|██▉       | 59/199 [00:28<01:06,  2.12it/s] 30%|███       | 60/199 [00:29<01:06,  2.08it/s] 31%|███       | 61/199 [00:29<00:53,  2.57it/s] 31%|███       | 62/199 [00:29<00:44,  3.06it/s] 32%|███▏      | 63/199 [00:29<00:38,  3.55it/s] 32%|███▏      | 64/199 [00:30<00:33,  3.98it/s] 33%|███▎      | 65/199 [00:30<00:30,  4.36it/s] 33%|███▎      | 66/199 [00:32<01:30,  1.47it/s] 34%|███▎      | 67/199 [00:32<01:09,  1.89it/s] 34%|███▍      | 68/199 [00:34<02:09,  1.01it/s] 35%|███▍      | 69/199 [00:34<01:37,  1.34it/s] 35%|███▌      | 70/199 [00:34<01:14,  1.73it/s] 36%|███▌      | 71/199 [00:34<00:58,  2.18it/s] 36%|███▌      | 72/199 [00:35<00:47,  2.67it/s] 37%|███▋      | 73/199 [00:35<00:39,  3.17it/s] 37%|███▋      | 74/199 [00:37<02:00,  1.04it/s] 38%|███▊      | 75/199 [00:38<01:52,  1.11it/s] 38%|███▊      | 76/199 [00:38<01:24,  1.46it/s] 39%|███▊      | 77/199 [00:38<01:05,  1.87it/s] 39%|███▉      | 78/199 [00:38<00:51,  2.34it/s] 40%|███▉      | 79/199 [00:39<00:42,  2.83it/s] 40%|████      | 80/199 [00:39<00:35,  3.33it/s] 41%|████      | 81/199 [00:39<00:31,  3.78it/s] 41%|████      | 82/199 [00:42<02:12,  1.14s/it] 42%|████▏     | 83/199 [00:43<01:52,  1.03it/s] 42%|████▏     | 84/199 [00:43<01:24,  1.37it/s] 43%|████▎     | 85/199 [00:43<01:04,  1.77it/s] 43%|████▎     | 86/199 [00:43<00:50,  2.22it/s] 44%|████▎     | 87/199 [00:43<00:41,  2.71it/s] 44%|████▍     | 88/199 [00:44<00:34,  3.21it/s] 45%|████▍     | 89/199 [00:44<00:29,  3.68it/s] 45%|████▌     | 90/199 [00:48<02:23,  1.32s/it] 46%|████▌     | 91/199 [00:48<01:45,  1.02it/s] 46%|████▌     | 92/199 [00:48<01:18,  1.36it/s] 47%|████▋     | 93/199 [00:48<01:00,  1.75it/s] 47%|████▋     | 94/199 [00:48<00:47,  2.21it/s] 48%|████▊     | 95/199 [00:49<00:38,  2.70it/s] 48%|████▊     | 96/199 [00:49<00:32,  3.19it/s] 49%|████▊     | 97/199 [00:49<00:27,  3.65it/s] 49%|████▉     | 98/199 [00:50<01:05,  1.54it/s] 50%|████▉     | 99/199 [00:51<00:50,  1.97it/s] 50%|█████     | 100/199 [00:52<01:14,  1.33it/s] 51%|█████     | 101/199 [00:52<00:56,  1.72it/s] 51%|█████▏    | 102/199 [00:52<00:44,  2.18it/s] 52%|█████▏    | 103/199 [00:52<00:36,  2.66it/s] 52%|█████▏    | 104/199 [00:53<00:30,  3.16it/s] 53%|█████▎    | 105/199 [00:53<00:25,  3.63it/s] 53%|█████▎    | 106/199 [00:55<01:06,  1.40it/s] 54%|█████▍    | 107/199 [00:55<00:50,  1.80it/s] 54%|█████▍    | 108/199 [00:57<01:33,  1.02s/it] 55%|█████▍    | 109/199 [00:57<01:09,  1.30it/s] 55%|█████▌    | 110/199 [00:57<00:52,  1.69it/s] 56%|█████▌    | 111/199 [00:57<00:41,  2.13it/s] 56%|█████▋    | 112/199 [00:58<00:33,  2.62it/s] 57%|█████▋    | 113/199 [00:58<00:27,  3.11it/s] 57%|█████▋    | 114/199 [00:58<00:29,  2.88it/s] 58%|█████▊    | 115/199 [00:58<00:24,  3.37it/s] 58%|█████▊    | 116/199 [01:01<01:13,  1.13it/s] 59%|█████▉    | 117/199 [01:01<00:55,  1.48it/s] 59%|█████▉    | 118/199 [01:01<00:42,  1.90it/s] 60%|█████▉    | 119/199 [01:01<00:33,  2.37it/s] 60%|██████    | 120/199 [01:01<00:27,  2.86it/s] 61%|██████    | 121/199 [01:01<00:23,  3.36it/s] 61%|██████▏   | 122/199 [01:03<00:53,  1.45it/s] 62%|██████▏   | 123/199 [01:03<00:40,  1.86it/s] 62%|██████▏   | 124/199 [01:04<00:42,  1.78it/s] 63%|██████▎   | 125/199 [01:04<00:33,  2.24it/s] 63%|██████▎   | 126/199 [01:04<00:26,  2.73it/s] 64%|██████▍   | 127/199 [01:04<00:22,  3.21it/s] 64%|██████▍   | 128/199 [01:05<00:19,  3.69it/s] 65%|██████▍   | 129/199 [01:05<00:17,  4.10it/s] 65%|██████▌   | 130/199 [01:06<00:28,  2.44it/s] 66%|██████▌   | 131/199 [01:06<00:23,  2.94it/s] 66%|██████▋   | 132/199 [01:07<00:38,  1.75it/s] 67%|██████▋   | 133/199 [01:07<00:30,  2.20it/s] 67%|██████▋   | 134/199 [01:07<00:24,  2.69it/s] 68%|██████▊   | 135/199 [01:07<00:20,  3.18it/s] 68%|██████▊   | 136/199 [01:08<00:17,  3.65it/s] 69%|██████▉   | 137/199 [01:08<00:15,  4.07it/s] 69%|██████▉   | 138/199 [01:11<01:01,  1.01s/it] 70%|██████▉   | 139/199 [01:11<00:45,  1.31it/s] 70%|███████   | 140/199 [01:11<00:34,  1.70it/s] 71%|███████   | 141/199 [01:11<00:26,  2.15it/s] 71%|███████▏  | 142/199 [01:11<00:21,  2.64it/s] 72%|███████▏  | 143/199 [01:11<00:17,  3.14it/s] 72%|███████▏  | 144/199 [01:12<00:15,  3.61it/s] 73%|███████▎  | 145/199 [01:12<00:13,  4.04it/s] 73%|███████▎  | 146/199 [01:14<00:47,  1.12it/s] 74%|███████▍  | 147/199 [01:14<00:35,  1.47it/s] 74%|███████▍  | 148/199 [01:15<00:27,  1.89it/s] 75%|███████▍  | 149/199 [01:15<00:21,  2.35it/s] 75%|███████▌  | 150/199 [01:15<00:17,  2.85it/s] 76%|███████▌  | 151/199 [01:15<00:14,  3.34it/s] 76%|███████▋  | 152/199 [01:15<00:12,  3.79it/s] 77%|███████▋  | 153/199 [01:15<00:10,  4.20it/s] 77%|███████▋  | 154/199 [01:18<00:47,  1.05s/it] 78%|███████▊  | 155/199 [01:19<00:34,  1.27it/s] 78%|███████▊  | 156/199 [01:19<00:26,  1.65it/s] 79%|███████▉  | 157/199 [01:19<00:20,  2.09it/s] 79%|███████▉  | 158/199 [01:19<00:15,  2.58it/s] 80%|███████▉  | 159/199 [01:19<00:13,  3.08it/s] 80%|████████  | 160/199 [01:19<00:11,  3.54it/s] 81%|████████  | 161/199 [01:20<00:09,  3.97it/s] 81%|████████▏ | 162/199 [01:21<00:20,  1.82it/s] 82%|████████▏ | 163/199 [01:21<00:15,  2.28it/s] 82%|████████▏ | 164/199 [01:21<00:12,  2.77it/s] 83%|████████▎ | 165/199 [01:21<00:10,  3.26it/s] 83%|████████▎ | 166/199 [01:22<00:08,  3.72it/s] 84%|████████▍ | 167/199 [01:22<00:07,  4.14it/s] 84%|████████▍ | 168/199 [01:22<00:06,  4.48it/s] 85%|████████▍ | 169/199 [01:22<00:06,  4.75it/s] 85%|████████▌ | 170/199 [01:23<00:10,  2.80it/s] 86%|████████▌ | 171/199 [01:23<00:08,  3.30it/s] 86%|████████▋ | 172/199 [01:24<00:13,  2.02it/s] 87%|████████▋ | 173/199 [01:24<00:10,  2.50it/s] 87%|████████▋ | 174/199 [01:24<00:08,  2.99it/s] 88%|████████▊ | 175/199 [01:25<00:06,  3.47it/s] 88%|████████▊ | 176/199 [01:25<00:05,  3.91it/s] 89%|████████▉ | 177/199 [01:25<00:05,  4.30it/s] 89%|████████▉ | 178/199 [01:26<00:09,  2.27it/s] 90%|████████▉ | 179/199 [01:26<00:07,  2.76it/s] 90%|█████████ | 180/199 [01:26<00:07,  2.51it/s] 91%|█████████ | 181/199 [01:27<00:05,  3.00it/s] 91%|█████████▏| 182/199 [01:27<00:04,  3.48it/s] 92%|█████████▏| 183/199 [01:27<00:05,  3.18it/s] 92%|█████████▏| 184/199 [01:27<00:04,  3.65it/s] 93%|█████████▎| 185/199 [01:28<00:03,  4.07it/s] 93%|█████████▎| 186/199 [01:29<00:09,  1.41it/s] 94%|█████████▍| 187/199 [01:30<00:06,  1.82it/s] 94%|█████████▍| 188/199 [01:30<00:04,  2.28it/s] 95%|█████████▍| 189/199 [01:30<00:03,  2.77it/s] 95%|█████████▌| 190/199 [01:30<00:02,  3.27it/s] 96%|█████████▌| 191/199 [01:31<00:02,  2.72it/s] 96%|█████████▋| 192/199 [01:31<00:02,  3.21it/s] 97%|█████████▋| 193/199 [01:31<00:01,  3.68it/s] 97%|█████████▋| 194/199 [01:32<00:03,  1.63it/s] 98%|█████████▊| 195/199 [01:33<00:01,  2.07it/s] 98%|█████████▊| 196/199 [01:33<00:01,  2.56it/s] 99%|█████████▉| 197/199 [01:33<00:00,  3.06it/s] 99%|█████████▉| 198/199 [01:35<00:00,  1.28it/s]100%|██████████| 199/199 [01:35<00:00,  1.71it/s]100%|██████████| 199/199 [01:35<00:00,  2.08it/s]
=> result
* total: 19,850
* correct: 6,435
* accuracy: 32.4%
* error: 67.6%
* macro_f1: 28.2%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat sun397 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/sun397/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/sun397/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_2.pkl
6352 3970 19850
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  397
# train_x  6,352
# val      3,970
# test     19,850
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/199 [00:00<?, ?it/s]  1%|          | 1/199 [00:05<19:34,  5.93s/it]  1%|          | 2/199 [00:06<08:22,  2.55s/it]  2%|▏         | 3/199 [00:06<04:47,  1.47s/it]  2%|▏         | 4/199 [00:06<03:06,  1.04it/s]  3%|▎         | 5/199 [00:06<02:11,  1.48it/s]  3%|▎         | 6/199 [00:06<01:37,  1.97it/s]  4%|▎         | 7/199 [00:07<01:16,  2.50it/s]  4%|▍         | 8/199 [00:07<01:02,  3.04it/s]  5%|▍         | 9/199 [00:08<02:09,  1.46it/s]  5%|▌         | 10/199 [00:08<01:39,  1.90it/s]  6%|▌         | 11/199 [00:11<03:30,  1.12s/it]  6%|▌         | 12/199 [00:11<02:35,  1.20it/s]  7%|▋         | 13/199 [00:11<01:58,  1.57it/s]  7%|▋         | 14/199 [00:11<01:32,  2.01it/s]  8%|▊         | 15/199 [00:12<01:13,  2.49it/s]  8%|▊         | 16/199 [00:12<01:01,  2.99it/s]  9%|▊         | 17/199 [00:12<00:52,  3.47it/s]  9%|▉         | 18/199 [00:12<00:46,  3.92it/s] 10%|▉         | 19/199 [00:14<01:52,  1.60it/s] 10%|█         | 20/199 [00:14<01:27,  2.04it/s] 11%|█         | 21/199 [00:14<01:10,  2.52it/s] 11%|█         | 22/199 [00:14<00:58,  3.02it/s] 12%|█▏        | 23/199 [00:14<00:50,  3.50it/s] 12%|█▏        | 24/199 [00:14<00:44,  3.94it/s] 13%|█▎        | 25/199 [00:15<00:40,  4.32it/s] 13%|█▎        | 26/199 [00:15<00:37,  4.64it/s] 14%|█▎        | 27/199 [00:17<02:38,  1.08it/s] 14%|█▍        | 28/199 [00:18<01:59,  1.43it/s] 15%|█▍        | 29/199 [00:18<01:32,  1.84it/s] 15%|█▌        | 30/199 [00:18<01:13,  2.30it/s] 16%|█▌        | 31/199 [00:18<01:00,  2.79it/s] 16%|█▌        | 32/199 [00:18<00:50,  3.29it/s] 17%|█▋        | 33/199 [00:18<00:44,  3.75it/s] 17%|█▋        | 34/199 [00:19<00:39,  4.15it/s] 18%|█▊        | 35/199 [00:20<01:50,  1.48it/s] 18%|█▊        | 36/199 [00:20<01:25,  1.90it/s] 19%|█▊        | 37/199 [00:21<01:08,  2.37it/s] 19%|█▉        | 38/199 [00:21<00:56,  2.87it/s] 20%|█▉        | 39/199 [00:21<00:47,  3.36it/s] 20%|██        | 40/199 [00:21<00:41,  3.82it/s] 21%|██        | 41/199 [00:21<00:37,  4.22it/s] 21%|██        | 42/199 [00:22<00:34,  4.56it/s] 22%|██▏       | 43/199 [00:23<01:53,  1.37it/s] 22%|██▏       | 44/199 [00:24<01:27,  1.77it/s] 23%|██▎       | 45/199 [00:24<01:09,  2.23it/s] 23%|██▎       | 46/199 [00:24<00:56,  2.71it/s] 24%|██▎       | 47/199 [00:24<00:47,  3.21it/s] 24%|██▍       | 48/199 [00:24<00:41,  3.68it/s] 25%|██▍       | 49/199 [00:25<00:36,  4.10it/s] 25%|██▌       | 50/199 [00:25<00:33,  4.45it/s] 26%|██▌       | 51/199 [00:27<02:04,  1.19it/s] 26%|██▌       | 52/199 [00:27<01:34,  1.55it/s] 27%|██▋       | 53/199 [00:27<01:13,  1.98it/s] 27%|██▋       | 54/199 [00:28<00:58,  2.46it/s] 28%|██▊       | 55/199 [00:28<00:48,  2.96it/s] 28%|██▊       | 56/199 [00:28<00:41,  3.44it/s] 29%|██▊       | 57/199 [00:28<00:36,  3.89it/s] 29%|██▉       | 58/199 [00:28<00:32,  4.27it/s] 30%|██▉       | 59/199 [00:29<01:11,  1.96it/s] 30%|███       | 60/199 [00:30<01:20,  1.72it/s] 31%|███       | 61/199 [00:30<01:03,  2.17it/s] 31%|███       | 62/199 [00:31<00:51,  2.66it/s] 32%|███▏      | 63/199 [00:31<00:43,  3.15it/s] 32%|███▏      | 64/199 [00:31<00:37,  3.62it/s] 33%|███▎      | 65/199 [00:31<00:33,  4.05it/s] 33%|███▎      | 66/199 [00:31<00:30,  4.40it/s] 34%|███▎      | 67/199 [00:32<00:56,  2.32it/s] 34%|███▍      | 68/199 [00:34<02:09,  1.01it/s] 35%|███▍      | 69/199 [00:35<01:36,  1.34it/s] 35%|███▌      | 70/199 [00:35<01:14,  1.74it/s] 36%|███▌      | 71/199 [00:35<00:58,  2.19it/s] 36%|███▌      | 72/199 [00:35<00:47,  2.68it/s] 37%|███▋      | 73/199 [00:35<00:39,  3.17it/s] 37%|███▋      | 74/199 [00:36<00:34,  3.64it/s] 38%|███▊      | 75/199 [00:36<00:58,  2.14it/s] 38%|███▊      | 76/199 [00:37<00:46,  2.62it/s] 39%|███▊      | 77/199 [00:37<00:39,  3.11it/s] 39%|███▉      | 78/199 [00:37<00:33,  3.58it/s] 40%|███▉      | 79/199 [00:37<00:29,  4.01it/s] 40%|████      | 80/199 [00:37<00:27,  4.37it/s] 41%|████      | 81/199 [00:38<00:25,  4.67it/s] 41%|████      | 82/199 [00:38<00:23,  4.91it/s] 42%|████▏     | 83/199 [00:40<01:45,  1.10it/s] 42%|████▏     | 84/199 [00:40<01:19,  1.45it/s] 43%|████▎     | 85/199 [00:41<01:01,  1.86it/s] 43%|████▎     | 86/199 [00:41<00:48,  2.33it/s] 44%|████▎     | 87/199 [00:41<00:39,  2.82it/s] 44%|████▍     | 88/199 [00:41<00:33,  3.31it/s] 45%|████▍     | 89/199 [00:41<00:29,  3.76it/s] 45%|████▌     | 90/199 [00:43<01:05,  1.65it/s] 46%|████▌     | 91/199 [00:43<00:51,  2.09it/s] 46%|████▌     | 92/199 [00:44<01:15,  1.42it/s] 47%|████▋     | 93/199 [00:44<00:58,  1.83it/s] 47%|████▋     | 94/199 [00:44<00:45,  2.29it/s] 48%|████▊     | 95/199 [00:45<00:37,  2.78it/s] 48%|████▊     | 96/199 [00:45<00:31,  3.28it/s] 49%|████▊     | 97/199 [00:45<00:27,  3.74it/s] 49%|████▉     | 98/199 [00:45<00:24,  4.11it/s] 50%|████▉     | 99/199 [00:45<00:22,  4.46it/s] 50%|█████     | 100/199 [00:49<01:51,  1.12s/it] 51%|█████     | 101/199 [00:49<01:22,  1.19it/s] 51%|█████▏    | 102/199 [00:49<01:02,  1.56it/s] 52%|█████▏    | 103/199 [00:49<00:48,  1.99it/s] 52%|█████▏    | 104/199 [00:49<00:38,  2.46it/s] 53%|█████▎    | 105/199 [00:50<00:31,  2.96it/s] 53%|█████▎    | 106/199 [00:50<00:27,  3.44it/s] 54%|█████▍    | 107/199 [00:50<00:23,  3.88it/s] 54%|█████▍    | 108/199 [00:53<01:34,  1.04s/it] 55%|█████▍    | 109/199 [00:53<01:10,  1.28it/s] 55%|█████▌    | 110/199 [00:53<00:53,  1.66it/s] 56%|█████▌    | 111/199 [00:53<00:41,  2.10it/s] 56%|█████▋    | 112/199 [00:53<00:33,  2.58it/s] 57%|█████▋    | 113/199 [00:54<00:27,  3.08it/s] 57%|█████▋    | 114/199 [00:54<00:23,  3.55it/s] 58%|█████▊    | 115/199 [00:54<00:21,  3.98it/s] 58%|█████▊    | 116/199 [00:56<01:08,  1.21it/s] 59%|█████▉    | 117/199 [00:56<00:51,  1.58it/s] 59%|█████▉    | 118/199 [00:57<00:40,  2.01it/s] 60%|█████▉    | 119/199 [00:57<00:32,  2.49it/s] 60%|██████    | 120/199 [00:57<00:26,  2.98it/s] 61%|██████    | 121/199 [00:57<00:22,  3.46it/s] 61%|██████▏   | 122/199 [00:57<00:19,  3.90it/s] 62%|██████▏   | 123/199 [00:57<00:17,  4.28it/s] 62%|██████▏   | 124/199 [00:59<00:53,  1.40it/s] 63%|██████▎   | 125/199 [00:59<00:40,  1.81it/s] 63%|██████▎   | 126/199 [01:00<00:32,  2.27it/s] 64%|██████▍   | 127/199 [01:00<00:26,  2.75it/s] 64%|██████▍   | 128/199 [01:00<00:21,  3.24it/s] 65%|██████▍   | 129/199 [01:00<00:18,  3.71it/s] 65%|██████▌   | 130/199 [01:00<00:16,  4.12it/s] 66%|██████▌   | 131/199 [01:01<00:15,  4.47it/s] 66%|██████▋   | 132/199 [01:02<00:34,  1.93it/s] 67%|██████▋   | 133/199 [01:02<00:27,  2.40it/s] 67%|██████▋   | 134/199 [01:02<00:22,  2.90it/s] 68%|██████▊   | 135/199 [01:02<00:18,  3.38it/s] 68%|██████▊   | 136/199 [01:02<00:16,  3.83it/s] 69%|██████▉   | 137/199 [01:03<00:14,  4.22it/s] 69%|██████▉   | 138/199 [01:04<00:26,  2.33it/s] 70%|██████▉   | 139/199 [01:04<00:21,  2.82it/s] 70%|███████   | 140/199 [01:05<00:41,  1.43it/s] 71%|███████   | 141/199 [01:05<00:31,  1.84it/s] 71%|███████▏  | 142/199 [01:06<00:24,  2.30it/s] 72%|███████▏  | 143/199 [01:06<00:20,  2.79it/s] 72%|███████▏  | 144/199 [01:06<00:16,  3.28it/s] 73%|███████▎  | 145/199 [01:06<00:14,  3.74it/s] 73%|███████▎  | 146/199 [01:07<00:24,  2.20it/s] 74%|███████▍  | 147/199 [01:07<00:19,  2.68it/s] 74%|███████▍  | 148/199 [01:07<00:16,  3.17it/s] 75%|███████▍  | 149/199 [01:08<00:13,  3.64it/s] 75%|███████▌  | 150/199 [01:08<00:12,  4.06it/s] 76%|███████▌  | 151/199 [01:08<00:10,  4.42it/s] 76%|███████▋  | 152/199 [01:08<00:09,  4.71it/s] 77%|███████▋  | 153/199 [01:08<00:09,  4.94it/s] 77%|███████▋  | 154/199 [01:11<00:45,  1.01s/it] 78%|███████▊  | 155/199 [01:11<00:33,  1.31it/s] 78%|███████▊  | 156/199 [01:12<00:25,  1.67it/s] 79%|███████▉  | 157/199 [01:12<00:19,  2.12it/s] 79%|███████▉  | 158/199 [01:12<00:15,  2.60it/s] 80%|███████▉  | 159/199 [01:12<00:12,  3.10it/s] 80%|████████  | 160/199 [01:12<00:10,  3.57it/s] 81%|████████  | 161/199 [01:12<00:09,  4.00it/s] 81%|████████▏ | 162/199 [01:13<00:16,  2.21it/s] 82%|████████▏ | 163/199 [01:14<00:13,  2.69it/s] 82%|████████▏ | 164/199 [01:14<00:10,  3.18it/s] 83%|████████▎ | 165/199 [01:14<00:09,  3.65it/s] 83%|████████▎ | 166/199 [01:14<00:08,  4.07it/s] 84%|████████▍ | 167/199 [01:14<00:07,  4.43it/s] 84%|████████▍ | 168/199 [01:14<00:06,  4.72it/s] 85%|████████▍ | 169/199 [01:15<00:06,  4.94it/s] 85%|████████▌ | 170/199 [01:15<00:08,  3.53it/s] 86%|████████▌ | 171/199 [01:15<00:07,  3.97it/s] 86%|████████▋ | 172/199 [01:17<00:18,  1.44it/s] 87%|████████▋ | 173/199 [01:17<00:14,  1.85it/s] 87%|████████▋ | 174/199 [01:17<00:10,  2.31it/s] 88%|████████▊ | 175/199 [01:18<00:08,  2.80it/s] 88%|████████▊ | 176/199 [01:18<00:06,  3.29it/s] 89%|████████▉ | 177/199 [01:18<00:05,  3.75it/s] 89%|████████▉ | 178/199 [01:18<00:05,  4.16it/s] 90%|████████▉ | 179/199 [01:18<00:04,  4.50it/s] 90%|█████████ | 180/199 [01:19<00:07,  2.58it/s] 91%|█████████ | 181/199 [01:19<00:05,  3.08it/s] 91%|█████████▏| 182/199 [01:20<00:08,  1.91it/s] 92%|█████████▏| 183/199 [01:20<00:06,  2.38it/s] 92%|█████████▏| 184/199 [01:21<00:05,  2.87it/s] 93%|█████████▎| 185/199 [01:21<00:04,  3.35it/s] 93%|█████████▎| 186/199 [01:21<00:03,  3.81it/s] 94%|█████████▍| 187/199 [01:21<00:02,  4.20it/s] 94%|█████████▍| 188/199 [01:21<00:02,  4.53it/s] 95%|█████████▍| 189/199 [01:21<00:02,  4.80it/s] 95%|█████████▌| 190/199 [01:24<00:07,  1.16it/s] 96%|█████████▌| 191/199 [01:24<00:05,  1.53it/s] 96%|█████████▋| 192/199 [01:24<00:03,  1.95it/s] 97%|█████████▋| 193/199 [01:24<00:02,  2.43it/s] 97%|█████████▋| 194/199 [01:25<00:01,  2.93it/s] 98%|█████████▊| 195/199 [01:25<00:01,  3.43it/s] 98%|█████████▊| 196/199 [01:25<00:00,  3.88it/s] 99%|█████████▉| 197/199 [01:25<00:00,  4.28it/s] 99%|█████████▉| 198/199 [01:28<00:00,  1.10it/s]100%|██████████| 199/199 [01:28<00:00,  1.48it/s]100%|██████████| 199/199 [01:28<00:00,  2.25it/s]
=> result
* total: 19,850
* correct: 6,878
* accuracy: 34.6%
* error: 65.4%
* macro_f1: 30.2%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat sun397 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/sun397/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/sun397/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_3.pkl
6352 3970 19850
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  397
# train_x  6,352
# val      3,970
# test     19,850
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/199 [00:00<?, ?it/s]  1%|          | 1/199 [00:05<19:47,  6.00s/it]  1%|          | 2/199 [00:06<08:27,  2.58s/it]  2%|▏         | 3/199 [00:06<04:50,  1.48s/it]  2%|▏         | 4/199 [00:06<03:08,  1.03it/s]  3%|▎         | 5/199 [00:06<02:12,  1.46it/s]  3%|▎         | 6/199 [00:06<01:38,  1.95it/s]  4%|▎         | 7/199 [00:07<01:17,  2.48it/s]  4%|▍         | 8/199 [00:07<01:03,  3.02it/s]  5%|▍         | 9/199 [00:08<01:50,  1.72it/s]  5%|▌         | 10/199 [00:09<02:08,  1.47it/s]  6%|▌         | 11/199 [00:11<03:24,  1.09s/it]  6%|▌         | 12/199 [00:11<02:31,  1.23it/s]  7%|▋         | 13/199 [00:11<01:55,  1.61it/s]  7%|▋         | 14/199 [00:11<01:29,  2.06it/s]  8%|▊         | 15/199 [00:12<01:12,  2.54it/s]  8%|▊         | 16/199 [00:12<01:00,  3.04it/s]  9%|▊         | 17/199 [00:12<00:51,  3.52it/s]  9%|▉         | 18/199 [00:12<01:05,  2.77it/s] 10%|▉         | 19/199 [00:14<01:59,  1.50it/s] 10%|█         | 20/199 [00:14<01:32,  1.93it/s] 11%|█         | 21/199 [00:14<01:14,  2.40it/s] 11%|█         | 22/199 [00:14<01:01,  2.89it/s] 12%|█▏        | 23/199 [00:15<00:52,  3.38it/s] 12%|█▏        | 24/199 [00:15<00:45,  3.83it/s] 13%|█▎        | 25/199 [00:15<00:52,  3.31it/s] 13%|█▎        | 26/199 [00:16<01:11,  2.43it/s] 14%|█▎        | 27/199 [00:18<02:41,  1.07it/s] 14%|█▍        | 28/199 [00:18<02:01,  1.41it/s] 15%|█▍        | 29/199 [00:18<01:33,  1.81it/s] 15%|█▌        | 30/199 [00:18<01:14,  2.27it/s] 16%|█▌        | 31/199 [00:19<01:00,  2.77it/s] 16%|█▌        | 32/199 [00:19<00:51,  3.26it/s] 17%|█▋        | 33/199 [00:19<00:44,  3.72it/s] 17%|█▋        | 34/199 [00:19<00:39,  4.13it/s] 18%|█▊        | 35/199 [00:21<02:00,  1.36it/s] 18%|█▊        | 36/199 [00:21<01:32,  1.76it/s] 19%|█▊        | 37/199 [00:21<01:13,  2.22it/s] 19%|█▉        | 38/199 [00:22<00:59,  2.71it/s] 20%|█▉        | 39/199 [00:22<00:49,  3.20it/s] 20%|██        | 40/199 [00:22<00:43,  3.67it/s] 21%|██        | 41/199 [00:22<00:38,  4.09it/s] 21%|██        | 42/199 [00:22<00:35,  4.45it/s] 22%|██▏       | 43/199 [00:24<01:49,  1.42it/s] 22%|██▏       | 44/199 [00:24<01:24,  1.83it/s] 23%|██▎       | 45/199 [00:24<01:07,  2.29it/s] 23%|██▎       | 46/199 [00:25<00:54,  2.78it/s] 24%|██▎       | 47/199 [00:25<00:46,  3.27it/s] 24%|██▍       | 48/199 [00:25<00:40,  3.74it/s] 25%|██▍       | 49/199 [00:25<00:36,  4.15it/s] 25%|██▌       | 50/199 [00:25<00:33,  4.49it/s] 26%|██▌       | 51/199 [00:28<02:12,  1.11it/s] 26%|██▌       | 52/199 [00:28<01:40,  1.46it/s] 27%|██▋       | 53/199 [00:28<01:17,  1.88it/s] 27%|██▋       | 54/199 [00:28<01:01,  2.35it/s] 28%|██▊       | 55/199 [00:29<00:50,  2.84it/s] 28%|██▊       | 56/199 [00:29<00:42,  3.34it/s] 29%|██▊       | 57/199 [00:29<00:37,  3.79it/s] 29%|██▉       | 58/199 [00:30<01:05,  2.14it/s] 30%|██▉       | 59/199 [00:31<01:13,  1.90it/s] 30%|███       | 60/199 [00:31<01:21,  1.71it/s] 31%|███       | 61/199 [00:31<01:03,  2.16it/s] 31%|███       | 62/199 [00:32<00:51,  2.65it/s] 32%|███▏      | 63/199 [00:32<00:43,  3.15it/s] 32%|███▏      | 64/199 [00:32<00:37,  3.63it/s] 33%|███▎      | 65/199 [00:32<00:33,  4.05it/s] 33%|███▎      | 66/199 [00:34<01:30,  1.46it/s] 34%|███▎      | 67/199 [00:34<01:10,  1.88it/s] 34%|███▍      | 68/199 [00:35<01:45,  1.24it/s] 35%|███▍      | 69/199 [00:36<01:20,  1.62it/s] 35%|███▌      | 70/199 [00:36<01:02,  2.06it/s] 36%|███▌      | 71/199 [00:36<00:50,  2.55it/s] 36%|███▌      | 72/199 [00:36<00:41,  3.04it/s] 37%|███▋      | 73/199 [00:36<00:35,  3.52it/s] 37%|███▋      | 74/199 [00:38<01:16,  1.64it/s] 38%|███▊      | 75/199 [00:38<01:17,  1.59it/s] 38%|███▊      | 76/199 [00:39<01:00,  2.03it/s] 39%|███▊      | 77/199 [00:39<00:48,  2.51it/s] 39%|███▉      | 78/199 [00:39<00:40,  3.00it/s] 40%|███▉      | 79/199 [00:39<00:34,  3.48it/s] 40%|████      | 80/199 [00:39<00:30,  3.92it/s] 41%|████      | 81/199 [00:39<00:27,  4.30it/s] 41%|████      | 82/199 [00:41<01:26,  1.35it/s] 42%|████▏     | 83/199 [00:42<01:23,  1.39it/s] 42%|████▏     | 84/199 [00:42<01:03,  1.80it/s] 43%|████▎     | 85/199 [00:42<00:50,  2.26it/s] 43%|████▎     | 86/199 [00:43<00:41,  2.74it/s] 44%|████▎     | 87/199 [00:43<00:34,  3.23it/s] 44%|████▍     | 88/199 [00:43<00:30,  3.70it/s] 45%|████▍     | 89/199 [00:43<00:26,  4.12it/s] 45%|████▌     | 90/199 [00:47<02:21,  1.30s/it] 46%|████▌     | 91/199 [00:47<01:43,  1.04it/s] 46%|████▌     | 92/199 [00:47<01:17,  1.38it/s] 47%|████▋     | 93/199 [00:47<00:59,  1.78it/s] 47%|████▋     | 94/199 [00:48<00:46,  2.23it/s] 48%|████▊     | 95/199 [00:48<00:38,  2.72it/s] 48%|████▊     | 96/199 [00:48<00:32,  3.22it/s] 49%|████▊     | 97/199 [00:48<00:27,  3.68it/s] 49%|████▉     | 98/199 [00:49<00:57,  1.76it/s] 50%|████▉     | 99/199 [00:50<00:45,  2.21it/s] 50%|█████     | 100/199 [00:50<00:41,  2.37it/s] 51%|█████     | 101/199 [00:50<00:34,  2.86it/s] 51%|█████▏    | 102/199 [00:50<00:28,  3.34it/s] 52%|█████▏    | 103/199 [00:50<00:25,  3.80it/s] 52%|█████▏    | 104/199 [00:51<00:22,  4.19it/s] 53%|█████▎    | 105/199 [00:51<00:20,  4.52it/s] 53%|█████▎    | 106/199 [00:53<01:24,  1.10it/s] 54%|█████▍    | 107/199 [00:54<01:03,  1.45it/s] 54%|█████▍    | 108/199 [00:54<01:01,  1.49it/s] 55%|█████▍    | 109/199 [00:54<00:47,  1.91it/s] 55%|█████▌    | 110/199 [00:55<00:37,  2.37it/s] 56%|█████▌    | 111/199 [00:55<00:30,  2.87it/s] 56%|█████▋    | 112/199 [00:55<00:25,  3.36it/s] 57%|█████▋    | 113/199 [00:55<00:22,  3.81it/s] 57%|█████▋    | 114/199 [00:57<00:53,  1.59it/s] 58%|█████▊    | 115/199 [00:57<00:41,  2.02it/s] 58%|█████▊    | 116/199 [00:58<00:50,  1.63it/s] 59%|█████▉    | 117/199 [00:58<00:39,  2.07it/s] 59%|█████▉    | 118/199 [00:58<00:31,  2.55it/s] 60%|█████▉    | 119/199 [00:58<00:26,  3.04it/s] 60%|██████    | 120/199 [00:58<00:22,  3.52it/s] 61%|██████    | 121/199 [00:59<00:19,  3.95it/s] 61%|██████▏   | 122/199 [01:01<01:12,  1.06it/s] 62%|██████▏   | 123/199 [01:01<00:54,  1.40it/s] 62%|██████▏   | 124/199 [01:01<00:41,  1.81it/s] 63%|██████▎   | 125/199 [01:02<00:32,  2.27it/s] 63%|██████▎   | 126/199 [01:02<00:26,  2.76it/s] 64%|██████▍   | 127/199 [01:02<00:22,  3.25it/s] 64%|██████▍   | 128/199 [01:02<00:19,  3.70it/s] 65%|██████▍   | 129/199 [01:02<00:17,  4.11it/s] 65%|██████▌   | 130/199 [01:03<00:30,  2.27it/s] 66%|██████▌   | 131/199 [01:03<00:24,  2.74it/s] 66%|██████▋   | 132/199 [01:04<00:20,  3.23it/s] 67%|██████▋   | 133/199 [01:04<00:17,  3.69it/s] 67%|██████▋   | 134/199 [01:04<00:15,  4.10it/s] 68%|██████▊   | 135/199 [01:04<00:14,  4.44it/s] 68%|██████▊   | 136/199 [01:04<00:13,  4.72it/s] 69%|██████▉   | 137/199 [01:05<00:12,  4.94it/s] 69%|██████▉   | 138/199 [01:08<01:11,  1.17s/it] 70%|██████▉   | 139/199 [01:08<00:52,  1.15it/s] 70%|███████   | 140/199 [01:08<00:39,  1.51it/s] 71%|███████   | 141/199 [01:08<00:29,  1.93it/s] 71%|███████▏  | 142/199 [01:09<00:23,  2.41it/s] 72%|███████▏  | 143/199 [01:09<00:19,  2.90it/s] 72%|███████▏  | 144/199 [01:09<00:16,  3.38it/s] 73%|███████▎  | 145/199 [01:09<00:14,  3.83it/s] 73%|███████▎  | 146/199 [01:11<00:39,  1.33it/s] 74%|███████▍  | 147/199 [01:11<00:30,  1.72it/s] 74%|███████▍  | 148/199 [01:11<00:23,  2.18it/s] 75%|███████▍  | 149/199 [01:12<00:18,  2.66it/s] 75%|███████▌  | 150/199 [01:12<00:15,  3.16it/s] 76%|███████▌  | 151/199 [01:12<00:13,  3.63it/s] 76%|███████▋  | 152/199 [01:12<00:11,  4.05it/s] 77%|███████▋  | 153/199 [01:12<00:10,  4.41it/s] 77%|███████▋  | 154/199 [01:15<00:41,  1.10it/s] 78%|███████▊  | 155/199 [01:15<00:30,  1.44it/s] 78%|███████▊  | 156/199 [01:15<00:23,  1.86it/s] 79%|███████▉  | 157/199 [01:15<00:18,  2.32it/s] 79%|███████▉  | 158/199 [01:16<00:14,  2.80it/s] 80%|███████▉  | 159/199 [01:16<00:12,  3.29it/s] 80%|████████  | 160/199 [01:16<00:10,  3.75it/s] 81%|████████  | 161/199 [01:16<00:09,  4.15it/s] 81%|████████▏ | 162/199 [01:17<00:14,  2.58it/s] 82%|████████▏ | 163/199 [01:17<00:11,  3.07it/s] 82%|████████▏ | 164/199 [01:17<00:09,  3.54it/s] 83%|████████▎ | 165/199 [01:17<00:08,  3.97it/s] 83%|████████▎ | 166/199 [01:18<00:07,  4.35it/s] 84%|████████▍ | 167/199 [01:18<00:06,  4.66it/s] 84%|████████▍ | 168/199 [01:18<00:06,  4.89it/s] 85%|████████▍ | 169/199 [01:18<00:05,  5.05it/s] 85%|████████▌ | 170/199 [01:18<00:07,  3.94it/s] 86%|████████▌ | 171/199 [01:19<00:06,  4.32it/s] 86%|████████▋ | 172/199 [01:19<00:05,  4.62it/s] 87%|████████▋ | 173/199 [01:19<00:05,  4.88it/s] 87%|████████▋ | 174/199 [01:19<00:04,  5.06it/s] 88%|████████▊ | 175/199 [01:19<00:04,  5.20it/s] 88%|████████▊ | 176/199 [01:20<00:06,  3.31it/s] 89%|████████▉ | 177/199 [01:20<00:05,  3.77it/s] 89%|████████▉ | 178/199 [01:21<00:09,  2.28it/s] 90%|████████▉ | 179/199 [01:21<00:09,  2.17it/s] 90%|█████████ | 180/199 [01:22<00:07,  2.65it/s] 91%|█████████ | 181/199 [01:22<00:05,  3.14it/s] 91%|█████████▏| 182/199 [01:22<00:04,  3.61it/s] 92%|█████████▏| 183/199 [01:23<00:05,  2.83it/s] 92%|█████████▏| 184/199 [01:23<00:04,  3.32it/s] 93%|█████████▎| 185/199 [01:23<00:03,  3.77it/s] 93%|█████████▎| 186/199 [01:24<00:06,  1.93it/s] 94%|█████████▍| 187/199 [01:25<00:06,  1.85it/s] 94%|█████████▍| 188/199 [01:25<00:04,  2.32it/s] 95%|█████████▍| 189/199 [01:25<00:03,  2.81it/s] 95%|█████████▌| 190/199 [01:25<00:02,  3.30it/s] 96%|█████████▌| 191/199 [01:26<00:02,  3.13it/s] 96%|█████████▋| 192/199 [01:26<00:01,  3.61it/s] 97%|█████████▋| 193/199 [01:26<00:01,  4.04it/s] 97%|█████████▋| 194/199 [01:27<00:02,  2.49it/s] 98%|█████████▊| 195/199 [01:28<00:02,  1.72it/s] 98%|█████████▊| 196/199 [01:28<00:01,  2.17it/s] 99%|█████████▉| 197/199 [01:28<00:00,  2.66it/s] 99%|█████████▉| 198/199 [01:29<00:00,  2.12it/s]100%|██████████| 199/199 [01:29<00:00,  2.71it/s]100%|██████████| 199/199 [01:29<00:00,  2.23it/s]
=> result
* total: 19,850
* correct: 8,714
* accuracy: 43.9%
* error: 56.1%
* macro_f1: 39.6%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat dtd 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/dtd/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/dtd/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_1.pkl
752 1128 1692
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  47
# train_x  752
# val      1,128
# test     1,692
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:03<01:03,  3.97s/it] 12%|█▏        | 2/17 [00:04<00:25,  1.70s/it] 18%|█▊        | 3/17 [00:04<00:13,  1.03it/s] 24%|██▎       | 4/17 [00:04<00:08,  1.58it/s] 29%|██▉       | 5/17 [00:04<00:05,  2.26it/s] 35%|███▌      | 6/17 [00:04<00:03,  3.03it/s] 41%|████      | 7/17 [00:04<00:02,  3.88it/s] 47%|████▋     | 8/17 [00:04<00:01,  4.75it/s] 53%|█████▎    | 9/17 [00:04<00:01,  5.59it/s] 59%|█████▉    | 10/17 [00:04<00:01,  6.35it/s] 65%|██████▍   | 11/17 [00:05<00:00,  7.00it/s] 71%|███████   | 12/17 [00:05<00:00,  7.54it/s] 76%|███████▋  | 13/17 [00:05<00:00,  7.96it/s] 82%|████████▏ | 14/17 [00:05<00:00,  8.28it/s] 88%|████████▊ | 15/17 [00:05<00:00,  8.53it/s] 94%|█████████▍| 16/17 [00:05<00:00,  8.70it/s]100%|██████████| 17/17 [00:05<00:00,  9.00it/s]100%|██████████| 17/17 [00:05<00:00,  2.94it/s]
=> result
* total: 1,692
* correct: 386
* accuracy: 22.8%
* error: 77.2%
* macro_f1: 18.3%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat dtd 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/dtd/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/dtd/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_2.pkl
752 1128 1692
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  47
# train_x  752
# val      1,128
# test     1,692
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:03<00:58,  3.63s/it] 12%|█▏        | 2/17 [00:03<00:23,  1.56s/it] 18%|█▊        | 3/17 [00:03<00:12,  1.11it/s] 24%|██▎       | 4/17 [00:03<00:07,  1.70it/s] 29%|██▉       | 5/17 [00:04<00:04,  2.41it/s] 35%|███▌      | 6/17 [00:04<00:03,  3.22it/s] 41%|████      | 7/17 [00:04<00:02,  4.09it/s] 47%|████▋     | 8/17 [00:04<00:01,  4.97it/s] 53%|█████▎    | 9/17 [00:04<00:01,  5.81it/s] 59%|█████▉    | 10/17 [00:04<00:01,  6.55it/s] 65%|██████▍   | 11/17 [00:04<00:00,  7.18it/s] 71%|███████   | 12/17 [00:04<00:00,  7.68it/s] 76%|███████▋  | 13/17 [00:04<00:00,  8.08it/s] 82%|████████▏ | 14/17 [00:05<00:00,  8.38it/s] 88%|████████▊ | 15/17 [00:05<00:00,  8.61it/s] 94%|█████████▍| 16/17 [00:05<00:00,  8.79it/s]100%|██████████| 17/17 [00:05<00:00,  9.09it/s]100%|██████████| 17/17 [00:05<00:00,  3.12it/s]
=> result
* total: 1,692
* correct: 271
* accuracy: 16.0%
* error: 84.0%
* macro_f1: 12.7%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat dtd 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/dtd/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/dtd/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:DescribableTextures
Loading dataset: DescribableTextures
Reading split from /shared/s2/lab01/dataset/clip/dtd/split_zhou_DescribableTextures.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/dtd/split_fewshot_taesup/shot_16-seed_3.pkl
752 1128 1692
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  47
# train_x  752
# val      1,128
# test     1,692
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:03<00:57,  3.57s/it] 12%|█▏        | 2/17 [00:03<00:23,  1.54s/it] 18%|█▊        | 3/17 [00:03<00:12,  1.13it/s] 24%|██▎       | 4/17 [00:03<00:07,  1.73it/s] 29%|██▉       | 5/17 [00:04<00:04,  2.45it/s] 35%|███▌      | 6/17 [00:04<00:03,  3.26it/s] 41%|████      | 7/17 [00:04<00:02,  4.14it/s] 47%|████▋     | 8/17 [00:04<00:01,  5.02it/s] 53%|█████▎    | 9/17 [00:04<00:01,  5.85it/s] 59%|█████▉    | 10/17 [00:04<00:01,  6.59it/s] 65%|██████▍   | 11/17 [00:04<00:00,  7.21it/s] 71%|███████   | 12/17 [00:04<00:00,  7.71it/s] 76%|███████▋  | 13/17 [00:04<00:00,  8.11it/s] 82%|████████▏ | 14/17 [00:04<00:00,  8.40it/s] 88%|████████▊ | 15/17 [00:05<00:00,  8.63it/s] 94%|█████████▍| 16/17 [00:05<00:00,  8.81it/s]100%|██████████| 17/17 [00:05<00:00,  9.11it/s]100%|██████████| 17/17 [00:05<00:00,  3.16it/s]
=> result
* total: 1,692
* correct: 431
* accuracy: 25.5%
* error: 74.5%
* macro_f1: 19.7%
+ for dataset in imagenet caltech101 oxford_pets stanford_cars oxford_flowers food101 ucf101 sun397 dtd eurosat
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat eurosat 1 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/eurosat/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/eurosat/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_1.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed1/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:03<04:10,  3.13s/it]  2%|▏         | 2/81 [00:03<01:46,  1.35s/it]  4%|▎         | 3/81 [00:03<01:01,  1.28it/s]  5%|▍         | 4/81 [00:03<00:39,  1.94it/s]  6%|▌         | 5/81 [00:03<00:27,  2.72it/s]  7%|▋         | 6/81 [00:03<00:20,  3.59it/s]  9%|▊         | 7/81 [00:03<00:16,  4.51it/s] 10%|▉         | 8/81 [00:03<00:13,  5.42it/s] 11%|█         | 9/81 [00:03<00:11,  6.26it/s] 12%|█▏        | 10/81 [00:04<00:10,  7.00it/s] 14%|█▎        | 11/81 [00:04<00:09,  7.61it/s] 15%|█▍        | 12/81 [00:04<00:08,  8.10it/s] 16%|█▌        | 13/81 [00:04<00:08,  8.48it/s] 17%|█▋        | 14/81 [00:04<00:07,  8.77it/s] 19%|█▊        | 15/81 [00:04<00:07,  8.98it/s] 20%|█▉        | 16/81 [00:04<00:07,  9.14it/s] 21%|██        | 17/81 [00:04<00:06,  9.23it/s] 22%|██▏       | 18/81 [00:04<00:06,  9.33it/s] 23%|██▎       | 19/81 [00:05<00:06,  9.40it/s] 25%|██▍       | 20/81 [00:05<00:06,  9.44it/s] 26%|██▌       | 21/81 [00:05<00:06,  9.47it/s] 27%|██▋       | 22/81 [00:05<00:06,  9.50it/s] 28%|██▊       | 23/81 [00:05<00:06,  9.51it/s] 30%|██▉       | 24/81 [00:05<00:05,  9.52it/s] 31%|███       | 25/81 [00:05<00:05,  9.49it/s] 32%|███▏      | 26/81 [00:05<00:05,  9.52it/s] 33%|███▎      | 27/81 [00:05<00:05,  9.42it/s] 35%|███▍      | 28/81 [00:05<00:05,  9.46it/s] 36%|███▌      | 29/81 [00:06<00:05,  9.47it/s] 37%|███▋      | 30/81 [00:06<00:05,  9.50it/s] 38%|███▊      | 31/81 [00:06<00:05,  9.52it/s] 40%|███▉      | 32/81 [00:06<00:05,  9.50it/s] 41%|████      | 33/81 [00:06<00:05,  9.46it/s] 42%|████▏     | 34/81 [00:06<00:04,  9.49it/s] 43%|████▎     | 35/81 [00:06<00:04,  9.48it/s] 44%|████▍     | 36/81 [00:06<00:04,  9.50it/s] 46%|████▌     | 37/81 [00:06<00:04,  9.52it/s] 47%|████▋     | 38/81 [00:07<00:04,  9.54it/s] 48%|████▊     | 39/81 [00:07<00:04,  9.54it/s] 49%|████▉     | 40/81 [00:07<00:04,  9.54it/s] 51%|█████     | 41/81 [00:07<00:04,  9.54it/s] 52%|█████▏    | 42/81 [00:07<00:04,  9.55it/s] 53%|█████▎    | 43/81 [00:07<00:03,  9.54it/s] 54%|█████▍    | 44/81 [00:07<00:03,  9.53it/s] 56%|█████▌    | 45/81 [00:07<00:03,  9.51it/s] 57%|█████▋    | 46/81 [00:07<00:03,  9.51it/s] 58%|█████▊    | 47/81 [00:07<00:03,  9.49it/s] 59%|█████▉    | 48/81 [00:08<00:03,  9.48it/s] 60%|██████    | 49/81 [00:08<00:03,  9.50it/s] 62%|██████▏   | 50/81 [00:08<00:03,  9.51it/s] 63%|██████▎   | 51/81 [00:08<00:03,  9.49it/s] 64%|██████▍   | 52/81 [00:08<00:03,  9.49it/s] 65%|██████▌   | 53/81 [00:08<00:02,  9.51it/s] 67%|██████▋   | 54/81 [00:08<00:02,  9.51it/s] 68%|██████▊   | 55/81 [00:08<00:02,  9.50it/s] 69%|██████▉   | 56/81 [00:08<00:02,  9.49it/s] 70%|███████   | 57/81 [00:09<00:02,  9.50it/s] 72%|███████▏  | 58/81 [00:09<00:02,  9.50it/s] 73%|███████▎  | 59/81 [00:09<00:02,  9.50it/s] 74%|███████▍  | 60/81 [00:09<00:02,  9.51it/s] 75%|███████▌  | 61/81 [00:09<00:02,  9.51it/s] 77%|███████▋  | 62/81 [00:09<00:01,  9.51it/s] 78%|███████▊  | 63/81 [00:09<00:01,  9.52it/s] 79%|███████▉  | 64/81 [00:09<00:02,  7.25it/s] 80%|████████  | 65/81 [00:10<00:04,  3.73it/s] 81%|████████▏ | 66/81 [00:10<00:03,  4.52it/s] 83%|████████▎ | 67/81 [00:10<00:02,  5.36it/s] 84%|████████▍ | 68/81 [00:10<00:02,  6.18it/s] 85%|████████▌ | 69/81 [00:10<00:01,  6.90it/s] 86%|████████▋ | 70/81 [00:11<00:02,  5.16it/s] 88%|████████▊ | 71/81 [00:11<00:01,  5.99it/s] 89%|████████▉ | 72/81 [00:11<00:02,  3.23it/s] 90%|█████████ | 73/81 [00:12<00:03,  2.56it/s] 91%|█████████▏| 74/81 [00:12<00:02,  3.06it/s] 93%|█████████▎| 75/81 [00:12<00:01,  3.85it/s] 94%|█████████▍| 76/81 [00:12<00:01,  4.69it/s] 95%|█████████▌| 77/81 [00:12<00:00,  5.53it/s] 96%|█████████▋| 78/81 [00:13<00:00,  5.32it/s] 98%|█████████▊| 79/81 [00:13<00:00,  6.14it/s] 99%|█████████▉| 80/81 [00:13<00:00,  3.17it/s]100%|██████████| 81/81 [00:14<00:00,  3.93it/s]100%|██████████| 81/81 [00:14<00:00,  5.72it/s]
=> result
* total: 8,100
* correct: 6,913
* accuracy: 85.3%
* error: 14.7%
* macro_f1: 85.1%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat eurosat 2 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/eurosat/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/eurosat/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_2.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed2/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:03<04:00,  3.00s/it]  2%|▏         | 2/81 [00:03<01:42,  1.30s/it]  4%|▎         | 3/81 [00:03<00:58,  1.33it/s]  5%|▍         | 4/81 [00:03<00:38,  2.01it/s]  6%|▌         | 5/81 [00:03<00:27,  2.81it/s]  7%|▋         | 6/81 [00:03<00:20,  3.70it/s]  9%|▊         | 7/81 [00:03<00:15,  4.63it/s] 10%|▉         | 8/81 [00:03<00:13,  5.54it/s] 11%|█         | 9/81 [00:03<00:11,  6.39it/s] 12%|█▏        | 10/81 [00:03<00:09,  7.11it/s] 14%|█▎        | 11/81 [00:04<00:09,  7.72it/s] 15%|█▍        | 12/81 [00:04<00:08,  8.20it/s] 16%|█▌        | 13/81 [00:04<00:07,  8.56it/s] 17%|█▋        | 14/81 [00:04<00:07,  8.85it/s] 19%|█▊        | 15/81 [00:04<00:07,  9.03it/s] 20%|█▉        | 16/81 [00:04<00:07,  9.20it/s] 21%|██        | 17/81 [00:04<00:06,  9.30it/s] 22%|██▏       | 18/81 [00:04<00:06,  9.38it/s] 23%|██▎       | 19/81 [00:04<00:06,  9.41it/s] 25%|██▍       | 20/81 [00:04<00:06,  9.44it/s] 26%|██▌       | 21/81 [00:05<00:06,  9.46it/s] 27%|██▋       | 22/81 [00:05<00:06,  9.38it/s] 28%|██▊       | 23/81 [00:05<00:06,  9.42it/s] 30%|██▉       | 24/81 [00:05<00:06,  9.46it/s] 31%|███       | 25/81 [00:05<00:05,  9.50it/s] 32%|███▏      | 26/81 [00:05<00:05,  9.51it/s] 33%|███▎      | 27/81 [00:05<00:05,  9.52it/s] 35%|███▍      | 28/81 [00:05<00:05,  9.51it/s] 36%|███▌      | 29/81 [00:05<00:05,  9.52it/s] 37%|███▋      | 30/81 [00:06<00:05,  9.52it/s] 38%|███▊      | 31/81 [00:06<00:05,  9.52it/s] 40%|███▉      | 32/81 [00:06<00:05,  9.54it/s] 41%|████      | 33/81 [00:06<00:05,  9.55it/s] 42%|████▏     | 34/81 [00:06<00:04,  9.54it/s] 43%|████▎     | 35/81 [00:06<00:04,  9.54it/s] 44%|████▍     | 36/81 [00:06<00:04,  9.52it/s] 46%|████▌     | 37/81 [00:06<00:04,  9.53it/s] 47%|████▋     | 38/81 [00:06<00:04,  9.53it/s] 48%|████▊     | 39/81 [00:06<00:04,  9.52it/s] 49%|████▉     | 40/81 [00:07<00:04,  9.55it/s] 51%|█████     | 41/81 [00:07<00:04,  9.55it/s] 52%|█████▏    | 42/81 [00:07<00:04,  9.54it/s] 53%|█████▎    | 43/81 [00:07<00:03,  9.52it/s] 54%|█████▍    | 44/81 [00:07<00:03,  9.52it/s] 56%|█████▌    | 45/81 [00:07<00:03,  9.53it/s] 57%|█████▋    | 46/81 [00:07<00:03,  9.52it/s] 58%|█████▊    | 47/81 [00:07<00:03,  9.52it/s] 59%|█████▉    | 48/81 [00:07<00:03,  9.55it/s] 60%|██████    | 49/81 [00:08<00:03,  9.55it/s] 62%|██████▏   | 50/81 [00:08<00:03,  9.53it/s] 63%|██████▎   | 51/81 [00:08<00:03,  9.53it/s] 64%|██████▍   | 52/81 [00:08<00:03,  9.49it/s] 65%|██████▌   | 53/81 [00:08<00:02,  9.49it/s] 67%|██████▋   | 54/81 [00:08<00:02,  9.50it/s] 68%|██████▊   | 55/81 [00:08<00:02,  9.48it/s] 69%|██████▉   | 56/81 [00:08<00:02,  9.51it/s] 70%|███████   | 57/81 [00:08<00:02,  9.48it/s] 72%|███████▏  | 58/81 [00:08<00:02,  9.47it/s] 73%|███████▎  | 59/81 [00:09<00:02,  9.49it/s] 74%|███████▍  | 60/81 [00:09<00:02,  9.50it/s] 75%|███████▌  | 61/81 [00:09<00:02,  9.51it/s] 77%|███████▋  | 62/81 [00:09<00:01,  9.51it/s] 78%|███████▊  | 63/81 [00:09<00:01,  9.50it/s] 79%|███████▉  | 64/81 [00:09<00:01,  9.54it/s] 80%|████████  | 65/81 [00:09<00:01,  9.53it/s] 81%|████████▏ | 66/81 [00:09<00:01,  9.53it/s] 83%|████████▎ | 67/81 [00:09<00:01,  9.55it/s] 84%|████████▍ | 68/81 [00:10<00:01,  9.57it/s] 85%|████████▌ | 69/81 [00:10<00:01,  9.58it/s] 86%|████████▋ | 70/81 [00:10<00:01,  9.59it/s] 88%|████████▊ | 71/81 [00:10<00:01,  9.60it/s] 89%|████████▉ | 72/81 [00:10<00:00,  9.61it/s] 90%|█████████ | 73/81 [00:10<00:00,  9.61it/s] 91%|█████████▏| 74/81 [00:10<00:00,  9.61it/s] 93%|█████████▎| 75/81 [00:10<00:00,  9.61it/s] 94%|█████████▍| 76/81 [00:10<00:00,  9.61it/s] 95%|█████████▌| 77/81 [00:10<00:00,  9.62it/s] 96%|█████████▋| 78/81 [00:11<00:00,  9.61it/s] 98%|█████████▊| 79/81 [00:11<00:00,  9.61it/s] 99%|█████████▉| 80/81 [00:11<00:00,  9.62it/s]100%|██████████| 81/81 [00:11<00:00,  9.61it/s]100%|██████████| 81/81 [00:11<00:00,  7.07it/s]
=> result
* total: 8,100
* correct: 6,788
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 83.6%
+ for seed in 1 2 3
+ sh scripts/coop/crossdataset_test.sh eurosat eurosat 3 0 vit_b16_ctxv1 16 200 CoOp
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/CoOp/vit_b16_ctxv1.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: True
head: 
load_epoch: 200
model_dir: output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/coop/crossdataset/test_target/source_eurosat/eurosat/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: CoOp
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 200
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/coop/crossdataset/test_target/source_eurosat/eurosat/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: a photo of a
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: CoOp
  RPO:
    CTX_INIT: 
    K1: 1
    K2: 1
    PREC: fp16
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:CoOp
Loading trainer: CoOp
requested:EuroSAT
Loading dataset: EuroSAT
Reading split from /shared/s2/lab01/dataset/clip/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/eurosat/split_fewshot_taesup/shot_16-seed_3.pkl
160 5400 8100
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      5,400
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Turning off gradients in both the image and the text encoder
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/coop/crossdataset/train_source/eurosat/shots_16/CoOp/vit_b16_ctxv1/seed3/prompt_learner/model.pth.tar-200" (epoch = 200)
Evaluate on the *test* set
  0%|          | 0/81 [00:00<?, ?it/s]  1%|          | 1/81 [00:02<03:52,  2.90s/it]  2%|▏         | 2/81 [00:03<01:39,  1.26s/it]  4%|▎         | 3/81 [00:03<00:57,  1.37it/s]  5%|▍         | 4/81 [00:03<00:37,  2.07it/s]  6%|▌         | 5/81 [00:03<00:26,  2.88it/s]  7%|▋         | 6/81 [00:03<00:19,  3.78it/s]  9%|▊         | 7/81 [00:03<00:15,  4.71it/s] 10%|▉         | 8/81 [00:03<00:12,  5.62it/s] 11%|█         | 9/81 [00:03<00:11,  6.45it/s] 12%|█▏        | 10/81 [00:03<00:09,  7.17it/s] 14%|█▎        | 11/81 [00:03<00:09,  7.75it/s] 15%|█▍        | 12/81 [00:04<00:08,  8.24it/s] 16%|█▌        | 13/81 [00:04<00:07,  8.61it/s] 17%|█▋        | 14/81 [00:04<00:07,  8.86it/s] 19%|█▊        | 15/81 [00:04<00:07,  9.06it/s] 20%|█▉        | 16/81 [00:04<00:07,  9.22it/s] 21%|██        | 17/81 [00:04<00:06,  9.32it/s] 22%|██▏       | 18/81 [00:04<00:06,  9.38it/s] 23%|██▎       | 19/81 [00:04<00:06,  9.42it/s] 25%|██▍       | 20/81 [00:04<00:06,  9.47it/s] 26%|██▌       | 21/81 [00:04<00:06,  9.50it/s] 27%|██▋       | 22/81 [00:05<00:06,  9.49it/s] 28%|██▊       | 23/81 [00:05<00:06,  9.50it/s] 30%|██▉       | 24/81 [00:05<00:05,  9.53it/s] 31%|███       | 25/81 [00:05<00:05,  9.53it/s] 32%|███▏      | 26/81 [00:05<00:05,  9.52it/s] 33%|███▎      | 27/81 [00:05<00:05,  9.52it/s] 35%|███▍      | 28/81 [00:05<00:05,  9.55it/s] 36%|███▌      | 29/81 [00:05<00:05,  9.55it/s] 37%|███▋      | 30/81 [00:05<00:05,  9.55it/s] 38%|███▊      | 31/81 [00:06<00:05,  9.55it/s] 40%|███▉      | 32/81 [00:06<00:05,  9.56it/s] 41%|████      | 33/81 [00:06<00:05,  9.56it/s] 42%|████▏     | 34/81 [00:06<00:04,  9.55it/s] 43%|████▎     | 35/81 [00:06<00:04,  9.54it/s] 44%|████▍     | 36/81 [00:06<00:04,  9.56it/s] 46%|████▌     | 37/81 [00:06<00:04,  9.54it/s] 47%|████▋     | 38/81 [00:06<00:04,  9.54it/s] 48%|████▊     | 39/81 [00:06<00:04,  9.53it/s] 49%|████▉     | 40/81 [00:06<00:04,  9.55it/s] 51%|█████     | 41/81 [00:07<00:04,  9.55it/s] 52%|█████▏    | 42/81 [00:07<00:04,  9.54it/s] 53%|█████▎    | 43/81 [00:07<00:03,  9.53it/s] 54%|█████▍    | 44/81 [00:07<00:03,  9.55it/s] 56%|█████▌    | 45/81 [00:07<00:03,  9.55it/s] 57%|█████▋    | 46/81 [00:07<00:03,  9.54it/s] 58%|█████▊    | 47/81 [00:07<00:03,  9.53it/s] 59%|█████▉    | 48/81 [00:07<00:03,  9.55it/s] 60%|██████    | 49/81 [00:07<00:03,  9.58it/s] 62%|██████▏   | 50/81 [00:08<00:03,  9.52it/s] 63%|██████▎   | 51/81 [00:08<00:03,  9.51it/s] 64%|██████▍   | 52/81 [00:08<00:03,  9.53it/s] 65%|██████▌   | 53/81 [00:08<00:02,  9.52it/s] 67%|██████▋   | 54/81 [00:08<00:02,  9.52it/s] 68%|██████▊   | 55/81 [00:08<00:02,  9.52it/s] 69%|██████▉   | 56/81 [00:08<00:02,  9.42it/s] 70%|███████   | 57/81 [00:08<00:02,  9.47it/s] 72%|███████▏  | 58/81 [00:08<00:02,  9.49it/s] 73%|███████▎  | 59/81 [00:08<00:02,  9.49it/s] 74%|███████▍  | 60/81 [00:09<00:02,  9.49it/s] 75%|███████▌  | 61/81 [00:09<00:02,  9.49it/s] 77%|███████▋  | 62/81 [00:09<00:02,  9.47it/s] 78%|███████▊  | 63/81 [00:09<00:01,  9.46it/s] 79%|███████▉  | 64/81 [00:09<00:01,  9.51it/s] 80%|████████  | 65/81 [00:09<00:01,  9.52it/s] 81%|████████▏ | 66/81 [00:09<00:01,  9.50it/s] 83%|████████▎ | 67/81 [00:09<00:01,  9.53it/s] 84%|████████▍ | 68/81 [00:09<00:01,  9.55it/s] 85%|████████▌ | 69/81 [00:10<00:01,  9.58it/s] 86%|████████▋ | 70/81 [00:10<00:01,  9.57it/s] 88%|████████▊ | 71/81 [00:10<00:01,  9.59it/s] 89%|████████▉ | 72/81 [00:10<00:00,  9.60it/s] 90%|█████████ | 73/81 [00:10<00:00,  9.60it/s] 91%|█████████▏| 74/81 [00:10<00:00,  9.62it/s] 93%|█████████▎| 75/81 [00:10<00:00,  9.61it/s] 94%|█████████▍| 76/81 [00:10<00:00,  9.61it/s] 95%|█████████▌| 77/81 [00:10<00:00,  9.61it/s] 96%|█████████▋| 78/81 [00:10<00:00,  9.58it/s] 98%|█████████▊| 79/81 [00:11<00:00,  9.58it/s] 99%|█████████▉| 80/81 [00:11<00:00,  9.60it/s]100%|██████████| 81/81 [00:11<00:00,  9.62it/s]100%|██████████| 81/81 [00:11<00:00,  7.13it/s]
=> result
* total: 8,100
* correct: 6,841
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 84.3%

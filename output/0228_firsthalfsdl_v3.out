set -e
set -x

eval "$(conda shell.bash hook)"
++ conda shell.bash hook
+ eval 'export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We're not allowing PS1 to be unbound. It must at least be set.
    # However, we're not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi
++ '[' -z x ']'

conda activate base
++ conda activate base
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate base
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate base
+++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate base
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(base) '
+++ PS1='(base) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
+++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
+++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda'
+++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda
+++ CONDA_PREFIX=/home/s2/mjoolee/anaconda
export CONDA_SHLVL='3'
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
export CONDA_DEFAULT_ENV='base'
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
export CONDA_PROMPT_MODIFIER='(base) '
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
export CONDA_PREFIX_2='/home/s2/mjoolee/anaconda/envs/dassl'
+++ export CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
+++ CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
+++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
+++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
+++ export _CE_M=
+++ _CE_M=
export _CE_CONDA=''
+++ export _CE_CONDA=
+++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
+++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
conda activate dassl
+ conda activate dassl
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate dassl
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate dassl
++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate dassl
+ ask_conda='PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
+ eval 'PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(dassl) '
++ PS1='(dassl) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda/envs/dassl'
++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
++ CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_SHLVL='4'
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
export CONDA_DEFAULT_ENV='dassl'
++ export CONDA_DEFAULT_ENV=dassl
++ CONDA_DEFAULT_ENV=dassl
export CONDA_PROMPT_MODIFIER='(dassl) '
++ export 'CONDA_PROMPT_MODIFIER=(dassl) '
++ CONDA_PROMPT_MODIFIER='(dassl) '
export CONDA_PREFIX_3='/home/s2/mjoolee/anaconda'
++ export CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
++ CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r

GPU=0
+ GPU=0
SHOT=16
+ SHOT=16

for dataset in caltech101 sun397 imagenet
#for dataset in caltech101 imagenet
do
    for seed in 1 2 3
    do
    sh scripts/rpo_prime/base2new_train_sdl.sh ${dataset} ${seed} ${GPU} main_tmp1_0.1sdl ${SHOT}
    #sh scripts/rpo_prime/base2new_test.sh ${dataset} ${seed} ${GPU} main_9_9 ${SHOT} base
    sh scripts/rpo_prime/base2new_test_sdl.sh ${dataset} ${seed} ${GPU} main_tmp1_0.1sdl ${SHOT} new
    done
done
+ for dataset in caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh caltech101 1 0 main_tmp1_0.1sdl 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
800 1036 1549
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      1,036
# test     1,549
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/200] time 0.248 (0.368) data 0.000 (0.057) loss 0.3689 (1.1539) lr 1.0000e-02 eta 0:36:40
epoch [1/30] batch [40/200] time 0.245 (0.308) data 0.000 (0.028) loss 2.7754 (1.1807) lr 1.0000e-02 eta 0:30:33
epoch [1/30] batch [60/200] time 0.248 (0.288) data 0.000 (0.019) loss 2.2090 (1.2431) lr 1.0000e-02 eta 0:28:28
epoch [1/30] batch [80/200] time 0.252 (0.279) data 0.000 (0.014) loss 0.1003 (1.1389) lr 1.0000e-02 eta 0:27:34
epoch [1/30] batch [100/200] time 0.244 (0.273) data 0.000 (0.011) loss -0.0529 (1.1247) lr 1.0000e-02 eta 0:26:50
epoch [1/30] batch [120/200] time 0.247 (0.268) data 0.000 (0.010) loss 1.7334 (1.1113) lr 1.0000e-02 eta 0:26:18
epoch [1/30] batch [140/200] time 0.244 (0.265) data 0.000 (0.008) loss 1.4795 (1.1089) lr 1.0000e-02 eta 0:25:54
epoch [1/30] batch [160/200] time 0.246 (0.263) data 0.000 (0.007) loss 1.6670 (1.1446) lr 1.0000e-02 eta 0:25:38
epoch [1/30] batch [180/200] time 0.243 (0.261) data 0.000 (0.006) loss 1.7754 (1.1382) lr 1.0000e-02 eta 0:25:20
epoch [1/30] batch [200/200] time 0.240 (0.259) data 0.000 (0.006) loss 0.4539 (1.1110) lr 9.9726e-03 eta 0:25:03
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:15,  1.57s/it] 18%|█▊        | 2/11 [00:01<00:06,  1.38it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.21it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.07it/s] 45%|████▌     | 5/11 [00:02<00:01,  3.90it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.67it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.33it/s] 73%|███████▎  | 8/11 [00:02<00:00,  5.88it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.32it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.66it/s]100%|██████████| 11/11 [00:02<00:00,  3.77it/s]=> result
* total: 1,036
* correct: 1,015
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 96.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/200] time 0.249 (0.285) data 0.000 (0.027) loss 2.1211 (1.2907) lr 9.9726e-03 eta 0:27:28
epoch [2/30] batch [40/200] time 0.246 (0.267) data 0.000 (0.014) loss 1.3467 (1.1023) lr 9.9726e-03 eta 0:25:35
epoch [2/30] batch [60/200] time 0.244 (0.260) data 0.000 (0.009) loss 1.2305 (1.1623) lr 9.9726e-03 eta 0:24:50
epoch [2/30] batch [80/200] time 0.244 (0.258) data 0.000 (0.007) loss 3.3633 (1.1305) lr 9.9726e-03 eta 0:24:33
epoch [2/30] batch [100/200] time 0.251 (0.256) data 0.000 (0.006) loss 2.0059 (1.0553) lr 9.9726e-03 eta 0:24:16
epoch [2/30] batch [120/200] time 0.248 (0.254) data 0.000 (0.005) loss 0.9619 (1.0190) lr 9.9726e-03 eta 0:24:05
epoch [2/30] batch [140/200] time 0.242 (0.253) data 0.000 (0.004) loss 2.5215 (0.9605) lr 9.9726e-03 eta 0:23:54
epoch [2/30] batch [160/200] time 0.248 (0.253) data 0.000 (0.004) loss 1.6445 (1.0121) lr 9.9726e-03 eta 0:23:44
epoch [2/30] batch [180/200] time 0.240 (0.252) data 0.000 (0.003) loss 0.0646 (0.9783) lr 9.9726e-03 eta 0:23:33
epoch [2/30] batch [200/200] time 0.239 (0.250) data 0.000 (0.003) loss 0.0308 (0.9379) lr 9.8907e-03 eta 0:23:21
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.38s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.55it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.43it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.31it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.15it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.90it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.53it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.04it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.41it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.72it/s]100%|██████████| 11/11 [00:02<00:00,  4.03it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 95.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/200] time 0.242 (0.277) data 0.000 (0.029) loss 1.1963 (0.8379) lr 9.8907e-03 eta 0:25:44
epoch [3/30] batch [40/200] time 0.245 (0.263) data 0.000 (0.015) loss 0.0907 (0.8511) lr 9.8907e-03 eta 0:24:21
epoch [3/30] batch [60/200] time 0.242 (0.257) data 0.000 (0.010) loss 1.8369 (0.9276) lr 9.8907e-03 eta 0:23:45
epoch [3/30] batch [80/200] time 0.247 (0.254) data 0.000 (0.008) loss -0.0466 (0.8443) lr 9.8907e-03 eta 0:23:22
epoch [3/30] batch [100/200] time 0.244 (0.253) data 0.000 (0.006) loss 1.6270 (0.9600) lr 9.8907e-03 eta 0:23:10
epoch [3/30] batch [120/200] time 0.244 (0.251) data 0.000 (0.005) loss 0.9810 (1.0055) lr 9.8907e-03 eta 0:22:57
epoch [3/30] batch [140/200] time 0.243 (0.250) data 0.000 (0.004) loss -0.0529 (0.9675) lr 9.8907e-03 eta 0:22:46
epoch [3/30] batch [160/200] time 0.247 (0.250) data 0.000 (0.004) loss 2.1328 (0.9674) lr 9.8907e-03 eta 0:22:40
epoch [3/30] batch [180/200] time 0.239 (0.249) data 0.000 (0.003) loss 0.7793 (0.9762) lr 9.8907e-03 eta 0:22:30
epoch [3/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss 0.6934 (0.9711) lr 9.7553e-03 eta 0:22:20
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.21s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.73it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.67it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.58it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.38it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.11it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.72it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.20it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.56it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.84it/s]100%|██████████| 11/11 [00:02<00:00,  4.28it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 95.9%

epoch [4/30] batch [20/200] time 0.247 (0.278) data 0.000 (0.027) loss 0.0159 (0.6656) lr 9.7553e-03 eta 0:24:55
epoch [4/30] batch [40/200] time 0.248 (0.263) data 0.000 (0.014) loss 1.4639 (0.7253) lr 9.7553e-03 eta 0:23:31
epoch [4/30] batch [60/200] time 0.246 (0.258) data 0.000 (0.009) loss 1.1777 (0.7973) lr 9.7553e-03 eta 0:22:58
epoch [4/30] batch [80/200] time 0.247 (0.257) data 0.000 (0.007) loss -0.0374 (0.8223) lr 9.7553e-03 eta 0:22:45
epoch [4/30] batch [100/200] time 0.244 (0.255) data 0.000 (0.006) loss 0.9258 (0.8164) lr 9.7553e-03 eta 0:22:30
epoch [4/30] batch [120/200] time 0.243 (0.253) data 0.000 (0.005) loss 0.9556 (0.8657) lr 9.7553e-03 eta 0:22:18
epoch [4/30] batch [140/200] time 0.244 (0.252) data 0.000 (0.004) loss 0.3716 (0.8151) lr 9.7553e-03 eta 0:22:06
epoch [4/30] batch [160/200] time 0.243 (0.252) data 0.000 (0.004) loss -0.0074 (0.8220) lr 9.7553e-03 eta 0:22:00
epoch [4/30] batch [180/200] time 0.239 (0.251) data 0.000 (0.003) loss 1.1289 (0.8431) lr 9.7553e-03 eta 0:21:50
epoch [4/30] batch [200/200] time 0.301 (0.250) data 0.000 (0.003) loss 0.3708 (0.8581) lr 9.5677e-03 eta 0:21:41
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.31s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.62it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.52it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.42it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.25it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.99it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.61it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.11it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.50it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.79it/s]100%|██████████| 11/11 [00:02<00:00,  4.12it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/200] time 0.247 (0.280) data 0.000 (0.027) loss 3.3398 (1.3642) lr 9.5677e-03 eta 0:24:08
epoch [5/30] batch [40/200] time 0.259 (0.264) data 0.000 (0.014) loss -0.0323 (1.2752) lr 9.5677e-03 eta 0:22:41
epoch [5/30] batch [60/200] time 0.245 (0.258) data 0.000 (0.009) loss 3.7949 (1.1738) lr 9.5677e-03 eta 0:22:08
epoch [5/30] batch [80/200] time 0.247 (0.256) data 0.000 (0.007) loss 0.2715 (1.1234) lr 9.5677e-03 eta 0:21:52
epoch [5/30] batch [100/200] time 0.243 (0.254) data 0.000 (0.006) loss 1.8213 (1.1917) lr 9.5677e-03 eta 0:21:34
epoch [5/30] batch [120/200] time 0.241 (0.252) data 0.000 (0.005) loss -0.0207 (1.1427) lr 9.5677e-03 eta 0:21:21
epoch [5/30] batch [140/200] time 0.242 (0.252) data 0.000 (0.004) loss 0.0203 (1.1116) lr 9.5677e-03 eta 0:21:13
epoch [5/30] batch [160/200] time 0.250 (0.251) data 0.000 (0.004) loss 1.4434 (1.0956) lr 9.5677e-03 eta 0:21:03
epoch [5/30] batch [180/200] time 0.239 (0.250) data 0.000 (0.003) loss 0.4241 (1.0559) lr 9.5677e-03 eta 0:20:54
epoch [5/30] batch [200/200] time 0.240 (0.249) data 0.000 (0.003) loss 0.2195 (1.0229) lr 9.3301e-03 eta 0:20:44
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.33s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.59it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.49it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.38it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.22it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.95it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.08it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.43it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.73it/s]100%|██████████| 11/11 [00:02<00:00,  4.10it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.5%

epoch [6/30] batch [20/200] time 0.247 (0.277) data 0.000 (0.027) loss 3.6387 (1.3627) lr 9.3301e-03 eta 0:23:01
epoch [6/30] batch [40/200] time 0.245 (0.262) data 0.000 (0.014) loss 0.4639 (0.8935) lr 9.3301e-03 eta 0:21:40
epoch [6/30] batch [60/200] time 0.247 (0.259) data 0.000 (0.009) loss 0.0380 (0.8781) lr 9.3301e-03 eta 0:21:17
epoch [6/30] batch [80/200] time 0.246 (0.255) data 0.000 (0.007) loss -0.0394 (0.7584) lr 9.3301e-03 eta 0:20:56
epoch [6/30] batch [100/200] time 0.304 (0.254) data 0.000 (0.006) loss 1.8936 (0.7214) lr 9.3301e-03 eta 0:20:43
epoch [6/30] batch [120/200] time 0.242 (0.252) data 0.000 (0.005) loss 1.7930 (0.7829) lr 9.3301e-03 eta 0:20:29
epoch [6/30] batch [140/200] time 0.252 (0.251) data 0.000 (0.004) loss 1.1309 (0.8069) lr 9.3301e-03 eta 0:20:20
epoch [6/30] batch [160/200] time 0.245 (0.250) data 0.000 (0.004) loss 1.2871 (0.8356) lr 9.3301e-03 eta 0:20:11
epoch [6/30] batch [180/200] time 0.240 (0.250) data 0.000 (0.003) loss 5.4609 (0.8663) lr 9.3301e-03 eta 0:20:02
epoch [6/30] batch [200/200] time 0.243 (0.249) data 0.000 (0.003) loss -0.0449 (0.8617) lr 9.0451e-03 eta 0:19:54
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.35s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.47it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.36it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.20it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.94it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.57it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.07it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.46it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.75it/s]100%|██████████| 11/11 [00:02<00:00,  4.08it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 95.9%

epoch [7/30] batch [20/200] time 0.242 (0.273) data 0.000 (0.027) loss 0.0272 (0.2948) lr 9.0451e-03 eta 0:21:46
epoch [7/30] batch [40/200] time 0.245 (0.261) data 0.000 (0.014) loss -0.0386 (0.5910) lr 9.0451e-03 eta 0:20:43
epoch [7/30] batch [60/200] time 0.245 (0.256) data 0.000 (0.009) loss 0.4583 (0.6187) lr 9.0451e-03 eta 0:20:12
epoch [7/30] batch [80/200] time 0.243 (0.253) data 0.000 (0.007) loss 2.2266 (0.6823) lr 9.0451e-03 eta 0:19:53
epoch [7/30] batch [100/200] time 0.244 (0.252) data 0.000 (0.006) loss 0.1963 (0.7149) lr 9.0451e-03 eta 0:19:43
epoch [7/30] batch [120/200] time 0.245 (0.251) data 0.000 (0.005) loss 0.4456 (0.6851) lr 9.0451e-03 eta 0:19:32
epoch [7/30] batch [140/200] time 0.244 (0.250) data 0.000 (0.004) loss 0.6621 (0.7770) lr 9.0451e-03 eta 0:19:23
epoch [7/30] batch [160/200] time 0.244 (0.249) data 0.000 (0.004) loss 1.1221 (0.7981) lr 9.0451e-03 eta 0:19:16
epoch [7/30] batch [180/200] time 0.240 (0.248) data 0.000 (0.003) loss 0.4192 (0.8040) lr 9.0451e-03 eta 0:19:07
epoch [7/30] batch [200/200] time 0.239 (0.247) data 0.000 (0.003) loss 0.1368 (0.8496) lr 8.7157e-03 eta 0:18:58
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.25s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.68it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.61it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.51it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.35it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.08it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.69it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.17it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.54it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.81it/s]100%|██████████| 11/11 [00:02<00:00,  4.24it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [8/30] batch [20/200] time 0.244 (0.278) data 0.000 (0.027) loss 0.0512 (0.8715) lr 8.7157e-03 eta 0:21:13
epoch [8/30] batch [40/200] time 0.245 (0.264) data 0.000 (0.013) loss 1.0410 (0.7505) lr 8.7157e-03 eta 0:20:01
epoch [8/30] batch [60/200] time 0.245 (0.257) data 0.000 (0.009) loss -0.0260 (0.7229) lr 8.7157e-03 eta 0:19:28
epoch [8/30] batch [80/200] time 0.242 (0.254) data 0.000 (0.007) loss 2.6602 (0.8242) lr 8.7157e-03 eta 0:19:09
epoch [8/30] batch [100/200] time 0.242 (0.252) data 0.000 (0.006) loss 0.6343 (0.8028) lr 8.7157e-03 eta 0:18:56
epoch [8/30] batch [120/200] time 0.249 (0.252) data 0.000 (0.005) loss 0.0857 (0.8960) lr 8.7157e-03 eta 0:18:47
epoch [8/30] batch [140/200] time 0.244 (0.251) data 0.000 (0.004) loss 0.1141 (0.8746) lr 8.7157e-03 eta 0:18:38
epoch [8/30] batch [160/200] time 0.245 (0.250) data 0.000 (0.004) loss 2.6309 (0.9159) lr 8.7157e-03 eta 0:18:31
epoch [8/30] batch [180/200] time 0.239 (0.250) data 0.000 (0.003) loss 0.7134 (0.9415) lr 8.7157e-03 eta 0:18:23
epoch [8/30] batch [200/200] time 0.238 (0.249) data 0.000 (0.003) loss 0.0807 (0.9346) lr 8.3457e-03 eta 0:18:14
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.22s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.72it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.66it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.57it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.40it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.13it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.72it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.19it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.55it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.82it/s]100%|██████████| 11/11 [00:02<00:00,  4.28it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/200] time 0.244 (0.276) data 0.000 (0.028) loss -0.0336 (0.3753) lr 8.3457e-03 eta 0:20:09
epoch [9/30] batch [40/200] time 0.243 (0.262) data 0.000 (0.014) loss 0.9512 (0.6493) lr 8.3457e-03 eta 0:19:01
epoch [9/30] batch [60/200] time 0.245 (0.256) data 0.000 (0.010) loss 0.4814 (0.7690) lr 8.3457e-03 eta 0:18:31
epoch [9/30] batch [80/200] time 0.244 (0.254) data 0.000 (0.007) loss 0.1498 (0.7657) lr 8.3457e-03 eta 0:18:18
epoch [9/30] batch [100/200] time 0.243 (0.252) data 0.000 (0.006) loss 0.0762 (0.8612) lr 8.3457e-03 eta 0:18:05
epoch [9/30] batch [120/200] time 0.245 (0.251) data 0.000 (0.005) loss 0.5049 (0.8816) lr 8.3457e-03 eta 0:17:55
epoch [9/30] batch [140/200] time 0.248 (0.251) data 0.000 (0.004) loss 1.7793 (0.9507) lr 8.3457e-03 eta 0:17:48
epoch [9/30] batch [160/200] time 0.247 (0.250) data 0.000 (0.004) loss 0.8066 (0.9366) lr 8.3457e-03 eta 0:17:41
epoch [9/30] batch [180/200] time 0.243 (0.250) data 0.000 (0.003) loss 4.4219 (0.9758) lr 8.3457e-03 eta 0:17:33
epoch [9/30] batch [200/200] time 0.242 (0.249) data 0.000 (0.003) loss -0.0034 (0.9227) lr 7.9389e-03 eta 0:17:24
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.22s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.72it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.66it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.57it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.41it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.13it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.70it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.19it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.55it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.83it/s]100%|██████████| 11/11 [00:02<00:00,  4.29it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.2%

epoch [10/30] batch [20/200] time 0.245 (0.277) data 0.000 (0.027) loss 0.5317 (0.5208) lr 7.9389e-03 eta 0:19:16
epoch [10/30] batch [40/200] time 0.243 (0.262) data 0.000 (0.014) loss -0.0081 (0.7318) lr 7.9389e-03 eta 0:18:09
epoch [10/30] batch [60/200] time 0.247 (0.258) data 0.000 (0.009) loss -0.0384 (0.8026) lr 7.9389e-03 eta 0:17:48
epoch [10/30] batch [80/200] time 0.247 (0.255) data 0.000 (0.007) loss -0.0493 (0.7826) lr 7.9389e-03 eta 0:17:31
epoch [10/30] batch [100/200] time 0.248 (0.253) data 0.000 (0.006) loss 0.1422 (0.7621) lr 7.9389e-03 eta 0:17:19
epoch [10/30] batch [120/200] time 0.250 (0.252) data 0.000 (0.005) loss 0.3286 (0.8283) lr 7.9389e-03 eta 0:17:09
epoch [10/30] batch [140/200] time 0.248 (0.252) data 0.000 (0.004) loss -0.0404 (0.7958) lr 7.9389e-03 eta 0:17:03
epoch [10/30] batch [160/200] time 0.247 (0.251) data 0.000 (0.004) loss 0.2380 (0.8262) lr 7.9389e-03 eta 0:16:55
epoch [10/30] batch [180/200] time 0.240 (0.250) data 0.000 (0.003) loss 0.2463 (0.8297) lr 7.9389e-03 eta 0:16:46
epoch [10/30] batch [200/200] time 0.239 (0.250) data 0.000 (0.003) loss 0.7900 (0.8501) lr 7.5000e-03 eta 0:16:38
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.21s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.73it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.66it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.57it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.41it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.13it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.72it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.18it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.55it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.82it/s]100%|██████████| 11/11 [00:02<00:00,  4.27it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/200] time 0.244 (0.277) data 0.000 (0.027) loss 0.2468 (0.6385) lr 7.5000e-03 eta 0:18:21
epoch [11/30] batch [40/200] time 0.248 (0.262) data 0.000 (0.013) loss 0.0863 (0.8001) lr 7.5000e-03 eta 0:17:18
epoch [11/30] batch [60/200] time 0.248 (0.257) data 0.000 (0.009) loss 1.6797 (0.7514) lr 7.5000e-03 eta 0:16:53
epoch [11/30] batch [80/200] time 0.245 (0.254) data 0.000 (0.007) loss 0.0722 (0.6997) lr 7.5000e-03 eta 0:16:36
epoch [11/30] batch [100/200] time 0.242 (0.253) data 0.000 (0.006) loss 0.2754 (0.6513) lr 7.5000e-03 eta 0:16:26
epoch [11/30] batch [120/200] time 0.246 (0.252) data 0.000 (0.005) loss 1.8486 (0.6928) lr 7.5000e-03 eta 0:16:16
epoch [11/30] batch [140/200] time 0.245 (0.251) data 0.000 (0.004) loss 1.4648 (0.6859) lr 7.5000e-03 eta 0:16:08
epoch [11/30] batch [160/200] time 0.245 (0.250) data 0.000 (0.004) loss 3.0078 (0.7116) lr 7.5000e-03 eta 0:16:00
epoch [11/30] batch [180/200] time 0.239 (0.250) data 0.000 (0.003) loss 0.2170 (0.7138) lr 7.5000e-03 eta 0:15:53
epoch [11/30] batch [200/200] time 0.239 (0.249) data 0.000 (0.003) loss -0.0562 (0.7013) lr 7.0337e-03 eta 0:15:44
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.59it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.48it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.38it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.22it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.96it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.08it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.47it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.76it/s]100%|██████████| 11/11 [00:02<00:00,  4.09it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.3%

epoch [12/30] batch [20/200] time 0.249 (0.276) data 0.000 (0.027) loss -0.0143 (0.6620) lr 7.0337e-03 eta 0:17:22
epoch [12/30] batch [40/200] time 0.243 (0.261) data 0.000 (0.014) loss 0.0045 (0.6075) lr 7.0337e-03 eta 0:16:20
epoch [12/30] batch [60/200] time 0.325 (0.257) data 0.000 (0.009) loss 0.0141 (0.6527) lr 7.0337e-03 eta 0:16:02
epoch [12/30] batch [80/200] time 0.242 (0.254) data 0.000 (0.007) loss 3.2090 (0.7524) lr 7.0337e-03 eta 0:15:46
epoch [12/30] batch [100/200] time 0.249 (0.252) data 0.000 (0.006) loss -0.0589 (0.8619) lr 7.0337e-03 eta 0:15:34
epoch [12/30] batch [120/200] time 0.245 (0.251) data 0.000 (0.005) loss 0.4280 (0.8388) lr 7.0337e-03 eta 0:15:25
epoch [12/30] batch [140/200] time 0.249 (0.251) data 0.000 (0.004) loss -0.0216 (0.8313) lr 7.0337e-03 eta 0:15:18
epoch [12/30] batch [160/200] time 0.247 (0.250) data 0.000 (0.004) loss 1.2432 (0.8294) lr 7.0337e-03 eta 0:15:11
epoch [12/30] batch [180/200] time 0.241 (0.250) data 0.000 (0.003) loss 1.3262 (0.7845) lr 7.0337e-03 eta 0:15:05
epoch [12/30] batch [200/200] time 0.241 (0.249) data 0.000 (0.003) loss 0.1049 (0.7690) lr 6.5451e-03 eta 0:14:57
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.27s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.66it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.58it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.48it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.32it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.05it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.66it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.15it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.52it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.78it/s]100%|██████████| 11/11 [00:02<00:00,  4.20it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.0%

epoch [13/30] batch [20/200] time 0.244 (0.279) data 0.000 (0.030) loss 0.1622 (1.0855) lr 6.5451e-03 eta 0:16:38
epoch [13/30] batch [40/200] time 0.249 (0.265) data 0.000 (0.015) loss 1.0557 (0.9810) lr 6.5451e-03 eta 0:15:44
epoch [13/30] batch [60/200] time 0.247 (0.259) data 0.000 (0.010) loss 0.0053 (0.9780) lr 6.5451e-03 eta 0:15:17
epoch [13/30] batch [80/200] time 0.247 (0.257) data 0.000 (0.008) loss -0.0344 (0.8336) lr 6.5451e-03 eta 0:15:03
epoch [13/30] batch [100/200] time 0.244 (0.255) data 0.000 (0.006) loss -0.0053 (0.8350) lr 6.5451e-03 eta 0:14:50
epoch [13/30] batch [120/200] time 0.246 (0.253) data 0.000 (0.005) loss 0.8882 (0.8929) lr 6.5451e-03 eta 0:14:39
epoch [13/30] batch [140/200] time 0.247 (0.252) data 0.000 (0.004) loss -0.0245 (0.8736) lr 6.5451e-03 eta 0:14:30
epoch [13/30] batch [160/200] time 0.245 (0.251) data 0.000 (0.004) loss 0.1548 (0.8677) lr 6.5451e-03 eta 0:14:23
epoch [13/30] batch [180/200] time 0.241 (0.250) data 0.000 (0.004) loss 1.1328 (0.8727) lr 6.5451e-03 eta 0:14:15
epoch [13/30] batch [200/200] time 0.241 (0.249) data 0.000 (0.003) loss 0.3628 (0.8551) lr 6.0396e-03 eta 0:14:07
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.27s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.66it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.57it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.48it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.31it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.05it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.66it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.14it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.52it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.80it/s]100%|██████████| 11/11 [00:02<00:00,  4.19it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.9%

epoch [14/30] batch [20/200] time 0.245 (0.281) data 0.000 (0.026) loss -0.0548 (0.4465) lr 6.0396e-03 eta 0:15:48
epoch [14/30] batch [40/200] time 0.245 (0.264) data 0.000 (0.013) loss 0.1219 (0.5128) lr 6.0396e-03 eta 0:14:47
epoch [14/30] batch [60/200] time 0.245 (0.258) data 0.000 (0.009) loss 2.4707 (0.7415) lr 6.0396e-03 eta 0:14:23
epoch [14/30] batch [80/200] time 0.242 (0.256) data 0.000 (0.007) loss 2.1602 (0.8327) lr 6.0396e-03 eta 0:14:11
epoch [14/30] batch [100/200] time 0.246 (0.254) data 0.000 (0.005) loss 0.6943 (0.7787) lr 6.0396e-03 eta 0:13:57
epoch [14/30] batch [120/200] time 0.244 (0.252) data 0.000 (0.005) loss 0.3704 (0.8299) lr 6.0396e-03 eta 0:13:47
epoch [14/30] batch [140/200] time 0.250 (0.252) data 0.000 (0.004) loss 1.5234 (0.8676) lr 6.0396e-03 eta 0:13:40
epoch [14/30] batch [160/200] time 0.244 (0.251) data 0.000 (0.004) loss -0.0193 (0.8488) lr 6.0396e-03 eta 0:13:31
epoch [14/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss 0.6748 (0.8422) lr 6.0396e-03 eta 0:13:23
epoch [14/30] batch [200/200] time 0.240 (0.248) data 0.000 (0.003) loss 0.2079 (0.8572) lr 5.5226e-03 eta 0:13:15
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.47it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.36it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.20it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.94it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.57it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.07it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.46it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.71it/s]100%|██████████| 11/11 [00:02<00:00,  4.07it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.4%

epoch [15/30] batch [20/200] time 0.245 (0.278) data 0.000 (0.029) loss 2.4395 (0.6480) lr 5.5226e-03 eta 0:14:44
epoch [15/30] batch [40/200] time 0.240 (0.261) data 0.000 (0.015) loss 0.5391 (0.7171) lr 5.5226e-03 eta 0:13:45
epoch [15/30] batch [60/200] time 0.246 (0.257) data 0.000 (0.010) loss 0.1885 (0.7524) lr 5.5226e-03 eta 0:13:27
epoch [15/30] batch [80/200] time 0.246 (0.255) data 0.000 (0.007) loss 0.1436 (0.7364) lr 5.5226e-03 eta 0:13:14
epoch [15/30] batch [100/200] time 0.243 (0.253) data 0.000 (0.006) loss 0.2058 (0.7929) lr 5.5226e-03 eta 0:13:02
epoch [15/30] batch [120/200] time 0.247 (0.251) data 0.000 (0.005) loss -0.0510 (0.8168) lr 5.5226e-03 eta 0:12:54
epoch [15/30] batch [140/200] time 0.250 (0.251) data 0.000 (0.004) loss 0.0031 (0.8053) lr 5.5226e-03 eta 0:12:48
epoch [15/30] batch [160/200] time 0.245 (0.251) data 0.000 (0.004) loss 1.1748 (0.7938) lr 5.5226e-03 eta 0:12:41
epoch [15/30] batch [180/200] time 0.241 (0.250) data 0.000 (0.003) loss -0.0474 (0.8132) lr 5.5226e-03 eta 0:12:34
epoch [15/30] batch [200/200] time 0.240 (0.249) data 0.000 (0.003) loss 0.0053 (0.8022) lr 5.0000e-03 eta 0:12:27
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.32s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.60it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.50it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.39it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.23it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.97it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.59it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.09it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.76it/s]100%|██████████| 11/11 [00:02<00:00,  4.12it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%

epoch [16/30] batch [20/200] time 0.241 (0.275) data 0.000 (0.026) loss 1.7520 (0.4764) lr 5.0000e-03 eta 0:13:40
epoch [16/30] batch [40/200] time 0.242 (0.259) data 0.000 (0.013) loss 2.9043 (0.6070) lr 5.0000e-03 eta 0:12:47
epoch [16/30] batch [60/200] time 0.248 (0.254) data 0.000 (0.009) loss 0.4810 (0.7417) lr 5.0000e-03 eta 0:12:27
epoch [16/30] batch [80/200] time 0.241 (0.252) data 0.000 (0.007) loss 0.7305 (0.7143) lr 5.0000e-03 eta 0:12:15
epoch [16/30] batch [100/200] time 0.242 (0.251) data 0.000 (0.005) loss 4.0117 (0.8127) lr 5.0000e-03 eta 0:12:08
epoch [16/30] batch [120/200] time 0.248 (0.250) data 0.000 (0.005) loss 1.0791 (0.8290) lr 5.0000e-03 eta 0:12:01
epoch [16/30] batch [140/200] time 0.246 (0.250) data 0.000 (0.004) loss 0.2253 (0.7982) lr 5.0000e-03 eta 0:11:54
epoch [16/30] batch [160/200] time 0.246 (0.249) data 0.000 (0.003) loss 0.0587 (0.8040) lr 5.0000e-03 eta 0:11:47
epoch [16/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss 1.2109 (0.8269) lr 5.0000e-03 eta 0:11:41
epoch [16/30] batch [200/200] time 0.238 (0.248) data 0.000 (0.003) loss 0.2300 (0.8448) lr 4.4774e-03 eta 0:11:33
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.23s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.71it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.64it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.55it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.39it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.11it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.71it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.19it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.55it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.83it/s]100%|██████████| 11/11 [00:02<00:00,  4.26it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%

epoch [17/30] batch [20/200] time 0.243 (0.276) data 0.000 (0.027) loss 0.2512 (0.5614) lr 4.4774e-03 eta 0:12:48
epoch [17/30] batch [40/200] time 0.243 (0.261) data 0.000 (0.014) loss 1.3330 (0.6711) lr 4.4774e-03 eta 0:11:59
epoch [17/30] batch [60/200] time 0.260 (0.257) data 0.000 (0.009) loss 0.0647 (0.6960) lr 4.4774e-03 eta 0:11:42
epoch [17/30] batch [80/200] time 0.248 (0.256) data 0.000 (0.007) loss 1.5566 (0.7898) lr 4.4774e-03 eta 0:11:35
epoch [17/30] batch [100/200] time 0.248 (0.254) data 0.000 (0.006) loss 0.0524 (0.7270) lr 4.4774e-03 eta 0:11:27
epoch [17/30] batch [120/200] time 0.246 (0.253) data 0.000 (0.005) loss 0.0464 (0.7134) lr 4.4774e-03 eta 0:11:18
epoch [17/30] batch [140/200] time 0.246 (0.253) data 0.000 (0.004) loss 1.9131 (0.7268) lr 4.4774e-03 eta 0:11:12
epoch [17/30] batch [160/200] time 0.248 (0.252) data 0.000 (0.004) loss -0.0572 (0.7707) lr 4.4774e-03 eta 0:11:05
epoch [17/30] batch [180/200] time 0.241 (0.251) data 0.000 (0.003) loss 0.1968 (0.7767) lr 4.4774e-03 eta 0:10:58
epoch [17/30] batch [200/200] time 0.242 (0.251) data 0.000 (0.003) loss 1.4473 (0.7643) lr 3.9604e-03 eta 0:10:51
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.59it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.48it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.38it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.22it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.96it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.08it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.47it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.76it/s]100%|██████████| 11/11 [00:02<00:00,  4.10it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.6%

epoch [18/30] batch [20/200] time 0.244 (0.275) data 0.000 (0.027) loss 0.0422 (0.9666) lr 3.9604e-03 eta 0:11:48
epoch [18/30] batch [40/200] time 0.251 (0.261) data 0.000 (0.014) loss 1.4941 (0.8382) lr 3.9604e-03 eta 0:11:07
epoch [18/30] batch [60/200] time 0.243 (0.256) data 0.000 (0.009) loss -0.0006 (0.7429) lr 3.9604e-03 eta 0:10:50
epoch [18/30] batch [80/200] time 0.249 (0.254) data 0.000 (0.007) loss 0.6284 (0.7171) lr 3.9604e-03 eta 0:10:39
epoch [18/30] batch [100/200] time 0.244 (0.253) data 0.000 (0.006) loss 1.0576 (0.7780) lr 3.9604e-03 eta 0:10:31
epoch [18/30] batch [120/200] time 0.250 (0.252) data 0.000 (0.005) loss 0.9189 (0.8055) lr 3.9604e-03 eta 0:10:23
epoch [18/30] batch [140/200] time 0.249 (0.251) data 0.000 (0.004) loss -0.0001 (0.7962) lr 3.9604e-03 eta 0:10:16
epoch [18/30] batch [160/200] time 0.246 (0.250) data 0.000 (0.004) loss 0.1887 (0.7955) lr 3.9604e-03 eta 0:10:09
epoch [18/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss 0.4558 (0.7798) lr 3.9604e-03 eta 0:10:03
epoch [18/30] batch [200/200] time 0.241 (0.249) data 0.000 (0.003) loss 0.8979 (0.7936) lr 3.4549e-03 eta 0:09:56
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.35s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.57it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.46it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.35it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.19it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.93it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.56it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.06it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.45it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.75it/s]100%|██████████| 11/11 [00:02<00:00,  4.08it/s]=> result
* total: 1,036
* correct: 1,021
* accuracy: 98.6%
* error: 1.4%
* macro_f1: 97.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/200] time 0.246 (0.278) data 0.000 (0.030) loss 3.1191 (1.5270) lr 3.4549e-03 eta 0:11:02
epoch [19/30] batch [40/200] time 0.248 (0.265) data 0.000 (0.015) loss 0.0760 (1.4850) lr 3.4549e-03 eta 0:10:25
epoch [19/30] batch [60/200] time 0.253 (0.259) data 0.000 (0.010) loss 0.8208 (1.2847) lr 3.4549e-03 eta 0:10:06
epoch [19/30] batch [80/200] time 0.244 (0.256) data 0.000 (0.008) loss -0.0203 (1.0715) lr 3.4549e-03 eta 0:09:53
epoch [19/30] batch [100/200] time 0.248 (0.255) data 0.000 (0.006) loss 0.4397 (1.0607) lr 3.4549e-03 eta 0:09:45
epoch [19/30] batch [120/200] time 0.246 (0.253) data 0.000 (0.005) loss 0.2484 (0.9700) lr 3.4549e-03 eta 0:09:37
epoch [19/30] batch [140/200] time 0.248 (0.252) data 0.000 (0.004) loss -0.0545 (0.9548) lr 3.4549e-03 eta 0:09:30
epoch [19/30] batch [160/200] time 0.247 (0.252) data 0.000 (0.004) loss 0.8921 (0.8712) lr 3.4549e-03 eta 0:09:24
epoch [19/30] batch [180/200] time 0.241 (0.251) data 0.000 (0.004) loss 0.4907 (0.8847) lr 3.4549e-03 eta 0:09:17
epoch [19/30] batch [200/200] time 0.240 (0.250) data 0.000 (0.003) loss 0.0247 (0.8886) lr 2.9663e-03 eta 0:09:10
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.22s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.72it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.65it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.57it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.41it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.13it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.72it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.20it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.56it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.84it/s]100%|██████████| 11/11 [00:02<00:00,  4.27it/s]=> result
* total: 1,036
* correct: 1,021
* accuracy: 98.6%
* error: 1.4%
* macro_f1: 97.0%

epoch [20/30] batch [20/200] time 0.244 (0.278) data 0.000 (0.028) loss 1.5947 (0.7292) lr 2.9663e-03 eta 0:10:06
epoch [20/30] batch [40/200] time 0.246 (0.265) data 0.000 (0.014) loss -0.0309 (0.7644) lr 2.9663e-03 eta 0:09:32
epoch [20/30] batch [60/200] time 0.253 (0.259) data 0.000 (0.010) loss -0.0365 (0.7015) lr 2.9663e-03 eta 0:09:14
epoch [20/30] batch [80/200] time 0.244 (0.256) data 0.000 (0.007) loss 0.2230 (0.7474) lr 2.9663e-03 eta 0:09:03
epoch [20/30] batch [100/200] time 0.247 (0.254) data 0.000 (0.006) loss 0.2583 (0.7609) lr 2.9663e-03 eta 0:08:53
epoch [20/30] batch [120/200] time 0.243 (0.253) data 0.000 (0.005) loss 0.0992 (0.6769) lr 2.9663e-03 eta 0:08:46
epoch [20/30] batch [140/200] time 0.244 (0.252) data 0.000 (0.004) loss 1.0703 (0.6960) lr 2.9663e-03 eta 0:08:39
epoch [20/30] batch [160/200] time 0.244 (0.251) data 0.000 (0.004) loss 1.7900 (0.7136) lr 2.9663e-03 eta 0:08:32
epoch [20/30] batch [180/200] time 0.239 (0.250) data 0.000 (0.003) loss 0.9346 (0.7680) lr 2.9663e-03 eta 0:08:24
epoch [20/30] batch [200/200] time 0.239 (0.249) data 0.000 (0.003) loss 1.3369 (0.7681) lr 2.5000e-03 eta 0:08:17
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.31s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.62it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.52it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.42it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.25it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.99it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.61it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.11it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.49it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.78it/s]100%|██████████| 11/11 [00:02<00:00,  4.15it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/200] time 0.243 (0.275) data 0.000 (0.027) loss 0.0026 (0.3410) lr 2.5000e-03 eta 0:09:04
epoch [21/30] batch [40/200] time 0.242 (0.260) data 0.000 (0.014) loss 0.0595 (0.4940) lr 2.5000e-03 eta 0:08:29
epoch [21/30] batch [60/200] time 0.246 (0.257) data 0.000 (0.009) loss -0.0573 (0.5415) lr 2.5000e-03 eta 0:08:17
epoch [21/30] batch [80/200] time 0.247 (0.254) data 0.000 (0.007) loss 1.3564 (0.6429) lr 2.5000e-03 eta 0:08:08
epoch [21/30] batch [100/200] time 0.248 (0.253) data 0.000 (0.006) loss 0.8384 (0.6028) lr 2.5000e-03 eta 0:08:00
epoch [21/30] batch [120/200] time 0.244 (0.252) data 0.000 (0.005) loss 0.1577 (0.6580) lr 2.5000e-03 eta 0:07:54
epoch [21/30] batch [140/200] time 0.246 (0.251) data 0.000 (0.004) loss -0.0465 (0.6579) lr 2.5000e-03 eta 0:07:47
epoch [21/30] batch [160/200] time 0.245 (0.251) data 0.000 (0.004) loss 1.0430 (0.6404) lr 2.5000e-03 eta 0:07:41
epoch [21/30] batch [180/200] time 0.239 (0.250) data 0.000 (0.003) loss 0.1481 (0.6369) lr 2.5000e-03 eta 0:07:34
epoch [21/30] batch [200/200] time 0.238 (0.249) data 0.000 (0.003) loss 0.8525 (0.6536) lr 2.0611e-03 eta 0:07:27
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.20s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.74it/s] 27%|██▋       | 3/11 [00:01<00:02,  2.68it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.59it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.43it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.15it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.74it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.21it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.56it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.83it/s]100%|██████████| 11/11 [00:02<00:00,  4.31it/s]=> result
* total: 1,036
* correct: 1,021
* accuracy: 98.6%
* error: 1.4%
* macro_f1: 97.1%

epoch [22/30] batch [20/200] time 0.247 (0.277) data 0.000 (0.027) loss 1.3457 (1.3035) lr 2.0611e-03 eta 0:08:13
epoch [22/30] batch [40/200] time 0.253 (0.261) data 0.000 (0.014) loss -0.0310 (0.9065) lr 2.0611e-03 eta 0:07:38
epoch [22/30] batch [60/200] time 0.245 (0.257) data 0.000 (0.009) loss 1.6670 (0.9367) lr 2.0611e-03 eta 0:07:27
epoch [22/30] batch [80/200] time 0.246 (0.254) data 0.000 (0.007) loss -0.0132 (0.9021) lr 2.0611e-03 eta 0:07:16
epoch [22/30] batch [100/200] time 0.245 (0.252) data 0.000 (0.006) loss 1.4150 (0.8823) lr 2.0611e-03 eta 0:07:08
epoch [22/30] batch [120/200] time 0.252 (0.251) data 0.000 (0.005) loss 3.6172 (0.8739) lr 2.0611e-03 eta 0:07:01
epoch [22/30] batch [140/200] time 0.244 (0.251) data 0.000 (0.004) loss 0.4661 (0.8539) lr 2.0611e-03 eta 0:06:55
epoch [22/30] batch [160/200] time 0.244 (0.250) data 0.000 (0.004) loss 0.1271 (0.8614) lr 2.0611e-03 eta 0:06:49
epoch [22/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss 2.3086 (0.8725) lr 2.0611e-03 eta 0:06:43
epoch [22/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss 0.5781 (0.8860) lr 1.6543e-03 eta 0:06:37
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.26s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.67it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.60it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.50it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.34it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.07it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.68it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.16it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.43it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.70it/s]100%|██████████| 11/11 [00:02<00:00,  4.20it/s]=> result
* total: 1,036
* correct: 1,021
* accuracy: 98.6%
* error: 1.4%
* macro_f1: 97.0%

epoch [23/30] batch [20/200] time 0.246 (0.276) data 0.000 (0.027) loss -0.0044 (0.8411) lr 1.6543e-03 eta 0:07:16
epoch [23/30] batch [40/200] time 0.245 (0.261) data 0.000 (0.013) loss -0.0200 (0.8767) lr 1.6543e-03 eta 0:06:46
epoch [23/30] batch [60/200] time 0.247 (0.256) data 0.000 (0.009) loss 0.0995 (0.9731) lr 1.6543e-03 eta 0:06:34
epoch [23/30] batch [80/200] time 0.245 (0.255) data 0.000 (0.007) loss 0.9961 (0.9496) lr 1.6543e-03 eta 0:06:27
epoch [23/30] batch [100/200] time 0.249 (0.253) data 0.000 (0.005) loss -0.0180 (0.9151) lr 1.6543e-03 eta 0:06:19
epoch [23/30] batch [120/200] time 0.245 (0.252) data 0.000 (0.005) loss 0.0444 (0.8995) lr 1.6543e-03 eta 0:06:13
epoch [23/30] batch [140/200] time 0.242 (0.251) data 0.000 (0.004) loss 1.7979 (0.8433) lr 1.6543e-03 eta 0:06:06
epoch [23/30] batch [160/200] time 0.245 (0.250) data 0.000 (0.004) loss 0.1161 (0.7835) lr 1.6543e-03 eta 0:06:00
epoch [23/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss 1.8809 (0.7984) lr 1.6543e-03 eta 0:05:53
epoch [23/30] batch [200/200] time 0.240 (0.248) data 0.000 (0.003) loss -0.0408 (0.7898) lr 1.2843e-03 eta 0:05:47
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.28s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.63it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.54it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.45it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.28it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.02it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.64it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.13it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.50it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.79it/s]100%|██████████| 11/11 [00:02<00:00,  4.17it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%

epoch [24/30] batch [20/200] time 0.245 (0.277) data 0.000 (0.027) loss 1.3457 (1.0828) lr 1.2843e-03 eta 0:06:22
epoch [24/30] batch [40/200] time 0.244 (0.262) data 0.000 (0.014) loss 0.8828 (1.0074) lr 1.2843e-03 eta 0:05:56
epoch [24/30] batch [60/200] time 0.244 (0.258) data 0.000 (0.009) loss 2.1055 (1.0472) lr 1.2843e-03 eta 0:05:46
epoch [24/30] batch [80/200] time 0.249 (0.255) data 0.000 (0.007) loss 0.0460 (0.9696) lr 1.2843e-03 eta 0:05:36
epoch [24/30] batch [100/200] time 0.249 (0.254) data 0.000 (0.006) loss 0.3108 (0.9241) lr 1.2843e-03 eta 0:05:29
epoch [24/30] batch [120/200] time 0.247 (0.253) data 0.001 (0.005) loss 0.6284 (0.9295) lr 1.2843e-03 eta 0:05:23
epoch [24/30] batch [140/200] time 0.248 (0.253) data 0.000 (0.004) loss 1.1289 (0.9225) lr 1.2843e-03 eta 0:05:18
epoch [24/30] batch [160/200] time 0.247 (0.252) data 0.000 (0.004) loss 0.1750 (0.8935) lr 1.2843e-03 eta 0:05:12
epoch [24/30] batch [180/200] time 0.241 (0.251) data 0.000 (0.003) loss -0.0296 (0.8628) lr 1.2843e-03 eta 0:05:06
epoch [24/30] batch [200/200] time 0.240 (0.250) data 0.000 (0.003) loss 0.0219 (0.8154) lr 9.5492e-04 eta 0:05:00
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.23s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.71it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.64it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.55it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.39it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.11it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.71it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.18it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.55it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.82it/s]100%|██████████| 11/11 [00:02<00:00,  4.25it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%

epoch [25/30] batch [20/200] time 0.243 (0.275) data 0.000 (0.026) loss 0.0601 (0.4033) lr 9.5492e-04 eta 0:05:24
epoch [25/30] batch [40/200] time 0.244 (0.260) data 0.000 (0.013) loss 1.1914 (0.7514) lr 9.5492e-04 eta 0:05:01
epoch [25/30] batch [60/200] time 0.248 (0.255) data 0.000 (0.009) loss -0.0485 (0.7423) lr 9.5492e-04 eta 0:04:50
epoch [25/30] batch [80/200] time 0.246 (0.253) data 0.000 (0.007) loss 0.0049 (0.7755) lr 9.5492e-04 eta 0:04:43
epoch [25/30] batch [100/200] time 0.243 (0.252) data 0.000 (0.005) loss 1.3760 (0.8006) lr 9.5492e-04 eta 0:04:36
epoch [25/30] batch [120/200] time 0.244 (0.251) data 0.000 (0.005) loss 0.1981 (0.8135) lr 9.5492e-04 eta 0:04:30
epoch [25/30] batch [140/200] time 0.262 (0.251) data 0.000 (0.004) loss 0.0061 (0.7695) lr 9.5492e-04 eta 0:04:25
epoch [25/30] batch [160/200] time 0.243 (0.250) data 0.000 (0.004) loss 0.0062 (0.7319) lr 9.5492e-04 eta 0:04:19
epoch [25/30] batch [180/200] time 0.243 (0.249) data 0.000 (0.003) loss 0.2585 (0.7427) lr 9.5492e-04 eta 0:04:13
epoch [25/30] batch [200/200] time 0.240 (0.248) data 0.000 (0.003) loss -0.0580 (0.7332) lr 6.6987e-04 eta 0:04:08
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.21s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.73it/s] 27%|██▋       | 3/11 [00:01<00:02,  2.67it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.58it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.42it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.14it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.74it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.20it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.56it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.83it/s]100%|██████████| 11/11 [00:02<00:00,  4.29it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%

epoch [26/30] batch [20/200] time 0.244 (0.278) data 0.000 (0.028) loss -0.0015 (0.8332) lr 6.6987e-04 eta 0:04:32
epoch [26/30] batch [40/200] time 0.244 (0.264) data 0.000 (0.014) loss 0.7036 (0.7373) lr 6.6987e-04 eta 0:04:13
epoch [26/30] batch [60/200] time 0.245 (0.258) data 0.000 (0.009) loss 0.8789 (0.6646) lr 6.6987e-04 eta 0:04:02
epoch [26/30] batch [80/200] time 0.246 (0.255) data 0.000 (0.007) loss 0.0930 (0.7107) lr 6.6987e-04 eta 0:03:54
epoch [26/30] batch [100/200] time 0.248 (0.254) data 0.000 (0.006) loss 2.2129 (0.7324) lr 6.6987e-04 eta 0:03:48
epoch [26/30] batch [120/200] time 0.243 (0.252) data 0.000 (0.005) loss 0.2150 (0.7418) lr 6.6987e-04 eta 0:03:42
epoch [26/30] batch [140/200] time 0.245 (0.251) data 0.000 (0.004) loss -0.0516 (0.7836) lr 6.6987e-04 eta 0:03:36
epoch [26/30] batch [160/200] time 0.244 (0.251) data 0.000 (0.004) loss 5.4336 (0.8193) lr 6.6987e-04 eta 0:03:30
epoch [26/30] batch [180/200] time 0.240 (0.250) data 0.000 (0.003) loss 0.5181 (0.8151) lr 6.6987e-04 eta 0:03:24
epoch [26/30] batch [200/200] time 0.238 (0.248) data 0.000 (0.003) loss 0.2372 (0.8094) lr 4.3227e-04 eta 0:03:18
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.31s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.62it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.52it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.42it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.26it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.99it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.61it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.11it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.49it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.78it/s]100%|██████████| 11/11 [00:02<00:00,  4.14it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%

epoch [27/30] batch [20/200] time 0.246 (0.280) data 0.000 (0.028) loss 0.2222 (0.6345) lr 4.3227e-04 eta 0:03:38
epoch [27/30] batch [40/200] time 0.245 (0.265) data 0.000 (0.014) loss 5.6523 (0.8278) lr 4.3227e-04 eta 0:03:21
epoch [27/30] batch [60/200] time 0.244 (0.258) data 0.000 (0.009) loss 0.1807 (0.7993) lr 4.3227e-04 eta 0:03:11
epoch [27/30] batch [80/200] time 0.244 (0.255) data 0.000 (0.007) loss -0.0377 (0.8503) lr 4.3227e-04 eta 0:03:03
epoch [27/30] batch [100/200] time 0.246 (0.254) data 0.000 (0.006) loss -0.0555 (0.8355) lr 4.3227e-04 eta 0:02:57
epoch [27/30] batch [120/200] time 0.247 (0.253) data 0.000 (0.005) loss 0.0876 (0.9176) lr 4.3227e-04 eta 0:02:51
epoch [27/30] batch [140/200] time 0.245 (0.252) data 0.000 (0.004) loss -0.0598 (0.8599) lr 4.3227e-04 eta 0:02:46
epoch [27/30] batch [160/200] time 0.250 (0.251) data 0.000 (0.004) loss 0.1365 (0.8833) lr 4.3227e-04 eta 0:02:40
epoch [27/30] batch [180/200] time 0.241 (0.251) data 0.000 (0.003) loss 0.3298 (0.8608) lr 4.3227e-04 eta 0:02:35
epoch [27/30] batch [200/200] time 0.240 (0.250) data 0.000 (0.003) loss 0.0503 (0.8507) lr 2.4472e-04 eta 0:02:29
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.22s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.72it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.66it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.57it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.40it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.12it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.72it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.19it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.54it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.81it/s]100%|██████████| 11/11 [00:02<00:00,  4.26it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%

epoch [28/30] batch [20/200] time 0.242 (0.274) data 0.000 (0.027) loss 0.8120 (0.9826) lr 2.4472e-04 eta 0:02:39
epoch [28/30] batch [40/200] time 0.244 (0.262) data 0.000 (0.014) loss -0.0494 (0.7651) lr 2.4472e-04 eta 0:02:26
epoch [28/30] batch [60/200] time 0.243 (0.256) data 0.000 (0.009) loss -0.0240 (0.9397) lr 2.4472e-04 eta 0:02:18
epoch [28/30] batch [80/200] time 0.246 (0.254) data 0.000 (0.007) loss 0.3403 (0.8716) lr 2.4472e-04 eta 0:02:11
epoch [28/30] batch [100/200] time 0.252 (0.253) data 0.000 (0.006) loss 1.3613 (0.8569) lr 2.4472e-04 eta 0:02:06
epoch [28/30] batch [120/200] time 0.244 (0.251) data 0.000 (0.005) loss -0.0355 (0.8181) lr 2.4472e-04 eta 0:02:00
epoch [28/30] batch [140/200] time 0.248 (0.250) data 0.000 (0.004) loss 2.2188 (0.8155) lr 2.4472e-04 eta 0:01:55
epoch [28/30] batch [160/200] time 0.244 (0.250) data 0.000 (0.004) loss 0.7197 (0.8002) lr 2.4472e-04 eta 0:01:49
epoch [28/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss 2.8438 (0.8148) lr 2.4472e-04 eta 0:01:44
epoch [28/30] batch [200/200] time 0.242 (0.248) data 0.000 (0.003) loss 1.2441 (0.8174) lr 1.0926e-04 eta 0:01:39
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.35s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.47it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.37it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.21it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.95it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.57it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.07it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.47it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.76it/s]100%|██████████| 11/11 [00:02<00:00,  4.09it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%

epoch [29/30] batch [20/200] time 0.243 (0.274) data 0.000 (0.027) loss 2.7344 (0.7059) lr 1.0926e-04 eta 0:01:44
epoch [29/30] batch [40/200] time 0.243 (0.261) data 0.000 (0.014) loss -0.0518 (0.6654) lr 1.0926e-04 eta 0:01:33
epoch [29/30] batch [60/200] time 0.245 (0.255) data 0.000 (0.009) loss -0.0214 (0.5938) lr 1.0926e-04 eta 0:01:26
epoch [29/30] batch [80/200] time 0.247 (0.252) data 0.000 (0.007) loss 0.3020 (0.6719) lr 1.0926e-04 eta 0:01:20
epoch [29/30] batch [100/200] time 0.245 (0.251) data 0.000 (0.006) loss -0.0557 (0.6918) lr 1.0926e-04 eta 0:01:15
epoch [29/30] batch [120/200] time 0.243 (0.251) data 0.000 (0.005) loss 0.3687 (0.6808) lr 1.0926e-04 eta 0:01:10
epoch [29/30] batch [140/200] time 0.243 (0.250) data 0.000 (0.004) loss 0.8569 (0.7159) lr 1.0926e-04 eta 0:01:04
epoch [29/30] batch [160/200] time 0.246 (0.249) data 0.000 (0.004) loss 0.5767 (0.7496) lr 1.0926e-04 eta 0:00:59
epoch [29/30] batch [180/200] time 0.238 (0.249) data 0.000 (0.003) loss -0.0339 (0.6941) lr 1.0926e-04 eta 0:00:54
epoch [29/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss 2.6211 (0.6956) lr 2.7391e-05 eta 0:00:49
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.26s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.67it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.59it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.49it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.33it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.06it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.67it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.16it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.53it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.21it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%

epoch [30/30] batch [20/200] time 0.253 (0.280) data 0.000 (0.027) loss 0.6641 (0.7812) lr 2.7391e-05 eta 0:00:50
epoch [30/30] batch [40/200] time 0.242 (0.262) data 0.000 (0.014) loss 4.9102 (1.0954) lr 2.7391e-05 eta 0:00:41
epoch [30/30] batch [60/200] time 0.242 (0.257) data 0.000 (0.009) loss 2.3320 (0.9736) lr 2.7391e-05 eta 0:00:36
epoch [30/30] batch [80/200] time 0.242 (0.254) data 0.000 (0.007) loss -0.0201 (0.9886) lr 2.7391e-05 eta 0:00:30
epoch [30/30] batch [100/200] time 0.243 (0.252) data 0.000 (0.006) loss 0.5957 (0.9543) lr 2.7391e-05 eta 0:00:25
epoch [30/30] batch [120/200] time 0.242 (0.251) data 0.000 (0.005) loss 1.0283 (0.9418) lr 2.7391e-05 eta 0:00:20
epoch [30/30] batch [140/200] time 0.244 (0.250) data 0.000 (0.004) loss 0.7769 (0.8783) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [160/200] time 0.256 (0.250) data 0.000 (0.004) loss -0.0307 (0.8679) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [180/200] time 0.241 (0.249) data 0.000 (0.003) loss 0.3586 (0.8283) lr 2.7391e-05 eta 0:00:04
epoch [30/30] batch [200/200] time 0.240 (0.248) data 0.000 (0.003) loss -0.0422 (0.8450) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.59it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.48it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.37it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.21it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.95it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.08it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.47it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.76it/s]100%|██████████| 11/11 [00:02<00:00,  4.10it/s]
=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 18)
Evaluate on the *test* set
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.64s/it] 12%|█▎        | 2/16 [00:01<00:10,  1.33it/s] 19%|█▉        | 3/16 [00:01<00:06,  2.13it/s] 25%|██▌       | 4/16 [00:02<00:04,  2.97it/s] 31%|███▏      | 5/16 [00:02<00:02,  3.80it/s] 38%|███▊      | 6/16 [00:02<00:02,  4.57it/s] 44%|████▍     | 7/16 [00:02<00:01,  5.24it/s] 50%|█████     | 8/16 [00:02<00:01,  5.80it/s] 56%|█████▋    | 9/16 [00:02<00:01,  6.25it/s] 62%|██████▎   | 10/16 [00:02<00:00,  6.59it/s] 69%|██████▉   | 11/16 [00:02<00:00,  6.85it/s] 75%|███████▌  | 12/16 [00:03<00:00,  7.04it/s] 81%|████████▏ | 13/16 [00:03<00:00,  7.19it/s] 88%|████████▊ | 14/16 [00:03<00:00,  7.29it/s] 94%|█████████▍| 15/16 [00:03<00:00,  7.35it/s]100%|██████████| 16/16 [00:03<00:00,  4.36it/s]
=> result
* total: 1,549
* correct: 1,525
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 97.0%
Elapsed: 0:26:22
+ sh scripts/rpo_prime/base2new_test_sdl.sh caltech101 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
800 613 916
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      613
# test     916
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 18)
Evaluate on the *test* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:03<00:28,  3.20s/it] 20%|██        | 2/10 [00:03<00:11,  1.40s/it] 30%|███       | 3/10 [00:03<00:05,  1.22it/s] 40%|████      | 4/10 [00:03<00:03,  1.82it/s] 50%|█████     | 5/10 [00:03<00:01,  2.51it/s] 60%|██████    | 6/10 [00:03<00:01,  3.25it/s] 70%|███████   | 7/10 [00:03<00:00,  3.99it/s] 80%|████████  | 8/10 [00:04<00:00,  4.69it/s] 90%|█████████ | 9/10 [00:04<00:00,  5.32it/s]100%|██████████| 10/10 [00:04<00:00,  2.28it/s]
=> result
* total: 916
* correct: 855
* accuracy: 93.3%
* error: 6.7%
* macro_f1: 93.8%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh caltech101 2 0 main_tmp1_0.1sdl 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
800 1036 1549
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      1,036
# test     1,549
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/200] time 0.252 (0.363) data 0.000 (0.049) loss -0.0299 (1.4319) lr 1.0000e-02 eta 0:36:10
epoch [1/30] batch [40/200] time 0.245 (0.305) data 0.000 (0.025) loss 0.7881 (1.1465) lr 1.0000e-02 eta 0:30:15
epoch [1/30] batch [60/200] time 0.248 (0.285) data 0.000 (0.017) loss 0.3909 (1.0593) lr 1.0000e-02 eta 0:28:15
epoch [1/30] batch [80/200] time 0.250 (0.277) data 0.000 (0.013) loss 1.8545 (1.0765) lr 1.0000e-02 eta 0:27:18
epoch [1/30] batch [100/200] time 0.244 (0.271) data 0.000 (0.010) loss 0.6416 (1.0419) lr 1.0000e-02 eta 0:26:36
epoch [1/30] batch [120/200] time 0.247 (0.267) data 0.000 (0.008) loss 0.0241 (1.0087) lr 1.0000e-02 eta 0:26:07
epoch [1/30] batch [140/200] time 0.244 (0.264) data 0.000 (0.007) loss 2.0059 (1.1081) lr 1.0000e-02 eta 0:25:46
epoch [1/30] batch [160/200] time 0.245 (0.262) data 0.000 (0.006) loss 1.2764 (1.0577) lr 1.0000e-02 eta 0:25:30
epoch [1/30] batch [180/200] time 0.241 (0.260) data 0.000 (0.006) loss 0.2900 (1.0374) lr 1.0000e-02 eta 0:25:12
epoch [1/30] batch [200/200] time 0.240 (0.258) data 0.000 (0.005) loss -0.0412 (1.0302) lr 9.9726e-03 eta 0:24:56
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.48it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.37it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.21it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.95it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.09it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.75it/s]100%|██████████| 11/11 [00:02<00:00,  4.09it/s]=> result
* total: 1,036
* correct: 1,014
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 95.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/200] time 0.248 (0.282) data 0.000 (0.029) loss 0.8511 (0.9467) lr 9.9726e-03 eta 0:27:12
epoch [2/30] batch [40/200] time 0.242 (0.264) data 0.000 (0.015) loss 0.8667 (0.9499) lr 9.9726e-03 eta 0:25:21
epoch [2/30] batch [60/200] time 0.242 (0.258) data 0.000 (0.010) loss 1.6904 (1.0665) lr 9.9726e-03 eta 0:24:38
epoch [2/30] batch [80/200] time 0.247 (0.255) data 0.000 (0.007) loss 3.2793 (1.1559) lr 9.9726e-03 eta 0:24:18
epoch [2/30] batch [100/200] time 0.242 (0.253) data 0.000 (0.006) loss 0.0218 (1.1222) lr 9.9726e-03 eta 0:24:02
epoch [2/30] batch [120/200] time 0.247 (0.252) data 0.000 (0.005) loss -0.0155 (1.1033) lr 9.9726e-03 eta 0:23:50
epoch [2/30] batch [140/200] time 0.245 (0.251) data 0.000 (0.004) loss 1.6172 (1.0917) lr 9.9726e-03 eta 0:23:42
epoch [2/30] batch [160/200] time 0.246 (0.250) data 0.000 (0.004) loss 0.0132 (1.0874) lr 9.9726e-03 eta 0:23:32
epoch [2/30] batch [180/200] time 0.240 (0.250) data 0.000 (0.003) loss 0.2493 (1.0889) lr 9.9726e-03 eta 0:23:22
epoch [2/30] batch [200/200] time 0.239 (0.249) data 0.000 (0.003) loss 1.0527 (1.0920) lr 9.8907e-03 eta 0:23:12
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.37s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.55it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.43it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.32it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.16it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.92it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.54it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.05it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.45it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.75it/s]100%|██████████| 11/11 [00:02<00:00,  4.04it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/200] time 0.247 (0.277) data 0.000 (0.027) loss 0.4292 (0.5739) lr 9.8907e-03 eta 0:25:42
epoch [3/30] batch [40/200] time 0.250 (0.262) data 0.000 (0.014) loss 0.6201 (0.6916) lr 9.8907e-03 eta 0:24:14
epoch [3/30] batch [60/200] time 0.242 (0.257) data 0.000 (0.009) loss 0.4272 (0.6881) lr 9.8907e-03 eta 0:23:45
epoch [3/30] batch [80/200] time 0.242 (0.254) data 0.000 (0.007) loss 4.1328 (0.7906) lr 9.8907e-03 eta 0:23:20
epoch [3/30] batch [100/200] time 0.312 (0.252) data 0.000 (0.006) loss -0.0302 (0.7151) lr 9.8907e-03 eta 0:23:08
epoch [3/30] batch [120/200] time 0.244 (0.251) data 0.000 (0.005) loss 2.1094 (0.7917) lr 9.8907e-03 eta 0:22:55
epoch [3/30] batch [140/200] time 0.244 (0.250) data 0.000 (0.004) loss 2.5957 (0.8381) lr 9.8907e-03 eta 0:22:45
epoch [3/30] batch [160/200] time 0.253 (0.249) data 0.000 (0.004) loss 0.3596 (0.8289) lr 9.8907e-03 eta 0:22:36
epoch [3/30] batch [180/200] time 0.241 (0.249) data 0.000 (0.003) loss 1.1123 (0.8751) lr 9.8907e-03 eta 0:22:27
epoch [3/30] batch [200/200] time 0.240 (0.248) data 0.000 (0.003) loss 0.1083 (0.8760) lr 9.7553e-03 eta 0:22:18
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.48it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.37it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.21it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.96it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.08it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.47it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.09it/s]=> result
* total: 1,036
* correct: 1,014
* accuracy: 97.9%
* error: 2.1%
* macro_f1: 95.5%

epoch [4/30] batch [20/200] time 0.247 (0.280) data 0.000 (0.030) loss 3.3730 (1.1536) lr 9.7553e-03 eta 0:25:08
epoch [4/30] batch [40/200] time 0.245 (0.265) data 0.000 (0.015) loss 3.4297 (0.9504) lr 9.7553e-03 eta 0:23:40
epoch [4/30] batch [60/200] time 0.242 (0.258) data 0.000 (0.010) loss 0.3447 (0.9227) lr 9.7553e-03 eta 0:22:57
epoch [4/30] batch [80/200] time 0.245 (0.254) data 0.000 (0.008) loss 0.0164 (0.9038) lr 9.7553e-03 eta 0:22:33
epoch [4/30] batch [100/200] time 0.243 (0.253) data 0.000 (0.006) loss 0.7861 (0.9013) lr 9.7553e-03 eta 0:22:22
epoch [4/30] batch [120/200] time 0.248 (0.252) data 0.000 (0.005) loss 2.1562 (0.9647) lr 9.7553e-03 eta 0:22:10
epoch [4/30] batch [140/200] time 0.243 (0.251) data 0.000 (0.004) loss -0.0014 (0.9762) lr 9.7553e-03 eta 0:21:59
epoch [4/30] batch [160/200] time 0.248 (0.250) data 0.000 (0.004) loss 0.2443 (0.9316) lr 9.7553e-03 eta 0:21:50
epoch [4/30] batch [180/200] time 0.243 (0.249) data 0.000 (0.004) loss 0.3286 (0.9280) lr 9.7553e-03 eta 0:21:41
epoch [4/30] batch [200/200] time 0.240 (0.248) data 0.000 (0.003) loss 0.3635 (0.9413) lr 9.5677e-03 eta 0:21:31
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:11,  1.20s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.74it/s] 27%|██▋       | 3/11 [00:01<00:02,  2.69it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.60it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.44it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.16it/s] 64%|██████▎   | 7/11 [00:01<00:00,  5.75it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.22it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.58it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.85it/s]100%|██████████| 11/11 [00:02<00:00,  4.33it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.2%

epoch [5/30] batch [20/200] time 0.245 (0.276) data 0.000 (0.028) loss -0.0443 (0.8532) lr 9.5677e-03 eta 0:23:49
epoch [5/30] batch [40/200] time 0.247 (0.263) data 0.000 (0.014) loss -0.0148 (1.0225) lr 9.5677e-03 eta 0:22:39
epoch [5/30] batch [60/200] time 0.244 (0.257) data 0.000 (0.010) loss 1.5820 (1.0329) lr 9.5677e-03 eta 0:22:03
epoch [5/30] batch [80/200] time 0.243 (0.255) data 0.000 (0.007) loss 0.9658 (1.0812) lr 9.5677e-03 eta 0:21:43
epoch [5/30] batch [100/200] time 0.248 (0.253) data 0.000 (0.006) loss 0.0341 (1.0676) lr 9.5677e-03 eta 0:21:31
epoch [5/30] batch [120/200] time 0.247 (0.252) data 0.000 (0.005) loss 0.0636 (0.9920) lr 9.5677e-03 eta 0:21:18
epoch [5/30] batch [140/200] time 0.247 (0.251) data 0.000 (0.004) loss -0.0302 (0.9533) lr 9.5677e-03 eta 0:21:09
epoch [5/30] batch [160/200] time 0.246 (0.250) data 0.000 (0.004) loss 0.0007 (0.9230) lr 9.5677e-03 eta 0:21:02
epoch [5/30] batch [180/200] time 0.240 (0.250) data 0.000 (0.003) loss -0.0399 (0.9369) lr 9.5677e-03 eta 0:20:53
epoch [5/30] batch [200/200] time 0.240 (0.249) data 0.000 (0.003) loss 1.0195 (0.9215) lr 9.3301e-03 eta 0:20:43
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.35s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.57it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.46it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.35it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.19it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.94it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.56it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.00it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.41it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.72it/s]100%|██████████| 11/11 [00:02<00:00,  4.07it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.4%

epoch [6/30] batch [20/200] time 0.244 (0.273) data 0.000 (0.027) loss 0.6797 (1.3944) lr 9.3301e-03 eta 0:22:41
epoch [6/30] batch [40/200] time 0.246 (0.262) data 0.000 (0.014) loss 0.4697 (1.1203) lr 9.3301e-03 eta 0:21:37
epoch [6/30] batch [60/200] time 0.242 (0.255) data 0.000 (0.009) loss 0.1567 (1.0751) lr 9.3301e-03 eta 0:21:01
epoch [6/30] batch [80/200] time 0.243 (0.252) data 0.000 (0.007) loss 2.4062 (1.0513) lr 9.3301e-03 eta 0:20:42
epoch [6/30] batch [100/200] time 0.249 (0.251) data 0.000 (0.006) loss -0.0295 (1.0710) lr 9.3301e-03 eta 0:20:31
epoch [6/30] batch [120/200] time 0.248 (0.251) data 0.000 (0.005) loss -0.0559 (0.9860) lr 9.3301e-03 eta 0:20:26
epoch [6/30] batch [140/200] time 0.245 (0.250) data 0.000 (0.004) loss 4.2148 (1.0127) lr 9.3301e-03 eta 0:20:17
epoch [6/30] batch [160/200] time 0.243 (0.250) data 0.000 (0.004) loss 0.1627 (1.0200) lr 9.3301e-03 eta 0:20:09
epoch [6/30] batch [180/200] time 0.241 (0.250) data 0.000 (0.003) loss 0.1282 (0.9654) lr 9.3301e-03 eta 0:20:03
epoch [6/30] batch [200/200] time 0.240 (0.249) data 0.000 (0.003) loss 0.0296 (0.9478) lr 9.0451e-03 eta 0:19:54
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.22s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.72it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.66it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.57it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.41it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.13it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.73it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.20it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.54it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.82it/s]100%|██████████| 11/11 [00:02<00:00,  4.28it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [7/30] batch [20/200] time 0.247 (0.274) data 0.000 (0.027) loss 0.0737 (1.0373) lr 9.0451e-03 eta 0:21:51
epoch [7/30] batch [40/200] time 0.246 (0.259) data 0.000 (0.014) loss 0.0204 (0.7962) lr 9.0451e-03 eta 0:20:34
epoch [7/30] batch [60/200] time 0.246 (0.256) data 0.000 (0.009) loss 0.0833 (0.9060) lr 9.0451e-03 eta 0:20:11
epoch [7/30] batch [80/200] time 0.242 (0.253) data 0.000 (0.007) loss -0.0217 (0.8028) lr 9.0451e-03 eta 0:19:53
epoch [7/30] batch [100/200] time 0.245 (0.251) data 0.000 (0.006) loss -0.0527 (0.7556) lr 9.0451e-03 eta 0:19:41
epoch [7/30] batch [120/200] time 0.253 (0.251) data 0.000 (0.005) loss 2.2930 (0.8140) lr 9.0451e-03 eta 0:19:34
epoch [7/30] batch [140/200] time 0.247 (0.250) data 0.000 (0.004) loss -0.0052 (0.9029) lr 9.0451e-03 eta 0:19:25
epoch [7/30] batch [160/200] time 0.245 (0.250) data 0.000 (0.004) loss -0.0099 (0.9385) lr 9.0451e-03 eta 0:19:17
epoch [7/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss 1.9834 (0.9410) lr 9.0451e-03 eta 0:19:09
epoch [7/30] batch [200/200] time 0.240 (0.248) data 0.000 (0.003) loss 0.6201 (0.9686) lr 8.7157e-03 eta 0:19:00
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.29s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.64it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.55it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.45it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.29it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.03it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.65it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.14it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.52it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.81it/s]100%|██████████| 11/11 [00:02<00:00,  4.18it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.2%

epoch [8/30] batch [20/200] time 0.245 (0.277) data 0.000 (0.027) loss 0.7427 (1.0541) lr 8.7157e-03 eta 0:21:10
epoch [8/30] batch [40/200] time 0.251 (0.263) data 0.000 (0.014) loss 0.5220 (1.0013) lr 8.7157e-03 eta 0:19:58
epoch [8/30] batch [60/200] time 0.246 (0.259) data 0.000 (0.009) loss 0.4763 (1.1038) lr 8.7157e-03 eta 0:19:34
epoch [8/30] batch [80/200] time 0.245 (0.256) data 0.000 (0.007) loss 0.2532 (1.0426) lr 8.7157e-03 eta 0:19:16
epoch [8/30] batch [100/200] time 0.243 (0.254) data 0.000 (0.006) loss 0.0428 (0.9500) lr 8.7157e-03 eta 0:19:02
epoch [8/30] batch [120/200] time 0.244 (0.252) data 0.000 (0.005) loss 0.0445 (0.9193) lr 8.7157e-03 eta 0:18:49
epoch [8/30] batch [140/200] time 0.247 (0.252) data 0.000 (0.004) loss 0.4668 (0.9341) lr 8.7157e-03 eta 0:18:42
epoch [8/30] batch [160/200] time 0.244 (0.251) data 0.000 (0.004) loss 0.6157 (0.8929) lr 8.7157e-03 eta 0:18:34
epoch [8/30] batch [180/200] time 0.301 (0.250) data 0.000 (0.003) loss 2.6152 (0.9296) lr 8.7157e-03 eta 0:18:25
epoch [8/30] batch [200/200] time 0.238 (0.249) data 0.000 (0.003) loss 0.1357 (0.9126) lr 8.3457e-03 eta 0:18:16
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.25s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.68it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.61it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.51it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.35it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.08it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.69it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.18it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.55it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.82it/s]100%|██████████| 11/11 [00:02<00:00,  4.23it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.3%

epoch [9/30] batch [20/200] time 0.246 (0.280) data 0.000 (0.032) loss 2.5020 (1.3051) lr 8.3457e-03 eta 0:20:27
epoch [9/30] batch [40/200] time 0.245 (0.263) data 0.000 (0.016) loss 0.1875 (1.2901) lr 8.3457e-03 eta 0:19:06
epoch [9/30] batch [60/200] time 0.244 (0.257) data 0.000 (0.011) loss 0.9907 (1.0966) lr 8.3457e-03 eta 0:18:37
epoch [9/30] batch [80/200] time 0.245 (0.254) data 0.000 (0.008) loss 0.9932 (1.0646) lr 8.3457e-03 eta 0:18:18
epoch [9/30] batch [100/200] time 0.242 (0.253) data 0.000 (0.007) loss 1.7266 (1.0011) lr 8.3457e-03 eta 0:18:08
epoch [9/30] batch [120/200] time 0.247 (0.252) data 0.000 (0.006) loss 1.1465 (1.0341) lr 8.3457e-03 eta 0:17:57
epoch [9/30] batch [140/200] time 0.243 (0.251) data 0.000 (0.005) loss 1.8525 (1.0053) lr 8.3457e-03 eta 0:17:48
epoch [9/30] batch [160/200] time 0.249 (0.251) data 0.000 (0.004) loss 0.2583 (0.9726) lr 8.3457e-03 eta 0:17:42
epoch [9/30] batch [180/200] time 0.239 (0.250) data 0.000 (0.004) loss 1.1875 (0.9522) lr 8.3457e-03 eta 0:17:33
epoch [9/30] batch [200/200] time 0.241 (0.249) data 0.000 (0.003) loss 0.4014 (0.9434) lr 7.9389e-03 eta 0:17:25
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.48it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.37it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.21it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.96it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.09it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.78it/s]100%|██████████| 11/11 [00:02<00:00,  4.09it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 95.9%

epoch [10/30] batch [20/200] time 0.248 (0.276) data 0.000 (0.027) loss 1.1045 (0.5716) lr 7.9389e-03 eta 0:19:14
epoch [10/30] batch [40/200] time 0.252 (0.264) data 0.000 (0.014) loss 1.7090 (0.7749) lr 7.9389e-03 eta 0:18:20
epoch [10/30] batch [60/200] time 0.247 (0.259) data 0.000 (0.009) loss 1.7480 (0.8586) lr 7.9389e-03 eta 0:17:53
epoch [10/30] batch [80/200] time 0.247 (0.256) data 0.000 (0.007) loss 6.2773 (0.9168) lr 7.9389e-03 eta 0:17:35
epoch [10/30] batch [100/200] time 0.316 (0.255) data 0.000 (0.006) loss -0.0508 (0.8405) lr 7.9389e-03 eta 0:17:25
epoch [10/30] batch [120/200] time 0.242 (0.253) data 0.000 (0.005) loss 1.1729 (0.8676) lr 7.9389e-03 eta 0:17:14
epoch [10/30] batch [140/200] time 0.248 (0.252) data 0.000 (0.004) loss 3.0273 (0.8849) lr 7.9389e-03 eta 0:17:04
epoch [10/30] batch [160/200] time 0.245 (0.252) data 0.000 (0.004) loss 2.5000 (0.8800) lr 7.9389e-03 eta 0:16:57
epoch [10/30] batch [180/200] time 0.240 (0.251) data 0.000 (0.003) loss 2.2422 (0.8892) lr 7.9389e-03 eta 0:16:48
epoch [10/30] batch [200/200] time 0.240 (0.250) data 0.000 (0.003) loss -0.0272 (0.8920) lr 7.5000e-03 eta 0:16:39
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.59it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.48it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.38it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.22it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.96it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.09it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.11it/s]=> result
* total: 1,036
* correct: 1,015
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 95.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/200] time 0.243 (0.276) data 0.000 (0.030) loss 0.5503 (1.1838) lr 7.5000e-03 eta 0:18:18
epoch [11/30] batch [40/200] time 0.242 (0.260) data 0.000 (0.015) loss 0.3354 (1.0602) lr 7.5000e-03 eta 0:17:08
epoch [11/30] batch [60/200] time 0.250 (0.256) data 0.000 (0.010) loss -0.0492 (0.9812) lr 7.5000e-03 eta 0:16:50
epoch [11/30] batch [80/200] time 0.248 (0.254) data 0.000 (0.008) loss 0.0023 (0.9681) lr 7.5000e-03 eta 0:16:35
epoch [11/30] batch [100/200] time 0.244 (0.252) data 0.000 (0.006) loss 1.2109 (0.9359) lr 7.5000e-03 eta 0:16:23
epoch [11/30] batch [120/200] time 0.246 (0.252) data 0.000 (0.005) loss 0.4541 (0.9314) lr 7.5000e-03 eta 0:16:17
epoch [11/30] batch [140/200] time 0.253 (0.251) data 0.000 (0.005) loss 2.8027 (0.9600) lr 7.5000e-03 eta 0:16:09
epoch [11/30] batch [160/200] time 0.250 (0.251) data 0.000 (0.004) loss 0.2141 (0.9389) lr 7.5000e-03 eta 0:16:02
epoch [11/30] batch [180/200] time 0.241 (0.250) data 0.000 (0.004) loss -0.0365 (0.9196) lr 7.5000e-03 eta 0:15:55
epoch [11/30] batch [200/200] time 0.241 (0.249) data 0.000 (0.003) loss 0.7969 (0.9119) lr 7.0337e-03 eta 0:15:46
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.21s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.74it/s] 27%|██▋       | 3/11 [00:01<00:02,  2.68it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.60it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.43it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.16it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.75it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.22it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.58it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.84it/s]100%|██████████| 11/11 [00:02<00:00,  4.33it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.4%

epoch [12/30] batch [20/200] time 0.242 (0.273) data 0.000 (0.027) loss 0.1030 (0.8080) lr 7.0337e-03 eta 0:17:13
epoch [12/30] batch [40/200] time 0.243 (0.261) data 0.000 (0.014) loss 0.1145 (0.8658) lr 7.0337e-03 eta 0:16:20
epoch [12/30] batch [60/200] time 0.243 (0.255) data 0.000 (0.009) loss 1.0635 (0.8240) lr 7.0337e-03 eta 0:15:53
epoch [12/30] batch [80/200] time 0.241 (0.252) data 0.000 (0.007) loss 2.0098 (0.8535) lr 7.0337e-03 eta 0:15:37
epoch [12/30] batch [100/200] time 0.244 (0.251) data 0.000 (0.006) loss 1.1904 (0.8679) lr 7.0337e-03 eta 0:15:30
epoch [12/30] batch [120/200] time 0.245 (0.250) data 0.000 (0.005) loss 0.1163 (0.8635) lr 7.0337e-03 eta 0:15:20
epoch [12/30] batch [140/200] time 0.243 (0.249) data 0.000 (0.004) loss 0.0123 (0.8920) lr 7.0337e-03 eta 0:15:12
epoch [12/30] batch [160/200] time 0.242 (0.249) data 0.000 (0.004) loss 0.8252 (0.8706) lr 7.0337e-03 eta 0:15:05
epoch [12/30] batch [180/200] time 0.238 (0.248) data 0.000 (0.003) loss 1.6514 (0.8986) lr 7.0337e-03 eta 0:14:56
epoch [12/30] batch [200/200] time 0.240 (0.247) data 0.000 (0.003) loss 0.3906 (0.8928) lr 6.5451e-03 eta 0:14:48
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.22s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.72it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.66it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.57it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.41it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.13it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.72it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.19it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.56it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.83it/s]100%|██████████| 11/11 [00:02<00:00,  4.28it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [13/30] batch [20/200] time 0.243 (0.274) data 0.000 (0.028) loss 0.4438 (0.8552) lr 6.5451e-03 eta 0:16:22
epoch [13/30] batch [40/200] time 0.249 (0.262) data 0.000 (0.014) loss 0.7646 (0.7427) lr 6.5451e-03 eta 0:15:32
epoch [13/30] batch [60/200] time 0.241 (0.256) data 0.000 (0.009) loss 2.4453 (0.8265) lr 6.5451e-03 eta 0:15:05
epoch [13/30] batch [80/200] time 0.257 (0.253) data 0.000 (0.007) loss -0.0190 (0.8369) lr 6.5451e-03 eta 0:14:50
epoch [13/30] batch [100/200] time 0.245 (0.252) data 0.000 (0.006) loss 3.3711 (0.8617) lr 6.5451e-03 eta 0:14:42
epoch [13/30] batch [120/200] time 0.246 (0.251) data 0.000 (0.005) loss 1.8242 (0.8557) lr 6.5451e-03 eta 0:14:33
epoch [13/30] batch [140/200] time 0.248 (0.251) data 0.000 (0.004) loss 0.1055 (0.8629) lr 6.5451e-03 eta 0:14:27
epoch [13/30] batch [160/200] time 0.243 (0.250) data 0.000 (0.004) loss 0.0585 (0.8176) lr 6.5451e-03 eta 0:14:20
epoch [13/30] batch [180/200] time 0.241 (0.249) data 0.000 (0.003) loss -0.0525 (0.8269) lr 6.5451e-03 eta 0:14:13
epoch [13/30] batch [200/200] time 0.241 (0.249) data 0.000 (0.003) loss 0.2284 (0.8049) lr 6.0396e-03 eta 0:14:05
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.24s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.70it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.63it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.55it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.38it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.11it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.72it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.19it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.56it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.83it/s]100%|██████████| 11/11 [00:02<00:00,  4.24it/s]=> result
* total: 1,036
* correct: 1,015
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 95.7%

epoch [14/30] batch [20/200] time 0.251 (0.277) data 0.000 (0.027) loss 4.0820 (1.0211) lr 6.0396e-03 eta 0:15:37
epoch [14/30] batch [40/200] time 0.245 (0.264) data 0.000 (0.014) loss -0.0555 (1.0168) lr 6.0396e-03 eta 0:14:45
epoch [14/30] batch [60/200] time 0.245 (0.258) data 0.000 (0.009) loss 1.5898 (0.9068) lr 6.0396e-03 eta 0:14:20
epoch [14/30] batch [80/200] time 0.249 (0.255) data 0.000 (0.007) loss 0.4749 (0.9230) lr 6.0396e-03 eta 0:14:05
epoch [14/30] batch [100/200] time 0.247 (0.254) data 0.000 (0.006) loss 0.6646 (1.0063) lr 6.0396e-03 eta 0:13:57
epoch [14/30] batch [120/200] time 0.246 (0.252) data 0.000 (0.005) loss 0.7021 (0.9301) lr 6.0396e-03 eta 0:13:47
epoch [14/30] batch [140/200] time 0.243 (0.251) data 0.000 (0.004) loss 0.2603 (0.9664) lr 6.0396e-03 eta 0:13:39
epoch [14/30] batch [160/200] time 0.245 (0.251) data 0.000 (0.004) loss 0.8857 (0.9778) lr 6.0396e-03 eta 0:13:32
epoch [14/30] batch [180/200] time 0.245 (0.250) data 0.000 (0.003) loss 0.1549 (0.9755) lr 6.0396e-03 eta 0:13:25
epoch [14/30] batch [200/200] time 0.248 (0.249) data 0.000 (0.003) loss -0.0332 (0.9721) lr 5.5226e-03 eta 0:13:17
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.31s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.62it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.52it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.42it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.26it/s] 55%|█████▍    | 6/11 [00:01<00:01,  5.00it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.62it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.11it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.49it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.79it/s]100%|██████████| 11/11 [00:02<00:00,  4.16it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [15/30] batch [20/200] time 0.246 (0.273) data 0.000 (0.027) loss -0.0556 (0.7451) lr 5.5226e-03 eta 0:14:28
epoch [15/30] batch [40/200] time 0.243 (0.261) data 0.000 (0.014) loss 1.1260 (0.8425) lr 5.5226e-03 eta 0:13:43
epoch [15/30] batch [60/200] time 0.241 (0.255) data 0.000 (0.009) loss 1.0801 (0.7402) lr 5.5226e-03 eta 0:13:20
epoch [15/30] batch [80/200] time 0.246 (0.253) data 0.000 (0.007) loss 0.0782 (0.8421) lr 5.5226e-03 eta 0:13:09
epoch [15/30] batch [100/200] time 0.244 (0.252) data 0.000 (0.006) loss 0.8208 (0.8360) lr 5.5226e-03 eta 0:12:59
epoch [15/30] batch [120/200] time 0.249 (0.250) data 0.000 (0.005) loss 0.0876 (0.8605) lr 5.5226e-03 eta 0:12:51
epoch [15/30] batch [140/200] time 0.245 (0.250) data 0.000 (0.004) loss 0.1382 (0.8409) lr 5.5226e-03 eta 0:12:45
epoch [15/30] batch [160/200] time 0.244 (0.250) data 0.000 (0.004) loss 2.1719 (0.8193) lr 5.5226e-03 eta 0:12:38
epoch [15/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss 1.9053 (0.8445) lr 5.5226e-03 eta 0:12:31
epoch [15/30] batch [200/200] time 0.241 (0.248) data 0.000 (0.003) loss 2.3320 (0.8794) lr 5.0000e-03 eta 0:12:24
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.32s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.60it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.50it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.40it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.23it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.98it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.60it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.10it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.12it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.1%

epoch [16/30] batch [20/200] time 0.243 (0.276) data 0.000 (0.029) loss 0.7520 (0.8825) lr 5.0000e-03 eta 0:13:43
epoch [16/30] batch [40/200] time 0.247 (0.265) data 0.000 (0.015) loss 2.2617 (0.8924) lr 5.0000e-03 eta 0:13:03
epoch [16/30] batch [60/200] time 0.249 (0.259) data 0.000 (0.010) loss 0.0044 (0.7851) lr 5.0000e-03 eta 0:12:41
epoch [16/30] batch [80/200] time 0.306 (0.257) data 0.000 (0.007) loss 0.8364 (0.7663) lr 5.0000e-03 eta 0:12:29
epoch [16/30] batch [100/200] time 0.243 (0.255) data 0.000 (0.006) loss 3.5898 (0.7988) lr 5.0000e-03 eta 0:12:18
epoch [16/30] batch [120/200] time 0.242 (0.253) data 0.000 (0.005) loss 0.6685 (0.7882) lr 5.0000e-03 eta 0:12:08
epoch [16/30] batch [140/200] time 0.246 (0.252) data 0.000 (0.004) loss -0.0602 (0.8188) lr 5.0000e-03 eta 0:11:59
epoch [16/30] batch [160/200] time 0.247 (0.251) data 0.000 (0.004) loss -0.0061 (0.8473) lr 5.0000e-03 eta 0:11:52
epoch [16/30] batch [180/200] time 0.239 (0.250) data 0.000 (0.003) loss 1.7441 (0.8169) lr 5.0000e-03 eta 0:11:44
epoch [16/30] batch [200/200] time 0.239 (0.249) data 0.000 (0.003) loss 2.1797 (0.8344) lr 4.4774e-03 eta 0:11:36
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.33s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.60it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.50it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.39it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.23it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.98it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.60it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.10it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.49it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.78it/s]100%|██████████| 11/11 [00:02<00:00,  4.11it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.1%

epoch [17/30] batch [20/200] time 0.243 (0.275) data 0.000 (0.028) loss 0.0663 (0.8359) lr 4.4774e-03 eta 0:12:44
epoch [17/30] batch [40/200] time 0.242 (0.262) data 0.000 (0.014) loss 0.1406 (0.7977) lr 4.4774e-03 eta 0:12:02
epoch [17/30] batch [60/200] time 0.244 (0.256) data 0.000 (0.009) loss 1.5244 (0.9089) lr 4.4774e-03 eta 0:11:42
epoch [17/30] batch [80/200] time 0.246 (0.254) data 0.000 (0.007) loss 0.6348 (0.7676) lr 4.4774e-03 eta 0:11:30
epoch [17/30] batch [100/200] time 0.247 (0.253) data 0.000 (0.006) loss -0.0542 (0.7495) lr 4.4774e-03 eta 0:11:22
epoch [17/30] batch [120/200] time 0.246 (0.252) data 0.000 (0.005) loss 0.5420 (0.7606) lr 4.4774e-03 eta 0:11:14
epoch [17/30] batch [140/200] time 0.243 (0.251) data 0.000 (0.004) loss 2.1035 (0.7889) lr 4.4774e-03 eta 0:11:06
epoch [17/30] batch [160/200] time 0.241 (0.250) data 0.000 (0.004) loss 0.3733 (0.7951) lr 4.4774e-03 eta 0:10:59
epoch [17/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss 0.6729 (0.7938) lr 4.4774e-03 eta 0:10:52
epoch [17/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss -0.0099 (0.7841) lr 3.9604e-03 eta 0:10:45
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.35s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.47it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.36it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.20it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.95it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.01it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.42it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.73it/s]100%|██████████| 11/11 [00:02<00:00,  4.09it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.0%

epoch [18/30] batch [20/200] time 0.243 (0.275) data 0.000 (0.028) loss 0.3013 (0.5089) lr 3.9604e-03 eta 0:11:49
epoch [18/30] batch [40/200] time 0.242 (0.262) data 0.000 (0.014) loss 3.7402 (0.8722) lr 3.9604e-03 eta 0:11:09
epoch [18/30] batch [60/200] time 0.244 (0.255) data 0.000 (0.009) loss 0.1233 (1.0184) lr 3.9604e-03 eta 0:10:48
epoch [18/30] batch [80/200] time 0.243 (0.253) data 0.000 (0.007) loss 1.3779 (0.9509) lr 3.9604e-03 eta 0:10:36
epoch [18/30] batch [100/200] time 0.243 (0.251) data 0.000 (0.006) loss 0.5410 (0.8915) lr 3.9604e-03 eta 0:10:27
epoch [18/30] batch [120/200] time 0.249 (0.251) data 0.000 (0.005) loss 0.1719 (0.8580) lr 3.9604e-03 eta 0:10:21
epoch [18/30] batch [140/200] time 0.248 (0.250) data 0.000 (0.004) loss 1.0811 (0.8490) lr 3.9604e-03 eta 0:10:14
epoch [18/30] batch [160/200] time 0.249 (0.249) data 0.000 (0.004) loss 0.5713 (0.8602) lr 3.9604e-03 eta 0:10:08
epoch [18/30] batch [180/200] time 0.239 (0.249) data 0.000 (0.003) loss 1.7627 (0.8430) lr 3.9604e-03 eta 0:10:02
epoch [18/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss 0.1326 (0.8662) lr 3.4549e-03 eta 0:09:54
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.26s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.68it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.60it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.51it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.35it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.08it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.68it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.17it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.54it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.82it/s]100%|██████████| 11/11 [00:02<00:00,  4.23it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.1%

epoch [19/30] batch [20/200] time 0.245 (0.275) data 0.000 (0.027) loss 0.1523 (0.4400) lr 3.4549e-03 eta 0:10:54
epoch [19/30] batch [40/200] time 0.244 (0.260) data 0.000 (0.014) loss 1.1016 (0.7275) lr 3.4549e-03 eta 0:10:14
epoch [19/30] batch [60/200] time 0.243 (0.256) data 0.000 (0.009) loss 3.4043 (0.9379) lr 3.4549e-03 eta 0:09:59
epoch [19/30] batch [80/200] time 0.250 (0.254) data 0.000 (0.007) loss 0.4307 (0.9434) lr 3.4549e-03 eta 0:09:49
epoch [19/30] batch [100/200] time 0.244 (0.253) data 0.000 (0.006) loss -0.0350 (0.9216) lr 3.4549e-03 eta 0:09:41
epoch [19/30] batch [120/200] time 0.245 (0.252) data 0.000 (0.005) loss 0.2842 (0.9198) lr 3.4549e-03 eta 0:09:35
epoch [19/30] batch [140/200] time 0.247 (0.252) data 0.000 (0.004) loss -0.0474 (0.9064) lr 3.4549e-03 eta 0:09:28
epoch [19/30] batch [160/200] time 0.242 (0.251) data 0.000 (0.004) loss -0.0178 (0.8613) lr 3.4549e-03 eta 0:09:21
epoch [19/30] batch [180/200] time 0.239 (0.250) data 0.000 (0.003) loss 1.7959 (0.8233) lr 3.4549e-03 eta 0:09:14
epoch [19/30] batch [200/200] time 0.238 (0.249) data 0.000 (0.003) loss -0.0352 (0.7902) lr 2.9663e-03 eta 0:09:07
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.48it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.37it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.21it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.95it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.57it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.08it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.46it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.75it/s]100%|██████████| 11/11 [00:02<00:00,  4.09it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.0%

epoch [20/30] batch [20/200] time 0.242 (0.274) data 0.000 (0.027) loss -0.0253 (0.7342) lr 2.9663e-03 eta 0:09:57
epoch [20/30] batch [40/200] time 0.242 (0.261) data 0.000 (0.014) loss 0.0279 (0.7016) lr 2.9663e-03 eta 0:09:24
epoch [20/30] batch [60/200] time 0.243 (0.255) data 0.000 (0.009) loss 0.9360 (0.6837) lr 2.9663e-03 eta 0:09:06
epoch [20/30] batch [80/200] time 0.247 (0.253) data 0.000 (0.007) loss 1.1797 (0.7571) lr 2.9663e-03 eta 0:08:56
epoch [20/30] batch [100/200] time 0.254 (0.252) data 0.000 (0.006) loss 1.0713 (0.8000) lr 2.9663e-03 eta 0:08:49
epoch [20/30] batch [120/200] time 0.247 (0.251) data 0.000 (0.005) loss 0.0671 (0.7725) lr 2.9663e-03 eta 0:08:43
epoch [20/30] batch [140/200] time 0.244 (0.251) data 0.000 (0.004) loss 0.0593 (0.7700) lr 2.9663e-03 eta 0:08:36
epoch [20/30] batch [160/200] time 0.247 (0.250) data 0.000 (0.004) loss 2.1211 (0.8097) lr 2.9663e-03 eta 0:08:30
epoch [20/30] batch [180/200] time 0.243 (0.249) data 0.000 (0.003) loss 2.8203 (0.7916) lr 2.9663e-03 eta 0:08:23
epoch [20/30] batch [200/200] time 0.244 (0.249) data 0.000 (0.003) loss 3.1641 (0.8192) lr 2.5000e-03 eta 0:08:17
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.27s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.66it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.58it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.49it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.32it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.06it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.67it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.15it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.52it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.80it/s]100%|██████████| 11/11 [00:02<00:00,  4.21it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/200] time 0.246 (0.275) data 0.000 (0.028) loss 2.8223 (0.9775) lr 2.5000e-03 eta 0:09:03
epoch [21/30] batch [40/200] time 0.244 (0.261) data 0.000 (0.014) loss -0.0419 (0.9336) lr 2.5000e-03 eta 0:08:32
epoch [21/30] batch [60/200] time 0.244 (0.255) data 0.000 (0.010) loss -0.0442 (0.9284) lr 2.5000e-03 eta 0:08:15
epoch [21/30] batch [80/200] time 0.243 (0.253) data 0.000 (0.007) loss 0.0345 (0.8585) lr 2.5000e-03 eta 0:08:05
epoch [21/30] batch [100/200] time 0.242 (0.251) data 0.000 (0.006) loss 0.5117 (0.7669) lr 2.5000e-03 eta 0:07:57
epoch [21/30] batch [120/200] time 0.247 (0.251) data 0.000 (0.005) loss 0.0495 (0.8310) lr 2.5000e-03 eta 0:07:50
epoch [21/30] batch [140/200] time 0.243 (0.250) data 0.000 (0.004) loss -0.0573 (0.7793) lr 2.5000e-03 eta 0:07:44
epoch [21/30] batch [160/200] time 0.246 (0.249) data 0.000 (0.004) loss 1.2666 (0.8056) lr 2.5000e-03 eta 0:07:38
epoch [21/30] batch [180/200] time 0.239 (0.248) data 0.000 (0.003) loss 2.0918 (0.7943) lr 2.5000e-03 eta 0:07:31
epoch [21/30] batch [200/200] time 0.239 (0.247) data 0.000 (0.003) loss 0.1223 (0.7968) lr 2.0611e-03 eta 0:07:25
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.48it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.37it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.21it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.95it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.08it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.47it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.76it/s]100%|██████████| 11/11 [00:02<00:00,  4.10it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.3%

epoch [22/30] batch [20/200] time 0.248 (0.275) data 0.000 (0.028) loss 0.1108 (0.8676) lr 2.0611e-03 eta 0:08:09
epoch [22/30] batch [40/200] time 0.245 (0.262) data 0.000 (0.014) loss -0.0290 (0.9126) lr 2.0611e-03 eta 0:07:41
epoch [22/30] batch [60/200] time 0.244 (0.257) data 0.000 (0.009) loss 2.0859 (0.9474) lr 2.0611e-03 eta 0:07:26
epoch [22/30] batch [80/200] time 0.306 (0.254) data 0.000 (0.007) loss 0.1907 (1.0103) lr 2.0611e-03 eta 0:07:17
epoch [22/30] batch [100/200] time 0.244 (0.252) data 0.000 (0.006) loss 0.3149 (0.9756) lr 2.0611e-03 eta 0:07:09
epoch [22/30] batch [120/200] time 0.243 (0.251) data 0.000 (0.005) loss 0.6030 (0.9846) lr 2.0611e-03 eta 0:07:01
epoch [22/30] batch [140/200] time 0.243 (0.250) data 0.000 (0.004) loss 0.9468 (0.9302) lr 2.0611e-03 eta 0:06:55
epoch [22/30] batch [160/200] time 0.249 (0.249) data 0.000 (0.004) loss 1.5049 (0.9524) lr 2.0611e-03 eta 0:06:49
epoch [22/30] batch [180/200] time 0.241 (0.249) data 0.000 (0.003) loss 2.3359 (0.9777) lr 2.0611e-03 eta 0:06:43
epoch [22/30] batch [200/200] time 0.241 (0.248) data 0.000 (0.003) loss 4.2344 (0.9818) lr 1.6543e-03 eta 0:06:36
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.28s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.65it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.56it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.47it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.30it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.04it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.65it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.14it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.52it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.80it/s]100%|██████████| 11/11 [00:02<00:00,  4.20it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [23/30] batch [20/200] time 0.243 (0.276) data 0.000 (0.027) loss 0.2688 (1.0417) lr 1.6543e-03 eta 0:07:15
epoch [23/30] batch [40/200] time 0.245 (0.263) data 0.000 (0.014) loss 2.9004 (1.0993) lr 1.6543e-03 eta 0:06:50
epoch [23/30] batch [60/200] time 0.247 (0.258) data 0.000 (0.009) loss 0.0593 (1.0571) lr 1.6543e-03 eta 0:06:37
epoch [23/30] batch [80/200] time 0.248 (0.255) data 0.000 (0.007) loss 0.7603 (0.9266) lr 1.6543e-03 eta 0:06:27
epoch [23/30] batch [100/200] time 0.250 (0.254) data 0.000 (0.006) loss 0.1390 (0.8574) lr 1.6543e-03 eta 0:06:20
epoch [23/30] batch [120/200] time 0.245 (0.253) data 0.000 (0.005) loss 1.6016 (0.7960) lr 1.6543e-03 eta 0:06:14
epoch [23/30] batch [140/200] time 0.244 (0.252) data 0.000 (0.004) loss 6.3125 (0.8578) lr 1.6543e-03 eta 0:06:08
epoch [23/30] batch [160/200] time 0.250 (0.252) data 0.000 (0.004) loss 1.5488 (0.8799) lr 1.6543e-03 eta 0:06:02
epoch [23/30] batch [180/200] time 0.240 (0.251) data 0.000 (0.003) loss 0.5825 (0.8966) lr 1.6543e-03 eta 0:05:56
epoch [23/30] batch [200/200] time 0.240 (0.250) data 0.000 (0.003) loss 0.5405 (0.8806) lr 1.2843e-03 eta 0:05:49
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.32s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.61it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.51it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.40it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.24it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.98it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.60it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.10it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.13it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.3%

epoch [24/30] batch [20/200] time 0.250 (0.276) data 0.001 (0.027) loss 1.4141 (0.9216) lr 1.2843e-03 eta 0:06:20
epoch [24/30] batch [40/200] time 0.245 (0.262) data 0.000 (0.014) loss 1.5098 (1.0360) lr 1.2843e-03 eta 0:05:55
epoch [24/30] batch [60/200] time 0.248 (0.258) data 0.000 (0.009) loss 0.0350 (0.8972) lr 1.2843e-03 eta 0:05:46
epoch [24/30] batch [80/200] time 0.251 (0.256) data 0.000 (0.007) loss -0.0335 (0.8141) lr 1.2843e-03 eta 0:05:37
epoch [24/30] batch [100/200] time 0.247 (0.254) data 0.000 (0.006) loss 0.1088 (0.7790) lr 1.2843e-03 eta 0:05:29
epoch [24/30] batch [120/200] time 0.247 (0.253) data 0.000 (0.005) loss 0.0694 (0.8059) lr 1.2843e-03 eta 0:05:24
epoch [24/30] batch [140/200] time 0.247 (0.253) data 0.000 (0.004) loss 0.5303 (0.7690) lr 1.2843e-03 eta 0:05:18
epoch [24/30] batch [160/200] time 0.243 (0.251) data 0.000 (0.004) loss 0.5967 (0.7687) lr 1.2843e-03 eta 0:05:11
epoch [24/30] batch [180/200] time 0.239 (0.250) data 0.000 (0.003) loss -0.0419 (0.8213) lr 1.2843e-03 eta 0:05:05
epoch [24/30] batch [200/200] time 0.239 (0.249) data 0.000 (0.003) loss 0.5073 (0.7980) lr 9.5492e-04 eta 0:04:59
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.22s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.72it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.65it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.57it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.41it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.13it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.73it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.20it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.57it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.84it/s]100%|██████████| 11/11 [00:02<00:00,  4.29it/s]=> result
* total: 1,036
* correct: 1,015
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 95.8%

epoch [25/30] batch [20/200] time 0.243 (0.274) data 0.000 (0.027) loss 0.0077 (0.4997) lr 9.5492e-04 eta 0:05:23
epoch [25/30] batch [40/200] time 0.247 (0.262) data 0.000 (0.014) loss 0.3179 (0.7115) lr 9.5492e-04 eta 0:05:04
epoch [25/30] batch [60/200] time 0.245 (0.257) data 0.000 (0.009) loss -0.0377 (0.7896) lr 9.5492e-04 eta 0:04:52
epoch [25/30] batch [80/200] time 0.244 (0.254) data 0.000 (0.007) loss 1.9102 (0.7284) lr 9.5492e-04 eta 0:04:44
epoch [25/30] batch [100/200] time 0.244 (0.253) data 0.000 (0.006) loss 1.3604 (0.7876) lr 9.5492e-04 eta 0:04:38
epoch [25/30] batch [120/200] time 0.249 (0.252) data 0.000 (0.005) loss 0.0357 (0.8042) lr 9.5492e-04 eta 0:04:32
epoch [25/30] batch [140/200] time 0.249 (0.251) data 0.000 (0.004) loss -0.0601 (0.7924) lr 9.5492e-04 eta 0:04:26
epoch [25/30] batch [160/200] time 0.249 (0.251) data 0.000 (0.004) loss -0.0084 (0.7821) lr 9.5492e-04 eta 0:04:21
epoch [25/30] batch [180/200] time 0.240 (0.250) data 0.000 (0.003) loss 0.1899 (0.7722) lr 9.5492e-04 eta 0:04:15
epoch [25/30] batch [200/200] time 0.242 (0.250) data 0.000 (0.003) loss 4.1406 (0.7911) lr 6.6987e-04 eta 0:04:09
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.23s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.71it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.64it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.55it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.39it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.11it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.71it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.19it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.55it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.83it/s]100%|██████████| 11/11 [00:02<00:00,  4.27it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.1%

epoch [26/30] batch [20/200] time 0.248 (0.273) data 0.000 (0.027) loss 0.2253 (0.7394) lr 6.6987e-04 eta 0:04:27
epoch [26/30] batch [40/200] time 0.243 (0.261) data 0.000 (0.014) loss -0.0436 (0.8282) lr 6.6987e-04 eta 0:04:10
epoch [26/30] batch [60/200] time 0.246 (0.255) data 0.000 (0.009) loss 0.1833 (0.7298) lr 6.6987e-04 eta 0:03:59
epoch [26/30] batch [80/200] time 0.247 (0.253) data 0.000 (0.007) loss 1.6885 (0.8668) lr 6.6987e-04 eta 0:03:52
epoch [26/30] batch [100/200] time 0.246 (0.251) data 0.000 (0.006) loss 0.7002 (0.8816) lr 6.6987e-04 eta 0:03:46
epoch [26/30] batch [120/200] time 0.244 (0.251) data 0.000 (0.005) loss 1.1035 (0.9051) lr 6.6987e-04 eta 0:03:40
epoch [26/30] batch [140/200] time 0.244 (0.250) data 0.000 (0.004) loss 1.9756 (0.8790) lr 6.6987e-04 eta 0:03:34
epoch [26/30] batch [160/200] time 0.245 (0.249) data 0.000 (0.004) loss -0.0193 (0.8695) lr 6.6987e-04 eta 0:03:29
epoch [26/30] batch [180/200] time 0.238 (0.249) data 0.000 (0.003) loss 1.0146 (0.8561) lr 6.6987e-04 eta 0:03:23
epoch [26/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss -0.0448 (0.8257) lr 4.3227e-04 eta 0:03:18
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.28s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.65it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.56it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.46it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.30it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.04it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.65it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.14it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.52it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.80it/s]100%|██████████| 11/11 [00:02<00:00,  4.18it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [27/30] batch [20/200] time 0.246 (0.279) data 0.000 (0.029) loss 0.9565 (1.1223) lr 4.3227e-04 eta 0:03:37
epoch [27/30] batch [40/200] time 0.246 (0.264) data 0.000 (0.015) loss 0.0756 (1.0271) lr 4.3227e-04 eta 0:03:20
epoch [27/30] batch [60/200] time 0.244 (0.258) data 0.000 (0.010) loss 2.2148 (0.8730) lr 4.3227e-04 eta 0:03:10
epoch [27/30] batch [80/200] time 0.244 (0.255) data 0.000 (0.007) loss 0.1401 (0.8349) lr 4.3227e-04 eta 0:03:03
epoch [27/30] batch [100/200] time 0.242 (0.254) data 0.000 (0.006) loss 1.3730 (0.8345) lr 4.3227e-04 eta 0:02:57
epoch [27/30] batch [120/200] time 0.247 (0.253) data 0.000 (0.005) loss -0.0366 (0.8280) lr 4.3227e-04 eta 0:02:51
epoch [27/30] batch [140/200] time 0.244 (0.251) data 0.000 (0.004) loss 3.5996 (0.8527) lr 4.3227e-04 eta 0:02:45
epoch [27/30] batch [160/200] time 0.243 (0.251) data 0.000 (0.004) loss 2.1562 (0.8105) lr 4.3227e-04 eta 0:02:40
epoch [27/30] batch [180/200] time 0.239 (0.250) data 0.000 (0.003) loss -0.0284 (0.7715) lr 4.3227e-04 eta 0:02:34
epoch [27/30] batch [200/200] time 0.239 (0.249) data 0.000 (0.003) loss 1.8164 (0.8023) lr 2.4472e-04 eta 0:02:29
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.23s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.71it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.64it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.55it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.39it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.12it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.72it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.20it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.56it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.84it/s]100%|██████████| 11/11 [00:02<00:00,  4.27it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [28/30] batch [20/200] time 0.245 (0.276) data 0.000 (0.028) loss 0.8711 (0.5951) lr 2.4472e-04 eta 0:02:40
epoch [28/30] batch [40/200] time 0.246 (0.264) data 0.000 (0.014) loss 0.1219 (0.5915) lr 2.4472e-04 eta 0:02:27
epoch [28/30] batch [60/200] time 0.244 (0.258) data 0.000 (0.009) loss 0.4810 (0.7732) lr 2.4472e-04 eta 0:02:19
epoch [28/30] batch [80/200] time 0.253 (0.255) data 0.000 (0.007) loss -0.0434 (0.6823) lr 2.4472e-04 eta 0:02:12
epoch [28/30] batch [100/200] time 0.247 (0.254) data 0.000 (0.006) loss 0.1432 (0.7587) lr 2.4472e-04 eta 0:02:07
epoch [28/30] batch [120/200] time 0.247 (0.253) data 0.000 (0.005) loss 1.1953 (0.7280) lr 2.4472e-04 eta 0:02:01
epoch [28/30] batch [140/200] time 0.247 (0.253) data 0.000 (0.004) loss 0.6172 (0.7287) lr 2.4472e-04 eta 0:01:56
epoch [28/30] batch [160/200] time 0.246 (0.252) data 0.000 (0.004) loss 1.6758 (0.7783) lr 2.4472e-04 eta 0:01:50
epoch [28/30] batch [180/200] time 0.240 (0.251) data 0.000 (0.003) loss 4.1875 (0.8028) lr 2.4472e-04 eta 0:01:45
epoch [28/30] batch [200/200] time 0.240 (0.250) data 0.000 (0.003) loss -0.0424 (0.7949) lr 1.0926e-04 eta 0:01:40
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.22s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.70it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.64it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.55it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.38it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.11it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.71it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.18it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.55it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.82it/s]100%|██████████| 11/11 [00:02<00:00,  4.25it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [29/30] batch [20/200] time 0.247 (0.275) data 0.000 (0.028) loss -0.0549 (0.4792) lr 1.0926e-04 eta 0:01:44
epoch [29/30] batch [40/200] time 0.245 (0.261) data 0.000 (0.014) loss 1.2129 (0.7126) lr 1.0926e-04 eta 0:01:34
epoch [29/30] batch [60/200] time 0.242 (0.256) data 0.000 (0.009) loss 0.0938 (0.7596) lr 1.0926e-04 eta 0:01:27
epoch [29/30] batch [80/200] time 0.245 (0.253) data 0.000 (0.007) loss 0.7568 (0.8504) lr 1.0926e-04 eta 0:01:20
epoch [29/30] batch [100/200] time 0.243 (0.252) data 0.000 (0.006) loss 0.6958 (0.8381) lr 1.0926e-04 eta 0:01:15
epoch [29/30] batch [120/200] time 0.242 (0.251) data 0.000 (0.005) loss 0.4595 (0.7786) lr 1.0926e-04 eta 0:01:10
epoch [29/30] batch [140/200] time 0.245 (0.250) data 0.000 (0.004) loss 1.9893 (0.8165) lr 1.0926e-04 eta 0:01:05
epoch [29/30] batch [160/200] time 0.243 (0.250) data 0.000 (0.004) loss 0.4192 (0.8005) lr 1.0926e-04 eta 0:00:59
epoch [29/30] batch [180/200] time 0.238 (0.249) data 0.000 (0.003) loss -0.0473 (0.7674) lr 1.0926e-04 eta 0:00:54
epoch [29/30] batch [200/200] time 0.238 (0.248) data 0.000 (0.003) loss 0.3555 (0.7826) lr 2.7391e-05 eta 0:00:49
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.20s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.72it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.66it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.58it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.41it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.14it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.74it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.21it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.57it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.85it/s]100%|██████████| 11/11 [00:02<00:00,  4.30it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [30/30] batch [20/200] time 0.247 (0.276) data 0.000 (0.028) loss 2.8887 (0.8328) lr 2.7391e-05 eta 0:00:49
epoch [30/30] batch [40/200] time 0.243 (0.261) data 0.000 (0.014) loss 0.1804 (0.7647) lr 2.7391e-05 eta 0:00:41
epoch [30/30] batch [60/200] time 0.244 (0.256) data 0.000 (0.009) loss 0.9326 (0.7885) lr 2.7391e-05 eta 0:00:35
epoch [30/30] batch [80/200] time 0.249 (0.255) data 0.000 (0.007) loss -0.0396 (0.7616) lr 2.7391e-05 eta 0:00:30
epoch [30/30] batch [100/200] time 0.246 (0.253) data 0.000 (0.006) loss 0.0989 (0.8085) lr 2.7391e-05 eta 0:00:25
epoch [30/30] batch [120/200] time 0.243 (0.252) data 0.000 (0.005) loss 0.1975 (0.7574) lr 2.7391e-05 eta 0:00:20
epoch [30/30] batch [140/200] time 0.243 (0.251) data 0.000 (0.004) loss -0.0564 (0.7501) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [160/200] time 0.247 (0.251) data 0.000 (0.004) loss 0.4719 (0.7379) lr 2.7391e-05 eta 0:00:10
epoch [30/30] batch [180/200] time 0.240 (0.250) data 0.000 (0.003) loss 0.0881 (0.7746) lr 2.7391e-05 eta 0:00:04
epoch [30/30] batch [200/200] time 0.239 (0.249) data 0.000 (0.003) loss -0.0509 (0.8039) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.35s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.47it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.37it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.21it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.95it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.58it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.09it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.78it/s]100%|██████████| 11/11 [00:02<00:00,  4.10it/s]
=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 2)
Evaluate on the *test* set
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:23,  1.54s/it] 12%|█▎        | 2/16 [00:01<00:09,  1.41it/s] 19%|█▉        | 3/16 [00:01<00:05,  2.24it/s] 25%|██▌       | 4/16 [00:01<00:03,  3.10it/s] 31%|███▏      | 5/16 [00:02<00:02,  3.93it/s] 38%|███▊      | 6/16 [00:02<00:02,  4.70it/s] 44%|████▍     | 7/16 [00:02<00:01,  5.36it/s] 50%|█████     | 8/16 [00:02<00:01,  5.90it/s] 56%|█████▋    | 9/16 [00:02<00:01,  6.33it/s] 62%|██████▎   | 10/16 [00:02<00:00,  6.66it/s] 69%|██████▉   | 11/16 [00:02<00:00,  6.90it/s] 75%|███████▌  | 12/16 [00:02<00:00,  7.08it/s] 81%|████████▏ | 13/16 [00:03<00:00,  7.21it/s] 88%|████████▊ | 14/16 [00:03<00:00,  7.30it/s] 94%|█████████▍| 15/16 [00:03<00:00,  7.37it/s]100%|██████████| 16/16 [00:03<00:00,  4.50it/s]
=> result
* total: 1,549
* correct: 1,520
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.3%
Elapsed: 0:26:20
+ sh scripts/rpo_prime/base2new_test_sdl.sh caltech101 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
800 613 916
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      613
# test     916
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 2)
Evaluate on the *test* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:02<00:26,  2.98s/it] 20%|██        | 2/10 [00:03<00:10,  1.31s/it] 30%|███       | 3/10 [00:03<00:05,  1.30it/s] 40%|████      | 4/10 [00:03<00:03,  1.93it/s] 50%|█████     | 5/10 [00:03<00:01,  2.64it/s] 60%|██████    | 6/10 [00:03<00:01,  3.39it/s] 70%|███████   | 7/10 [00:03<00:00,  4.13it/s] 80%|████████  | 8/10 [00:03<00:00,  4.83it/s] 90%|█████████ | 9/10 [00:04<00:00,  5.45it/s]100%|██████████| 10/10 [00:04<00:00,  2.40it/s]
=> result
* total: 916
* correct: 861
* accuracy: 94.0%
* error: 6.0%
* macro_f1: 94.2%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh caltech101 3 0 main_tmp1_0.1sdl 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
800 1036 1549
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      1,036
# test     1,549
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/200] time 0.241 (0.359) data 0.000 (0.048) loss 1.9648 (1.5914) lr 1.0000e-02 eta 0:35:48
epoch [1/30] batch [40/200] time 0.246 (0.302) data 0.000 (0.024) loss 0.9702 (1.4355) lr 1.0000e-02 eta 0:30:01
epoch [1/30] batch [60/200] time 0.247 (0.284) data 0.000 (0.016) loss 1.0059 (1.0991) lr 1.0000e-02 eta 0:28:06
epoch [1/30] batch [80/200] time 0.241 (0.276) data 0.000 (0.012) loss 1.1377 (1.2027) lr 1.0000e-02 eta 0:27:11
epoch [1/30] batch [100/200] time 0.243 (0.270) data 0.000 (0.010) loss 3.9043 (1.3163) lr 1.0000e-02 eta 0:26:31
epoch [1/30] batch [120/200] time 0.243 (0.266) data 0.000 (0.008) loss 0.2374 (1.2693) lr 1.0000e-02 eta 0:26:02
epoch [1/30] batch [140/200] time 0.246 (0.263) data 0.000 (0.007) loss 0.0844 (1.2212) lr 1.0000e-02 eta 0:25:40
epoch [1/30] batch [160/200] time 0.245 (0.261) data 0.000 (0.006) loss -0.0510 (1.1915) lr 1.0000e-02 eta 0:25:26
epoch [1/30] batch [180/200] time 0.242 (0.260) data 0.000 (0.006) loss 0.9053 (1.1889) lr 1.0000e-02 eta 0:25:10
epoch [1/30] batch [200/200] time 0.253 (0.258) data 0.000 (0.005) loss 1.4072 (1.1665) lr 9.9726e-03 eta 0:24:55
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.35s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.57it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.46it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.35it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.19it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.94it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.57it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.07it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.46it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.76it/s]100%|██████████| 11/11 [00:02<00:00,  4.06it/s]=> result
* total: 1,036
* correct: 1,015
* accuracy: 98.0%
* error: 2.0%
* macro_f1: 95.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/200] time 0.245 (0.283) data 0.000 (0.029) loss -0.0204 (0.8559) lr 9.9726e-03 eta 0:27:13
epoch [2/30] batch [40/200] time 0.244 (0.265) data 0.000 (0.014) loss 0.7593 (1.0279) lr 9.9726e-03 eta 0:25:26
epoch [2/30] batch [60/200] time 0.243 (0.259) data 0.000 (0.010) loss 1.1592 (0.9890) lr 9.9726e-03 eta 0:24:44
epoch [2/30] batch [80/200] time 0.244 (0.256) data 0.000 (0.007) loss 3.6621 (1.0614) lr 9.9726e-03 eta 0:24:26
epoch [2/30] batch [100/200] time 0.244 (0.254) data 0.000 (0.006) loss 1.1758 (1.0046) lr 9.9726e-03 eta 0:24:08
epoch [2/30] batch [120/200] time 0.243 (0.253) data 0.000 (0.005) loss 0.0162 (1.0541) lr 9.9726e-03 eta 0:23:55
epoch [2/30] batch [140/200] time 0.244 (0.252) data 0.000 (0.004) loss -0.0182 (1.1344) lr 9.9726e-03 eta 0:23:44
epoch [2/30] batch [160/200] time 0.242 (0.251) data 0.000 (0.004) loss 1.8594 (1.1285) lr 9.9726e-03 eta 0:23:35
epoch [2/30] batch [180/200] time 0.238 (0.250) data 0.000 (0.003) loss 0.0984 (1.0866) lr 9.9726e-03 eta 0:23:24
epoch [2/30] batch [200/200] time 0.239 (0.249) data 0.000 (0.003) loss 2.6875 (1.0943) lr 9.8907e-03 eta 0:23:12
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.35s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.46it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.36it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.19it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.94it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.56it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.07it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.45it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.75it/s]100%|██████████| 11/11 [00:02<00:00,  4.07it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/200] time 0.248 (0.276) data 0.000 (0.028) loss 0.5703 (1.2338) lr 9.8907e-03 eta 0:25:42
epoch [3/30] batch [40/200] time 0.246 (0.264) data 0.000 (0.014) loss 3.2559 (1.1188) lr 9.8907e-03 eta 0:24:26
epoch [3/30] batch [60/200] time 0.246 (0.258) data 0.000 (0.009) loss 1.4561 (1.0083) lr 9.8907e-03 eta 0:23:48
epoch [3/30] batch [80/200] time 0.243 (0.255) data 0.000 (0.007) loss 2.3594 (1.1719) lr 9.8907e-03 eta 0:23:25
epoch [3/30] batch [100/200] time 0.244 (0.253) data 0.000 (0.006) loss 1.8369 (1.1083) lr 9.8907e-03 eta 0:23:10
epoch [3/30] batch [120/200] time 0.248 (0.252) data 0.000 (0.005) loss -0.0172 (1.0944) lr 9.8907e-03 eta 0:23:03
epoch [3/30] batch [140/200] time 0.242 (0.251) data 0.000 (0.004) loss 1.8809 (1.0617) lr 9.8907e-03 eta 0:22:51
epoch [3/30] batch [160/200] time 0.306 (0.251) data 0.000 (0.004) loss 1.3252 (1.0719) lr 9.8907e-03 eta 0:22:44
epoch [3/30] batch [180/200] time 0.241 (0.250) data 0.000 (0.003) loss 0.0154 (1.1139) lr 9.8907e-03 eta 0:22:35
epoch [3/30] batch [200/200] time 0.240 (0.249) data 0.000 (0.003) loss 3.0566 (1.0989) lr 9.7553e-03 eta 0:22:24
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.22s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.72it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.66it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.57it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.41it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.12it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.72it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.19it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.56it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.83it/s]100%|██████████| 11/11 [00:02<00:00,  4.28it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/200] time 0.254 (0.278) data 0.000 (0.028) loss 0.1361 (1.1351) lr 9.7553e-03 eta 0:24:57
epoch [4/30] batch [40/200] time 0.244 (0.262) data 0.000 (0.014) loss 1.9990 (0.9615) lr 9.7553e-03 eta 0:23:24
epoch [4/30] batch [60/200] time 0.247 (0.258) data 0.000 (0.009) loss 1.5156 (0.9272) lr 9.7553e-03 eta 0:22:58
epoch [4/30] batch [80/200] time 0.246 (0.256) data 0.000 (0.007) loss 0.0634 (0.9510) lr 9.7553e-03 eta 0:22:40
epoch [4/30] batch [100/200] time 0.247 (0.254) data 0.000 (0.006) loss 2.7656 (0.9874) lr 9.7553e-03 eta 0:22:25
epoch [4/30] batch [120/200] time 0.245 (0.253) data 0.000 (0.005) loss 0.4832 (1.0037) lr 9.7553e-03 eta 0:22:16
epoch [4/30] batch [140/200] time 0.243 (0.252) data 0.000 (0.004) loss 1.9297 (1.0264) lr 9.7553e-03 eta 0:22:06
epoch [4/30] batch [160/200] time 0.244 (0.251) data 0.000 (0.004) loss 1.5615 (1.0716) lr 9.7553e-03 eta 0:21:56
epoch [4/30] batch [180/200] time 0.242 (0.250) data 0.000 (0.003) loss 1.3564 (1.0452) lr 9.7553e-03 eta 0:21:46
epoch [4/30] batch [200/200] time 0.240 (0.249) data 0.000 (0.003) loss 0.5337 (1.0409) lr 9.5677e-03 eta 0:21:37
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.25s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.68it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.60it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.51it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.35it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.07it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.68it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.16it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.52it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.78it/s]100%|██████████| 11/11 [00:02<00:00,  4.22it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/200] time 0.242 (0.277) data 0.000 (0.028) loss 0.0266 (1.0804) lr 9.5677e-03 eta 0:23:54
epoch [5/30] batch [40/200] time 0.250 (0.260) data 0.000 (0.014) loss 0.5044 (0.9499) lr 9.5677e-03 eta 0:22:24
epoch [5/30] batch [60/200] time 0.242 (0.257) data 0.000 (0.010) loss 3.0020 (0.9386) lr 9.5677e-03 eta 0:22:00
epoch [5/30] batch [80/200] time 0.243 (0.254) data 0.000 (0.007) loss 1.5088 (0.9960) lr 9.5677e-03 eta 0:21:38
epoch [5/30] batch [100/200] time 0.244 (0.252) data 0.000 (0.006) loss 1.1162 (0.9176) lr 9.5677e-03 eta 0:21:22
epoch [5/30] batch [120/200] time 0.243 (0.250) data 0.000 (0.005) loss 0.4871 (0.9090) lr 9.5677e-03 eta 0:21:11
epoch [5/30] batch [140/200] time 0.244 (0.250) data 0.000 (0.004) loss 1.1338 (0.9188) lr 9.5677e-03 eta 0:21:03
epoch [5/30] batch [160/200] time 0.243 (0.249) data 0.000 (0.004) loss -0.0026 (0.9321) lr 9.5677e-03 eta 0:20:55
epoch [5/30] batch [180/200] time 0.307 (0.249) data 0.000 (0.003) loss -0.0249 (0.9791) lr 9.5677e-03 eta 0:20:47
epoch [5/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss 0.5200 (0.9862) lr 9.3301e-03 eta 0:20:37
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.32s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.61it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.51it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.41it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.23it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.97it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.59it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.09it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.12it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.4%

epoch [6/30] batch [20/200] time 0.245 (0.276) data 0.000 (0.031) loss 0.0962 (0.8740) lr 9.3301e-03 eta 0:22:56
epoch [6/30] batch [40/200] time 0.242 (0.260) data 0.000 (0.015) loss 0.2452 (1.0809) lr 9.3301e-03 eta 0:21:29
epoch [6/30] batch [60/200] time 0.247 (0.255) data 0.000 (0.010) loss 0.1241 (1.0477) lr 9.3301e-03 eta 0:20:57
epoch [6/30] batch [80/200] time 0.242 (0.253) data 0.000 (0.008) loss 0.1790 (0.9517) lr 9.3301e-03 eta 0:20:45
epoch [6/30] batch [100/200] time 0.241 (0.251) data 0.000 (0.006) loss 3.1289 (0.9121) lr 9.3301e-03 eta 0:20:31
epoch [6/30] batch [120/200] time 0.245 (0.250) data 0.000 (0.005) loss 1.9502 (0.9443) lr 9.3301e-03 eta 0:20:21
epoch [6/30] batch [140/200] time 0.251 (0.250) data 0.000 (0.005) loss 1.9795 (0.9260) lr 9.3301e-03 eta 0:20:14
epoch [6/30] batch [160/200] time 0.243 (0.249) data 0.000 (0.004) loss 0.0824 (0.8760) lr 9.3301e-03 eta 0:20:06
epoch [6/30] batch [180/200] time 0.239 (0.248) data 0.000 (0.004) loss 0.7676 (0.8663) lr 9.3301e-03 eta 0:19:57
epoch [6/30] batch [200/200] time 0.239 (0.247) data 0.000 (0.003) loss 0.1375 (0.8513) lr 9.0451e-03 eta 0:19:47
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.27s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.66it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.57it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.48it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.31it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.04it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.65it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.14it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.52it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.79it/s]100%|██████████| 11/11 [00:02<00:00,  4.18it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.4%

epoch [7/30] batch [20/200] time 0.252 (0.284) data 0.000 (0.032) loss 2.4375 (1.0704) lr 9.0451e-03 eta 0:22:35
epoch [7/30] batch [40/200] time 0.250 (0.267) data 0.000 (0.016) loss 4.6328 (1.1395) lr 9.0451e-03 eta 0:21:09
epoch [7/30] batch [60/200] time 0.246 (0.260) data 0.000 (0.011) loss 3.9023 (1.1220) lr 9.0451e-03 eta 0:20:31
epoch [7/30] batch [80/200] time 0.246 (0.256) data 0.000 (0.008) loss 3.1953 (1.1145) lr 9.0451e-03 eta 0:20:10
epoch [7/30] batch [100/200] time 0.248 (0.255) data 0.000 (0.007) loss 0.0393 (1.0996) lr 9.0451e-03 eta 0:19:57
epoch [7/30] batch [120/200] time 0.243 (0.253) data 0.000 (0.006) loss 0.7271 (1.0308) lr 9.0451e-03 eta 0:19:44
epoch [7/30] batch [140/200] time 0.247 (0.252) data 0.000 (0.005) loss 0.6177 (1.0300) lr 9.0451e-03 eta 0:19:35
epoch [7/30] batch [160/200] time 0.254 (0.252) data 0.000 (0.004) loss 0.0798 (0.9763) lr 9.0451e-03 eta 0:19:28
epoch [7/30] batch [180/200] time 0.244 (0.251) data 0.000 (0.004) loss 0.2366 (0.9667) lr 9.0451e-03 eta 0:19:19
epoch [7/30] batch [200/200] time 0.242 (0.250) data 0.000 (0.003) loss 1.0762 (0.9569) lr 8.7157e-03 eta 0:19:10
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.31s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.61it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.51it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.41it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.25it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.99it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.61it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.10it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.49it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.78it/s]100%|██████████| 11/11 [00:02<00:00,  4.12it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/200] time 0.244 (0.277) data 0.000 (0.029) loss 0.1519 (0.5065) lr 8.7157e-03 eta 0:21:09
epoch [8/30] batch [40/200] time 0.248 (0.263) data 0.000 (0.015) loss 3.2617 (0.6676) lr 8.7157e-03 eta 0:20:00
epoch [8/30] batch [60/200] time 0.242 (0.257) data 0.000 (0.010) loss 0.1398 (0.6184) lr 8.7157e-03 eta 0:19:24
epoch [8/30] batch [80/200] time 0.243 (0.253) data 0.000 (0.008) loss 0.3472 (0.9551) lr 8.7157e-03 eta 0:19:04
epoch [8/30] batch [100/200] time 0.241 (0.252) data 0.000 (0.006) loss 1.9756 (0.9490) lr 8.7157e-03 eta 0:18:53
epoch [8/30] batch [120/200] time 0.246 (0.251) data 0.000 (0.005) loss 1.7783 (0.9176) lr 8.7157e-03 eta 0:18:42
epoch [8/30] batch [140/200] time 0.244 (0.250) data 0.000 (0.004) loss 2.9316 (0.9252) lr 8.7157e-03 eta 0:18:33
epoch [8/30] batch [160/200] time 0.245 (0.249) data 0.000 (0.004) loss 3.6016 (0.9271) lr 8.7157e-03 eta 0:18:25
epoch [8/30] batch [180/200] time 0.239 (0.248) data 0.000 (0.003) loss 0.4138 (0.9327) lr 8.7157e-03 eta 0:18:16
epoch [8/30] batch [200/200] time 0.238 (0.247) data 0.000 (0.003) loss -0.0577 (0.8975) lr 8.3457e-03 eta 0:18:07
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.23s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.71it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.64it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.55it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.38it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.11it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.71it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.18it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.54it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.81it/s]100%|██████████| 11/11 [00:02<00:00,  4.26it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.3%

epoch [9/30] batch [20/200] time 0.244 (0.278) data 0.000 (0.028) loss -0.0196 (0.8396) lr 8.3457e-03 eta 0:20:19
epoch [9/30] batch [40/200] time 0.246 (0.264) data 0.000 (0.014) loss 0.6738 (0.9233) lr 8.3457e-03 eta 0:19:10
epoch [9/30] batch [60/200] time 0.253 (0.258) data 0.000 (0.009) loss 2.5215 (1.0225) lr 8.3457e-03 eta 0:18:40
epoch [9/30] batch [80/200] time 0.245 (0.255) data 0.000 (0.007) loss 0.0184 (0.9382) lr 8.3457e-03 eta 0:18:21
epoch [9/30] batch [100/200] time 0.244 (0.254) data 0.000 (0.006) loss 0.0170 (0.8477) lr 8.3457e-03 eta 0:18:10
epoch [9/30] batch [120/200] time 0.245 (0.252) data 0.000 (0.005) loss 3.2324 (0.9039) lr 8.3457e-03 eta 0:17:59
epoch [9/30] batch [140/200] time 0.245 (0.251) data 0.000 (0.004) loss 0.2502 (0.9167) lr 8.3457e-03 eta 0:17:50
epoch [9/30] batch [160/200] time 0.243 (0.250) data 0.000 (0.004) loss 2.7656 (0.8937) lr 8.3457e-03 eta 0:17:42
epoch [9/30] batch [180/200] time 0.240 (0.250) data 0.000 (0.003) loss 0.5879 (0.8675) lr 8.3457e-03 eta 0:17:33
epoch [9/30] batch [200/200] time 0.243 (0.249) data 0.000 (0.003) loss -0.0229 (0.8469) lr 7.9389e-03 eta 0:17:24
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.33s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.60it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.49it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.39it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.23it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.97it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.59it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.09it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.47it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.11it/s]=> result
* total: 1,036
* correct: 1,022
* accuracy: 98.6%
* error: 1.4%
* macro_f1: 97.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/200] time 0.242 (0.275) data 0.000 (0.027) loss 1.3438 (1.0681) lr 7.9389e-03 eta 0:19:10
epoch [10/30] batch [40/200] time 0.242 (0.261) data 0.000 (0.014) loss 0.3091 (0.9399) lr 7.9389e-03 eta 0:18:06
epoch [10/30] batch [60/200] time 0.246 (0.256) data 0.000 (0.009) loss 1.1133 (0.8306) lr 7.9389e-03 eta 0:17:39
epoch [10/30] batch [80/200] time 0.243 (0.253) data 0.000 (0.007) loss 0.2063 (0.8707) lr 7.9389e-03 eta 0:17:21
epoch [10/30] batch [100/200] time 0.245 (0.251) data 0.000 (0.006) loss 0.6104 (0.9178) lr 7.9389e-03 eta 0:17:09
epoch [10/30] batch [120/200] time 0.241 (0.250) data 0.000 (0.005) loss 0.9658 (1.0091) lr 7.9389e-03 eta 0:17:00
epoch [10/30] batch [140/200] time 0.243 (0.249) data 0.000 (0.004) loss 0.0960 (0.9826) lr 7.9389e-03 eta 0:16:52
epoch [10/30] batch [160/200] time 0.242 (0.248) data 0.000 (0.004) loss 0.0555 (0.9533) lr 7.9389e-03 eta 0:16:43
epoch [10/30] batch [180/200] time 0.238 (0.248) data 0.000 (0.003) loss 0.8862 (0.9375) lr 7.9389e-03 eta 0:16:36
epoch [10/30] batch [200/200] time 0.239 (0.247) data 0.000 (0.003) loss 0.0192 (0.9567) lr 7.5000e-03 eta 0:16:27
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.36s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.56it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.44it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.34it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.17it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.92it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.55it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.06it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.45it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.75it/s]100%|██████████| 11/11 [00:02<00:00,  4.05it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/200] time 0.244 (0.277) data 0.000 (0.028) loss 0.0216 (0.7097) lr 7.5000e-03 eta 0:18:21
epoch [11/30] batch [40/200] time 0.244 (0.261) data 0.000 (0.014) loss 0.4695 (0.8184) lr 7.5000e-03 eta 0:17:11
epoch [11/30] batch [60/200] time 0.246 (0.257) data 0.000 (0.010) loss 0.5239 (0.8049) lr 7.5000e-03 eta 0:16:51
epoch [11/30] batch [80/200] time 0.253 (0.254) data 0.000 (0.007) loss -0.0566 (0.6848) lr 7.5000e-03 eta 0:16:34
epoch [11/30] batch [100/200] time 0.245 (0.252) data 0.000 (0.006) loss 0.0018 (0.7372) lr 7.5000e-03 eta 0:16:22
epoch [11/30] batch [120/200] time 0.259 (0.252) data 0.000 (0.005) loss -0.0569 (0.7320) lr 7.5000e-03 eta 0:16:16
epoch [11/30] batch [140/200] time 0.252 (0.251) data 0.000 (0.004) loss 3.3340 (0.7732) lr 7.5000e-03 eta 0:16:09
epoch [11/30] batch [160/200] time 0.244 (0.250) data 0.000 (0.004) loss 0.6323 (0.7890) lr 7.5000e-03 eta 0:16:01
epoch [11/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss 0.0393 (0.7981) lr 7.5000e-03 eta 0:15:52
epoch [11/30] batch [200/200] time 0.240 (0.248) data 0.000 (0.003) loss 2.0723 (0.8503) lr 7.0337e-03 eta 0:15:43
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.21s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.70it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.64it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.55it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.38it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.11it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.71it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.18it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.55it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.82it/s]100%|██████████| 11/11 [00:02<00:00,  4.26it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.4%

epoch [12/30] batch [20/200] time 0.245 (0.275) data 0.000 (0.027) loss -0.0512 (0.3922) lr 7.0337e-03 eta 0:17:18
epoch [12/30] batch [40/200] time 0.244 (0.261) data 0.000 (0.014) loss 0.4521 (0.5475) lr 7.0337e-03 eta 0:16:22
epoch [12/30] batch [60/200] time 0.247 (0.256) data 0.000 (0.009) loss 1.6318 (0.6851) lr 7.0337e-03 eta 0:15:58
epoch [12/30] batch [80/200] time 0.245 (0.254) data 0.000 (0.007) loss 0.9355 (0.7991) lr 7.0337e-03 eta 0:15:43
epoch [12/30] batch [100/200] time 0.243 (0.253) data 0.000 (0.006) loss 0.0175 (0.7956) lr 7.0337e-03 eta 0:15:34
epoch [12/30] batch [120/200] time 0.247 (0.251) data 0.000 (0.005) loss 0.0048 (0.7658) lr 7.0337e-03 eta 0:15:24
epoch [12/30] batch [140/200] time 0.247 (0.251) data 0.000 (0.004) loss 4.2695 (0.8834) lr 7.0337e-03 eta 0:15:17
epoch [12/30] batch [160/200] time 0.249 (0.250) data 0.000 (0.004) loss 0.1251 (0.8563) lr 7.0337e-03 eta 0:15:11
epoch [12/30] batch [180/200] time 0.240 (0.250) data 0.000 (0.003) loss -0.0296 (0.8446) lr 7.0337e-03 eta 0:15:04
epoch [12/30] batch [200/200] time 0.240 (0.249) data 0.000 (0.003) loss 4.4883 (0.8475) lr 6.5451e-03 eta 0:14:55
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.25s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.68it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.60it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.51it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.35it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.08it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.68it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.15it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.53it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.81it/s]100%|██████████| 11/11 [00:02<00:00,  4.23it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.4%

epoch [13/30] batch [20/200] time 0.242 (0.279) data 0.000 (0.027) loss 0.2274 (0.9575) lr 6.5451e-03 eta 0:16:39
epoch [13/30] batch [40/200] time 0.243 (0.264) data 0.000 (0.014) loss -0.0513 (0.9123) lr 6.5451e-03 eta 0:15:38
epoch [13/30] batch [60/200] time 0.244 (0.257) data 0.000 (0.009) loss 1.3291 (1.0616) lr 6.5451e-03 eta 0:15:09
epoch [13/30] batch [80/200] time 0.243 (0.254) data 0.000 (0.007) loss -0.0169 (0.9467) lr 6.5451e-03 eta 0:14:53
epoch [13/30] batch [100/200] time 0.242 (0.252) data 0.000 (0.006) loss 2.7090 (0.9444) lr 6.5451e-03 eta 0:14:43
epoch [13/30] batch [120/200] time 0.245 (0.251) data 0.000 (0.005) loss 1.9355 (0.9158) lr 6.5451e-03 eta 0:14:33
epoch [13/30] batch [140/200] time 0.245 (0.250) data 0.000 (0.004) loss 1.7891 (0.9263) lr 6.5451e-03 eta 0:14:24
epoch [13/30] batch [160/200] time 0.243 (0.249) data 0.000 (0.004) loss 0.0990 (0.9182) lr 6.5451e-03 eta 0:14:17
epoch [13/30] batch [180/200] time 0.239 (0.248) data 0.000 (0.003) loss 0.6680 (0.8963) lr 6.5451e-03 eta 0:14:09
epoch [13/30] batch [200/200] time 0.240 (0.247) data 0.000 (0.003) loss 0.9482 (0.8973) lr 6.0396e-03 eta 0:14:01
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.30s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.63it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.53it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.43it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.27it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.01it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.62it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.11it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.45it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.75it/s]100%|██████████| 11/11 [00:02<00:00,  4.13it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.8%

epoch [14/30] batch [20/200] time 0.244 (0.276) data 0.000 (0.029) loss 2.0527 (0.6829) lr 6.0396e-03 eta 0:15:34
epoch [14/30] batch [40/200] time 0.249 (0.263) data 0.000 (0.014) loss 0.2632 (0.9215) lr 6.0396e-03 eta 0:14:43
epoch [14/30] batch [60/200] time 0.243 (0.256) data 0.000 (0.010) loss 0.2966 (0.8995) lr 6.0396e-03 eta 0:14:15
epoch [14/30] batch [80/200] time 0.248 (0.253) data 0.000 (0.007) loss -0.0562 (0.8391) lr 6.0396e-03 eta 0:14:01
epoch [14/30] batch [100/200] time 0.243 (0.252) data 0.000 (0.006) loss 2.4980 (0.8607) lr 6.0396e-03 eta 0:13:50
epoch [14/30] batch [120/200] time 0.248 (0.251) data 0.000 (0.005) loss 0.0423 (0.8294) lr 6.0396e-03 eta 0:13:44
epoch [14/30] batch [140/200] time 0.245 (0.250) data 0.000 (0.004) loss 0.1940 (0.8357) lr 6.0396e-03 eta 0:13:36
epoch [14/30] batch [160/200] time 0.244 (0.250) data 0.000 (0.004) loss 2.1699 (0.8658) lr 6.0396e-03 eta 0:13:28
epoch [14/30] batch [180/200] time 0.239 (0.249) data 0.000 (0.003) loss 0.4202 (0.8694) lr 6.0396e-03 eta 0:13:22
epoch [14/30] batch [200/200] time 0.238 (0.248) data 0.000 (0.003) loss -0.0489 (0.8509) lr 5.5226e-03 eta 0:13:13
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.37s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.55it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.43it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.32it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.16it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.90it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.53it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.04it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.44it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.74it/s]100%|██████████| 11/11 [00:02<00:00,  4.04it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.6%

epoch [15/30] batch [20/200] time 0.243 (0.277) data 0.000 (0.028) loss 1.5215 (1.2478) lr 5.5226e-03 eta 0:14:42
epoch [15/30] batch [40/200] time 0.243 (0.261) data 0.000 (0.014) loss -0.0555 (0.9610) lr 5.5226e-03 eta 0:13:45
epoch [15/30] batch [60/200] time 0.243 (0.255) data 0.000 (0.010) loss 1.4844 (0.9781) lr 5.5226e-03 eta 0:13:22
epoch [15/30] batch [80/200] time 0.245 (0.254) data 0.000 (0.007) loss -0.0292 (0.9445) lr 5.5226e-03 eta 0:13:12
epoch [15/30] batch [100/200] time 0.243 (0.252) data 0.000 (0.006) loss 1.0439 (1.0119) lr 5.5226e-03 eta 0:13:00
epoch [15/30] batch [120/200] time 0.243 (0.251) data 0.000 (0.005) loss 0.1421 (1.0185) lr 5.5226e-03 eta 0:12:51
epoch [15/30] batch [140/200] time 0.244 (0.250) data 0.000 (0.004) loss -0.0143 (0.9871) lr 5.5226e-03 eta 0:12:45
epoch [15/30] batch [160/200] time 0.246 (0.250) data 0.000 (0.004) loss -0.0024 (0.9302) lr 5.5226e-03 eta 0:12:39
epoch [15/30] batch [180/200] time 0.238 (0.249) data 0.000 (0.003) loss 0.5967 (0.8764) lr 5.5226e-03 eta 0:12:31
epoch [15/30] batch [200/200] time 0.241 (0.248) data 0.000 (0.003) loss 0.3569 (0.8947) lr 5.0000e-03 eta 0:12:23
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.26s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.68it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.60it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.51it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.35it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.08it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.68it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.16it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.53it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.81it/s]100%|██████████| 11/11 [00:02<00:00,  4.23it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.7%

epoch [16/30] batch [20/200] time 0.245 (0.282) data 0.000 (0.028) loss 1.7451 (0.4497) lr 5.0000e-03 eta 0:13:59
epoch [16/30] batch [40/200] time 0.244 (0.264) data 0.000 (0.014) loss 1.8574 (0.9121) lr 5.0000e-03 eta 0:13:00
epoch [16/30] batch [60/200] time 0.244 (0.257) data 0.000 (0.009) loss 1.5410 (0.7464) lr 5.0000e-03 eta 0:12:36
epoch [16/30] batch [80/200] time 0.247 (0.254) data 0.000 (0.007) loss 1.2080 (0.8403) lr 5.0000e-03 eta 0:12:22
epoch [16/30] batch [100/200] time 0.245 (0.254) data 0.000 (0.006) loss 0.4163 (0.7664) lr 5.0000e-03 eta 0:12:15
epoch [16/30] batch [120/200] time 0.248 (0.253) data 0.000 (0.005) loss 2.8242 (0.7894) lr 5.0000e-03 eta 0:12:07
epoch [16/30] batch [140/200] time 0.244 (0.252) data 0.000 (0.004) loss 0.6875 (0.7736) lr 5.0000e-03 eta 0:11:59
epoch [16/30] batch [160/200] time 0.252 (0.251) data 0.000 (0.004) loss 1.3828 (0.7998) lr 5.0000e-03 eta 0:11:53
epoch [16/30] batch [180/200] time 0.240 (0.250) data 0.000 (0.003) loss 1.1299 (0.8022) lr 5.0000e-03 eta 0:11:45
epoch [16/30] batch [200/200] time 0.240 (0.249) data 0.000 (0.003) loss 2.2266 (0.7976) lr 4.4774e-03 eta 0:11:37
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.35s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.57it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.47it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.36it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.20it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.95it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.57it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.07it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.47it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.73it/s]100%|██████████| 11/11 [00:02<00:00,  4.08it/s]=> result
* total: 1,036
* correct: 1,021
* accuracy: 98.6%
* error: 1.4%
* macro_f1: 97.0%

epoch [17/30] batch [20/200] time 0.243 (0.278) data 0.000 (0.028) loss 0.6411 (0.7381) lr 4.4774e-03 eta 0:12:53
epoch [17/30] batch [40/200] time 0.242 (0.263) data 0.000 (0.014) loss -0.0281 (0.6764) lr 4.4774e-03 eta 0:12:04
epoch [17/30] batch [60/200] time 0.243 (0.258) data 0.000 (0.009) loss 2.7637 (0.8580) lr 4.4774e-03 eta 0:11:46
epoch [17/30] batch [80/200] time 0.248 (0.255) data 0.000 (0.007) loss -0.0587 (0.8598) lr 4.4774e-03 eta 0:11:33
epoch [17/30] batch [100/200] time 0.247 (0.253) data 0.000 (0.006) loss 2.6836 (0.8828) lr 4.4774e-03 eta 0:11:23
epoch [17/30] batch [120/200] time 0.243 (0.252) data 0.000 (0.005) loss 1.2109 (0.9194) lr 4.4774e-03 eta 0:11:15
epoch [17/30] batch [140/200] time 0.245 (0.251) data 0.000 (0.004) loss -0.0502 (0.8241) lr 4.4774e-03 eta 0:11:07
epoch [17/30] batch [160/200] time 0.243 (0.250) data 0.000 (0.004) loss 1.5928 (0.8283) lr 4.4774e-03 eta 0:11:00
epoch [17/30] batch [180/200] time 0.239 (0.249) data 0.000 (0.003) loss 1.1602 (0.8177) lr 4.4774e-03 eta 0:10:52
epoch [17/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss 3.9277 (0.8457) lr 3.9604e-03 eta 0:10:44
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.33s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.60it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.49it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.39it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.23it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.97it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.59it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.09it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.11it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.6%

epoch [18/30] batch [20/200] time 0.243 (0.276) data 0.000 (0.027) loss 0.4634 (0.5426) lr 3.9604e-03 eta 0:11:53
epoch [18/30] batch [40/200] time 0.245 (0.263) data 0.000 (0.014) loss -0.0265 (0.5272) lr 3.9604e-03 eta 0:11:13
epoch [18/30] batch [60/200] time 0.244 (0.257) data 0.000 (0.009) loss -0.0568 (0.6908) lr 3.9604e-03 eta 0:10:53
epoch [18/30] batch [80/200] time 0.245 (0.255) data 0.000 (0.007) loss -0.0307 (0.6464) lr 3.9604e-03 eta 0:10:41
epoch [18/30] batch [100/200] time 0.246 (0.253) data 0.000 (0.006) loss 1.9336 (0.6944) lr 3.9604e-03 eta 0:10:33
epoch [18/30] batch [120/200] time 0.246 (0.252) data 0.000 (0.005) loss 4.3828 (0.6712) lr 3.9604e-03 eta 0:10:25
epoch [18/30] batch [140/200] time 0.247 (0.251) data 0.000 (0.004) loss 0.1562 (0.7004) lr 3.9604e-03 eta 0:10:17
epoch [18/30] batch [160/200] time 0.246 (0.250) data 0.000 (0.004) loss 0.4688 (0.7350) lr 3.9604e-03 eta 0:10:10
epoch [18/30] batch [180/200] time 0.238 (0.249) data 0.000 (0.003) loss -0.0403 (0.7408) lr 3.9604e-03 eta 0:10:03
epoch [18/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss 0.3765 (0.7630) lr 3.4549e-03 eta 0:09:55
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.33s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.60it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.49it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.39it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.23it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.97it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.59it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.09it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.12it/s]=> result
* total: 1,036
* correct: 1,020
* accuracy: 98.5%
* error: 1.5%
* macro_f1: 96.8%

epoch [19/30] batch [20/200] time 0.242 (0.275) data 0.000 (0.027) loss 0.0185 (0.8083) lr 3.4549e-03 eta 0:10:55
epoch [19/30] batch [40/200] time 0.243 (0.262) data 0.000 (0.014) loss -0.0382 (0.6169) lr 3.4549e-03 eta 0:10:18
epoch [19/30] batch [60/200] time 0.244 (0.256) data 0.000 (0.009) loss 0.3677 (0.7181) lr 3.4549e-03 eta 0:09:58
epoch [19/30] batch [80/200] time 0.243 (0.253) data 0.000 (0.007) loss 2.1035 (0.8399) lr 3.4549e-03 eta 0:09:46
epoch [19/30] batch [100/200] time 0.243 (0.251) data 0.000 (0.006) loss 0.2134 (0.8070) lr 3.4549e-03 eta 0:09:36
epoch [19/30] batch [120/200] time 0.244 (0.250) data 0.000 (0.005) loss 0.0034 (0.8580) lr 3.4549e-03 eta 0:09:30
epoch [19/30] batch [140/200] time 0.244 (0.249) data 0.000 (0.004) loss 4.9844 (0.8846) lr 3.4549e-03 eta 0:09:23
epoch [19/30] batch [160/200] time 0.242 (0.249) data 0.000 (0.004) loss 2.1836 (0.8996) lr 3.4549e-03 eta 0:09:16
epoch [19/30] batch [180/200] time 0.238 (0.248) data 0.000 (0.003) loss 1.1064 (0.8685) lr 3.4549e-03 eta 0:09:10
epoch [19/30] batch [200/200] time 0.239 (0.247) data 0.000 (0.003) loss 0.0964 (0.8185) lr 2.9663e-03 eta 0:09:03
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.23s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.70it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.63it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.54it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.38it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.11it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.71it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.18it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.54it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.82it/s]100%|██████████| 11/11 [00:02<00:00,  4.26it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [20/30] batch [20/200] time 0.245 (0.279) data 0.000 (0.031) loss 0.8677 (0.5554) lr 2.9663e-03 eta 0:10:09
epoch [20/30] batch [40/200] time 0.252 (0.263) data 0.000 (0.015) loss 0.5547 (0.5964) lr 2.9663e-03 eta 0:09:28
epoch [20/30] batch [60/200] time 0.244 (0.259) data 0.000 (0.010) loss 1.7051 (0.6653) lr 2.9663e-03 eta 0:09:13
epoch [20/30] batch [80/200] time 0.244 (0.256) data 0.000 (0.008) loss 0.0632 (0.6907) lr 2.9663e-03 eta 0:09:02
epoch [20/30] batch [100/200] time 0.242 (0.254) data 0.000 (0.006) loss 0.0507 (0.6633) lr 2.9663e-03 eta 0:08:53
epoch [20/30] batch [120/200] time 0.245 (0.253) data 0.000 (0.005) loss 1.0840 (0.6525) lr 2.9663e-03 eta 0:08:45
epoch [20/30] batch [140/200] time 0.241 (0.251) data 0.000 (0.005) loss 0.4941 (0.7108) lr 2.9663e-03 eta 0:08:37
epoch [20/30] batch [160/200] time 0.242 (0.250) data 0.000 (0.004) loss 2.1562 (0.7594) lr 2.9663e-03 eta 0:08:31
epoch [20/30] batch [180/200] time 0.239 (0.249) data 0.000 (0.004) loss -0.0524 (0.7608) lr 2.9663e-03 eta 0:08:23
epoch [20/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss 0.9019 (0.7576) lr 2.5000e-03 eta 0:08:16
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.31s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.62it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.52it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.42it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.26it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.00it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.62it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.11it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.50it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.78it/s]100%|██████████| 11/11 [00:02<00:00,  4.12it/s]=> result
* total: 1,036
* correct: 1,017
* accuracy: 98.2%
* error: 1.8%
* macro_f1: 96.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/200] time 0.245 (0.278) data 0.000 (0.027) loss 1.6807 (0.8505) lr 2.5000e-03 eta 0:09:09
epoch [21/30] batch [40/200] time 0.246 (0.264) data 0.000 (0.014) loss 1.3711 (0.7432) lr 2.5000e-03 eta 0:08:37
epoch [21/30] batch [60/200] time 0.246 (0.258) data 0.000 (0.009) loss -0.0317 (0.6726) lr 2.5000e-03 eta 0:08:20
epoch [21/30] batch [80/200] time 0.245 (0.255) data 0.000 (0.007) loss 2.3594 (0.6501) lr 2.5000e-03 eta 0:08:10
epoch [21/30] batch [100/200] time 0.251 (0.254) data 0.000 (0.006) loss -0.0440 (0.7441) lr 2.5000e-03 eta 0:08:03
epoch [21/30] batch [120/200] time 0.246 (0.253) data 0.000 (0.005) loss 2.0156 (0.7743) lr 2.5000e-03 eta 0:07:55
epoch [21/30] batch [140/200] time 0.249 (0.252) data 0.001 (0.004) loss 0.1173 (0.7596) lr 2.5000e-03 eta 0:07:48
epoch [21/30] batch [160/200] time 0.246 (0.251) data 0.000 (0.004) loss 0.1555 (0.7937) lr 2.5000e-03 eta 0:07:42
epoch [21/30] batch [180/200] time 0.238 (0.250) data 0.000 (0.003) loss 0.0578 (0.8040) lr 2.5000e-03 eta 0:07:35
epoch [21/30] batch [200/200] time 0.239 (0.249) data 0.000 (0.003) loss -0.0315 (0.8113) lr 2.0611e-03 eta 0:07:28
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.32s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.60it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.50it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.40it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.24it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.96it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.59it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.08it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.47it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.76it/s]100%|██████████| 11/11 [00:02<00:00,  4.12it/s]=> result
* total: 1,036
* correct: 1,016
* accuracy: 98.1%
* error: 1.9%
* macro_f1: 96.2%

epoch [22/30] batch [20/200] time 0.242 (0.272) data 0.000 (0.027) loss 0.1370 (0.5293) lr 2.0611e-03 eta 0:08:04
epoch [22/30] batch [40/200] time 0.246 (0.261) data 0.000 (0.013) loss -0.0539 (0.5731) lr 2.0611e-03 eta 0:07:39
epoch [22/30] batch [60/200] time 0.251 (0.256) data 0.000 (0.009) loss 0.4990 (0.6598) lr 2.0611e-03 eta 0:07:25
epoch [22/30] batch [80/200] time 0.247 (0.253) data 0.000 (0.007) loss 0.0101 (0.6729) lr 2.0611e-03 eta 0:07:15
epoch [22/30] batch [100/200] time 0.246 (0.252) data 0.000 (0.006) loss 1.3525 (0.5962) lr 2.0611e-03 eta 0:07:08
epoch [22/30] batch [120/200] time 0.244 (0.251) data 0.000 (0.005) loss 0.2725 (0.6902) lr 2.0611e-03 eta 0:07:01
epoch [22/30] batch [140/200] time 0.251 (0.251) data 0.000 (0.004) loss 1.0430 (0.6653) lr 2.0611e-03 eta 0:06:55
epoch [22/30] batch [160/200] time 0.243 (0.250) data 0.000 (0.004) loss 0.2415 (0.6889) lr 2.0611e-03 eta 0:06:50
epoch [22/30] batch [180/200] time 0.238 (0.249) data 0.000 (0.003) loss 0.3040 (0.6998) lr 2.0611e-03 eta 0:06:43
epoch [22/30] batch [200/200] time 0.238 (0.248) data 0.000 (0.003) loss 1.0605 (0.7317) lr 1.6543e-03 eta 0:06:36
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.33s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.59it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.49it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.38it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.22it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.97it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.59it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.09it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.48it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.10it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [23/30] batch [20/200] time 0.247 (0.280) data 0.000 (0.027) loss 0.2061 (0.6599) lr 1.6543e-03 eta 0:07:22
epoch [23/30] batch [40/200] time 0.243 (0.262) data 0.000 (0.014) loss 2.3125 (0.8020) lr 1.6543e-03 eta 0:06:49
epoch [23/30] batch [60/200] time 0.243 (0.256) data 0.000 (0.009) loss -0.0602 (0.7255) lr 1.6543e-03 eta 0:06:34
epoch [23/30] batch [80/200] time 0.243 (0.254) data 0.000 (0.007) loss -0.0433 (0.5913) lr 1.6543e-03 eta 0:06:25
epoch [23/30] batch [100/200] time 0.242 (0.252) data 0.000 (0.006) loss 0.6963 (0.6785) lr 1.6543e-03 eta 0:06:17
epoch [23/30] batch [120/200] time 0.242 (0.251) data 0.000 (0.005) loss 0.9160 (0.6667) lr 1.6543e-03 eta 0:06:10
epoch [23/30] batch [140/200] time 0.245 (0.250) data 0.000 (0.004) loss 1.8574 (0.6802) lr 1.6543e-03 eta 0:06:05
epoch [23/30] batch [160/200] time 0.247 (0.250) data 0.000 (0.004) loss 0.0485 (0.6833) lr 1.6543e-03 eta 0:05:59
epoch [23/30] batch [180/200] time 0.240 (0.249) data 0.000 (0.003) loss -0.0495 (0.6927) lr 1.6543e-03 eta 0:05:53
epoch [23/30] batch [200/200] time 0.240 (0.248) data 0.000 (0.003) loss 0.7554 (0.7055) lr 1.2843e-03 eta 0:05:47
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.47it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.36it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.20it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.95it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.57it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.07it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.46it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.75it/s]100%|██████████| 11/11 [00:02<00:00,  4.08it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.6%

epoch [24/30] batch [20/200] time 0.248 (0.277) data 0.000 (0.028) loss 0.0521 (0.4677) lr 1.2843e-03 eta 0:06:22
epoch [24/30] batch [40/200] time 0.243 (0.261) data 0.000 (0.014) loss -0.0498 (0.7274) lr 1.2843e-03 eta 0:05:54
epoch [24/30] batch [60/200] time 0.242 (0.257) data 0.000 (0.009) loss 1.4326 (0.7872) lr 1.2843e-03 eta 0:05:44
epoch [24/30] batch [80/200] time 0.243 (0.253) data 0.000 (0.007) loss -0.0250 (0.8102) lr 1.2843e-03 eta 0:05:34
epoch [24/30] batch [100/200] time 0.316 (0.253) data 0.000 (0.006) loss 0.0015 (0.8380) lr 1.2843e-03 eta 0:05:28
epoch [24/30] batch [120/200] time 0.244 (0.252) data 0.000 (0.005) loss 2.1367 (0.8452) lr 1.2843e-03 eta 0:05:22
epoch [24/30] batch [140/200] time 0.243 (0.251) data 0.000 (0.004) loss -0.0563 (0.8605) lr 1.2843e-03 eta 0:05:16
epoch [24/30] batch [160/200] time 0.244 (0.250) data 0.000 (0.004) loss 0.0324 (0.8479) lr 1.2843e-03 eta 0:05:10
epoch [24/30] batch [180/200] time 0.241 (0.249) data 0.000 (0.003) loss -0.0514 (0.8085) lr 1.2843e-03 eta 0:05:04
epoch [24/30] batch [200/200] time 0.240 (0.251) data 0.000 (0.003) loss 0.8706 (0.8047) lr 9.5492e-04 eta 0:05:00
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.27s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.66it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.57it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.48it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.31it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.04it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.65it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.13it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.43it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.73it/s]100%|██████████| 11/11 [00:02<00:00,  4.18it/s]=> result
* total: 1,036
* correct: 1,018
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.5%

epoch [25/30] batch [20/200] time 0.245 (0.274) data 0.000 (0.028) loss 0.0944 (0.8036) lr 9.5492e-04 eta 0:05:23
epoch [25/30] batch [40/200] time 0.246 (0.261) data 0.000 (0.014) loss 0.8550 (0.8590) lr 9.5492e-04 eta 0:05:03
epoch [25/30] batch [60/200] time 0.242 (0.256) data 0.000 (0.010) loss -0.0199 (0.8359) lr 9.5492e-04 eta 0:04:51
epoch [25/30] batch [80/200] time 0.244 (0.253) data 0.000 (0.007) loss 0.1735 (0.7884) lr 9.5492e-04 eta 0:04:42
epoch [25/30] batch [100/200] time 0.243 (0.252) data 0.000 (0.006) loss 0.2483 (0.8105) lr 9.5492e-04 eta 0:04:36
epoch [25/30] batch [120/200] time 0.243 (0.250) data 0.000 (0.005) loss 1.8574 (0.8095) lr 9.5492e-04 eta 0:04:30
epoch [25/30] batch [140/200] time 0.243 (0.250) data 0.000 (0.004) loss 0.1443 (0.8483) lr 9.5492e-04 eta 0:04:24
epoch [25/30] batch [160/200] time 0.243 (0.249) data 0.000 (0.004) loss -0.0590 (0.8613) lr 9.5492e-04 eta 0:04:18
epoch [25/30] batch [180/200] time 0.238 (0.248) data 0.000 (0.003) loss 1.9199 (0.8830) lr 9.5492e-04 eta 0:04:12
epoch [25/30] batch [200/200] time 0.238 (0.247) data 0.000 (0.003) loss 0.4351 (0.8898) lr 6.6987e-04 eta 0:04:07
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.24s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.70it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.63it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.54it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.37it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.10it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.70it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.13it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.51it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.80it/s]100%|██████████| 11/11 [00:02<00:00,  4.24it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.7%

epoch [26/30] batch [20/200] time 0.248 (0.277) data 0.000 (0.030) loss -0.0503 (0.2789) lr 6.6987e-04 eta 0:04:31
epoch [26/30] batch [40/200] time 0.247 (0.262) data 0.000 (0.015) loss 1.0469 (0.4006) lr 6.6987e-04 eta 0:04:11
epoch [26/30] batch [60/200] time 0.243 (0.256) data 0.000 (0.010) loss 1.5039 (0.5154) lr 6.6987e-04 eta 0:04:00
epoch [26/30] batch [80/200] time 0.244 (0.253) data 0.000 (0.008) loss -0.0605 (0.5502) lr 6.6987e-04 eta 0:03:53
epoch [26/30] batch [100/200] time 0.243 (0.252) data 0.000 (0.006) loss 1.1084 (0.5465) lr 6.6987e-04 eta 0:03:47
epoch [26/30] batch [120/200] time 0.243 (0.251) data 0.000 (0.005) loss 0.0770 (0.5496) lr 6.6987e-04 eta 0:03:40
epoch [26/30] batch [140/200] time 0.244 (0.250) data 0.000 (0.005) loss 1.3750 (0.5171) lr 6.6987e-04 eta 0:03:34
epoch [26/30] batch [160/200] time 0.243 (0.249) data 0.000 (0.004) loss 2.0469 (0.6068) lr 6.6987e-04 eta 0:03:29
epoch [26/30] batch [180/200] time 0.239 (0.248) data 0.000 (0.004) loss 0.2395 (0.6269) lr 6.6987e-04 eta 0:03:23
epoch [26/30] batch [200/200] time 0.239 (0.247) data 0.000 (0.003) loss 0.5391 (0.6380) lr 4.3227e-04 eta 0:03:17
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:12,  1.24s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.70it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.63it/s] 36%|███▋      | 4/11 [00:01<00:01,  3.54it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.38it/s] 55%|█████▍    | 6/11 [00:01<00:00,  5.10it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.69it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.17it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.53it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.81it/s]100%|██████████| 11/11 [00:02<00:00,  4.24it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.7%

epoch [27/30] batch [20/200] time 0.243 (0.274) data 0.000 (0.027) loss 0.1469 (1.1953) lr 4.3227e-04 eta 0:03:33
epoch [27/30] batch [40/200] time 0.243 (0.261) data 0.000 (0.014) loss 1.3047 (1.0476) lr 4.3227e-04 eta 0:03:18
epoch [27/30] batch [60/200] time 0.243 (0.256) data 0.000 (0.009) loss 0.4998 (0.9469) lr 4.3227e-04 eta 0:03:09
epoch [27/30] batch [80/200] time 0.250 (0.253) data 0.000 (0.007) loss 0.1030 (0.8895) lr 4.3227e-04 eta 0:03:02
epoch [27/30] batch [100/200] time 0.245 (0.252) data 0.000 (0.006) loss 2.2852 (0.8489) lr 4.3227e-04 eta 0:02:56
epoch [27/30] batch [120/200] time 0.245 (0.251) data 0.000 (0.005) loss 0.3501 (0.8127) lr 4.3227e-04 eta 0:02:50
epoch [27/30] batch [140/200] time 0.244 (0.250) data 0.000 (0.004) loss 0.3933 (0.8439) lr 4.3227e-04 eta 0:02:45
epoch [27/30] batch [160/200] time 0.243 (0.250) data 0.000 (0.004) loss 0.7188 (0.7995) lr 4.3227e-04 eta 0:02:40
epoch [27/30] batch [180/200] time 0.241 (0.249) data 0.000 (0.003) loss 0.6670 (0.8142) lr 4.3227e-04 eta 0:02:34
epoch [27/30] batch [200/200] time 0.238 (0.248) data 0.000 (0.003) loss -0.0450 (0.8232) lr 2.4472e-04 eta 0:02:28
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.35s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.58it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.47it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.33it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.17it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.91it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.54it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.04it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.44it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.73it/s]100%|██████████| 11/11 [00:02<00:00,  4.05it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.7%

epoch [28/30] batch [20/200] time 0.243 (0.276) data 0.000 (0.028) loss 2.5430 (1.0915) lr 2.4472e-04 eta 0:02:39
epoch [28/30] batch [40/200] time 0.243 (0.262) data 0.000 (0.014) loss 4.0430 (0.7959) lr 2.4472e-04 eta 0:02:26
epoch [28/30] batch [60/200] time 0.247 (0.256) data 0.000 (0.010) loss 0.7817 (0.7161) lr 2.4472e-04 eta 0:02:18
epoch [28/30] batch [80/200] time 0.253 (0.253) data 0.000 (0.007) loss 1.3896 (0.7231) lr 2.4472e-04 eta 0:02:11
epoch [28/30] batch [100/200] time 0.249 (0.252) data 0.000 (0.006) loss 1.9863 (0.7631) lr 2.4472e-04 eta 0:02:05
epoch [28/30] batch [120/200] time 0.246 (0.252) data 0.000 (0.005) loss 0.8242 (0.7617) lr 2.4472e-04 eta 0:02:00
epoch [28/30] batch [140/200] time 0.242 (0.251) data 0.000 (0.004) loss 0.1300 (0.7323) lr 2.4472e-04 eta 0:01:55
epoch [28/30] batch [160/200] time 0.242 (0.250) data 0.000 (0.004) loss 0.2854 (0.7139) lr 2.4472e-04 eta 0:01:49
epoch [28/30] batch [180/200] time 0.238 (0.249) data 0.000 (0.003) loss 0.1460 (0.7272) lr 2.4472e-04 eta 0:01:44
epoch [28/30] batch [200/200] time 0.238 (0.248) data 0.000 (0.003) loss 2.8379 (0.7498) lr 1.0926e-04 eta 0:01:39
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.31s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.61it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.51it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.41it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.25it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.99it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.61it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.10it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.49it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.77it/s]100%|██████████| 11/11 [00:02<00:00,  4.13it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.7%

epoch [29/30] batch [20/200] time 0.242 (0.275) data 0.000 (0.028) loss 0.9653 (0.9137) lr 1.0926e-04 eta 0:01:44
epoch [29/30] batch [40/200] time 0.247 (0.259) data 0.000 (0.014) loss 1.9170 (0.9265) lr 1.0926e-04 eta 0:01:33
epoch [29/30] batch [60/200] time 0.243 (0.254) data 0.000 (0.010) loss 0.0450 (0.9946) lr 1.0926e-04 eta 0:01:26
epoch [29/30] batch [80/200] time 0.245 (0.253) data 0.000 (0.007) loss 2.9805 (0.8814) lr 1.0926e-04 eta 0:01:20
epoch [29/30] batch [100/200] time 0.253 (0.252) data 0.000 (0.006) loss -0.0280 (0.9316) lr 1.0926e-04 eta 0:01:15
epoch [29/30] batch [120/200] time 0.245 (0.251) data 0.000 (0.005) loss 0.2905 (0.8737) lr 1.0926e-04 eta 0:01:10
epoch [29/30] batch [140/200] time 0.245 (0.250) data 0.000 (0.004) loss 2.1348 (0.8482) lr 1.0926e-04 eta 0:01:05
epoch [29/30] batch [160/200] time 0.243 (0.249) data 0.000 (0.004) loss 0.1731 (0.7828) lr 1.0926e-04 eta 0:00:59
epoch [29/30] batch [180/200] time 0.243 (0.248) data 0.000 (0.003) loss 0.9155 (0.7823) lr 1.0926e-04 eta 0:00:54
epoch [29/30] batch [200/200] time 0.239 (0.248) data 0.000 (0.003) loss -0.0114 (0.7710) lr 2.7391e-05 eta 0:00:49
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.32s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.61it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.51it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.41it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.25it/s] 55%|█████▍    | 6/11 [00:01<00:01,  4.99it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.61it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.11it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.50it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.79it/s]100%|██████████| 11/11 [00:02<00:00,  4.12it/s]=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.7%

epoch [30/30] batch [20/200] time 0.249 (0.279) data 0.000 (0.028) loss -0.0380 (0.5104) lr 2.7391e-05 eta 0:00:50
epoch [30/30] batch [40/200] time 0.245 (0.261) data 0.000 (0.014) loss 0.3884 (0.7559) lr 2.7391e-05 eta 0:00:41
epoch [30/30] batch [60/200] time 0.248 (0.256) data 0.000 (0.010) loss 0.3042 (0.7185) lr 2.7391e-05 eta 0:00:35
epoch [30/30] batch [80/200] time 0.245 (0.254) data 0.000 (0.007) loss 0.0600 (0.7025) lr 2.7391e-05 eta 0:00:30
epoch [30/30] batch [100/200] time 0.243 (0.253) data 0.000 (0.006) loss 1.4844 (0.7390) lr 2.7391e-05 eta 0:00:25
epoch [30/30] batch [120/200] time 0.242 (0.251) data 0.000 (0.005) loss 0.3936 (0.7543) lr 2.7391e-05 eta 0:00:20
epoch [30/30] batch [140/200] time 0.242 (0.251) data 0.000 (0.004) loss 0.1754 (0.7400) lr 2.7391e-05 eta 0:00:15
epoch [30/30] batch [160/200] time 0.241 (0.250) data 0.000 (0.004) loss 0.0403 (0.6902) lr 2.7391e-05 eta 0:00:09
epoch [30/30] batch [180/200] time 0.238 (0.249) data 0.000 (0.003) loss 1.4150 (0.7196) lr 2.7391e-05 eta 0:00:04
epoch [30/30] batch [200/200] time 0.238 (0.248) data 0.000 (0.003) loss 0.0508 (0.7053) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:01<00:13,  1.34s/it] 18%|█▊        | 2/11 [00:01<00:05,  1.59it/s] 27%|██▋       | 3/11 [00:01<00:03,  2.48it/s] 36%|███▋      | 4/11 [00:01<00:02,  3.38it/s] 45%|████▌     | 5/11 [00:01<00:01,  4.22it/s] 55%|█████▍    | 6/11 [00:02<00:01,  4.94it/s] 64%|██████▎   | 7/11 [00:02<00:00,  5.56it/s] 73%|███████▎  | 8/11 [00:02<00:00,  6.01it/s] 82%|████████▏ | 9/11 [00:02<00:00,  6.41it/s] 91%|█████████ | 10/11 [00:02<00:00,  6.72it/s]100%|██████████| 11/11 [00:02<00:00,  4.07it/s]
=> result
* total: 1,036
* correct: 1,019
* accuracy: 98.4%
* error: 1.6%
* macro_f1: 96.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 9)
Evaluate on the *test* set
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.60s/it] 12%|█▎        | 2/16 [00:01<00:10,  1.35it/s] 19%|█▉        | 3/16 [00:01<00:06,  2.16it/s] 25%|██▌       | 4/16 [00:02<00:03,  3.01it/s] 31%|███▏      | 5/16 [00:02<00:02,  3.84it/s] 38%|███▊      | 6/16 [00:02<00:02,  4.61it/s] 44%|████▍     | 7/16 [00:02<00:01,  5.27it/s] 50%|█████     | 8/16 [00:02<00:01,  5.83it/s] 56%|█████▋    | 9/16 [00:02<00:01,  6.27it/s] 62%|██████▎   | 10/16 [00:02<00:00,  6.60it/s] 69%|██████▉   | 11/16 [00:02<00:00,  6.86it/s] 75%|███████▌  | 12/16 [00:03<00:00,  7.05it/s] 81%|████████▏ | 13/16 [00:03<00:00,  7.18it/s] 88%|████████▊ | 14/16 [00:03<00:00,  7.27it/s] 94%|█████████▍| 15/16 [00:03<00:00,  7.34it/s]100%|██████████| 16/16 [00:03<00:00,  4.39it/s]
=> result
* total: 1,549
* correct: 1,523
* accuracy: 98.3%
* error: 1.7%
* macro_f1: 96.7%
Elapsed: 0:26:19
+ sh scripts/rpo_prime/base2new_test_sdl.sh caltech101 3 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:Caltech101
Loading dataset: Caltech101
Reading split from /shared/s2/lab01/dataset/clip/caltech-101/split_zhou_Caltech101.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/caltech-101/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
800 613 916
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  50
# train_x  800
# val      613
# test     916
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/caltech101/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 9)
Evaluate on the *test* set
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:03<00:27,  3.10s/it] 20%|██        | 2/10 [00:03<00:10,  1.36s/it] 30%|███       | 3/10 [00:03<00:05,  1.25it/s] 40%|████      | 4/10 [00:03<00:03,  1.87it/s] 50%|█████     | 5/10 [00:03<00:01,  2.57it/s] 60%|██████    | 6/10 [00:03<00:01,  3.31it/s] 70%|███████   | 7/10 [00:03<00:00,  4.06it/s] 80%|████████  | 8/10 [00:04<00:00,  4.74it/s] 90%|█████████ | 9/10 [00:04<00:00,  5.36it/s]100%|██████████| 10/10 [00:04<00:00,  2.34it/s]
=> result
* total: 916
* correct: 863
* accuracy: 94.2%
* error: 5.8%
* macro_f1: 94.4%
+ for dataset in caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh sun397 1 0 main_tmp1_0.1sdl 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
3184 1990 9950
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  199
# train_x  3,184
# val      1,990
# test     9,950
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/796] time 0.400 (0.503) data 0.000 (0.055) loss 3.1426 (2.6511) lr 1.0000e-02 eta 3:20:05
epoch [1/30] batch [40/796] time 0.360 (0.445) data 0.000 (0.028) loss 1.1289 (2.4653) lr 1.0000e-02 eta 2:56:53
epoch [1/30] batch [60/796] time 0.379 (0.423) data 0.000 (0.019) loss 4.9453 (2.3121) lr 1.0000e-02 eta 2:47:58
epoch [1/30] batch [80/796] time 0.352 (0.413) data 0.000 (0.014) loss 2.9102 (2.2628) lr 1.0000e-02 eta 2:43:57
epoch [1/30] batch [100/796] time 0.353 (0.406) data 0.000 (0.011) loss 1.3506 (2.2278) lr 1.0000e-02 eta 2:40:50
epoch [1/30] batch [120/796] time 0.405 (0.400) data 0.000 (0.009) loss 1.0059 (2.2154) lr 1.0000e-02 eta 2:38:32
epoch [1/30] batch [140/796] time 0.356 (0.398) data 0.000 (0.008) loss 3.5820 (2.2409) lr 1.0000e-02 eta 2:37:39
epoch [1/30] batch [160/796] time 0.363 (0.396) data 0.000 (0.007) loss 1.8008 (2.1912) lr 1.0000e-02 eta 2:36:24
epoch [1/30] batch [180/796] time 0.413 (0.394) data 0.000 (0.006) loss 0.9575 (2.2140) lr 1.0000e-02 eta 2:35:49
epoch [1/30] batch [200/796] time 0.404 (0.394) data 0.000 (0.006) loss 0.9375 (2.1992) lr 1.0000e-02 eta 2:35:19
epoch [1/30] batch [220/796] time 0.429 (0.392) data 0.000 (0.005) loss 6.2930 (2.2025) lr 1.0000e-02 eta 2:34:45
epoch [1/30] batch [240/796] time 0.388 (0.391) data 0.000 (0.005) loss 0.8691 (2.1843) lr 1.0000e-02 eta 2:34:08
epoch [1/30] batch [260/796] time 0.384 (0.390) data 0.000 (0.004) loss 1.5000 (2.1830) lr 1.0000e-02 eta 2:33:36
epoch [1/30] batch [280/796] time 0.348 (0.389) data 0.000 (0.004) loss 2.2227 (2.1735) lr 1.0000e-02 eta 2:33:11
epoch [1/30] batch [300/796] time 0.396 (0.389) data 0.000 (0.004) loss 1.2363 (2.1786) lr 1.0000e-02 eta 2:32:58
epoch [1/30] batch [320/796] time 0.399 (0.388) data 0.000 (0.004) loss 0.7217 (2.2019) lr 1.0000e-02 eta 2:32:27
epoch [1/30] batch [340/796] time 0.364 (0.388) data 0.000 (0.003) loss 0.2671 (2.2035) lr 1.0000e-02 eta 2:32:11
epoch [1/30] batch [360/796] time 0.412 (0.388) data 0.000 (0.003) loss 3.6348 (2.2018) lr 1.0000e-02 eta 2:31:54
epoch [1/30] batch [380/796] time 0.351 (0.387) data 0.000 (0.003) loss 1.9199 (2.1832) lr 1.0000e-02 eta 2:31:43
epoch [1/30] batch [400/796] time 0.376 (0.387) data 0.000 (0.003) loss 3.5605 (2.2006) lr 1.0000e-02 eta 2:31:28
epoch [1/30] batch [420/796] time 0.400 (0.387) data 0.000 (0.003) loss 2.0996 (2.1898) lr 1.0000e-02 eta 2:31:20
epoch [1/30] batch [440/796] time 0.393 (0.387) data 0.000 (0.003) loss 0.9819 (2.1808) lr 1.0000e-02 eta 2:31:03
epoch [1/30] batch [460/796] time 0.360 (0.386) data 0.000 (0.003) loss 0.7485 (2.1588) lr 1.0000e-02 eta 2:30:38
epoch [1/30] batch [480/796] time 0.361 (0.386) data 0.000 (0.003) loss 4.9961 (2.1496) lr 1.0000e-02 eta 2:30:22
epoch [1/30] batch [500/796] time 0.393 (0.385) data 0.000 (0.002) loss 2.6270 (2.1447) lr 1.0000e-02 eta 2:30:04
epoch [1/30] batch [520/796] time 0.400 (0.385) data 0.001 (0.002) loss 4.3086 (2.1382) lr 1.0000e-02 eta 2:29:57
epoch [1/30] batch [540/796] time 0.376 (0.385) data 0.000 (0.002) loss 2.5645 (2.1366) lr 1.0000e-02 eta 2:29:47
epoch [1/30] batch [560/796] time 0.359 (0.385) data 0.000 (0.002) loss 0.7256 (2.1223) lr 1.0000e-02 eta 2:29:32
epoch [1/30] batch [580/796] time 0.366 (0.385) data 0.000 (0.002) loss 1.7480 (2.1241) lr 1.0000e-02 eta 2:29:19
epoch [1/30] batch [600/796] time 0.347 (0.384) data 0.000 (0.002) loss 1.4150 (2.1267) lr 1.0000e-02 eta 2:29:05
epoch [1/30] batch [620/796] time 0.390 (0.384) data 0.000 (0.002) loss 2.8887 (2.1509) lr 1.0000e-02 eta 2:29:00
epoch [1/30] batch [640/796] time 0.387 (0.384) data 0.000 (0.002) loss 3.4180 (2.1707) lr 1.0000e-02 eta 2:28:49
epoch [1/30] batch [660/796] time 0.357 (0.384) data 0.000 (0.002) loss 5.4688 (2.1797) lr 1.0000e-02 eta 2:28:38
epoch [1/30] batch [680/796] time 0.387 (0.384) data 0.000 (0.002) loss 0.8350 (2.1896) lr 1.0000e-02 eta 2:28:28
epoch [1/30] batch [700/796] time 0.370 (0.384) data 0.000 (0.002) loss 1.2314 (2.1973) lr 1.0000e-02 eta 2:28:14
epoch [1/30] batch [720/796] time 0.400 (0.384) data 0.000 (0.002) loss 2.6680 (2.2108) lr 1.0000e-02 eta 2:28:08
epoch [1/30] batch [740/796] time 0.402 (0.384) data 0.000 (0.002) loss 1.7109 (2.2176) lr 1.0000e-02 eta 2:27:55
epoch [1/30] batch [760/796] time 0.384 (0.383) data 0.000 (0.002) loss 3.4609 (2.2201) lr 1.0000e-02 eta 2:27:46
epoch [1/30] batch [780/796] time 0.338 (0.383) data 0.000 (0.002) loss 0.8340 (2.2294) lr 1.0000e-02 eta 2:27:17
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.67s/it] 10%|█         | 2/20 [00:06<00:53,  2.96s/it] 15%|█▌        | 3/20 [00:07<00:29,  1.74s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.50it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.84it/s] 40%|████      | 8/20 [00:08<00:05,  2.15it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.41it/s] 50%|█████     | 10/20 [00:09<00:03,  2.64it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.99it/s] 60%|██████    | 12/20 [00:09<00:02,  3.28it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.48it/s] 70%|███████   | 14/20 [00:10<00:01,  3.63it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.72it/s] 80%|████████  | 16/20 [00:10<00:01,  3.89it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.14it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.25it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.71it/s]100%|██████████| 20/20 [00:11<00:00,  4.17it/s]100%|██████████| 20/20 [00:11<00:00,  1.71it/s]=> result
* total: 1,990
* correct: 1,518
* accuracy: 76.3%
* error: 23.7%
* macro_f1: 75.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/796] time 0.346 (0.415) data 0.000 (0.032) loss 3.4609 (2.3145) lr 9.9726e-03 eta 2:39:40
epoch [2/30] batch [40/796] time 0.349 (0.399) data 0.000 (0.016) loss 1.7334 (2.1247) lr 9.9726e-03 eta 2:33:13
epoch [2/30] batch [60/796] time 0.362 (0.391) data 0.000 (0.011) loss 1.3076 (2.1951) lr 9.9726e-03 eta 2:30:12
epoch [2/30] batch [80/796] time 0.366 (0.386) data 0.000 (0.008) loss 1.0371 (2.2094) lr 9.9726e-03 eta 2:28:03
epoch [2/30] batch [100/796] time 0.379 (0.385) data 0.000 (0.007) loss 0.8208 (2.1653) lr 9.9726e-03 eta 2:27:37
epoch [2/30] batch [120/796] time 0.393 (0.384) data 0.000 (0.006) loss 1.0283 (2.2407) lr 9.9726e-03 eta 2:27:00
epoch [2/30] batch [140/796] time 0.361 (0.383) data 0.000 (0.005) loss 2.4258 (2.1991) lr 9.9726e-03 eta 2:26:34
epoch [2/30] batch [160/796] time 0.377 (0.383) data 0.000 (0.004) loss 1.8369 (2.1698) lr 9.9726e-03 eta 2:26:25
epoch [2/30] batch [180/796] time 0.364 (0.382) data 0.000 (0.004) loss 3.9707 (2.1550) lr 9.9726e-03 eta 2:25:52
epoch [2/30] batch [200/796] time 0.374 (0.382) data 0.000 (0.003) loss 0.1595 (2.1075) lr 9.9726e-03 eta 2:25:50
epoch [2/30] batch [220/796] time 0.395 (0.382) data 0.000 (0.003) loss 3.3320 (2.1188) lr 9.9726e-03 eta 2:25:40
epoch [2/30] batch [240/796] time 0.412 (0.382) data 0.000 (0.003) loss 7.1758 (2.0790) lr 9.9726e-03 eta 2:25:29
epoch [2/30] batch [260/796] time 0.413 (0.383) data 0.000 (0.003) loss 1.1670 (2.0655) lr 9.9726e-03 eta 2:25:37
epoch [2/30] batch [280/796] time 0.343 (0.383) data 0.000 (0.003) loss 2.9062 (2.1504) lr 9.9726e-03 eta 2:25:27
epoch [2/30] batch [300/796] time 0.368 (0.382) data 0.000 (0.002) loss 2.8984 (2.1291) lr 9.9726e-03 eta 2:25:10
epoch [2/30] batch [320/796] time 0.401 (0.383) data 0.000 (0.002) loss 1.9854 (2.1047) lr 9.9726e-03 eta 2:25:10
epoch [2/30] batch [340/796] time 0.402 (0.383) data 0.000 (0.002) loss 0.9092 (2.1287) lr 9.9726e-03 eta 2:25:02
epoch [2/30] batch [360/796] time 0.376 (0.382) data 0.000 (0.002) loss 1.5000 (2.1155) lr 9.9726e-03 eta 2:24:46
epoch [2/30] batch [380/796] time 0.405 (0.382) data 0.000 (0.002) loss 1.7949 (2.1253) lr 9.9726e-03 eta 2:24:34
epoch [2/30] batch [400/796] time 0.372 (0.382) data 0.001 (0.002) loss 1.3828 (2.1144) lr 9.9726e-03 eta 2:24:23
epoch [2/30] batch [420/796] time 0.374 (0.382) data 0.000 (0.002) loss 4.5469 (2.1414) lr 9.9726e-03 eta 2:24:16
epoch [2/30] batch [440/796] time 0.352 (0.382) data 0.000 (0.002) loss 1.5039 (2.1420) lr 9.9726e-03 eta 2:24:05
epoch [2/30] batch [460/796] time 0.379 (0.382) data 0.000 (0.002) loss 3.8242 (2.1305) lr 9.9726e-03 eta 2:23:53
epoch [2/30] batch [480/796] time 0.357 (0.381) data 0.000 (0.002) loss 1.5049 (2.1227) lr 9.9726e-03 eta 2:23:39
epoch [2/30] batch [500/796] time 0.387 (0.381) data 0.000 (0.002) loss 0.6196 (2.1164) lr 9.9726e-03 eta 2:23:31
epoch [2/30] batch [520/796] time 0.400 (0.381) data 0.000 (0.001) loss 1.3770 (2.1106) lr 9.9726e-03 eta 2:23:18
epoch [2/30] batch [540/796] time 0.375 (0.381) data 0.000 (0.001) loss 1.0342 (2.1024) lr 9.9726e-03 eta 2:23:03
epoch [2/30] batch [560/796] time 0.388 (0.381) data 0.001 (0.001) loss 1.1328 (2.0872) lr 9.9726e-03 eta 2:22:51
epoch [2/30] batch [580/796] time 0.360 (0.381) data 0.000 (0.001) loss 4.3008 (2.0923) lr 9.9726e-03 eta 2:22:43
epoch [2/30] batch [600/796] time 0.373 (0.381) data 0.000 (0.001) loss 2.4648 (2.0896) lr 9.9726e-03 eta 2:22:39
epoch [2/30] batch [620/796] time 0.410 (0.381) data 0.000 (0.001) loss 0.9707 (2.1052) lr 9.9726e-03 eta 2:22:30
epoch [2/30] batch [640/796] time 0.412 (0.381) data 0.000 (0.001) loss 1.6035 (2.1101) lr 9.9726e-03 eta 2:22:26
epoch [2/30] batch [660/796] time 0.349 (0.381) data 0.000 (0.001) loss 1.2939 (2.0996) lr 9.9726e-03 eta 2:22:14
epoch [2/30] batch [680/796] time 0.361 (0.380) data 0.000 (0.001) loss 0.8921 (2.1039) lr 9.9726e-03 eta 2:22:00
epoch [2/30] batch [700/796] time 0.394 (0.380) data 0.000 (0.001) loss 0.6460 (2.0940) lr 9.9726e-03 eta 2:21:51
epoch [2/30] batch [720/796] time 0.377 (0.380) data 0.000 (0.001) loss 0.4072 (2.0882) lr 9.9726e-03 eta 2:21:43
epoch [2/30] batch [740/796] time 0.380 (0.380) data 0.000 (0.001) loss 1.9111 (2.0967) lr 9.9726e-03 eta 2:21:39
epoch [2/30] batch [760/796] time 0.395 (0.380) data 0.000 (0.001) loss 0.0149 (2.0826) lr 9.9726e-03 eta 2:21:29
epoch [2/30] batch [780/796] time 0.344 (0.379) data 0.000 (0.001) loss 0.5669 (2.0882) lr 9.9726e-03 eta 2:21:01
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.48s/it] 10%|█         | 2/20 [00:06<00:53,  2.95s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.74s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.02it/s] 60%|██████    | 12/20 [00:09<00:02,  3.20it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.36it/s] 70%|███████   | 14/20 [00:09<00:01,  3.62it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.71it/s] 80%|████████  | 16/20 [00:10<00:01,  3.92it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.09it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.20it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.52it/s]100%|██████████| 20/20 [00:11<00:00,  4.85it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,529
* accuracy: 76.8%
* error: 23.2%
* macro_f1: 75.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/796] time 0.406 (0.427) data 0.000 (0.036) loss 2.7500 (2.5571) lr 9.8907e-03 eta 2:38:31
epoch [3/30] batch [40/796] time 0.373 (0.406) data 0.000 (0.018) loss 2.6504 (2.2983) lr 9.8907e-03 eta 2:30:37
epoch [3/30] batch [60/796] time 0.364 (0.397) data 0.000 (0.012) loss 2.2012 (2.1322) lr 9.8907e-03 eta 2:27:13
epoch [3/30] batch [80/796] time 0.348 (0.392) data 0.000 (0.009) loss 3.8223 (2.0773) lr 9.8907e-03 eta 2:25:11
epoch [3/30] batch [100/796] time 0.351 (0.390) data 0.000 (0.007) loss 2.2832 (1.9986) lr 9.8907e-03 eta 2:24:11
epoch [3/30] batch [120/796] time 0.382 (0.388) data 0.000 (0.006) loss 2.2695 (2.0510) lr 9.8907e-03 eta 2:23:29
epoch [3/30] batch [140/796] time 0.386 (0.387) data 0.000 (0.005) loss 1.1641 (2.0607) lr 9.8907e-03 eta 2:22:58
epoch [3/30] batch [160/796] time 0.406 (0.386) data 0.000 (0.005) loss 0.9536 (2.0667) lr 9.8907e-03 eta 2:22:29
epoch [3/30] batch [180/796] time 0.384 (0.386) data 0.000 (0.004) loss 1.3184 (2.0723) lr 9.8907e-03 eta 2:22:10
epoch [3/30] batch [200/796] time 0.379 (0.385) data 0.000 (0.004) loss 0.9976 (2.0678) lr 9.8907e-03 eta 2:21:51
epoch [3/30] batch [220/796] time 0.370 (0.385) data 0.000 (0.004) loss 2.5566 (2.0139) lr 9.8907e-03 eta 2:21:39
epoch [3/30] batch [240/796] time 0.346 (0.385) data 0.000 (0.003) loss 0.3286 (2.0002) lr 9.8907e-03 eta 2:21:24
epoch [3/30] batch [260/796] time 0.371 (0.384) data 0.000 (0.003) loss 5.3047 (2.0116) lr 9.8907e-03 eta 2:21:02
epoch [3/30] batch [280/796] time 0.353 (0.384) data 0.000 (0.003) loss 0.5381 (1.9922) lr 9.8907e-03 eta 2:20:53
epoch [3/30] batch [300/796] time 0.401 (0.384) data 0.000 (0.003) loss 1.2051 (1.9627) lr 9.8907e-03 eta 2:20:39
epoch [3/30] batch [320/796] time 0.370 (0.384) data 0.000 (0.003) loss 2.5469 (1.9418) lr 9.8907e-03 eta 2:20:26
epoch [3/30] batch [340/796] time 0.363 (0.383) data 0.000 (0.002) loss 1.5088 (1.9743) lr 9.8907e-03 eta 2:20:13
epoch [3/30] batch [360/796] time 0.384 (0.383) data 0.000 (0.002) loss 3.3984 (1.9778) lr 9.8907e-03 eta 2:19:51
epoch [3/30] batch [380/796] time 0.402 (0.383) data 0.000 (0.002) loss 1.9834 (1.9658) lr 9.8907e-03 eta 2:19:48
epoch [3/30] batch [400/796] time 0.398 (0.382) data 0.000 (0.002) loss 0.4854 (1.9406) lr 9.8907e-03 eta 2:19:28
epoch [3/30] batch [420/796] time 0.356 (0.382) data 0.000 (0.002) loss 1.9268 (1.9437) lr 9.8907e-03 eta 2:19:14
epoch [3/30] batch [440/796] time 0.384 (0.382) data 0.000 (0.002) loss 2.0586 (1.9476) lr 9.8907e-03 eta 2:19:01
epoch [3/30] batch [460/796] time 0.448 (0.382) data 0.000 (0.002) loss 3.6973 (1.9799) lr 9.8907e-03 eta 2:18:56
epoch [3/30] batch [480/796] time 0.369 (0.382) data 0.000 (0.002) loss 0.2959 (1.9936) lr 9.8907e-03 eta 2:18:45
epoch [3/30] batch [500/796] time 0.389 (0.381) data 0.000 (0.002) loss 2.6191 (1.9996) lr 9.8907e-03 eta 2:18:29
epoch [3/30] batch [520/796] time 0.358 (0.381) data 0.000 (0.002) loss 2.1875 (1.9982) lr 9.8907e-03 eta 2:18:15
epoch [3/30] batch [540/796] time 0.366 (0.381) data 0.000 (0.002) loss 0.3767 (1.9867) lr 9.8907e-03 eta 2:18:04
epoch [3/30] batch [560/796] time 0.369 (0.381) data 0.000 (0.002) loss 0.4014 (1.9719) lr 9.8907e-03 eta 2:17:55
epoch [3/30] batch [580/796] time 0.375 (0.381) data 0.000 (0.001) loss 1.1406 (1.9726) lr 9.8907e-03 eta 2:17:53
epoch [3/30] batch [600/796] time 0.355 (0.381) data 0.000 (0.001) loss 0.3320 (1.9545) lr 9.8907e-03 eta 2:17:41
epoch [3/30] batch [620/796] time 0.360 (0.381) data 0.000 (0.001) loss 0.4116 (1.9477) lr 9.8907e-03 eta 2:17:30
epoch [3/30] batch [640/796] time 0.377 (0.381) data 0.000 (0.001) loss 2.2402 (1.9499) lr 9.8907e-03 eta 2:17:22
epoch [3/30] batch [660/796] time 0.360 (0.381) data 0.000 (0.001) loss 5.4453 (1.9440) lr 9.8907e-03 eta 2:17:19
epoch [3/30] batch [680/796] time 0.382 (0.381) data 0.000 (0.001) loss 0.2240 (1.9426) lr 9.8907e-03 eta 2:17:10
epoch [3/30] batch [700/796] time 0.397 (0.381) data 0.000 (0.001) loss 1.2832 (1.9583) lr 9.8907e-03 eta 2:16:58
epoch [3/30] batch [720/796] time 0.393 (0.381) data 0.000 (0.001) loss 2.1387 (1.9466) lr 9.8907e-03 eta 2:16:50
epoch [3/30] batch [740/796] time 0.392 (0.381) data 0.000 (0.001) loss 3.6426 (1.9447) lr 9.8907e-03 eta 2:16:43
epoch [3/30] batch [760/796] time 0.384 (0.381) data 0.000 (0.001) loss 0.4602 (1.9506) lr 9.8907e-03 eta 2:16:34
epoch [3/30] batch [780/796] time 0.340 (0.380) data 0.000 (0.001) loss 0.8315 (1.9453) lr 9.8907e-03 eta 2:16:09
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.60s/it] 10%|█         | 2/20 [00:06<00:51,  2.85s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.71it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.01it/s] 60%|██████    | 12/20 [00:09<00:02,  3.23it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.35it/s] 70%|███████   | 14/20 [00:09<00:01,  3.67it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.83it/s] 80%|████████  | 16/20 [00:10<00:01,  3.77it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.79it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.18it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.50it/s]100%|██████████| 20/20 [00:11<00:00,  4.83it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,542
* accuracy: 77.5%
* error: 22.5%
* macro_f1: 76.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/796] time 0.394 (0.425) data 0.000 (0.030) loss 3.8789 (2.1643) lr 9.7553e-03 eta 2:31:56
epoch [4/30] batch [40/796] time 0.394 (0.407) data 0.000 (0.015) loss 4.2109 (2.2647) lr 9.7553e-03 eta 2:25:28
epoch [4/30] batch [60/796] time 0.396 (0.400) data 0.000 (0.010) loss 2.7207 (1.9489) lr 9.7553e-03 eta 2:22:48
epoch [4/30] batch [80/796] time 0.369 (0.394) data 0.000 (0.008) loss 0.8408 (1.8742) lr 9.7553e-03 eta 2:20:37
epoch [4/30] batch [100/796] time 0.453 (0.391) data 0.000 (0.006) loss 1.4375 (1.8829) lr 9.7553e-03 eta 2:19:28
epoch [4/30] batch [120/796] time 0.398 (0.388) data 0.000 (0.005) loss 1.1182 (1.9288) lr 9.7553e-03 eta 2:18:10
epoch [4/30] batch [140/796] time 0.393 (0.387) data 0.000 (0.005) loss 0.8691 (1.9788) lr 9.7553e-03 eta 2:17:43
epoch [4/30] batch [160/796] time 0.351 (0.386) data 0.000 (0.004) loss 4.7305 (1.9968) lr 9.7553e-03 eta 2:17:17
epoch [4/30] batch [180/796] time 0.403 (0.385) data 0.000 (0.004) loss 1.5059 (2.0065) lr 9.7553e-03 eta 2:16:55
epoch [4/30] batch [200/796] time 0.390 (0.385) data 0.000 (0.003) loss 1.7988 (1.9617) lr 9.7553e-03 eta 2:16:35
epoch [4/30] batch [220/796] time 0.426 (0.385) data 0.000 (0.003) loss 2.5684 (1.9460) lr 9.7553e-03 eta 2:16:22
epoch [4/30] batch [240/796] time 0.390 (0.385) data 0.000 (0.003) loss 4.9727 (1.9363) lr 9.7553e-03 eta 2:16:14
epoch [4/30] batch [260/796] time 0.390 (0.385) data 0.000 (0.003) loss 2.7402 (1.9086) lr 9.7553e-03 eta 2:16:08
epoch [4/30] batch [280/796] time 0.358 (0.384) data 0.000 (0.002) loss 4.6523 (1.9454) lr 9.7553e-03 eta 2:15:44
epoch [4/30] batch [300/796] time 0.397 (0.384) data 0.000 (0.002) loss 2.3633 (1.9731) lr 9.7553e-03 eta 2:15:32
epoch [4/30] batch [320/796] time 0.385 (0.383) data 0.000 (0.002) loss 1.0820 (1.9705) lr 9.7553e-03 eta 2:15:18
epoch [4/30] batch [340/796] time 0.381 (0.383) data 0.000 (0.002) loss 3.8477 (1.9993) lr 9.7553e-03 eta 2:15:03
epoch [4/30] batch [360/796] time 0.378 (0.383) data 0.000 (0.002) loss 1.5840 (2.0271) lr 9.7553e-03 eta 2:14:43
epoch [4/30] batch [380/796] time 0.368 (0.382) data 0.000 (0.002) loss 0.2927 (2.0244) lr 9.7553e-03 eta 2:14:26
epoch [4/30] batch [400/796] time 0.376 (0.382) data 0.000 (0.002) loss 3.7305 (2.0218) lr 9.7553e-03 eta 2:14:21
epoch [4/30] batch [420/796] time 0.369 (0.382) data 0.000 (0.002) loss 0.8872 (2.0078) lr 9.7553e-03 eta 2:14:01
epoch [4/30] batch [440/796] time 0.379 (0.381) data 0.000 (0.002) loss 3.8887 (1.9941) lr 9.7553e-03 eta 2:13:49
epoch [4/30] batch [460/796] time 0.389 (0.381) data 0.000 (0.002) loss 0.5889 (1.9974) lr 9.7553e-03 eta 2:13:42
epoch [4/30] batch [480/796] time 0.404 (0.381) data 0.000 (0.002) loss 0.9248 (2.0005) lr 9.7553e-03 eta 2:13:34
epoch [4/30] batch [500/796] time 0.360 (0.381) data 0.000 (0.001) loss 2.0156 (1.9980) lr 9.7553e-03 eta 2:13:27
epoch [4/30] batch [520/796] time 0.401 (0.381) data 0.000 (0.001) loss 2.9199 (2.0024) lr 9.7553e-03 eta 2:13:17
epoch [4/30] batch [540/796] time 0.342 (0.381) data 0.000 (0.001) loss 3.4219 (1.9933) lr 9.7553e-03 eta 2:13:12
epoch [4/30] batch [560/796] time 0.389 (0.381) data 0.000 (0.001) loss 0.3362 (1.9746) lr 9.7553e-03 eta 2:13:00
epoch [4/30] batch [580/796] time 0.414 (0.381) data 0.000 (0.001) loss 2.3711 (1.9595) lr 9.7553e-03 eta 2:12:49
epoch [4/30] batch [600/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.2034 (1.9767) lr 9.7553e-03 eta 2:12:47
epoch [4/30] batch [620/796] time 0.387 (0.381) data 0.000 (0.001) loss 0.9067 (1.9710) lr 9.7553e-03 eta 2:12:41
epoch [4/30] batch [640/796] time 0.373 (0.381) data 0.000 (0.001) loss 5.1328 (1.9817) lr 9.7553e-03 eta 2:12:29
epoch [4/30] batch [660/796] time 0.357 (0.381) data 0.000 (0.001) loss 4.1172 (1.9809) lr 9.7553e-03 eta 2:12:19
epoch [4/30] batch [680/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.8110 (1.9706) lr 9.7553e-03 eta 2:12:19
epoch [4/30] batch [700/796] time 0.403 (0.381) data 0.000 (0.001) loss 2.5059 (1.9701) lr 9.7553e-03 eta 2:12:09
epoch [4/30] batch [720/796] time 0.382 (0.381) data 0.000 (0.001) loss 0.5425 (1.9715) lr 9.7553e-03 eta 2:11:59
epoch [4/30] batch [740/796] time 0.384 (0.381) data 0.000 (0.001) loss 0.0394 (1.9581) lr 9.7553e-03 eta 2:11:53
epoch [4/30] batch [760/796] time 0.382 (0.381) data 0.000 (0.001) loss 1.1680 (1.9577) lr 9.7553e-03 eta 2:11:41
epoch [4/30] batch [780/796] time 0.344 (0.380) data 0.000 (0.001) loss 0.8486 (1.9536) lr 9.7553e-03 eta 2:11:17
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.61s/it] 10%|█         | 2/20 [00:06<00:48,  2.68s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.59s/it] 20%|██        | 4/20 [00:06<00:17,  1.08s/it] 25%|██▌       | 5/20 [00:07<00:11,  1.26it/s] 30%|███       | 6/20 [00:07<00:08,  1.59it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.91it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.53it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.87it/s] 60%|██████    | 12/20 [00:09<00:02,  3.03it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.23it/s] 70%|███████   | 14/20 [00:09<00:01,  3.54it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.65it/s] 80%|████████  | 16/20 [00:10<00:01,  3.76it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.74it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.14it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.47it/s]100%|██████████| 20/20 [00:10<00:00,  4.81it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,557
* accuracy: 78.2%
* error: 21.8%
* macro_f1: 77.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/796] time 0.375 (0.434) data 0.000 (0.037) loss 2.7832 (1.9018) lr 9.5677e-03 eta 2:29:36
epoch [5/30] batch [40/796] time 0.361 (0.407) data 0.000 (0.019) loss 1.2754 (2.0780) lr 9.5677e-03 eta 2:20:00
epoch [5/30] batch [60/796] time 0.405 (0.397) data 0.000 (0.013) loss 1.4756 (2.2410) lr 9.5677e-03 eta 2:16:28
epoch [5/30] batch [80/796] time 0.392 (0.393) data 0.000 (0.009) loss 2.0449 (2.2023) lr 9.5677e-03 eta 2:15:07
epoch [5/30] batch [100/796] time 0.389 (0.390) data 0.000 (0.008) loss 2.6641 (2.1168) lr 9.5677e-03 eta 2:13:50
epoch [5/30] batch [120/796] time 0.399 (0.388) data 0.000 (0.006) loss 0.6025 (2.0637) lr 9.5677e-03 eta 2:13:02
epoch [5/30] batch [140/796] time 0.413 (0.387) data 0.000 (0.006) loss 1.2998 (1.9788) lr 9.5677e-03 eta 2:12:41
epoch [5/30] batch [160/796] time 0.384 (0.386) data 0.000 (0.005) loss 1.6357 (1.9415) lr 9.5677e-03 eta 2:12:13
epoch [5/30] batch [180/796] time 0.377 (0.386) data 0.000 (0.004) loss 4.1406 (1.9221) lr 9.5677e-03 eta 2:12:01
epoch [5/30] batch [200/796] time 0.365 (0.386) data 0.000 (0.004) loss 0.8594 (1.9056) lr 9.5677e-03 eta 2:11:58
epoch [5/30] batch [220/796] time 0.383 (0.386) data 0.000 (0.004) loss 2.9355 (1.9127) lr 9.5677e-03 eta 2:11:33
epoch [5/30] batch [240/796] time 0.379 (0.386) data 0.000 (0.003) loss 0.0859 (1.8916) lr 9.5677e-03 eta 2:11:33
epoch [5/30] batch [260/796] time 0.376 (0.385) data 0.000 (0.003) loss 0.6455 (1.8862) lr 9.5677e-03 eta 2:11:15
epoch [5/30] batch [280/796] time 0.374 (0.385) data 0.000 (0.003) loss 0.9580 (1.8441) lr 9.5677e-03 eta 2:11:09
epoch [5/30] batch [300/796] time 0.411 (0.385) data 0.000 (0.003) loss 0.3262 (1.8347) lr 9.5677e-03 eta 2:10:51
epoch [5/30] batch [320/796] time 0.384 (0.385) data 0.000 (0.003) loss 2.6973 (1.8269) lr 9.5677e-03 eta 2:10:42
epoch [5/30] batch [340/796] time 0.360 (0.384) data 0.000 (0.002) loss 1.6250 (1.8046) lr 9.5677e-03 eta 2:10:22
epoch [5/30] batch [360/796] time 0.371 (0.384) data 0.000 (0.002) loss 0.8081 (1.8070) lr 9.5677e-03 eta 2:10:10
epoch [5/30] batch [380/796] time 0.404 (0.384) data 0.000 (0.002) loss 0.2255 (1.8062) lr 9.5677e-03 eta 2:09:53
epoch [5/30] batch [400/796] time 0.355 (0.383) data 0.000 (0.002) loss 0.1113 (1.8109) lr 9.5677e-03 eta 2:09:41
epoch [5/30] batch [420/796] time 0.382 (0.383) data 0.000 (0.002) loss 2.4785 (1.8114) lr 9.5677e-03 eta 2:09:31
epoch [5/30] batch [440/796] time 0.402 (0.383) data 0.000 (0.002) loss 2.7266 (1.8157) lr 9.5677e-03 eta 2:09:18
epoch [5/30] batch [460/796] time 0.365 (0.383) data 0.000 (0.002) loss 0.5693 (1.8251) lr 9.5677e-03 eta 2:09:06
epoch [5/30] batch [480/796] time 0.390 (0.383) data 0.000 (0.002) loss 3.0957 (1.8442) lr 9.5677e-03 eta 2:08:59
epoch [5/30] batch [500/796] time 0.353 (0.382) data 0.000 (0.002) loss 2.4316 (1.8523) lr 9.5677e-03 eta 2:08:43
epoch [5/30] batch [520/796] time 0.380 (0.382) data 0.000 (0.002) loss 1.3252 (1.8558) lr 9.5677e-03 eta 2:08:28
epoch [5/30] batch [540/796] time 0.356 (0.382) data 0.000 (0.002) loss 1.0605 (1.8579) lr 9.5677e-03 eta 2:08:17
epoch [5/30] batch [560/796] time 0.353 (0.382) data 0.000 (0.002) loss 4.8438 (1.8617) lr 9.5677e-03 eta 2:08:05
epoch [5/30] batch [580/796] time 0.402 (0.382) data 0.000 (0.002) loss 2.1641 (1.8578) lr 9.5677e-03 eta 2:07:59
epoch [5/30] batch [600/796] time 0.417 (0.382) data 0.000 (0.001) loss 2.5566 (1.8599) lr 9.5677e-03 eta 2:07:50
epoch [5/30] batch [620/796] time 0.358 (0.382) data 0.000 (0.001) loss 5.6719 (1.8713) lr 9.5677e-03 eta 2:07:39
epoch [5/30] batch [640/796] time 0.390 (0.381) data 0.000 (0.001) loss 3.1895 (1.8574) lr 9.5677e-03 eta 2:07:30
epoch [5/30] batch [660/796] time 0.353 (0.381) data 0.000 (0.001) loss 5.8633 (1.8495) lr 9.5677e-03 eta 2:07:21
epoch [5/30] batch [680/796] time 0.352 (0.381) data 0.000 (0.001) loss 1.2949 (1.8490) lr 9.5677e-03 eta 2:07:06
epoch [5/30] batch [700/796] time 0.358 (0.381) data 0.000 (0.001) loss 0.3687 (1.8417) lr 9.5677e-03 eta 2:06:53
epoch [5/30] batch [720/796] time 0.430 (0.381) data 0.000 (0.001) loss 0.4949 (1.8406) lr 9.5677e-03 eta 2:06:48
epoch [5/30] batch [740/796] time 0.455 (0.381) data 0.000 (0.001) loss 1.1074 (1.8499) lr 9.5677e-03 eta 2:06:41
epoch [5/30] batch [760/796] time 0.354 (0.381) data 0.000 (0.001) loss 1.9648 (1.8381) lr 9.5677e-03 eta 2:06:33
epoch [5/30] batch [780/796] time 0.342 (0.380) data 0.000 (0.001) loss 3.2891 (1.8556) lr 9.5677e-03 eta 2:06:11
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.58s/it] 10%|█         | 2/20 [00:06<00:51,  2.87s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.43it/s] 50%|█████     | 10/20 [00:08<00:03,  2.68it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.21it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.37it/s] 70%|███████   | 14/20 [00:09<00:01,  3.61it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.71it/s] 80%|████████  | 16/20 [00:10<00:01,  3.76it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.73it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.13it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.46it/s]100%|██████████| 20/20 [00:11<00:00,  4.80it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,560
* accuracy: 78.4%
* error: 21.6%
* macro_f1: 77.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/796] time 0.349 (0.421) data 0.000 (0.036) loss 2.2500 (1.5364) lr 9.3301e-03 eta 2:19:25
epoch [6/30] batch [40/796] time 0.348 (0.397) data 0.000 (0.018) loss 0.4475 (1.7289) lr 9.3301e-03 eta 2:11:29
epoch [6/30] batch [60/796] time 0.391 (0.394) data 0.000 (0.012) loss 0.1879 (1.8163) lr 9.3301e-03 eta 2:10:16
epoch [6/30] batch [80/796] time 0.359 (0.391) data 0.000 (0.009) loss 0.9214 (1.7342) lr 9.3301e-03 eta 2:09:14
epoch [6/30] batch [100/796] time 0.385 (0.389) data 0.000 (0.007) loss 1.2510 (1.6939) lr 9.3301e-03 eta 2:08:27
epoch [6/30] batch [120/796] time 0.348 (0.388) data 0.000 (0.006) loss 0.4006 (1.6998) lr 9.3301e-03 eta 2:07:53
epoch [6/30] batch [140/796] time 0.353 (0.387) data 0.000 (0.005) loss 0.7686 (1.7202) lr 9.3301e-03 eta 2:07:35
epoch [6/30] batch [160/796] time 0.385 (0.386) data 0.000 (0.005) loss 1.6895 (1.7075) lr 9.3301e-03 eta 2:07:08
epoch [6/30] batch [180/796] time 0.395 (0.386) data 0.000 (0.004) loss 0.3347 (1.6620) lr 9.3301e-03 eta 2:06:58
epoch [6/30] batch [200/796] time 0.359 (0.386) data 0.000 (0.004) loss 0.4233 (1.6781) lr 9.3301e-03 eta 2:06:43
epoch [6/30] batch [220/796] time 0.387 (0.385) data 0.000 (0.004) loss 2.5547 (1.6912) lr 9.3301e-03 eta 2:06:23
epoch [6/30] batch [240/796] time 0.404 (0.385) data 0.000 (0.003) loss 2.7012 (1.7059) lr 9.3301e-03 eta 2:06:05
epoch [6/30] batch [260/796] time 0.408 (0.384) data 0.000 (0.003) loss 4.3711 (1.7103) lr 9.3301e-03 eta 2:05:46
epoch [6/30] batch [280/796] time 0.372 (0.383) data 0.000 (0.003) loss 6.8906 (1.7647) lr 9.3301e-03 eta 2:05:24
epoch [6/30] batch [300/796] time 0.391 (0.383) data 0.000 (0.003) loss 0.4949 (1.7483) lr 9.3301e-03 eta 2:05:11
epoch [6/30] batch [320/796] time 0.366 (0.383) data 0.000 (0.002) loss 1.5332 (1.7583) lr 9.3301e-03 eta 2:04:51
epoch [6/30] batch [340/796] time 0.396 (0.382) data 0.000 (0.002) loss 1.0420 (1.7813) lr 9.3301e-03 eta 2:04:34
epoch [6/30] batch [360/796] time 0.403 (0.382) data 0.000 (0.002) loss 0.6465 (1.7703) lr 9.3301e-03 eta 2:04:26
epoch [6/30] batch [380/796] time 0.394 (0.382) data 0.000 (0.002) loss 2.4121 (1.7681) lr 9.3301e-03 eta 2:04:17
epoch [6/30] batch [400/796] time 0.359 (0.382) data 0.000 (0.002) loss 0.9268 (1.7826) lr 9.3301e-03 eta 2:04:08
epoch [6/30] batch [420/796] time 0.349 (0.382) data 0.000 (0.002) loss 5.4180 (1.7861) lr 9.3301e-03 eta 2:03:53
epoch [6/30] batch [440/796] time 0.385 (0.381) data 0.000 (0.002) loss 1.1416 (1.8235) lr 9.3301e-03 eta 2:03:42
epoch [6/30] batch [460/796] time 0.365 (0.381) data 0.000 (0.002) loss 1.0928 (1.8114) lr 9.3301e-03 eta 2:03:32
epoch [6/30] batch [480/796] time 0.375 (0.381) data 0.000 (0.002) loss 2.8965 (1.8163) lr 9.3301e-03 eta 2:03:24
epoch [6/30] batch [500/796] time 0.388 (0.381) data 0.000 (0.002) loss 0.6675 (1.8137) lr 9.3301e-03 eta 2:03:17
epoch [6/30] batch [520/796] time 0.393 (0.382) data 0.000 (0.002) loss 0.5234 (1.8184) lr 9.3301e-03 eta 2:03:14
epoch [6/30] batch [540/796] time 0.398 (0.381) data 0.000 (0.002) loss 2.3066 (1.8123) lr 9.3301e-03 eta 2:03:04
epoch [6/30] batch [560/796] time 0.380 (0.381) data 0.000 (0.002) loss 2.7246 (1.8201) lr 9.3301e-03 eta 2:02:56
epoch [6/30] batch [580/796] time 0.410 (0.381) data 0.000 (0.001) loss 2.5371 (1.8107) lr 9.3301e-03 eta 2:02:48
epoch [6/30] batch [600/796] time 0.392 (0.382) data 0.000 (0.001) loss 0.6963 (1.7981) lr 9.3301e-03 eta 2:02:48
epoch [6/30] batch [620/796] time 0.385 (0.382) data 0.000 (0.001) loss 0.1985 (1.8002) lr 9.3301e-03 eta 2:02:38
epoch [6/30] batch [640/796] time 0.369 (0.382) data 0.000 (0.001) loss 0.9175 (1.8154) lr 9.3301e-03 eta 2:02:28
epoch [6/30] batch [660/796] time 0.403 (0.381) data 0.000 (0.001) loss 1.2354 (1.8038) lr 9.3301e-03 eta 2:02:19
epoch [6/30] batch [680/796] time 0.401 (0.381) data 0.000 (0.001) loss 1.6973 (1.8073) lr 9.3301e-03 eta 2:02:11
epoch [6/30] batch [700/796] time 0.361 (0.381) data 0.000 (0.001) loss 4.1523 (1.8094) lr 9.3301e-03 eta 2:02:04
epoch [6/30] batch [720/796] time 0.377 (0.381) data 0.000 (0.001) loss 1.0410 (1.8141) lr 9.3301e-03 eta 2:01:52
epoch [6/30] batch [740/796] time 0.395 (0.381) data 0.000 (0.001) loss 2.9727 (1.8195) lr 9.3301e-03 eta 2:01:47
epoch [6/30] batch [760/796] time 0.389 (0.381) data 0.000 (0.001) loss 2.7578 (1.8238) lr 9.3301e-03 eta 2:01:38
epoch [6/30] batch [780/796] time 0.341 (0.380) data 0.000 (0.001) loss 1.0381 (1.8223) lr 9.3301e-03 eta 2:01:15
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.54s/it] 10%|█         | 2/20 [00:06<00:52,  2.91s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.72s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.49it/s] 50%|█████     | 10/20 [00:08<00:03,  2.75it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.02it/s] 60%|██████    | 12/20 [00:09<00:02,  3.21it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.42it/s] 70%|███████   | 14/20 [00:09<00:01,  3.59it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.66it/s] 80%|████████  | 16/20 [00:10<00:01,  3.85it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.05it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.13it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.46it/s]100%|██████████| 20/20 [00:11<00:00,  4.80it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,580
* accuracy: 79.4%
* error: 20.6%
* macro_f1: 78.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/796] time 0.369 (0.419) data 0.000 (0.033) loss 1.9902 (1.7911) lr 9.0451e-03 eta 2:13:15
epoch [7/30] batch [40/796] time 0.361 (0.398) data 0.000 (0.017) loss 3.2148 (1.9727) lr 9.0451e-03 eta 2:06:20
epoch [7/30] batch [60/796] time 0.365 (0.393) data 0.000 (0.011) loss 0.9653 (2.0518) lr 9.0451e-03 eta 2:04:38
epoch [7/30] batch [80/796] time 0.351 (0.388) data 0.000 (0.008) loss 3.0039 (1.9630) lr 9.0451e-03 eta 2:03:06
epoch [7/30] batch [100/796] time 0.360 (0.387) data 0.000 (0.007) loss 6.4961 (1.9894) lr 9.0451e-03 eta 2:02:39
epoch [7/30] batch [120/796] time 0.346 (0.386) data 0.000 (0.006) loss 0.2771 (1.8992) lr 9.0451e-03 eta 2:02:05
epoch [7/30] batch [140/796] time 0.357 (0.383) data 0.000 (0.005) loss 3.8516 (2.0194) lr 9.0451e-03 eta 2:01:06
epoch [7/30] batch [160/796] time 0.404 (0.382) data 0.000 (0.004) loss 0.6558 (2.0159) lr 9.0451e-03 eta 2:00:45
epoch [7/30] batch [180/796] time 0.351 (0.383) data 0.000 (0.004) loss 1.8057 (2.0211) lr 9.0451e-03 eta 2:00:51
epoch [7/30] batch [200/796] time 0.391 (0.383) data 0.000 (0.004) loss 0.5464 (1.9404) lr 9.0451e-03 eta 2:00:49
epoch [7/30] batch [220/796] time 0.353 (0.383) data 0.000 (0.003) loss 3.1855 (1.9764) lr 9.0451e-03 eta 2:00:32
epoch [7/30] batch [240/796] time 0.406 (0.383) data 0.000 (0.003) loss 4.9219 (1.9618) lr 9.0451e-03 eta 2:00:17
epoch [7/30] batch [260/796] time 0.372 (0.383) data 0.000 (0.003) loss 2.1602 (1.9960) lr 9.0451e-03 eta 2:00:07
epoch [7/30] batch [280/796] time 0.394 (0.382) data 0.000 (0.003) loss 0.9014 (2.0070) lr 9.0451e-03 eta 1:59:56
epoch [7/30] batch [300/796] time 0.403 (0.383) data 0.000 (0.002) loss 1.6748 (2.0084) lr 9.0451e-03 eta 1:59:56
epoch [7/30] batch [320/796] time 0.380 (0.383) data 0.000 (0.002) loss 1.6299 (2.0323) lr 9.0451e-03 eta 1:59:49
epoch [7/30] batch [340/796] time 0.380 (0.383) data 0.000 (0.002) loss 1.2891 (2.0448) lr 9.0451e-03 eta 1:59:39
epoch [7/30] batch [360/796] time 0.379 (0.382) data 0.000 (0.002) loss 2.1562 (2.0171) lr 9.0451e-03 eta 1:59:29
epoch [7/30] batch [380/796] time 0.399 (0.383) data 0.000 (0.002) loss 7.7383 (2.0109) lr 9.0451e-03 eta 1:59:28
epoch [7/30] batch [400/796] time 0.385 (0.383) data 0.000 (0.002) loss 2.3379 (2.0165) lr 9.0451e-03 eta 1:59:21
epoch [7/30] batch [420/796] time 0.404 (0.383) data 0.000 (0.002) loss 3.2559 (2.0109) lr 9.0451e-03 eta 1:59:13
epoch [7/30] batch [440/796] time 0.387 (0.383) data 0.000 (0.002) loss 0.4580 (1.9891) lr 9.0451e-03 eta 1:59:06
epoch [7/30] batch [460/796] time 0.380 (0.383) data 0.000 (0.002) loss 4.8906 (1.9847) lr 9.0451e-03 eta 1:58:53
epoch [7/30] batch [480/796] time 0.389 (0.382) data 0.000 (0.002) loss 0.9014 (1.9685) lr 9.0451e-03 eta 1:58:42
epoch [7/30] batch [500/796] time 0.398 (0.382) data 0.000 (0.002) loss 0.2054 (1.9569) lr 9.0451e-03 eta 1:58:32
epoch [7/30] batch [520/796] time 0.400 (0.382) data 0.000 (0.002) loss 1.8984 (1.9452) lr 9.0451e-03 eta 1:58:19
epoch [7/30] batch [540/796] time 0.362 (0.382) data 0.000 (0.001) loss 4.1758 (1.9467) lr 9.0451e-03 eta 1:58:13
epoch [7/30] batch [560/796] time 0.388 (0.382) data 0.000 (0.001) loss 4.0078 (1.9447) lr 9.0451e-03 eta 1:58:09
epoch [7/30] batch [580/796] time 0.404 (0.383) data 0.000 (0.001) loss 0.9224 (1.9334) lr 9.0451e-03 eta 1:58:05
epoch [7/30] batch [600/796] time 0.358 (0.382) data 0.000 (0.001) loss 1.2852 (1.9300) lr 9.0451e-03 eta 1:57:54
epoch [7/30] batch [620/796] time 0.401 (0.382) data 0.000 (0.001) loss 1.0879 (1.9215) lr 9.0451e-03 eta 1:57:49
epoch [7/30] batch [640/796] time 0.387 (0.382) data 0.000 (0.001) loss 2.8809 (1.9194) lr 9.0451e-03 eta 1:57:37
epoch [7/30] batch [660/796] time 0.350 (0.382) data 0.000 (0.001) loss 0.7339 (1.9096) lr 9.0451e-03 eta 1:57:24
epoch [7/30] batch [680/796] time 0.355 (0.382) data 0.000 (0.001) loss 0.5000 (1.9079) lr 9.0451e-03 eta 1:57:16
epoch [7/30] batch [700/796] time 0.366 (0.382) data 0.000 (0.001) loss 2.9043 (1.8910) lr 9.0451e-03 eta 1:57:06
epoch [7/30] batch [720/796] time 0.402 (0.382) data 0.000 (0.001) loss 1.4551 (1.8817) lr 9.0451e-03 eta 1:56:57
epoch [7/30] batch [740/796] time 0.369 (0.382) data 0.000 (0.001) loss 2.7012 (1.8867) lr 9.0451e-03 eta 1:56:48
epoch [7/30] batch [760/796] time 0.346 (0.381) data 0.000 (0.001) loss 0.7881 (1.8862) lr 9.0451e-03 eta 1:56:37
epoch [7/30] batch [780/796] time 0.339 (0.381) data 0.000 (0.001) loss 3.4961 (1.8950) lr 9.0451e-03 eta 1:56:14
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.68s/it] 10%|█         | 2/20 [00:06<00:52,  2.91s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.71s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.83it/s] 40%|████      | 8/20 [00:08<00:05,  2.14it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.81it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.05it/s] 60%|██████    | 12/20 [00:09<00:02,  3.28it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.41it/s] 70%|███████   | 14/20 [00:09<00:01,  3.66it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.67it/s] 80%|████████  | 16/20 [00:10<00:01,  3.95it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.90it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.26it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.57it/s]100%|██████████| 20/20 [00:11<00:00,  4.89it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,565
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 78.1%

epoch [8/30] batch [20/796] time 0.464 (0.417) data 0.000 (0.033) loss 1.0146 (1.9580) lr 8.7157e-03 eta 2:07:12
epoch [8/30] batch [40/796] time 0.391 (0.400) data 0.000 (0.017) loss 1.0146 (1.9973) lr 8.7157e-03 eta 2:01:41
epoch [8/30] batch [60/796] time 0.393 (0.392) data 0.000 (0.011) loss 0.2698 (1.8702) lr 8.7157e-03 eta 1:59:14
epoch [8/30] batch [80/796] time 0.385 (0.387) data 0.000 (0.009) loss 3.1289 (1.7879) lr 8.7157e-03 eta 1:57:31
epoch [8/30] batch [100/796] time 0.408 (0.386) data 0.000 (0.007) loss 2.0059 (1.7353) lr 8.7157e-03 eta 1:57:01
epoch [8/30] batch [120/796] time 0.366 (0.385) data 0.000 (0.006) loss 0.9595 (1.6318) lr 8.7157e-03 eta 1:56:49
epoch [8/30] batch [140/796] time 0.384 (0.384) data 0.000 (0.005) loss 2.5293 (1.6271) lr 8.7157e-03 eta 1:56:23
epoch [8/30] batch [160/796] time 0.413 (0.385) data 0.000 (0.004) loss 1.3213 (1.6803) lr 8.7157e-03 eta 1:56:18
epoch [8/30] batch [180/796] time 0.396 (0.385) data 0.000 (0.004) loss 1.1045 (1.7617) lr 8.7157e-03 eta 1:56:14
epoch [8/30] batch [200/796] time 0.402 (0.384) data 0.000 (0.004) loss 1.7070 (1.7241) lr 8.7157e-03 eta 1:55:51
epoch [8/30] batch [220/796] time 0.384 (0.383) data 0.000 (0.003) loss 1.2686 (1.6966) lr 8.7157e-03 eta 1:55:36
epoch [8/30] batch [240/796] time 0.391 (0.383) data 0.000 (0.003) loss 2.7734 (1.7239) lr 8.7157e-03 eta 1:55:25
epoch [8/30] batch [260/796] time 0.403 (0.383) data 0.000 (0.003) loss 2.2734 (1.7322) lr 8.7157e-03 eta 1:55:11
epoch [8/30] batch [280/796] time 0.388 (0.383) data 0.000 (0.003) loss 0.6064 (1.7138) lr 8.7157e-03 eta 1:55:02
epoch [8/30] batch [300/796] time 0.354 (0.383) data 0.000 (0.002) loss 2.5430 (1.7079) lr 8.7157e-03 eta 1:54:52
epoch [8/30] batch [320/796] time 0.384 (0.383) data 0.000 (0.002) loss 0.3872 (1.7037) lr 8.7157e-03 eta 1:54:53
epoch [8/30] batch [340/796] time 0.374 (0.383) data 0.000 (0.002) loss 1.3281 (1.7223) lr 8.7157e-03 eta 1:54:42
epoch [8/30] batch [360/796] time 0.387 (0.383) data 0.000 (0.002) loss 1.1035 (1.7288) lr 8.7157e-03 eta 1:54:33
epoch [8/30] batch [380/796] time 0.381 (0.383) data 0.000 (0.002) loss 0.6606 (1.7361) lr 8.7157e-03 eta 1:54:18
epoch [8/30] batch [400/796] time 0.365 (0.383) data 0.000 (0.002) loss 0.9062 (1.7410) lr 8.7157e-03 eta 1:54:10
epoch [8/30] batch [420/796] time 0.389 (0.382) data 0.000 (0.002) loss 7.9805 (1.7561) lr 8.7157e-03 eta 1:53:54
epoch [8/30] batch [440/796] time 0.398 (0.382) data 0.000 (0.002) loss 4.5117 (1.7802) lr 8.7157e-03 eta 1:53:44
epoch [8/30] batch [460/796] time 0.381 (0.382) data 0.000 (0.002) loss 1.5518 (1.7972) lr 8.7157e-03 eta 1:53:41
epoch [8/30] batch [480/796] time 0.354 (0.382) data 0.000 (0.002) loss 2.6465 (1.7840) lr 8.7157e-03 eta 1:53:33
epoch [8/30] batch [500/796] time 0.408 (0.382) data 0.000 (0.002) loss 1.2480 (1.7810) lr 8.7157e-03 eta 1:53:29
epoch [8/30] batch [520/796] time 0.368 (0.382) data 0.000 (0.002) loss 1.7148 (1.7784) lr 8.7157e-03 eta 1:53:17
epoch [8/30] batch [540/796] time 0.361 (0.382) data 0.000 (0.001) loss 2.8359 (1.7887) lr 8.7157e-03 eta 1:53:02
epoch [8/30] batch [560/796] time 0.363 (0.382) data 0.000 (0.001) loss 3.4062 (1.7954) lr 8.7157e-03 eta 1:52:56
epoch [8/30] batch [580/796] time 0.394 (0.382) data 0.000 (0.001) loss 0.2993 (1.7859) lr 8.7157e-03 eta 1:52:47
epoch [8/30] batch [600/796] time 0.418 (0.382) data 0.000 (0.001) loss 0.4229 (1.7692) lr 8.7157e-03 eta 1:52:36
epoch [8/30] batch [620/796] time 0.385 (0.381) data 0.000 (0.001) loss 0.6807 (1.7422) lr 8.7157e-03 eta 1:52:26
epoch [8/30] batch [640/796] time 0.357 (0.382) data 0.000 (0.001) loss 0.3650 (1.7554) lr 8.7157e-03 eta 1:52:21
epoch [8/30] batch [660/796] time 0.393 (0.382) data 0.000 (0.001) loss 0.8643 (1.7615) lr 8.7157e-03 eta 1:52:12
epoch [8/30] batch [680/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.9375 (1.7629) lr 8.7157e-03 eta 1:52:03
epoch [8/30] batch [700/796] time 0.363 (0.381) data 0.000 (0.001) loss 1.5596 (1.7666) lr 8.7157e-03 eta 1:51:57
epoch [8/30] batch [720/796] time 0.359 (0.381) data 0.000 (0.001) loss 0.3831 (1.7564) lr 8.7157e-03 eta 1:51:45
epoch [8/30] batch [740/796] time 0.366 (0.381) data 0.000 (0.001) loss 0.7974 (1.7612) lr 8.7157e-03 eta 1:51:35
epoch [8/30] batch [760/796] time 0.370 (0.381) data 0.000 (0.001) loss 4.5312 (1.7678) lr 8.7157e-03 eta 1:51:30
epoch [8/30] batch [780/796] time 0.339 (0.380) data 0.000 (0.001) loss 0.6924 (1.7680) lr 8.7157e-03 eta 1:51:07
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.68s/it] 10%|█         | 2/20 [00:06<00:52,  2.92s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.73s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.52it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.47it/s] 50%|█████     | 10/20 [00:08<00:03,  2.76it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.01it/s] 60%|██████    | 12/20 [00:09<00:02,  3.20it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.35it/s] 70%|███████   | 14/20 [00:10<00:01,  3.58it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.70it/s] 80%|████████  | 16/20 [00:10<00:01,  3.90it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.91it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.26it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.57it/s]100%|██████████| 20/20 [00:11<00:00,  4.88it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,585
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 79.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [9/30] batch [20/796] time 0.399 (0.418) data 0.000 (0.034) loss 1.5781 (1.5501) lr 8.3457e-03 eta 2:01:52
epoch [9/30] batch [40/796] time 0.408 (0.398) data 0.000 (0.017) loss 2.5527 (1.6299) lr 8.3457e-03 eta 1:55:58
epoch [9/30] batch [60/796] time 0.393 (0.394) data 0.000 (0.011) loss 2.0020 (1.5534) lr 8.3457e-03 eta 1:54:32
epoch [9/30] batch [80/796] time 0.374 (0.390) data 0.000 (0.009) loss 0.9771 (1.5977) lr 8.3457e-03 eta 1:53:15
epoch [9/30] batch [100/796] time 0.390 (0.388) data 0.000 (0.007) loss 0.5142 (1.5936) lr 8.3457e-03 eta 1:52:31
epoch [9/30] batch [120/796] time 0.394 (0.386) data 0.000 (0.006) loss 2.7480 (1.6085) lr 8.3457e-03 eta 1:51:50
epoch [9/30] batch [140/796] time 0.398 (0.386) data 0.000 (0.005) loss 3.8008 (1.6279) lr 8.3457e-03 eta 1:51:40
epoch [9/30] batch [160/796] time 0.371 (0.385) data 0.000 (0.004) loss 3.0508 (1.6570) lr 8.3457e-03 eta 1:51:17
epoch [9/30] batch [180/796] time 0.428 (0.385) data 0.000 (0.004) loss 1.5986 (1.6691) lr 8.3457e-03 eta 1:51:04
epoch [9/30] batch [200/796] time 0.395 (0.384) data 0.000 (0.004) loss 0.1760 (1.6451) lr 8.3457e-03 eta 1:50:45
epoch [9/30] batch [220/796] time 0.356 (0.384) data 0.000 (0.003) loss 2.3320 (1.6981) lr 8.3457e-03 eta 1:50:33
epoch [9/30] batch [240/796] time 0.352 (0.384) data 0.000 (0.003) loss 1.3086 (1.7240) lr 8.3457e-03 eta 1:50:29
epoch [9/30] batch [260/796] time 0.383 (0.384) data 0.000 (0.003) loss 1.4600 (1.7012) lr 8.3457e-03 eta 1:50:16
epoch [9/30] batch [280/796] time 0.384 (0.384) data 0.000 (0.003) loss 2.1445 (1.6966) lr 8.3457e-03 eta 1:50:11
epoch [9/30] batch [300/796] time 0.364 (0.383) data 0.000 (0.002) loss 1.7402 (1.7142) lr 8.3457e-03 eta 1:49:54
epoch [9/30] batch [320/796] time 0.404 (0.383) data 0.000 (0.002) loss 0.8945 (1.7013) lr 8.3457e-03 eta 1:49:46
epoch [9/30] batch [340/796] time 0.386 (0.383) data 0.000 (0.002) loss 0.8281 (1.7144) lr 8.3457e-03 eta 1:49:32
epoch [9/30] batch [360/796] time 0.365 (0.382) data 0.000 (0.002) loss 0.6865 (1.6883) lr 8.3457e-03 eta 1:49:15
epoch [9/30] batch [380/796] time 0.379 (0.382) data 0.000 (0.002) loss 1.1377 (1.7114) lr 8.3457e-03 eta 1:49:08
epoch [9/30] batch [400/796] time 0.380 (0.382) data 0.000 (0.002) loss 1.2197 (1.7117) lr 8.3457e-03 eta 1:49:01
epoch [9/30] batch [420/796] time 0.369 (0.382) data 0.000 (0.002) loss 0.0635 (1.7122) lr 8.3457e-03 eta 1:48:53
epoch [9/30] batch [440/796] time 0.380 (0.382) data 0.000 (0.002) loss 1.3926 (1.7215) lr 8.3457e-03 eta 1:48:42
epoch [9/30] batch [460/796] time 0.393 (0.382) data 0.000 (0.002) loss 2.4277 (1.7422) lr 8.3457e-03 eta 1:48:38
epoch [9/30] batch [480/796] time 0.403 (0.382) data 0.000 (0.002) loss 2.3477 (1.7470) lr 8.3457e-03 eta 1:48:25
epoch [9/30] batch [500/796] time 0.405 (0.382) data 0.000 (0.002) loss 0.3489 (1.7366) lr 8.3457e-03 eta 1:48:25
epoch [9/30] batch [520/796] time 0.394 (0.382) data 0.000 (0.002) loss 4.0273 (1.7519) lr 8.3457e-03 eta 1:48:13
epoch [9/30] batch [540/796] time 0.361 (0.382) data 0.000 (0.001) loss 5.2734 (1.7406) lr 8.3457e-03 eta 1:48:03
epoch [9/30] batch [560/796] time 0.352 (0.382) data 0.000 (0.001) loss 1.9736 (1.7647) lr 8.3457e-03 eta 1:47:50
epoch [9/30] batch [580/796] time 0.401 (0.382) data 0.000 (0.001) loss 1.4414 (1.7545) lr 8.3457e-03 eta 1:47:43
epoch [9/30] batch [600/796] time 0.403 (0.382) data 0.000 (0.001) loss 1.4629 (1.7526) lr 8.3457e-03 eta 1:47:36
epoch [9/30] batch [620/796] time 0.392 (0.382) data 0.000 (0.001) loss 1.9004 (1.7480) lr 8.3457e-03 eta 1:47:30
epoch [9/30] batch [640/796] time 0.344 (0.382) data 0.000 (0.001) loss 0.1503 (1.7524) lr 8.3457e-03 eta 1:47:21
epoch [9/30] batch [660/796] time 0.387 (0.382) data 0.000 (0.001) loss 3.8613 (1.7576) lr 8.3457e-03 eta 1:47:09
epoch [9/30] batch [680/796] time 0.352 (0.382) data 0.000 (0.001) loss 1.6611 (1.7648) lr 8.3457e-03 eta 1:47:05
epoch [9/30] batch [700/796] time 0.397 (0.382) data 0.000 (0.001) loss 2.2129 (1.7862) lr 8.3457e-03 eta 1:46:57
epoch [9/30] batch [720/796] time 0.349 (0.382) data 0.000 (0.001) loss 1.2939 (1.7978) lr 8.3457e-03 eta 1:46:50
epoch [9/30] batch [740/796] time 0.397 (0.382) data 0.000 (0.001) loss 0.3979 (1.7895) lr 8.3457e-03 eta 1:46:42
epoch [9/30] batch [760/796] time 0.354 (0.382) data 0.000 (0.001) loss 0.4004 (1.7812) lr 8.3457e-03 eta 1:46:32
epoch [9/30] batch [780/796] time 0.338 (0.381) data 0.000 (0.001) loss 0.8027 (1.7707) lr 8.3457e-03 eta 1:46:11
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.51s/it] 10%|█         | 2/20 [00:06<00:50,  2.83s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.47it/s] 50%|█████     | 10/20 [00:08<00:03,  2.68it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.98it/s] 60%|██████    | 12/20 [00:09<00:02,  3.32it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.60it/s] 70%|███████   | 14/20 [00:09<00:01,  3.67it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.86it/s] 80%|████████  | 16/20 [00:10<00:00,  4.17it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.04it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.69it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.09it/s]100%|██████████| 20/20 [00:11<00:00,  4.49it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,594
* accuracy: 80.1%
* error: 19.9%
* macro_f1: 79.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/796] time 0.385 (0.425) data 0.000 (0.040) loss 2.2988 (1.5187) lr 7.9389e-03 eta 1:58:12
epoch [10/30] batch [40/796] time 0.379 (0.403) data 0.000 (0.020) loss 0.6680 (1.4690) lr 7.9389e-03 eta 1:51:59
epoch [10/30] batch [60/796] time 0.398 (0.397) data 0.000 (0.013) loss 0.4404 (1.5507) lr 7.9389e-03 eta 1:50:12
epoch [10/30] batch [80/796] time 0.409 (0.393) data 0.000 (0.010) loss 1.4912 (1.6142) lr 7.9389e-03 eta 1:49:03
epoch [10/30] batch [100/796] time 0.346 (0.390) data 0.000 (0.008) loss 1.5693 (1.6039) lr 7.9389e-03 eta 1:47:53
epoch [10/30] batch [120/796] time 0.353 (0.387) data 0.000 (0.007) loss 2.2363 (1.5962) lr 7.9389e-03 eta 1:47:08
epoch [10/30] batch [140/796] time 0.409 (0.387) data 0.000 (0.006) loss 1.0889 (1.6258) lr 7.9389e-03 eta 1:46:47
epoch [10/30] batch [160/796] time 0.352 (0.386) data 0.000 (0.005) loss 2.7109 (1.5981) lr 7.9389e-03 eta 1:46:23
epoch [10/30] batch [180/796] time 0.368 (0.385) data 0.000 (0.005) loss 0.7905 (1.5724) lr 7.9389e-03 eta 1:45:59
epoch [10/30] batch [200/796] time 0.354 (0.384) data 0.000 (0.004) loss 1.4824 (1.5738) lr 7.9389e-03 eta 1:45:38
epoch [10/30] batch [220/796] time 0.385 (0.384) data 0.000 (0.004) loss 1.2256 (1.6194) lr 7.9389e-03 eta 1:45:28
epoch [10/30] batch [240/796] time 0.409 (0.383) data 0.000 (0.004) loss 3.9102 (1.6435) lr 7.9389e-03 eta 1:45:18
epoch [10/30] batch [260/796] time 0.392 (0.383) data 0.000 (0.003) loss 1.4824 (1.6482) lr 7.9389e-03 eta 1:45:02
epoch [10/30] batch [280/796] time 0.398 (0.383) data 0.000 (0.003) loss 1.7852 (1.6509) lr 7.9389e-03 eta 1:44:51
epoch [10/30] batch [300/796] time 0.408 (0.383) data 0.000 (0.003) loss 2.2695 (1.6556) lr 7.9389e-03 eta 1:44:45
epoch [10/30] batch [320/796] time 0.364 (0.383) data 0.000 (0.003) loss 3.4688 (1.6665) lr 7.9389e-03 eta 1:44:35
epoch [10/30] batch [340/796] time 0.375 (0.382) data 0.000 (0.003) loss 0.7217 (1.6357) lr 7.9389e-03 eta 1:44:23
epoch [10/30] batch [360/796] time 0.368 (0.382) data 0.000 (0.002) loss 1.9668 (1.6451) lr 7.9389e-03 eta 1:44:12
epoch [10/30] batch [380/796] time 0.380 (0.382) data 0.000 (0.002) loss 0.9399 (1.6573) lr 7.9389e-03 eta 1:44:04
epoch [10/30] batch [400/796] time 0.411 (0.382) data 0.000 (0.002) loss 0.3357 (1.6556) lr 7.9389e-03 eta 1:43:52
epoch [10/30] batch [420/796] time 0.391 (0.382) data 0.000 (0.002) loss 2.5781 (1.6602) lr 7.9389e-03 eta 1:43:50
epoch [10/30] batch [440/796] time 0.412 (0.382) data 0.000 (0.002) loss 2.0605 (1.6646) lr 7.9389e-03 eta 1:43:36
epoch [10/30] batch [460/796] time 0.405 (0.382) data 0.000 (0.002) loss 2.3887 (1.6684) lr 7.9389e-03 eta 1:43:26
epoch [10/30] batch [480/796] time 0.354 (0.382) data 0.000 (0.002) loss 1.3125 (1.6681) lr 7.9389e-03 eta 1:43:15
epoch [10/30] batch [500/796] time 0.399 (0.382) data 0.000 (0.002) loss 1.0693 (1.6820) lr 7.9389e-03 eta 1:43:09
epoch [10/30] batch [520/796] time 0.393 (0.382) data 0.000 (0.002) loss 0.6973 (1.6676) lr 7.9389e-03 eta 1:43:05
epoch [10/30] batch [540/796] time 0.377 (0.382) data 0.000 (0.002) loss 0.5547 (1.6601) lr 7.9389e-03 eta 1:42:56
epoch [10/30] batch [560/796] time 0.399 (0.382) data 0.000 (0.002) loss 1.5195 (1.6620) lr 7.9389e-03 eta 1:42:49
epoch [10/30] batch [580/796] time 0.368 (0.382) data 0.000 (0.002) loss 2.5938 (1.6644) lr 7.9389e-03 eta 1:42:38
epoch [10/30] batch [600/796] time 0.374 (0.382) data 0.000 (0.002) loss 0.9307 (1.6731) lr 7.9389e-03 eta 1:42:30
epoch [10/30] batch [620/796] time 0.362 (0.382) data 0.000 (0.002) loss 0.7690 (1.6767) lr 7.9389e-03 eta 1:42:21
epoch [10/30] batch [640/796] time 0.376 (0.381) data 0.000 (0.001) loss 0.3894 (1.6916) lr 7.9389e-03 eta 1:42:11
epoch [10/30] batch [660/796] time 0.369 (0.381) data 0.000 (0.001) loss 0.8384 (1.6883) lr 7.9389e-03 eta 1:42:02
epoch [10/30] batch [680/796] time 0.353 (0.381) data 0.000 (0.001) loss 3.5684 (1.6839) lr 7.9389e-03 eta 1:41:54
epoch [10/30] batch [700/796] time 0.388 (0.381) data 0.000 (0.001) loss 0.5425 (1.6958) lr 7.9389e-03 eta 1:41:46
epoch [10/30] batch [720/796] time 0.354 (0.381) data 0.000 (0.001) loss 2.6621 (1.6899) lr 7.9389e-03 eta 1:41:35
epoch [10/30] batch [740/796] time 0.347 (0.381) data 0.000 (0.001) loss 1.9824 (1.7020) lr 7.9389e-03 eta 1:41:29
epoch [10/30] batch [760/796] time 0.379 (0.381) data 0.000 (0.001) loss 1.3975 (1.7076) lr 7.9389e-03 eta 1:41:20
epoch [10/30] batch [780/796] time 0.339 (0.380) data 0.000 (0.001) loss 0.3218 (1.6966) lr 7.9389e-03 eta 1:40:58
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.48s/it] 10%|█         | 2/20 [00:06<00:51,  2.87s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.87it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.49it/s] 50%|█████     | 10/20 [00:08<00:03,  2.74it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.97it/s] 60%|██████    | 12/20 [00:09<00:02,  3.16it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.40it/s] 70%|███████   | 14/20 [00:09<00:01,  3.54it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.72it/s] 80%|████████  | 16/20 [00:10<00:01,  3.73it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.76it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.15it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.47it/s]100%|██████████| 20/20 [00:11<00:00,  4.81it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,584
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 79.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/796] time 0.400 (0.426) data 0.000 (0.035) loss 3.9414 (1.5820) lr 7.5000e-03 eta 1:52:47
epoch [11/30] batch [40/796] time 0.389 (0.403) data 0.000 (0.017) loss 0.2781 (1.5350) lr 7.5000e-03 eta 1:46:40
epoch [11/30] batch [60/796] time 0.387 (0.393) data 0.000 (0.012) loss 1.7725 (1.4402) lr 7.5000e-03 eta 1:43:47
epoch [11/30] batch [80/796] time 0.376 (0.388) data 0.000 (0.009) loss 1.6064 (1.5271) lr 7.5000e-03 eta 1:42:29
epoch [11/30] batch [100/796] time 0.407 (0.385) data 0.000 (0.007) loss 0.3799 (1.5589) lr 7.5000e-03 eta 1:41:30
epoch [11/30] batch [120/796] time 0.405 (0.385) data 0.000 (0.006) loss 0.7524 (1.5441) lr 7.5000e-03 eta 1:41:16
epoch [11/30] batch [140/796] time 0.357 (0.383) data 0.000 (0.005) loss 1.3213 (1.5499) lr 7.5000e-03 eta 1:40:49
epoch [11/30] batch [160/796] time 0.353 (0.382) data 0.000 (0.005) loss 1.8486 (1.5403) lr 7.5000e-03 eta 1:40:27
epoch [11/30] batch [180/796] time 0.361 (0.383) data 0.000 (0.004) loss 1.8916 (1.5452) lr 7.5000e-03 eta 1:40:24
epoch [11/30] batch [200/796] time 0.379 (0.382) data 0.000 (0.004) loss 0.7690 (1.5672) lr 7.5000e-03 eta 1:40:06
epoch [11/30] batch [220/796] time 0.359 (0.382) data 0.000 (0.003) loss 0.3718 (1.5532) lr 7.5000e-03 eta 1:39:54
epoch [11/30] batch [240/796] time 0.412 (0.382) data 0.000 (0.003) loss 0.5908 (1.5534) lr 7.5000e-03 eta 1:39:52
epoch [11/30] batch [260/796] time 0.410 (0.382) data 0.000 (0.003) loss 4.0469 (1.5912) lr 7.5000e-03 eta 1:39:36
epoch [11/30] batch [280/796] time 0.408 (0.382) data 0.000 (0.003) loss 2.7168 (1.6070) lr 7.5000e-03 eta 1:39:28
epoch [11/30] batch [300/796] time 0.395 (0.381) data 0.000 (0.003) loss 0.6421 (1.5956) lr 7.5000e-03 eta 1:39:10
epoch [11/30] batch [320/796] time 0.395 (0.381) data 0.000 (0.002) loss 1.1045 (1.6114) lr 7.5000e-03 eta 1:39:09
epoch [11/30] batch [340/796] time 0.400 (0.381) data 0.000 (0.002) loss 0.7275 (1.6248) lr 7.5000e-03 eta 1:39:00
epoch [11/30] batch [360/796] time 0.383 (0.381) data 0.000 (0.002) loss 2.1816 (1.6286) lr 7.5000e-03 eta 1:38:55
epoch [11/30] batch [380/796] time 0.371 (0.381) data 0.000 (0.002) loss 3.9688 (1.6407) lr 7.5000e-03 eta 1:38:48
epoch [11/30] batch [400/796] time 0.363 (0.381) data 0.000 (0.002) loss 0.9546 (1.6357) lr 7.5000e-03 eta 1:38:39
epoch [11/30] batch [420/796] time 0.397 (0.381) data 0.000 (0.002) loss 1.7256 (1.6510) lr 7.5000e-03 eta 1:38:32
epoch [11/30] batch [440/796] time 0.397 (0.382) data 0.000 (0.002) loss 2.9668 (1.6508) lr 7.5000e-03 eta 1:38:28
epoch [11/30] batch [460/796] time 0.358 (0.382) data 0.000 (0.002) loss 2.6016 (1.6607) lr 7.5000e-03 eta 1:38:18
epoch [11/30] batch [480/796] time 0.360 (0.381) data 0.000 (0.002) loss 3.8555 (1.6737) lr 7.5000e-03 eta 1:38:09
epoch [11/30] batch [500/796] time 0.354 (0.381) data 0.000 (0.002) loss 1.1543 (1.6946) lr 7.5000e-03 eta 1:37:56
epoch [11/30] batch [520/796] time 0.395 (0.381) data 0.000 (0.002) loss 3.8203 (1.7013) lr 7.5000e-03 eta 1:37:49
epoch [11/30] batch [540/796] time 0.386 (0.381) data 0.000 (0.002) loss 3.0020 (1.7148) lr 7.5000e-03 eta 1:37:43
epoch [11/30] batch [560/796] time 0.393 (0.381) data 0.000 (0.001) loss 2.1348 (1.7232) lr 7.5000e-03 eta 1:37:33
epoch [11/30] batch [580/796] time 0.400 (0.381) data 0.000 (0.001) loss 2.2930 (1.7244) lr 7.5000e-03 eta 1:37:26
epoch [11/30] batch [600/796] time 0.347 (0.381) data 0.000 (0.001) loss 1.1660 (1.7140) lr 7.5000e-03 eta 1:37:18
epoch [11/30] batch [620/796] time 0.391 (0.381) data 0.000 (0.001) loss 1.4717 (1.7333) lr 7.5000e-03 eta 1:37:11
epoch [11/30] batch [640/796] time 0.351 (0.381) data 0.000 (0.001) loss 3.5859 (1.7465) lr 7.5000e-03 eta 1:37:05
epoch [11/30] batch [660/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.9976 (1.7472) lr 7.5000e-03 eta 1:36:56
epoch [11/30] batch [680/796] time 0.353 (0.381) data 0.000 (0.001) loss 0.5928 (1.7420) lr 7.5000e-03 eta 1:36:47
epoch [11/30] batch [700/796] time 0.395 (0.381) data 0.000 (0.001) loss 0.7412 (1.7368) lr 7.5000e-03 eta 1:36:41
epoch [11/30] batch [720/796] time 0.384 (0.381) data 0.000 (0.001) loss 3.4434 (1.7409) lr 7.5000e-03 eta 1:36:33
epoch [11/30] batch [740/796] time 0.357 (0.381) data 0.000 (0.001) loss 0.4280 (1.7360) lr 7.5000e-03 eta 1:36:24
epoch [11/30] batch [760/796] time 0.385 (0.381) data 0.000 (0.001) loss 2.3008 (1.7300) lr 7.5000e-03 eta 1:36:14
epoch [11/30] batch [780/796] time 0.339 (0.380) data 0.000 (0.001) loss 1.8096 (1.7335) lr 7.5000e-03 eta 1:35:53
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.52s/it] 10%|█         | 2/20 [00:06<00:52,  2.90s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.71s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.52it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.77it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.99it/s] 60%|██████    | 12/20 [00:09<00:02,  3.26it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.44it/s] 70%|███████   | 14/20 [00:09<00:01,  3.60it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.86it/s] 80%|████████  | 16/20 [00:10<00:01,  3.99it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.02it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.00it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.36it/s]100%|██████████| 20/20 [00:11<00:00,  4.72it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,583
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 78.9%

epoch [12/30] batch [20/796] time 0.416 (0.420) data 0.000 (0.031) loss 0.2944 (1.5012) lr 7.0337e-03 eta 1:45:43
epoch [12/30] batch [40/796] time 0.360 (0.403) data 0.000 (0.016) loss 0.3467 (1.5886) lr 7.0337e-03 eta 1:41:11
epoch [12/30] batch [60/796] time 0.398 (0.398) data 0.000 (0.011) loss 1.4648 (1.6295) lr 7.0337e-03 eta 1:39:56
epoch [12/30] batch [80/796] time 0.389 (0.396) data 0.000 (0.008) loss 3.6445 (1.5779) lr 7.0337e-03 eta 1:39:13
epoch [12/30] batch [100/796] time 0.350 (0.391) data 0.000 (0.006) loss 1.2197 (1.5045) lr 7.0337e-03 eta 1:37:53
epoch [12/30] batch [120/796] time 0.388 (0.389) data 0.000 (0.005) loss 0.3242 (1.4894) lr 7.0337e-03 eta 1:37:17
epoch [12/30] batch [140/796] time 0.388 (0.388) data 0.000 (0.005) loss 1.2764 (1.4714) lr 7.0337e-03 eta 1:36:56
epoch [12/30] batch [160/796] time 0.393 (0.387) data 0.000 (0.004) loss 0.8276 (1.4914) lr 7.0337e-03 eta 1:36:29
epoch [12/30] batch [180/796] time 0.394 (0.387) data 0.000 (0.004) loss 3.4160 (1.5168) lr 7.0337e-03 eta 1:36:17
epoch [12/30] batch [200/796] time 0.351 (0.387) data 0.000 (0.003) loss 0.6626 (1.5383) lr 7.0337e-03 eta 1:36:12
epoch [12/30] batch [220/796] time 0.401 (0.386) data 0.000 (0.003) loss 0.6367 (1.5377) lr 7.0337e-03 eta 1:35:56
epoch [12/30] batch [240/796] time 0.369 (0.385) data 0.000 (0.003) loss 0.3306 (1.5182) lr 7.0337e-03 eta 1:35:33
epoch [12/30] batch [260/796] time 0.391 (0.385) data 0.000 (0.003) loss 0.4863 (1.5699) lr 7.0337e-03 eta 1:35:29
epoch [12/30] batch [280/796] time 0.406 (0.385) data 0.000 (0.002) loss 2.5801 (1.5831) lr 7.0337e-03 eta 1:35:10
epoch [12/30] batch [300/796] time 0.370 (0.384) data 0.000 (0.002) loss 0.9409 (1.5782) lr 7.0337e-03 eta 1:34:55
epoch [12/30] batch [320/796] time 0.368 (0.384) data 0.000 (0.002) loss 1.8291 (1.6089) lr 7.0337e-03 eta 1:34:48
epoch [12/30] batch [340/796] time 0.357 (0.384) data 0.000 (0.002) loss 1.1514 (1.6159) lr 7.0337e-03 eta 1:34:33
epoch [12/30] batch [360/796] time 0.363 (0.383) data 0.000 (0.002) loss 0.4900 (1.6135) lr 7.0337e-03 eta 1:34:19
epoch [12/30] batch [380/796] time 0.393 (0.383) data 0.000 (0.002) loss 1.3398 (1.6033) lr 7.0337e-03 eta 1:34:08
epoch [12/30] batch [400/796] time 0.351 (0.383) data 0.000 (0.002) loss 1.4209 (1.6187) lr 7.0337e-03 eta 1:33:58
epoch [12/30] batch [420/796] time 0.358 (0.383) data 0.000 (0.002) loss 1.7041 (1.6073) lr 7.0337e-03 eta 1:33:50
epoch [12/30] batch [440/796] time 0.388 (0.383) data 0.000 (0.002) loss 1.8486 (1.6098) lr 7.0337e-03 eta 1:33:39
epoch [12/30] batch [460/796] time 0.364 (0.382) data 0.000 (0.002) loss 3.6211 (1.6058) lr 7.0337e-03 eta 1:33:28
epoch [12/30] batch [480/796] time 0.365 (0.382) data 0.000 (0.002) loss 2.8145 (1.6263) lr 7.0337e-03 eta 1:33:18
epoch [12/30] batch [500/796] time 0.374 (0.382) data 0.000 (0.002) loss 0.4731 (1.6108) lr 7.0337e-03 eta 1:33:12
epoch [12/30] batch [520/796] time 0.376 (0.382) data 0.000 (0.001) loss 1.6504 (1.6159) lr 7.0337e-03 eta 1:33:04
epoch [12/30] batch [540/796] time 0.425 (0.382) data 0.000 (0.001) loss 0.6860 (1.6117) lr 7.0337e-03 eta 1:32:54
epoch [12/30] batch [560/796] time 0.398 (0.382) data 0.000 (0.001) loss 5.0586 (1.6289) lr 7.0337e-03 eta 1:32:42
epoch [12/30] batch [580/796] time 0.384 (0.382) data 0.000 (0.001) loss 3.6465 (1.6430) lr 7.0337e-03 eta 1:32:35
epoch [12/30] batch [600/796] time 0.395 (0.382) data 0.000 (0.001) loss 0.8862 (1.6518) lr 7.0337e-03 eta 1:32:24
epoch [12/30] batch [620/796] time 0.345 (0.382) data 0.000 (0.001) loss 2.8301 (1.6649) lr 7.0337e-03 eta 1:32:17
epoch [12/30] batch [640/796] time 0.402 (0.382) data 0.000 (0.001) loss 0.4070 (1.6635) lr 7.0337e-03 eta 1:32:06
epoch [12/30] batch [660/796] time 0.365 (0.382) data 0.000 (0.001) loss 0.8149 (1.6543) lr 7.0337e-03 eta 1:32:00
epoch [12/30] batch [680/796] time 0.385 (0.382) data 0.000 (0.001) loss 2.3047 (1.6494) lr 7.0337e-03 eta 1:31:53
epoch [12/30] batch [700/796] time 0.386 (0.382) data 0.000 (0.001) loss 1.3037 (1.6591) lr 7.0337e-03 eta 1:31:43
epoch [12/30] batch [720/796] time 0.393 (0.381) data 0.000 (0.001) loss 1.6885 (1.6563) lr 7.0337e-03 eta 1:31:33
epoch [12/30] batch [740/796] time 0.378 (0.381) data 0.000 (0.001) loss 0.6255 (1.6578) lr 7.0337e-03 eta 1:31:27
epoch [12/30] batch [760/796] time 0.387 (0.382) data 0.000 (0.001) loss 0.6880 (1.6592) lr 7.0337e-03 eta 1:31:20
epoch [12/30] batch [780/796] time 0.340 (0.381) data 0.000 (0.001) loss 1.0859 (1.6702) lr 7.0337e-03 eta 1:31:03
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:42,  5.40s/it] 10%|█         | 2/20 [00:06<00:49,  2.76s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.64s/it] 20%|██        | 4/20 [00:06<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.23it/s] 30%|███       | 6/20 [00:07<00:08,  1.57it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.91it/s] 40%|████      | 8/20 [00:08<00:05,  2.22it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.49it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.88it/s] 60%|██████    | 12/20 [00:09<00:02,  3.03it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.29it/s] 70%|███████   | 14/20 [00:09<00:01,  3.60it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.70it/s] 80%|████████  | 16/20 [00:10<00:01,  3.67it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.81it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.20it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.52it/s]100%|██████████| 20/20 [00:11<00:00,  4.84it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,601
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 80.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [13/30] batch [20/796] time 0.422 (0.417) data 0.000 (0.033) loss 2.7148 (1.7678) lr 6.5451e-03 eta 1:39:31
epoch [13/30] batch [40/796] time 0.365 (0.400) data 0.000 (0.016) loss 2.5391 (1.6363) lr 6.5451e-03 eta 1:35:08
epoch [13/30] batch [60/796] time 0.390 (0.394) data 0.000 (0.011) loss 1.3428 (1.5258) lr 6.5451e-03 eta 1:33:37
epoch [13/30] batch [80/796] time 0.390 (0.390) data 0.000 (0.008) loss 2.1016 (1.4456) lr 6.5451e-03 eta 1:32:31
epoch [13/30] batch [100/796] time 0.390 (0.387) data 0.000 (0.007) loss 1.1299 (1.4909) lr 6.5451e-03 eta 1:31:50
epoch [13/30] batch [120/796] time 0.392 (0.388) data 0.000 (0.006) loss 0.6631 (1.5520) lr 6.5451e-03 eta 1:31:57
epoch [13/30] batch [140/796] time 0.375 (0.387) data 0.000 (0.005) loss 0.6963 (1.4769) lr 6.5451e-03 eta 1:31:31
epoch [13/30] batch [160/796] time 0.358 (0.387) data 0.000 (0.004) loss 4.9609 (1.5035) lr 6.5451e-03 eta 1:31:17
epoch [13/30] batch [180/796] time 0.390 (0.386) data 0.000 (0.004) loss 0.3862 (1.5119) lr 6.5451e-03 eta 1:30:57
epoch [13/30] batch [200/796] time 0.406 (0.384) data 0.000 (0.004) loss 0.9004 (1.5047) lr 6.5451e-03 eta 1:30:31
epoch [13/30] batch [220/796] time 0.363 (0.384) data 0.000 (0.003) loss 1.7832 (1.5288) lr 6.5451e-03 eta 1:30:19
epoch [13/30] batch [240/796] time 0.392 (0.384) data 0.000 (0.003) loss 2.0586 (1.5120) lr 6.5451e-03 eta 1:30:10
epoch [13/30] batch [260/796] time 0.363 (0.384) data 0.000 (0.003) loss 0.1853 (1.4973) lr 6.5451e-03 eta 1:30:03
epoch [13/30] batch [280/796] time 0.401 (0.384) data 0.000 (0.003) loss 2.2520 (1.5191) lr 6.5451e-03 eta 1:29:54
epoch [13/30] batch [300/796] time 0.400 (0.384) data 0.000 (0.002) loss 1.0068 (1.5033) lr 6.5451e-03 eta 1:29:45
epoch [13/30] batch [320/796] time 0.415 (0.384) data 0.000 (0.002) loss 5.5625 (1.5374) lr 6.5451e-03 eta 1:29:35
epoch [13/30] batch [340/796] time 0.373 (0.383) data 0.000 (0.002) loss 1.2979 (1.5271) lr 6.5451e-03 eta 1:29:23
epoch [13/30] batch [360/796] time 0.371 (0.383) data 0.000 (0.002) loss 1.9297 (1.5357) lr 6.5451e-03 eta 1:29:12
epoch [13/30] batch [380/796] time 0.357 (0.383) data 0.000 (0.002) loss 0.1831 (1.5608) lr 6.5451e-03 eta 1:29:02
epoch [13/30] batch [400/796] time 0.394 (0.383) data 0.000 (0.002) loss 1.4834 (1.5661) lr 6.5451e-03 eta 1:28:52
epoch [13/30] batch [420/796] time 0.394 (0.383) data 0.000 (0.002) loss 2.3848 (1.5597) lr 6.5451e-03 eta 1:28:45
epoch [13/30] batch [440/796] time 0.393 (0.383) data 0.000 (0.002) loss 0.1802 (1.5517) lr 6.5451e-03 eta 1:28:37
epoch [13/30] batch [460/796] time 0.362 (0.383) data 0.000 (0.002) loss 1.7754 (1.5599) lr 6.5451e-03 eta 1:28:25
epoch [13/30] batch [480/796] time 0.403 (0.382) data 0.000 (0.002) loss 1.2500 (1.5683) lr 6.5451e-03 eta 1:28:14
epoch [13/30] batch [500/796] time 0.391 (0.382) data 0.000 (0.002) loss 4.6992 (1.5830) lr 6.5451e-03 eta 1:28:06
epoch [13/30] batch [520/796] time 0.357 (0.382) data 0.000 (0.002) loss 0.4275 (1.5919) lr 6.5451e-03 eta 1:27:58
epoch [13/30] batch [540/796] time 0.385 (0.383) data 0.000 (0.001) loss 0.6338 (1.6020) lr 6.5451e-03 eta 1:27:54
epoch [13/30] batch [560/796] time 0.386 (0.382) data 0.000 (0.001) loss 3.3066 (1.6136) lr 6.5451e-03 eta 1:27:42
epoch [13/30] batch [580/796] time 0.408 (0.382) data 0.000 (0.001) loss 1.5322 (1.6248) lr 6.5451e-03 eta 1:27:34
epoch [13/30] batch [600/796] time 0.404 (0.382) data 0.000 (0.001) loss 2.5449 (1.6333) lr 6.5451e-03 eta 1:27:23
epoch [13/30] batch [620/796] time 0.354 (0.382) data 0.000 (0.001) loss 2.1738 (1.6446) lr 6.5451e-03 eta 1:27:11
epoch [13/30] batch [640/796] time 0.394 (0.381) data 0.000 (0.001) loss 1.2686 (1.6324) lr 6.5451e-03 eta 1:27:00
epoch [13/30] batch [660/796] time 0.381 (0.381) data 0.000 (0.001) loss 2.7734 (1.6363) lr 6.5451e-03 eta 1:26:51
epoch [13/30] batch [680/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.3086 (1.6312) lr 6.5451e-03 eta 1:26:41
epoch [13/30] batch [700/796] time 0.361 (0.381) data 0.000 (0.001) loss 1.3613 (1.6535) lr 6.5451e-03 eta 1:26:31
epoch [13/30] batch [720/796] time 0.347 (0.381) data 0.000 (0.001) loss 0.6245 (1.6426) lr 6.5451e-03 eta 1:26:22
epoch [13/30] batch [740/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.2659 (1.6426) lr 6.5451e-03 eta 1:26:14
epoch [13/30] batch [760/796] time 0.370 (0.381) data 0.000 (0.001) loss 0.6597 (1.6360) lr 6.5451e-03 eta 1:26:07
epoch [13/30] batch [780/796] time 0.342 (0.380) data 0.000 (0.001) loss 3.4727 (1.6461) lr 6.5451e-03 eta 1:25:47
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:48,  5.72s/it] 10%|█         | 2/20 [00:06<00:52,  2.89s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:08<00:03,  2.81it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.11it/s] 60%|██████    | 12/20 [00:09<00:02,  3.27it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.42it/s] 70%|███████   | 14/20 [00:09<00:01,  3.51it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.82it/s] 80%|████████  | 16/20 [00:10<00:01,  3.90it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.07it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.60it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.01it/s]100%|██████████| 20/20 [00:11<00:00,  4.43it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,602
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 79.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [14/30] batch [20/796] time 0.358 (0.434) data 0.000 (0.049) loss 2.3574 (1.5348) lr 6.0396e-03 eta 1:37:43
epoch [14/30] batch [40/796] time 0.397 (0.411) data 0.000 (0.025) loss 1.0371 (1.3683) lr 6.0396e-03 eta 1:32:31
epoch [14/30] batch [60/796] time 0.390 (0.402) data 0.000 (0.017) loss 2.2402 (1.5149) lr 6.0396e-03 eta 1:30:10
epoch [14/30] batch [80/796] time 0.396 (0.397) data 0.000 (0.013) loss 2.9238 (1.4454) lr 6.0396e-03 eta 1:28:56
epoch [14/30] batch [100/796] time 0.376 (0.392) data 0.000 (0.010) loss 1.6650 (1.5898) lr 6.0396e-03 eta 1:27:43
epoch [14/30] batch [120/796] time 0.401 (0.391) data 0.000 (0.008) loss 0.6250 (1.6099) lr 6.0396e-03 eta 1:27:19
epoch [14/30] batch [140/796] time 0.404 (0.388) data 0.000 (0.007) loss 0.8853 (1.6205) lr 6.0396e-03 eta 1:26:42
epoch [14/30] batch [160/796] time 0.353 (0.387) data 0.000 (0.006) loss 0.4722 (1.5988) lr 6.0396e-03 eta 1:26:13
epoch [14/30] batch [180/796] time 0.411 (0.386) data 0.000 (0.006) loss 0.9258 (1.6002) lr 6.0396e-03 eta 1:25:57
epoch [14/30] batch [200/796] time 0.397 (0.386) data 0.000 (0.005) loss 0.8818 (1.5920) lr 6.0396e-03 eta 1:25:48
epoch [14/30] batch [220/796] time 0.386 (0.386) data 0.000 (0.005) loss 1.7100 (1.5984) lr 6.0396e-03 eta 1:25:44
epoch [14/30] batch [240/796] time 0.393 (0.386) data 0.000 (0.004) loss 0.8452 (1.5630) lr 6.0396e-03 eta 1:25:33
epoch [14/30] batch [260/796] time 0.392 (0.385) data 0.000 (0.004) loss 1.7822 (1.5656) lr 6.0396e-03 eta 1:25:13
epoch [14/30] batch [280/796] time 0.401 (0.384) data 0.000 (0.004) loss 3.8633 (1.5398) lr 6.0396e-03 eta 1:24:55
epoch [14/30] batch [300/796] time 0.352 (0.384) data 0.000 (0.004) loss 2.3926 (1.5557) lr 6.0396e-03 eta 1:24:38
epoch [14/30] batch [320/796] time 0.407 (0.383) data 0.000 (0.003) loss 2.4043 (1.5481) lr 6.0396e-03 eta 1:24:23
epoch [14/30] batch [340/796] time 0.377 (0.383) data 0.000 (0.003) loss 1.3730 (1.5581) lr 6.0396e-03 eta 1:24:07
epoch [14/30] batch [360/796] time 0.396 (0.382) data 0.000 (0.003) loss 2.7344 (1.5709) lr 6.0396e-03 eta 1:23:55
epoch [14/30] batch [380/796] time 0.389 (0.382) data 0.000 (0.003) loss 0.7627 (1.5631) lr 6.0396e-03 eta 1:23:46
epoch [14/30] batch [400/796] time 0.393 (0.382) data 0.000 (0.003) loss 3.5898 (1.5605) lr 6.0396e-03 eta 1:23:42
epoch [14/30] batch [420/796] time 0.392 (0.382) data 0.000 (0.003) loss 2.4941 (1.5530) lr 6.0396e-03 eta 1:23:33
epoch [14/30] batch [440/796] time 0.413 (0.383) data 0.000 (0.002) loss 3.0527 (1.5707) lr 6.0396e-03 eta 1:23:28
epoch [14/30] batch [460/796] time 0.375 (0.382) data 0.000 (0.002) loss 1.4619 (1.5837) lr 6.0396e-03 eta 1:23:14
epoch [14/30] batch [480/796] time 0.374 (0.382) data 0.000 (0.002) loss 2.0527 (1.5814) lr 6.0396e-03 eta 1:23:00
epoch [14/30] batch [500/796] time 0.370 (0.382) data 0.000 (0.002) loss 2.3613 (1.5897) lr 6.0396e-03 eta 1:22:52
epoch [14/30] batch [520/796] time 0.370 (0.382) data 0.000 (0.002) loss 3.8574 (1.5902) lr 6.0396e-03 eta 1:22:44
epoch [14/30] batch [540/796] time 0.383 (0.381) data 0.000 (0.002) loss 1.2363 (1.5803) lr 6.0396e-03 eta 1:22:35
epoch [14/30] batch [560/796] time 0.367 (0.381) data 0.000 (0.002) loss 0.9673 (1.5834) lr 6.0396e-03 eta 1:22:27
epoch [14/30] batch [580/796] time 0.396 (0.381) data 0.000 (0.002) loss 0.6841 (1.5901) lr 6.0396e-03 eta 1:22:17
epoch [14/30] batch [600/796] time 0.386 (0.381) data 0.000 (0.002) loss 1.3467 (1.6050) lr 6.0396e-03 eta 1:22:08
epoch [14/30] batch [620/796] time 0.379 (0.381) data 0.000 (0.002) loss 1.7412 (1.5912) lr 6.0396e-03 eta 1:21:59
epoch [14/30] batch [640/796] time 0.388 (0.381) data 0.000 (0.002) loss 1.7354 (1.6268) lr 6.0396e-03 eta 1:21:52
epoch [14/30] batch [660/796] time 0.378 (0.381) data 0.000 (0.002) loss 0.6489 (1.6156) lr 6.0396e-03 eta 1:21:44
epoch [14/30] batch [680/796] time 0.394 (0.381) data 0.000 (0.002) loss 2.2012 (1.6173) lr 6.0396e-03 eta 1:21:37
epoch [14/30] batch [700/796] time 0.366 (0.381) data 0.000 (0.002) loss 4.4258 (1.6167) lr 6.0396e-03 eta 1:21:28
epoch [14/30] batch [720/796] time 0.393 (0.381) data 0.000 (0.002) loss 0.4045 (1.6090) lr 6.0396e-03 eta 1:21:19
epoch [14/30] batch [740/796] time 0.392 (0.381) data 0.000 (0.002) loss 1.3301 (1.6006) lr 6.0396e-03 eta 1:21:09
epoch [14/30] batch [760/796] time 0.374 (0.381) data 0.000 (0.002) loss 0.6533 (1.5994) lr 6.0396e-03 eta 1:21:02
epoch [14/30] batch [780/796] time 0.347 (0.380) data 0.000 (0.002) loss 1.9932 (1.6128) lr 6.0396e-03 eta 1:20:44
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.54s/it] 10%|█         | 2/20 [00:06<00:48,  2.70s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.61s/it] 20%|██        | 4/20 [00:06<00:17,  1.09s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.25it/s] 30%|███       | 6/20 [00:07<00:08,  1.59it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.92it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.49it/s] 50%|█████     | 10/20 [00:08<00:03,  2.75it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.15it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.50it/s] 70%|███████   | 14/20 [00:09<00:01,  3.65it/s] 75%|███████▌  | 15/20 [00:09<00:01,  4.01it/s] 80%|████████  | 16/20 [00:10<00:00,  4.07it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.13it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.48it/s] 95%|█████████▌| 19/20 [00:10<00:00,  3.91it/s]100%|██████████| 20/20 [00:11<00:00,  4.34it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,590
* accuracy: 79.9%
* error: 20.1%
* macro_f1: 79.4%

epoch [15/30] batch [20/796] time 0.348 (0.418) data 0.000 (0.036) loss 1.5127 (1.2746) lr 5.5226e-03 eta 1:28:33
epoch [15/30] batch [40/796] time 0.391 (0.396) data 0.000 (0.018) loss 1.7461 (1.1344) lr 5.5226e-03 eta 1:23:51
epoch [15/30] batch [60/796] time 0.366 (0.391) data 0.000 (0.012) loss 2.1113 (1.2718) lr 5.5226e-03 eta 1:22:36
epoch [15/30] batch [80/796] time 0.365 (0.390) data 0.000 (0.009) loss 1.4424 (1.4828) lr 5.5226e-03 eta 1:22:18
epoch [15/30] batch [100/796] time 0.355 (0.387) data 0.000 (0.007) loss 0.6675 (1.5733) lr 5.5226e-03 eta 1:21:25
epoch [15/30] batch [120/796] time 0.395 (0.386) data 0.000 (0.006) loss 0.6260 (1.6184) lr 5.5226e-03 eta 1:21:08
epoch [15/30] batch [140/796] time 0.391 (0.385) data 0.000 (0.005) loss 1.6826 (1.6237) lr 5.5226e-03 eta 1:20:44
epoch [15/30] batch [160/796] time 0.413 (0.383) data 0.000 (0.005) loss 0.5962 (1.6546) lr 5.5226e-03 eta 1:20:19
epoch [15/30] batch [180/796] time 0.405 (0.384) data 0.000 (0.004) loss 1.1729 (1.6771) lr 5.5226e-03 eta 1:20:20
epoch [15/30] batch [200/796] time 0.385 (0.384) data 0.000 (0.004) loss 1.8340 (1.6535) lr 5.5226e-03 eta 1:20:10
epoch [15/30] batch [220/796] time 0.360 (0.384) data 0.000 (0.003) loss 0.8921 (1.6727) lr 5.5226e-03 eta 1:20:00
epoch [15/30] batch [240/796] time 0.394 (0.383) data 0.000 (0.003) loss 1.9375 (1.6467) lr 5.5226e-03 eta 1:19:46
epoch [15/30] batch [260/796] time 0.386 (0.383) data 0.000 (0.003) loss 2.9238 (1.6523) lr 5.5226e-03 eta 1:19:40
epoch [15/30] batch [280/796] time 0.374 (0.382) data 0.000 (0.003) loss 0.2290 (1.6617) lr 5.5226e-03 eta 1:19:24
epoch [15/30] batch [300/796] time 0.353 (0.381) data 0.000 (0.003) loss 1.5791 (1.6472) lr 5.5226e-03 eta 1:19:02
epoch [15/30] batch [320/796] time 0.355 (0.381) data 0.000 (0.002) loss 3.6035 (1.6418) lr 5.5226e-03 eta 1:18:52
epoch [15/30] batch [340/796] time 0.398 (0.381) data 0.000 (0.002) loss 0.7192 (1.6317) lr 5.5226e-03 eta 1:18:43
epoch [15/30] batch [360/796] time 0.424 (0.381) data 0.000 (0.002) loss 0.7705 (1.6422) lr 5.5226e-03 eta 1:18:35
epoch [15/30] batch [380/796] time 0.345 (0.381) data 0.000 (0.002) loss 0.3159 (1.6656) lr 5.5226e-03 eta 1:18:23
epoch [15/30] batch [400/796] time 0.382 (0.381) data 0.000 (0.002) loss 2.7266 (1.6551) lr 5.5226e-03 eta 1:18:17
epoch [15/30] batch [420/796] time 0.381 (0.381) data 0.000 (0.002) loss 2.2031 (1.6888) lr 5.5226e-03 eta 1:18:11
epoch [15/30] batch [440/796] time 0.351 (0.380) data 0.000 (0.002) loss 2.4199 (1.6858) lr 5.5226e-03 eta 1:17:57
epoch [15/30] batch [460/796] time 0.409 (0.381) data 0.000 (0.002) loss 0.2903 (1.6847) lr 5.5226e-03 eta 1:17:51
epoch [15/30] batch [480/796] time 0.408 (0.381) data 0.000 (0.002) loss 3.0352 (1.6794) lr 5.5226e-03 eta 1:17:44
epoch [15/30] batch [500/796] time 0.362 (0.381) data 0.000 (0.002) loss 1.6299 (1.6894) lr 5.5226e-03 eta 1:17:38
epoch [15/30] batch [520/796] time 0.380 (0.381) data 0.000 (0.002) loss 2.8164 (1.6887) lr 5.5226e-03 eta 1:17:31
epoch [15/30] batch [540/796] time 0.364 (0.381) data 0.000 (0.002) loss 1.1855 (1.6897) lr 5.5226e-03 eta 1:17:21
epoch [15/30] batch [560/796] time 0.418 (0.381) data 0.000 (0.002) loss 0.7793 (1.6879) lr 5.5226e-03 eta 1:17:14
epoch [15/30] batch [580/796] time 0.375 (0.381) data 0.000 (0.001) loss 0.2021 (1.6858) lr 5.5226e-03 eta 1:17:08
epoch [15/30] batch [600/796] time 0.390 (0.381) data 0.000 (0.001) loss 0.5913 (1.6843) lr 5.5226e-03 eta 1:16:58
epoch [15/30] batch [620/796] time 0.462 (0.380) data 0.000 (0.001) loss 0.4746 (1.6955) lr 5.5226e-03 eta 1:16:49
epoch [15/30] batch [640/796] time 0.362 (0.380) data 0.000 (0.001) loss 2.8945 (1.6922) lr 5.5226e-03 eta 1:16:41
epoch [15/30] batch [660/796] time 0.390 (0.380) data 0.000 (0.001) loss 0.8125 (1.6942) lr 5.5226e-03 eta 1:16:31
epoch [15/30] batch [680/796] time 0.401 (0.380) data 0.000 (0.001) loss 1.2861 (1.7050) lr 5.5226e-03 eta 1:16:22
epoch [15/30] batch [700/796] time 0.372 (0.380) data 0.000 (0.001) loss 0.9556 (1.7022) lr 5.5226e-03 eta 1:16:14
epoch [15/30] batch [720/796] time 0.391 (0.380) data 0.000 (0.001) loss 1.7666 (1.7013) lr 5.5226e-03 eta 1:16:07
epoch [15/30] batch [740/796] time 0.412 (0.380) data 0.000 (0.001) loss 0.6372 (1.7088) lr 5.5226e-03 eta 1:16:00
epoch [15/30] batch [760/796] time 0.360 (0.380) data 0.000 (0.001) loss 2.6738 (1.7034) lr 5.5226e-03 eta 1:15:53
epoch [15/30] batch [780/796] time 0.339 (0.379) data 0.000 (0.001) loss 0.4456 (1.7089) lr 5.5226e-03 eta 1:15:35
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.54s/it] 10%|█         | 2/20 [00:06<00:50,  2.83s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.47it/s] 50%|█████     | 10/20 [00:08<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.99it/s] 60%|██████    | 12/20 [00:09<00:02,  3.23it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.38it/s] 70%|███████   | 14/20 [00:09<00:01,  3.70it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.69it/s] 80%|████████  | 16/20 [00:10<00:01,  3.84it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.97it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.33it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.63it/s]100%|██████████| 20/20 [00:11<00:00,  4.94it/s]100%|██████████| 20/20 [00:11<00:00,  1.79it/s]=> result
* total: 1,990
* correct: 1,607
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 80.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [16/30] batch [20/796] time 0.373 (0.422) data 0.000 (0.036) loss 1.3828 (1.5843) lr 5.0000e-03 eta 1:23:46
epoch [16/30] batch [40/796] time 0.350 (0.396) data 0.000 (0.018) loss 5.0039 (1.9902) lr 5.0000e-03 eta 1:18:37
epoch [16/30] batch [60/796] time 0.392 (0.391) data 0.000 (0.012) loss 0.8872 (1.9805) lr 5.0000e-03 eta 1:17:27
epoch [16/30] batch [80/796] time 0.364 (0.385) data 0.000 (0.009) loss 2.1543 (1.9148) lr 5.0000e-03 eta 1:16:01
epoch [16/30] batch [100/796] time 0.368 (0.385) data 0.000 (0.007) loss 0.9028 (1.8070) lr 5.0000e-03 eta 1:15:55
epoch [16/30] batch [120/796] time 0.361 (0.384) data 0.000 (0.006) loss 0.1307 (1.8078) lr 5.0000e-03 eta 1:15:37
epoch [16/30] batch [140/796] time 0.367 (0.384) data 0.000 (0.005) loss 3.1172 (1.7673) lr 5.0000e-03 eta 1:15:28
epoch [16/30] batch [160/796] time 0.370 (0.382) data 0.000 (0.005) loss 1.4844 (1.7683) lr 5.0000e-03 eta 1:15:02
epoch [16/30] batch [180/796] time 0.364 (0.381) data 0.000 (0.004) loss 0.7754 (1.7768) lr 5.0000e-03 eta 1:14:44
epoch [16/30] batch [200/796] time 0.348 (0.381) data 0.000 (0.004) loss 0.4595 (1.7876) lr 5.0000e-03 eta 1:14:36
epoch [16/30] batch [220/796] time 0.381 (0.382) data 0.000 (0.003) loss 0.4944 (1.7801) lr 5.0000e-03 eta 1:14:34
epoch [16/30] batch [240/796] time 0.401 (0.381) data 0.000 (0.003) loss 0.3940 (1.7843) lr 5.0000e-03 eta 1:14:17
epoch [16/30] batch [260/796] time 0.375 (0.380) data 0.000 (0.003) loss 0.7065 (1.7729) lr 5.0000e-03 eta 1:13:59
epoch [16/30] batch [280/796] time 0.379 (0.380) data 0.000 (0.003) loss 4.6406 (1.7509) lr 5.0000e-03 eta 1:13:46
epoch [16/30] batch [300/796] time 0.391 (0.380) data 0.000 (0.003) loss 0.6616 (1.7604) lr 5.0000e-03 eta 1:13:37
epoch [16/30] batch [320/796] time 0.393 (0.380) data 0.000 (0.002) loss 2.4941 (1.7282) lr 5.0000e-03 eta 1:13:32
epoch [16/30] batch [340/796] time 0.384 (0.380) data 0.000 (0.002) loss 0.4348 (1.7160) lr 5.0000e-03 eta 1:13:23
epoch [16/30] batch [360/796] time 0.347 (0.380) data 0.000 (0.002) loss 1.1250 (1.7173) lr 5.0000e-03 eta 1:13:19
epoch [16/30] batch [380/796] time 0.364 (0.380) data 0.000 (0.002) loss 0.5376 (1.7176) lr 5.0000e-03 eta 1:13:09
epoch [16/30] batch [400/796] time 0.399 (0.379) data 0.000 (0.002) loss 0.3386 (1.7021) lr 5.0000e-03 eta 1:12:58
epoch [16/30] batch [420/796] time 0.390 (0.380) data 0.000 (0.002) loss 2.5684 (1.7156) lr 5.0000e-03 eta 1:12:52
epoch [16/30] batch [440/796] time 0.401 (0.380) data 0.000 (0.002) loss 0.7500 (1.6946) lr 5.0000e-03 eta 1:12:47
epoch [16/30] batch [460/796] time 0.373 (0.380) data 0.000 (0.002) loss 1.1348 (1.6951) lr 5.0000e-03 eta 1:12:40
epoch [16/30] batch [480/796] time 0.368 (0.380) data 0.000 (0.002) loss 1.7617 (1.6809) lr 5.0000e-03 eta 1:12:32
epoch [16/30] batch [500/796] time 0.384 (0.380) data 0.000 (0.002) loss 2.6855 (1.6986) lr 5.0000e-03 eta 1:12:28
epoch [16/30] batch [520/796] time 0.423 (0.380) data 0.000 (0.002) loss 2.5664 (1.7062) lr 5.0000e-03 eta 1:12:22
epoch [16/30] batch [540/796] time 0.405 (0.380) data 0.000 (0.002) loss 2.3633 (1.7069) lr 5.0000e-03 eta 1:12:15
epoch [16/30] batch [560/796] time 0.377 (0.380) data 0.000 (0.002) loss 1.4707 (1.6971) lr 5.0000e-03 eta 1:12:04
epoch [16/30] batch [580/796] time 0.353 (0.380) data 0.000 (0.001) loss 1.4941 (1.6973) lr 5.0000e-03 eta 1:11:57
epoch [16/30] batch [600/796] time 0.391 (0.380) data 0.000 (0.001) loss 0.7397 (1.7098) lr 5.0000e-03 eta 1:11:50
epoch [16/30] batch [620/796] time 0.402 (0.380) data 0.000 (0.001) loss 0.1141 (1.7171) lr 5.0000e-03 eta 1:11:46
epoch [16/30] batch [640/796] time 0.358 (0.380) data 0.000 (0.001) loss 2.7559 (1.7223) lr 5.0000e-03 eta 1:11:38
epoch [16/30] batch [660/796] time 0.393 (0.381) data 0.000 (0.001) loss 3.1230 (1.7203) lr 5.0000e-03 eta 1:11:33
epoch [16/30] batch [680/796] time 0.370 (0.381) data 0.000 (0.001) loss 0.2786 (1.7168) lr 5.0000e-03 eta 1:11:27
epoch [16/30] batch [700/796] time 0.377 (0.381) data 0.000 (0.001) loss 1.6904 (1.7321) lr 5.0000e-03 eta 1:11:20
epoch [16/30] batch [720/796] time 0.350 (0.381) data 0.000 (0.001) loss 0.5625 (1.7383) lr 5.0000e-03 eta 1:11:12
epoch [16/30] batch [740/796] time 0.405 (0.381) data 0.000 (0.001) loss 0.7031 (1.7337) lr 5.0000e-03 eta 1:11:03
epoch [16/30] batch [760/796] time 0.406 (0.381) data 0.000 (0.001) loss 2.5625 (1.7394) lr 5.0000e-03 eta 1:10:56
epoch [16/30] batch [780/796] time 0.340 (0.380) data 0.000 (0.001) loss 1.2100 (1.7248) lr 5.0000e-03 eta 1:10:40
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:48,  5.69s/it] 10%|█         | 2/20 [00:06<00:51,  2.84s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.67s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.96it/s] 60%|██████    | 12/20 [00:09<00:02,  3.31it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.57it/s] 70%|███████   | 14/20 [00:09<00:01,  3.68it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.98it/s] 80%|████████  | 16/20 [00:10<00:00,  4.07it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.16it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.50it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.93it/s]100%|██████████| 20/20 [00:11<00:00,  4.36it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,595
* accuracy: 80.2%
* error: 19.8%
* macro_f1: 79.5%

epoch [17/30] batch [20/796] time 0.409 (0.427) data 0.000 (0.032) loss 2.9453 (1.8793) lr 4.4774e-03 eta 1:19:12
epoch [17/30] batch [40/796] time 0.348 (0.402) data 0.000 (0.016) loss 0.8701 (1.6961) lr 4.4774e-03 eta 1:14:25
epoch [17/30] batch [60/796] time 0.384 (0.391) data 0.000 (0.011) loss 0.2683 (1.5634) lr 4.4774e-03 eta 1:12:17
epoch [17/30] batch [80/796] time 0.352 (0.387) data 0.000 (0.008) loss 2.6445 (1.6530) lr 4.4774e-03 eta 1:11:21
epoch [17/30] batch [100/796] time 0.395 (0.385) data 0.000 (0.007) loss 0.3594 (1.5912) lr 4.4774e-03 eta 1:10:54
epoch [17/30] batch [120/796] time 0.400 (0.385) data 0.000 (0.006) loss 1.0000 (1.5299) lr 4.4774e-03 eta 1:10:45
epoch [17/30] batch [140/796] time 0.353 (0.385) data 0.000 (0.005) loss 0.4517 (1.4784) lr 4.4774e-03 eta 1:10:40
epoch [17/30] batch [160/796] time 0.359 (0.384) data 0.000 (0.004) loss 1.3604 (1.5399) lr 4.4774e-03 eta 1:10:22
epoch [17/30] batch [180/796] time 0.383 (0.383) data 0.000 (0.004) loss 1.6660 (1.5660) lr 4.4774e-03 eta 1:10:01
epoch [17/30] batch [200/796] time 0.363 (0.383) data 0.000 (0.003) loss 0.8330 (1.5722) lr 4.4774e-03 eta 1:09:47
epoch [17/30] batch [220/796] time 0.380 (0.382) data 0.000 (0.003) loss 1.9229 (1.5723) lr 4.4774e-03 eta 1:09:30
epoch [17/30] batch [240/796] time 0.386 (0.382) data 0.000 (0.003) loss 0.5142 (1.5494) lr 4.4774e-03 eta 1:09:23
epoch [17/30] batch [260/796] time 0.366 (0.382) data 0.000 (0.003) loss 2.7852 (1.5725) lr 4.4774e-03 eta 1:09:12
epoch [17/30] batch [280/796] time 0.370 (0.382) data 0.000 (0.003) loss 0.2747 (1.5656) lr 4.4774e-03 eta 1:09:06
epoch [17/30] batch [300/796] time 0.357 (0.381) data 0.000 (0.002) loss 3.1133 (1.5693) lr 4.4774e-03 eta 1:08:53
epoch [17/30] batch [320/796] time 0.393 (0.381) data 0.000 (0.002) loss 1.1846 (1.5988) lr 4.4774e-03 eta 1:08:42
epoch [17/30] batch [340/796] time 0.357 (0.381) data 0.000 (0.002) loss 0.9341 (1.6075) lr 4.4774e-03 eta 1:08:32
epoch [17/30] batch [360/796] time 0.391 (0.381) data 0.000 (0.002) loss 2.5879 (1.5837) lr 4.4774e-03 eta 1:08:23
epoch [17/30] batch [380/796] time 0.406 (0.381) data 0.000 (0.002) loss 0.0061 (1.5665) lr 4.4774e-03 eta 1:08:17
epoch [17/30] batch [400/796] time 0.382 (0.381) data 0.000 (0.002) loss 3.4531 (1.6021) lr 4.4774e-03 eta 1:08:08
epoch [17/30] batch [420/796] time 0.399 (0.381) data 0.000 (0.002) loss 1.4434 (1.5923) lr 4.4774e-03 eta 1:08:03
epoch [17/30] batch [440/796] time 0.390 (0.381) data 0.000 (0.002) loss 1.9990 (1.5838) lr 4.4774e-03 eta 1:07:55
epoch [17/30] batch [460/796] time 0.351 (0.381) data 0.000 (0.002) loss 0.8359 (1.5869) lr 4.4774e-03 eta 1:07:46
epoch [17/30] batch [480/796] time 0.364 (0.381) data 0.000 (0.002) loss 1.8232 (1.6096) lr 4.4774e-03 eta 1:07:38
epoch [17/30] batch [500/796] time 0.356 (0.380) data 0.000 (0.002) loss 1.9512 (1.6191) lr 4.4774e-03 eta 1:07:24
epoch [17/30] batch [520/796] time 0.387 (0.380) data 0.000 (0.001) loss 2.6602 (1.6448) lr 4.4774e-03 eta 1:07:15
epoch [17/30] batch [540/796] time 0.373 (0.380) data 0.000 (0.001) loss 0.9375 (1.6493) lr 4.4774e-03 eta 1:07:07
epoch [17/30] batch [560/796] time 0.395 (0.380) data 0.000 (0.001) loss 1.7920 (1.6691) lr 4.4774e-03 eta 1:07:00
epoch [17/30] batch [580/796] time 0.382 (0.380) data 0.000 (0.001) loss 0.7817 (1.6533) lr 4.4774e-03 eta 1:06:55
epoch [17/30] batch [600/796] time 0.353 (0.380) data 0.000 (0.001) loss 0.5356 (1.6551) lr 4.4774e-03 eta 1:06:46
epoch [17/30] batch [620/796] time 0.366 (0.380) data 0.000 (0.001) loss 0.6357 (1.6469) lr 4.4774e-03 eta 1:06:39
epoch [17/30] batch [640/796] time 0.390 (0.380) data 0.000 (0.001) loss 2.5645 (1.6508) lr 4.4774e-03 eta 1:06:31
epoch [17/30] batch [660/796] time 0.405 (0.380) data 0.000 (0.001) loss 3.1738 (1.6516) lr 4.4774e-03 eta 1:06:25
epoch [17/30] batch [680/796] time 0.395 (0.380) data 0.000 (0.001) loss 1.2910 (1.6577) lr 4.4774e-03 eta 1:06:19
epoch [17/30] batch [700/796] time 0.343 (0.380) data 0.000 (0.001) loss 0.5283 (1.6602) lr 4.4774e-03 eta 1:06:12
epoch [17/30] batch [720/796] time 0.395 (0.380) data 0.000 (0.001) loss 1.4473 (1.6502) lr 4.4774e-03 eta 1:06:03
epoch [17/30] batch [740/796] time 0.366 (0.380) data 0.000 (0.001) loss 1.0283 (1.6467) lr 4.4774e-03 eta 1:05:54
epoch [17/30] batch [760/796] time 0.416 (0.380) data 0.000 (0.001) loss 0.8804 (1.6507) lr 4.4774e-03 eta 1:05:49
epoch [17/30] batch [780/796] time 0.340 (0.380) data 0.000 (0.001) loss 0.5415 (1.6623) lr 4.4774e-03 eta 1:05:34
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.59s/it] 10%|█         | 2/20 [00:06<00:50,  2.82s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.67s/it] 20%|██        | 4/20 [00:07<00:17,  1.12s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:08,  1.56it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.91it/s] 60%|██████    | 12/20 [00:09<00:02,  3.27it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.38it/s] 70%|███████   | 14/20 [00:09<00:01,  3.66it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.78it/s] 80%|████████  | 16/20 [00:10<00:01,  3.95it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.87it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.21it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.53it/s]100%|██████████| 20/20 [00:11<00:00,  4.85it/s]100%|██████████| 20/20 [00:11<00:00,  1.79it/s]=> result
* total: 1,990
* correct: 1,612
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 80.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/796] time 0.407 (0.423) data 0.000 (0.035) loss 1.0361 (1.7874) lr 3.9604e-03 eta 1:12:45
epoch [18/30] batch [40/796] time 0.418 (0.403) data 0.000 (0.018) loss 1.0225 (1.6512) lr 3.9604e-03 eta 1:09:10
epoch [18/30] batch [60/796] time 0.388 (0.394) data 0.000 (0.012) loss 2.1895 (1.6898) lr 3.9604e-03 eta 1:07:33
epoch [18/30] batch [80/796] time 0.365 (0.391) data 0.000 (0.009) loss 0.6108 (1.6831) lr 3.9604e-03 eta 1:06:57
epoch [18/30] batch [100/796] time 0.397 (0.389) data 0.000 (0.007) loss 1.2344 (1.7065) lr 3.9604e-03 eta 1:06:27
epoch [18/30] batch [120/796] time 0.358 (0.389) data 0.000 (0.006) loss 2.0898 (1.6668) lr 3.9604e-03 eta 1:06:22
epoch [18/30] batch [140/796] time 0.391 (0.389) data 0.000 (0.005) loss 0.2169 (1.6790) lr 3.9604e-03 eta 1:06:06
epoch [18/30] batch [160/796] time 0.363 (0.387) data 0.000 (0.005) loss 0.2169 (1.6006) lr 3.9604e-03 eta 1:05:42
epoch [18/30] batch [180/796] time 0.395 (0.386) data 0.000 (0.004) loss 0.5229 (1.6148) lr 3.9604e-03 eta 1:05:25
epoch [18/30] batch [200/796] time 0.385 (0.385) data 0.000 (0.004) loss 3.5234 (1.5660) lr 3.9604e-03 eta 1:05:07
epoch [18/30] batch [220/796] time 0.393 (0.384) data 0.000 (0.003) loss 1.0986 (1.5864) lr 3.9604e-03 eta 1:04:50
epoch [18/30] batch [240/796] time 0.396 (0.384) data 0.000 (0.003) loss 0.3599 (1.5927) lr 3.9604e-03 eta 1:04:37
epoch [18/30] batch [260/796] time 0.354 (0.383) data 0.000 (0.003) loss 1.2754 (1.5901) lr 3.9604e-03 eta 1:04:24
epoch [18/30] batch [280/796] time 0.364 (0.383) data 0.000 (0.003) loss 0.8667 (1.5881) lr 3.9604e-03 eta 1:04:11
epoch [18/30] batch [300/796] time 0.400 (0.383) data 0.000 (0.003) loss 3.3828 (1.5866) lr 3.9604e-03 eta 1:04:06
epoch [18/30] batch [320/796] time 0.397 (0.383) data 0.000 (0.002) loss 2.8281 (1.5818) lr 3.9604e-03 eta 1:03:55
epoch [18/30] batch [340/796] time 0.346 (0.382) data 0.000 (0.002) loss 1.3652 (1.5947) lr 3.9604e-03 eta 1:03:42
epoch [18/30] batch [360/796] time 0.407 (0.382) data 0.000 (0.002) loss 1.3389 (1.5786) lr 3.9604e-03 eta 1:03:35
epoch [18/30] batch [380/796] time 0.390 (0.382) data 0.000 (0.002) loss 1.5811 (1.5643) lr 3.9604e-03 eta 1:03:27
epoch [18/30] batch [400/796] time 0.371 (0.382) data 0.000 (0.002) loss 0.5396 (1.5580) lr 3.9604e-03 eta 1:03:20
epoch [18/30] batch [420/796] time 0.375 (0.382) data 0.000 (0.002) loss 0.3452 (1.5963) lr 3.9604e-03 eta 1:03:08
epoch [18/30] batch [440/796] time 0.344 (0.381) data 0.000 (0.002) loss 0.9854 (1.5905) lr 3.9604e-03 eta 1:02:57
epoch [18/30] batch [460/796] time 0.382 (0.381) data 0.000 (0.002) loss 0.8350 (1.5689) lr 3.9604e-03 eta 1:02:50
epoch [18/30] batch [480/796] time 0.366 (0.381) data 0.000 (0.002) loss 3.4629 (1.5719) lr 3.9604e-03 eta 1:02:44
epoch [18/30] batch [500/796] time 0.355 (0.381) data 0.000 (0.002) loss 1.2920 (1.5686) lr 3.9604e-03 eta 1:02:36
epoch [18/30] batch [520/796] time 0.379 (0.382) data 0.000 (0.002) loss 1.4023 (1.5693) lr 3.9604e-03 eta 1:02:29
epoch [18/30] batch [540/796] time 0.407 (0.382) data 0.000 (0.002) loss 1.8623 (1.5708) lr 3.9604e-03 eta 1:02:23
epoch [18/30] batch [560/796] time 0.364 (0.382) data 0.000 (0.001) loss 5.3906 (1.5772) lr 3.9604e-03 eta 1:02:14
epoch [18/30] batch [580/796] time 0.403 (0.382) data 0.000 (0.001) loss 1.7852 (1.5733) lr 3.9604e-03 eta 1:02:08
epoch [18/30] batch [600/796] time 0.391 (0.382) data 0.000 (0.001) loss 0.5483 (1.5566) lr 3.9604e-03 eta 1:01:59
epoch [18/30] batch [620/796] time 0.349 (0.381) data 0.000 (0.001) loss 0.7085 (1.5640) lr 3.9604e-03 eta 1:01:49
epoch [18/30] batch [640/796] time 0.379 (0.381) data 0.000 (0.001) loss 0.3318 (1.5661) lr 3.9604e-03 eta 1:01:42
epoch [18/30] batch [660/796] time 0.376 (0.381) data 0.000 (0.001) loss 1.0000 (1.5679) lr 3.9604e-03 eta 1:01:35
epoch [18/30] batch [680/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.4390 (1.5624) lr 3.9604e-03 eta 1:01:25
epoch [18/30] batch [700/796] time 0.408 (0.381) data 0.000 (0.001) loss 0.6938 (1.5666) lr 3.9604e-03 eta 1:01:18
epoch [18/30] batch [720/796] time 0.371 (0.381) data 0.000 (0.001) loss 2.1484 (1.5703) lr 3.9604e-03 eta 1:01:10
epoch [18/30] batch [740/796] time 0.385 (0.381) data 0.000 (0.001) loss 1.0586 (1.5627) lr 3.9604e-03 eta 1:01:03
epoch [18/30] batch [760/796] time 0.370 (0.381) data 0.000 (0.001) loss 2.9375 (1.5581) lr 3.9604e-03 eta 1:00:56
epoch [18/30] batch [780/796] time 0.340 (0.380) data 0.000 (0.001) loss 4.5703 (1.5604) lr 3.9604e-03 eta 1:00:40
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.62s/it] 10%|█         | 2/20 [00:06<00:50,  2.82s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.67s/it] 20%|██        | 4/20 [00:07<00:17,  1.12s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.15it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.30it/s] 70%|███████   | 14/20 [00:09<00:01,  3.46it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.62it/s] 80%|████████  | 16/20 [00:10<00:01,  3.95it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.14it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.12it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.45it/s]100%|██████████| 20/20 [00:11<00:00,  4.79it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,604
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 80.0%

epoch [19/30] batch [20/796] time 0.363 (0.427) data 0.000 (0.044) loss 2.3672 (1.2985) lr 3.4549e-03 eta 1:07:51
epoch [19/30] batch [40/796] time 0.392 (0.405) data 0.000 (0.022) loss 0.7021 (1.4315) lr 3.4549e-03 eta 1:04:15
epoch [19/30] batch [60/796] time 0.350 (0.398) data 0.000 (0.015) loss 1.1260 (1.2277) lr 3.4549e-03 eta 1:02:53
epoch [19/30] batch [80/796] time 0.411 (0.394) data 0.000 (0.011) loss 0.4739 (1.3280) lr 3.4549e-03 eta 1:02:15
epoch [19/30] batch [100/796] time 0.381 (0.391) data 0.000 (0.009) loss 1.8369 (1.3360) lr 3.4549e-03 eta 1:01:36
epoch [19/30] batch [120/796] time 0.390 (0.389) data 0.000 (0.008) loss 1.5898 (1.3624) lr 3.4549e-03 eta 1:01:08
epoch [19/30] batch [140/796] time 0.411 (0.389) data 0.000 (0.007) loss 0.6807 (1.3901) lr 3.4549e-03 eta 1:01:00
epoch [19/30] batch [160/796] time 0.392 (0.388) data 0.000 (0.006) loss 0.4905 (1.3907) lr 3.4549e-03 eta 1:00:48
epoch [19/30] batch [180/796] time 0.399 (0.387) data 0.000 (0.005) loss 0.7090 (1.4390) lr 3.4549e-03 eta 1:00:28
epoch [19/30] batch [200/796] time 0.393 (0.387) data 0.000 (0.005) loss 0.4348 (1.4098) lr 3.4549e-03 eta 1:00:18
epoch [19/30] batch [220/796] time 0.382 (0.386) data 0.000 (0.004) loss 0.8750 (1.4379) lr 3.4549e-03 eta 1:00:04
epoch [19/30] batch [240/796] time 0.355 (0.386) data 0.000 (0.004) loss 0.8843 (1.4309) lr 3.4549e-03 eta 0:59:53
epoch [19/30] batch [260/796] time 0.359 (0.385) data 0.000 (0.004) loss 3.2246 (1.4802) lr 3.4549e-03 eta 0:59:38
epoch [19/30] batch [280/796] time 0.386 (0.385) data 0.000 (0.003) loss 0.2983 (1.5220) lr 3.4549e-03 eta 0:59:25
epoch [19/30] batch [300/796] time 0.387 (0.384) data 0.000 (0.003) loss 0.1459 (1.5197) lr 3.4549e-03 eta 0:59:11
epoch [19/30] batch [320/796] time 0.355 (0.383) data 0.000 (0.003) loss 0.8037 (1.5053) lr 3.4549e-03 eta 0:58:58
epoch [19/30] batch [340/796] time 0.372 (0.383) data 0.000 (0.003) loss 0.2827 (1.5236) lr 3.4549e-03 eta 0:58:45
epoch [19/30] batch [360/796] time 0.349 (0.383) data 0.000 (0.003) loss 3.8301 (1.5161) lr 3.4549e-03 eta 0:58:38
epoch [19/30] batch [380/796] time 0.397 (0.383) data 0.000 (0.003) loss 0.7861 (1.5285) lr 3.4549e-03 eta 0:58:33
epoch [19/30] batch [400/796] time 0.395 (0.383) data 0.000 (0.002) loss 1.1426 (1.5304) lr 3.4549e-03 eta 0:58:22
epoch [19/30] batch [420/796] time 0.351 (0.382) data 0.000 (0.002) loss 1.2275 (1.5494) lr 3.4549e-03 eta 0:58:12
epoch [19/30] batch [440/796] time 0.387 (0.382) data 0.000 (0.002) loss 1.3555 (1.5509) lr 3.4549e-03 eta 0:58:03
epoch [19/30] batch [460/796] time 0.353 (0.382) data 0.000 (0.002) loss 0.2544 (1.5648) lr 3.4549e-03 eta 0:57:55
epoch [19/30] batch [480/796] time 0.360 (0.382) data 0.000 (0.002) loss 0.4299 (1.5615) lr 3.4549e-03 eta 0:57:45
epoch [19/30] batch [500/796] time 0.396 (0.382) data 0.000 (0.002) loss 0.8784 (1.5635) lr 3.4549e-03 eta 0:57:37
epoch [19/30] batch [520/796] time 0.399 (0.382) data 0.000 (0.002) loss 0.6377 (1.5571) lr 3.4549e-03 eta 0:57:27
epoch [19/30] batch [540/796] time 0.383 (0.382) data 0.000 (0.002) loss 2.0605 (1.5651) lr 3.4549e-03 eta 0:57:20
epoch [19/30] batch [560/796] time 0.406 (0.382) data 0.000 (0.002) loss 3.1211 (1.5600) lr 3.4549e-03 eta 0:57:13
epoch [19/30] batch [580/796] time 0.363 (0.382) data 0.000 (0.002) loss 7.5273 (1.5729) lr 3.4549e-03 eta 0:57:04
epoch [19/30] batch [600/796] time 0.344 (0.382) data 0.000 (0.002) loss 0.0467 (1.5597) lr 3.4549e-03 eta 0:56:55
epoch [19/30] batch [620/796] time 0.388 (0.382) data 0.000 (0.002) loss 0.8477 (1.5599) lr 3.4549e-03 eta 0:56:47
epoch [19/30] batch [640/796] time 0.412 (0.381) data 0.000 (0.002) loss 0.8379 (1.5572) lr 3.4549e-03 eta 0:56:38
epoch [19/30] batch [660/796] time 0.365 (0.381) data 0.000 (0.002) loss 2.4219 (1.5610) lr 3.4549e-03 eta 0:56:31
epoch [19/30] batch [680/796] time 0.378 (0.382) data 0.000 (0.002) loss 1.7949 (1.5813) lr 3.4549e-03 eta 0:56:24
epoch [19/30] batch [700/796] time 0.382 (0.382) data 0.000 (0.002) loss 0.3306 (1.5807) lr 3.4549e-03 eta 0:56:17
epoch [19/30] batch [720/796] time 0.396 (0.382) data 0.000 (0.001) loss 1.3027 (1.5772) lr 3.4549e-03 eta 0:56:09
epoch [19/30] batch [740/796] time 0.399 (0.382) data 0.000 (0.001) loss 1.4248 (1.5728) lr 3.4549e-03 eta 0:56:02
epoch [19/30] batch [760/796] time 0.376 (0.381) data 0.000 (0.001) loss 1.3184 (1.5701) lr 3.4549e-03 eta 0:55:52
epoch [19/30] batch [780/796] time 0.342 (0.381) data 0.000 (0.001) loss 0.1531 (1.5752) lr 3.4549e-03 eta 0:55:38
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.66s/it] 10%|█         | 2/20 [00:06<00:51,  2.88s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.87it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.43it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.05it/s] 60%|██████    | 12/20 [00:09<00:02,  3.36it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.49it/s] 70%|███████   | 14/20 [00:09<00:01,  3.69it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.78it/s] 80%|████████  | 16/20 [00:10<00:01,  3.93it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.08it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.17it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.50it/s]100%|██████████| 20/20 [00:11<00:00,  4.83it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,611
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 80.5%

epoch [20/30] batch [20/796] time 0.350 (0.420) data 0.000 (0.034) loss 0.6055 (1.3799) lr 2.9663e-03 eta 1:01:07
epoch [20/30] batch [40/796] time 0.377 (0.397) data 0.000 (0.017) loss 0.4980 (1.6361) lr 2.9663e-03 eta 0:57:37
epoch [20/30] batch [60/796] time 0.354 (0.391) data 0.000 (0.011) loss 1.0947 (1.5054) lr 2.9663e-03 eta 0:56:43
epoch [20/30] batch [80/796] time 0.355 (0.388) data 0.000 (0.009) loss 4.1680 (1.5100) lr 2.9663e-03 eta 0:56:06
epoch [20/30] batch [100/796] time 0.398 (0.386) data 0.000 (0.007) loss 3.2676 (1.4873) lr 2.9663e-03 eta 0:55:38
epoch [20/30] batch [120/796] time 0.396 (0.384) data 0.000 (0.006) loss 0.3477 (1.4499) lr 2.9663e-03 eta 0:55:14
epoch [20/30] batch [140/796] time 0.357 (0.384) data 0.000 (0.005) loss 0.7114 (1.4714) lr 2.9663e-03 eta 0:55:11
epoch [20/30] batch [160/796] time 0.395 (0.384) data 0.000 (0.004) loss 1.6650 (1.4745) lr 2.9663e-03 eta 0:54:58
epoch [20/30] batch [180/796] time 0.393 (0.383) data 0.000 (0.004) loss 1.8369 (1.4367) lr 2.9663e-03 eta 0:54:42
epoch [20/30] batch [200/796] time 0.404 (0.383) data 0.000 (0.004) loss 0.5693 (1.4692) lr 2.9663e-03 eta 0:54:40
epoch [20/30] batch [220/796] time 0.380 (0.383) data 0.000 (0.003) loss 0.7256 (1.4351) lr 2.9663e-03 eta 0:54:32
epoch [20/30] batch [240/796] time 0.466 (0.384) data 0.001 (0.003) loss 1.0332 (1.4491) lr 2.9663e-03 eta 0:54:26
epoch [20/30] batch [260/796] time 0.389 (0.383) data 0.000 (0.003) loss 0.3762 (1.4417) lr 2.9663e-03 eta 0:54:14
epoch [20/30] batch [280/796] time 0.387 (0.383) data 0.000 (0.003) loss 1.1611 (1.4375) lr 2.9663e-03 eta 0:54:07
epoch [20/30] batch [300/796] time 0.403 (0.383) data 0.000 (0.002) loss 0.7549 (1.4554) lr 2.9663e-03 eta 0:53:59
epoch [20/30] batch [320/796] time 0.365 (0.383) data 0.000 (0.002) loss 0.9297 (1.4562) lr 2.9663e-03 eta 0:53:49
epoch [20/30] batch [340/796] time 0.359 (0.383) data 0.000 (0.002) loss 2.7148 (1.4700) lr 2.9663e-03 eta 0:53:39
epoch [20/30] batch [360/796] time 0.355 (0.382) data 0.000 (0.002) loss 0.6108 (1.4584) lr 2.9663e-03 eta 0:53:27
epoch [20/30] batch [380/796] time 0.371 (0.382) data 0.000 (0.002) loss 1.1719 (1.4758) lr 2.9663e-03 eta 0:53:19
epoch [20/30] batch [400/796] time 0.375 (0.382) data 0.000 (0.002) loss 1.8389 (1.4652) lr 2.9663e-03 eta 0:53:12
epoch [20/30] batch [420/796] time 0.405 (0.382) data 0.000 (0.002) loss 1.9443 (1.4721) lr 2.9663e-03 eta 0:53:06
epoch [20/30] batch [440/796] time 0.364 (0.382) data 0.000 (0.002) loss 0.1686 (1.4711) lr 2.9663e-03 eta 0:52:57
epoch [20/30] batch [460/796] time 0.422 (0.382) data 0.000 (0.002) loss 0.5166 (1.4661) lr 2.9663e-03 eta 0:52:46
epoch [20/30] batch [480/796] time 0.364 (0.381) data 0.000 (0.002) loss 0.7349 (1.4658) lr 2.9663e-03 eta 0:52:36
epoch [20/30] batch [500/796] time 0.379 (0.381) data 0.000 (0.002) loss 0.6299 (1.4522) lr 2.9663e-03 eta 0:52:28
epoch [20/30] batch [520/796] time 0.364 (0.381) data 0.000 (0.002) loss 1.9980 (1.4660) lr 2.9663e-03 eta 0:52:20
epoch [20/30] batch [540/796] time 0.351 (0.381) data 0.000 (0.001) loss 0.2661 (1.4795) lr 2.9663e-03 eta 0:52:11
epoch [20/30] batch [560/796] time 0.380 (0.381) data 0.000 (0.001) loss 1.9932 (1.4882) lr 2.9663e-03 eta 0:52:01
epoch [20/30] batch [580/796] time 0.399 (0.381) data 0.000 (0.001) loss 0.0290 (1.5061) lr 2.9663e-03 eta 0:51:53
epoch [20/30] batch [600/796] time 0.390 (0.381) data 0.000 (0.001) loss 1.2139 (1.4949) lr 2.9663e-03 eta 0:51:45
epoch [20/30] batch [620/796] time 0.376 (0.381) data 0.000 (0.001) loss 2.3945 (1.5093) lr 2.9663e-03 eta 0:51:38
epoch [20/30] batch [640/796] time 0.382 (0.381) data 0.000 (0.001) loss 0.7773 (1.5018) lr 2.9663e-03 eta 0:51:29
epoch [20/30] batch [660/796] time 0.358 (0.381) data 0.000 (0.001) loss 0.5547 (1.5079) lr 2.9663e-03 eta 0:51:23
epoch [20/30] batch [680/796] time 0.355 (0.381) data 0.000 (0.001) loss 1.6572 (1.5157) lr 2.9663e-03 eta 0:51:15
epoch [20/30] batch [700/796] time 0.348 (0.381) data 0.000 (0.001) loss 1.7520 (1.5161) lr 2.9663e-03 eta 0:51:07
epoch [20/30] batch [720/796] time 0.360 (0.381) data 0.000 (0.001) loss 0.9565 (1.5247) lr 2.9663e-03 eta 0:51:00
epoch [20/30] batch [740/796] time 0.398 (0.381) data 0.000 (0.001) loss 0.9512 (1.5264) lr 2.9663e-03 eta 0:50:51
epoch [20/30] batch [760/796] time 0.367 (0.381) data 0.000 (0.001) loss 0.2395 (1.5209) lr 2.9663e-03 eta 0:50:44
epoch [20/30] batch [780/796] time 0.340 (0.380) data 0.000 (0.001) loss 0.5181 (1.5153) lr 2.9663e-03 eta 0:50:30
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:40,  5.31s/it] 10%|█         | 2/20 [00:06<00:52,  2.90s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.71s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.52it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.84it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.97it/s] 60%|██████    | 12/20 [00:09<00:02,  3.16it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.36it/s] 70%|███████   | 14/20 [00:09<00:01,  3.69it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.76it/s] 80%|████████  | 16/20 [00:10<00:00,  4.11it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.11it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.09it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.43it/s]100%|██████████| 20/20 [00:11<00:00,  4.78it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,603
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 80.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/796] time 0.360 (0.424) data 0.000 (0.033) loss 0.8008 (1.7928) lr 2.5000e-03 eta 0:56:05
epoch [21/30] batch [40/796] time 0.374 (0.402) data 0.000 (0.017) loss 0.7529 (1.8364) lr 2.5000e-03 eta 0:53:01
epoch [21/30] batch [60/796] time 0.361 (0.394) data 0.000 (0.011) loss 0.5264 (1.7496) lr 2.5000e-03 eta 0:51:48
epoch [21/30] batch [80/796] time 0.374 (0.391) data 0.000 (0.008) loss 0.8423 (1.6895) lr 2.5000e-03 eta 0:51:17
epoch [21/30] batch [100/796] time 0.349 (0.388) data 0.000 (0.007) loss 1.4609 (1.6755) lr 2.5000e-03 eta 0:50:48
epoch [21/30] batch [120/796] time 0.353 (0.385) data 0.000 (0.006) loss 1.3545 (1.6665) lr 2.5000e-03 eta 0:50:21
epoch [21/30] batch [140/796] time 0.396 (0.384) data 0.000 (0.005) loss 0.2062 (1.6159) lr 2.5000e-03 eta 0:50:04
epoch [21/30] batch [160/796] time 0.387 (0.383) data 0.000 (0.004) loss 3.3555 (1.6115) lr 2.5000e-03 eta 0:49:47
epoch [21/30] batch [180/796] time 0.367 (0.382) data 0.000 (0.004) loss 1.3096 (1.6093) lr 2.5000e-03 eta 0:49:35
epoch [21/30] batch [200/796] time 0.362 (0.382) data 0.000 (0.003) loss 4.0820 (1.5943) lr 2.5000e-03 eta 0:49:26
epoch [21/30] batch [220/796] time 0.372 (0.382) data 0.000 (0.003) loss 0.8906 (1.5882) lr 2.5000e-03 eta 0:49:16
epoch [21/30] batch [240/796] time 0.394 (0.382) data 0.000 (0.003) loss 3.3887 (1.5904) lr 2.5000e-03 eta 0:49:06
epoch [21/30] batch [260/796] time 0.400 (0.381) data 0.000 (0.003) loss 1.3691 (1.6009) lr 2.5000e-03 eta 0:48:55
epoch [21/30] batch [280/796] time 0.377 (0.381) data 0.000 (0.003) loss 4.1172 (1.5830) lr 2.5000e-03 eta 0:48:45
epoch [21/30] batch [300/796] time 0.369 (0.380) data 0.000 (0.002) loss 1.4199 (1.5911) lr 2.5000e-03 eta 0:48:33
epoch [21/30] batch [320/796] time 0.386 (0.381) data 0.000 (0.002) loss 1.0703 (1.6079) lr 2.5000e-03 eta 0:48:28
epoch [21/30] batch [340/796] time 0.465 (0.381) data 0.000 (0.002) loss 0.3923 (1.5894) lr 2.5000e-03 eta 0:48:22
epoch [21/30] batch [360/796] time 0.395 (0.381) data 0.000 (0.002) loss 0.4395 (1.5869) lr 2.5000e-03 eta 0:48:14
epoch [21/30] batch [380/796] time 0.391 (0.380) data 0.000 (0.002) loss 2.3867 (1.5575) lr 2.5000e-03 eta 0:48:04
epoch [21/30] batch [400/796] time 0.348 (0.380) data 0.000 (0.002) loss 1.8906 (1.5811) lr 2.5000e-03 eta 0:47:53
epoch [21/30] batch [420/796] time 0.401 (0.380) data 0.000 (0.002) loss 0.7490 (1.5619) lr 2.5000e-03 eta 0:47:47
epoch [21/30] batch [440/796] time 0.369 (0.380) data 0.000 (0.002) loss 1.5381 (1.5999) lr 2.5000e-03 eta 0:47:37
epoch [21/30] batch [460/796] time 0.357 (0.380) data 0.000 (0.002) loss 1.5342 (1.5868) lr 2.5000e-03 eta 0:47:31
epoch [21/30] batch [480/796] time 0.353 (0.380) data 0.000 (0.002) loss 1.9766 (1.5967) lr 2.5000e-03 eta 0:47:23
epoch [21/30] batch [500/796] time 0.356 (0.380) data 0.000 (0.002) loss 5.5508 (1.5990) lr 2.5000e-03 eta 0:47:14
epoch [21/30] batch [520/796] time 0.405 (0.380) data 0.000 (0.001) loss 1.7236 (1.6035) lr 2.5000e-03 eta 0:47:06
epoch [21/30] batch [540/796] time 0.352 (0.380) data 0.000 (0.001) loss 3.1074 (1.6143) lr 2.5000e-03 eta 0:46:58
epoch [21/30] batch [560/796] time 0.388 (0.380) data 0.000 (0.001) loss 3.2891 (1.6205) lr 2.5000e-03 eta 0:46:51
epoch [21/30] batch [580/796] time 0.384 (0.380) data 0.000 (0.001) loss 4.0430 (1.6248) lr 2.5000e-03 eta 0:46:45
epoch [21/30] batch [600/796] time 0.357 (0.380) data 0.000 (0.001) loss 2.5586 (1.6249) lr 2.5000e-03 eta 0:46:39
epoch [21/30] batch [620/796] time 0.394 (0.380) data 0.000 (0.001) loss 0.0637 (1.6135) lr 2.5000e-03 eta 0:46:31
epoch [21/30] batch [640/796] time 0.420 (0.380) data 0.000 (0.001) loss 0.4446 (1.5982) lr 2.5000e-03 eta 0:46:24
epoch [21/30] batch [660/796] time 0.393 (0.380) data 0.000 (0.001) loss 2.4551 (1.6068) lr 2.5000e-03 eta 0:46:14
epoch [21/30] batch [680/796] time 0.380 (0.380) data 0.001 (0.001) loss 0.3203 (1.6087) lr 2.5000e-03 eta 0:46:08
epoch [21/30] batch [700/796] time 0.390 (0.381) data 0.000 (0.001) loss 3.6758 (1.6095) lr 2.5000e-03 eta 0:46:03
epoch [21/30] batch [720/796] time 0.382 (0.380) data 0.000 (0.001) loss 0.7871 (1.5933) lr 2.5000e-03 eta 0:45:54
epoch [21/30] batch [740/796] time 0.349 (0.380) data 0.000 (0.001) loss 1.1348 (1.6008) lr 2.5000e-03 eta 0:45:46
epoch [21/30] batch [760/796] time 0.370 (0.381) data 0.000 (0.001) loss 2.9492 (1.5933) lr 2.5000e-03 eta 0:45:39
epoch [21/30] batch [780/796] time 0.341 (0.380) data 0.000 (0.001) loss 1.7373 (1.5877) lr 2.5000e-03 eta 0:45:27
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.63s/it] 10%|█         | 2/20 [00:06<00:51,  2.86s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.69s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.47it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.03it/s] 60%|██████    | 12/20 [00:09<00:02,  3.23it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.35it/s] 70%|███████   | 14/20 [00:09<00:01,  3.45it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.66it/s] 80%|████████  | 16/20 [00:10<00:01,  3.75it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.82it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.20it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.52it/s]100%|██████████| 20/20 [00:11<00:00,  4.84it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,618
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 80.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [22/30] batch [20/796] time 0.401 (0.432) data 0.000 (0.039) loss 0.8086 (1.6516) lr 2.0611e-03 eta 0:51:27
epoch [22/30] batch [40/796] time 0.360 (0.404) data 0.000 (0.020) loss 4.3594 (1.4950) lr 2.0611e-03 eta 0:47:55
epoch [22/30] batch [60/796] time 0.374 (0.397) data 0.000 (0.013) loss 0.4944 (1.5651) lr 2.0611e-03 eta 0:47:00
epoch [22/30] batch [80/796] time 0.408 (0.394) data 0.000 (0.010) loss 0.0539 (1.5957) lr 2.0611e-03 eta 0:46:30
epoch [22/30] batch [100/796] time 0.388 (0.391) data 0.000 (0.008) loss 0.2383 (1.5211) lr 2.0611e-03 eta 0:46:04
epoch [22/30] batch [120/796] time 0.377 (0.388) data 0.000 (0.007) loss 3.9199 (1.5530) lr 2.0611e-03 eta 0:45:31
epoch [22/30] batch [140/796] time 0.362 (0.387) data 0.000 (0.006) loss 1.4111 (1.5121) lr 2.0611e-03 eta 0:45:15
epoch [22/30] batch [160/796] time 0.356 (0.385) data 0.000 (0.005) loss 1.1182 (1.5714) lr 2.0611e-03 eta 0:44:56
epoch [22/30] batch [180/796] time 0.389 (0.386) data 0.000 (0.005) loss 0.7983 (1.5131) lr 2.0611e-03 eta 0:44:52
epoch [22/30] batch [200/796] time 0.393 (0.385) data 0.000 (0.004) loss 0.8008 (1.5268) lr 2.0611e-03 eta 0:44:43
epoch [22/30] batch [220/796] time 0.385 (0.385) data 0.000 (0.004) loss 1.6182 (1.5494) lr 2.0611e-03 eta 0:44:32
epoch [22/30] batch [240/796] time 0.346 (0.385) data 0.000 (0.004) loss 0.8354 (1.5443) lr 2.0611e-03 eta 0:44:27
epoch [22/30] batch [260/796] time 0.403 (0.385) data 0.000 (0.003) loss 0.1144 (1.5539) lr 2.0611e-03 eta 0:44:15
epoch [22/30] batch [280/796] time 0.364 (0.384) data 0.000 (0.003) loss 2.3672 (1.5719) lr 2.0611e-03 eta 0:44:04
epoch [22/30] batch [300/796] time 0.356 (0.383) data 0.000 (0.003) loss 0.9121 (1.5723) lr 2.0611e-03 eta 0:43:51
epoch [22/30] batch [320/796] time 0.353 (0.383) data 0.000 (0.003) loss 2.2461 (1.5564) lr 2.0611e-03 eta 0:43:41
epoch [22/30] batch [340/796] time 0.433 (0.383) data 0.000 (0.003) loss 0.7949 (1.5777) lr 2.0611e-03 eta 0:43:31
epoch [22/30] batch [360/796] time 0.349 (0.383) data 0.000 (0.002) loss 3.4883 (1.5887) lr 2.0611e-03 eta 0:43:23
epoch [22/30] batch [380/796] time 0.365 (0.382) data 0.000 (0.002) loss 0.2300 (1.5869) lr 2.0611e-03 eta 0:43:13
epoch [22/30] batch [400/796] time 0.370 (0.382) data 0.000 (0.002) loss 0.3008 (1.5670) lr 2.0611e-03 eta 0:43:03
epoch [22/30] batch [420/796] time 0.363 (0.382) data 0.000 (0.002) loss 0.4021 (1.5692) lr 2.0611e-03 eta 0:42:55
epoch [22/30] batch [440/796] time 0.401 (0.382) data 0.000 (0.002) loss 0.5029 (1.5787) lr 2.0611e-03 eta 0:42:48
epoch [22/30] batch [460/796] time 0.411 (0.382) data 0.000 (0.002) loss 0.4026 (1.5630) lr 2.0611e-03 eta 0:42:41
epoch [22/30] batch [480/796] time 0.400 (0.382) data 0.000 (0.002) loss 2.7910 (1.5535) lr 2.0611e-03 eta 0:42:35
epoch [22/30] batch [500/796] time 0.401 (0.382) data 0.000 (0.002) loss 0.4543 (1.5476) lr 2.0611e-03 eta 0:42:26
epoch [22/30] batch [520/796] time 0.373 (0.382) data 0.000 (0.002) loss 1.9355 (1.5512) lr 2.0611e-03 eta 0:42:18
epoch [22/30] batch [540/796] time 0.395 (0.382) data 0.001 (0.002) loss 0.8413 (1.5455) lr 2.0611e-03 eta 0:42:10
epoch [22/30] batch [560/796] time 0.399 (0.382) data 0.000 (0.002) loss 2.5566 (1.5450) lr 2.0611e-03 eta 0:42:02
epoch [22/30] batch [580/796] time 0.375 (0.382) data 0.000 (0.002) loss 1.2676 (1.5438) lr 2.0611e-03 eta 0:41:54
epoch [22/30] batch [600/796] time 0.393 (0.382) data 0.000 (0.002) loss 2.0938 (1.5310) lr 2.0611e-03 eta 0:41:46
epoch [22/30] batch [620/796] time 0.371 (0.381) data 0.000 (0.002) loss 0.5361 (1.5163) lr 2.0611e-03 eta 0:41:36
epoch [22/30] batch [640/796] time 0.350 (0.381) data 0.000 (0.001) loss 0.4900 (1.5318) lr 2.0611e-03 eta 0:41:26
epoch [22/30] batch [660/796] time 0.356 (0.381) data 0.000 (0.001) loss 2.3535 (1.5496) lr 2.0611e-03 eta 0:41:16
epoch [22/30] batch [680/796] time 0.381 (0.381) data 0.000 (0.001) loss 1.1670 (1.5458) lr 2.0611e-03 eta 0:41:09
epoch [22/30] batch [700/796] time 0.357 (0.381) data 0.000 (0.001) loss 0.6978 (1.5353) lr 2.0611e-03 eta 0:41:01
epoch [22/30] batch [720/796] time 0.368 (0.381) data 0.000 (0.001) loss 2.7910 (1.5327) lr 2.0611e-03 eta 0:40:53
epoch [22/30] batch [740/796] time 0.394 (0.381) data 0.000 (0.001) loss 2.0449 (1.5315) lr 2.0611e-03 eta 0:40:47
epoch [22/30] batch [760/796] time 0.377 (0.381) data 0.000 (0.001) loss 0.5815 (1.5308) lr 2.0611e-03 eta 0:40:39
epoch [22/30] batch [780/796] time 0.339 (0.380) data 0.000 (0.001) loss 1.8115 (1.5326) lr 2.0611e-03 eta 0:40:26
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.51s/it] 10%|█         | 2/20 [00:06<00:52,  2.93s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.73s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.43it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.95it/s] 60%|██████    | 12/20 [00:09<00:02,  3.23it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.58it/s] 70%|███████   | 14/20 [00:09<00:01,  3.76it/s] 75%|███████▌  | 15/20 [00:10<00:01,  4.03it/s] 80%|████████  | 16/20 [00:10<00:00,  4.02it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.96it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.46it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.89it/s]100%|██████████| 20/20 [00:11<00:00,  4.33it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,614
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 80.7%

epoch [23/30] batch [20/796] time 0.385 (0.426) data 0.000 (0.036) loss 0.2874 (1.5589) lr 1.6543e-03 eta 0:45:06
epoch [23/30] batch [40/796] time 0.378 (0.400) data 0.000 (0.018) loss 2.7168 (1.6415) lr 1.6543e-03 eta 0:42:11
epoch [23/30] batch [60/796] time 0.355 (0.393) data 0.000 (0.012) loss 0.5889 (1.6039) lr 1.6543e-03 eta 0:41:22
epoch [23/30] batch [80/796] time 0.374 (0.390) data 0.000 (0.009) loss 4.0781 (1.6248) lr 1.6543e-03 eta 0:40:51
epoch [23/30] batch [100/796] time 0.369 (0.388) data 0.000 (0.007) loss 4.2266 (1.6252) lr 1.6543e-03 eta 0:40:32
epoch [23/30] batch [120/796] time 0.354 (0.388) data 0.000 (0.006) loss 1.6865 (1.5863) lr 1.6543e-03 eta 0:40:26
epoch [23/30] batch [140/796] time 0.386 (0.388) data 0.000 (0.005) loss 1.3809 (1.5580) lr 1.6543e-03 eta 0:40:16
epoch [23/30] batch [160/796] time 0.357 (0.387) data 0.000 (0.005) loss 0.0956 (1.5201) lr 1.6543e-03 eta 0:40:02
epoch [23/30] batch [180/796] time 0.392 (0.387) data 0.000 (0.004) loss 0.1074 (1.5258) lr 1.6543e-03 eta 0:39:51
epoch [23/30] batch [200/796] time 0.345 (0.386) data 0.000 (0.004) loss 0.1044 (1.5215) lr 1.6543e-03 eta 0:39:42
epoch [23/30] batch [220/796] time 0.364 (0.385) data 0.000 (0.003) loss 0.9326 (1.5302) lr 1.6543e-03 eta 0:39:27
epoch [23/30] batch [240/796] time 0.397 (0.384) data 0.000 (0.003) loss 0.2524 (1.5215) lr 1.6543e-03 eta 0:39:15
epoch [23/30] batch [260/796] time 0.360 (0.384) data 0.000 (0.003) loss 0.5254 (1.5224) lr 1.6543e-03 eta 0:39:03
epoch [23/30] batch [280/796] time 0.377 (0.383) data 0.000 (0.003) loss 0.1730 (1.5100) lr 1.6543e-03 eta 0:38:51
epoch [23/30] batch [300/796] time 0.363 (0.383) data 0.000 (0.003) loss 3.5332 (1.5481) lr 1.6543e-03 eta 0:38:41
epoch [23/30] batch [320/796] time 0.395 (0.383) data 0.000 (0.002) loss 0.3738 (1.5430) lr 1.6543e-03 eta 0:38:33
epoch [23/30] batch [340/796] time 0.380 (0.382) data 0.000 (0.002) loss 0.5195 (1.5645) lr 1.6543e-03 eta 0:38:23
epoch [23/30] batch [360/796] time 0.355 (0.382) data 0.000 (0.002) loss 1.4717 (1.5571) lr 1.6543e-03 eta 0:38:13
epoch [23/30] batch [380/796] time 0.409 (0.382) data 0.000 (0.002) loss 5.1055 (1.5216) lr 1.6543e-03 eta 0:38:04
epoch [23/30] batch [400/796] time 0.391 (0.382) data 0.000 (0.002) loss 3.2930 (1.5142) lr 1.6543e-03 eta 0:37:57
epoch [23/30] batch [420/796] time 0.366 (0.381) data 0.000 (0.002) loss 0.3062 (1.5231) lr 1.6543e-03 eta 0:37:48
epoch [23/30] batch [440/796] time 0.390 (0.381) data 0.000 (0.002) loss 2.8281 (1.5476) lr 1.6543e-03 eta 0:37:41
epoch [23/30] batch [460/796] time 0.396 (0.381) data 0.000 (0.002) loss 0.2076 (1.5491) lr 1.6543e-03 eta 0:37:33
epoch [23/30] batch [480/796] time 0.361 (0.381) data 0.000 (0.002) loss 0.5835 (1.5555) lr 1.6543e-03 eta 0:37:23
epoch [23/30] batch [500/796] time 0.377 (0.380) data 0.000 (0.002) loss 1.6816 (1.5376) lr 1.6543e-03 eta 0:37:12
epoch [23/30] batch [520/796] time 0.349 (0.380) data 0.000 (0.002) loss 2.5781 (1.5280) lr 1.6543e-03 eta 0:37:04
epoch [23/30] batch [540/796] time 0.358 (0.381) data 0.000 (0.002) loss 1.0557 (1.5272) lr 1.6543e-03 eta 0:36:57
epoch [23/30] batch [560/796] time 0.435 (0.381) data 0.000 (0.002) loss 1.4824 (1.5247) lr 1.6543e-03 eta 0:36:50
epoch [23/30] batch [580/796] time 0.377 (0.381) data 0.000 (0.001) loss 2.6367 (1.5522) lr 1.6543e-03 eta 0:36:43
epoch [23/30] batch [600/796] time 0.405 (0.381) data 0.000 (0.001) loss 0.9883 (1.5432) lr 1.6543e-03 eta 0:36:37
epoch [23/30] batch [620/796] time 0.354 (0.381) data 0.000 (0.001) loss 1.9268 (1.5478) lr 1.6543e-03 eta 0:36:28
epoch [23/30] batch [640/796] time 0.397 (0.381) data 0.000 (0.001) loss 0.9517 (1.5489) lr 1.6543e-03 eta 0:36:21
epoch [23/30] batch [660/796] time 0.387 (0.381) data 0.000 (0.001) loss 1.8857 (1.5559) lr 1.6543e-03 eta 0:36:12
epoch [23/30] batch [680/796] time 0.362 (0.381) data 0.000 (0.001) loss 0.6040 (1.5479) lr 1.6543e-03 eta 0:36:04
epoch [23/30] batch [700/796] time 0.388 (0.381) data 0.000 (0.001) loss 1.1465 (1.5446) lr 1.6543e-03 eta 0:35:57
epoch [23/30] batch [720/796] time 0.389 (0.381) data 0.000 (0.001) loss 1.1035 (1.5329) lr 1.6543e-03 eta 0:35:49
epoch [23/30] batch [740/796] time 0.390 (0.381) data 0.000 (0.001) loss 0.0592 (1.5204) lr 1.6543e-03 eta 0:35:42
epoch [23/30] batch [760/796] time 0.361 (0.381) data 0.000 (0.001) loss 3.0820 (1.5166) lr 1.6543e-03 eta 0:35:35
epoch [23/30] batch [780/796] time 0.339 (0.380) data 0.000 (0.001) loss 0.3650 (1.5046) lr 1.6543e-03 eta 0:35:22
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.64s/it] 10%|█         | 2/20 [00:06<00:51,  2.88s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.87it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.42it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.03it/s] 60%|██████    | 12/20 [00:09<00:02,  3.25it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.44it/s] 70%|███████   | 14/20 [00:09<00:01,  3.53it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.61it/s] 80%|████████  | 16/20 [00:10<00:01,  3.81it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.90it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.25it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.56it/s]100%|██████████| 20/20 [00:11<00:00,  4.87it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,615
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 80.8%

epoch [24/30] batch [20/796] time 0.379 (0.430) data 0.000 (0.033) loss 0.3943 (1.2060) lr 1.2843e-03 eta 0:39:49
epoch [24/30] batch [40/796] time 0.387 (0.407) data 0.000 (0.017) loss 0.9580 (1.2937) lr 1.2843e-03 eta 0:37:28
epoch [24/30] batch [60/796] time 0.387 (0.396) data 0.000 (0.011) loss 1.0283 (1.2715) lr 1.2843e-03 eta 0:36:25
epoch [24/30] batch [80/796] time 0.379 (0.393) data 0.000 (0.009) loss 2.3652 (1.3277) lr 1.2843e-03 eta 0:35:56
epoch [24/30] batch [100/796] time 0.383 (0.389) data 0.000 (0.007) loss 0.1061 (1.3773) lr 1.2843e-03 eta 0:35:31
epoch [24/30] batch [120/796] time 0.392 (0.388) data 0.000 (0.006) loss 2.3086 (1.4410) lr 1.2843e-03 eta 0:35:17
epoch [24/30] batch [140/796] time 0.355 (0.386) data 0.000 (0.005) loss 2.3770 (1.3934) lr 1.2843e-03 eta 0:34:55
epoch [24/30] batch [160/796] time 0.376 (0.385) data 0.000 (0.004) loss 0.2417 (1.4383) lr 1.2843e-03 eta 0:34:44
epoch [24/30] batch [180/796] time 0.350 (0.384) data 0.000 (0.004) loss 0.8447 (1.4029) lr 1.2843e-03 eta 0:34:32
epoch [24/30] batch [200/796] time 0.367 (0.383) data 0.000 (0.004) loss 0.6187 (1.4042) lr 1.2843e-03 eta 0:34:18
epoch [24/30] batch [220/796] time 0.406 (0.382) data 0.000 (0.003) loss 0.8145 (1.4251) lr 1.2843e-03 eta 0:34:07
epoch [24/30] batch [240/796] time 0.360 (0.382) data 0.000 (0.003) loss 3.8203 (1.4431) lr 1.2843e-03 eta 0:33:56
epoch [24/30] batch [260/796] time 0.389 (0.381) data 0.000 (0.003) loss 0.7412 (1.4415) lr 1.2843e-03 eta 0:33:45
epoch [24/30] batch [280/796] time 0.358 (0.381) data 0.000 (0.003) loss 4.6719 (1.4323) lr 1.2843e-03 eta 0:33:37
epoch [24/30] batch [300/796] time 0.391 (0.381) data 0.000 (0.002) loss 0.9375 (1.4478) lr 1.2843e-03 eta 0:33:30
epoch [24/30] batch [320/796] time 0.383 (0.381) data 0.000 (0.002) loss 0.3723 (1.4260) lr 1.2843e-03 eta 0:33:22
epoch [24/30] batch [340/796] time 0.395 (0.381) data 0.000 (0.002) loss 2.2480 (1.4313) lr 1.2843e-03 eta 0:33:15
epoch [24/30] batch [360/796] time 0.395 (0.381) data 0.000 (0.002) loss 2.2305 (1.4589) lr 1.2843e-03 eta 0:33:07
epoch [24/30] batch [380/796] time 0.372 (0.381) data 0.000 (0.002) loss 1.3203 (1.4734) lr 1.2843e-03 eta 0:33:00
epoch [24/30] batch [400/796] time 0.396 (0.381) data 0.000 (0.002) loss 1.2920 (1.4992) lr 1.2843e-03 eta 0:32:51
epoch [24/30] batch [420/796] time 0.377 (0.381) data 0.000 (0.002) loss 0.2617 (1.5018) lr 1.2843e-03 eta 0:32:42
epoch [24/30] batch [440/796] time 0.381 (0.381) data 0.000 (0.002) loss 0.4822 (1.4847) lr 1.2843e-03 eta 0:32:35
epoch [24/30] batch [460/796] time 0.366 (0.381) data 0.000 (0.002) loss 0.2020 (1.4569) lr 1.2843e-03 eta 0:32:27
epoch [24/30] batch [480/796] time 0.371 (0.381) data 0.000 (0.002) loss 0.9365 (1.4609) lr 1.2843e-03 eta 0:32:19
epoch [24/30] batch [500/796] time 0.386 (0.381) data 0.000 (0.002) loss 5.3516 (1.4644) lr 1.2843e-03 eta 0:32:11
epoch [24/30] batch [520/796] time 0.362 (0.381) data 0.000 (0.002) loss 3.9277 (1.4644) lr 1.2843e-03 eta 0:32:02
epoch [24/30] batch [540/796] time 0.412 (0.381) data 0.000 (0.001) loss 1.2764 (1.4621) lr 1.2843e-03 eta 0:31:56
epoch [24/30] batch [560/796] time 0.386 (0.381) data 0.000 (0.001) loss 0.1486 (1.4547) lr 1.2843e-03 eta 0:31:48
epoch [24/30] batch [580/796] time 0.387 (0.381) data 0.000 (0.001) loss 0.6748 (1.4630) lr 1.2843e-03 eta 0:31:40
epoch [24/30] batch [600/796] time 0.395 (0.381) data 0.000 (0.001) loss 0.2327 (1.4708) lr 1.2843e-03 eta 0:31:32
epoch [24/30] batch [620/796] time 0.376 (0.381) data 0.000 (0.001) loss 1.1387 (1.4736) lr 1.2843e-03 eta 0:31:24
epoch [24/30] batch [640/796] time 0.407 (0.381) data 0.000 (0.001) loss 0.1472 (1.4720) lr 1.2843e-03 eta 0:31:17
epoch [24/30] batch [660/796] time 0.371 (0.381) data 0.000 (0.001) loss 1.9365 (1.4848) lr 1.2843e-03 eta 0:31:09
epoch [24/30] batch [680/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.5176 (1.4843) lr 1.2843e-03 eta 0:31:01
epoch [24/30] batch [700/796] time 0.362 (0.380) data 0.000 (0.001) loss 0.8384 (1.4848) lr 1.2843e-03 eta 0:30:53
epoch [24/30] batch [720/796] time 0.360 (0.380) data 0.000 (0.001) loss 0.6294 (1.4802) lr 1.2843e-03 eta 0:30:45
epoch [24/30] batch [740/796] time 0.361 (0.381) data 0.000 (0.001) loss 0.8643 (1.4723) lr 1.2843e-03 eta 0:30:39
epoch [24/30] batch [760/796] time 0.396 (0.381) data 0.000 (0.001) loss 0.5610 (1.4804) lr 1.2843e-03 eta 0:30:32
epoch [24/30] batch [780/796] time 0.342 (0.380) data 0.000 (0.001) loss 0.8711 (1.4783) lr 1.2843e-03 eta 0:30:20
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.64s/it] 10%|█         | 2/20 [00:06<00:51,  2.84s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.49it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.99it/s] 60%|██████    | 12/20 [00:09<00:02,  3.25it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.54it/s] 70%|███████   | 14/20 [00:09<00:01,  3.65it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.77it/s] 80%|████████  | 16/20 [00:10<00:00,  4.03it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.02it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.87it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.24it/s]100%|██████████| 20/20 [00:11<00:00,  4.62it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,612
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 80.6%

epoch [25/30] batch [20/796] time 0.368 (0.412) data 0.000 (0.030) loss 0.2188 (1.1061) lr 9.5492e-04 eta 0:32:39
epoch [25/30] batch [40/796] time 0.408 (0.392) data 0.000 (0.015) loss 2.1094 (1.5233) lr 9.5492e-04 eta 0:30:58
epoch [25/30] batch [60/796] time 0.385 (0.390) data 0.000 (0.010) loss 0.8179 (1.4243) lr 9.5492e-04 eta 0:30:37
epoch [25/30] batch [80/796] time 0.389 (0.386) data 0.000 (0.008) loss 0.8135 (1.4458) lr 9.5492e-04 eta 0:30:12
epoch [25/30] batch [100/796] time 0.354 (0.385) data 0.000 (0.006) loss 2.4102 (1.4106) lr 9.5492e-04 eta 0:30:01
epoch [25/30] batch [120/796] time 0.371 (0.384) data 0.000 (0.005) loss 0.6182 (1.3717) lr 9.5492e-04 eta 0:29:49
epoch [25/30] batch [140/796] time 0.350 (0.384) data 0.000 (0.005) loss 1.2100 (1.3769) lr 9.5492e-04 eta 0:29:39
epoch [25/30] batch [160/796] time 0.366 (0.383) data 0.000 (0.004) loss 0.8447 (1.3898) lr 9.5492e-04 eta 0:29:29
epoch [25/30] batch [180/796] time 0.389 (0.383) data 0.000 (0.004) loss 3.5176 (1.3857) lr 9.5492e-04 eta 0:29:20
epoch [25/30] batch [200/796] time 0.401 (0.384) data 0.000 (0.003) loss 0.6626 (1.3825) lr 9.5492e-04 eta 0:29:15
epoch [25/30] batch [220/796] time 0.349 (0.383) data 0.000 (0.003) loss 1.5430 (1.3782) lr 9.5492e-04 eta 0:29:05
epoch [25/30] batch [240/796] time 0.394 (0.383) data 0.000 (0.003) loss 0.9385 (1.3694) lr 9.5492e-04 eta 0:28:57
epoch [25/30] batch [260/796] time 0.352 (0.383) data 0.000 (0.003) loss 1.3428 (1.3652) lr 9.5492e-04 eta 0:28:50
epoch [25/30] batch [280/796] time 0.398 (0.383) data 0.000 (0.002) loss 0.2686 (1.3490) lr 9.5492e-04 eta 0:28:41
epoch [25/30] batch [300/796] time 0.369 (0.383) data 0.000 (0.002) loss 3.4160 (1.3574) lr 9.5492e-04 eta 0:28:32
epoch [25/30] batch [320/796] time 0.407 (0.383) data 0.000 (0.002) loss 3.6113 (1.3771) lr 9.5492e-04 eta 0:28:25
epoch [25/30] batch [340/796] time 0.366 (0.383) data 0.000 (0.002) loss 0.2166 (1.3775) lr 9.5492e-04 eta 0:28:19
epoch [25/30] batch [360/796] time 0.358 (0.383) data 0.000 (0.002) loss 1.5068 (1.3836) lr 9.5492e-04 eta 0:28:11
epoch [25/30] batch [380/796] time 0.382 (0.383) data 0.000 (0.002) loss 1.2363 (1.3815) lr 9.5492e-04 eta 0:28:04
epoch [25/30] batch [400/796] time 0.360 (0.383) data 0.000 (0.002) loss 1.3457 (1.3938) lr 9.5492e-04 eta 0:27:56
epoch [25/30] batch [420/796] time 0.428 (0.383) data 0.000 (0.002) loss 0.1559 (1.3957) lr 9.5492e-04 eta 0:27:49
epoch [25/30] batch [440/796] time 0.412 (0.383) data 0.000 (0.002) loss 0.9009 (1.4239) lr 9.5492e-04 eta 0:27:41
epoch [25/30] batch [460/796] time 0.388 (0.383) data 0.000 (0.002) loss 2.3184 (1.4386) lr 9.5492e-04 eta 0:27:34
epoch [25/30] batch [480/796] time 0.363 (0.383) data 0.000 (0.002) loss 1.3252 (1.4450) lr 9.5492e-04 eta 0:27:26
epoch [25/30] batch [500/796] time 0.386 (0.383) data 0.000 (0.001) loss 1.0732 (1.4410) lr 9.5492e-04 eta 0:27:17
epoch [25/30] batch [520/796] time 0.364 (0.383) data 0.000 (0.001) loss 0.4578 (1.4439) lr 9.5492e-04 eta 0:27:09
epoch [25/30] batch [540/796] time 0.397 (0.383) data 0.000 (0.001) loss 0.9082 (1.4422) lr 9.5492e-04 eta 0:27:02
epoch [25/30] batch [560/796] time 0.360 (0.383) data 0.000 (0.001) loss 0.6753 (1.4367) lr 9.5492e-04 eta 0:26:53
epoch [25/30] batch [580/796] time 0.405 (0.383) data 0.000 (0.001) loss 2.5664 (1.4309) lr 9.5492e-04 eta 0:26:45
epoch [25/30] batch [600/796] time 0.386 (0.382) data 0.000 (0.001) loss 2.6230 (1.4318) lr 9.5492e-04 eta 0:26:37
epoch [25/30] batch [620/796] time 0.375 (0.382) data 0.000 (0.001) loss 2.1914 (1.4403) lr 9.5492e-04 eta 0:26:28
epoch [25/30] batch [640/796] time 0.366 (0.382) data 0.000 (0.001) loss 1.3281 (1.4500) lr 9.5492e-04 eta 0:26:21
epoch [25/30] batch [660/796] time 0.372 (0.382) data 0.000 (0.001) loss 0.8564 (1.4513) lr 9.5492e-04 eta 0:26:13
epoch [25/30] batch [680/796] time 0.388 (0.382) data 0.000 (0.001) loss 0.6777 (1.4573) lr 9.5492e-04 eta 0:26:06
epoch [25/30] batch [700/796] time 0.398 (0.383) data 0.000 (0.001) loss 0.4590 (1.4528) lr 9.5492e-04 eta 0:25:59
epoch [25/30] batch [720/796] time 0.381 (0.382) data 0.000 (0.001) loss 1.7715 (1.4465) lr 9.5492e-04 eta 0:25:50
epoch [25/30] batch [740/796] time 0.368 (0.382) data 0.000 (0.001) loss 0.1260 (1.4341) lr 9.5492e-04 eta 0:25:43
epoch [25/30] batch [760/796] time 0.396 (0.382) data 0.000 (0.001) loss 0.4771 (1.4299) lr 9.5492e-04 eta 0:25:35
epoch [25/30] batch [780/796] time 0.341 (0.382) data 0.000 (0.001) loss 0.9805 (1.4389) lr 9.5492e-04 eta 0:25:24
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.62s/it] 10%|█         | 2/20 [00:06<00:50,  2.81s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.66s/it] 20%|██        | 4/20 [00:07<00:17,  1.12s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:08,  1.56it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.98it/s] 60%|██████    | 12/20 [00:09<00:02,  3.19it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.48it/s] 70%|███████   | 14/20 [00:09<00:01,  3.62it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.88it/s] 80%|████████  | 16/20 [00:10<00:00,  4.08it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.05it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.64it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.05it/s]100%|██████████| 20/20 [00:11<00:00,  4.46it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,618
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 80.9%

epoch [26/30] batch [20/796] time 0.387 (0.418) data 0.000 (0.032) loss 1.2646 (1.4242) lr 6.6987e-04 eta 0:27:35
epoch [26/30] batch [40/796] time 0.351 (0.399) data 0.000 (0.016) loss 0.4985 (1.4540) lr 6.6987e-04 eta 0:26:10
epoch [26/30] batch [60/796] time 0.377 (0.391) data 0.000 (0.011) loss 3.3418 (1.5017) lr 6.6987e-04 eta 0:25:30
epoch [26/30] batch [80/796] time 0.358 (0.386) data 0.000 (0.008) loss 0.0684 (1.4178) lr 6.6987e-04 eta 0:25:07
epoch [26/30] batch [100/796] time 0.376 (0.385) data 0.000 (0.007) loss 1.6025 (1.4269) lr 6.6987e-04 eta 0:24:53
epoch [26/30] batch [120/796] time 0.396 (0.385) data 0.000 (0.005) loss 3.7363 (1.4620) lr 6.6987e-04 eta 0:24:45
epoch [26/30] batch [140/796] time 0.354 (0.384) data 0.000 (0.005) loss 2.3203 (1.5479) lr 6.6987e-04 eta 0:24:35
epoch [26/30] batch [160/796] time 0.378 (0.383) data 0.000 (0.004) loss 1.8857 (1.5109) lr 6.6987e-04 eta 0:24:23
epoch [26/30] batch [180/796] time 0.392 (0.383) data 0.000 (0.004) loss 1.1455 (1.4874) lr 6.6987e-04 eta 0:24:14
epoch [26/30] batch [200/796] time 0.353 (0.382) data 0.000 (0.003) loss 0.8911 (1.4775) lr 6.6987e-04 eta 0:24:03
epoch [26/30] batch [220/796] time 0.370 (0.381) data 0.000 (0.003) loss 1.6484 (1.5072) lr 6.6987e-04 eta 0:23:53
epoch [26/30] batch [240/796] time 0.371 (0.382) data 0.001 (0.003) loss 0.7017 (1.4779) lr 6.6987e-04 eta 0:23:48
epoch [26/30] batch [260/796] time 0.409 (0.382) data 0.000 (0.003) loss 0.4763 (1.4796) lr 6.6987e-04 eta 0:23:42
epoch [26/30] batch [280/796] time 0.400 (0.382) data 0.000 (0.002) loss 1.6416 (1.4705) lr 6.6987e-04 eta 0:23:33
epoch [26/30] batch [300/796] time 0.395 (0.382) data 0.000 (0.002) loss 1.2725 (1.4656) lr 6.6987e-04 eta 0:23:24
epoch [26/30] batch [320/796] time 0.372 (0.381) data 0.000 (0.002) loss 0.2942 (1.4582) lr 6.6987e-04 eta 0:23:16
epoch [26/30] batch [340/796] time 0.388 (0.381) data 0.000 (0.002) loss 0.4749 (1.4305) lr 6.6987e-04 eta 0:23:08
epoch [26/30] batch [360/796] time 0.358 (0.382) data 0.000 (0.002) loss 1.3428 (1.4248) lr 6.6987e-04 eta 0:23:01
epoch [26/30] batch [380/796] time 0.393 (0.382) data 0.000 (0.002) loss 1.0166 (1.4280) lr 6.6987e-04 eta 0:22:55
epoch [26/30] batch [400/796] time 0.358 (0.382) data 0.000 (0.002) loss 1.9619 (1.4339) lr 6.6987e-04 eta 0:22:46
epoch [26/30] batch [420/796] time 0.360 (0.382) data 0.000 (0.002) loss 1.8262 (1.4328) lr 6.6987e-04 eta 0:22:38
epoch [26/30] batch [440/796] time 0.407 (0.381) data 0.000 (0.002) loss 2.9082 (1.4297) lr 6.6987e-04 eta 0:22:30
epoch [26/30] batch [460/796] time 0.362 (0.381) data 0.000 (0.002) loss 1.7842 (1.4335) lr 6.6987e-04 eta 0:22:22
epoch [26/30] batch [480/796] time 0.408 (0.381) data 0.000 (0.002) loss 0.7227 (1.4331) lr 6.6987e-04 eta 0:22:13
epoch [26/30] batch [500/796] time 0.365 (0.381) data 0.000 (0.001) loss 0.3503 (1.4138) lr 6.6987e-04 eta 0:22:06
epoch [26/30] batch [520/796] time 0.361 (0.381) data 0.000 (0.001) loss 1.5713 (1.4158) lr 6.6987e-04 eta 0:21:58
epoch [26/30] batch [540/796] time 0.379 (0.381) data 0.000 (0.001) loss 0.3357 (1.4212) lr 6.6987e-04 eta 0:21:50
epoch [26/30] batch [560/796] time 0.376 (0.381) data 0.000 (0.001) loss 3.8438 (1.4187) lr 6.6987e-04 eta 0:21:42
epoch [26/30] batch [580/796] time 0.351 (0.381) data 0.000 (0.001) loss 1.3799 (1.4032) lr 6.6987e-04 eta 0:21:34
epoch [26/30] batch [600/796] time 0.390 (0.381) data 0.000 (0.001) loss 0.9282 (1.4050) lr 6.6987e-04 eta 0:21:26
epoch [26/30] batch [620/796] time 0.406 (0.381) data 0.000 (0.001) loss 0.3523 (1.4018) lr 6.6987e-04 eta 0:21:19
epoch [26/30] batch [640/796] time 0.403 (0.381) data 0.000 (0.001) loss 1.0273 (1.4043) lr 6.6987e-04 eta 0:21:11
epoch [26/30] batch [660/796] time 0.346 (0.381) data 0.000 (0.001) loss 3.1055 (1.4152) lr 6.6987e-04 eta 0:21:03
epoch [26/30] batch [680/796] time 0.411 (0.381) data 0.000 (0.001) loss 0.3250 (1.4138) lr 6.6987e-04 eta 0:20:56
epoch [26/30] batch [700/796] time 0.371 (0.380) data 0.000 (0.001) loss 0.9482 (1.4129) lr 6.6987e-04 eta 0:20:47
epoch [26/30] batch [720/796] time 0.364 (0.380) data 0.000 (0.001) loss 0.3167 (1.4128) lr 6.6987e-04 eta 0:20:40
epoch [26/30] batch [740/796] time 0.360 (0.380) data 0.000 (0.001) loss 0.5044 (1.4163) lr 6.6987e-04 eta 0:20:31
epoch [26/30] batch [760/796] time 0.356 (0.380) data 0.000 (0.001) loss 0.7285 (1.4142) lr 6.6987e-04 eta 0:20:24
epoch [26/30] batch [780/796] time 0.338 (0.379) data 0.000 (0.001) loss 0.1198 (1.4083) lr 6.6987e-04 eta 0:20:13
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.54s/it] 10%|█         | 2/20 [00:06<00:50,  2.83s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.67s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.96it/s] 60%|██████    | 12/20 [00:09<00:02,  3.29it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.61it/s] 70%|███████   | 14/20 [00:09<00:01,  3.70it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.81it/s] 80%|████████  | 16/20 [00:10<00:01,  3.90it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.92it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.80it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.18it/s]100%|██████████| 20/20 [00:11<00:00,  4.57it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,616
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 80.8%

epoch [27/30] batch [20/796] time 0.353 (0.428) data 0.000 (0.038) loss 1.0488 (1.2653) lr 4.3227e-04 eta 0:22:33
epoch [27/30] batch [40/796] time 0.372 (0.402) data 0.000 (0.019) loss 1.5117 (1.1305) lr 4.3227e-04 eta 0:21:02
epoch [27/30] batch [60/796] time 0.361 (0.395) data 0.000 (0.013) loss 0.1289 (1.1481) lr 4.3227e-04 eta 0:20:33
epoch [27/30] batch [80/796] time 0.363 (0.391) data 0.000 (0.010) loss 1.1270 (1.1636) lr 4.3227e-04 eta 0:20:12
epoch [27/30] batch [100/796] time 0.347 (0.387) data 0.000 (0.008) loss 0.6133 (1.1896) lr 4.3227e-04 eta 0:19:53
epoch [27/30] batch [120/796] time 0.403 (0.385) data 0.000 (0.007) loss 0.8560 (1.2148) lr 4.3227e-04 eta 0:19:41
epoch [27/30] batch [140/796] time 0.391 (0.384) data 0.000 (0.006) loss 0.1282 (1.2507) lr 4.3227e-04 eta 0:19:30
epoch [27/30] batch [160/796] time 0.360 (0.384) data 0.000 (0.005) loss 1.8945 (1.2579) lr 4.3227e-04 eta 0:19:20
epoch [27/30] batch [180/796] time 0.381 (0.383) data 0.000 (0.004) loss 2.5918 (1.2393) lr 4.3227e-04 eta 0:19:10
epoch [27/30] batch [200/796] time 0.354 (0.382) data 0.000 (0.004) loss 0.4504 (1.2400) lr 4.3227e-04 eta 0:19:00
epoch [27/30] batch [220/796] time 0.350 (0.382) data 0.000 (0.004) loss 1.7021 (1.2300) lr 4.3227e-04 eta 0:18:52
epoch [27/30] batch [240/796] time 0.356 (0.382) data 0.000 (0.003) loss 1.3311 (1.2864) lr 4.3227e-04 eta 0:18:43
epoch [27/30] batch [260/796] time 0.388 (0.381) data 0.000 (0.003) loss 1.5586 (1.3111) lr 4.3227e-04 eta 0:18:34
epoch [27/30] batch [280/796] time 0.389 (0.381) data 0.000 (0.003) loss 0.6855 (1.3253) lr 4.3227e-04 eta 0:18:27
epoch [27/30] batch [300/796] time 0.380 (0.381) data 0.000 (0.003) loss 0.7593 (1.3130) lr 4.3227e-04 eta 0:18:18
epoch [27/30] batch [320/796] time 0.412 (0.381) data 0.000 (0.003) loss 1.1396 (1.3103) lr 4.3227e-04 eta 0:18:11
epoch [27/30] batch [340/796] time 0.357 (0.381) data 0.000 (0.002) loss 1.1416 (1.3324) lr 4.3227e-04 eta 0:18:04
epoch [27/30] batch [360/796] time 0.370 (0.381) data 0.000 (0.002) loss 0.5537 (1.3327) lr 4.3227e-04 eta 0:17:56
epoch [27/30] batch [380/796] time 0.362 (0.381) data 0.000 (0.002) loss 0.0807 (1.3142) lr 4.3227e-04 eta 0:17:48
epoch [27/30] batch [400/796] time 0.350 (0.381) data 0.000 (0.002) loss 1.6484 (1.3419) lr 4.3227e-04 eta 0:17:40
epoch [27/30] batch [420/796] time 0.346 (0.381) data 0.000 (0.002) loss 1.5117 (1.3624) lr 4.3227e-04 eta 0:17:32
epoch [27/30] batch [440/796] time 0.379 (0.381) data 0.000 (0.002) loss 2.5684 (1.3628) lr 4.3227e-04 eta 0:17:24
epoch [27/30] batch [460/796] time 0.372 (0.381) data 0.000 (0.002) loss 0.5093 (1.3694) lr 4.3227e-04 eta 0:17:17
epoch [27/30] batch [480/796] time 0.345 (0.381) data 0.000 (0.002) loss 0.5513 (1.3694) lr 4.3227e-04 eta 0:17:09
epoch [27/30] batch [500/796] time 0.363 (0.380) data 0.000 (0.002) loss 0.9419 (1.3635) lr 4.3227e-04 eta 0:17:01
epoch [27/30] batch [520/796] time 0.366 (0.381) data 0.000 (0.002) loss 0.5640 (1.3515) lr 4.3227e-04 eta 0:16:54
epoch [27/30] batch [540/796] time 0.355 (0.381) data 0.000 (0.002) loss 1.3535 (1.3571) lr 4.3227e-04 eta 0:16:46
epoch [27/30] batch [560/796] time 0.375 (0.381) data 0.000 (0.002) loss 1.1865 (1.3638) lr 4.3227e-04 eta 0:16:38
epoch [27/30] batch [580/796] time 0.460 (0.381) data 0.000 (0.002) loss 0.1236 (1.3753) lr 4.3227e-04 eta 0:16:31
epoch [27/30] batch [600/796] time 0.396 (0.381) data 0.000 (0.002) loss 0.2313 (1.3655) lr 4.3227e-04 eta 0:16:24
epoch [27/30] batch [620/796] time 0.384 (0.381) data 0.000 (0.001) loss 0.9038 (1.3751) lr 4.3227e-04 eta 0:16:16
epoch [27/30] batch [640/796] time 0.388 (0.381) data 0.000 (0.001) loss 0.6284 (1.3687) lr 4.3227e-04 eta 0:16:08
epoch [27/30] batch [660/796] time 0.385 (0.381) data 0.000 (0.001) loss 3.3223 (1.3668) lr 4.3227e-04 eta 0:16:00
epoch [27/30] batch [680/796] time 0.389 (0.380) data 0.000 (0.001) loss 1.2852 (1.3677) lr 4.3227e-04 eta 0:15:52
epoch [27/30] batch [700/796] time 0.398 (0.380) data 0.000 (0.001) loss 0.8047 (1.3580) lr 4.3227e-04 eta 0:15:45
epoch [27/30] batch [720/796] time 0.408 (0.380) data 0.000 (0.001) loss 0.4890 (1.3675) lr 4.3227e-04 eta 0:15:37
epoch [27/30] batch [740/796] time 0.364 (0.381) data 0.000 (0.001) loss 2.9648 (1.3622) lr 4.3227e-04 eta 0:15:30
epoch [27/30] batch [760/796] time 0.368 (0.381) data 0.000 (0.001) loss 2.4453 (1.3657) lr 4.3227e-04 eta 0:15:22
epoch [27/30] batch [780/796] time 0.339 (0.380) data 0.000 (0.001) loss 3.2441 (1.3772) lr 4.3227e-04 eta 0:15:13
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.61s/it] 10%|█         | 2/20 [00:06<00:49,  2.75s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.63s/it] 20%|██        | 4/20 [00:06<00:17,  1.10s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.23it/s] 30%|███       | 6/20 [00:07<00:08,  1.57it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.68it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.89it/s] 60%|██████    | 12/20 [00:09<00:02,  3.09it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.39it/s] 70%|███████   | 14/20 [00:09<00:01,  3.49it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.83it/s] 80%|████████  | 16/20 [00:10<00:00,  4.09it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.99it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.95it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.32it/s]100%|██████████| 20/20 [00:11<00:00,  4.69it/s]100%|██████████| 20/20 [00:11<00:00,  1.79it/s]=> result
* total: 1,990
* correct: 1,624
* accuracy: 81.6%
* error: 18.4%
* macro_f1: 81.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [28/30] batch [20/796] time 0.387 (0.426) data 0.000 (0.041) loss 5.6641 (2.1173) lr 2.4472e-04 eta 0:16:49
epoch [28/30] batch [40/796] time 0.410 (0.400) data 0.000 (0.021) loss 1.7266 (2.0060) lr 2.4472e-04 eta 0:15:39
epoch [28/30] batch [60/796] time 0.355 (0.397) data 0.000 (0.014) loss 0.6719 (1.8512) lr 2.4472e-04 eta 0:15:23
epoch [28/30] batch [80/796] time 0.399 (0.394) data 0.000 (0.010) loss 2.5215 (1.7727) lr 2.4472e-04 eta 0:15:08
epoch [28/30] batch [100/796] time 0.357 (0.390) data 0.000 (0.008) loss 1.2793 (1.7176) lr 2.4472e-04 eta 0:14:51
epoch [28/30] batch [120/796] time 0.391 (0.387) data 0.000 (0.007) loss 0.5928 (1.6158) lr 2.4472e-04 eta 0:14:37
epoch [28/30] batch [140/796] time 0.381 (0.387) data 0.000 (0.006) loss 2.9238 (1.6352) lr 2.4472e-04 eta 0:14:29
epoch [28/30] batch [160/796] time 0.386 (0.385) data 0.000 (0.005) loss 0.9468 (1.5699) lr 2.4472e-04 eta 0:14:18
epoch [28/30] batch [180/796] time 0.374 (0.385) data 0.000 (0.005) loss 0.8521 (1.5524) lr 2.4472e-04 eta 0:14:09
epoch [28/30] batch [200/796] time 0.408 (0.384) data 0.000 (0.004) loss 0.7407 (1.5402) lr 2.4472e-04 eta 0:14:00
epoch [28/30] batch [220/796] time 0.378 (0.384) data 0.000 (0.004) loss 2.5449 (1.4982) lr 2.4472e-04 eta 0:13:52
epoch [28/30] batch [240/796] time 0.382 (0.384) data 0.000 (0.004) loss 1.1973 (1.5063) lr 2.4472e-04 eta 0:13:44
epoch [28/30] batch [260/796] time 0.408 (0.384) data 0.000 (0.003) loss 1.2656 (1.4829) lr 2.4472e-04 eta 0:13:36
epoch [28/30] batch [280/796] time 0.395 (0.383) data 0.000 (0.003) loss 1.2988 (1.5140) lr 2.4472e-04 eta 0:13:27
epoch [28/30] batch [300/796] time 0.362 (0.383) data 0.000 (0.003) loss 0.4109 (1.5066) lr 2.4472e-04 eta 0:13:19
epoch [28/30] batch [320/796] time 0.383 (0.383) data 0.000 (0.003) loss 0.7466 (1.5125) lr 2.4472e-04 eta 0:13:11
epoch [28/30] batch [340/796] time 0.348 (0.383) data 0.000 (0.003) loss 1.7393 (1.5286) lr 2.4472e-04 eta 0:13:03
epoch [28/30] batch [360/796] time 0.400 (0.383) data 0.000 (0.003) loss 1.6250 (1.5259) lr 2.4472e-04 eta 0:12:56
epoch [28/30] batch [380/796] time 0.384 (0.383) data 0.000 (0.002) loss 1.2715 (1.5047) lr 2.4472e-04 eta 0:12:48
epoch [28/30] batch [400/796] time 0.367 (0.383) data 0.000 (0.002) loss 0.0770 (1.4879) lr 2.4472e-04 eta 0:12:40
epoch [28/30] batch [420/796] time 0.358 (0.382) data 0.000 (0.002) loss 1.7080 (1.4735) lr 2.4472e-04 eta 0:12:32
epoch [28/30] batch [440/796] time 0.391 (0.382) data 0.000 (0.002) loss 0.3232 (1.4599) lr 2.4472e-04 eta 0:12:24
epoch [28/30] batch [460/796] time 0.396 (0.382) data 0.000 (0.002) loss 4.5742 (1.4655) lr 2.4472e-04 eta 0:12:16
epoch [28/30] batch [480/796] time 0.393 (0.382) data 0.000 (0.002) loss 2.2559 (1.4606) lr 2.4472e-04 eta 0:12:09
epoch [28/30] batch [500/796] time 0.384 (0.382) data 0.000 (0.002) loss 0.2903 (1.4432) lr 2.4472e-04 eta 0:12:01
epoch [28/30] batch [520/796] time 0.363 (0.382) data 0.000 (0.002) loss 0.7036 (1.4529) lr 2.4472e-04 eta 0:11:53
epoch [28/30] batch [540/796] time 0.361 (0.382) data 0.000 (0.002) loss 0.6958 (1.4493) lr 2.4472e-04 eta 0:11:45
epoch [28/30] batch [560/796] time 0.353 (0.382) data 0.000 (0.002) loss 3.9648 (1.4616) lr 2.4472e-04 eta 0:11:38
epoch [28/30] batch [580/796] time 0.377 (0.382) data 0.000 (0.002) loss 0.9751 (1.4543) lr 2.4472e-04 eta 0:11:30
epoch [28/30] batch [600/796] time 0.385 (0.382) data 0.000 (0.002) loss 3.0684 (1.4455) lr 2.4472e-04 eta 0:11:22
epoch [28/30] batch [620/796] time 0.355 (0.382) data 0.000 (0.002) loss 1.3174 (1.4435) lr 2.4472e-04 eta 0:11:15
epoch [28/30] batch [640/796] time 0.401 (0.382) data 0.000 (0.002) loss 0.9580 (1.4318) lr 2.4472e-04 eta 0:11:07
epoch [28/30] batch [660/796] time 0.369 (0.382) data 0.000 (0.001) loss 0.1964 (1.4270) lr 2.4472e-04 eta 0:10:59
epoch [28/30] batch [680/796] time 0.371 (0.381) data 0.000 (0.001) loss 0.6216 (1.4218) lr 2.4472e-04 eta 0:10:51
epoch [28/30] batch [700/796] time 0.350 (0.381) data 0.000 (0.001) loss 2.0234 (1.4117) lr 2.4472e-04 eta 0:10:43
epoch [28/30] batch [720/796] time 0.395 (0.381) data 0.000 (0.001) loss 0.8374 (1.4096) lr 2.4472e-04 eta 0:10:36
epoch [28/30] batch [740/796] time 0.376 (0.381) data 0.000 (0.001) loss 0.3992 (1.4091) lr 2.4472e-04 eta 0:10:28
epoch [28/30] batch [760/796] time 0.352 (0.381) data 0.000 (0.001) loss 2.3457 (1.3960) lr 2.4472e-04 eta 0:10:20
epoch [28/30] batch [780/796] time 0.341 (0.380) data 0.000 (0.001) loss 0.3528 (1.3828) lr 2.4472e-04 eta 0:10:11
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:42,  5.38s/it] 10%|█         | 2/20 [00:06<00:51,  2.87s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.52it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.47it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.93it/s] 60%|██████    | 12/20 [00:09<00:02,  3.16it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.43it/s] 70%|███████   | 14/20 [00:09<00:01,  3.52it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.73it/s] 80%|████████  | 16/20 [00:10<00:01,  3.80it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.86it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.24it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.56it/s]100%|██████████| 20/20 [00:11<00:00,  4.88it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,626
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 81.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [29/30] batch [20/796] time 0.403 (0.423) data 0.000 (0.032) loss 1.9512 (1.1726) lr 1.0926e-04 eta 0:11:04
epoch [29/30] batch [40/796] time 0.395 (0.398) data 0.000 (0.016) loss 0.3708 (1.1991) lr 1.0926e-04 eta 0:10:17
epoch [29/30] batch [60/796] time 0.351 (0.393) data 0.000 (0.011) loss 1.1367 (1.0924) lr 1.0926e-04 eta 0:10:02
epoch [29/30] batch [80/796] time 0.370 (0.388) data 0.000 (0.008) loss 3.6270 (1.1768) lr 1.0926e-04 eta 0:09:45
epoch [29/30] batch [100/796] time 0.360 (0.385) data 0.000 (0.007) loss 2.7617 (1.2360) lr 1.0926e-04 eta 0:09:34
epoch [29/30] batch [120/796] time 0.367 (0.385) data 0.000 (0.006) loss 0.2974 (1.2819) lr 1.0926e-04 eta 0:09:27
epoch [29/30] batch [140/796] time 0.412 (0.384) data 0.000 (0.005) loss 3.1387 (1.2893) lr 1.0926e-04 eta 0:09:18
epoch [29/30] batch [160/796] time 0.394 (0.384) data 0.000 (0.004) loss 4.1641 (1.3321) lr 1.0926e-04 eta 0:09:09
epoch [29/30] batch [180/796] time 0.356 (0.382) data 0.000 (0.004) loss 1.1924 (1.2821) lr 1.0926e-04 eta 0:08:59
epoch [29/30] batch [200/796] time 0.406 (0.383) data 0.000 (0.003) loss 0.9487 (1.2796) lr 1.0926e-04 eta 0:08:53
epoch [29/30] batch [220/796] time 0.388 (0.383) data 0.000 (0.003) loss 2.0430 (1.2935) lr 1.0926e-04 eta 0:08:45
epoch [29/30] batch [240/796] time 0.403 (0.383) data 0.000 (0.003) loss 2.9336 (1.2928) lr 1.0926e-04 eta 0:08:38
epoch [29/30] batch [260/796] time 0.408 (0.383) data 0.000 (0.003) loss 1.7627 (1.2658) lr 1.0926e-04 eta 0:08:30
epoch [29/30] batch [280/796] time 0.391 (0.382) data 0.000 (0.003) loss 2.4629 (1.2673) lr 1.0926e-04 eta 0:08:21
epoch [29/30] batch [300/796] time 0.353 (0.382) data 0.000 (0.002) loss 0.7080 (1.3032) lr 1.0926e-04 eta 0:08:13
epoch [29/30] batch [320/796] time 0.398 (0.382) data 0.000 (0.002) loss 2.2930 (1.3157) lr 1.0926e-04 eta 0:08:05
epoch [29/30] batch [340/796] time 0.393 (0.382) data 0.000 (0.002) loss 4.7656 (1.3316) lr 1.0926e-04 eta 0:07:57
epoch [29/30] batch [360/796] time 0.383 (0.382) data 0.000 (0.002) loss 2.8398 (1.3152) lr 1.0926e-04 eta 0:07:50
epoch [29/30] batch [380/796] time 0.385 (0.382) data 0.000 (0.002) loss 0.7651 (1.3259) lr 1.0926e-04 eta 0:07:43
epoch [29/30] batch [400/796] time 0.378 (0.382) data 0.000 (0.002) loss 0.9414 (1.3110) lr 1.0926e-04 eta 0:07:35
epoch [29/30] batch [420/796] time 0.395 (0.382) data 0.000 (0.002) loss 0.0459 (1.3189) lr 1.0926e-04 eta 0:07:27
epoch [29/30] batch [440/796] time 0.389 (0.382) data 0.000 (0.002) loss 1.7861 (1.3407) lr 1.0926e-04 eta 0:07:20
epoch [29/30] batch [460/796] time 0.394 (0.382) data 0.000 (0.002) loss 0.1654 (1.3391) lr 1.0926e-04 eta 0:07:12
epoch [29/30] batch [480/796] time 0.373 (0.382) data 0.000 (0.002) loss 0.0532 (1.3459) lr 1.0926e-04 eta 0:07:04
epoch [29/30] batch [500/796] time 0.381 (0.382) data 0.000 (0.002) loss 0.1339 (1.3420) lr 1.0926e-04 eta 0:06:56
epoch [29/30] batch [520/796] time 0.356 (0.382) data 0.000 (0.001) loss 1.1143 (1.3416) lr 1.0926e-04 eta 0:06:48
epoch [29/30] batch [540/796] time 0.358 (0.382) data 0.000 (0.001) loss 3.9941 (1.3492) lr 1.0926e-04 eta 0:06:41
epoch [29/30] batch [560/796] time 0.398 (0.381) data 0.000 (0.001) loss 0.7393 (1.3516) lr 1.0926e-04 eta 0:06:33
epoch [29/30] batch [580/796] time 0.412 (0.381) data 0.000 (0.001) loss 0.2123 (1.3519) lr 1.0926e-04 eta 0:06:26
epoch [29/30] batch [600/796] time 0.385 (0.381) data 0.000 (0.001) loss 1.3330 (1.3557) lr 1.0926e-04 eta 0:06:18
epoch [29/30] batch [620/796] time 0.364 (0.381) data 0.000 (0.001) loss 1.7275 (1.3591) lr 1.0926e-04 eta 0:06:10
epoch [29/30] batch [640/796] time 0.475 (0.381) data 0.000 (0.001) loss 0.1923 (1.3559) lr 1.0926e-04 eta 0:06:02
epoch [29/30] batch [660/796] time 0.358 (0.381) data 0.000 (0.001) loss 0.1412 (1.3563) lr 1.0926e-04 eta 0:05:55
epoch [29/30] batch [680/796] time 0.351 (0.381) data 0.000 (0.001) loss 2.5020 (1.3621) lr 1.0926e-04 eta 0:05:47
epoch [29/30] batch [700/796] time 0.390 (0.381) data 0.000 (0.001) loss 0.3096 (1.3553) lr 1.0926e-04 eta 0:05:40
epoch [29/30] batch [720/796] time 0.400 (0.381) data 0.000 (0.001) loss 0.3455 (1.3562) lr 1.0926e-04 eta 0:05:32
epoch [29/30] batch [740/796] time 0.390 (0.382) data 0.000 (0.001) loss 3.4590 (1.3633) lr 1.0926e-04 eta 0:05:25
epoch [29/30] batch [760/796] time 0.372 (0.382) data 0.000 (0.001) loss 0.6758 (1.3573) lr 1.0926e-04 eta 0:05:17
epoch [29/30] batch [780/796] time 0.341 (0.381) data 0.000 (0.001) loss 0.3677 (1.3532) lr 1.0926e-04 eta 0:05:09
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.58s/it] 10%|█         | 2/20 [00:06<00:49,  2.75s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.63s/it] 20%|██        | 4/20 [00:06<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.23it/s] 30%|███       | 6/20 [00:07<00:08,  1.57it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.51it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.90it/s] 60%|██████    | 12/20 [00:09<00:02,  3.25it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.53it/s] 70%|███████   | 14/20 [00:09<00:01,  3.67it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.89it/s] 80%|████████  | 16/20 [00:10<00:00,  4.26it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.57it/s] 90%|█████████ | 18/20 [00:11<00:00,  2.41it/s] 95%|█████████▌| 19/20 [00:11<00:00,  2.89it/s]100%|██████████| 20/20 [00:11<00:00,  3.41it/s]100%|██████████| 20/20 [00:11<00:00,  1.72it/s]=> result
* total: 1,990
* correct: 1,627
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 81.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [30/30] batch [20/796] time 0.357 (0.425) data 0.000 (0.036) loss 0.2122 (1.3954) lr 2.7391e-05 eta 0:05:30
epoch [30/30] batch [40/796] time 0.403 (0.400) data 0.000 (0.018) loss 0.9229 (1.2057) lr 2.7391e-05 eta 0:05:02
epoch [30/30] batch [60/796] time 0.385 (0.393) data 0.000 (0.012) loss 0.9424 (1.0953) lr 2.7391e-05 eta 0:04:49
epoch [30/30] batch [80/796] time 0.381 (0.391) data 0.000 (0.009) loss 0.6035 (1.2631) lr 2.7391e-05 eta 0:04:39
epoch [30/30] batch [100/796] time 0.377 (0.391) data 0.000 (0.007) loss 0.4304 (1.2991) lr 2.7391e-05 eta 0:04:31
epoch [30/30] batch [120/796] time 0.361 (0.387) data 0.000 (0.006) loss 1.6396 (1.3335) lr 2.7391e-05 eta 0:04:21
epoch [30/30] batch [140/796] time 0.353 (0.385) data 0.000 (0.005) loss 0.6846 (1.3204) lr 2.7391e-05 eta 0:04:12
epoch [30/30] batch [160/796] time 0.390 (0.385) data 0.000 (0.005) loss 2.6836 (1.3359) lr 2.7391e-05 eta 0:04:04
epoch [30/30] batch [180/796] time 0.371 (0.384) data 0.000 (0.004) loss 2.4102 (1.3511) lr 2.7391e-05 eta 0:03:56
epoch [30/30] batch [200/796] time 0.376 (0.383) data 0.000 (0.004) loss 2.5117 (1.3091) lr 2.7391e-05 eta 0:03:48
epoch [30/30] batch [220/796] time 0.397 (0.383) data 0.000 (0.003) loss 0.6240 (1.3192) lr 2.7391e-05 eta 0:03:40
epoch [30/30] batch [240/796] time 0.365 (0.382) data 0.000 (0.003) loss 0.5059 (1.3489) lr 2.7391e-05 eta 0:03:32
epoch [30/30] batch [260/796] time 0.349 (0.382) data 0.000 (0.003) loss 4.2617 (1.3506) lr 2.7391e-05 eta 0:03:24
epoch [30/30] batch [280/796] time 0.374 (0.381) data 0.000 (0.003) loss 0.7334 (1.3448) lr 2.7391e-05 eta 0:03:16
epoch [30/30] batch [300/796] time 0.364 (0.381) data 0.000 (0.003) loss 0.2964 (1.3278) lr 2.7391e-05 eta 0:03:09
epoch [30/30] batch [320/796] time 0.385 (0.382) data 0.000 (0.002) loss 0.3538 (1.3281) lr 2.7391e-05 eta 0:03:01
epoch [30/30] batch [340/796] time 0.352 (0.382) data 0.000 (0.002) loss 0.1030 (1.3433) lr 2.7391e-05 eta 0:02:54
epoch [30/30] batch [360/796] time 0.365 (0.381) data 0.000 (0.002) loss 1.8369 (1.3265) lr 2.7391e-05 eta 0:02:46
epoch [30/30] batch [380/796] time 0.364 (0.381) data 0.000 (0.002) loss 2.9668 (1.3267) lr 2.7391e-05 eta 0:02:38
epoch [30/30] batch [400/796] time 0.367 (0.381) data 0.000 (0.002) loss 1.2363 (1.3270) lr 2.7391e-05 eta 0:02:30
epoch [30/30] batch [420/796] time 0.410 (0.381) data 0.000 (0.002) loss 0.5815 (1.3245) lr 2.7391e-05 eta 0:02:23
epoch [30/30] batch [440/796] time 0.384 (0.382) data 0.000 (0.002) loss 1.4082 (1.3207) lr 2.7391e-05 eta 0:02:15
epoch [30/30] batch [460/796] time 0.406 (0.382) data 0.000 (0.002) loss 0.4485 (1.3198) lr 2.7391e-05 eta 0:02:08
epoch [30/30] batch [480/796] time 0.398 (0.382) data 0.000 (0.002) loss 2.2559 (1.3093) lr 2.7391e-05 eta 0:02:00
epoch [30/30] batch [500/796] time 0.403 (0.382) data 0.000 (0.002) loss 0.1037 (1.2999) lr 2.7391e-05 eta 0:01:52
epoch [30/30] batch [520/796] time 0.370 (0.382) data 0.000 (0.002) loss 3.9980 (1.3129) lr 2.7391e-05 eta 0:01:45
epoch [30/30] batch [540/796] time 0.369 (0.381) data 0.000 (0.002) loss 0.3936 (1.3030) lr 2.7391e-05 eta 0:01:37
epoch [30/30] batch [560/796] time 0.432 (0.381) data 0.000 (0.002) loss 1.2627 (1.3199) lr 2.7391e-05 eta 0:01:29
epoch [30/30] batch [580/796] time 0.359 (0.381) data 0.000 (0.001) loss 2.3418 (1.3213) lr 2.7391e-05 eta 0:01:22
epoch [30/30] batch [600/796] time 0.353 (0.381) data 0.000 (0.001) loss 3.6074 (1.3229) lr 2.7391e-05 eta 0:01:14
epoch [30/30] batch [620/796] time 0.401 (0.381) data 0.000 (0.001) loss 1.0469 (1.3224) lr 2.7391e-05 eta 0:01:07
epoch [30/30] batch [640/796] time 0.402 (0.381) data 0.000 (0.001) loss 0.3816 (1.3175) lr 2.7391e-05 eta 0:00:59
epoch [30/30] batch [660/796] time 0.403 (0.381) data 0.000 (0.001) loss 2.6406 (1.3184) lr 2.7391e-05 eta 0:00:51
epoch [30/30] batch [680/796] time 0.351 (0.381) data 0.000 (0.001) loss 1.4141 (1.3168) lr 2.7391e-05 eta 0:00:44
epoch [30/30] batch [700/796] time 0.374 (0.381) data 0.000 (0.001) loss 2.4707 (1.3127) lr 2.7391e-05 eta 0:00:36
epoch [30/30] batch [720/796] time 0.397 (0.382) data 0.000 (0.001) loss 5.6484 (1.3346) lr 2.7391e-05 eta 0:00:28
epoch [30/30] batch [740/796] time 0.400 (0.382) data 0.000 (0.001) loss 2.4863 (1.3380) lr 2.7391e-05 eta 0:00:21
epoch [30/30] batch [760/796] time 0.366 (0.382) data 0.000 (0.001) loss 0.4048 (1.3324) lr 2.7391e-05 eta 0:00:13
epoch [30/30] batch [780/796] time 0.343 (0.381) data 0.000 (0.001) loss 1.4238 (1.3324) lr 2.7391e-05 eta 0:00:06
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:48,  5.73s/it] 10%|█         | 2/20 [00:06<00:51,  2.89s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.49it/s] 50%|█████     | 10/20 [00:08<00:03,  2.74it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.99it/s] 60%|██████    | 12/20 [00:09<00:02,  3.25it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.65it/s] 70%|███████   | 14/20 [00:09<00:01,  3.88it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.90it/s] 80%|████████  | 16/20 [00:10<00:01,  3.93it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.14it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.28it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.73it/s]100%|██████████| 20/20 [00:11<00:00,  4.18it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]
=> result
* total: 1,990
* correct: 1,627
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 81.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 29)
Evaluate on the *test* set
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:05<09:02,  5.48s/it]  2%|▏         | 2/100 [00:05<04:10,  2.56s/it]  3%|▎         | 3/100 [00:07<03:22,  2.09s/it]  4%|▍         | 4/100 [00:07<02:19,  1.45s/it]  5%|▌         | 5/100 [00:08<01:46,  1.12s/it]  6%|▌         | 6/100 [00:09<01:25,  1.10it/s]  7%|▋         | 7/100 [00:09<01:12,  1.27it/s]  8%|▊         | 8/100 [00:09<01:01,  1.49it/s]  9%|▉         | 9/100 [00:10<00:54,  1.66it/s] 10%|█         | 10/100 [00:10<00:49,  1.82it/s] 11%|█         | 11/100 [00:11<00:46,  1.92it/s] 12%|█▏        | 12/100 [00:11<00:44,  1.97it/s] 13%|█▎        | 13/100 [00:12<00:42,  2.07it/s] 14%|█▍        | 14/100 [00:12<00:42,  2.04it/s] 15%|█▌        | 15/100 [00:13<00:42,  2.00it/s] 16%|█▌        | 16/100 [00:13<00:42,  2.00it/s] 17%|█▋        | 17/100 [00:14<00:40,  2.05it/s] 18%|█▊        | 18/100 [00:14<00:40,  2.00it/s] 19%|█▉        | 19/100 [00:15<00:38,  2.09it/s] 20%|██        | 20/100 [00:15<00:37,  2.14it/s] 21%|██        | 21/100 [00:16<00:36,  2.15it/s] 22%|██▏       | 22/100 [00:16<00:35,  2.22it/s] 23%|██▎       | 23/100 [00:16<00:33,  2.27it/s] 24%|██▍       | 24/100 [00:17<00:32,  2.31it/s] 25%|██▌       | 25/100 [00:17<00:32,  2.32it/s] 26%|██▌       | 26/100 [00:18<00:32,  2.31it/s] 27%|██▋       | 27/100 [00:18<00:31,  2.32it/s] 28%|██▊       | 28/100 [00:19<00:31,  2.28it/s] 29%|██▉       | 29/100 [00:19<00:31,  2.28it/s] 30%|███       | 30/100 [00:19<00:31,  2.25it/s] 31%|███       | 31/100 [00:20<00:31,  2.22it/s] 32%|███▏      | 32/100 [00:20<00:32,  2.10it/s] 33%|███▎      | 33/100 [00:21<00:32,  2.09it/s] 34%|███▍      | 34/100 [00:21<00:30,  2.18it/s] 35%|███▌      | 35/100 [00:22<00:29,  2.20it/s] 36%|███▌      | 36/100 [00:22<00:27,  2.30it/s] 37%|███▋      | 37/100 [00:23<00:25,  2.50it/s] 38%|███▊      | 38/100 [00:23<00:20,  2.96it/s] 39%|███▉      | 39/100 [00:23<00:21,  2.80it/s] 40%|████      | 40/100 [00:24<00:23,  2.57it/s] 41%|████      | 41/100 [00:24<00:23,  2.51it/s] 42%|████▏     | 42/100 [00:24<00:24,  2.40it/s] 43%|████▎     | 43/100 [00:25<00:23,  2.38it/s] 44%|████▍     | 44/100 [00:25<00:23,  2.39it/s] 45%|████▌     | 45/100 [00:26<00:23,  2.37it/s] 46%|████▌     | 46/100 [00:26<00:22,  2.42it/s] 47%|████▋     | 47/100 [00:27<00:21,  2.43it/s] 48%|████▊     | 48/100 [00:27<00:21,  2.37it/s] 49%|████▉     | 49/100 [00:27<00:21,  2.34it/s] 50%|█████     | 50/100 [00:28<00:21,  2.31it/s] 51%|█████     | 51/100 [00:28<00:21,  2.23it/s] 52%|█████▏    | 52/100 [00:29<00:20,  2.36it/s] 53%|█████▎    | 53/100 [00:29<00:19,  2.39it/s] 54%|█████▍    | 54/100 [00:30<00:19,  2.40it/s] 55%|█████▌    | 55/100 [00:30<00:18,  2.38it/s] 56%|█████▌    | 56/100 [00:30<00:18,  2.33it/s] 57%|█████▋    | 57/100 [00:31<00:18,  2.31it/s] 58%|█████▊    | 58/100 [00:31<00:18,  2.28it/s] 59%|█████▉    | 59/100 [00:32<00:17,  2.35it/s] 60%|██████    | 60/100 [00:32<00:16,  2.38it/s] 61%|██████    | 61/100 [00:32<00:15,  2.47it/s] 62%|██████▏   | 62/100 [00:33<00:15,  2.38it/s] 63%|██████▎   | 63/100 [00:33<00:15,  2.38it/s] 64%|██████▍   | 64/100 [00:34<00:15,  2.39it/s] 65%|██████▌   | 65/100 [00:34<00:15,  2.33it/s] 66%|██████▌   | 66/100 [00:35<00:14,  2.30it/s] 67%|██████▋   | 67/100 [00:35<00:14,  2.27it/s] 68%|██████▊   | 68/100 [00:36<00:14,  2.27it/s] 69%|██████▉   | 69/100 [00:36<00:13,  2.26it/s] 70%|███████   | 70/100 [00:36<00:12,  2.33it/s] 71%|███████   | 71/100 [00:37<00:11,  2.47it/s] 72%|███████▏  | 72/100 [00:37<00:10,  2.55it/s] 73%|███████▎  | 73/100 [00:37<00:10,  2.64it/s] 74%|███████▍  | 74/100 [00:38<00:09,  2.78it/s] 75%|███████▌  | 75/100 [00:38<00:08,  2.91it/s] 76%|███████▌  | 76/100 [00:38<00:08,  2.97it/s] 77%|███████▋  | 77/100 [00:39<00:07,  3.04it/s] 78%|███████▊  | 78/100 [00:39<00:07,  3.10it/s] 79%|███████▉  | 79/100 [00:39<00:06,  3.24it/s] 80%|████████  | 80/100 [00:40<00:05,  3.43it/s] 81%|████████  | 81/100 [00:40<00:05,  3.77it/s] 82%|████████▏ | 82/100 [00:40<00:04,  4.16it/s] 83%|████████▎ | 83/100 [00:40<00:03,  4.49it/s] 84%|████████▍ | 84/100 [00:40<00:03,  4.74it/s] 85%|████████▌ | 85/100 [00:40<00:03,  4.94it/s] 86%|████████▌ | 86/100 [00:41<00:02,  5.09it/s] 87%|████████▋ | 87/100 [00:41<00:02,  5.20it/s] 88%|████████▊ | 88/100 [00:41<00:02,  5.28it/s] 89%|████████▉ | 89/100 [00:41<00:02,  5.34it/s] 90%|█████████ | 90/100 [00:41<00:01,  5.38it/s] 91%|█████████ | 91/100 [00:42<00:01,  5.41it/s] 92%|█████████▏| 92/100 [00:42<00:01,  5.43it/s] 93%|█████████▎| 93/100 [00:42<00:01,  5.44it/s] 94%|█████████▍| 94/100 [00:42<00:01,  5.45it/s] 95%|█████████▌| 95/100 [00:42<00:00,  5.45it/s] 96%|█████████▌| 96/100 [00:43<00:00,  5.46it/s] 97%|█████████▋| 97/100 [00:43<00:00,  5.46it/s] 98%|█████████▊| 98/100 [00:43<00:00,  5.47it/s] 99%|█████████▉| 99/100 [00:43<00:00,  5.47it/s]100%|██████████| 100/100 [00:43<00:00,  6.01it/s]100%|██████████| 100/100 [00:43<00:00,  2.28it/s]
=> result
* total: 9,950
* correct: 8,131
* accuracy: 81.7%
* error: 18.3%
* macro_f1: 81.5%
Elapsed: 2:37:34
+ sh scripts/rpo_prime/base2new_test_sdl.sh sun397 1 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
3168 1980 9900
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  198
# train_x  3,168
# val      1,980
# test     9,900
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar" (epoch = 29)
Evaluate on the *test* set
  0%|          | 0/99 [00:00<?, ?it/s]  1%|          | 1/99 [00:10<16:42, 10.23s/it]  2%|▏         | 2/99 [00:10<07:14,  4.48s/it]  3%|▎         | 3/99 [00:11<04:09,  2.59s/it]  4%|▍         | 4/99 [00:11<02:43,  1.72s/it]  5%|▌         | 5/99 [00:11<01:54,  1.22s/it]  6%|▌         | 6/99 [00:12<01:25,  1.09it/s]  7%|▋         | 7/99 [00:12<01:06,  1.38it/s]  8%|▊         | 8/99 [00:12<00:54,  1.67it/s]  9%|▉         | 9/99 [00:13<00:46,  1.95it/s] 10%|█         | 10/99 [00:13<00:40,  2.18it/s] 11%|█         | 11/99 [00:13<00:37,  2.35it/s] 12%|█▏        | 12/99 [00:14<00:35,  2.44it/s] 13%|█▎        | 13/99 [00:14<00:34,  2.46it/s] 14%|█▍        | 14/99 [00:14<00:34,  2.46it/s] 15%|█▌        | 15/99 [00:15<00:34,  2.41it/s] 16%|█▌        | 16/99 [00:15<00:35,  2.34it/s] 17%|█▋        | 17/99 [00:16<00:35,  2.30it/s] 18%|█▊        | 18/99 [00:16<00:37,  2.18it/s] 19%|█▉        | 19/99 [00:17<00:37,  2.13it/s] 20%|██        | 20/99 [00:17<00:36,  2.18it/s] 21%|██        | 21/99 [00:18<00:35,  2.18it/s] 22%|██▏       | 22/99 [00:18<00:37,  2.03it/s] 23%|██▎       | 23/99 [00:19<00:35,  2.11it/s] 24%|██▍       | 24/99 [00:19<00:35,  2.14it/s] 25%|██▌       | 25/99 [00:20<00:34,  2.17it/s] 26%|██▋       | 26/99 [00:20<00:31,  2.35it/s] 27%|██▋       | 27/99 [00:20<00:29,  2.48it/s] 28%|██▊       | 28/99 [00:21<00:26,  2.63it/s] 29%|██▉       | 29/99 [00:21<00:26,  2.68it/s] 30%|███       | 30/99 [00:21<00:25,  2.74it/s] 31%|███▏      | 31/99 [00:22<00:24,  2.73it/s] 32%|███▏      | 32/99 [00:22<00:24,  2.73it/s] 33%|███▎      | 33/99 [00:22<00:25,  2.60it/s] 34%|███▍      | 34/99 [00:23<00:25,  2.59it/s] 35%|███▌      | 35/99 [00:23<00:25,  2.53it/s] 36%|███▋      | 36/99 [00:24<00:25,  2.43it/s] 37%|███▋      | 37/99 [00:24<00:25,  2.42it/s] 38%|███▊      | 38/99 [00:24<00:24,  2.50it/s] 39%|███▉      | 39/99 [00:25<00:24,  2.46it/s] 40%|████      | 40/99 [00:25<00:24,  2.44it/s] 41%|████▏     | 41/99 [00:26<00:23,  2.50it/s] 42%|████▏     | 42/99 [00:26<00:23,  2.46it/s] 43%|████▎     | 43/99 [00:26<00:21,  2.58it/s] 44%|████▍     | 44/99 [00:27<00:20,  2.66it/s] 45%|████▌     | 45/99 [00:27<00:20,  2.65it/s] 46%|████▋     | 46/99 [00:28<00:20,  2.64it/s] 47%|████▋     | 47/99 [00:28<00:19,  2.60it/s] 48%|████▊     | 48/99 [00:28<00:19,  2.56it/s] 49%|████▉     | 49/99 [00:29<00:20,  2.47it/s] 51%|█████     | 50/99 [00:29<00:20,  2.41it/s] 52%|█████▏    | 51/99 [00:30<00:20,  2.37it/s] 53%|█████▎    | 52/99 [00:30<00:20,  2.34it/s] 54%|█████▎    | 53/99 [00:31<00:19,  2.34it/s] 55%|█████▍    | 54/99 [00:31<00:18,  2.39it/s] 56%|█████▌    | 55/99 [00:31<00:18,  2.40it/s] 57%|█████▋    | 56/99 [00:32<00:18,  2.36it/s] 58%|█████▊    | 57/99 [00:32<00:16,  2.48it/s] 59%|█████▊    | 58/99 [00:33<00:15,  2.58it/s] 60%|█████▉    | 59/99 [00:33<00:15,  2.61it/s] 61%|██████    | 60/99 [00:33<00:15,  2.54it/s] 62%|██████▏   | 61/99 [00:34<00:15,  2.48it/s] 63%|██████▎   | 62/99 [00:34<00:15,  2.45it/s] 64%|██████▎   | 63/99 [00:35<00:14,  2.41it/s] 65%|██████▍   | 64/99 [00:35<00:14,  2.41it/s] 66%|██████▌   | 65/99 [00:35<00:13,  2.44it/s] 67%|██████▋   | 66/99 [00:36<00:12,  2.56it/s] 68%|██████▊   | 67/99 [00:36<00:12,  2.62it/s] 69%|██████▊   | 68/99 [00:36<00:11,  2.64it/s] 70%|██████▉   | 69/99 [00:37<00:11,  2.72it/s] 71%|███████   | 70/99 [00:37<00:10,  2.76it/s] 72%|███████▏  | 71/99 [00:37<00:09,  2.86it/s] 73%|███████▎  | 72/99 [00:38<00:09,  2.98it/s] 74%|███████▎  | 73/99 [00:38<00:08,  3.09it/s] 75%|███████▍  | 74/99 [00:38<00:07,  3.15it/s] 76%|███████▌  | 75/99 [00:39<00:07,  3.23it/s] 77%|███████▋  | 76/99 [00:39<00:06,  3.31it/s] 78%|███████▊  | 77/99 [00:39<00:06,  3.31it/s] 79%|███████▉  | 78/99 [00:40<00:06,  3.36it/s] 80%|███████▉  | 79/99 [00:40<00:05,  3.45it/s] 81%|████████  | 80/99 [00:40<00:05,  3.69it/s] 82%|████████▏ | 81/99 [00:40<00:04,  4.04it/s] 83%|████████▎ | 82/99 [00:40<00:04,  4.25it/s] 84%|████████▍ | 83/99 [00:41<00:03,  4.57it/s] 85%|████████▍ | 84/99 [00:41<00:03,  4.80it/s] 86%|████████▌ | 85/99 [00:41<00:02,  4.99it/s] 87%|████████▋ | 86/99 [00:41<00:02,  5.14it/s] 88%|████████▊ | 87/99 [00:41<00:02,  5.25it/s] 89%|████████▉ | 88/99 [00:42<00:02,  5.32it/s] 90%|████████▉ | 89/99 [00:42<00:01,  5.38it/s] 91%|█████████ | 90/99 [00:42<00:01,  5.42it/s] 92%|█████████▏| 91/99 [00:42<00:01,  5.45it/s] 93%|█████████▎| 92/99 [00:42<00:01,  5.47it/s] 94%|█████████▍| 93/99 [00:42<00:01,  5.48it/s] 95%|█████████▍| 94/99 [00:43<00:00,  5.49it/s] 96%|█████████▌| 95/99 [00:43<00:00,  5.50it/s] 97%|█████████▋| 96/99 [00:43<00:00,  5.50it/s] 98%|█████████▊| 97/99 [00:43<00:00,  5.41it/s] 99%|█████████▉| 98/99 [00:43<00:00,  5.44it/s]100%|██████████| 99/99 [00:44<00:00,  5.46it/s]100%|██████████| 99/99 [00:44<00:00,  2.24it/s]
=> result
* total: 9,900
* correct: 7,752
* accuracy: 78.3%
* error: 21.7%
* macro_f1: 77.4%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh sun397 2 0 main_tmp1_0.1sdl 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
3184 1990 9950
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  199
# train_x  3,184
# val      1,990
# test     9,950
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/796] time 0.378 (0.515) data 0.000 (0.061) loss 0.8511 (2.4310) lr 1.0000e-02 eta 3:24:56
epoch [1/30] batch [40/796] time 0.367 (0.447) data 0.000 (0.031) loss 1.4229 (2.1143) lr 1.0000e-02 eta 2:57:26
epoch [1/30] batch [60/796] time 0.350 (0.421) data 0.000 (0.020) loss 0.9062 (2.2811) lr 1.0000e-02 eta 2:47:15
epoch [1/30] batch [80/796] time 0.356 (0.410) data 0.000 (0.015) loss 0.0463 (2.2970) lr 1.0000e-02 eta 2:42:45
epoch [1/30] batch [100/796] time 0.359 (0.402) data 0.000 (0.012) loss 4.4883 (2.4028) lr 1.0000e-02 eta 2:39:27
epoch [1/30] batch [120/796] time 0.403 (0.397) data 0.000 (0.010) loss 1.7676 (2.3668) lr 1.0000e-02 eta 2:37:22
epoch [1/30] batch [140/796] time 0.417 (0.395) data 0.000 (0.009) loss 2.9062 (2.3686) lr 1.0000e-02 eta 2:36:26
epoch [1/30] batch [160/796] time 0.393 (0.393) data 0.000 (0.008) loss 0.9180 (2.3537) lr 1.0000e-02 eta 2:35:28
epoch [1/30] batch [180/796] time 0.380 (0.391) data 0.000 (0.007) loss 1.3281 (2.3004) lr 1.0000e-02 eta 2:34:26
epoch [1/30] batch [200/796] time 0.367 (0.390) data 0.000 (0.006) loss 0.1211 (2.2839) lr 1.0000e-02 eta 2:33:45
epoch [1/30] batch [220/796] time 0.408 (0.389) data 0.000 (0.006) loss 2.3320 (2.2892) lr 1.0000e-02 eta 2:33:21
epoch [1/30] batch [240/796] time 0.357 (0.388) data 0.000 (0.005) loss 4.4648 (2.2889) lr 1.0000e-02 eta 2:33:00
epoch [1/30] batch [260/796] time 0.361 (0.387) data 0.000 (0.005) loss 1.6084 (2.2954) lr 1.0000e-02 eta 2:32:26
epoch [1/30] batch [280/796] time 0.404 (0.386) data 0.000 (0.005) loss 1.5811 (2.2480) lr 1.0000e-02 eta 2:32:00
epoch [1/30] batch [300/796] time 0.376 (0.386) data 0.000 (0.004) loss 0.9272 (2.2779) lr 1.0000e-02 eta 2:31:48
epoch [1/30] batch [320/796] time 0.357 (0.386) data 0.000 (0.004) loss 0.8755 (2.2435) lr 1.0000e-02 eta 2:31:24
epoch [1/30] batch [340/796] time 0.364 (0.385) data 0.000 (0.004) loss 1.6533 (2.2391) lr 1.0000e-02 eta 2:31:06
epoch [1/30] batch [360/796] time 0.400 (0.385) data 0.000 (0.004) loss 0.2185 (2.2492) lr 1.0000e-02 eta 2:31:01
epoch [1/30] batch [380/796] time 0.366 (0.384) data 0.000 (0.003) loss 1.9570 (2.2633) lr 1.0000e-02 eta 2:30:32
epoch [1/30] batch [400/796] time 0.413 (0.385) data 0.000 (0.003) loss 1.7734 (2.2437) lr 1.0000e-02 eta 2:30:28
epoch [1/30] batch [420/796] time 0.368 (0.384) data 0.000 (0.003) loss 4.4453 (2.2505) lr 1.0000e-02 eta 2:30:11
epoch [1/30] batch [440/796] time 0.368 (0.384) data 0.000 (0.003) loss 7.3281 (2.2540) lr 1.0000e-02 eta 2:30:04
epoch [1/30] batch [460/796] time 0.352 (0.384) data 0.000 (0.003) loss 1.2451 (2.2395) lr 1.0000e-02 eta 2:29:55
epoch [1/30] batch [480/796] time 0.349 (0.384) data 0.000 (0.003) loss 2.3340 (2.2134) lr 1.0000e-02 eta 2:29:44
epoch [1/30] batch [500/796] time 0.399 (0.384) data 0.000 (0.003) loss 3.7715 (2.2182) lr 1.0000e-02 eta 2:29:36
epoch [1/30] batch [520/796] time 0.393 (0.384) data 0.000 (0.003) loss 0.4958 (2.1940) lr 1.0000e-02 eta 2:29:22
epoch [1/30] batch [540/796] time 0.370 (0.384) data 0.000 (0.002) loss 0.2344 (2.1849) lr 1.0000e-02 eta 2:29:12
epoch [1/30] batch [560/796] time 0.355 (0.383) data 0.000 (0.002) loss 1.5371 (2.1987) lr 1.0000e-02 eta 2:29:00
epoch [1/30] batch [580/796] time 0.380 (0.383) data 0.000 (0.002) loss 3.2988 (2.2054) lr 1.0000e-02 eta 2:28:46
epoch [1/30] batch [600/796] time 0.409 (0.383) data 0.000 (0.002) loss 4.5938 (2.2092) lr 1.0000e-02 eta 2:28:39
epoch [1/30] batch [620/796] time 0.396 (0.383) data 0.000 (0.002) loss 0.3916 (2.2122) lr 1.0000e-02 eta 2:28:29
epoch [1/30] batch [640/796] time 0.353 (0.383) data 0.000 (0.002) loss 3.1328 (2.2109) lr 1.0000e-02 eta 2:28:17
epoch [1/30] batch [660/796] time 0.385 (0.383) data 0.000 (0.002) loss 1.4443 (2.2063) lr 1.0000e-02 eta 2:28:09
epoch [1/30] batch [680/796] time 0.369 (0.383) data 0.000 (0.002) loss 1.3447 (2.1974) lr 1.0000e-02 eta 2:27:59
epoch [1/30] batch [700/796] time 0.377 (0.383) data 0.000 (0.002) loss 1.8447 (2.1926) lr 1.0000e-02 eta 2:27:48
epoch [1/30] batch [720/796] time 0.359 (0.383) data 0.000 (0.002) loss 3.4512 (2.1911) lr 1.0000e-02 eta 2:27:40
epoch [1/30] batch [740/796] time 0.373 (0.382) data 0.000 (0.002) loss 2.5020 (2.1870) lr 1.0000e-02 eta 2:27:27
epoch [1/30] batch [760/796] time 0.365 (0.382) data 0.000 (0.002) loss 0.9102 (2.1875) lr 1.0000e-02 eta 2:27:15
epoch [1/30] batch [780/796] time 0.340 (0.381) data 0.000 (0.002) loss 2.9062 (2.1939) lr 1.0000e-02 eta 2:26:49
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.63s/it] 10%|█         | 2/20 [00:06<00:49,  2.78s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.64s/it] 20%|██        | 4/20 [00:06<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:08,  1.56it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.49it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.97it/s] 60%|██████    | 12/20 [00:09<00:02,  3.19it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.48it/s] 70%|███████   | 14/20 [00:09<00:01,  3.62it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.93it/s] 80%|████████  | 16/20 [00:10<00:00,  4.13it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.21it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.74it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.14it/s]100%|██████████| 20/20 [00:11<00:00,  4.53it/s]100%|██████████| 20/20 [00:11<00:00,  1.79it/s]=> result
* total: 1,990
* correct: 1,523
* accuracy: 76.5%
* error: 23.5%
* macro_f1: 75.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/796] time 0.350 (0.430) data 0.000 (0.038) loss 0.2399 (1.7086) lr 9.9726e-03 eta 2:45:27
epoch [2/30] batch [40/796] time 0.395 (0.399) data 0.000 (0.019) loss 0.3132 (1.9450) lr 9.9726e-03 eta 2:33:17
epoch [2/30] batch [60/796] time 0.392 (0.391) data 0.000 (0.013) loss 0.8701 (1.9378) lr 9.9726e-03 eta 2:29:57
epoch [2/30] batch [80/796] time 0.398 (0.388) data 0.000 (0.010) loss 0.4536 (1.9877) lr 9.9726e-03 eta 2:28:51
epoch [2/30] batch [100/796] time 0.390 (0.386) data 0.000 (0.008) loss 3.0742 (2.0422) lr 9.9726e-03 eta 2:27:51
epoch [2/30] batch [120/796] time 0.395 (0.385) data 0.000 (0.007) loss 1.9912 (2.0320) lr 9.9726e-03 eta 2:27:21
epoch [2/30] batch [140/796] time 0.390 (0.385) data 0.000 (0.006) loss 0.2109 (1.9969) lr 9.9726e-03 eta 2:27:15
epoch [2/30] batch [160/796] time 0.388 (0.384) data 0.000 (0.005) loss 1.2314 (1.9896) lr 9.9726e-03 eta 2:26:37
epoch [2/30] batch [180/796] time 0.389 (0.383) data 0.000 (0.004) loss 2.8184 (1.9561) lr 9.9726e-03 eta 2:26:01
epoch [2/30] batch [200/796] time 0.384 (0.382) data 0.000 (0.004) loss 0.5493 (1.9793) lr 9.9726e-03 eta 2:25:34
epoch [2/30] batch [220/796] time 0.387 (0.381) data 0.000 (0.004) loss 2.9902 (1.9776) lr 9.9726e-03 eta 2:25:12
epoch [2/30] batch [240/796] time 0.383 (0.381) data 0.000 (0.003) loss 1.4834 (2.0001) lr 9.9726e-03 eta 2:25:01
epoch [2/30] batch [260/796] time 0.370 (0.380) data 0.000 (0.003) loss 3.5078 (1.9979) lr 9.9726e-03 eta 2:24:43
epoch [2/30] batch [280/796] time 0.369 (0.380) data 0.000 (0.003) loss 2.2559 (1.9699) lr 9.9726e-03 eta 2:24:35
epoch [2/30] batch [300/796] time 0.357 (0.380) data 0.000 (0.003) loss 0.4072 (1.9729) lr 9.9726e-03 eta 2:24:22
epoch [2/30] batch [320/796] time 0.376 (0.381) data 0.000 (0.003) loss 1.1113 (1.9569) lr 9.9726e-03 eta 2:24:22
epoch [2/30] batch [340/796] time 0.382 (0.380) data 0.000 (0.002) loss 2.4609 (1.9053) lr 9.9726e-03 eta 2:24:11
epoch [2/30] batch [360/796] time 0.363 (0.380) data 0.000 (0.002) loss 2.3633 (1.9600) lr 9.9726e-03 eta 2:24:00
epoch [2/30] batch [380/796] time 0.350 (0.381) data 0.000 (0.002) loss 0.4248 (1.9955) lr 9.9726e-03 eta 2:24:00
epoch [2/30] batch [400/796] time 0.400 (0.381) data 0.000 (0.002) loss 1.9453 (1.9873) lr 9.9726e-03 eta 2:24:02
epoch [2/30] batch [420/796] time 0.413 (0.381) data 0.000 (0.002) loss 2.9980 (1.9802) lr 9.9726e-03 eta 2:23:53
epoch [2/30] batch [440/796] time 0.348 (0.381) data 0.000 (0.002) loss 2.7949 (1.9647) lr 9.9726e-03 eta 2:23:48
epoch [2/30] batch [460/796] time 0.362 (0.381) data 0.000 (0.002) loss 2.1016 (1.9958) lr 9.9726e-03 eta 2:23:37
epoch [2/30] batch [480/796] time 0.406 (0.381) data 0.000 (0.002) loss 1.4258 (1.9899) lr 9.9726e-03 eta 2:23:27
epoch [2/30] batch [500/796] time 0.400 (0.381) data 0.000 (0.002) loss 1.7930 (1.9858) lr 9.9726e-03 eta 2:23:16
epoch [2/30] batch [520/796] time 0.394 (0.380) data 0.000 (0.002) loss 1.3486 (2.0018) lr 9.9726e-03 eta 2:23:04
epoch [2/30] batch [540/796] time 0.352 (0.380) data 0.000 (0.002) loss 0.8936 (2.0108) lr 9.9726e-03 eta 2:22:55
epoch [2/30] batch [560/796] time 0.388 (0.380) data 0.000 (0.002) loss 3.0605 (2.0051) lr 9.9726e-03 eta 2:22:46
epoch [2/30] batch [580/796] time 0.402 (0.380) data 0.000 (0.002) loss 1.2783 (2.0021) lr 9.9726e-03 eta 2:22:39
epoch [2/30] batch [600/796] time 0.367 (0.380) data 0.000 (0.002) loss 1.8311 (2.0167) lr 9.9726e-03 eta 2:22:29
epoch [2/30] batch [620/796] time 0.389 (0.380) data 0.000 (0.001) loss 4.6445 (2.0135) lr 9.9726e-03 eta 2:22:20
epoch [2/30] batch [640/796] time 0.358 (0.380) data 0.000 (0.001) loss 1.6680 (2.0199) lr 9.9726e-03 eta 2:22:16
epoch [2/30] batch [660/796] time 0.373 (0.380) data 0.000 (0.001) loss 1.4258 (2.0252) lr 9.9726e-03 eta 2:22:10
epoch [2/30] batch [680/796] time 0.360 (0.380) data 0.000 (0.001) loss 2.2617 (2.0246) lr 9.9726e-03 eta 2:22:01
epoch [2/30] batch [700/796] time 0.361 (0.380) data 0.000 (0.001) loss 1.8633 (2.0147) lr 9.9726e-03 eta 2:21:49
epoch [2/30] batch [720/796] time 0.391 (0.380) data 0.000 (0.001) loss 1.6436 (2.0173) lr 9.9726e-03 eta 2:21:42
epoch [2/30] batch [740/796] time 0.368 (0.380) data 0.000 (0.001) loss 3.3145 (2.0059) lr 9.9726e-03 eta 2:21:30
epoch [2/30] batch [760/796] time 0.366 (0.380) data 0.000 (0.001) loss 1.6279 (2.0046) lr 9.9726e-03 eta 2:21:22
epoch [2/30] batch [780/796] time 0.340 (0.379) data 0.000 (0.001) loss 4.3125 (2.0192) lr 9.9726e-03 eta 2:20:57
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:42,  5.40s/it] 10%|█         | 2/20 [00:06<00:52,  2.93s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.73s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.84it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.05it/s] 60%|██████    | 12/20 [00:09<00:02,  3.22it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.45it/s] 70%|███████   | 14/20 [00:09<00:01,  3.53it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.63it/s] 80%|████████  | 16/20 [00:10<00:01,  3.77it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.87it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.22it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.53it/s]100%|██████████| 20/20 [00:11<00:00,  4.86it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,526
* accuracy: 76.7%
* error: 23.3%
* macro_f1: 75.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/796] time 0.407 (0.427) data 0.000 (0.038) loss 1.4609 (1.8557) lr 9.8907e-03 eta 2:38:18
epoch [3/30] batch [40/796] time 0.355 (0.404) data 0.000 (0.019) loss 1.1309 (1.9370) lr 9.8907e-03 eta 2:29:39
epoch [3/30] batch [60/796] time 0.391 (0.395) data 0.000 (0.013) loss 0.7388 (1.9166) lr 9.8907e-03 eta 2:26:23
epoch [3/30] batch [80/796] time 0.374 (0.390) data 0.000 (0.010) loss 2.7676 (1.8428) lr 9.8907e-03 eta 2:24:22
epoch [3/30] batch [100/796] time 0.367 (0.386) data 0.000 (0.008) loss 2.0840 (1.7798) lr 9.8907e-03 eta 2:22:35
epoch [3/30] batch [120/796] time 0.351 (0.384) data 0.000 (0.007) loss 0.8433 (1.7761) lr 9.8907e-03 eta 2:21:55
epoch [3/30] batch [140/796] time 0.364 (0.383) data 0.000 (0.006) loss 3.2266 (1.7503) lr 9.8907e-03 eta 2:21:18
epoch [3/30] batch [160/796] time 0.394 (0.381) data 0.000 (0.005) loss 4.8359 (1.7738) lr 9.8907e-03 eta 2:20:39
epoch [3/30] batch [180/796] time 0.399 (0.381) data 0.000 (0.004) loss 0.6489 (1.7948) lr 9.8907e-03 eta 2:20:28
epoch [3/30] batch [200/796] time 0.364 (0.381) data 0.000 (0.004) loss 0.1978 (1.8057) lr 9.8907e-03 eta 2:20:22
epoch [3/30] batch [220/796] time 0.346 (0.381) data 0.000 (0.004) loss 1.3271 (1.8370) lr 9.8907e-03 eta 2:20:08
epoch [3/30] batch [240/796] time 0.359 (0.381) data 0.000 (0.003) loss 2.3223 (1.8867) lr 9.8907e-03 eta 2:19:53
epoch [3/30] batch [260/796] time 0.383 (0.380) data 0.000 (0.003) loss 1.3066 (1.8897) lr 9.8907e-03 eta 2:19:35
epoch [3/30] batch [280/796] time 0.406 (0.380) data 0.000 (0.003) loss 2.3066 (1.8896) lr 9.8907e-03 eta 2:19:25
epoch [3/30] batch [300/796] time 0.403 (0.380) data 0.000 (0.003) loss 1.0479 (1.9151) lr 9.8907e-03 eta 2:19:15
epoch [3/30] batch [320/796] time 0.351 (0.380) data 0.000 (0.003) loss 3.8242 (1.9273) lr 9.8907e-03 eta 2:19:02
epoch [3/30] batch [340/796] time 0.361 (0.380) data 0.000 (0.002) loss 0.7075 (1.9750) lr 9.8907e-03 eta 2:19:00
epoch [3/30] batch [360/796] time 0.358 (0.380) data 0.000 (0.002) loss 3.2012 (1.9799) lr 9.8907e-03 eta 2:18:57
epoch [3/30] batch [380/796] time 0.421 (0.380) data 0.000 (0.002) loss 2.6777 (2.0044) lr 9.8907e-03 eta 2:18:54
epoch [3/30] batch [400/796] time 0.354 (0.381) data 0.000 (0.002) loss 0.5205 (2.0013) lr 9.8907e-03 eta 2:18:49
epoch [3/30] batch [420/796] time 0.385 (0.380) data 0.000 (0.002) loss 0.8652 (2.0031) lr 9.8907e-03 eta 2:18:35
epoch [3/30] batch [440/796] time 0.349 (0.380) data 0.000 (0.002) loss 0.4478 (2.0127) lr 9.8907e-03 eta 2:18:23
epoch [3/30] batch [460/796] time 0.369 (0.380) data 0.000 (0.002) loss 1.3965 (1.9943) lr 9.8907e-03 eta 2:18:15
epoch [3/30] batch [480/796] time 0.357 (0.380) data 0.000 (0.002) loss 0.4663 (2.0101) lr 9.8907e-03 eta 2:18:12
epoch [3/30] batch [500/796] time 0.376 (0.380) data 0.000 (0.002) loss 0.5327 (1.9895) lr 9.8907e-03 eta 2:18:03
epoch [3/30] batch [520/796] time 0.369 (0.380) data 0.000 (0.002) loss 3.2383 (1.9839) lr 9.8907e-03 eta 2:17:57
epoch [3/30] batch [540/796] time 0.349 (0.380) data 0.000 (0.002) loss 3.5469 (2.0047) lr 9.8907e-03 eta 2:17:51
epoch [3/30] batch [560/796] time 0.401 (0.380) data 0.000 (0.002) loss 2.8516 (2.0229) lr 9.8907e-03 eta 2:17:36
epoch [3/30] batch [580/796] time 0.371 (0.380) data 0.000 (0.002) loss 3.1582 (2.0255) lr 9.8907e-03 eta 2:17:24
epoch [3/30] batch [600/796] time 0.378 (0.380) data 0.000 (0.002) loss 1.6689 (2.0229) lr 9.8907e-03 eta 2:17:18
epoch [3/30] batch [620/796] time 0.401 (0.380) data 0.000 (0.001) loss 0.2111 (2.0099) lr 9.8907e-03 eta 2:17:16
epoch [3/30] batch [640/796] time 0.352 (0.380) data 0.000 (0.001) loss 2.3184 (1.9962) lr 9.8907e-03 eta 2:17:07
epoch [3/30] batch [660/796] time 0.401 (0.380) data 0.000 (0.001) loss 0.2151 (2.0012) lr 9.8907e-03 eta 2:17:02
epoch [3/30] batch [680/796] time 0.394 (0.380) data 0.000 (0.001) loss 2.4258 (1.9978) lr 9.8907e-03 eta 2:16:56
epoch [3/30] batch [700/796] time 0.372 (0.380) data 0.000 (0.001) loss 0.0090 (1.9893) lr 9.8907e-03 eta 2:16:53
epoch [3/30] batch [720/796] time 0.400 (0.381) data 0.000 (0.001) loss 2.7617 (1.9759) lr 9.8907e-03 eta 2:16:50
epoch [3/30] batch [740/796] time 0.366 (0.380) data 0.000 (0.001) loss 0.8408 (1.9738) lr 9.8907e-03 eta 2:16:38
epoch [3/30] batch [760/796] time 0.352 (0.380) data 0.000 (0.001) loss 1.1504 (1.9608) lr 9.8907e-03 eta 2:16:31
epoch [3/30] batch [780/796] time 0.339 (0.380) data 0.000 (0.001) loss 3.3555 (1.9646) lr 9.8907e-03 eta 2:16:04
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:42,  5.40s/it] 10%|█         | 2/20 [00:06<00:49,  2.78s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.65s/it] 20%|██        | 4/20 [00:06<00:17,  1.12s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.49it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.98it/s] 60%|██████    | 12/20 [00:09<00:02,  3.16it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.37it/s] 70%|███████   | 14/20 [00:09<00:01,  3.63it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.74it/s] 80%|████████  | 16/20 [00:10<00:01,  3.86it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.88it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.26it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.56it/s]100%|██████████| 20/20 [00:11<00:00,  4.88it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,538
* accuracy: 77.3%
* error: 22.7%
* macro_f1: 76.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/796] time 0.378 (0.423) data 0.000 (0.036) loss 1.9395 (2.0911) lr 9.7553e-03 eta 2:31:33
epoch [4/30] batch [40/796] time 0.380 (0.402) data 0.000 (0.018) loss 0.2238 (1.8468) lr 9.7553e-03 eta 2:23:48
epoch [4/30] batch [60/796] time 0.393 (0.395) data 0.000 (0.012) loss 1.5850 (2.0751) lr 9.7553e-03 eta 2:21:11
epoch [4/30] batch [80/796] time 0.392 (0.392) data 0.000 (0.009) loss 0.9946 (2.0540) lr 9.7553e-03 eta 2:19:52
epoch [4/30] batch [100/796] time 0.477 (0.391) data 0.000 (0.007) loss 2.1660 (2.1728) lr 9.7553e-03 eta 2:19:19
epoch [4/30] batch [120/796] time 0.370 (0.389) data 0.000 (0.006) loss 2.7363 (2.1127) lr 9.7553e-03 eta 2:18:23
epoch [4/30] batch [140/796] time 0.396 (0.387) data 0.000 (0.005) loss 1.4092 (2.0792) lr 9.7553e-03 eta 2:17:45
epoch [4/30] batch [160/796] time 0.379 (0.386) data 0.000 (0.005) loss 1.3008 (2.0537) lr 9.7553e-03 eta 2:17:13
epoch [4/30] batch [180/796] time 0.384 (0.385) data 0.000 (0.004) loss 2.1484 (2.0547) lr 9.7553e-03 eta 2:16:38
epoch [4/30] batch [200/796] time 0.355 (0.384) data 0.000 (0.004) loss 5.9023 (2.0444) lr 9.7553e-03 eta 2:16:19
epoch [4/30] batch [220/796] time 0.354 (0.384) data 0.000 (0.003) loss 0.5601 (1.9953) lr 9.7553e-03 eta 2:16:08
epoch [4/30] batch [240/796] time 0.383 (0.383) data 0.000 (0.003) loss 5.0938 (1.9575) lr 9.7553e-03 eta 2:15:46
epoch [4/30] batch [260/796] time 0.401 (0.383) data 0.000 (0.003) loss 0.3115 (1.9458) lr 9.7553e-03 eta 2:15:30
epoch [4/30] batch [280/796] time 0.360 (0.383) data 0.000 (0.003) loss 3.0820 (1.9356) lr 9.7553e-03 eta 2:15:13
epoch [4/30] batch [300/796] time 0.367 (0.382) data 0.000 (0.003) loss 0.9771 (1.9320) lr 9.7553e-03 eta 2:15:01
epoch [4/30] batch [320/796] time 0.396 (0.382) data 0.000 (0.002) loss 1.4082 (1.9015) lr 9.7553e-03 eta 2:14:47
epoch [4/30] batch [340/796] time 0.383 (0.381) data 0.000 (0.002) loss 0.0930 (1.8659) lr 9.7553e-03 eta 2:14:25
epoch [4/30] batch [360/796] time 0.376 (0.381) data 0.000 (0.002) loss 4.0508 (1.8643) lr 9.7553e-03 eta 2:14:12
epoch [4/30] batch [380/796] time 0.374 (0.380) data 0.000 (0.002) loss 2.1172 (1.8574) lr 9.7553e-03 eta 2:13:45
epoch [4/30] batch [400/796] time 0.389 (0.380) data 0.000 (0.002) loss 2.6328 (1.8552) lr 9.7553e-03 eta 2:13:34
epoch [4/30] batch [420/796] time 0.363 (0.380) data 0.000 (0.002) loss 1.7607 (1.8806) lr 9.7553e-03 eta 2:13:20
epoch [4/30] batch [440/796] time 0.372 (0.380) data 0.000 (0.002) loss 4.8867 (1.8742) lr 9.7553e-03 eta 2:13:14
epoch [4/30] batch [460/796] time 0.392 (0.380) data 0.000 (0.002) loss 1.3574 (1.8580) lr 9.7553e-03 eta 2:13:13
epoch [4/30] batch [480/796] time 0.361 (0.380) data 0.000 (0.002) loss 2.2891 (1.8580) lr 9.7553e-03 eta 2:13:11
epoch [4/30] batch [500/796] time 0.369 (0.380) data 0.000 (0.002) loss 1.8984 (1.8653) lr 9.7553e-03 eta 2:13:03
epoch [4/30] batch [520/796] time 0.411 (0.380) data 0.000 (0.002) loss 3.8262 (1.8774) lr 9.7553e-03 eta 2:12:57
epoch [4/30] batch [540/796] time 0.368 (0.381) data 0.000 (0.002) loss 2.2617 (1.8858) lr 9.7553e-03 eta 2:12:52
epoch [4/30] batch [560/796] time 0.390 (0.380) data 0.000 (0.002) loss 2.7090 (1.8850) lr 9.7553e-03 eta 2:12:41
epoch [4/30] batch [580/796] time 0.388 (0.380) data 0.000 (0.001) loss 0.9521 (1.8918) lr 9.7553e-03 eta 2:12:32
epoch [4/30] batch [600/796] time 0.372 (0.380) data 0.000 (0.001) loss 0.4548 (1.8946) lr 9.7553e-03 eta 2:12:20
epoch [4/30] batch [620/796] time 0.352 (0.380) data 0.000 (0.001) loss 4.9961 (1.9026) lr 9.7553e-03 eta 2:12:08
epoch [4/30] batch [640/796] time 0.391 (0.380) data 0.000 (0.001) loss 0.8306 (1.8975) lr 9.7553e-03 eta 2:12:01
epoch [4/30] batch [660/796] time 0.395 (0.380) data 0.000 (0.001) loss 4.8477 (1.8999) lr 9.7553e-03 eta 2:11:53
epoch [4/30] batch [680/796] time 0.360 (0.380) data 0.000 (0.001) loss 4.8438 (1.9108) lr 9.7553e-03 eta 2:11:48
epoch [4/30] batch [700/796] time 0.395 (0.380) data 0.000 (0.001) loss 4.8086 (1.9367) lr 9.7553e-03 eta 2:11:44
epoch [4/30] batch [720/796] time 0.385 (0.380) data 0.000 (0.001) loss 3.2168 (1.9408) lr 9.7553e-03 eta 2:11:38
epoch [4/30] batch [740/796] time 0.411 (0.380) data 0.000 (0.001) loss 1.2744 (1.9501) lr 9.7553e-03 eta 2:11:27
epoch [4/30] batch [760/796] time 0.370 (0.380) data 0.000 (0.001) loss 3.8301 (1.9586) lr 9.7553e-03 eta 2:11:18
epoch [4/30] batch [780/796] time 0.342 (0.379) data 0.000 (0.001) loss 1.3008 (1.9490) lr 9.7553e-03 eta 2:10:55
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:43,  5.47s/it] 10%|█         | 2/20 [00:06<00:51,  2.87s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.69s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:07<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.15it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.42it/s] 50%|█████     | 10/20 [00:08<00:03,  2.76it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.01it/s] 60%|██████    | 12/20 [00:09<00:02,  3.19it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.36it/s] 70%|███████   | 14/20 [00:09<00:01,  3.65it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.96it/s] 80%|████████  | 16/20 [00:10<00:00,  4.14it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.07it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.80it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.18it/s]100%|██████████| 20/20 [00:11<00:00,  4.57it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,554
* accuracy: 78.1%
* error: 21.9%
* macro_f1: 77.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/796] time 0.363 (0.425) data 0.000 (0.033) loss 2.3184 (1.9919) lr 9.5677e-03 eta 2:26:29
epoch [5/30] batch [40/796] time 0.393 (0.403) data 0.000 (0.017) loss 0.3811 (2.0991) lr 9.5677e-03 eta 2:18:46
epoch [5/30] batch [60/796] time 0.378 (0.395) data 0.000 (0.011) loss 1.5020 (2.1431) lr 9.5677e-03 eta 2:15:57
epoch [5/30] batch [80/796] time 0.384 (0.390) data 0.000 (0.009) loss 0.5303 (2.0642) lr 9.5677e-03 eta 2:14:09
epoch [5/30] batch [100/796] time 0.402 (0.389) data 0.000 (0.007) loss 0.5488 (2.0009) lr 9.5677e-03 eta 2:13:30
epoch [5/30] batch [120/796] time 0.399 (0.387) data 0.000 (0.006) loss 2.7129 (2.0556) lr 9.5677e-03 eta 2:12:51
epoch [5/30] batch [140/796] time 0.351 (0.386) data 0.000 (0.005) loss 2.5605 (2.0362) lr 9.5677e-03 eta 2:12:08
epoch [5/30] batch [160/796] time 0.356 (0.385) data 0.000 (0.004) loss 0.6982 (2.0262) lr 9.5677e-03 eta 2:11:40
epoch [5/30] batch [180/796] time 0.401 (0.385) data 0.000 (0.004) loss 2.5996 (1.9560) lr 9.5677e-03 eta 2:11:47
epoch [5/30] batch [200/796] time 0.376 (0.385) data 0.000 (0.004) loss 2.0977 (1.9474) lr 9.5677e-03 eta 2:11:37
epoch [5/30] batch [220/796] time 0.392 (0.384) data 0.000 (0.003) loss 0.9580 (1.9683) lr 9.5677e-03 eta 2:11:03
epoch [5/30] batch [240/796] time 0.349 (0.383) data 0.000 (0.003) loss 1.2666 (1.9647) lr 9.5677e-03 eta 2:10:43
epoch [5/30] batch [260/796] time 0.377 (0.383) data 0.000 (0.003) loss 1.1250 (1.9496) lr 9.5677e-03 eta 2:10:25
epoch [5/30] batch [280/796] time 0.366 (0.382) data 0.000 (0.003) loss 4.8633 (1.9182) lr 9.5677e-03 eta 2:10:03
epoch [5/30] batch [300/796] time 0.374 (0.382) data 0.001 (0.002) loss 3.2285 (1.9025) lr 9.5677e-03 eta 2:09:48
epoch [5/30] batch [320/796] time 0.354 (0.382) data 0.000 (0.002) loss 3.1562 (1.9028) lr 9.5677e-03 eta 2:09:49
epoch [5/30] batch [340/796] time 0.367 (0.382) data 0.000 (0.002) loss 1.6816 (1.9025) lr 9.5677e-03 eta 2:09:32
epoch [5/30] batch [360/796] time 0.364 (0.381) data 0.000 (0.002) loss 0.1108 (1.9023) lr 9.5677e-03 eta 2:09:16
epoch [5/30] batch [380/796] time 0.383 (0.381) data 0.000 (0.002) loss 0.0863 (1.8907) lr 9.5677e-03 eta 2:09:00
epoch [5/30] batch [400/796] time 0.364 (0.381) data 0.000 (0.002) loss 1.4941 (1.8659) lr 9.5677e-03 eta 2:08:52
epoch [5/30] batch [420/796] time 0.355 (0.381) data 0.000 (0.002) loss 6.9805 (1.8921) lr 9.5677e-03 eta 2:08:46
epoch [5/30] batch [440/796] time 0.384 (0.381) data 0.000 (0.002) loss 2.5703 (1.9202) lr 9.5677e-03 eta 2:08:40
epoch [5/30] batch [460/796] time 0.390 (0.381) data 0.000 (0.002) loss 2.4277 (1.9407) lr 9.5677e-03 eta 2:08:35
epoch [5/30] batch [480/796] time 0.398 (0.381) data 0.000 (0.002) loss 2.6973 (1.9655) lr 9.5677e-03 eta 2:08:24
epoch [5/30] batch [500/796] time 0.381 (0.381) data 0.000 (0.002) loss 1.4922 (1.9652) lr 9.5677e-03 eta 2:08:15
epoch [5/30] batch [520/796] time 0.403 (0.381) data 0.000 (0.002) loss 0.4355 (1.9718) lr 9.5677e-03 eta 2:08:09
epoch [5/30] batch [540/796] time 0.363 (0.381) data 0.000 (0.001) loss 0.9619 (1.9608) lr 9.5677e-03 eta 2:07:58
epoch [5/30] batch [560/796] time 0.391 (0.381) data 0.000 (0.001) loss 2.1621 (1.9622) lr 9.5677e-03 eta 2:07:49
epoch [5/30] batch [580/796] time 0.384 (0.381) data 0.000 (0.001) loss 4.8633 (1.9667) lr 9.5677e-03 eta 2:07:43
epoch [5/30] batch [600/796] time 0.365 (0.381) data 0.000 (0.001) loss 1.6631 (1.9464) lr 9.5677e-03 eta 2:07:33
epoch [5/30] batch [620/796] time 0.399 (0.381) data 0.000 (0.001) loss 2.5449 (1.9501) lr 9.5677e-03 eta 2:07:32
epoch [5/30] batch [640/796] time 0.365 (0.381) data 0.000 (0.001) loss 2.8398 (1.9581) lr 9.5677e-03 eta 2:07:25
epoch [5/30] batch [660/796] time 0.411 (0.381) data 0.000 (0.001) loss 4.6211 (1.9527) lr 9.5677e-03 eta 2:07:17
epoch [5/30] batch [680/796] time 0.404 (0.381) data 0.000 (0.001) loss 1.1230 (1.9461) lr 9.5677e-03 eta 2:07:09
epoch [5/30] batch [700/796] time 0.356 (0.381) data 0.000 (0.001) loss 0.8774 (1.9463) lr 9.5677e-03 eta 2:06:58
epoch [5/30] batch [720/796] time 0.402 (0.381) data 0.000 (0.001) loss 1.8076 (1.9422) lr 9.5677e-03 eta 2:06:49
epoch [5/30] batch [740/796] time 0.368 (0.381) data 0.000 (0.001) loss 2.8340 (1.9506) lr 9.5677e-03 eta 2:06:42
epoch [5/30] batch [760/796] time 0.383 (0.381) data 0.000 (0.001) loss 2.1348 (1.9609) lr 9.5677e-03 eta 2:06:26
epoch [5/30] batch [780/796] time 0.342 (0.380) data 0.000 (0.001) loss 0.7441 (1.9515) lr 9.5677e-03 eta 2:06:03
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.65s/it] 10%|█         | 2/20 [00:06<00:47,  2.65s/it] 15%|█▌        | 3/20 [00:06<00:26,  1.57s/it] 20%|██        | 4/20 [00:06<00:17,  1.07s/it] 25%|██▌       | 5/20 [00:07<00:11,  1.26it/s] 30%|███       | 6/20 [00:07<00:08,  1.60it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.93it/s] 40%|████      | 8/20 [00:07<00:05,  2.25it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.54it/s] 50%|█████     | 10/20 [00:08<00:03,  2.76it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.93it/s] 60%|██████    | 12/20 [00:09<00:02,  3.08it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.30it/s] 70%|███████   | 14/20 [00:09<00:01,  3.58it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.68it/s] 80%|████████  | 16/20 [00:10<00:01,  3.72it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.92it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.29it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.59it/s]100%|██████████| 20/20 [00:10<00:00,  4.91it/s]100%|██████████| 20/20 [00:10<00:00,  1.82it/s]=> result
* total: 1,990
* correct: 1,556
* accuracy: 78.2%
* error: 21.8%
* macro_f1: 77.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/796] time 0.348 (0.420) data 0.000 (0.042) loss 0.8159 (1.5735) lr 9.3301e-03 eta 2:19:05
epoch [6/30] batch [40/796] time 0.364 (0.398) data 0.000 (0.021) loss 1.6504 (1.4649) lr 9.3301e-03 eta 2:11:43
epoch [6/30] batch [60/796] time 0.366 (0.395) data 0.000 (0.014) loss 1.3574 (1.7652) lr 9.3301e-03 eta 2:10:31
epoch [6/30] batch [80/796] time 0.415 (0.391) data 0.000 (0.011) loss 0.3459 (1.7220) lr 9.3301e-03 eta 2:09:18
epoch [6/30] batch [100/796] time 0.388 (0.390) data 0.000 (0.009) loss 0.5464 (1.7848) lr 9.3301e-03 eta 2:08:34
epoch [6/30] batch [120/796] time 0.414 (0.388) data 0.000 (0.007) loss 0.5488 (1.7893) lr 9.3301e-03 eta 2:07:54
epoch [6/30] batch [140/796] time 0.392 (0.387) data 0.000 (0.006) loss 3.1602 (1.9104) lr 9.3301e-03 eta 2:07:32
epoch [6/30] batch [160/796] time 0.388 (0.387) data 0.000 (0.005) loss 3.3672 (1.9637) lr 9.3301e-03 eta 2:07:13
epoch [6/30] batch [180/796] time 0.362 (0.386) data 0.000 (0.005) loss 1.3291 (1.9197) lr 9.3301e-03 eta 2:06:54
epoch [6/30] batch [200/796] time 0.387 (0.386) data 0.000 (0.004) loss 1.1152 (1.8967) lr 9.3301e-03 eta 2:06:38
epoch [6/30] batch [220/796] time 0.396 (0.385) data 0.000 (0.004) loss 0.2854 (1.8159) lr 9.3301e-03 eta 2:06:18
epoch [6/30] batch [240/796] time 0.400 (0.385) data 0.000 (0.004) loss 0.9565 (1.8055) lr 9.3301e-03 eta 2:06:04
epoch [6/30] batch [260/796] time 0.356 (0.384) data 0.000 (0.003) loss 1.2031 (1.8052) lr 9.3301e-03 eta 2:05:35
epoch [6/30] batch [280/796] time 0.400 (0.383) data 0.001 (0.003) loss 0.3760 (1.7793) lr 9.3301e-03 eta 2:05:16
epoch [6/30] batch [300/796] time 0.384 (0.383) data 0.000 (0.003) loss 1.7031 (1.7628) lr 9.3301e-03 eta 2:05:14
epoch [6/30] batch [320/796] time 0.351 (0.383) data 0.000 (0.003) loss 1.4141 (1.7739) lr 9.3301e-03 eta 2:04:56
epoch [6/30] batch [340/796] time 0.383 (0.382) data 0.000 (0.003) loss 1.0869 (1.7755) lr 9.3301e-03 eta 2:04:37
epoch [6/30] batch [360/796] time 0.412 (0.382) data 0.000 (0.003) loss 1.6182 (1.7976) lr 9.3301e-03 eta 2:04:20
epoch [6/30] batch [380/796] time 0.373 (0.382) data 0.000 (0.002) loss 0.8496 (1.7848) lr 9.3301e-03 eta 2:04:07
epoch [6/30] batch [400/796] time 0.348 (0.381) data 0.000 (0.002) loss 2.7363 (1.8337) lr 9.3301e-03 eta 2:03:56
epoch [6/30] batch [420/796] time 0.361 (0.381) data 0.000 (0.002) loss 0.2035 (1.8327) lr 9.3301e-03 eta 2:03:48
epoch [6/30] batch [440/796] time 0.362 (0.381) data 0.000 (0.002) loss 3.1973 (1.8489) lr 9.3301e-03 eta 2:03:34
epoch [6/30] batch [460/796] time 0.367 (0.381) data 0.000 (0.002) loss 1.1113 (1.8453) lr 9.3301e-03 eta 2:03:23
epoch [6/30] batch [480/796] time 0.364 (0.381) data 0.000 (0.002) loss 5.4141 (1.8540) lr 9.3301e-03 eta 2:03:17
epoch [6/30] batch [500/796] time 0.399 (0.381) data 0.000 (0.002) loss 0.3022 (1.8460) lr 9.3301e-03 eta 2:03:08
epoch [6/30] batch [520/796] time 0.398 (0.381) data 0.000 (0.002) loss 2.0918 (1.8341) lr 9.3301e-03 eta 2:02:58
epoch [6/30] batch [540/796] time 0.354 (0.381) data 0.000 (0.002) loss 2.6914 (1.8265) lr 9.3301e-03 eta 2:02:53
epoch [6/30] batch [560/796] time 0.375 (0.381) data 0.000 (0.002) loss 0.7153 (1.8357) lr 9.3301e-03 eta 2:02:40
epoch [6/30] batch [580/796] time 0.379 (0.380) data 0.000 (0.002) loss 1.4053 (1.8348) lr 9.3301e-03 eta 2:02:29
epoch [6/30] batch [600/796] time 0.411 (0.380) data 0.000 (0.002) loss 2.0488 (1.8245) lr 9.3301e-03 eta 2:02:18
epoch [6/30] batch [620/796] time 0.398 (0.381) data 0.000 (0.002) loss 1.1172 (1.8329) lr 9.3301e-03 eta 2:02:17
epoch [6/30] batch [640/796] time 0.394 (0.380) data 0.000 (0.002) loss 3.1035 (1.8367) lr 9.3301e-03 eta 2:02:06
epoch [6/30] batch [660/796] time 0.396 (0.381) data 0.000 (0.002) loss 1.5010 (1.8558) lr 9.3301e-03 eta 2:02:01
epoch [6/30] batch [680/796] time 0.398 (0.380) data 0.000 (0.001) loss 1.5635 (1.8559) lr 9.3301e-03 eta 2:01:50
epoch [6/30] batch [700/796] time 0.355 (0.380) data 0.000 (0.001) loss 5.5664 (1.8595) lr 9.3301e-03 eta 2:01:42
epoch [6/30] batch [720/796] time 0.417 (0.380) data 0.000 (0.001) loss 5.5625 (1.8656) lr 9.3301e-03 eta 2:01:31
epoch [6/30] batch [740/796] time 0.408 (0.380) data 0.000 (0.001) loss 3.6289 (1.8662) lr 9.3301e-03 eta 2:01:25
epoch [6/30] batch [760/796] time 0.370 (0.380) data 0.000 (0.001) loss 1.8418 (1.8675) lr 9.3301e-03 eta 2:01:15
epoch [6/30] batch [780/796] time 0.345 (0.379) data 0.000 (0.001) loss 3.6445 (1.8958) lr 9.3301e-03 eta 2:00:53
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.67s/it] 10%|█         | 2/20 [00:06<00:51,  2.87s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.69s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.87it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.96it/s] 60%|██████    | 12/20 [00:09<00:02,  3.26it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.52it/s] 70%|███████   | 14/20 [00:09<00:01,  3.64it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.74it/s] 80%|████████  | 16/20 [00:10<00:01,  3.93it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.94it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.79it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.18it/s]100%|██████████| 20/20 [00:11<00:00,  4.57it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,554
* accuracy: 78.1%
* error: 21.9%
* macro_f1: 77.3%

epoch [7/30] batch [20/796] time 0.379 (0.423) data 0.001 (0.033) loss 3.9141 (1.9034) lr 9.0451e-03 eta 2:14:33
epoch [7/30] batch [40/796] time 0.364 (0.399) data 0.000 (0.017) loss 0.4368 (1.8396) lr 9.0451e-03 eta 2:06:52
epoch [7/30] batch [60/796] time 0.348 (0.393) data 0.000 (0.011) loss 1.1562 (1.8356) lr 9.0451e-03 eta 2:04:36
epoch [7/30] batch [80/796] time 0.369 (0.388) data 0.000 (0.009) loss 2.0215 (1.7965) lr 9.0451e-03 eta 2:02:57
epoch [7/30] batch [100/796] time 0.383 (0.386) data 0.000 (0.007) loss 4.0664 (1.8086) lr 9.0451e-03 eta 2:02:08
epoch [7/30] batch [120/796] time 0.382 (0.384) data 0.000 (0.006) loss 0.8813 (1.7674) lr 9.0451e-03 eta 2:01:35
epoch [7/30] batch [140/796] time 0.370 (0.383) data 0.000 (0.005) loss 2.4258 (1.8140) lr 9.0451e-03 eta 2:01:12
epoch [7/30] batch [160/796] time 0.375 (0.382) data 0.000 (0.004) loss 1.5977 (1.8278) lr 9.0451e-03 eta 2:00:46
epoch [7/30] batch [180/796] time 0.407 (0.382) data 0.000 (0.004) loss 1.3418 (1.8122) lr 9.0451e-03 eta 2:00:38
epoch [7/30] batch [200/796] time 0.394 (0.383) data 0.000 (0.004) loss 0.5938 (1.8325) lr 9.0451e-03 eta 2:00:34
epoch [7/30] batch [220/796] time 0.404 (0.382) data 0.000 (0.003) loss 2.6406 (1.8443) lr 9.0451e-03 eta 2:00:19
epoch [7/30] batch [240/796] time 0.350 (0.382) data 0.000 (0.003) loss 1.2031 (1.8966) lr 9.0451e-03 eta 2:00:08
epoch [7/30] batch [260/796] time 0.347 (0.382) data 0.000 (0.003) loss 4.3711 (1.9023) lr 9.0451e-03 eta 1:59:53
epoch [7/30] batch [280/796] time 0.351 (0.382) data 0.000 (0.003) loss 1.1904 (1.8709) lr 9.0451e-03 eta 1:59:52
epoch [7/30] batch [300/796] time 0.370 (0.382) data 0.000 (0.002) loss 0.1531 (1.8869) lr 9.0451e-03 eta 1:59:47
epoch [7/30] batch [320/796] time 0.383 (0.382) data 0.000 (0.002) loss 2.6621 (1.9061) lr 9.0451e-03 eta 1:59:38
epoch [7/30] batch [340/796] time 0.408 (0.382) data 0.000 (0.002) loss 0.9775 (1.8628) lr 9.0451e-03 eta 1:59:18
epoch [7/30] batch [360/796] time 0.350 (0.382) data 0.000 (0.002) loss 3.1133 (1.8678) lr 9.0451e-03 eta 1:59:12
epoch [7/30] batch [380/796] time 0.354 (0.382) data 0.000 (0.002) loss 1.0195 (1.8950) lr 9.0451e-03 eta 1:59:05
epoch [7/30] batch [400/796] time 0.355 (0.382) data 0.000 (0.002) loss 0.4788 (1.8735) lr 9.0451e-03 eta 1:58:56
epoch [7/30] batch [420/796] time 0.344 (0.381) data 0.001 (0.002) loss 2.4668 (1.8762) lr 9.0451e-03 eta 1:58:40
epoch [7/30] batch [440/796] time 0.348 (0.381) data 0.000 (0.002) loss 1.4727 (1.8733) lr 9.0451e-03 eta 1:58:29
epoch [7/30] batch [460/796] time 0.403 (0.381) data 0.000 (0.002) loss 1.9043 (1.8523) lr 9.0451e-03 eta 1:58:17
epoch [7/30] batch [480/796] time 0.359 (0.381) data 0.000 (0.002) loss 3.2070 (1.8306) lr 9.0451e-03 eta 1:58:13
epoch [7/30] batch [500/796] time 0.388 (0.381) data 0.000 (0.002) loss 1.7188 (1.8248) lr 9.0451e-03 eta 1:58:07
epoch [7/30] batch [520/796] time 0.389 (0.381) data 0.000 (0.002) loss 2.1562 (1.8162) lr 9.0451e-03 eta 1:58:04
epoch [7/30] batch [540/796] time 0.346 (0.381) data 0.000 (0.001) loss 1.2529 (1.8237) lr 9.0451e-03 eta 1:57:56
epoch [7/30] batch [560/796] time 0.383 (0.381) data 0.000 (0.001) loss 3.0547 (1.8212) lr 9.0451e-03 eta 1:57:46
epoch [7/30] batch [580/796] time 0.394 (0.381) data 0.000 (0.001) loss 1.4238 (1.8218) lr 9.0451e-03 eta 1:57:42
epoch [7/30] batch [600/796] time 0.401 (0.381) data 0.000 (0.001) loss 1.9492 (1.8344) lr 9.0451e-03 eta 1:57:28
epoch [7/30] batch [620/796] time 0.379 (0.381) data 0.000 (0.001) loss 0.8579 (1.8376) lr 9.0451e-03 eta 1:57:21
epoch [7/30] batch [640/796] time 0.392 (0.381) data 0.000 (0.001) loss 2.0059 (1.8479) lr 9.0451e-03 eta 1:57:10
epoch [7/30] batch [660/796] time 0.355 (0.381) data 0.000 (0.001) loss 2.2207 (1.8492) lr 9.0451e-03 eta 1:56:58
epoch [7/30] batch [680/796] time 0.395 (0.380) data 0.000 (0.001) loss 0.3081 (1.8545) lr 9.0451e-03 eta 1:56:49
epoch [7/30] batch [700/796] time 0.401 (0.380) data 0.000 (0.001) loss 0.7051 (1.8464) lr 9.0451e-03 eta 1:56:37
epoch [7/30] batch [720/796] time 0.377 (0.380) data 0.000 (0.001) loss 3.2441 (1.8526) lr 9.0451e-03 eta 1:56:31
epoch [7/30] batch [740/796] time 0.354 (0.380) data 0.000 (0.001) loss 0.0330 (1.8430) lr 9.0451e-03 eta 1:56:21
epoch [7/30] batch [760/796] time 0.396 (0.380) data 0.000 (0.001) loss 2.3281 (1.8443) lr 9.0451e-03 eta 1:56:12
epoch [7/30] batch [780/796] time 0.340 (0.379) data 0.000 (0.001) loss 3.5469 (1.8432) lr 9.0451e-03 eta 1:55:48
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:43,  5.46s/it] 10%|█         | 2/20 [00:06<00:50,  2.82s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.67s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.87it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.01it/s] 60%|██████    | 12/20 [00:09<00:02,  3.21it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.35it/s] 70%|███████   | 14/20 [00:09<00:01,  3.62it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.82it/s] 80%|████████  | 16/20 [00:10<00:01,  3.98it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.04it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.00it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.35it/s]100%|██████████| 20/20 [00:11<00:00,  4.71it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,572
* accuracy: 79.0%
* error: 21.0%
* macro_f1: 78.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/796] time 0.398 (0.425) data 0.000 (0.038) loss 0.4451 (1.9268) lr 8.7157e-03 eta 2:09:37
epoch [8/30] batch [40/796] time 0.363 (0.400) data 0.000 (0.019) loss 4.8438 (1.7961) lr 8.7157e-03 eta 2:01:42
epoch [8/30] batch [60/796] time 0.399 (0.393) data 0.000 (0.013) loss 2.4922 (1.8660) lr 8.7157e-03 eta 1:59:30
epoch [8/30] batch [80/796] time 0.379 (0.390) data 0.000 (0.010) loss 3.1230 (1.8541) lr 8.7157e-03 eta 1:58:34
epoch [8/30] batch [100/796] time 0.353 (0.387) data 0.000 (0.008) loss 2.9648 (1.9366) lr 8.7157e-03 eta 1:57:29
epoch [8/30] batch [120/796] time 0.370 (0.385) data 0.000 (0.006) loss 0.2612 (1.8689) lr 8.7157e-03 eta 1:56:51
epoch [8/30] batch [140/796] time 0.361 (0.384) data 0.000 (0.006) loss 5.9062 (1.8614) lr 8.7157e-03 eta 1:56:18
epoch [8/30] batch [160/796] time 0.407 (0.385) data 0.000 (0.005) loss 3.6152 (1.8598) lr 8.7157e-03 eta 1:56:18
epoch [8/30] batch [180/796] time 0.350 (0.384) data 0.000 (0.004) loss 0.2286 (1.8551) lr 8.7157e-03 eta 1:56:05
epoch [8/30] batch [200/796] time 0.395 (0.384) data 0.000 (0.004) loss 2.2480 (1.8449) lr 8.7157e-03 eta 1:55:59
epoch [8/30] batch [220/796] time 0.405 (0.384) data 0.000 (0.004) loss 1.9482 (1.8752) lr 8.7157e-03 eta 1:55:52
epoch [8/30] batch [240/796] time 0.356 (0.384) data 0.000 (0.003) loss 0.4004 (1.8650) lr 8.7157e-03 eta 1:55:45
epoch [8/30] batch [260/796] time 0.375 (0.384) data 0.000 (0.003) loss 2.1387 (1.8576) lr 8.7157e-03 eta 1:55:31
epoch [8/30] batch [280/796] time 0.375 (0.384) data 0.000 (0.003) loss 1.3652 (1.8919) lr 8.7157e-03 eta 1:55:15
epoch [8/30] batch [300/796] time 0.396 (0.384) data 0.000 (0.003) loss 2.0020 (1.8949) lr 8.7157e-03 eta 1:55:06
epoch [8/30] batch [320/796] time 0.372 (0.383) data 0.000 (0.003) loss 4.4688 (1.8899) lr 8.7157e-03 eta 1:54:53
epoch [8/30] batch [340/796] time 0.370 (0.383) data 0.000 (0.002) loss 3.6855 (1.8918) lr 8.7157e-03 eta 1:54:42
epoch [8/30] batch [360/796] time 0.353 (0.383) data 0.000 (0.002) loss 7.0039 (1.9167) lr 8.7157e-03 eta 1:54:28
epoch [8/30] batch [380/796] time 0.399 (0.383) data 0.000 (0.002) loss 2.0430 (1.9134) lr 8.7157e-03 eta 1:54:17
epoch [8/30] batch [400/796] time 0.417 (0.382) data 0.000 (0.002) loss 1.8564 (1.9056) lr 8.7157e-03 eta 1:54:09
epoch [8/30] batch [420/796] time 0.365 (0.383) data 0.000 (0.002) loss 4.8438 (1.9028) lr 8.7157e-03 eta 1:54:02
epoch [8/30] batch [440/796] time 0.351 (0.382) data 0.000 (0.002) loss 2.7168 (1.8851) lr 8.7157e-03 eta 1:53:44
epoch [8/30] batch [460/796] time 0.344 (0.382) data 0.000 (0.002) loss 0.4390 (1.8814) lr 8.7157e-03 eta 1:53:35
epoch [8/30] batch [480/796] time 0.388 (0.382) data 0.000 (0.002) loss 0.4580 (1.8853) lr 8.7157e-03 eta 1:53:27
epoch [8/30] batch [500/796] time 0.366 (0.382) data 0.000 (0.002) loss 1.5234 (1.8711) lr 8.7157e-03 eta 1:53:16
epoch [8/30] batch [520/796] time 0.368 (0.381) data 0.000 (0.002) loss 6.2539 (1.8737) lr 8.7157e-03 eta 1:53:05
epoch [8/30] batch [540/796] time 0.358 (0.381) data 0.000 (0.002) loss 1.7305 (1.8712) lr 8.7157e-03 eta 1:52:55
epoch [8/30] batch [560/796] time 0.345 (0.381) data 0.000 (0.002) loss 0.4790 (1.8521) lr 8.7157e-03 eta 1:52:50
epoch [8/30] batch [580/796] time 0.366 (0.381) data 0.000 (0.002) loss 5.6641 (1.8555) lr 8.7157e-03 eta 1:52:41
epoch [8/30] batch [600/796] time 0.356 (0.381) data 0.000 (0.001) loss 0.3523 (1.8549) lr 8.7157e-03 eta 1:52:31
epoch [8/30] batch [620/796] time 0.353 (0.381) data 0.000 (0.001) loss 2.4043 (1.8401) lr 8.7157e-03 eta 1:52:22
epoch [8/30] batch [640/796] time 0.397 (0.381) data 0.000 (0.001) loss 1.1562 (1.8380) lr 8.7157e-03 eta 1:52:19
epoch [8/30] batch [660/796] time 0.387 (0.381) data 0.000 (0.001) loss 0.2266 (1.8370) lr 8.7157e-03 eta 1:52:11
epoch [8/30] batch [680/796] time 0.389 (0.381) data 0.000 (0.001) loss 1.5049 (1.8325) lr 8.7157e-03 eta 1:52:04
epoch [8/30] batch [700/796] time 0.378 (0.382) data 0.000 (0.001) loss 1.9092 (1.8282) lr 8.7157e-03 eta 1:51:59
epoch [8/30] batch [720/796] time 0.392 (0.381) data 0.000 (0.001) loss 2.1074 (1.8146) lr 8.7157e-03 eta 1:51:47
epoch [8/30] batch [740/796] time 0.377 (0.381) data 0.000 (0.001) loss 1.6562 (1.8046) lr 8.7157e-03 eta 1:51:39
epoch [8/30] batch [760/796] time 0.393 (0.381) data 0.000 (0.001) loss 4.8945 (1.8135) lr 8.7157e-03 eta 1:51:30
epoch [8/30] batch [780/796] time 0.344 (0.380) data 0.000 (0.001) loss 1.5000 (1.8314) lr 8.7157e-03 eta 1:51:08
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.64s/it] 10%|█         | 2/20 [00:06<00:48,  2.69s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.60s/it] 20%|██        | 4/20 [00:06<00:17,  1.09s/it] 25%|██▌       | 5/20 [00:07<00:11,  1.25it/s] 30%|███       | 6/20 [00:07<00:08,  1.59it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.91it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.67it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.89it/s] 60%|██████    | 12/20 [00:09<00:02,  3.16it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.38it/s] 70%|███████   | 14/20 [00:09<00:01,  3.62it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.79it/s] 80%|████████  | 16/20 [00:10<00:01,  3.87it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.02it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.37it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.66it/s]100%|██████████| 20/20 [00:10<00:00,  4.96it/s]100%|██████████| 20/20 [00:11<00:00,  1.81it/s]=> result
* total: 1,990
* correct: 1,568
* accuracy: 78.8%
* error: 21.2%
* macro_f1: 78.1%

epoch [9/30] batch [20/796] time 0.349 (0.431) data 0.000 (0.051) loss 2.8652 (1.9128) lr 8.3457e-03 eta 2:05:31
epoch [9/30] batch [40/796] time 0.397 (0.406) data 0.000 (0.026) loss 2.4492 (1.9179) lr 8.3457e-03 eta 1:58:20
epoch [9/30] batch [60/796] time 0.363 (0.396) data 0.000 (0.017) loss 0.3508 (1.8081) lr 8.3457e-03 eta 1:55:16
epoch [9/30] batch [80/796] time 0.353 (0.393) data 0.000 (0.013) loss 0.7979 (1.7307) lr 8.3457e-03 eta 1:54:09
epoch [9/30] batch [100/796] time 0.368 (0.391) data 0.000 (0.010) loss 2.4863 (1.6481) lr 8.3457e-03 eta 1:53:23
epoch [9/30] batch [120/796] time 0.365 (0.389) data 0.000 (0.009) loss 0.5068 (1.6557) lr 8.3457e-03 eta 1:52:44
epoch [9/30] batch [140/796] time 0.393 (0.388) data 0.000 (0.008) loss 1.1553 (1.6523) lr 8.3457e-03 eta 1:52:21
epoch [9/30] batch [160/796] time 0.361 (0.387) data 0.000 (0.007) loss 0.2122 (1.6730) lr 8.3457e-03 eta 1:51:48
epoch [9/30] batch [180/796] time 0.416 (0.386) data 0.000 (0.006) loss 1.4424 (1.7160) lr 8.3457e-03 eta 1:51:30
epoch [9/30] batch [200/796] time 0.382 (0.385) data 0.000 (0.005) loss 2.6113 (1.7547) lr 8.3457e-03 eta 1:51:12
epoch [9/30] batch [220/796] time 0.388 (0.384) data 0.001 (0.005) loss 2.3652 (1.7666) lr 8.3457e-03 eta 1:50:40
epoch [9/30] batch [240/796] time 0.406 (0.384) data 0.000 (0.005) loss 0.5659 (1.7567) lr 8.3457e-03 eta 1:50:32
epoch [9/30] batch [260/796] time 0.355 (0.383) data 0.000 (0.004) loss 0.4075 (1.7283) lr 8.3457e-03 eta 1:50:14
epoch [9/30] batch [280/796] time 0.384 (0.383) data 0.000 (0.004) loss 2.3457 (1.7488) lr 8.3457e-03 eta 1:50:05
epoch [9/30] batch [300/796] time 0.407 (0.383) data 0.000 (0.004) loss 3.8906 (1.7574) lr 8.3457e-03 eta 1:49:53
epoch [9/30] batch [320/796] time 0.392 (0.383) data 0.000 (0.003) loss 3.7871 (1.7222) lr 8.3457e-03 eta 1:49:45
epoch [9/30] batch [340/796] time 0.385 (0.382) data 0.000 (0.003) loss 2.7734 (1.7184) lr 8.3457e-03 eta 1:49:27
epoch [9/30] batch [360/796] time 0.343 (0.382) data 0.000 (0.003) loss 2.8438 (1.7302) lr 8.3457e-03 eta 1:49:09
epoch [9/30] batch [380/796] time 0.388 (0.382) data 0.000 (0.003) loss 1.1484 (1.7404) lr 8.3457e-03 eta 1:48:56
epoch [9/30] batch [400/796] time 0.365 (0.381) data 0.000 (0.003) loss 0.6167 (1.7379) lr 8.3457e-03 eta 1:48:44
epoch [9/30] batch [420/796] time 0.380 (0.381) data 0.000 (0.003) loss 0.9458 (1.7407) lr 8.3457e-03 eta 1:48:35
epoch [9/30] batch [440/796] time 0.364 (0.381) data 0.000 (0.003) loss 1.6777 (1.7324) lr 8.3457e-03 eta 1:48:21
epoch [9/30] batch [460/796] time 0.388 (0.381) data 0.000 (0.002) loss 0.9414 (1.7319) lr 8.3457e-03 eta 1:48:10
epoch [9/30] batch [480/796] time 0.394 (0.380) data 0.000 (0.002) loss 1.3252 (1.7169) lr 8.3457e-03 eta 1:48:00
epoch [9/30] batch [500/796] time 0.363 (0.380) data 0.000 (0.002) loss 1.6094 (1.7338) lr 8.3457e-03 eta 1:47:50
epoch [9/30] batch [520/796] time 0.387 (0.380) data 0.000 (0.002) loss 4.4414 (1.7503) lr 8.3457e-03 eta 1:47:38
epoch [9/30] batch [540/796] time 0.368 (0.380) data 0.000 (0.002) loss 0.9360 (1.7480) lr 8.3457e-03 eta 1:47:29
epoch [9/30] batch [560/796] time 0.364 (0.380) data 0.000 (0.002) loss 0.2969 (1.7406) lr 8.3457e-03 eta 1:47:24
epoch [9/30] batch [580/796] time 0.362 (0.380) data 0.000 (0.002) loss 1.8750 (1.7561) lr 8.3457e-03 eta 1:47:16
epoch [9/30] batch [600/796] time 0.385 (0.380) data 0.000 (0.002) loss 1.2031 (1.7443) lr 8.3457e-03 eta 1:47:12
epoch [9/30] batch [620/796] time 0.372 (0.380) data 0.000 (0.002) loss 2.6465 (1.7460) lr 8.3457e-03 eta 1:47:07
epoch [9/30] batch [640/796] time 0.395 (0.380) data 0.000 (0.002) loss 1.0010 (1.7450) lr 8.3457e-03 eta 1:46:56
epoch [9/30] batch [660/796] time 0.398 (0.380) data 0.000 (0.002) loss 3.5840 (1.7731) lr 8.3457e-03 eta 1:46:49
epoch [9/30] batch [680/796] time 0.361 (0.380) data 0.000 (0.002) loss 2.5820 (1.7814) lr 8.3457e-03 eta 1:46:43
epoch [9/30] batch [700/796] time 0.395 (0.380) data 0.000 (0.002) loss 1.9004 (1.7812) lr 8.3457e-03 eta 1:46:35
epoch [9/30] batch [720/796] time 0.369 (0.380) data 0.000 (0.002) loss 3.3926 (1.7861) lr 8.3457e-03 eta 1:46:24
epoch [9/30] batch [740/796] time 0.346 (0.380) data 0.000 (0.002) loss 0.5840 (1.7958) lr 8.3457e-03 eta 1:46:16
epoch [9/30] batch [760/796] time 0.371 (0.380) data 0.000 (0.002) loss 0.7749 (1.7889) lr 8.3457e-03 eta 1:46:10
epoch [9/30] batch [780/796] time 0.339 (0.379) data 0.000 (0.002) loss 1.2393 (1.7762) lr 8.3457e-03 eta 1:45:48
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:49,  5.78s/it] 10%|█         | 2/20 [00:06<00:53,  2.97s/it] 15%|█▌        | 3/20 [00:07<00:29,  1.75s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.16it/s] 30%|███       | 6/20 [00:07<00:09,  1.50it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.84it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:09<00:03,  2.71it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.04it/s] 60%|██████    | 12/20 [00:09<00:02,  3.28it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.57it/s] 70%|███████   | 14/20 [00:10<00:01,  3.66it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.95it/s] 80%|████████  | 16/20 [00:10<00:01,  3.91it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.98it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.76it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.16it/s]100%|██████████| 20/20 [00:11<00:00,  4.55it/s]100%|██████████| 20/20 [00:11<00:00,  1.73it/s]=> result
* total: 1,990
* correct: 1,578
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 78.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/796] time 0.367 (0.424) data 0.000 (0.035) loss 0.0923 (1.9289) lr 7.9389e-03 eta 1:57:53
epoch [10/30] batch [40/796] time 0.351 (0.404) data 0.000 (0.018) loss 0.3113 (1.7708) lr 7.9389e-03 eta 1:52:17
epoch [10/30] batch [60/796] time 0.368 (0.394) data 0.000 (0.012) loss 1.2607 (1.6589) lr 7.9389e-03 eta 1:49:26
epoch [10/30] batch [80/796] time 0.401 (0.390) data 0.000 (0.009) loss 0.7490 (1.6231) lr 7.9389e-03 eta 1:48:03
epoch [10/30] batch [100/796] time 0.400 (0.386) data 0.000 (0.007) loss 5.2656 (1.5189) lr 7.9389e-03 eta 1:46:57
epoch [10/30] batch [120/796] time 0.369 (0.385) data 0.000 (0.006) loss 1.7168 (1.6037) lr 7.9389e-03 eta 1:46:28
epoch [10/30] batch [140/796] time 0.368 (0.384) data 0.000 (0.005) loss 1.8086 (1.7066) lr 7.9389e-03 eta 1:46:03
epoch [10/30] batch [160/796] time 0.363 (0.383) data 0.000 (0.005) loss 1.5664 (1.6864) lr 7.9389e-03 eta 1:45:45
epoch [10/30] batch [180/796] time 0.377 (0.383) data 0.000 (0.004) loss 0.2365 (1.7187) lr 7.9389e-03 eta 1:45:39
epoch [10/30] batch [200/796] time 0.399 (0.384) data 0.000 (0.004) loss 0.7368 (1.7420) lr 7.9389e-03 eta 1:45:36
epoch [10/30] batch [220/796] time 0.354 (0.383) data 0.000 (0.003) loss 2.1055 (1.7553) lr 7.9389e-03 eta 1:45:24
epoch [10/30] batch [240/796] time 0.377 (0.383) data 0.000 (0.003) loss 3.5254 (1.7329) lr 7.9389e-03 eta 1:45:18
epoch [10/30] batch [260/796] time 0.367 (0.383) data 0.000 (0.003) loss 0.6250 (1.7703) lr 7.9389e-03 eta 1:45:01
epoch [10/30] batch [280/796] time 0.411 (0.383) data 0.000 (0.003) loss 1.0674 (1.7303) lr 7.9389e-03 eta 1:44:55
epoch [10/30] batch [300/796] time 0.362 (0.383) data 0.000 (0.003) loss 0.5781 (1.7237) lr 7.9389e-03 eta 1:44:46
epoch [10/30] batch [320/796] time 0.379 (0.382) data 0.000 (0.002) loss 0.2959 (1.7231) lr 7.9389e-03 eta 1:44:30
epoch [10/30] batch [340/796] time 0.385 (0.383) data 0.000 (0.002) loss 1.8721 (1.7532) lr 7.9389e-03 eta 1:44:26
epoch [10/30] batch [360/796] time 0.349 (0.382) data 0.000 (0.002) loss 2.7090 (1.7570) lr 7.9389e-03 eta 1:44:14
epoch [10/30] batch [380/796] time 0.380 (0.382) data 0.000 (0.002) loss 3.0176 (1.7684) lr 7.9389e-03 eta 1:43:57
epoch [10/30] batch [400/796] time 0.378 (0.382) data 0.000 (0.002) loss 0.8140 (1.7541) lr 7.9389e-03 eta 1:43:46
epoch [10/30] batch [420/796] time 0.362 (0.381) data 0.000 (0.002) loss 0.9839 (1.7639) lr 7.9389e-03 eta 1:43:31
epoch [10/30] batch [440/796] time 0.375 (0.381) data 0.000 (0.002) loss 2.4277 (1.7528) lr 7.9389e-03 eta 1:43:18
epoch [10/30] batch [460/796] time 0.386 (0.381) data 0.000 (0.002) loss 0.3452 (1.7666) lr 7.9389e-03 eta 1:43:10
epoch [10/30] batch [480/796] time 0.353 (0.381) data 0.000 (0.002) loss 1.1748 (1.7599) lr 7.9389e-03 eta 1:43:03
epoch [10/30] batch [500/796] time 0.349 (0.381) data 0.000 (0.002) loss 2.8555 (1.7539) lr 7.9389e-03 eta 1:42:57
epoch [10/30] batch [520/796] time 0.379 (0.381) data 0.000 (0.002) loss 1.0459 (1.7500) lr 7.9389e-03 eta 1:42:47
epoch [10/30] batch [540/796] time 0.382 (0.381) data 0.000 (0.002) loss 4.5195 (1.7416) lr 7.9389e-03 eta 1:42:40
epoch [10/30] batch [560/796] time 0.356 (0.380) data 0.000 (0.002) loss 2.6699 (1.7516) lr 7.9389e-03 eta 1:42:26
epoch [10/30] batch [580/796] time 0.350 (0.381) data 0.000 (0.001) loss 0.5996 (1.7581) lr 7.9389e-03 eta 1:42:22
epoch [10/30] batch [600/796] time 0.356 (0.380) data 0.000 (0.001) loss 0.7954 (1.7644) lr 7.9389e-03 eta 1:42:11
epoch [10/30] batch [620/796] time 0.390 (0.380) data 0.000 (0.001) loss 1.3672 (1.7841) lr 7.9389e-03 eta 1:42:01
epoch [10/30] batch [640/796] time 0.380 (0.380) data 0.000 (0.001) loss 2.7598 (1.7882) lr 7.9389e-03 eta 1:41:52
epoch [10/30] batch [660/796] time 0.351 (0.380) data 0.000 (0.001) loss 1.9756 (1.7852) lr 7.9389e-03 eta 1:41:43
epoch [10/30] batch [680/796] time 0.370 (0.380) data 0.000 (0.001) loss 2.4473 (1.7848) lr 7.9389e-03 eta 1:41:32
epoch [10/30] batch [700/796] time 0.349 (0.380) data 0.000 (0.001) loss 3.1719 (1.8086) lr 7.9389e-03 eta 1:41:22
epoch [10/30] batch [720/796] time 0.379 (0.380) data 0.000 (0.001) loss 0.3845 (1.8081) lr 7.9389e-03 eta 1:41:14
epoch [10/30] batch [740/796] time 0.396 (0.380) data 0.000 (0.001) loss 1.4072 (1.8082) lr 7.9389e-03 eta 1:41:11
epoch [10/30] batch [760/796] time 0.362 (0.380) data 0.000 (0.001) loss 0.8003 (1.7967) lr 7.9389e-03 eta 1:41:05
epoch [10/30] batch [780/796] time 0.340 (0.379) data 0.000 (0.001) loss 2.2422 (1.8088) lr 7.9389e-03 eta 1:40:44
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.54s/it] 10%|█         | 2/20 [00:06<00:50,  2.78s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.65s/it] 20%|██        | 4/20 [00:06<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:08,  1.56it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.93it/s] 60%|██████    | 12/20 [00:09<00:02,  3.19it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.36it/s] 70%|███████   | 14/20 [00:09<00:01,  3.50it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.80it/s] 80%|████████  | 16/20 [00:10<00:01,  3.97it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.05it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.26it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.57it/s]100%|██████████| 20/20 [00:11<00:00,  4.88it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,574
* accuracy: 79.1%
* error: 20.9%
* macro_f1: 78.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/796] time 0.383 (0.417) data 0.000 (0.039) loss 2.0078 (2.4647) lr 7.5000e-03 eta 1:50:32
epoch [11/30] batch [40/796] time 0.385 (0.401) data 0.000 (0.020) loss 3.0625 (2.3476) lr 7.5000e-03 eta 1:46:10
epoch [11/30] batch [60/796] time 0.421 (0.394) data 0.000 (0.013) loss 0.7939 (2.1330) lr 7.5000e-03 eta 1:44:05
epoch [11/30] batch [80/796] time 0.381 (0.390) data 0.000 (0.010) loss 1.3105 (1.9870) lr 7.5000e-03 eta 1:42:56
epoch [11/30] batch [100/796] time 0.409 (0.387) data 0.000 (0.008) loss 2.7891 (2.0079) lr 7.5000e-03 eta 1:42:03
epoch [11/30] batch [120/796] time 0.398 (0.386) data 0.000 (0.007) loss 3.2227 (1.9659) lr 7.5000e-03 eta 1:41:41
epoch [11/30] batch [140/796] time 0.393 (0.385) data 0.000 (0.006) loss 0.2131 (1.9153) lr 7.5000e-03 eta 1:41:17
epoch [11/30] batch [160/796] time 0.390 (0.384) data 0.000 (0.005) loss 0.8066 (1.8747) lr 7.5000e-03 eta 1:40:58
epoch [11/30] batch [180/796] time 0.388 (0.385) data 0.000 (0.005) loss 1.9170 (1.8818) lr 7.5000e-03 eta 1:40:58
epoch [11/30] batch [200/796] time 0.397 (0.385) data 0.000 (0.004) loss 0.1102 (1.8982) lr 7.5000e-03 eta 1:40:52
epoch [11/30] batch [220/796] time 0.377 (0.385) data 0.000 (0.004) loss 2.1562 (1.8750) lr 7.5000e-03 eta 1:40:38
epoch [11/30] batch [240/796] time 0.359 (0.384) data 0.000 (0.003) loss 1.5586 (1.8690) lr 7.5000e-03 eta 1:40:21
epoch [11/30] batch [260/796] time 0.402 (0.383) data 0.000 (0.003) loss 0.2710 (1.8598) lr 7.5000e-03 eta 1:39:56
epoch [11/30] batch [280/796] time 0.379 (0.383) data 0.000 (0.003) loss 0.8569 (1.9006) lr 7.5000e-03 eta 1:39:49
epoch [11/30] batch [300/796] time 0.397 (0.383) data 0.000 (0.003) loss 1.2803 (1.9070) lr 7.5000e-03 eta 1:39:40
epoch [11/30] batch [320/796] time 0.408 (0.383) data 0.000 (0.003) loss 1.3623 (1.8934) lr 7.5000e-03 eta 1:39:40
epoch [11/30] batch [340/796] time 0.369 (0.383) data 0.000 (0.003) loss 1.4004 (1.8806) lr 7.5000e-03 eta 1:39:27
epoch [11/30] batch [360/796] time 0.375 (0.383) data 0.000 (0.002) loss 6.8555 (1.8864) lr 7.5000e-03 eta 1:39:13
epoch [11/30] batch [380/796] time 0.356 (0.382) data 0.000 (0.002) loss 1.5957 (1.8885) lr 7.5000e-03 eta 1:39:00
epoch [11/30] batch [400/796] time 0.384 (0.382) data 0.000 (0.002) loss 1.1289 (1.8682) lr 7.5000e-03 eta 1:38:51
epoch [11/30] batch [420/796] time 0.370 (0.382) data 0.000 (0.002) loss 0.8887 (1.8426) lr 7.5000e-03 eta 1:38:38
epoch [11/30] batch [440/796] time 0.393 (0.382) data 0.000 (0.002) loss 0.6641 (1.8418) lr 7.5000e-03 eta 1:38:28
epoch [11/30] batch [460/796] time 0.406 (0.382) data 0.000 (0.002) loss 3.6582 (1.8436) lr 7.5000e-03 eta 1:38:24
epoch [11/30] batch [480/796] time 0.363 (0.382) data 0.000 (0.002) loss 1.7334 (1.8281) lr 7.5000e-03 eta 1:38:12
epoch [11/30] batch [500/796] time 0.373 (0.381) data 0.000 (0.002) loss 0.2091 (1.8335) lr 7.5000e-03 eta 1:38:02
epoch [11/30] batch [520/796] time 0.347 (0.381) data 0.000 (0.002) loss 1.0898 (1.8135) lr 7.5000e-03 eta 1:37:54
epoch [11/30] batch [540/796] time 0.368 (0.381) data 0.000 (0.002) loss 0.7671 (1.8111) lr 7.5000e-03 eta 1:37:46
epoch [11/30] batch [560/796] time 0.344 (0.381) data 0.000 (0.002) loss 1.4053 (1.8043) lr 7.5000e-03 eta 1:37:35
epoch [11/30] batch [580/796] time 0.367 (0.381) data 0.000 (0.002) loss 0.2698 (1.8025) lr 7.5000e-03 eta 1:37:26
epoch [11/30] batch [600/796] time 0.400 (0.381) data 0.000 (0.002) loss 2.2773 (1.8109) lr 7.5000e-03 eta 1:37:20
epoch [11/30] batch [620/796] time 0.372 (0.381) data 0.000 (0.001) loss 0.0962 (1.8011) lr 7.5000e-03 eta 1:37:07
epoch [11/30] batch [640/796] time 0.363 (0.381) data 0.000 (0.001) loss 0.6753 (1.7971) lr 7.5000e-03 eta 1:36:59
epoch [11/30] batch [660/796] time 0.369 (0.381) data 0.000 (0.001) loss 3.7617 (1.8028) lr 7.5000e-03 eta 1:36:52
epoch [11/30] batch [680/796] time 0.390 (0.381) data 0.000 (0.001) loss 1.4209 (1.7998) lr 7.5000e-03 eta 1:36:41
epoch [11/30] batch [700/796] time 0.350 (0.380) data 0.000 (0.001) loss 2.2715 (1.7899) lr 7.5000e-03 eta 1:36:30
epoch [11/30] batch [720/796] time 0.396 (0.380) data 0.000 (0.001) loss 1.2207 (1.8029) lr 7.5000e-03 eta 1:36:23
epoch [11/30] batch [740/796] time 0.391 (0.380) data 0.000 (0.001) loss 1.1660 (1.8063) lr 7.5000e-03 eta 1:36:11
epoch [11/30] batch [760/796] time 0.393 (0.380) data 0.000 (0.001) loss 4.7773 (1.8080) lr 7.5000e-03 eta 1:36:04
epoch [11/30] batch [780/796] time 0.339 (0.379) data 0.000 (0.001) loss 3.3672 (1.8164) lr 7.5000e-03 eta 1:35:44
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.52s/it] 10%|█         | 2/20 [00:06<00:50,  2.81s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.66s/it] 20%|██        | 4/20 [00:07<00:17,  1.12s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.90it/s] 60%|██████    | 12/20 [00:09<00:02,  3.21it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.54it/s] 70%|███████   | 14/20 [00:09<00:01,  3.75it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.92it/s] 80%|████████  | 16/20 [00:10<00:00,  4.17it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.10it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.29it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.74it/s]100%|██████████| 20/20 [00:11<00:00,  4.19it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,584
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 78.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [12/30] batch [20/796] time 0.392 (0.434) data 0.000 (0.048) loss 0.6519 (1.8692) lr 7.0337e-03 eta 1:49:16
epoch [12/30] batch [40/796] time 0.359 (0.408) data 0.000 (0.024) loss 0.4058 (1.7637) lr 7.0337e-03 eta 1:42:34
epoch [12/30] batch [60/796] time 0.386 (0.400) data 0.000 (0.016) loss 5.7148 (1.9166) lr 7.0337e-03 eta 1:40:21
epoch [12/30] batch [80/796] time 0.385 (0.394) data 0.000 (0.012) loss 3.0293 (1.8639) lr 7.0337e-03 eta 1:38:54
epoch [12/30] batch [100/796] time 0.358 (0.389) data 0.000 (0.010) loss 2.6250 (1.8231) lr 7.0337e-03 eta 1:37:19
epoch [12/30] batch [120/796] time 0.370 (0.388) data 0.000 (0.008) loss 2.2051 (1.7963) lr 7.0337e-03 eta 1:36:59
epoch [12/30] batch [140/796] time 0.394 (0.386) data 0.000 (0.007) loss 2.5723 (1.7907) lr 7.0337e-03 eta 1:36:22
epoch [12/30] batch [160/796] time 0.373 (0.385) data 0.000 (0.006) loss 3.0410 (1.8331) lr 7.0337e-03 eta 1:35:54
epoch [12/30] batch [180/796] time 0.389 (0.384) data 0.000 (0.006) loss 3.6602 (1.7937) lr 7.0337e-03 eta 1:35:37
epoch [12/30] batch [200/796] time 0.384 (0.384) data 0.000 (0.005) loss 2.1055 (1.8324) lr 7.0337e-03 eta 1:35:24
epoch [12/30] batch [220/796] time 0.391 (0.384) data 0.000 (0.005) loss 1.6396 (1.8446) lr 7.0337e-03 eta 1:35:17
epoch [12/30] batch [240/796] time 0.385 (0.383) data 0.000 (0.004) loss 0.2346 (1.8460) lr 7.0337e-03 eta 1:35:00
epoch [12/30] batch [260/796] time 0.396 (0.383) data 0.000 (0.004) loss 3.4414 (1.8506) lr 7.0337e-03 eta 1:34:59
epoch [12/30] batch [280/796] time 0.347 (0.383) data 0.000 (0.004) loss 3.2520 (1.8230) lr 7.0337e-03 eta 1:34:43
epoch [12/30] batch [300/796] time 0.359 (0.383) data 0.000 (0.003) loss 0.1796 (1.8247) lr 7.0337e-03 eta 1:34:35
epoch [12/30] batch [320/796] time 0.351 (0.383) data 0.000 (0.003) loss 3.1992 (1.8398) lr 7.0337e-03 eta 1:34:27
epoch [12/30] batch [340/796] time 0.366 (0.383) data 0.000 (0.003) loss 8.4453 (1.8391) lr 7.0337e-03 eta 1:34:19
epoch [12/30] batch [360/796] time 0.356 (0.383) data 0.000 (0.003) loss 0.4397 (1.8213) lr 7.0337e-03 eta 1:34:08
epoch [12/30] batch [380/796] time 0.368 (0.382) data 0.000 (0.003) loss 4.4688 (1.8403) lr 7.0337e-03 eta 1:33:55
epoch [12/30] batch [400/796] time 0.380 (0.382) data 0.000 (0.003) loss 1.7734 (1.8627) lr 7.0337e-03 eta 1:33:44
epoch [12/30] batch [420/796] time 0.392 (0.382) data 0.000 (0.003) loss 0.7344 (1.8298) lr 7.0337e-03 eta 1:33:34
epoch [12/30] batch [440/796] time 0.363 (0.381) data 0.000 (0.002) loss 1.8799 (1.8136) lr 7.0337e-03 eta 1:33:20
epoch [12/30] batch [460/796] time 0.359 (0.381) data 0.000 (0.002) loss 1.1953 (1.8109) lr 7.0337e-03 eta 1:33:11
epoch [12/30] batch [480/796] time 0.356 (0.381) data 0.000 (0.002) loss 2.3848 (1.8020) lr 7.0337e-03 eta 1:33:05
epoch [12/30] batch [500/796] time 0.383 (0.381) data 0.000 (0.002) loss 0.5659 (1.7932) lr 7.0337e-03 eta 1:32:56
epoch [12/30] batch [520/796] time 0.414 (0.381) data 0.000 (0.002) loss 1.3584 (1.7945) lr 7.0337e-03 eta 1:32:48
epoch [12/30] batch [540/796] time 0.384 (0.381) data 0.000 (0.002) loss 2.8672 (1.8133) lr 7.0337e-03 eta 1:32:38
epoch [12/30] batch [560/796] time 0.402 (0.381) data 0.000 (0.002) loss 1.3018 (1.7932) lr 7.0337e-03 eta 1:32:25
epoch [12/30] batch [580/796] time 0.397 (0.381) data 0.000 (0.002) loss 1.2891 (1.7854) lr 7.0337e-03 eta 1:32:18
epoch [12/30] batch [600/796] time 0.346 (0.381) data 0.000 (0.002) loss 2.6543 (1.7662) lr 7.0337e-03 eta 1:32:10
epoch [12/30] batch [620/796] time 0.379 (0.381) data 0.000 (0.002) loss 2.7832 (1.7557) lr 7.0337e-03 eta 1:32:00
epoch [12/30] batch [640/796] time 0.360 (0.380) data 0.000 (0.002) loss 1.2031 (1.7479) lr 7.0337e-03 eta 1:31:51
epoch [12/30] batch [660/796] time 0.394 (0.380) data 0.000 (0.002) loss 5.9922 (1.7612) lr 7.0337e-03 eta 1:31:41
epoch [12/30] batch [680/796] time 0.383 (0.381) data 0.000 (0.002) loss 0.5239 (1.7671) lr 7.0337e-03 eta 1:31:37
epoch [12/30] batch [700/796] time 0.399 (0.381) data 0.000 (0.002) loss 4.0898 (1.7815) lr 7.0337e-03 eta 1:31:28
epoch [12/30] batch [720/796] time 0.399 (0.381) data 0.000 (0.002) loss 2.1953 (1.7800) lr 7.0337e-03 eta 1:31:20
epoch [12/30] batch [740/796] time 0.361 (0.381) data 0.000 (0.002) loss 1.3213 (1.7733) lr 7.0337e-03 eta 1:31:14
epoch [12/30] batch [760/796] time 0.357 (0.381) data 0.000 (0.002) loss 0.2896 (1.7600) lr 7.0337e-03 eta 1:31:06
epoch [12/30] batch [780/796] time 0.340 (0.380) data 0.000 (0.001) loss 2.2031 (1.7528) lr 7.0337e-03 eta 1:30:46
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:43,  5.44s/it] 10%|█         | 2/20 [00:06<00:51,  2.87s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.76it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.06it/s] 60%|██████    | 12/20 [00:09<00:02,  3.33it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.53it/s] 70%|███████   | 14/20 [00:09<00:01,  3.64it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.72it/s] 80%|████████  | 16/20 [00:10<00:01,  3.88it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.88it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.08it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.43it/s]100%|██████████| 20/20 [00:11<00:00,  4.77it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,589
* accuracy: 79.8%
* error: 20.2%
* macro_f1: 79.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [13/30] batch [20/796] time 0.377 (0.424) data 0.000 (0.033) loss 0.2051 (1.7917) lr 6.5451e-03 eta 1:41:11
epoch [13/30] batch [40/796] time 0.366 (0.401) data 0.000 (0.017) loss 1.5801 (1.6028) lr 6.5451e-03 eta 1:35:32
epoch [13/30] batch [60/796] time 0.406 (0.395) data 0.000 (0.011) loss 2.5645 (1.7225) lr 6.5451e-03 eta 1:33:53
epoch [13/30] batch [80/796] time 0.369 (0.390) data 0.000 (0.008) loss 0.8511 (1.6159) lr 6.5451e-03 eta 1:32:41
epoch [13/30] batch [100/796] time 0.365 (0.388) data 0.000 (0.007) loss 1.6211 (1.5512) lr 6.5451e-03 eta 1:32:07
epoch [13/30] batch [120/796] time 0.349 (0.388) data 0.000 (0.006) loss 4.8477 (1.6163) lr 6.5451e-03 eta 1:31:48
epoch [13/30] batch [140/796] time 0.384 (0.387) data 0.000 (0.005) loss 0.1151 (1.6270) lr 6.5451e-03 eta 1:31:31
epoch [13/30] batch [160/796] time 0.383 (0.387) data 0.000 (0.004) loss 2.5645 (1.6361) lr 6.5451e-03 eta 1:31:16
epoch [13/30] batch [180/796] time 0.372 (0.386) data 0.000 (0.004) loss 0.4490 (1.6159) lr 6.5451e-03 eta 1:31:02
epoch [13/30] batch [200/796] time 0.363 (0.385) data 0.000 (0.003) loss 2.2559 (1.6521) lr 6.5451e-03 eta 1:30:37
epoch [13/30] batch [220/796] time 0.369 (0.384) data 0.000 (0.003) loss 1.2168 (1.6168) lr 6.5451e-03 eta 1:30:14
epoch [13/30] batch [240/796] time 0.391 (0.384) data 0.000 (0.003) loss 3.4902 (1.6184) lr 6.5451e-03 eta 1:30:07
epoch [13/30] batch [260/796] time 0.404 (0.384) data 0.000 (0.003) loss 1.3027 (1.6476) lr 6.5451e-03 eta 1:29:56
epoch [13/30] batch [280/796] time 0.377 (0.383) data 0.000 (0.003) loss 1.4824 (1.6584) lr 6.5451e-03 eta 1:29:40
epoch [13/30] batch [300/796] time 0.360 (0.383) data 0.000 (0.002) loss 0.2739 (1.6417) lr 6.5451e-03 eta 1:29:36
epoch [13/30] batch [320/796] time 0.370 (0.383) data 0.000 (0.002) loss 0.9390 (1.6329) lr 6.5451e-03 eta 1:29:26
epoch [13/30] batch [340/796] time 0.399 (0.383) data 0.000 (0.002) loss 3.2422 (1.6246) lr 6.5451e-03 eta 1:29:16
epoch [13/30] batch [360/796] time 0.377 (0.383) data 0.000 (0.002) loss 1.8125 (1.6514) lr 6.5451e-03 eta 1:29:06
epoch [13/30] batch [380/796] time 0.351 (0.383) data 0.000 (0.002) loss 0.8599 (1.6719) lr 6.5451e-03 eta 1:28:59
epoch [13/30] batch [400/796] time 0.409 (0.383) data 0.000 (0.002) loss 0.9683 (1.6649) lr 6.5451e-03 eta 1:28:51
epoch [13/30] batch [420/796] time 0.364 (0.382) data 0.000 (0.002) loss 1.5547 (1.6502) lr 6.5451e-03 eta 1:28:35
epoch [13/30] batch [440/796] time 0.377 (0.382) data 0.000 (0.002) loss 2.5098 (1.6485) lr 6.5451e-03 eta 1:28:25
epoch [13/30] batch [460/796] time 0.397 (0.382) data 0.000 (0.002) loss 0.3125 (1.6253) lr 6.5451e-03 eta 1:28:14
epoch [13/30] batch [480/796] time 0.384 (0.382) data 0.000 (0.002) loss 0.3784 (1.6071) lr 6.5451e-03 eta 1:28:05
epoch [13/30] batch [500/796] time 0.391 (0.382) data 0.000 (0.002) loss 1.3389 (1.6196) lr 6.5451e-03 eta 1:28:01
epoch [13/30] batch [520/796] time 0.358 (0.382) data 0.000 (0.001) loss 0.4106 (1.6263) lr 6.5451e-03 eta 1:27:51
epoch [13/30] batch [540/796] time 0.387 (0.382) data 0.000 (0.001) loss 0.7183 (1.6301) lr 6.5451e-03 eta 1:27:41
epoch [13/30] batch [560/796] time 0.396 (0.382) data 0.000 (0.001) loss 2.3125 (1.6276) lr 6.5451e-03 eta 1:27:33
epoch [13/30] batch [580/796] time 0.366 (0.382) data 0.000 (0.001) loss 1.3838 (1.6494) lr 6.5451e-03 eta 1:27:26
epoch [13/30] batch [600/796] time 0.347 (0.381) data 0.000 (0.001) loss 2.2227 (1.6461) lr 6.5451e-03 eta 1:27:15
epoch [13/30] batch [620/796] time 0.363 (0.381) data 0.000 (0.001) loss 0.7520 (1.6402) lr 6.5451e-03 eta 1:27:06
epoch [13/30] batch [640/796] time 0.370 (0.381) data 0.000 (0.001) loss 2.3125 (1.6331) lr 6.5451e-03 eta 1:26:56
epoch [13/30] batch [660/796] time 0.348 (0.381) data 0.000 (0.001) loss 0.3162 (1.6314) lr 6.5451e-03 eta 1:26:47
epoch [13/30] batch [680/796] time 0.352 (0.381) data 0.000 (0.001) loss 0.8013 (1.6231) lr 6.5451e-03 eta 1:26:37
epoch [13/30] batch [700/796] time 0.407 (0.381) data 0.000 (0.001) loss 0.4028 (1.6381) lr 6.5451e-03 eta 1:26:30
epoch [13/30] batch [720/796] time 0.366 (0.381) data 0.000 (0.001) loss 0.7134 (1.6306) lr 6.5451e-03 eta 1:26:21
epoch [13/30] batch [740/796] time 0.352 (0.381) data 0.000 (0.001) loss 2.3438 (1.6309) lr 6.5451e-03 eta 1:26:11
epoch [13/30] batch [760/796] time 0.387 (0.381) data 0.000 (0.001) loss 2.4160 (1.6216) lr 6.5451e-03 eta 1:26:04
epoch [13/30] batch [780/796] time 0.344 (0.380) data 0.000 (0.001) loss 3.8242 (1.6277) lr 6.5451e-03 eta 1:25:46
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.50s/it] 10%|█         | 2/20 [00:06<00:49,  2.76s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.63s/it] 20%|██        | 4/20 [00:06<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.23it/s] 30%|███       | 6/20 [00:07<00:08,  1.57it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.92it/s] 40%|████      | 8/20 [00:08<00:05,  2.22it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.90it/s] 60%|██████    | 12/20 [00:09<00:02,  3.15it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.52it/s] 70%|███████   | 14/20 [00:09<00:01,  3.70it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.74it/s] 80%|████████  | 16/20 [00:10<00:01,  3.92it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.08it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.40it/s] 95%|█████████▌| 19/20 [00:10<00:00,  3.84it/s]100%|██████████| 20/20 [00:11<00:00,  4.28it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,589
* accuracy: 79.8%
* error: 20.2%
* macro_f1: 79.4%

epoch [14/30] batch [20/796] time 0.368 (0.425) data 0.000 (0.033) loss 0.4185 (1.3463) lr 6.0396e-03 eta 1:35:40
epoch [14/30] batch [40/796] time 0.424 (0.407) data 0.000 (0.017) loss 0.6006 (1.6166) lr 6.0396e-03 eta 1:31:34
epoch [14/30] batch [60/796] time 0.389 (0.395) data 0.000 (0.011) loss 2.7402 (1.6837) lr 6.0396e-03 eta 1:28:43
epoch [14/30] batch [80/796] time 0.363 (0.388) data 0.000 (0.009) loss 2.1055 (1.7055) lr 6.0396e-03 eta 1:27:02
epoch [14/30] batch [100/796] time 0.361 (0.388) data 0.000 (0.007) loss 4.0586 (1.8214) lr 6.0396e-03 eta 1:26:45
epoch [14/30] batch [120/796] time 0.364 (0.385) data 0.000 (0.006) loss 7.2578 (1.8382) lr 6.0396e-03 eta 1:26:07
epoch [14/30] batch [140/796] time 0.409 (0.385) data 0.000 (0.005) loss 0.4280 (1.7004) lr 6.0396e-03 eta 1:25:49
epoch [14/30] batch [160/796] time 0.354 (0.384) data 0.000 (0.004) loss 3.1094 (1.6993) lr 6.0396e-03 eta 1:25:38
epoch [14/30] batch [180/796] time 0.375 (0.383) data 0.000 (0.004) loss 0.5840 (1.7138) lr 6.0396e-03 eta 1:25:13
epoch [14/30] batch [200/796] time 0.360 (0.382) data 0.000 (0.004) loss 0.7329 (1.7230) lr 6.0396e-03 eta 1:24:58
epoch [14/30] batch [220/796] time 0.361 (0.382) data 0.000 (0.003) loss 0.7480 (1.7132) lr 6.0396e-03 eta 1:24:47
epoch [14/30] batch [240/796] time 0.371 (0.382) data 0.000 (0.003) loss 0.2465 (1.7020) lr 6.0396e-03 eta 1:24:34
epoch [14/30] batch [260/796] time 0.396 (0.382) data 0.000 (0.003) loss 3.8340 (1.6850) lr 6.0396e-03 eta 1:24:24
epoch [14/30] batch [280/796] time 0.388 (0.381) data 0.000 (0.003) loss 1.7041 (1.7109) lr 6.0396e-03 eta 1:24:08
epoch [14/30] batch [300/796] time 0.357 (0.381) data 0.000 (0.002) loss 1.1113 (1.7115) lr 6.0396e-03 eta 1:23:58
epoch [14/30] batch [320/796] time 0.355 (0.381) data 0.000 (0.002) loss 3.1445 (1.6993) lr 6.0396e-03 eta 1:23:47
epoch [14/30] batch [340/796] time 0.346 (0.380) data 0.000 (0.002) loss 4.4180 (1.7181) lr 6.0396e-03 eta 1:23:34
epoch [14/30] batch [360/796] time 0.383 (0.380) data 0.000 (0.002) loss 1.7207 (1.7115) lr 6.0396e-03 eta 1:23:28
epoch [14/30] batch [380/796] time 0.369 (0.380) data 0.000 (0.002) loss 1.0898 (1.6859) lr 6.0396e-03 eta 1:23:21
epoch [14/30] batch [400/796] time 0.394 (0.380) data 0.000 (0.002) loss 0.7192 (1.6716) lr 6.0396e-03 eta 1:23:08
epoch [14/30] batch [420/796] time 0.384 (0.380) data 0.000 (0.002) loss 2.4004 (1.6654) lr 6.0396e-03 eta 1:23:04
epoch [14/30] batch [440/796] time 0.357 (0.380) data 0.000 (0.002) loss 3.3184 (1.6891) lr 6.0396e-03 eta 1:22:54
epoch [14/30] batch [460/796] time 0.400 (0.380) data 0.000 (0.002) loss 1.9473 (1.6727) lr 6.0396e-03 eta 1:22:46
epoch [14/30] batch [480/796] time 0.379 (0.380) data 0.000 (0.002) loss 0.3291 (1.6844) lr 6.0396e-03 eta 1:22:41
epoch [14/30] batch [500/796] time 0.405 (0.380) data 0.000 (0.002) loss 2.6914 (1.6858) lr 6.0396e-03 eta 1:22:34
epoch [14/30] batch [520/796] time 0.391 (0.380) data 0.000 (0.002) loss 1.0938 (1.6884) lr 6.0396e-03 eta 1:22:30
epoch [14/30] batch [540/796] time 0.388 (0.380) data 0.000 (0.001) loss 2.2812 (1.6869) lr 6.0396e-03 eta 1:22:20
epoch [14/30] batch [560/796] time 0.383 (0.380) data 0.000 (0.001) loss 0.5430 (1.6765) lr 6.0396e-03 eta 1:22:08
epoch [14/30] batch [580/796] time 0.369 (0.380) data 0.000 (0.001) loss 1.8330 (1.6500) lr 6.0396e-03 eta 1:22:01
epoch [14/30] batch [600/796] time 0.360 (0.380) data 0.000 (0.001) loss 1.3330 (1.6577) lr 6.0396e-03 eta 1:21:52
epoch [14/30] batch [620/796] time 0.403 (0.380) data 0.000 (0.001) loss 0.8037 (1.6638) lr 6.0396e-03 eta 1:21:44
epoch [14/30] batch [640/796] time 0.410 (0.380) data 0.000 (0.001) loss 1.9424 (1.6755) lr 6.0396e-03 eta 1:21:36
epoch [14/30] batch [660/796] time 0.380 (0.380) data 0.000 (0.001) loss 1.8613 (1.6785) lr 6.0396e-03 eta 1:21:30
epoch [14/30] batch [680/796] time 0.395 (0.380) data 0.000 (0.001) loss 1.0967 (1.6696) lr 6.0396e-03 eta 1:21:25
epoch [14/30] batch [700/796] time 0.405 (0.380) data 0.000 (0.001) loss 0.4189 (1.6625) lr 6.0396e-03 eta 1:21:15
epoch [14/30] batch [720/796] time 0.363 (0.380) data 0.000 (0.001) loss 0.6279 (1.6481) lr 6.0396e-03 eta 1:21:07
epoch [14/30] batch [740/796] time 0.355 (0.380) data 0.000 (0.001) loss 3.1484 (1.6645) lr 6.0396e-03 eta 1:20:56
epoch [14/30] batch [760/796] time 0.384 (0.380) data 0.000 (0.001) loss 1.1172 (1.6616) lr 6.0396e-03 eta 1:20:48
epoch [14/30] batch [780/796] time 0.339 (0.379) data 0.000 (0.001) loss 2.0078 (1.6695) lr 6.0396e-03 eta 1:20:30
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:40,  5.30s/it] 10%|█         | 2/20 [00:06<00:52,  2.93s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.73s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.83it/s] 40%|████      | 8/20 [00:08<00:05,  2.14it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.41it/s] 50%|█████     | 10/20 [00:08<00:03,  2.68it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.96it/s] 60%|██████    | 12/20 [00:09<00:02,  3.12it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.34it/s] 70%|███████   | 14/20 [00:09<00:01,  3.60it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.91it/s] 80%|████████  | 16/20 [00:10<00:00,  4.09it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.19it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.28it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.58it/s]100%|██████████| 20/20 [00:11<00:00,  4.89it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,581
* accuracy: 79.4%
* error: 20.6%
* macro_f1: 79.0%

epoch [15/30] batch [20/796] time 0.360 (0.431) data 0.000 (0.035) loss 0.5874 (1.5379) lr 5.5226e-03 eta 1:31:15
epoch [15/30] batch [40/796] time 0.352 (0.404) data 0.000 (0.018) loss 0.5361 (1.5144) lr 5.5226e-03 eta 1:25:29
epoch [15/30] batch [60/796] time 0.391 (0.395) data 0.000 (0.012) loss 1.0586 (1.5751) lr 5.5226e-03 eta 1:23:24
epoch [15/30] batch [80/796] time 0.363 (0.391) data 0.000 (0.009) loss 0.9453 (1.6073) lr 5.5226e-03 eta 1:22:32
epoch [15/30] batch [100/796] time 0.347 (0.388) data 0.000 (0.007) loss 3.8965 (1.7061) lr 5.5226e-03 eta 1:21:44
epoch [15/30] batch [120/796] time 0.372 (0.387) data 0.000 (0.006) loss 0.4456 (1.6589) lr 5.5226e-03 eta 1:21:23
epoch [15/30] batch [140/796] time 0.395 (0.386) data 0.000 (0.005) loss 1.0918 (1.6657) lr 5.5226e-03 eta 1:20:55
epoch [15/30] batch [160/796] time 0.348 (0.385) data 0.000 (0.005) loss 1.9580 (1.6580) lr 5.5226e-03 eta 1:20:42
epoch [15/30] batch [180/796] time 0.395 (0.384) data 0.000 (0.004) loss 1.2344 (1.6597) lr 5.5226e-03 eta 1:20:18
epoch [15/30] batch [200/796] time 0.399 (0.384) data 0.000 (0.004) loss 2.9609 (1.6203) lr 5.5226e-03 eta 1:20:14
epoch [15/30] batch [220/796] time 0.411 (0.385) data 0.000 (0.003) loss 0.2406 (1.6015) lr 5.5226e-03 eta 1:20:13
epoch [15/30] batch [240/796] time 0.350 (0.385) data 0.000 (0.003) loss 1.2988 (1.5927) lr 5.5226e-03 eta 1:20:06
epoch [15/30] batch [260/796] time 0.365 (0.384) data 0.000 (0.003) loss 3.0215 (1.5913) lr 5.5226e-03 eta 1:19:54
epoch [15/30] batch [280/796] time 0.400 (0.384) data 0.000 (0.003) loss 1.3096 (1.5879) lr 5.5226e-03 eta 1:19:41
epoch [15/30] batch [300/796] time 0.402 (0.383) data 0.000 (0.003) loss 1.1055 (1.5703) lr 5.5226e-03 eta 1:19:23
epoch [15/30] batch [320/796] time 0.440 (0.383) data 0.000 (0.002) loss 1.5391 (1.5603) lr 5.5226e-03 eta 1:19:16
epoch [15/30] batch [340/796] time 0.390 (0.383) data 0.000 (0.002) loss 1.8223 (1.5699) lr 5.5226e-03 eta 1:19:02
epoch [15/30] batch [360/796] time 0.393 (0.382) data 0.000 (0.002) loss 1.5371 (1.5772) lr 5.5226e-03 eta 1:18:53
epoch [15/30] batch [380/796] time 0.396 (0.382) data 0.000 (0.002) loss 3.2754 (1.6110) lr 5.5226e-03 eta 1:18:43
epoch [15/30] batch [400/796] time 0.348 (0.382) data 0.000 (0.002) loss 0.5225 (1.5910) lr 5.5226e-03 eta 1:18:33
epoch [15/30] batch [420/796] time 0.385 (0.382) data 0.000 (0.002) loss 0.8730 (1.5644) lr 5.5226e-03 eta 1:18:23
epoch [15/30] batch [440/796] time 0.405 (0.382) data 0.000 (0.002) loss 0.3167 (1.5463) lr 5.5226e-03 eta 1:18:14
epoch [15/30] batch [460/796] time 0.349 (0.382) data 0.000 (0.002) loss 1.2725 (1.5577) lr 5.5226e-03 eta 1:18:08
epoch [15/30] batch [480/796] time 0.384 (0.382) data 0.000 (0.002) loss 2.0938 (1.5740) lr 5.5226e-03 eta 1:17:58
epoch [15/30] batch [500/796] time 0.353 (0.382) data 0.000 (0.002) loss 1.6943 (1.5819) lr 5.5226e-03 eta 1:17:50
epoch [15/30] batch [520/796] time 0.385 (0.382) data 0.000 (0.002) loss 1.4238 (1.5912) lr 5.5226e-03 eta 1:17:44
epoch [15/30] batch [540/796] time 0.364 (0.382) data 0.000 (0.002) loss 0.9463 (1.5927) lr 5.5226e-03 eta 1:17:35
epoch [15/30] batch [560/796] time 0.358 (0.382) data 0.000 (0.001) loss 1.1582 (1.6041) lr 5.5226e-03 eta 1:17:26
epoch [15/30] batch [580/796] time 0.347 (0.381) data 0.000 (0.001) loss 1.4268 (1.5996) lr 5.5226e-03 eta 1:17:15
epoch [15/30] batch [600/796] time 0.404 (0.381) data 0.000 (0.001) loss 0.9834 (1.6124) lr 5.5226e-03 eta 1:17:05
epoch [15/30] batch [620/796] time 0.383 (0.381) data 0.000 (0.001) loss 1.7715 (1.6037) lr 5.5226e-03 eta 1:16:59
epoch [15/30] batch [640/796] time 0.374 (0.381) data 0.000 (0.001) loss 0.7017 (1.6159) lr 5.5226e-03 eta 1:16:49
epoch [15/30] batch [660/796] time 0.390 (0.381) data 0.000 (0.001) loss 2.1016 (1.6053) lr 5.5226e-03 eta 1:16:41
epoch [15/30] batch [680/796] time 0.382 (0.381) data 0.000 (0.001) loss 1.5117 (1.5988) lr 5.5226e-03 eta 1:16:32
epoch [15/30] batch [700/796] time 0.403 (0.381) data 0.000 (0.001) loss 0.6465 (1.5984) lr 5.5226e-03 eta 1:16:26
epoch [15/30] batch [720/796] time 0.358 (0.381) data 0.000 (0.001) loss 2.6113 (1.6035) lr 5.5226e-03 eta 1:16:17
epoch [15/30] batch [740/796] time 0.366 (0.381) data 0.000 (0.001) loss 0.3760 (1.6169) lr 5.5226e-03 eta 1:16:10
epoch [15/30] batch [760/796] time 0.395 (0.381) data 0.000 (0.001) loss 1.9512 (1.6206) lr 5.5226e-03 eta 1:16:00
epoch [15/30] batch [780/796] time 0.340 (0.380) data 0.000 (0.001) loss 1.0059 (1.6082) lr 5.5226e-03 eta 1:15:43
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.68s/it] 10%|█         | 2/20 [00:06<00:52,  2.91s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.72s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.52it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.87it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.74it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.01it/s] 60%|██████    | 12/20 [00:09<00:02,  3.21it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.43it/s] 70%|███████   | 14/20 [00:09<00:01,  3.60it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.77it/s] 80%|████████  | 16/20 [00:10<00:01,  3.82it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.79it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.15it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.48it/s]100%|██████████| 20/20 [00:11<00:00,  4.81it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,594
* accuracy: 80.1%
* error: 19.9%
* macro_f1: 79.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [16/30] batch [20/796] time 0.403 (0.427) data 0.000 (0.041) loss 0.3975 (1.9257) lr 5.0000e-03 eta 1:24:50
epoch [16/30] batch [40/796] time 0.383 (0.401) data 0.000 (0.021) loss 0.2358 (1.7261) lr 5.0000e-03 eta 1:19:31
epoch [16/30] batch [60/796] time 0.380 (0.394) data 0.000 (0.014) loss 7.4258 (1.9316) lr 5.0000e-03 eta 1:17:57
epoch [16/30] batch [80/796] time 0.349 (0.389) data 0.000 (0.010) loss 0.8247 (1.8263) lr 5.0000e-03 eta 1:16:53
epoch [16/30] batch [100/796] time 0.385 (0.386) data 0.000 (0.008) loss 1.5566 (1.7806) lr 5.0000e-03 eta 1:16:07
epoch [16/30] batch [120/796] time 0.398 (0.386) data 0.000 (0.007) loss 1.2227 (1.7751) lr 5.0000e-03 eta 1:16:03
epoch [16/30] batch [140/796] time 0.376 (0.385) data 0.000 (0.006) loss 1.5801 (1.7456) lr 5.0000e-03 eta 1:15:48
epoch [16/30] batch [160/796] time 0.378 (0.385) data 0.000 (0.005) loss 0.8936 (1.6901) lr 5.0000e-03 eta 1:15:34
epoch [16/30] batch [180/796] time 0.361 (0.384) data 0.000 (0.005) loss 4.7422 (1.6611) lr 5.0000e-03 eta 1:15:21
epoch [16/30] batch [200/796] time 0.368 (0.384) data 0.000 (0.004) loss 1.6162 (1.6627) lr 5.0000e-03 eta 1:15:04
epoch [16/30] batch [220/796] time 0.402 (0.382) data 0.000 (0.004) loss 2.0254 (1.6285) lr 5.0000e-03 eta 1:14:42
epoch [16/30] batch [240/796] time 0.394 (0.382) data 0.000 (0.004) loss 1.4062 (1.6473) lr 5.0000e-03 eta 1:14:29
epoch [16/30] batch [260/796] time 0.369 (0.382) data 0.000 (0.003) loss 1.9307 (1.6497) lr 5.0000e-03 eta 1:14:17
epoch [16/30] batch [280/796] time 0.353 (0.381) data 0.000 (0.003) loss 0.7539 (1.6223) lr 5.0000e-03 eta 1:14:07
epoch [16/30] batch [300/796] time 0.378 (0.382) data 0.000 (0.003) loss 0.2019 (1.6079) lr 5.0000e-03 eta 1:14:03
epoch [16/30] batch [320/796] time 0.365 (0.381) data 0.000 (0.003) loss 4.3008 (1.6106) lr 5.0000e-03 eta 1:13:51
epoch [16/30] batch [340/796] time 0.346 (0.381) data 0.000 (0.003) loss 2.5547 (1.6015) lr 5.0000e-03 eta 1:13:41
epoch [16/30] batch [360/796] time 0.358 (0.381) data 0.000 (0.003) loss 1.2686 (1.6355) lr 5.0000e-03 eta 1:13:30
epoch [16/30] batch [380/796] time 0.366 (0.381) data 0.000 (0.002) loss 0.3738 (1.6224) lr 5.0000e-03 eta 1:13:21
epoch [16/30] batch [400/796] time 0.352 (0.380) data 0.000 (0.002) loss 1.3496 (1.6447) lr 5.0000e-03 eta 1:13:10
epoch [16/30] batch [420/796] time 0.372 (0.380) data 0.000 (0.002) loss 1.2793 (1.6562) lr 5.0000e-03 eta 1:13:01
epoch [16/30] batch [440/796] time 0.372 (0.380) data 0.000 (0.002) loss 0.4524 (1.6602) lr 5.0000e-03 eta 1:12:50
epoch [16/30] batch [460/796] time 0.387 (0.380) data 0.000 (0.002) loss 2.1758 (1.6634) lr 5.0000e-03 eta 1:12:42
epoch [16/30] batch [480/796] time 0.397 (0.380) data 0.000 (0.002) loss 0.0745 (1.6734) lr 5.0000e-03 eta 1:12:35
epoch [16/30] batch [500/796] time 0.401 (0.380) data 0.000 (0.002) loss 0.8159 (1.6768) lr 5.0000e-03 eta 1:12:27
epoch [16/30] batch [520/796] time 0.399 (0.380) data 0.001 (0.002) loss 1.4248 (1.6981) lr 5.0000e-03 eta 1:12:22
epoch [16/30] batch [540/796] time 0.401 (0.380) data 0.000 (0.002) loss 0.0925 (1.6741) lr 5.0000e-03 eta 1:12:16
epoch [16/30] batch [560/796] time 0.401 (0.381) data 0.000 (0.002) loss 3.1016 (1.6805) lr 5.0000e-03 eta 1:12:12
epoch [16/30] batch [580/796] time 0.402 (0.381) data 0.000 (0.002) loss 0.9663 (1.6651) lr 5.0000e-03 eta 1:12:06
epoch [16/30] batch [600/796] time 0.412 (0.381) data 0.000 (0.002) loss 0.5469 (1.6673) lr 5.0000e-03 eta 1:11:57
epoch [16/30] batch [620/796] time 0.401 (0.381) data 0.000 (0.002) loss 3.5020 (1.6848) lr 5.0000e-03 eta 1:11:47
epoch [16/30] batch [640/796] time 0.369 (0.380) data 0.000 (0.002) loss 1.0645 (1.6755) lr 5.0000e-03 eta 1:11:38
epoch [16/30] batch [660/796] time 0.368 (0.381) data 0.000 (0.001) loss 2.6250 (1.6762) lr 5.0000e-03 eta 1:11:32
epoch [16/30] batch [680/796] time 0.349 (0.381) data 0.000 (0.001) loss 0.8369 (1.6716) lr 5.0000e-03 eta 1:11:24
epoch [16/30] batch [700/796] time 0.384 (0.381) data 0.000 (0.001) loss 0.2844 (1.6685) lr 5.0000e-03 eta 1:11:18
epoch [16/30] batch [720/796] time 0.354 (0.380) data 0.000 (0.001) loss 0.5562 (1.6659) lr 5.0000e-03 eta 1:11:09
epoch [16/30] batch [740/796] time 0.388 (0.380) data 0.000 (0.001) loss 3.3730 (1.6658) lr 5.0000e-03 eta 1:11:01
epoch [16/30] batch [760/796] time 0.353 (0.380) data 0.000 (0.001) loss 1.7598 (1.6552) lr 5.0000e-03 eta 1:10:53
epoch [16/30] batch [780/796] time 0.340 (0.380) data 0.000 (0.001) loss 0.1686 (1.6593) lr 5.0000e-03 eta 1:10:36
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.52s/it] 10%|█         | 2/20 [00:06<00:51,  2.83s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.43it/s] 50%|█████     | 10/20 [00:08<00:03,  2.68it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.06it/s] 60%|██████    | 12/20 [00:09<00:02,  3.33it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.68it/s] 70%|███████   | 14/20 [00:09<00:01,  3.73it/s] 75%|███████▌  | 15/20 [00:09<00:01,  4.06it/s] 80%|████████  | 16/20 [00:10<00:00,  4.24it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.36it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.20it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.65it/s]100%|██████████| 20/20 [00:11<00:00,  4.12it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,617
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 80.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [17/30] batch [20/796] time 0.386 (0.422) data 0.000 (0.037) loss 0.2864 (1.3534) lr 4.4774e-03 eta 1:18:15
epoch [17/30] batch [40/796] time 0.390 (0.405) data 0.000 (0.018) loss 1.3604 (1.5307) lr 4.4774e-03 eta 1:14:52
epoch [17/30] batch [60/796] time 0.389 (0.393) data 0.000 (0.012) loss 0.7246 (1.4948) lr 4.4774e-03 eta 1:12:31
epoch [17/30] batch [80/796] time 0.349 (0.389) data 0.000 (0.009) loss 1.8770 (1.4647) lr 4.4774e-03 eta 1:11:44
epoch [17/30] batch [100/796] time 0.397 (0.388) data 0.000 (0.008) loss 0.3557 (1.5133) lr 4.4774e-03 eta 1:11:27
epoch [17/30] batch [120/796] time 0.348 (0.386) data 0.000 (0.006) loss 0.8013 (1.6039) lr 4.4774e-03 eta 1:10:56
epoch [17/30] batch [140/796] time 0.375 (0.384) data 0.000 (0.005) loss 0.6055 (1.6257) lr 4.4774e-03 eta 1:10:29
epoch [17/30] batch [160/796] time 0.349 (0.384) data 0.000 (0.005) loss 1.4648 (1.6517) lr 4.4774e-03 eta 1:10:16
epoch [17/30] batch [180/796] time 0.391 (0.384) data 0.000 (0.004) loss 1.3477 (1.6256) lr 4.4774e-03 eta 1:10:11
epoch [17/30] batch [200/796] time 0.385 (0.383) data 0.000 (0.004) loss 0.3784 (1.6407) lr 4.4774e-03 eta 1:09:54
epoch [17/30] batch [220/796] time 0.347 (0.383) data 0.000 (0.004) loss 1.6377 (1.6192) lr 4.4774e-03 eta 1:09:47
epoch [17/30] batch [240/796] time 0.396 (0.383) data 0.000 (0.003) loss 0.2751 (1.6369) lr 4.4774e-03 eta 1:09:32
epoch [17/30] batch [260/796] time 0.351 (0.382) data 0.000 (0.003) loss 0.7988 (1.6376) lr 4.4774e-03 eta 1:09:13
epoch [17/30] batch [280/796] time 0.411 (0.381) data 0.000 (0.003) loss 0.1931 (1.6466) lr 4.4774e-03 eta 1:09:03
epoch [17/30] batch [300/796] time 0.392 (0.381) data 0.000 (0.003) loss 0.5859 (1.6757) lr 4.4774e-03 eta 1:08:52
epoch [17/30] batch [320/796] time 0.422 (0.381) data 0.000 (0.003) loss 0.5981 (1.6752) lr 4.4774e-03 eta 1:08:43
epoch [17/30] batch [340/796] time 0.403 (0.381) data 0.000 (0.002) loss 0.6504 (1.6826) lr 4.4774e-03 eta 1:08:35
epoch [17/30] batch [360/796] time 0.385 (0.381) data 0.000 (0.002) loss 1.0645 (1.6797) lr 4.4774e-03 eta 1:08:25
epoch [17/30] batch [380/796] time 0.380 (0.381) data 0.000 (0.002) loss 1.6143 (1.6614) lr 4.4774e-03 eta 1:08:17
epoch [17/30] batch [400/796] time 0.404 (0.381) data 0.000 (0.002) loss 0.9175 (1.6622) lr 4.4774e-03 eta 1:08:13
epoch [17/30] batch [420/796] time 0.361 (0.381) data 0.000 (0.002) loss 0.6416 (1.6381) lr 4.4774e-03 eta 1:08:06
epoch [17/30] batch [440/796] time 0.380 (0.381) data 0.000 (0.002) loss 2.3242 (1.6322) lr 4.4774e-03 eta 1:07:59
epoch [17/30] batch [460/796] time 0.360 (0.381) data 0.000 (0.002) loss 1.6309 (1.6399) lr 4.4774e-03 eta 1:07:50
epoch [17/30] batch [480/796] time 0.392 (0.381) data 0.000 (0.002) loss 1.0908 (1.6371) lr 4.4774e-03 eta 1:07:42
epoch [17/30] batch [500/796] time 0.389 (0.381) data 0.000 (0.002) loss 1.4014 (1.6474) lr 4.4774e-03 eta 1:07:34
epoch [17/30] batch [520/796] time 0.381 (0.381) data 0.000 (0.002) loss 1.7637 (1.6599) lr 4.4774e-03 eta 1:07:24
epoch [17/30] batch [540/796] time 0.400 (0.381) data 0.000 (0.002) loss 4.9531 (1.6837) lr 4.4774e-03 eta 1:07:16
epoch [17/30] batch [560/796] time 0.354 (0.380) data 0.000 (0.002) loss 2.1035 (1.6822) lr 4.4774e-03 eta 1:07:06
epoch [17/30] batch [580/796] time 0.350 (0.380) data 0.000 (0.002) loss 2.4570 (1.6700) lr 4.4774e-03 eta 1:06:58
epoch [17/30] batch [600/796] time 0.400 (0.381) data 0.000 (0.001) loss 1.4805 (1.6663) lr 4.4774e-03 eta 1:06:52
epoch [17/30] batch [620/796] time 0.362 (0.381) data 0.000 (0.001) loss 0.1260 (1.6635) lr 4.4774e-03 eta 1:06:44
epoch [17/30] batch [640/796] time 0.378 (0.381) data 0.000 (0.001) loss 0.8843 (1.6545) lr 4.4774e-03 eta 1:06:36
epoch [17/30] batch [660/796] time 0.363 (0.380) data 0.000 (0.001) loss 0.0859 (1.6433) lr 4.4774e-03 eta 1:06:28
epoch [17/30] batch [680/796] time 0.418 (0.380) data 0.000 (0.001) loss 2.5508 (1.6504) lr 4.4774e-03 eta 1:06:21
epoch [17/30] batch [700/796] time 0.380 (0.380) data 0.000 (0.001) loss 0.4219 (1.6423) lr 4.4774e-03 eta 1:06:13
epoch [17/30] batch [720/796] time 0.363 (0.380) data 0.000 (0.001) loss 0.5894 (1.6387) lr 4.4774e-03 eta 1:06:04
epoch [17/30] batch [740/796] time 0.374 (0.380) data 0.000 (0.001) loss 0.7256 (1.6235) lr 4.4774e-03 eta 1:05:54
epoch [17/30] batch [760/796] time 0.366 (0.380) data 0.000 (0.001) loss 1.6553 (1.6129) lr 4.4774e-03 eta 1:05:46
epoch [17/30] batch [780/796] time 0.342 (0.379) data 0.000 (0.001) loss 0.8389 (1.6115) lr 4.4774e-03 eta 1:05:31
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.55s/it] 10%|█         | 2/20 [00:06<00:49,  2.73s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.62s/it] 20%|██        | 4/20 [00:06<00:17,  1.09s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.25it/s] 30%|███       | 6/20 [00:07<00:08,  1.59it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.91it/s] 40%|████      | 8/20 [00:08<00:05,  2.22it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.91it/s] 60%|██████    | 12/20 [00:09<00:02,  3.13it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.31it/s] 70%|███████   | 14/20 [00:09<00:01,  3.53it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.82it/s] 80%|████████  | 16/20 [00:10<00:01,  3.81it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.74it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.11it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.44it/s]100%|██████████| 20/20 [00:11<00:00,  4.78it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,608
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 80.5%

epoch [18/30] batch [20/796] time 0.375 (0.425) data 0.000 (0.034) loss 0.6450 (1.1843) lr 3.9604e-03 eta 1:13:08
epoch [18/30] batch [40/796] time 0.360 (0.401) data 0.000 (0.017) loss 1.0615 (1.2875) lr 3.9604e-03 eta 1:08:55
epoch [18/30] batch [60/796] time 0.349 (0.393) data 0.000 (0.011) loss 0.6279 (1.4713) lr 3.9604e-03 eta 1:07:20
epoch [18/30] batch [80/796] time 0.434 (0.389) data 0.000 (0.009) loss 2.5762 (1.4850) lr 3.9604e-03 eta 1:06:39
epoch [18/30] batch [100/796] time 0.406 (0.387) data 0.000 (0.007) loss 2.1230 (1.4541) lr 3.9604e-03 eta 1:06:10
epoch [18/30] batch [120/796] time 0.373 (0.385) data 0.000 (0.006) loss 0.5542 (1.4570) lr 3.9604e-03 eta 1:05:38
epoch [18/30] batch [140/796] time 0.360 (0.384) data 0.000 (0.005) loss 1.7715 (1.4760) lr 3.9604e-03 eta 1:05:18
epoch [18/30] batch [160/796] time 0.348 (0.384) data 0.000 (0.004) loss 1.0049 (1.4618) lr 3.9604e-03 eta 1:05:07
epoch [18/30] batch [180/796] time 0.398 (0.384) data 0.000 (0.004) loss 1.0820 (1.4517) lr 3.9604e-03 eta 1:05:01
epoch [18/30] batch [200/796] time 0.392 (0.384) data 0.000 (0.004) loss 1.2061 (1.4631) lr 3.9604e-03 eta 1:04:55
epoch [18/30] batch [220/796] time 0.398 (0.384) data 0.000 (0.003) loss 0.8921 (1.4558) lr 3.9604e-03 eta 1:04:50
epoch [18/30] batch [240/796] time 0.387 (0.383) data 0.000 (0.003) loss 0.1656 (1.4662) lr 3.9604e-03 eta 1:04:31
epoch [18/30] batch [260/796] time 0.357 (0.383) data 0.000 (0.003) loss 0.6494 (1.4683) lr 3.9604e-03 eta 1:04:20
epoch [18/30] batch [280/796] time 0.397 (0.383) data 0.000 (0.003) loss 0.7207 (1.5010) lr 3.9604e-03 eta 1:04:11
epoch [18/30] batch [300/796] time 0.396 (0.382) data 0.000 (0.002) loss 0.8579 (1.5022) lr 3.9604e-03 eta 1:04:00
epoch [18/30] batch [320/796] time 0.385 (0.382) data 0.000 (0.002) loss 1.2510 (1.5330) lr 3.9604e-03 eta 1:03:49
epoch [18/30] batch [340/796] time 0.353 (0.382) data 0.000 (0.002) loss 1.7246 (1.5434) lr 3.9604e-03 eta 1:03:41
epoch [18/30] batch [360/796] time 0.392 (0.382) data 0.000 (0.002) loss 0.4556 (1.5444) lr 3.9604e-03 eta 1:03:36
epoch [18/30] batch [380/796] time 0.378 (0.382) data 0.000 (0.002) loss 1.6924 (1.5299) lr 3.9604e-03 eta 1:03:25
epoch [18/30] batch [400/796] time 0.351 (0.382) data 0.000 (0.002) loss 3.3027 (1.5296) lr 3.9604e-03 eta 1:03:17
epoch [18/30] batch [420/796] time 0.399 (0.382) data 0.000 (0.002) loss 0.7754 (1.5382) lr 3.9604e-03 eta 1:03:08
epoch [18/30] batch [440/796] time 0.356 (0.381) data 0.000 (0.002) loss 3.8730 (1.5715) lr 3.9604e-03 eta 1:02:56
epoch [18/30] batch [460/796] time 0.348 (0.381) data 0.000 (0.002) loss 1.9893 (1.5688) lr 3.9604e-03 eta 1:02:50
epoch [18/30] batch [480/796] time 0.399 (0.381) data 0.000 (0.002) loss 0.2913 (1.5793) lr 3.9604e-03 eta 1:02:40
epoch [18/30] batch [500/796] time 0.375 (0.381) data 0.000 (0.002) loss 0.4011 (1.5965) lr 3.9604e-03 eta 1:02:34
epoch [18/30] batch [520/796] time 0.349 (0.381) data 0.000 (0.002) loss 4.3750 (1.5996) lr 3.9604e-03 eta 1:02:27
epoch [18/30] batch [540/796] time 0.383 (0.381) data 0.000 (0.001) loss 0.0881 (1.6028) lr 3.9604e-03 eta 1:02:20
epoch [18/30] batch [560/796] time 0.358 (0.381) data 0.000 (0.001) loss 1.4629 (1.6183) lr 3.9604e-03 eta 1:02:11
epoch [18/30] batch [580/796] time 0.390 (0.381) data 0.000 (0.001) loss 3.2148 (1.6160) lr 3.9604e-03 eta 1:02:01
epoch [18/30] batch [600/796] time 0.382 (0.381) data 0.000 (0.001) loss 7.3086 (1.6242) lr 3.9604e-03 eta 1:01:52
epoch [18/30] batch [620/796] time 0.369 (0.381) data 0.000 (0.001) loss 1.4268 (1.6336) lr 3.9604e-03 eta 1:01:44
epoch [18/30] batch [640/796] time 0.384 (0.381) data 0.000 (0.001) loss 1.7529 (1.6414) lr 3.9604e-03 eta 1:01:38
epoch [18/30] batch [660/796] time 0.361 (0.381) data 0.000 (0.001) loss 0.1904 (1.6449) lr 3.9604e-03 eta 1:01:29
epoch [18/30] batch [680/796] time 0.366 (0.381) data 0.000 (0.001) loss 2.6387 (1.6486) lr 3.9604e-03 eta 1:01:21
epoch [18/30] batch [700/796] time 0.396 (0.381) data 0.000 (0.001) loss 3.7168 (1.6543) lr 3.9604e-03 eta 1:01:15
epoch [18/30] batch [720/796] time 0.399 (0.381) data 0.000 (0.001) loss 0.4133 (1.6403) lr 3.9604e-03 eta 1:01:07
epoch [18/30] batch [740/796] time 0.368 (0.381) data 0.000 (0.001) loss 0.6479 (1.6309) lr 3.9604e-03 eta 1:00:58
epoch [18/30] batch [760/796] time 0.362 (0.381) data 0.000 (0.001) loss 1.3633 (1.6459) lr 3.9604e-03 eta 1:00:50
epoch [18/30] batch [780/796] time 0.343 (0.380) data 0.000 (0.001) loss 3.4980 (1.6388) lr 3.9604e-03 eta 1:00:35
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:49,  5.74s/it] 10%|█         | 2/20 [00:06<00:50,  2.80s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.66s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.87it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.67it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.92it/s] 60%|██████    | 12/20 [00:09<00:02,  3.17it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.40it/s] 70%|███████   | 14/20 [00:09<00:01,  3.75it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.84it/s] 80%|████████  | 16/20 [00:10<00:00,  4.07it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.99it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.31it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.60it/s]100%|██████████| 20/20 [00:11<00:00,  4.90it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,597
* accuracy: 80.3%
* error: 19.7%
* macro_f1: 79.9%

epoch [19/30] batch [20/796] time 0.394 (0.421) data 0.000 (0.045) loss 1.1475 (1.9042) lr 3.4549e-03 eta 1:06:57
epoch [19/30] batch [40/796] time 0.379 (0.399) data 0.000 (0.022) loss 3.7988 (1.7084) lr 3.4549e-03 eta 1:03:16
epoch [19/30] batch [60/796] time 0.381 (0.396) data 0.000 (0.015) loss 1.3447 (1.7893) lr 3.4549e-03 eta 1:02:36
epoch [19/30] batch [80/796] time 0.388 (0.390) data 0.000 (0.011) loss 0.2603 (1.7542) lr 3.4549e-03 eta 1:01:30
epoch [19/30] batch [100/796] time 0.354 (0.386) data 0.000 (0.009) loss 4.0234 (1.7297) lr 3.4549e-03 eta 1:00:49
epoch [19/30] batch [120/796] time 0.452 (0.385) data 0.000 (0.008) loss 0.9092 (1.7621) lr 3.4549e-03 eta 1:00:32
epoch [19/30] batch [140/796] time 0.367 (0.383) data 0.000 (0.007) loss 4.6367 (1.7022) lr 3.4549e-03 eta 1:00:05
epoch [19/30] batch [160/796] time 0.389 (0.382) data 0.000 (0.006) loss 2.3262 (1.6647) lr 3.4549e-03 eta 0:59:49
epoch [19/30] batch [180/796] time 0.375 (0.382) data 0.000 (0.005) loss 0.2389 (1.6558) lr 3.4549e-03 eta 0:59:37
epoch [19/30] batch [200/796] time 0.346 (0.382) data 0.000 (0.005) loss 0.2913 (1.6571) lr 3.4549e-03 eta 0:59:32
epoch [19/30] batch [220/796] time 0.369 (0.381) data 0.000 (0.004) loss 0.8374 (1.6436) lr 3.4549e-03 eta 0:59:17
epoch [19/30] batch [240/796] time 0.397 (0.381) data 0.000 (0.004) loss 5.5391 (1.6496) lr 3.4549e-03 eta 0:59:10
epoch [19/30] batch [260/796] time 0.357 (0.381) data 0.000 (0.004) loss 0.2959 (1.6706) lr 3.4549e-03 eta 0:59:02
epoch [19/30] batch [280/796] time 0.363 (0.381) data 0.000 (0.003) loss 1.5879 (1.6405) lr 3.4549e-03 eta 0:58:50
epoch [19/30] batch [300/796] time 0.351 (0.381) data 0.000 (0.003) loss 1.0703 (1.6360) lr 3.4549e-03 eta 0:58:43
epoch [19/30] batch [320/796] time 0.363 (0.381) data 0.000 (0.003) loss 2.8477 (1.6231) lr 3.4549e-03 eta 0:58:34
epoch [19/30] batch [340/796] time 0.356 (0.381) data 0.000 (0.003) loss 0.1689 (1.6070) lr 3.4549e-03 eta 0:58:26
epoch [19/30] batch [360/796] time 0.363 (0.380) data 0.000 (0.003) loss 1.7852 (1.5940) lr 3.4549e-03 eta 0:58:15
epoch [19/30] batch [380/796] time 0.384 (0.380) data 0.000 (0.003) loss 0.5352 (1.6145) lr 3.4549e-03 eta 0:58:08
epoch [19/30] batch [400/796] time 0.385 (0.380) data 0.000 (0.002) loss 2.6367 (1.6265) lr 3.4549e-03 eta 0:58:00
epoch [19/30] batch [420/796] time 0.344 (0.381) data 0.000 (0.002) loss 1.5830 (1.6378) lr 3.4549e-03 eta 0:57:55
epoch [19/30] batch [440/796] time 0.373 (0.380) data 0.000 (0.002) loss 2.3672 (1.6370) lr 3.4549e-03 eta 0:57:43
epoch [19/30] batch [460/796] time 0.393 (0.380) data 0.000 (0.002) loss 1.9834 (1.6083) lr 3.4549e-03 eta 0:57:36
epoch [19/30] batch [480/796] time 0.386 (0.380) data 0.000 (0.002) loss 2.0977 (1.6124) lr 3.4549e-03 eta 0:57:27
epoch [19/30] batch [500/796] time 0.369 (0.380) data 0.000 (0.002) loss 1.7021 (1.6011) lr 3.4549e-03 eta 0:57:20
epoch [19/30] batch [520/796] time 0.381 (0.380) data 0.000 (0.002) loss 1.4756 (1.5827) lr 3.4549e-03 eta 0:57:12
epoch [19/30] batch [540/796] time 0.351 (0.380) data 0.000 (0.002) loss 5.0391 (1.6065) lr 3.4549e-03 eta 0:57:03
epoch [19/30] batch [560/796] time 0.355 (0.380) data 0.000 (0.002) loss 0.2092 (1.5917) lr 3.4549e-03 eta 0:56:54
epoch [19/30] batch [580/796] time 0.413 (0.380) data 0.000 (0.002) loss 0.3669 (1.5964) lr 3.4549e-03 eta 0:56:46
epoch [19/30] batch [600/796] time 0.383 (0.380) data 0.000 (0.002) loss 0.9326 (1.6010) lr 3.4549e-03 eta 0:56:38
epoch [19/30] batch [620/796] time 0.367 (0.380) data 0.000 (0.002) loss 3.2559 (1.5873) lr 3.4549e-03 eta 0:56:31
epoch [19/30] batch [640/796] time 0.361 (0.380) data 0.000 (0.002) loss 0.2134 (1.5810) lr 3.4549e-03 eta 0:56:22
epoch [19/30] batch [660/796] time 0.385 (0.379) data 0.000 (0.002) loss 0.7900 (1.5897) lr 3.4549e-03 eta 0:56:14
epoch [19/30] batch [680/796] time 0.395 (0.380) data 0.000 (0.002) loss 1.5215 (1.5776) lr 3.4549e-03 eta 0:56:07
epoch [19/30] batch [700/796] time 0.396 (0.379) data 0.000 (0.002) loss 3.5020 (1.5791) lr 3.4549e-03 eta 0:55:59
epoch [19/30] batch [720/796] time 0.420 (0.379) data 0.000 (0.001) loss 1.4883 (1.5834) lr 3.4549e-03 eta 0:55:51
epoch [19/30] batch [740/796] time 0.368 (0.379) data 0.000 (0.001) loss 1.6455 (1.5782) lr 3.4549e-03 eta 0:55:43
epoch [19/30] batch [760/796] time 0.399 (0.379) data 0.000 (0.001) loss 1.1016 (1.5708) lr 3.4549e-03 eta 0:55:36
epoch [19/30] batch [780/796] time 0.339 (0.379) data 0.000 (0.001) loss 3.3594 (1.5607) lr 3.4549e-03 eta 0:55:22
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.63s/it] 10%|█         | 2/20 [00:06<00:51,  2.86s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.69s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:08,  1.56it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.75it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.95it/s] 60%|██████    | 12/20 [00:09<00:02,  3.17it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.47it/s] 70%|███████   | 14/20 [00:09<00:01,  3.60it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.82it/s] 80%|████████  | 16/20 [00:10<00:00,  4.04it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.14it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.75it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.14it/s]100%|██████████| 20/20 [00:11<00:00,  4.54it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,599
* accuracy: 80.4%
* error: 19.6%
* macro_f1: 79.8%

epoch [20/30] batch [20/796] time 0.391 (0.423) data 0.000 (0.034) loss 1.4717 (1.2583) lr 2.9663e-03 eta 1:01:35
epoch [20/30] batch [40/796] time 0.396 (0.400) data 0.000 (0.017) loss 0.0639 (1.3386) lr 2.9663e-03 eta 0:58:07
epoch [20/30] batch [60/796] time 0.352 (0.394) data 0.000 (0.012) loss 0.3745 (1.3952) lr 2.9663e-03 eta 0:57:06
epoch [20/30] batch [80/796] time 0.394 (0.392) data 0.000 (0.009) loss 3.0371 (1.4243) lr 2.9663e-03 eta 0:56:38
epoch [20/30] batch [100/796] time 0.378 (0.389) data 0.000 (0.007) loss 0.6841 (1.4378) lr 2.9663e-03 eta 0:56:03
epoch [20/30] batch [120/796] time 0.361 (0.386) data 0.000 (0.006) loss 1.7666 (1.5093) lr 2.9663e-03 eta 0:55:35
epoch [20/30] batch [140/796] time 0.358 (0.385) data 0.000 (0.005) loss 1.4678 (1.4698) lr 2.9663e-03 eta 0:55:16
epoch [20/30] batch [160/796] time 0.363 (0.384) data 0.000 (0.005) loss 1.1992 (1.4344) lr 2.9663e-03 eta 0:55:00
epoch [20/30] batch [180/796] time 0.385 (0.384) data 0.000 (0.004) loss 1.2559 (1.4468) lr 2.9663e-03 eta 0:54:56
epoch [20/30] batch [200/796] time 0.380 (0.384) data 0.000 (0.004) loss 4.6133 (1.4543) lr 2.9663e-03 eta 0:54:44
epoch [20/30] batch [220/796] time 0.398 (0.384) data 0.000 (0.003) loss 0.6509 (1.4888) lr 2.9663e-03 eta 0:54:38
epoch [20/30] batch [240/796] time 0.400 (0.383) data 0.000 (0.003) loss 0.5039 (1.4893) lr 2.9663e-03 eta 0:54:25
epoch [20/30] batch [260/796] time 0.357 (0.383) data 0.000 (0.003) loss 0.5708 (1.5197) lr 2.9663e-03 eta 0:54:10
epoch [20/30] batch [280/796] time 0.361 (0.382) data 0.000 (0.003) loss 1.5449 (1.5094) lr 2.9663e-03 eta 0:53:59
epoch [20/30] batch [300/796] time 0.367 (0.382) data 0.000 (0.003) loss 0.1014 (1.5077) lr 2.9663e-03 eta 0:53:47
epoch [20/30] batch [320/796] time 0.406 (0.382) data 0.000 (0.002) loss 1.5205 (1.5297) lr 2.9663e-03 eta 0:53:42
epoch [20/30] batch [340/796] time 0.398 (0.382) data 0.000 (0.002) loss 0.2588 (1.5403) lr 2.9663e-03 eta 0:53:37
epoch [20/30] batch [360/796] time 0.363 (0.382) data 0.000 (0.002) loss 0.2949 (1.5682) lr 2.9663e-03 eta 0:53:26
epoch [20/30] batch [380/796] time 0.366 (0.382) data 0.000 (0.002) loss 2.3770 (1.5619) lr 2.9663e-03 eta 0:53:16
epoch [20/30] batch [400/796] time 0.369 (0.382) data 0.000 (0.002) loss 2.7070 (1.5642) lr 2.9663e-03 eta 0:53:09
epoch [20/30] batch [420/796] time 0.353 (0.381) data 0.000 (0.002) loss 0.2661 (1.5661) lr 2.9663e-03 eta 0:52:58
epoch [20/30] batch [440/796] time 0.358 (0.381) data 0.000 (0.002) loss 0.9761 (1.5844) lr 2.9663e-03 eta 0:52:49
epoch [20/30] batch [460/796] time 0.436 (0.381) data 0.000 (0.002) loss 8.0234 (1.5835) lr 2.9663e-03 eta 0:52:41
epoch [20/30] batch [480/796] time 0.385 (0.381) data 0.000 (0.002) loss 1.1875 (1.5896) lr 2.9663e-03 eta 0:52:33
epoch [20/30] batch [500/796] time 0.373 (0.381) data 0.000 (0.002) loss 0.2063 (1.5793) lr 2.9663e-03 eta 0:52:27
epoch [20/30] batch [520/796] time 0.365 (0.381) data 0.000 (0.002) loss 0.0760 (1.5677) lr 2.9663e-03 eta 0:52:17
epoch [20/30] batch [540/796] time 0.375 (0.381) data 0.000 (0.002) loss 2.6523 (1.5571) lr 2.9663e-03 eta 0:52:13
epoch [20/30] batch [560/796] time 0.382 (0.381) data 0.000 (0.001) loss 5.4141 (1.5761) lr 2.9663e-03 eta 0:52:03
epoch [20/30] batch [580/796] time 0.401 (0.381) data 0.000 (0.001) loss 2.3945 (1.5652) lr 2.9663e-03 eta 0:51:58
epoch [20/30] batch [600/796] time 0.397 (0.382) data 0.000 (0.001) loss 1.6377 (1.5532) lr 2.9663e-03 eta 0:51:52
epoch [20/30] batch [620/796] time 0.373 (0.382) data 0.000 (0.001) loss 1.1592 (1.5612) lr 2.9663e-03 eta 0:51:45
epoch [20/30] batch [640/796] time 0.378 (0.381) data 0.000 (0.001) loss 0.4749 (1.5584) lr 2.9663e-03 eta 0:51:35
epoch [20/30] batch [660/796] time 0.369 (0.381) data 0.000 (0.001) loss 1.2188 (1.5677) lr 2.9663e-03 eta 0:51:27
epoch [20/30] batch [680/796] time 0.361 (0.381) data 0.000 (0.001) loss 3.3984 (1.5726) lr 2.9663e-03 eta 0:51:18
epoch [20/30] batch [700/796] time 0.380 (0.381) data 0.000 (0.001) loss 0.8228 (1.5777) lr 2.9663e-03 eta 0:51:09
epoch [20/30] batch [720/796] time 0.371 (0.381) data 0.000 (0.001) loss 3.6562 (1.5808) lr 2.9663e-03 eta 0:51:00
epoch [20/30] batch [740/796] time 0.359 (0.381) data 0.000 (0.001) loss 3.4141 (1.5869) lr 2.9663e-03 eta 0:50:51
epoch [20/30] batch [760/796] time 0.353 (0.381) data 0.000 (0.001) loss 0.1198 (1.5746) lr 2.9663e-03 eta 0:50:44
epoch [20/30] batch [780/796] time 0.342 (0.380) data 0.000 (0.001) loss 1.7422 (1.5666) lr 2.9663e-03 eta 0:50:30
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:48,  5.70s/it] 10%|█         | 2/20 [00:06<00:51,  2.89s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:08<00:03,  2.68it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.92it/s] 60%|██████    | 12/20 [00:09<00:02,  3.17it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.32it/s] 70%|███████   | 14/20 [00:10<00:01,  3.50it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.84it/s] 80%|████████  | 16/20 [00:10<00:01,  3.83it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.12it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.33it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.63it/s]100%|██████████| 20/20 [00:11<00:00,  4.93it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,601
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 79.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/796] time 0.381 (0.427) data 0.000 (0.034) loss 0.6372 (1.5003) lr 2.5000e-03 eta 0:56:32
epoch [21/30] batch [40/796] time 0.356 (0.405) data 0.000 (0.017) loss 0.1482 (1.2515) lr 2.5000e-03 eta 0:53:25
epoch [21/30] batch [60/796] time 0.399 (0.395) data 0.000 (0.011) loss 1.7725 (1.2679) lr 2.5000e-03 eta 0:52:04
epoch [21/30] batch [80/796] time 0.347 (0.391) data 0.000 (0.009) loss 2.7754 (1.3454) lr 2.5000e-03 eta 0:51:23
epoch [21/30] batch [100/796] time 0.397 (0.390) data 0.000 (0.007) loss 1.8154 (1.3388) lr 2.5000e-03 eta 0:51:03
epoch [21/30] batch [120/796] time 0.416 (0.388) data 0.000 (0.006) loss 1.5137 (1.3261) lr 2.5000e-03 eta 0:50:43
epoch [21/30] batch [140/796] time 0.345 (0.386) data 0.000 (0.005) loss 0.2148 (1.3596) lr 2.5000e-03 eta 0:50:19
epoch [21/30] batch [160/796] time 0.351 (0.385) data 0.000 (0.004) loss 0.2820 (1.3506) lr 2.5000e-03 eta 0:50:04
epoch [21/30] batch [180/796] time 0.387 (0.384) data 0.000 (0.004) loss 0.1665 (1.3574) lr 2.5000e-03 eta 0:49:48
epoch [21/30] batch [200/796] time 0.394 (0.384) data 0.000 (0.004) loss 3.3789 (1.4182) lr 2.5000e-03 eta 0:49:36
epoch [21/30] batch [220/796] time 0.366 (0.383) data 0.000 (0.003) loss 0.8325 (1.4557) lr 2.5000e-03 eta 0:49:24
epoch [21/30] batch [240/796] time 0.354 (0.382) data 0.000 (0.003) loss 1.7871 (1.4789) lr 2.5000e-03 eta 0:49:10
epoch [21/30] batch [260/796] time 0.353 (0.382) data 0.000 (0.003) loss 2.0586 (1.4982) lr 2.5000e-03 eta 0:49:03
epoch [21/30] batch [280/796] time 0.393 (0.382) data 0.000 (0.003) loss 0.1376 (1.4772) lr 2.5000e-03 eta 0:48:54
epoch [21/30] batch [300/796] time 0.387 (0.382) data 0.000 (0.002) loss 4.3789 (1.4756) lr 2.5000e-03 eta 0:48:46
epoch [21/30] batch [320/796] time 0.379 (0.382) data 0.000 (0.002) loss 1.3604 (1.4614) lr 2.5000e-03 eta 0:48:38
epoch [21/30] batch [340/796] time 0.347 (0.382) data 0.000 (0.002) loss 1.4004 (1.5033) lr 2.5000e-03 eta 0:48:30
epoch [21/30] batch [360/796] time 0.394 (0.382) data 0.000 (0.002) loss 3.9941 (1.5059) lr 2.5000e-03 eta 0:48:19
epoch [21/30] batch [380/796] time 0.369 (0.381) data 0.000 (0.002) loss 3.6387 (1.5155) lr 2.5000e-03 eta 0:48:11
epoch [21/30] batch [400/796] time 0.392 (0.381) data 0.000 (0.002) loss 1.0430 (1.5335) lr 2.5000e-03 eta 0:48:01
epoch [21/30] batch [420/796] time 0.357 (0.381) data 0.000 (0.002) loss 3.3477 (1.5149) lr 2.5000e-03 eta 0:47:55
epoch [21/30] batch [440/796] time 0.374 (0.381) data 0.000 (0.002) loss 1.8936 (1.5103) lr 2.5000e-03 eta 0:47:45
epoch [21/30] batch [460/796] time 0.378 (0.381) data 0.000 (0.002) loss 0.1868 (1.5403) lr 2.5000e-03 eta 0:47:37
epoch [21/30] batch [480/796] time 0.362 (0.381) data 0.000 (0.002) loss 0.3616 (1.5295) lr 2.5000e-03 eta 0:47:31
epoch [21/30] batch [500/796] time 0.355 (0.381) data 0.000 (0.002) loss 1.4336 (1.5191) lr 2.5000e-03 eta 0:47:24
epoch [21/30] batch [520/796] time 0.376 (0.381) data 0.000 (0.002) loss 0.5449 (1.5112) lr 2.5000e-03 eta 0:47:16
epoch [21/30] batch [540/796] time 0.348 (0.381) data 0.000 (0.002) loss 1.1055 (1.4987) lr 2.5000e-03 eta 0:47:09
epoch [21/30] batch [560/796] time 0.401 (0.381) data 0.000 (0.001) loss 0.3230 (1.5120) lr 2.5000e-03 eta 0:47:01
epoch [21/30] batch [580/796] time 0.406 (0.381) data 0.000 (0.001) loss 0.9185 (1.5205) lr 2.5000e-03 eta 0:46:53
epoch [21/30] batch [600/796] time 0.408 (0.381) data 0.000 (0.001) loss 0.9072 (1.5173) lr 2.5000e-03 eta 0:46:47
epoch [21/30] batch [620/796] time 0.356 (0.381) data 0.000 (0.001) loss 0.3962 (1.5093) lr 2.5000e-03 eta 0:46:37
epoch [21/30] batch [640/796] time 0.385 (0.381) data 0.000 (0.001) loss 0.6831 (1.5223) lr 2.5000e-03 eta 0:46:30
epoch [21/30] batch [660/796] time 0.352 (0.381) data 0.000 (0.001) loss 1.9668 (1.5159) lr 2.5000e-03 eta 0:46:21
epoch [21/30] batch [680/796] time 0.399 (0.381) data 0.000 (0.001) loss 0.7026 (1.5304) lr 2.5000e-03 eta 0:46:14
epoch [21/30] batch [700/796] time 0.461 (0.381) data 0.000 (0.001) loss 1.1045 (1.5361) lr 2.5000e-03 eta 0:46:06
epoch [21/30] batch [720/796] time 0.374 (0.381) data 0.000 (0.001) loss 2.5273 (1.5339) lr 2.5000e-03 eta 0:45:59
epoch [21/30] batch [740/796] time 0.370 (0.381) data 0.000 (0.001) loss 0.9517 (1.5393) lr 2.5000e-03 eta 0:45:51
epoch [21/30] batch [760/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.5283 (1.5426) lr 2.5000e-03 eta 0:45:42
epoch [21/30] batch [780/796] time 0.342 (0.380) data 0.000 (0.001) loss 0.5044 (1.5414) lr 2.5000e-03 eta 0:45:28
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.59s/it] 10%|█         | 2/20 [00:06<00:51,  2.84s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.67s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.71it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.91it/s] 60%|██████    | 12/20 [00:09<00:02,  3.26it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.42it/s] 70%|███████   | 14/20 [00:09<00:01,  3.71it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.78it/s] 80%|████████  | 16/20 [00:10<00:00,  4.04it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.16it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.04it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.38it/s]100%|██████████| 20/20 [00:11<00:00,  4.73it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,602
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 80.2%

epoch [22/30] batch [20/796] time 0.358 (0.430) data 0.000 (0.036) loss 0.2988 (1.6332) lr 2.0611e-03 eta 0:51:12
epoch [22/30] batch [40/796] time 0.374 (0.402) data 0.000 (0.018) loss 1.5156 (1.7434) lr 2.0611e-03 eta 0:47:43
epoch [22/30] batch [60/796] time 0.447 (0.395) data 0.000 (0.012) loss 0.9546 (1.6810) lr 2.0611e-03 eta 0:46:49
epoch [22/30] batch [80/796] time 0.387 (0.393) data 0.000 (0.009) loss 1.2217 (1.5829) lr 2.0611e-03 eta 0:46:24
epoch [22/30] batch [100/796] time 0.357 (0.392) data 0.000 (0.007) loss 1.5928 (1.5295) lr 2.0611e-03 eta 0:46:06
epoch [22/30] batch [120/796] time 0.352 (0.389) data 0.000 (0.006) loss 3.3340 (1.5288) lr 2.0611e-03 eta 0:45:37
epoch [22/30] batch [140/796] time 0.369 (0.389) data 0.000 (0.005) loss 1.3779 (1.4869) lr 2.0611e-03 eta 0:45:29
epoch [22/30] batch [160/796] time 0.389 (0.387) data 0.000 (0.005) loss 2.3457 (1.4629) lr 2.0611e-03 eta 0:45:10
epoch [22/30] batch [180/796] time 0.372 (0.386) data 0.000 (0.004) loss 1.6201 (1.5260) lr 2.0611e-03 eta 0:44:53
epoch [22/30] batch [200/796] time 0.367 (0.385) data 0.000 (0.004) loss 1.3076 (1.5525) lr 2.0611e-03 eta 0:44:43
epoch [22/30] batch [220/796] time 0.394 (0.386) data 0.000 (0.004) loss 0.6567 (1.5177) lr 2.0611e-03 eta 0:44:38
epoch [22/30] batch [240/796] time 0.356 (0.385) data 0.000 (0.003) loss 0.9365 (1.5347) lr 2.0611e-03 eta 0:44:27
epoch [22/30] batch [260/796] time 0.347 (0.385) data 0.000 (0.003) loss 1.4150 (1.5516) lr 2.0611e-03 eta 0:44:18
epoch [22/30] batch [280/796] time 0.392 (0.385) data 0.000 (0.003) loss 3.3516 (1.5390) lr 2.0611e-03 eta 0:44:07
epoch [22/30] batch [300/796] time 0.381 (0.384) data 0.000 (0.003) loss 3.9590 (1.5324) lr 2.0611e-03 eta 0:43:56
epoch [22/30] batch [320/796] time 0.385 (0.384) data 0.000 (0.003) loss 0.5884 (1.5270) lr 2.0611e-03 eta 0:43:47
epoch [22/30] batch [340/796] time 0.354 (0.384) data 0.000 (0.002) loss 1.1641 (1.5209) lr 2.0611e-03 eta 0:43:37
epoch [22/30] batch [360/796] time 0.396 (0.383) data 0.000 (0.002) loss 0.9688 (1.4917) lr 2.0611e-03 eta 0:43:26
epoch [22/30] batch [380/796] time 0.353 (0.383) data 0.000 (0.002) loss 1.4541 (1.4880) lr 2.0611e-03 eta 0:43:15
epoch [22/30] batch [400/796] time 0.376 (0.382) data 0.000 (0.002) loss 0.5273 (1.4718) lr 2.0611e-03 eta 0:43:06
epoch [22/30] batch [420/796] time 0.360 (0.382) data 0.000 (0.002) loss 0.6343 (1.4808) lr 2.0611e-03 eta 0:42:57
epoch [22/30] batch [440/796] time 0.390 (0.382) data 0.000 (0.002) loss 2.2285 (1.4970) lr 2.0611e-03 eta 0:42:47
epoch [22/30] batch [460/796] time 0.355 (0.381) data 0.000 (0.002) loss 1.4941 (1.5166) lr 2.0611e-03 eta 0:42:36
epoch [22/30] batch [480/796] time 0.396 (0.381) data 0.000 (0.002) loss 0.0465 (1.5145) lr 2.0611e-03 eta 0:42:28
epoch [22/30] batch [500/796] time 0.344 (0.382) data 0.000 (0.002) loss 2.6914 (1.5316) lr 2.0611e-03 eta 0:42:22
epoch [22/30] batch [520/796] time 0.400 (0.381) data 0.000 (0.002) loss 0.5093 (1.5272) lr 2.0611e-03 eta 0:42:13
epoch [22/30] batch [540/796] time 0.388 (0.381) data 0.000 (0.002) loss 4.1094 (1.5351) lr 2.0611e-03 eta 0:42:06
epoch [22/30] batch [560/796] time 0.363 (0.381) data 0.000 (0.002) loss 0.8521 (1.5353) lr 2.0611e-03 eta 0:41:57
epoch [22/30] batch [580/796] time 0.360 (0.381) data 0.000 (0.001) loss 1.7373 (1.5425) lr 2.0611e-03 eta 0:41:48
epoch [22/30] batch [600/796] time 0.400 (0.381) data 0.000 (0.001) loss 0.9717 (1.5407) lr 2.0611e-03 eta 0:41:39
epoch [22/30] batch [620/796] time 0.369 (0.381) data 0.000 (0.001) loss 2.4316 (1.5324) lr 2.0611e-03 eta 0:41:30
epoch [22/30] batch [640/796] time 0.398 (0.381) data 0.000 (0.001) loss 0.8340 (1.5456) lr 2.0611e-03 eta 0:41:23
epoch [22/30] batch [660/796] time 0.400 (0.381) data 0.000 (0.001) loss 0.2893 (1.5340) lr 2.0611e-03 eta 0:41:16
epoch [22/30] batch [680/796] time 0.387 (0.381) data 0.000 (0.001) loss 0.5732 (1.5280) lr 2.0611e-03 eta 0:41:10
epoch [22/30] batch [700/796] time 0.367 (0.381) data 0.000 (0.001) loss 0.1653 (1.5188) lr 2.0611e-03 eta 0:41:00
epoch [22/30] batch [720/796] time 0.354 (0.380) data 0.000 (0.001) loss 0.5366 (1.5214) lr 2.0611e-03 eta 0:40:50
epoch [22/30] batch [740/796] time 0.347 (0.380) data 0.000 (0.001) loss 0.1661 (1.5151) lr 2.0611e-03 eta 0:40:42
epoch [22/30] batch [760/796] time 0.402 (0.380) data 0.000 (0.001) loss 1.2607 (1.5250) lr 2.0611e-03 eta 0:40:35
epoch [22/30] batch [780/796] time 0.341 (0.380) data 0.000 (0.001) loss 1.1729 (1.5253) lr 2.0611e-03 eta 0:40:23
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:48,  5.74s/it] 10%|█         | 2/20 [00:06<00:48,  2.72s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.61s/it] 20%|██        | 4/20 [00:06<00:17,  1.09s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.25it/s] 30%|███       | 6/20 [00:07<00:08,  1.58it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.92it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.51it/s] 50%|█████     | 10/20 [00:08<00:03,  2.74it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.92it/s] 60%|██████    | 12/20 [00:09<00:02,  3.17it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.48it/s] 70%|███████   | 14/20 [00:09<00:01,  3.56it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.81it/s] 80%|████████  | 16/20 [00:10<00:00,  4.00it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.90it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.86it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.24it/s]100%|██████████| 20/20 [00:11<00:00,  4.61it/s]100%|██████████| 20/20 [00:11<00:00,  1.79it/s]=> result
* total: 1,990
* correct: 1,605
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 80.2%

epoch [23/30] batch [20/796] time 0.395 (0.420) data 0.000 (0.038) loss 5.2500 (1.6917) lr 1.6543e-03 eta 0:44:27
epoch [23/30] batch [40/796] time 0.346 (0.400) data 0.000 (0.019) loss 1.0488 (1.6569) lr 1.6543e-03 eta 0:42:08
epoch [23/30] batch [60/796] time 0.370 (0.392) data 0.000 (0.013) loss 0.2233 (1.5416) lr 1.6543e-03 eta 0:41:12
epoch [23/30] batch [80/796] time 0.362 (0.390) data 0.000 (0.010) loss 3.6230 (1.5233) lr 1.6543e-03 eta 0:40:49
epoch [23/30] batch [100/796] time 0.345 (0.387) data 0.000 (0.008) loss 0.2915 (1.5530) lr 1.6543e-03 eta 0:40:24
epoch [23/30] batch [120/796] time 0.392 (0.384) data 0.000 (0.007) loss 0.4331 (1.4906) lr 1.6543e-03 eta 0:40:01
epoch [23/30] batch [140/796] time 0.364 (0.384) data 0.000 (0.006) loss 0.6460 (1.5657) lr 1.6543e-03 eta 0:39:50
epoch [23/30] batch [160/796] time 0.408 (0.383) data 0.000 (0.005) loss 1.3711 (1.5993) lr 1.6543e-03 eta 0:39:38
epoch [23/30] batch [180/796] time 0.415 (0.383) data 0.000 (0.004) loss 1.6328 (1.6124) lr 1.6543e-03 eta 0:39:27
epoch [23/30] batch [200/796] time 0.394 (0.382) data 0.000 (0.004) loss 0.5728 (1.6088) lr 1.6543e-03 eta 0:39:15
epoch [23/30] batch [220/796] time 0.376 (0.382) data 0.000 (0.004) loss 0.8716 (1.5531) lr 1.6543e-03 eta 0:39:11
epoch [23/30] batch [240/796] time 0.381 (0.382) data 0.000 (0.003) loss 1.9326 (1.5624) lr 1.6543e-03 eta 0:39:01
epoch [23/30] batch [260/796] time 0.387 (0.382) data 0.000 (0.003) loss 0.9976 (1.5424) lr 1.6543e-03 eta 0:38:51
epoch [23/30] batch [280/796] time 0.367 (0.381) data 0.000 (0.003) loss 0.2145 (1.5418) lr 1.6543e-03 eta 0:38:41
epoch [23/30] batch [300/796] time 0.407 (0.381) data 0.000 (0.003) loss 4.0625 (1.5187) lr 1.6543e-03 eta 0:38:32
epoch [23/30] batch [320/796] time 0.411 (0.381) data 0.000 (0.003) loss 1.2637 (1.4941) lr 1.6543e-03 eta 0:38:25
epoch [23/30] batch [340/796] time 0.396 (0.381) data 0.000 (0.003) loss 2.4277 (1.4806) lr 1.6543e-03 eta 0:38:18
epoch [23/30] batch [360/796] time 0.360 (0.381) data 0.000 (0.002) loss 0.4763 (1.4721) lr 1.6543e-03 eta 0:38:08
epoch [23/30] batch [380/796] time 0.395 (0.381) data 0.000 (0.002) loss 2.0332 (1.4680) lr 1.6543e-03 eta 0:38:00
epoch [23/30] batch [400/796] time 0.425 (0.381) data 0.000 (0.002) loss 0.7002 (1.4812) lr 1.6543e-03 eta 0:37:54
epoch [23/30] batch [420/796] time 0.352 (0.381) data 0.000 (0.002) loss 1.2998 (1.4915) lr 1.6543e-03 eta 0:37:46
epoch [23/30] batch [440/796] time 0.355 (0.381) data 0.000 (0.002) loss 3.1387 (1.4999) lr 1.6543e-03 eta 0:37:37
epoch [23/30] batch [460/796] time 0.369 (0.381) data 0.000 (0.002) loss 1.9775 (1.5128) lr 1.6543e-03 eta 0:37:30
epoch [23/30] batch [480/796] time 0.352 (0.381) data 0.000 (0.002) loss 0.4727 (1.5172) lr 1.6543e-03 eta 0:37:23
epoch [23/30] batch [500/796] time 0.398 (0.381) data 0.000 (0.002) loss 0.7378 (1.5033) lr 1.6543e-03 eta 0:37:15
epoch [23/30] batch [520/796] time 0.355 (0.380) data 0.000 (0.002) loss 2.2344 (1.5113) lr 1.6543e-03 eta 0:37:04
epoch [23/30] batch [540/796] time 0.363 (0.381) data 0.000 (0.002) loss 2.1836 (1.5066) lr 1.6543e-03 eta 0:36:57
epoch [23/30] batch [560/796] time 0.401 (0.381) data 0.000 (0.002) loss 1.3936 (1.5026) lr 1.6543e-03 eta 0:36:51
epoch [23/30] batch [580/796] time 0.353 (0.381) data 0.000 (0.002) loss 0.1750 (1.5041) lr 1.6543e-03 eta 0:36:43
epoch [23/30] batch [600/796] time 0.348 (0.381) data 0.000 (0.002) loss 0.2527 (1.4969) lr 1.6543e-03 eta 0:36:35
epoch [23/30] batch [620/796] time 0.341 (0.380) data 0.000 (0.001) loss 0.0101 (1.5028) lr 1.6543e-03 eta 0:36:24
epoch [23/30] batch [640/796] time 0.360 (0.380) data 0.000 (0.001) loss 1.9121 (1.5183) lr 1.6543e-03 eta 0:36:18
epoch [23/30] batch [660/796] time 0.397 (0.381) data 0.000 (0.001) loss 0.2866 (1.5104) lr 1.6543e-03 eta 0:36:13
epoch [23/30] batch [680/796] time 0.398 (0.381) data 0.000 (0.001) loss 4.5039 (1.5228) lr 1.6543e-03 eta 0:36:06
epoch [23/30] batch [700/796] time 0.361 (0.381) data 0.000 (0.001) loss 1.0693 (1.5157) lr 1.6543e-03 eta 0:35:58
epoch [23/30] batch [720/796] time 0.398 (0.381) data 0.000 (0.001) loss 1.5371 (1.5153) lr 1.6543e-03 eta 0:35:50
epoch [23/30] batch [740/796] time 0.358 (0.381) data 0.000 (0.001) loss 1.5869 (1.5126) lr 1.6543e-03 eta 0:35:43
epoch [23/30] batch [760/796] time 0.378 (0.381) data 0.000 (0.001) loss 2.4648 (1.5095) lr 1.6543e-03 eta 0:35:35
epoch [23/30] batch [780/796] time 0.339 (0.380) data 0.000 (0.001) loss 0.2419 (1.5179) lr 1.6543e-03 eta 0:35:23
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:43,  5.45s/it] 10%|█         | 2/20 [00:06<00:49,  2.73s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.61s/it] 20%|██        | 4/20 [00:06<00:17,  1.09s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.24it/s] 30%|███       | 6/20 [00:07<00:08,  1.58it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.91it/s] 40%|████      | 8/20 [00:08<00:05,  2.22it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.50it/s] 50%|█████     | 10/20 [00:08<00:03,  2.74it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.91it/s] 60%|██████    | 12/20 [00:09<00:02,  3.14it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.33it/s] 70%|███████   | 14/20 [00:09<00:01,  3.52it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.62it/s] 80%|████████  | 16/20 [00:10<00:01,  3.72it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.66it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.05it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.39it/s]100%|██████████| 20/20 [00:11<00:00,  4.74it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,615
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 80.8%

epoch [24/30] batch [20/796] time 0.355 (0.415) data 0.000 (0.033) loss 1.9053 (1.4812) lr 1.2843e-03 eta 0:38:25
epoch [24/30] batch [40/796] time 0.355 (0.397) data 0.000 (0.017) loss 0.1577 (1.5678) lr 1.2843e-03 eta 0:36:35
epoch [24/30] batch [60/796] time 0.353 (0.388) data 0.000 (0.011) loss 0.9541 (1.4472) lr 1.2843e-03 eta 0:35:37
epoch [24/30] batch [80/796] time 0.361 (0.387) data 0.000 (0.008) loss 0.3135 (1.4183) lr 1.2843e-03 eta 0:35:22
epoch [24/30] batch [100/796] time 0.365 (0.385) data 0.000 (0.007) loss 0.0210 (1.4436) lr 1.2843e-03 eta 0:35:07
epoch [24/30] batch [120/796] time 0.354 (0.384) data 0.000 (0.006) loss 2.3906 (1.4246) lr 1.2843e-03 eta 0:34:54
epoch [24/30] batch [140/796] time 0.365 (0.384) data 0.000 (0.005) loss 2.1973 (1.3695) lr 1.2843e-03 eta 0:34:46
epoch [24/30] batch [160/796] time 0.405 (0.384) data 0.000 (0.004) loss 0.1627 (1.4409) lr 1.2843e-03 eta 0:34:38
epoch [24/30] batch [180/796] time 0.390 (0.384) data 0.000 (0.004) loss 0.8330 (1.4203) lr 1.2843e-03 eta 0:34:28
epoch [24/30] batch [200/796] time 0.352 (0.384) data 0.000 (0.004) loss 0.7236 (1.3823) lr 1.2843e-03 eta 0:34:24
epoch [24/30] batch [220/796] time 0.392 (0.384) data 0.000 (0.003) loss 2.4316 (1.3993) lr 1.2843e-03 eta 0:34:14
epoch [24/30] batch [240/796] time 0.359 (0.383) data 0.000 (0.003) loss 0.8115 (1.3865) lr 1.2843e-03 eta 0:34:04
epoch [24/30] batch [260/796] time 0.347 (0.383) data 0.000 (0.003) loss 0.0965 (1.3756) lr 1.2843e-03 eta 0:33:53
epoch [24/30] batch [280/796] time 0.364 (0.382) data 0.000 (0.003) loss 4.9883 (1.3945) lr 1.2843e-03 eta 0:33:43
epoch [24/30] batch [300/796] time 0.352 (0.382) data 0.000 (0.002) loss 3.1562 (1.4076) lr 1.2843e-03 eta 0:33:34
epoch [24/30] batch [320/796] time 0.349 (0.382) data 0.000 (0.002) loss 0.0179 (1.3778) lr 1.2843e-03 eta 0:33:27
epoch [24/30] batch [340/796] time 0.386 (0.382) data 0.000 (0.002) loss 1.4990 (1.3870) lr 1.2843e-03 eta 0:33:18
epoch [24/30] batch [360/796] time 0.365 (0.382) data 0.000 (0.002) loss 0.8564 (1.3941) lr 1.2843e-03 eta 0:33:10
epoch [24/30] batch [380/796] time 0.378 (0.382) data 0.000 (0.002) loss 2.9824 (1.3967) lr 1.2843e-03 eta 0:33:04
epoch [24/30] batch [400/796] time 0.358 (0.382) data 0.000 (0.002) loss 2.4004 (1.3959) lr 1.2843e-03 eta 0:32:55
epoch [24/30] batch [420/796] time 0.381 (0.382) data 0.000 (0.002) loss 0.1010 (1.4055) lr 1.2843e-03 eta 0:32:46
epoch [24/30] batch [440/796] time 0.360 (0.382) data 0.000 (0.002) loss 2.3828 (1.4098) lr 1.2843e-03 eta 0:32:38
epoch [24/30] batch [460/796] time 0.362 (0.382) data 0.000 (0.002) loss 0.4307 (1.4208) lr 1.2843e-03 eta 0:32:31
epoch [24/30] batch [480/796] time 0.396 (0.382) data 0.000 (0.002) loss 2.5996 (1.4235) lr 1.2843e-03 eta 0:32:23
epoch [24/30] batch [500/796] time 0.368 (0.381) data 0.000 (0.002) loss 0.4785 (1.4155) lr 1.2843e-03 eta 0:32:14
epoch [24/30] batch [520/796] time 0.404 (0.382) data 0.000 (0.002) loss 3.3555 (1.4166) lr 1.2843e-03 eta 0:32:07
epoch [24/30] batch [540/796] time 0.407 (0.382) data 0.000 (0.001) loss 0.7812 (1.4340) lr 1.2843e-03 eta 0:32:01
epoch [24/30] batch [560/796] time 0.352 (0.381) data 0.000 (0.001) loss 1.9395 (1.4564) lr 1.2843e-03 eta 0:31:51
epoch [24/30] batch [580/796] time 0.387 (0.381) data 0.000 (0.001) loss 1.6270 (1.4453) lr 1.2843e-03 eta 0:31:44
epoch [24/30] batch [600/796] time 0.397 (0.381) data 0.000 (0.001) loss 2.2715 (1.4474) lr 1.2843e-03 eta 0:31:35
epoch [24/30] batch [620/796] time 0.373 (0.381) data 0.000 (0.001) loss 3.5449 (1.4430) lr 1.2843e-03 eta 0:31:28
epoch [24/30] batch [640/796] time 0.385 (0.381) data 0.000 (0.001) loss 2.9043 (1.4407) lr 1.2843e-03 eta 0:31:20
epoch [24/30] batch [660/796] time 0.361 (0.381) data 0.000 (0.001) loss 1.4316 (1.4537) lr 1.2843e-03 eta 0:31:13
epoch [24/30] batch [680/796] time 0.388 (0.381) data 0.000 (0.001) loss 1.4199 (1.4456) lr 1.2843e-03 eta 0:31:05
epoch [24/30] batch [700/796] time 0.365 (0.381) data 0.000 (0.001) loss 1.6113 (1.4444) lr 1.2843e-03 eta 0:30:56
epoch [24/30] batch [720/796] time 0.345 (0.381) data 0.000 (0.001) loss 3.5352 (1.4408) lr 1.2843e-03 eta 0:30:49
epoch [24/30] batch [740/796] time 0.372 (0.381) data 0.000 (0.001) loss 0.9502 (1.4339) lr 1.2843e-03 eta 0:30:41
epoch [24/30] batch [760/796] time 0.389 (0.381) data 0.000 (0.001) loss 1.9238 (1.4344) lr 1.2843e-03 eta 0:30:33
epoch [24/30] batch [780/796] time 0.340 (0.380) data 0.000 (0.001) loss 2.4902 (1.4427) lr 1.2843e-03 eta 0:30:21
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:49,  5.74s/it] 10%|█         | 2/20 [00:06<00:47,  2.65s/it] 15%|█▌        | 3/20 [00:06<00:26,  1.57s/it] 20%|██        | 4/20 [00:06<00:17,  1.07s/it] 25%|██▌       | 5/20 [00:07<00:11,  1.27it/s] 30%|███       | 6/20 [00:07<00:08,  1.63it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.98it/s] 40%|████      | 8/20 [00:07<00:05,  2.27it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.53it/s] 50%|█████     | 10/20 [00:08<00:03,  2.76it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.96it/s] 60%|██████    | 12/20 [00:09<00:02,  3.09it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.20it/s] 70%|███████   | 14/20 [00:09<00:01,  3.31it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.61it/s] 80%|████████  | 16/20 [00:10<00:01,  3.66it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.76it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.06it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.41it/s]100%|██████████| 20/20 [00:10<00:00,  4.75it/s]100%|██████████| 20/20 [00:11<00:00,  1.81it/s]=> result
* total: 1,990
* correct: 1,614
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 80.7%

epoch [25/30] batch [20/796] time 0.409 (0.431) data 0.000 (0.037) loss 1.8262 (1.2317) lr 9.5492e-04 eta 0:34:10
epoch [25/30] batch [40/796] time 0.393 (0.405) data 0.000 (0.018) loss 2.0859 (1.3029) lr 9.5492e-04 eta 0:31:58
epoch [25/30] batch [60/796] time 0.390 (0.397) data 0.000 (0.012) loss 3.2988 (1.4176) lr 9.5492e-04 eta 0:31:13
epoch [25/30] batch [80/796] time 0.361 (0.393) data 0.000 (0.009) loss 1.0654 (1.5125) lr 9.5492e-04 eta 0:30:44
epoch [25/30] batch [100/796] time 0.377 (0.390) data 0.000 (0.008) loss 0.0792 (1.4335) lr 9.5492e-04 eta 0:30:24
epoch [25/30] batch [120/796] time 0.405 (0.388) data 0.000 (0.006) loss 1.0713 (1.4666) lr 9.5492e-04 eta 0:30:04
epoch [25/30] batch [140/796] time 0.373 (0.388) data 0.000 (0.005) loss 0.5137 (1.5521) lr 9.5492e-04 eta 0:29:58
epoch [25/30] batch [160/796] time 0.374 (0.387) data 0.000 (0.005) loss 0.4868 (1.4963) lr 9.5492e-04 eta 0:29:45
epoch [25/30] batch [180/796] time 0.356 (0.386) data 0.000 (0.004) loss 1.5088 (1.4993) lr 9.5492e-04 eta 0:29:33
epoch [25/30] batch [200/796] time 0.347 (0.385) data 0.001 (0.004) loss 0.1641 (1.4538) lr 9.5492e-04 eta 0:29:22
epoch [25/30] batch [220/796] time 0.351 (0.384) data 0.000 (0.004) loss 1.4082 (1.4207) lr 9.5492e-04 eta 0:29:08
epoch [25/30] batch [240/796] time 0.355 (0.382) data 0.000 (0.003) loss 0.7061 (1.4364) lr 9.5492e-04 eta 0:28:54
epoch [25/30] batch [260/796] time 0.366 (0.382) data 0.000 (0.003) loss 1.0176 (1.4485) lr 9.5492e-04 eta 0:28:45
epoch [25/30] batch [280/796] time 0.402 (0.382) data 0.000 (0.003) loss 0.0409 (1.4430) lr 9.5492e-04 eta 0:28:36
epoch [25/30] batch [300/796] time 0.353 (0.381) data 0.000 (0.003) loss 1.4258 (1.4303) lr 9.5492e-04 eta 0:28:27
epoch [25/30] batch [320/796] time 0.397 (0.381) data 0.000 (0.003) loss 0.2883 (1.4089) lr 9.5492e-04 eta 0:28:18
epoch [25/30] batch [340/796] time 0.390 (0.381) data 0.000 (0.002) loss 0.7344 (1.4025) lr 9.5492e-04 eta 0:28:11
epoch [25/30] batch [360/796] time 0.429 (0.381) data 0.000 (0.002) loss 2.2539 (1.4039) lr 9.5492e-04 eta 0:28:02
epoch [25/30] batch [380/796] time 0.358 (0.381) data 0.000 (0.002) loss 0.4954 (1.4150) lr 9.5492e-04 eta 0:27:54
epoch [25/30] batch [400/796] time 0.360 (0.381) data 0.000 (0.002) loss 0.6973 (1.4244) lr 9.5492e-04 eta 0:27:47
epoch [25/30] batch [420/796] time 0.403 (0.381) data 0.000 (0.002) loss 0.1600 (1.4168) lr 9.5492e-04 eta 0:27:40
epoch [25/30] batch [440/796] time 0.379 (0.381) data 0.000 (0.002) loss 4.0352 (1.4293) lr 9.5492e-04 eta 0:27:33
epoch [25/30] batch [460/796] time 0.402 (0.381) data 0.000 (0.002) loss 1.7334 (1.4320) lr 9.5492e-04 eta 0:27:24
epoch [25/30] batch [480/796] time 0.379 (0.381) data 0.000 (0.002) loss 1.1113 (1.4330) lr 9.5492e-04 eta 0:27:17
epoch [25/30] batch [500/796] time 0.379 (0.381) data 0.000 (0.002) loss 1.3887 (1.4353) lr 9.5492e-04 eta 0:27:10
epoch [25/30] batch [520/796] time 0.358 (0.381) data 0.000 (0.002) loss 0.5205 (1.4224) lr 9.5492e-04 eta 0:27:02
epoch [25/30] batch [540/796] time 0.356 (0.381) data 0.000 (0.002) loss 0.2588 (1.4274) lr 9.5492e-04 eta 0:26:52
epoch [25/30] batch [560/796] time 0.362 (0.381) data 0.000 (0.002) loss 0.9854 (1.4155) lr 9.5492e-04 eta 0:26:45
epoch [25/30] batch [580/796] time 0.361 (0.381) data 0.000 (0.002) loss 0.2820 (1.4234) lr 9.5492e-04 eta 0:26:36
epoch [25/30] batch [600/796] time 0.405 (0.381) data 0.000 (0.001) loss 0.2583 (1.4250) lr 9.5492e-04 eta 0:26:28
epoch [25/30] batch [620/796] time 0.363 (0.381) data 0.000 (0.001) loss 3.6953 (1.4445) lr 9.5492e-04 eta 0:26:21
epoch [25/30] batch [640/796] time 0.404 (0.381) data 0.000 (0.001) loss 0.5532 (1.4381) lr 9.5492e-04 eta 0:26:14
epoch [25/30] batch [660/796] time 0.397 (0.381) data 0.000 (0.001) loss 0.9043 (1.4364) lr 9.5492e-04 eta 0:26:06
epoch [25/30] batch [680/796] time 0.363 (0.380) data 0.000 (0.001) loss 0.7808 (1.4473) lr 9.5492e-04 eta 0:25:57
epoch [25/30] batch [700/796] time 0.381 (0.380) data 0.000 (0.001) loss 4.6641 (1.4409) lr 9.5492e-04 eta 0:25:50
epoch [25/30] batch [720/796] time 0.397 (0.380) data 0.000 (0.001) loss 2.3730 (1.4330) lr 9.5492e-04 eta 0:25:43
epoch [25/30] batch [740/796] time 0.346 (0.380) data 0.000 (0.001) loss 1.6113 (1.4276) lr 9.5492e-04 eta 0:25:34
epoch [25/30] batch [760/796] time 0.358 (0.380) data 0.000 (0.001) loss 2.5391 (1.4371) lr 9.5492e-04 eta 0:25:26
epoch [25/30] batch [780/796] time 0.342 (0.379) data 0.000 (0.001) loss 2.3477 (1.4404) lr 9.5492e-04 eta 0:25:15
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.50s/it] 10%|█         | 2/20 [00:06<00:53,  2.95s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.74s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.50it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:08<00:03,  2.77it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.07it/s] 60%|██████    | 12/20 [00:09<00:02,  3.38it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.56it/s] 70%|███████   | 14/20 [00:09<00:01,  3.58it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.68it/s] 80%|████████  | 16/20 [00:10<00:01,  3.71it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.98it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.09it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.43it/s]100%|██████████| 20/20 [00:11<00:00,  4.77it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,608
* accuracy: 80.8%
* error: 19.2%
* macro_f1: 80.4%

epoch [26/30] batch [20/796] time 0.356 (0.421) data 0.000 (0.033) loss 0.2158 (1.1582) lr 6.6987e-04 eta 0:27:46
epoch [26/30] batch [40/796] time 0.403 (0.403) data 0.000 (0.017) loss 0.3284 (1.5271) lr 6.6987e-04 eta 0:26:29
epoch [26/30] batch [60/796] time 0.352 (0.394) data 0.000 (0.011) loss 0.1566 (1.4294) lr 6.6987e-04 eta 0:25:45
epoch [26/30] batch [80/796] time 0.399 (0.392) data 0.000 (0.009) loss 1.3662 (1.3881) lr 6.6987e-04 eta 0:25:29
epoch [26/30] batch [100/796] time 0.383 (0.389) data 0.000 (0.007) loss 0.8896 (1.4771) lr 6.6987e-04 eta 0:25:08
epoch [26/30] batch [120/796] time 0.403 (0.386) data 0.000 (0.006) loss 0.7812 (1.5439) lr 6.6987e-04 eta 0:24:51
epoch [26/30] batch [140/796] time 0.348 (0.386) data 0.000 (0.005) loss 0.5068 (1.5159) lr 6.6987e-04 eta 0:24:41
epoch [26/30] batch [160/796] time 0.391 (0.386) data 0.000 (0.004) loss 0.9282 (1.5477) lr 6.6987e-04 eta 0:24:33
epoch [26/30] batch [180/796] time 0.362 (0.385) data 0.000 (0.004) loss 2.3574 (1.5482) lr 6.6987e-04 eta 0:24:21
epoch [26/30] batch [200/796] time 0.353 (0.383) data 0.000 (0.004) loss 0.7021 (1.5434) lr 6.6987e-04 eta 0:24:08
epoch [26/30] batch [220/796] time 0.350 (0.382) data 0.000 (0.003) loss 0.7231 (1.4922) lr 6.6987e-04 eta 0:23:57
epoch [26/30] batch [240/796] time 0.392 (0.382) data 0.000 (0.003) loss 1.9014 (1.5017) lr 6.6987e-04 eta 0:23:48
epoch [26/30] batch [260/796] time 0.351 (0.381) data 0.000 (0.003) loss 1.7910 (1.5425) lr 6.6987e-04 eta 0:23:39
epoch [26/30] batch [280/796] time 0.392 (0.382) data 0.000 (0.003) loss 1.8457 (1.5234) lr 6.6987e-04 eta 0:23:31
epoch [26/30] batch [300/796] time 0.389 (0.381) data 0.000 (0.002) loss 0.3787 (1.5130) lr 6.6987e-04 eta 0:23:23
epoch [26/30] batch [320/796] time 0.354 (0.381) data 0.000 (0.002) loss 3.2539 (1.4949) lr 6.6987e-04 eta 0:23:14
epoch [26/30] batch [340/796] time 0.397 (0.381) data 0.000 (0.002) loss 0.3088 (1.4966) lr 6.6987e-04 eta 0:23:07
epoch [26/30] batch [360/796] time 0.428 (0.381) data 0.000 (0.002) loss 0.8052 (1.4715) lr 6.6987e-04 eta 0:23:00
epoch [26/30] batch [380/796] time 0.355 (0.381) data 0.000 (0.002) loss 0.4578 (1.4503) lr 6.6987e-04 eta 0:22:53
epoch [26/30] batch [400/796] time 0.349 (0.381) data 0.000 (0.002) loss 5.2734 (1.4720) lr 6.6987e-04 eta 0:22:45
epoch [26/30] batch [420/796] time 0.381 (0.382) data 0.000 (0.002) loss 0.9175 (1.4563) lr 6.6987e-04 eta 0:22:38
epoch [26/30] batch [440/796] time 0.395 (0.382) data 0.000 (0.002) loss 1.4990 (1.4600) lr 6.6987e-04 eta 0:22:30
epoch [26/30] batch [460/796] time 0.360 (0.382) data 0.000 (0.002) loss 1.7402 (1.4622) lr 6.6987e-04 eta 0:22:24
epoch [26/30] batch [480/796] time 0.390 (0.382) data 0.000 (0.002) loss 1.8320 (1.4590) lr 6.6987e-04 eta 0:22:17
epoch [26/30] batch [500/796] time 0.374 (0.382) data 0.000 (0.002) loss 0.6611 (1.4484) lr 6.6987e-04 eta 0:22:10
epoch [26/30] batch [520/796] time 0.399 (0.382) data 0.000 (0.002) loss 1.7754 (1.4385) lr 6.6987e-04 eta 0:22:02
epoch [26/30] batch [540/796] time 0.378 (0.382) data 0.000 (0.001) loss 3.0547 (1.4373) lr 6.6987e-04 eta 0:21:53
epoch [26/30] batch [560/796] time 0.358 (0.381) data 0.000 (0.001) loss 2.9727 (1.4389) lr 6.6987e-04 eta 0:21:44
epoch [26/30] batch [580/796] time 0.406 (0.381) data 0.000 (0.001) loss 0.3208 (1.4428) lr 6.6987e-04 eta 0:21:37
epoch [26/30] batch [600/796] time 0.365 (0.382) data 0.000 (0.001) loss 0.0710 (1.4383) lr 6.6987e-04 eta 0:21:29
epoch [26/30] batch [620/796] time 0.372 (0.381) data 0.000 (0.001) loss 1.2471 (1.4345) lr 6.6987e-04 eta 0:21:21
epoch [26/30] batch [640/796] time 0.355 (0.381) data 0.000 (0.001) loss 0.1628 (1.4478) lr 6.6987e-04 eta 0:21:13
epoch [26/30] batch [660/796] time 0.352 (0.381) data 0.000 (0.001) loss 2.9648 (1.4446) lr 6.6987e-04 eta 0:21:05
epoch [26/30] batch [680/796] time 0.390 (0.381) data 0.000 (0.001) loss 2.0234 (1.4639) lr 6.6987e-04 eta 0:20:57
epoch [26/30] batch [700/796] time 0.396 (0.381) data 0.000 (0.001) loss 1.5098 (1.4597) lr 6.6987e-04 eta 0:20:49
epoch [26/30] batch [720/796] time 0.410 (0.381) data 0.000 (0.001) loss 2.2793 (1.4680) lr 6.6987e-04 eta 0:20:42
epoch [26/30] batch [740/796] time 0.359 (0.381) data 0.000 (0.001) loss 1.2402 (1.4672) lr 6.6987e-04 eta 0:20:35
epoch [26/30] batch [760/796] time 0.380 (0.381) data 0.000 (0.001) loss 0.5811 (1.4660) lr 6.6987e-04 eta 0:20:27
epoch [26/30] batch [780/796] time 0.342 (0.380) data 0.000 (0.001) loss 0.4761 (1.4689) lr 6.6987e-04 eta 0:20:17
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.49s/it] 10%|█         | 2/20 [00:06<00:49,  2.72s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.61s/it] 20%|██        | 4/20 [00:06<00:17,  1.09s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.24it/s] 30%|███       | 6/20 [00:07<00:08,  1.59it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.93it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.71it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.88it/s] 60%|██████    | 12/20 [00:09<00:02,  3.08it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.27it/s] 70%|███████   | 14/20 [00:09<00:01,  3.58it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.78it/s] 80%|████████  | 16/20 [00:10<00:00,  4.02it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.05it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.92it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.28it/s]100%|██████████| 20/20 [00:10<00:00,  4.65it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,620
* accuracy: 81.4%
* error: 18.6%
* macro_f1: 81.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar

epoch [27/30] batch [20/796] time 0.402 (0.426) data 0.000 (0.041) loss 0.5386 (1.6059) lr 4.3227e-04 eta 0:22:27
epoch [27/30] batch [40/796] time 0.376 (0.401) data 0.000 (0.021) loss 0.5444 (1.5724) lr 4.3227e-04 eta 0:21:01
epoch [27/30] batch [60/796] time 0.362 (0.390) data 0.000 (0.014) loss 0.8735 (1.5405) lr 4.3227e-04 eta 0:20:16
epoch [27/30] batch [80/796] time 0.389 (0.385) data 0.000 (0.011) loss 1.1045 (1.4371) lr 4.3227e-04 eta 0:19:56
epoch [27/30] batch [100/796] time 0.392 (0.384) data 0.000 (0.008) loss 0.3516 (1.4414) lr 4.3227e-04 eta 0:19:45
epoch [27/30] batch [120/796] time 0.358 (0.382) data 0.000 (0.007) loss 1.0020 (1.5444) lr 4.3227e-04 eta 0:19:31
epoch [27/30] batch [140/796] time 0.362 (0.382) data 0.000 (0.006) loss 1.1895 (1.5074) lr 4.3227e-04 eta 0:19:23
epoch [27/30] batch [160/796] time 0.354 (0.381) data 0.000 (0.005) loss 1.5957 (1.4437) lr 4.3227e-04 eta 0:19:12
epoch [27/30] batch [180/796] time 0.393 (0.381) data 0.000 (0.005) loss 1.6318 (1.4468) lr 4.3227e-04 eta 0:19:04
epoch [27/30] batch [200/796] time 0.415 (0.381) data 0.000 (0.004) loss 3.1172 (1.4472) lr 4.3227e-04 eta 0:18:57
epoch [27/30] batch [220/796] time 0.354 (0.381) data 0.000 (0.004) loss 0.8794 (1.4850) lr 4.3227e-04 eta 0:18:49
epoch [27/30] batch [240/796] time 0.390 (0.381) data 0.000 (0.004) loss 0.3867 (1.4862) lr 4.3227e-04 eta 0:18:40
epoch [27/30] batch [260/796] time 0.352 (0.381) data 0.000 (0.003) loss 1.2803 (1.4839) lr 4.3227e-04 eta 0:18:33
epoch [27/30] batch [280/796] time 0.378 (0.381) data 0.000 (0.003) loss 1.4932 (1.4627) lr 4.3227e-04 eta 0:18:25
epoch [27/30] batch [300/796] time 0.408 (0.380) data 0.000 (0.003) loss 2.9766 (1.4612) lr 4.3227e-04 eta 0:18:17
epoch [27/30] batch [320/796] time 0.386 (0.380) data 0.000 (0.003) loss 0.6494 (1.4966) lr 4.3227e-04 eta 0:18:08
epoch [27/30] batch [340/796] time 0.402 (0.380) data 0.000 (0.003) loss 1.5488 (1.5128) lr 4.3227e-04 eta 0:18:01
epoch [27/30] batch [360/796] time 0.408 (0.380) data 0.000 (0.003) loss 1.1465 (1.5036) lr 4.3227e-04 eta 0:17:52
epoch [27/30] batch [380/796] time 0.397 (0.380) data 0.000 (0.002) loss 4.4297 (1.4991) lr 4.3227e-04 eta 0:17:44
epoch [27/30] batch [400/796] time 0.361 (0.380) data 0.000 (0.002) loss 0.2537 (1.5002) lr 4.3227e-04 eta 0:17:36
epoch [27/30] batch [420/796] time 0.387 (0.380) data 0.000 (0.002) loss 0.3635 (1.4974) lr 4.3227e-04 eta 0:17:29
epoch [27/30] batch [440/796] time 0.383 (0.380) data 0.000 (0.002) loss 0.9995 (1.4828) lr 4.3227e-04 eta 0:17:22
epoch [27/30] batch [460/796] time 0.391 (0.380) data 0.000 (0.002) loss 1.8887 (1.4772) lr 4.3227e-04 eta 0:17:14
epoch [27/30] batch [480/796] time 0.396 (0.380) data 0.000 (0.002) loss 3.4531 (1.4920) lr 4.3227e-04 eta 0:17:07
epoch [27/30] batch [500/796] time 0.351 (0.380) data 0.000 (0.002) loss 0.9316 (1.4775) lr 4.3227e-04 eta 0:16:59
epoch [27/30] batch [520/796] time 0.369 (0.380) data 0.000 (0.002) loss 1.7930 (1.4977) lr 4.3227e-04 eta 0:16:52
epoch [27/30] batch [540/796] time 0.357 (0.380) data 0.000 (0.002) loss 0.2323 (1.4948) lr 4.3227e-04 eta 0:16:44
epoch [27/30] batch [560/796] time 0.349 (0.380) data 0.000 (0.002) loss 1.3203 (1.5029) lr 4.3227e-04 eta 0:16:35
epoch [27/30] batch [580/796] time 0.400 (0.380) data 0.000 (0.002) loss 1.8682 (1.5173) lr 4.3227e-04 eta 0:16:28
epoch [27/30] batch [600/796] time 0.403 (0.379) data 0.000 (0.002) loss 1.3799 (1.5015) lr 4.3227e-04 eta 0:16:20
epoch [27/30] batch [620/796] time 0.377 (0.380) data 0.000 (0.002) loss 1.2998 (1.4918) lr 4.3227e-04 eta 0:16:13
epoch [27/30] batch [640/796] time 0.383 (0.380) data 0.000 (0.002) loss 0.3254 (1.4931) lr 4.3227e-04 eta 0:16:05
epoch [27/30] batch [660/796] time 0.401 (0.379) data 0.000 (0.001) loss 2.5234 (1.4921) lr 4.3227e-04 eta 0:15:57
epoch [27/30] batch [680/796] time 0.353 (0.380) data 0.000 (0.001) loss 0.1572 (1.4913) lr 4.3227e-04 eta 0:15:50
epoch [27/30] batch [700/796] time 0.358 (0.379) data 0.000 (0.001) loss 2.9766 (1.4988) lr 4.3227e-04 eta 0:15:42
epoch [27/30] batch [720/796] time 0.394 (0.380) data 0.000 (0.001) loss 1.2012 (1.4980) lr 4.3227e-04 eta 0:15:35
epoch [27/30] batch [740/796] time 0.371 (0.380) data 0.000 (0.001) loss 1.1768 (1.4850) lr 4.3227e-04 eta 0:15:27
epoch [27/30] batch [760/796] time 0.402 (0.379) data 0.000 (0.001) loss 1.0156 (1.4849) lr 4.3227e-04 eta 0:15:19
epoch [27/30] batch [780/796] time 0.339 (0.379) data 0.000 (0.001) loss 0.0739 (1.4827) lr 4.3227e-04 eta 0:15:10
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.55s/it] 10%|█         | 2/20 [00:06<00:52,  2.92s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.72s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.71it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.03it/s] 60%|██████    | 12/20 [00:09<00:02,  3.27it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.55it/s] 70%|███████   | 14/20 [00:09<00:01,  3.61it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.93it/s] 80%|████████  | 16/20 [00:10<00:00,  4.14it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.19it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.81it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.20it/s]100%|██████████| 20/20 [00:11<00:00,  4.58it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,611
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 80.6%

epoch [28/30] batch [20/796] time 0.388 (0.426) data 0.000 (0.033) loss 1.9717 (1.4780) lr 2.4472e-04 eta 0:16:48
epoch [28/30] batch [40/796] time 0.349 (0.399) data 0.000 (0.017) loss 2.6328 (1.3576) lr 2.4472e-04 eta 0:15:37
epoch [28/30] batch [60/796] time 0.385 (0.390) data 0.000 (0.011) loss 2.8867 (1.4482) lr 2.4472e-04 eta 0:15:08
epoch [28/30] batch [80/796] time 0.387 (0.389) data 0.000 (0.008) loss 1.5283 (1.5126) lr 2.4472e-04 eta 0:14:57
epoch [28/30] batch [100/796] time 0.371 (0.387) data 0.000 (0.007) loss 1.9160 (1.5781) lr 2.4472e-04 eta 0:14:46
epoch [28/30] batch [120/796] time 0.354 (0.386) data 0.000 (0.006) loss 0.1638 (1.5766) lr 2.4472e-04 eta 0:14:36
epoch [28/30] batch [140/796] time 0.346 (0.384) data 0.000 (0.005) loss 2.1426 (1.5429) lr 2.4472e-04 eta 0:14:24
epoch [28/30] batch [160/796] time 0.361 (0.383) data 0.000 (0.004) loss 0.8750 (1.5244) lr 2.4472e-04 eta 0:14:13
epoch [28/30] batch [180/796] time 0.379 (0.382) data 0.000 (0.004) loss 1.4053 (1.5329) lr 2.4472e-04 eta 0:14:03
epoch [28/30] batch [200/796] time 0.344 (0.382) data 0.000 (0.004) loss 0.8325 (1.5267) lr 2.4472e-04 eta 0:13:55
epoch [28/30] batch [220/796] time 0.391 (0.382) data 0.000 (0.003) loss 4.0898 (1.5234) lr 2.4472e-04 eta 0:13:47
epoch [28/30] batch [240/796] time 0.372 (0.382) data 0.000 (0.003) loss 0.5259 (1.4848) lr 2.4472e-04 eta 0:13:39
epoch [28/30] batch [260/796] time 0.407 (0.381) data 0.000 (0.003) loss 0.3867 (1.4492) lr 2.4472e-04 eta 0:13:30
epoch [28/30] batch [280/796] time 0.362 (0.381) data 0.000 (0.003) loss 3.1309 (1.4352) lr 2.4472e-04 eta 0:13:23
epoch [28/30] batch [300/796] time 0.380 (0.381) data 0.000 (0.002) loss 0.3792 (1.4379) lr 2.4472e-04 eta 0:13:14
epoch [28/30] batch [320/796] time 0.391 (0.381) data 0.000 (0.002) loss 1.1201 (1.4417) lr 2.4472e-04 eta 0:13:07
epoch [28/30] batch [340/796] time 0.371 (0.380) data 0.000 (0.002) loss 3.4688 (1.4275) lr 2.4472e-04 eta 0:12:58
epoch [28/30] batch [360/796] time 0.392 (0.380) data 0.000 (0.002) loss 1.0303 (1.4183) lr 2.4472e-04 eta 0:12:51
epoch [28/30] batch [380/796] time 0.387 (0.380) data 0.000 (0.002) loss 4.2539 (1.4135) lr 2.4472e-04 eta 0:12:43
epoch [28/30] batch [400/796] time 0.402 (0.380) data 0.000 (0.002) loss 2.8730 (1.3941) lr 2.4472e-04 eta 0:12:35
epoch [28/30] batch [420/796] time 0.378 (0.380) data 0.000 (0.002) loss 0.5942 (1.3894) lr 2.4472e-04 eta 0:12:27
epoch [28/30] batch [440/796] time 0.386 (0.380) data 0.000 (0.002) loss 4.0508 (1.3936) lr 2.4472e-04 eta 0:12:20
epoch [28/30] batch [460/796] time 0.370 (0.380) data 0.000 (0.002) loss 3.1875 (1.4132) lr 2.4472e-04 eta 0:12:12
epoch [28/30] batch [480/796] time 0.394 (0.380) data 0.000 (0.002) loss 1.0332 (1.4109) lr 2.4472e-04 eta 0:12:04
epoch [28/30] batch [500/796] time 0.386 (0.380) data 0.000 (0.002) loss 0.7983 (1.4048) lr 2.4472e-04 eta 0:11:56
epoch [28/30] batch [520/796] time 0.377 (0.379) data 0.000 (0.002) loss 1.3672 (1.4047) lr 2.4472e-04 eta 0:11:48
epoch [28/30] batch [540/796] time 0.360 (0.380) data 0.000 (0.001) loss 0.2761 (1.4192) lr 2.4472e-04 eta 0:11:41
epoch [28/30] batch [560/796] time 0.392 (0.380) data 0.000 (0.001) loss 3.9082 (1.4479) lr 2.4472e-04 eta 0:11:34
epoch [28/30] batch [580/796] time 0.388 (0.380) data 0.000 (0.001) loss 2.7031 (1.4481) lr 2.4472e-04 eta 0:11:26
epoch [28/30] batch [600/796] time 0.399 (0.380) data 0.000 (0.001) loss 0.6006 (1.4532) lr 2.4472e-04 eta 0:11:19
epoch [28/30] batch [620/796] time 0.353 (0.380) data 0.000 (0.001) loss 1.6484 (1.4489) lr 2.4472e-04 eta 0:11:11
epoch [28/30] batch [640/796] time 0.364 (0.380) data 0.000 (0.001) loss 1.3926 (1.4536) lr 2.4472e-04 eta 0:11:04
epoch [28/30] batch [660/796] time 0.393 (0.380) data 0.000 (0.001) loss 1.1191 (1.4472) lr 2.4472e-04 eta 0:10:56
epoch [28/30] batch [680/796] time 0.392 (0.380) data 0.000 (0.001) loss 0.7310 (1.4477) lr 2.4472e-04 eta 0:10:48
epoch [28/30] batch [700/796] time 0.356 (0.380) data 0.000 (0.001) loss 0.8105 (1.4521) lr 2.4472e-04 eta 0:10:41
epoch [28/30] batch [720/796] time 0.391 (0.380) data 0.000 (0.001) loss 0.1779 (1.4495) lr 2.4472e-04 eta 0:10:33
epoch [28/30] batch [740/796] time 0.385 (0.380) data 0.000 (0.001) loss 0.7036 (1.4630) lr 2.4472e-04 eta 0:10:25
epoch [28/30] batch [760/796] time 0.406 (0.380) data 0.000 (0.001) loss 1.8027 (1.4692) lr 2.4472e-04 eta 0:10:18
epoch [28/30] batch [780/796] time 0.340 (0.379) data 0.000 (0.001) loss 6.2656 (1.4728) lr 2.4472e-04 eta 0:10:09
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.52s/it] 10%|█         | 2/20 [00:06<00:49,  2.77s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.64s/it] 20%|██        | 4/20 [00:06<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.23it/s] 30%|███       | 6/20 [00:07<00:08,  1.58it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.92it/s] 40%|████      | 8/20 [00:08<00:05,  2.22it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.49it/s] 50%|█████     | 10/20 [00:08<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.17it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.42it/s] 70%|███████   | 14/20 [00:09<00:01,  3.77it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.86it/s] 80%|████████  | 16/20 [00:10<00:01,  3.84it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.85it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.21it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.52it/s]100%|██████████| 20/20 [00:10<00:00,  4.85it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,613
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 80.7%

epoch [29/30] batch [20/796] time 0.397 (0.429) data 0.000 (0.032) loss 0.4695 (1.1173) lr 1.0926e-04 eta 0:11:14
epoch [29/30] batch [40/796] time 0.374 (0.407) data 0.000 (0.016) loss 0.4358 (1.2318) lr 1.0926e-04 eta 0:10:31
epoch [29/30] batch [60/796] time 0.398 (0.396) data 0.000 (0.011) loss 1.0977 (1.2836) lr 1.0926e-04 eta 0:10:06
epoch [29/30] batch [80/796] time 0.356 (0.390) data 0.000 (0.008) loss 2.3672 (1.3669) lr 1.0926e-04 eta 0:09:49
epoch [29/30] batch [100/796] time 0.361 (0.388) data 0.000 (0.007) loss 0.5708 (1.3581) lr 1.0926e-04 eta 0:09:38
epoch [29/30] batch [120/796] time 0.385 (0.386) data 0.000 (0.005) loss 0.8765 (1.3664) lr 1.0926e-04 eta 0:09:28
epoch [29/30] batch [140/796] time 0.392 (0.385) data 0.000 (0.005) loss 0.0163 (1.3776) lr 1.0926e-04 eta 0:09:18
epoch [29/30] batch [160/796] time 0.387 (0.384) data 0.000 (0.004) loss 0.2472 (1.3673) lr 1.0926e-04 eta 0:09:09
epoch [29/30] batch [180/796] time 0.360 (0.383) data 0.000 (0.004) loss 2.3906 (1.3683) lr 1.0926e-04 eta 0:09:00
epoch [29/30] batch [200/796] time 0.394 (0.382) data 0.000 (0.003) loss 2.4590 (1.3680) lr 1.0926e-04 eta 0:08:51
epoch [29/30] batch [220/796] time 0.399 (0.382) data 0.000 (0.003) loss 2.5508 (1.3820) lr 1.0926e-04 eta 0:08:44
epoch [29/30] batch [240/796] time 0.357 (0.382) data 0.000 (0.003) loss 1.1143 (1.3816) lr 1.0926e-04 eta 0:08:36
epoch [29/30] batch [260/796] time 0.376 (0.381) data 0.000 (0.003) loss 2.9062 (1.3855) lr 1.0926e-04 eta 0:08:28
epoch [29/30] batch [280/796] time 0.350 (0.382) data 0.000 (0.002) loss 2.0039 (1.3687) lr 1.0926e-04 eta 0:08:20
epoch [29/30] batch [300/796] time 0.359 (0.381) data 0.000 (0.002) loss 0.6636 (1.3650) lr 1.0926e-04 eta 0:08:12
epoch [29/30] batch [320/796] time 0.403 (0.381) data 0.000 (0.002) loss 0.7896 (1.3785) lr 1.0926e-04 eta 0:08:05
epoch [29/30] batch [340/796] time 0.401 (0.381) data 0.000 (0.002) loss 0.1772 (1.3941) lr 1.0926e-04 eta 0:07:57
epoch [29/30] batch [360/796] time 0.380 (0.381) data 0.000 (0.002) loss 1.1689 (1.3849) lr 1.0926e-04 eta 0:07:49
epoch [29/30] batch [380/796] time 0.384 (0.381) data 0.000 (0.002) loss 0.9155 (1.3768) lr 1.0926e-04 eta 0:07:41
epoch [29/30] batch [400/796] time 0.345 (0.381) data 0.000 (0.002) loss 0.0853 (1.3780) lr 1.0926e-04 eta 0:07:34
epoch [29/30] batch [420/796] time 0.373 (0.381) data 0.000 (0.002) loss 0.9922 (1.3766) lr 1.0926e-04 eta 0:07:26
epoch [29/30] batch [440/796] time 0.412 (0.381) data 0.000 (0.002) loss 0.5171 (1.3567) lr 1.0926e-04 eta 0:07:18
epoch [29/30] batch [460/796] time 0.450 (0.381) data 0.000 (0.002) loss 0.2218 (1.3503) lr 1.0926e-04 eta 0:07:10
epoch [29/30] batch [480/796] time 0.362 (0.381) data 0.000 (0.002) loss 1.3711 (1.3685) lr 1.0926e-04 eta 0:07:03
epoch [29/30] batch [500/796] time 0.418 (0.381) data 0.000 (0.002) loss 3.2188 (1.3754) lr 1.0926e-04 eta 0:06:56
epoch [29/30] batch [520/796] time 0.364 (0.381) data 0.000 (0.001) loss 0.6479 (1.3886) lr 1.0926e-04 eta 0:06:48
epoch [29/30] batch [540/796] time 0.374 (0.381) data 0.000 (0.001) loss 3.5195 (1.4088) lr 1.0926e-04 eta 0:06:40
epoch [29/30] batch [560/796] time 0.399 (0.380) data 0.000 (0.001) loss 2.8164 (1.4179) lr 1.0926e-04 eta 0:06:32
epoch [29/30] batch [580/796] time 0.378 (0.380) data 0.000 (0.001) loss 1.1172 (1.4214) lr 1.0926e-04 eta 0:06:24
epoch [29/30] batch [600/796] time 0.391 (0.380) data 0.000 (0.001) loss 0.4976 (1.4164) lr 1.0926e-04 eta 0:06:17
epoch [29/30] batch [620/796] time 0.399 (0.380) data 0.000 (0.001) loss 0.3044 (1.4171) lr 1.0926e-04 eta 0:06:09
epoch [29/30] batch [640/796] time 0.412 (0.380) data 0.000 (0.001) loss 0.4382 (1.4154) lr 1.0926e-04 eta 0:06:01
epoch [29/30] batch [660/796] time 0.400 (0.380) data 0.000 (0.001) loss 1.5928 (1.4245) lr 1.0926e-04 eta 0:05:54
epoch [29/30] batch [680/796] time 0.367 (0.380) data 0.000 (0.001) loss 0.1741 (1.4189) lr 1.0926e-04 eta 0:05:46
epoch [29/30] batch [700/796] time 0.410 (0.380) data 0.000 (0.001) loss 0.8789 (1.4169) lr 1.0926e-04 eta 0:05:39
epoch [29/30] batch [720/796] time 0.399 (0.380) data 0.000 (0.001) loss 2.0195 (1.4244) lr 1.0926e-04 eta 0:05:31
epoch [29/30] batch [740/796] time 0.384 (0.380) data 0.000 (0.001) loss 3.3828 (1.4237) lr 1.0926e-04 eta 0:05:23
epoch [29/30] batch [760/796] time 0.363 (0.380) data 0.000 (0.001) loss 0.0646 (1.4082) lr 1.0926e-04 eta 0:05:16
epoch [29/30] batch [780/796] time 0.339 (0.379) data 0.000 (0.001) loss 2.0449 (1.4044) lr 1.0926e-04 eta 0:05:07
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.49s/it] 10%|█         | 2/20 [00:06<00:51,  2.88s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:08<00:03,  2.66it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.00it/s] 60%|██████    | 12/20 [00:09<00:02,  3.34it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.70it/s] 70%|███████   | 14/20 [00:09<00:01,  3.69it/s] 75%|███████▌  | 15/20 [00:10<00:01,  4.01it/s] 80%|████████  | 16/20 [00:10<00:00,  4.25it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.19it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.33it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.77it/s]100%|██████████| 20/20 [00:11<00:00,  4.22it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,611
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 80.6%

epoch [30/30] batch [20/796] time 0.388 (0.429) data 0.000 (0.042) loss 3.1602 (1.8629) lr 2.7391e-05 eta 0:05:32
epoch [30/30] batch [40/796] time 0.375 (0.407) data 0.000 (0.021) loss 0.8760 (1.7341) lr 2.7391e-05 eta 0:05:07
epoch [30/30] batch [60/796] time 0.357 (0.396) data 0.000 (0.014) loss 1.0449 (1.6460) lr 2.7391e-05 eta 0:04:51
epoch [30/30] batch [80/796] time 0.392 (0.394) data 0.000 (0.011) loss 1.0830 (1.4869) lr 2.7391e-05 eta 0:04:42
epoch [30/30] batch [100/796] time 0.391 (0.392) data 0.000 (0.009) loss 1.7979 (1.4659) lr 2.7391e-05 eta 0:04:33
epoch [30/30] batch [120/796] time 0.359 (0.389) data 0.000 (0.007) loss 4.3359 (1.4762) lr 2.7391e-05 eta 0:04:23
epoch [30/30] batch [140/796] time 0.375 (0.387) data 0.000 (0.006) loss 0.2484 (1.4428) lr 2.7391e-05 eta 0:04:14
epoch [30/30] batch [160/796] time 0.363 (0.386) data 0.000 (0.005) loss 2.8242 (1.4174) lr 2.7391e-05 eta 0:04:05
epoch [30/30] batch [180/796] time 0.361 (0.384) data 0.000 (0.005) loss 0.2986 (1.4124) lr 2.7391e-05 eta 0:03:56
epoch [30/30] batch [200/796] time 0.367 (0.384) data 0.000 (0.004) loss 0.8955 (1.4193) lr 2.7391e-05 eta 0:03:48
epoch [30/30] batch [220/796] time 0.343 (0.382) data 0.000 (0.004) loss 0.5605 (1.4087) lr 2.7391e-05 eta 0:03:39
epoch [30/30] batch [240/796] time 0.391 (0.381) data 0.000 (0.004) loss 1.2393 (1.3852) lr 2.7391e-05 eta 0:03:32
epoch [30/30] batch [260/796] time 0.396 (0.381) data 0.000 (0.003) loss 2.1914 (1.3912) lr 2.7391e-05 eta 0:03:24
epoch [30/30] batch [280/796] time 0.359 (0.381) data 0.000 (0.003) loss 1.7998 (1.4013) lr 2.7391e-05 eta 0:03:16
epoch [30/30] batch [300/796] time 0.352 (0.381) data 0.000 (0.003) loss 1.9717 (1.4036) lr 2.7391e-05 eta 0:03:08
epoch [30/30] batch [320/796] time 0.355 (0.381) data 0.000 (0.003) loss 1.5889 (1.4117) lr 2.7391e-05 eta 0:03:01
epoch [30/30] batch [340/796] time 0.374 (0.382) data 0.000 (0.003) loss 0.8848 (1.4052) lr 2.7391e-05 eta 0:02:54
epoch [30/30] batch [360/796] time 0.406 (0.382) data 0.000 (0.003) loss 2.6953 (1.3770) lr 2.7391e-05 eta 0:02:46
epoch [30/30] batch [380/796] time 0.371 (0.381) data 0.000 (0.002) loss 1.4795 (1.3792) lr 2.7391e-05 eta 0:02:38
epoch [30/30] batch [400/796] time 0.352 (0.381) data 0.000 (0.002) loss 2.1367 (1.3744) lr 2.7391e-05 eta 0:02:30
epoch [30/30] batch [420/796] time 0.367 (0.381) data 0.000 (0.002) loss 1.5264 (1.3554) lr 2.7391e-05 eta 0:02:23
epoch [30/30] batch [440/796] time 0.382 (0.381) data 0.000 (0.002) loss 0.4272 (1.3560) lr 2.7391e-05 eta 0:02:15
epoch [30/30] batch [460/796] time 0.372 (0.380) data 0.000 (0.002) loss 5.5742 (1.3987) lr 2.7391e-05 eta 0:02:07
epoch [30/30] batch [480/796] time 0.353 (0.380) data 0.000 (0.002) loss 1.7910 (1.3960) lr 2.7391e-05 eta 0:02:00
epoch [30/30] batch [500/796] time 0.400 (0.380) data 0.000 (0.002) loss 0.8159 (1.4007) lr 2.7391e-05 eta 0:01:52
epoch [30/30] batch [520/796] time 0.368 (0.380) data 0.000 (0.002) loss 0.5088 (1.4015) lr 2.7391e-05 eta 0:01:44
epoch [30/30] batch [540/796] time 0.359 (0.380) data 0.000 (0.002) loss 0.4822 (1.3949) lr 2.7391e-05 eta 0:01:37
epoch [30/30] batch [560/796] time 0.373 (0.380) data 0.000 (0.002) loss 1.5557 (1.3920) lr 2.7391e-05 eta 0:01:29
epoch [30/30] batch [580/796] time 0.403 (0.380) data 0.000 (0.002) loss 2.5254 (1.3903) lr 2.7391e-05 eta 0:01:22
epoch [30/30] batch [600/796] time 0.407 (0.380) data 0.000 (0.002) loss 0.7979 (1.3927) lr 2.7391e-05 eta 0:01:14
epoch [30/30] batch [620/796] time 0.408 (0.380) data 0.000 (0.002) loss 0.6348 (1.3913) lr 2.7391e-05 eta 0:01:06
epoch [30/30] batch [640/796] time 0.378 (0.380) data 0.000 (0.002) loss 1.3447 (1.3977) lr 2.7391e-05 eta 0:00:59
epoch [30/30] batch [660/796] time 0.361 (0.380) data 0.000 (0.002) loss 1.9258 (1.4077) lr 2.7391e-05 eta 0:00:51
epoch [30/30] batch [680/796] time 0.345 (0.380) data 0.000 (0.001) loss 0.2441 (1.4106) lr 2.7391e-05 eta 0:00:44
epoch [30/30] batch [700/796] time 0.439 (0.380) data 0.000 (0.001) loss 2.9863 (1.4170) lr 2.7391e-05 eta 0:00:36
epoch [30/30] batch [720/796] time 0.396 (0.380) data 0.000 (0.001) loss 0.3774 (1.4093) lr 2.7391e-05 eta 0:00:28
epoch [30/30] batch [740/796] time 0.395 (0.380) data 0.000 (0.001) loss 0.5981 (1.4062) lr 2.7391e-05 eta 0:00:21
epoch [30/30] batch [760/796] time 0.401 (0.380) data 0.000 (0.001) loss 2.5039 (1.4065) lr 2.7391e-05 eta 0:00:13
epoch [30/30] batch [780/796] time 0.344 (0.380) data 0.000 (0.001) loss 1.6875 (1.4022) lr 2.7391e-05 eta 0:00:06
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.64s/it] 10%|█         | 2/20 [00:06<00:49,  2.76s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.64s/it] 20%|██        | 4/20 [00:06<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:08,  1.57it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.51it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.22it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.58it/s] 70%|███████   | 14/20 [00:09<00:01,  3.64it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.66it/s] 80%|████████  | 16/20 [00:10<00:01,  3.89it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.99it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.80it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.18it/s]100%|██████████| 20/20 [00:11<00:00,  4.57it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]
=> result
* total: 1,990
* correct: 1,612
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 80.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 26)
Evaluate on the *test* set
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:05<08:45,  5.31s/it]  2%|▏         | 2/100 [00:05<04:08,  2.54s/it]  3%|▎         | 3/100 [00:07<03:27,  2.14s/it]  4%|▍         | 4/100 [00:08<02:23,  1.50s/it]  5%|▌         | 5/100 [00:08<01:47,  1.14s/it]  6%|▌         | 6/100 [00:09<01:27,  1.07it/s]  7%|▋         | 7/100 [00:09<01:13,  1.27it/s]  8%|▊         | 8/100 [00:10<01:03,  1.46it/s]  9%|▉         | 9/100 [00:10<00:56,  1.61it/s] 10%|█         | 10/100 [00:11<00:51,  1.75it/s] 11%|█         | 11/100 [00:11<00:47,  1.86it/s] 12%|█▏        | 12/100 [00:12<00:47,  1.86it/s] 13%|█▎        | 13/100 [00:12<00:44,  1.94it/s] 14%|█▍        | 14/100 [00:13<00:44,  1.91it/s] 15%|█▌        | 15/100 [00:13<00:43,  1.96it/s] 16%|█▌        | 16/100 [00:14<00:44,  1.91it/s] 17%|█▋        | 17/100 [00:14<00:42,  1.93it/s] 18%|█▊        | 18/100 [00:15<00:42,  1.91it/s] 19%|█▉        | 19/100 [00:15<00:41,  1.95it/s] 20%|██        | 20/100 [00:16<00:39,  2.04it/s] 21%|██        | 21/100 [00:16<00:38,  2.08it/s] 22%|██▏       | 22/100 [00:16<00:35,  2.18it/s] 23%|██▎       | 23/100 [00:17<00:33,  2.30it/s] 24%|██▍       | 24/100 [00:17<00:31,  2.39it/s] 25%|██▌       | 25/100 [00:18<00:30,  2.44it/s] 26%|██▌       | 26/100 [00:18<00:30,  2.41it/s] 27%|██▋       | 27/100 [00:18<00:31,  2.35it/s] 28%|██▊       | 28/100 [00:19<00:30,  2.33it/s] 29%|██▉       | 29/100 [00:19<00:31,  2.28it/s] 30%|███       | 30/100 [00:20<00:31,  2.24it/s] 31%|███       | 31/100 [00:20<00:32,  2.15it/s] 32%|███▏      | 32/100 [00:21<00:32,  2.08it/s] 33%|███▎      | 33/100 [00:21<00:32,  2.04it/s] 34%|███▍      | 34/100 [00:22<00:32,  2.04it/s] 35%|███▌      | 35/100 [00:22<00:30,  2.12it/s] 36%|███▌      | 36/100 [00:23<00:28,  2.21it/s] 37%|███▋      | 37/100 [00:23<00:28,  2.23it/s] 38%|███▊      | 38/100 [00:23<00:26,  2.30it/s] 39%|███▉      | 39/100 [00:24<00:26,  2.31it/s] 40%|████      | 40/100 [00:24<00:26,  2.27it/s] 41%|████      | 41/100 [00:25<00:25,  2.34it/s] 42%|████▏     | 42/100 [00:25<00:23,  2.46it/s] 43%|████▎     | 43/100 [00:25<00:22,  2.55it/s] 44%|████▍     | 44/100 [00:26<00:21,  2.61it/s] 45%|████▌     | 45/100 [00:26<00:21,  2.61it/s] 46%|████▌     | 46/100 [00:27<00:20,  2.62it/s] 47%|████▋     | 47/100 [00:27<00:19,  2.69it/s] 48%|████▊     | 48/100 [00:27<00:19,  2.62it/s] 49%|████▉     | 49/100 [00:28<00:19,  2.61it/s] 50%|█████     | 50/100 [00:28<00:19,  2.55it/s] 51%|█████     | 51/100 [00:29<00:19,  2.47it/s] 52%|█████▏    | 52/100 [00:29<00:19,  2.45it/s] 53%|█████▎    | 53/100 [00:29<00:18,  2.52it/s] 54%|█████▍    | 54/100 [00:30<00:17,  2.57it/s] 55%|█████▌    | 55/100 [00:30<00:17,  2.58it/s] 56%|█████▌    | 56/100 [00:31<00:16,  2.59it/s] 57%|█████▋    | 57/100 [00:31<00:16,  2.61it/s] 58%|█████▊    | 58/100 [00:31<00:16,  2.56it/s] 59%|█████▉    | 59/100 [00:32<00:16,  2.49it/s] 60%|██████    | 60/100 [00:32<00:15,  2.58it/s] 61%|██████    | 61/100 [00:33<00:15,  2.49it/s] 62%|██████▏   | 62/100 [00:33<00:16,  2.37it/s] 63%|██████▎   | 63/100 [00:33<00:15,  2.31it/s] 64%|██████▍   | 64/100 [00:34<00:15,  2.33it/s] 65%|██████▌   | 65/100 [00:34<00:15,  2.32it/s] 66%|██████▌   | 66/100 [00:35<00:14,  2.28it/s] 67%|██████▋   | 67/100 [00:35<00:14,  2.24it/s] 68%|██████▊   | 68/100 [00:36<00:14,  2.18it/s] 69%|██████▉   | 69/100 [00:36<00:13,  2.23it/s] 70%|███████   | 70/100 [00:36<00:12,  2.38it/s] 71%|███████   | 71/100 [00:37<00:11,  2.54it/s] 72%|███████▏  | 72/100 [00:37<00:10,  2.65it/s] 73%|███████▎  | 73/100 [00:37<00:09,  2.76it/s] 74%|███████▍  | 74/100 [00:38<00:09,  2.88it/s] 75%|███████▌  | 75/100 [00:38<00:08,  2.96it/s] 76%|███████▌  | 76/100 [00:38<00:07,  3.06it/s] 77%|███████▋  | 77/100 [00:39<00:07,  3.13it/s] 78%|███████▊  | 78/100 [00:39<00:06,  3.24it/s] 79%|███████▉  | 79/100 [00:39<00:06,  3.27it/s] 80%|████████  | 80/100 [00:40<00:05,  3.37it/s] 81%|████████  | 81/100 [00:40<00:05,  3.65it/s] 82%|████████▏ | 82/100 [00:40<00:04,  4.06it/s] 83%|████████▎ | 83/100 [00:40<00:03,  4.40it/s] 84%|████████▍ | 84/100 [00:40<00:03,  4.68it/s] 85%|████████▌ | 85/100 [00:41<00:03,  4.90it/s] 86%|████████▌ | 86/100 [00:41<00:02,  5.06it/s] 87%|████████▋ | 87/100 [00:41<00:02,  5.19it/s] 88%|████████▊ | 88/100 [00:41<00:02,  5.27it/s] 89%|████████▉ | 89/100 [00:41<00:02,  5.34it/s] 90%|█████████ | 90/100 [00:41<00:01,  5.38it/s] 91%|█████████ | 91/100 [00:42<00:01,  5.41it/s] 92%|█████████▏| 92/100 [00:42<00:01,  5.44it/s] 93%|█████████▎| 93/100 [00:42<00:01,  5.46it/s] 94%|█████████▍| 94/100 [00:42<00:01,  5.47it/s] 95%|█████████▌| 95/100 [00:42<00:00,  5.47it/s] 96%|█████████▌| 96/100 [00:43<00:00,  5.48it/s] 97%|█████████▋| 97/100 [00:43<00:00,  5.48it/s] 98%|█████████▊| 98/100 [00:43<00:00,  5.48it/s] 99%|█████████▉| 99/100 [00:43<00:00,  5.48it/s]100%|██████████| 100/100 [00:43<00:00,  6.03it/s]100%|██████████| 100/100 [00:43<00:00,  2.28it/s]
=> result
* total: 9,950
* correct: 8,106
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 81.2%
Elapsed: 2:37:17
+ sh scripts/rpo_prime/base2new_test_sdl.sh sun397 2 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
3168 1980 9900
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  198
# train_x  3,168
# val      1,980
# test     9,900
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed2/prompt_learner/model-best.pth.tar" (epoch = 26)
Evaluate on the *test* set
  0%|          | 0/99 [00:00<?, ?it/s]  1%|          | 1/99 [00:09<16:02,  9.83s/it]  2%|▏         | 2/99 [00:10<06:55,  4.29s/it]  3%|▎         | 3/99 [00:10<03:58,  2.48s/it]  4%|▍         | 4/99 [00:10<02:34,  1.63s/it]  5%|▌         | 5/99 [00:11<01:49,  1.16s/it]  6%|▌         | 6/99 [00:11<01:22,  1.13it/s]  7%|▋         | 7/99 [00:11<01:04,  1.42it/s]  8%|▊         | 8/99 [00:12<00:53,  1.71it/s]  9%|▉         | 9/99 [00:12<00:45,  1.98it/s] 10%|█         | 10/99 [00:12<00:40,  2.19it/s] 11%|█         | 11/99 [00:13<00:37,  2.35it/s] 12%|█▏        | 12/99 [00:13<00:36,  2.41it/s] 13%|█▎        | 13/99 [00:14<00:34,  2.50it/s] 14%|█▍        | 14/99 [00:14<00:35,  2.42it/s] 15%|█▌        | 15/99 [00:14<00:35,  2.35it/s] 16%|█▌        | 16/99 [00:15<00:37,  2.24it/s] 17%|█▋        | 17/99 [00:15<00:36,  2.25it/s] 18%|█▊        | 18/99 [00:16<00:36,  2.20it/s] 19%|█▉        | 19/99 [00:16<00:37,  2.15it/s] 20%|██        | 20/99 [00:17<00:35,  2.23it/s] 21%|██        | 21/99 [00:17<00:35,  2.23it/s] 22%|██▏       | 22/99 [00:18<00:35,  2.20it/s] 23%|██▎       | 23/99 [00:18<00:34,  2.21it/s] 24%|██▍       | 24/99 [00:19<00:33,  2.23it/s] 25%|██▌       | 25/99 [00:19<00:33,  2.21it/s] 26%|██▋       | 26/99 [00:19<00:32,  2.27it/s] 27%|██▋       | 27/99 [00:20<00:29,  2.46it/s] 28%|██▊       | 28/99 [00:20<00:27,  2.62it/s] 29%|██▉       | 29/99 [00:20<00:26,  2.67it/s] 30%|███       | 30/99 [00:21<00:24,  2.77it/s] 31%|███▏      | 31/99 [00:21<00:24,  2.80it/s] 32%|███▏      | 32/99 [00:21<00:23,  2.80it/s] 33%|███▎      | 33/99 [00:22<00:23,  2.79it/s] 34%|███▍      | 34/99 [00:22<00:24,  2.70it/s] 35%|███▌      | 35/99 [00:23<00:24,  2.66it/s] 36%|███▋      | 36/99 [00:23<00:25,  2.46it/s] 37%|███▋      | 37/99 [00:24<00:26,  2.36it/s] 38%|███▊      | 38/99 [00:24<00:25,  2.38it/s] 39%|███▉      | 39/99 [00:24<00:24,  2.41it/s] 40%|████      | 40/99 [00:25<00:24,  2.45it/s] 41%|████▏     | 41/99 [00:25<00:23,  2.51it/s] 42%|████▏     | 42/99 [00:26<00:22,  2.53it/s] 43%|████▎     | 43/99 [00:26<00:22,  2.52it/s] 44%|████▍     | 44/99 [00:26<00:21,  2.58it/s] 45%|████▌     | 45/99 [00:27<00:21,  2.56it/s] 46%|████▋     | 46/99 [00:27<00:20,  2.60it/s] 47%|████▋     | 47/99 [00:27<00:20,  2.57it/s] 48%|████▊     | 48/99 [00:28<00:20,  2.46it/s] 49%|████▉     | 49/99 [00:28<00:20,  2.48it/s] 51%|█████     | 50/99 [00:29<00:19,  2.45it/s] 52%|█████▏    | 51/99 [00:29<00:19,  2.46it/s] 53%|█████▎    | 52/99 [00:30<00:19,  2.42it/s] 54%|█████▎    | 53/99 [00:30<00:19,  2.40it/s] 55%|█████▍    | 54/99 [00:30<00:19,  2.31it/s] 56%|█████▌    | 55/99 [00:31<00:19,  2.28it/s] 57%|█████▋    | 56/99 [00:31<00:18,  2.32it/s] 58%|█████▊    | 57/99 [00:32<00:17,  2.45it/s] 59%|█████▊    | 58/99 [00:32<00:15,  2.59it/s] 60%|█████▉    | 59/99 [00:32<00:15,  2.59it/s] 61%|██████    | 60/99 [00:33<00:15,  2.51it/s] 62%|██████▏   | 61/99 [00:33<00:15,  2.38it/s] 63%|██████▎   | 62/99 [00:34<00:15,  2.38it/s] 64%|██████▎   | 63/99 [00:34<00:15,  2.38it/s] 65%|██████▍   | 64/99 [00:34<00:13,  2.51it/s] 66%|██████▌   | 65/99 [00:35<00:13,  2.46it/s] 67%|██████▋   | 66/99 [00:35<00:13,  2.40it/s] 68%|██████▊   | 67/99 [00:36<00:12,  2.50it/s] 69%|██████▊   | 68/99 [00:36<00:12,  2.53it/s] 70%|██████▉   | 69/99 [00:36<00:11,  2.60it/s] 71%|███████   | 70/99 [00:37<00:10,  2.64it/s] 72%|███████▏  | 71/99 [00:37<00:10,  2.75it/s] 73%|███████▎  | 72/99 [00:37<00:09,  2.91it/s] 74%|███████▎  | 73/99 [00:38<00:08,  2.99it/s] 75%|███████▍  | 74/99 [00:38<00:08,  3.03it/s] 76%|███████▌  | 75/99 [00:38<00:07,  3.14it/s] 77%|███████▋  | 76/99 [00:39<00:07,  3.23it/s] 78%|███████▊  | 77/99 [00:39<00:06,  3.28it/s] 79%|███████▉  | 78/99 [00:39<00:06,  3.36it/s] 80%|███████▉  | 79/99 [00:39<00:05,  3.62it/s] 81%|████████  | 80/99 [00:40<00:05,  3.69it/s] 82%|████████▏ | 81/99 [00:40<00:04,  3.76it/s] 83%|████████▎ | 82/99 [00:40<00:04,  4.15it/s] 84%|████████▍ | 83/99 [00:40<00:03,  4.48it/s] 85%|████████▍ | 84/99 [00:41<00:03,  4.74it/s] 86%|████████▌ | 85/99 [00:41<00:02,  4.95it/s] 87%|████████▋ | 86/99 [00:41<00:02,  5.08it/s] 88%|████████▊ | 87/99 [00:41<00:02,  5.20it/s] 89%|████████▉ | 88/99 [00:41<00:02,  5.28it/s] 90%|████████▉ | 89/99 [00:41<00:01,  5.34it/s] 91%|█████████ | 90/99 [00:42<00:01,  5.39it/s] 92%|█████████▏| 91/99 [00:42<00:01,  5.42it/s] 93%|█████████▎| 92/99 [00:42<00:01,  5.44it/s] 94%|█████████▍| 93/99 [00:42<00:01,  5.46it/s] 95%|█████████▍| 94/99 [00:42<00:00,  5.45it/s] 96%|█████████▌| 95/99 [00:43<00:00,  5.47it/s] 97%|█████████▋| 96/99 [00:43<00:00,  5.48it/s] 98%|█████████▊| 97/99 [00:43<00:00,  5.49it/s] 99%|█████████▉| 98/99 [00:43<00:00,  5.49it/s]100%|██████████| 99/99 [00:43<00:00,  5.49it/s]100%|██████████| 99/99 [00:43<00:00,  2.26it/s]
=> result
* total: 9,900
* correct: 7,785
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 77.6%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh sun397 3 0 main_tmp1_0.1sdl 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
3184 1990 9950
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  199
# train_x  3,184
# val      1,990
# test     9,950
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/796] time 0.403 (0.508) data 0.000 (0.061) loss 3.3086 (2.7496) lr 1.0000e-02 eta 3:21:58
epoch [1/30] batch [40/796] time 0.400 (0.445) data 0.000 (0.031) loss 4.9219 (2.8429) lr 1.0000e-02 eta 2:56:54
epoch [1/30] batch [60/796] time 0.420 (0.421) data 0.000 (0.021) loss 3.7988 (2.7934) lr 1.0000e-02 eta 2:47:07
epoch [1/30] batch [80/796] time 0.385 (0.411) data 0.000 (0.015) loss 3.3320 (2.6980) lr 1.0000e-02 eta 2:42:57
epoch [1/30] batch [100/796] time 0.398 (0.405) data 0.000 (0.012) loss 2.0508 (2.6703) lr 1.0000e-02 eta 2:40:28
epoch [1/30] batch [120/796] time 0.399 (0.401) data 0.000 (0.010) loss 0.8896 (2.5271) lr 1.0000e-02 eta 2:38:54
epoch [1/30] batch [140/796] time 0.351 (0.398) data 0.000 (0.009) loss 5.0938 (2.5472) lr 1.0000e-02 eta 2:37:18
epoch [1/30] batch [160/796] time 0.395 (0.395) data 0.000 (0.008) loss 1.9092 (2.5334) lr 1.0000e-02 eta 2:36:07
epoch [1/30] batch [180/796] time 0.400 (0.394) data 0.000 (0.007) loss 0.5420 (2.4595) lr 1.0000e-02 eta 2:35:26
epoch [1/30] batch [200/796] time 0.398 (0.392) data 0.000 (0.006) loss 4.4922 (2.4835) lr 1.0000e-02 eta 2:34:34
epoch [1/30] batch [220/796] time 0.390 (0.390) data 0.000 (0.006) loss 1.0342 (2.4530) lr 1.0000e-02 eta 2:33:48
epoch [1/30] batch [240/796] time 0.350 (0.389) data 0.000 (0.005) loss 1.8193 (2.3933) lr 1.0000e-02 eta 2:33:15
epoch [1/30] batch [260/796] time 0.394 (0.389) data 0.000 (0.005) loss 2.2109 (2.3597) lr 1.0000e-02 eta 2:33:12
epoch [1/30] batch [280/796] time 0.361 (0.388) data 0.000 (0.005) loss 1.3311 (2.3075) lr 1.0000e-02 eta 2:32:35
epoch [1/30] batch [300/796] time 0.401 (0.388) data 0.000 (0.004) loss 4.0078 (2.2996) lr 1.0000e-02 eta 2:32:20
epoch [1/30] batch [320/796] time 0.371 (0.387) data 0.000 (0.004) loss 2.7305 (2.2701) lr 1.0000e-02 eta 2:32:03
epoch [1/30] batch [340/796] time 0.398 (0.387) data 0.000 (0.004) loss 1.6377 (2.2494) lr 1.0000e-02 eta 2:31:46
epoch [1/30] batch [360/796] time 0.394 (0.386) data 0.000 (0.004) loss 0.7036 (2.2048) lr 1.0000e-02 eta 2:31:27
epoch [1/30] batch [380/796] time 0.376 (0.386) data 0.000 (0.003) loss 0.3796 (2.2217) lr 1.0000e-02 eta 2:31:09
epoch [1/30] batch [400/796] time 0.378 (0.386) data 0.000 (0.003) loss 0.3442 (2.1954) lr 1.0000e-02 eta 2:31:02
epoch [1/30] batch [420/796] time 0.381 (0.386) data 0.000 (0.003) loss 3.9160 (2.2339) lr 1.0000e-02 eta 2:30:45
epoch [1/30] batch [440/796] time 0.357 (0.385) data 0.000 (0.003) loss 3.0234 (2.2315) lr 1.0000e-02 eta 2:30:30
epoch [1/30] batch [460/796] time 0.403 (0.385) data 0.000 (0.003) loss 1.3604 (2.2341) lr 1.0000e-02 eta 2:30:11
epoch [1/30] batch [480/796] time 0.356 (0.385) data 0.000 (0.003) loss 2.4609 (2.2510) lr 1.0000e-02 eta 2:30:00
epoch [1/30] batch [500/796] time 0.386 (0.384) data 0.000 (0.003) loss 1.2900 (2.2261) lr 1.0000e-02 eta 2:29:43
epoch [1/30] batch [520/796] time 0.397 (0.384) data 0.000 (0.003) loss 1.1426 (2.2030) lr 1.0000e-02 eta 2:29:23
epoch [1/30] batch [540/796] time 0.401 (0.384) data 0.000 (0.003) loss 3.0430 (2.2091) lr 1.0000e-02 eta 2:29:13
epoch [1/30] batch [560/796] time 0.396 (0.384) data 0.000 (0.002) loss 2.4043 (2.2072) lr 1.0000e-02 eta 2:29:06
epoch [1/30] batch [580/796] time 0.390 (0.384) data 0.000 (0.002) loss 1.6904 (2.1796) lr 1.0000e-02 eta 2:28:55
epoch [1/30] batch [600/796] time 0.380 (0.383) data 0.000 (0.002) loss 1.8203 (2.1757) lr 1.0000e-02 eta 2:28:45
epoch [1/30] batch [620/796] time 0.390 (0.383) data 0.000 (0.002) loss 2.4395 (2.1641) lr 1.0000e-02 eta 2:28:36
epoch [1/30] batch [640/796] time 0.379 (0.383) data 0.000 (0.002) loss 1.1943 (2.1489) lr 1.0000e-02 eta 2:28:26
epoch [1/30] batch [660/796] time 0.361 (0.383) data 0.000 (0.002) loss 0.7314 (2.1443) lr 1.0000e-02 eta 2:28:20
epoch [1/30] batch [680/796] time 0.359 (0.383) data 0.000 (0.002) loss 6.6836 (2.1478) lr 1.0000e-02 eta 2:28:10
epoch [1/30] batch [700/796] time 0.377 (0.383) data 0.000 (0.002) loss 3.5820 (2.1490) lr 1.0000e-02 eta 2:28:00
epoch [1/30] batch [720/796] time 0.393 (0.383) data 0.000 (0.002) loss 1.4590 (2.1545) lr 1.0000e-02 eta 2:27:53
epoch [1/30] batch [740/796] time 0.384 (0.383) data 0.000 (0.002) loss 4.5703 (2.1386) lr 1.0000e-02 eta 2:27:45
epoch [1/30] batch [760/796] time 0.377 (0.383) data 0.000 (0.002) loss 0.5361 (2.1256) lr 1.0000e-02 eta 2:27:37
epoch [1/30] batch [780/796] time 0.342 (0.382) data 0.000 (0.002) loss 7.3867 (2.1310) lr 1.0000e-02 eta 2:27:13
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:48,  5.73s/it] 10%|█         | 2/20 [00:06<00:52,  2.90s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.71s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.42it/s] 50%|█████     | 10/20 [00:09<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.97it/s] 60%|██████    | 12/20 [00:09<00:02,  3.23it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.31it/s] 70%|███████   | 14/20 [00:10<00:01,  3.44it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.76it/s] 80%|████████  | 16/20 [00:10<00:01,  3.87it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.90it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.27it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.57it/s]100%|██████████| 20/20 [00:11<00:00,  4.89it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,512
* accuracy: 76.0%
* error: 24.0%
* macro_f1: 74.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/796] time 0.357 (0.419) data 0.000 (0.033) loss 1.4414 (2.0918) lr 9.9726e-03 eta 2:41:10
epoch [2/30] batch [40/796] time 0.418 (0.400) data 0.000 (0.016) loss 3.2363 (2.1294) lr 9.9726e-03 eta 2:33:43
epoch [2/30] batch [60/796] time 0.389 (0.394) data 0.000 (0.011) loss 0.7227 (2.1800) lr 9.9726e-03 eta 2:31:09
epoch [2/30] batch [80/796] time 0.348 (0.392) data 0.000 (0.008) loss 2.6406 (2.1657) lr 9.9726e-03 eta 2:30:06
epoch [2/30] batch [100/796] time 0.393 (0.391) data 0.000 (0.007) loss 3.9180 (2.1024) lr 9.9726e-03 eta 2:29:44
epoch [2/30] batch [120/796] time 0.402 (0.390) data 0.000 (0.006) loss 0.1562 (2.0674) lr 9.9726e-03 eta 2:29:07
epoch [2/30] batch [140/796] time 0.401 (0.388) data 0.000 (0.005) loss 0.5986 (2.0402) lr 9.9726e-03 eta 2:28:19
epoch [2/30] batch [160/796] time 0.373 (0.387) data 0.000 (0.004) loss 1.2002 (1.9817) lr 9.9726e-03 eta 2:27:42
epoch [2/30] batch [180/796] time 0.397 (0.385) data 0.000 (0.004) loss 2.4082 (2.0052) lr 9.9726e-03 eta 2:27:06
epoch [2/30] batch [200/796] time 0.378 (0.385) data 0.000 (0.003) loss 0.4053 (1.9799) lr 9.9726e-03 eta 2:26:57
epoch [2/30] batch [220/796] time 0.403 (0.384) data 0.000 (0.003) loss 0.4294 (1.9967) lr 9.9726e-03 eta 2:26:23
epoch [2/30] batch [240/796] time 0.376 (0.383) data 0.000 (0.003) loss 2.2266 (2.0080) lr 9.9726e-03 eta 2:25:56
epoch [2/30] batch [260/796] time 0.403 (0.383) data 0.000 (0.003) loss 2.0449 (2.0489) lr 9.9726e-03 eta 2:25:46
epoch [2/30] batch [280/796] time 0.399 (0.383) data 0.000 (0.003) loss 1.1807 (2.0438) lr 9.9726e-03 eta 2:25:41
epoch [2/30] batch [300/796] time 0.371 (0.383) data 0.000 (0.002) loss 1.0605 (2.0562) lr 9.9726e-03 eta 2:25:26
epoch [2/30] batch [320/796] time 0.372 (0.383) data 0.000 (0.002) loss 1.5986 (2.0605) lr 9.9726e-03 eta 2:25:13
epoch [2/30] batch [340/796] time 0.359 (0.382) data 0.000 (0.002) loss 1.2246 (2.0678) lr 9.9726e-03 eta 2:24:58
epoch [2/30] batch [360/796] time 0.387 (0.383) data 0.000 (0.002) loss 1.1572 (2.0265) lr 9.9726e-03 eta 2:24:55
epoch [2/30] batch [380/796] time 0.364 (0.383) data 0.000 (0.002) loss 0.7148 (2.0212) lr 9.9726e-03 eta 2:24:51
epoch [2/30] batch [400/796] time 0.354 (0.383) data 0.000 (0.002) loss 3.1836 (2.0144) lr 9.9726e-03 eta 2:24:51
epoch [2/30] batch [420/796] time 0.393 (0.383) data 0.000 (0.002) loss 1.8877 (2.0053) lr 9.9726e-03 eta 2:24:38
epoch [2/30] batch [440/796] time 0.368 (0.383) data 0.000 (0.002) loss 1.7480 (1.9910) lr 9.9726e-03 eta 2:24:32
epoch [2/30] batch [460/796] time 0.363 (0.383) data 0.000 (0.002) loss 0.8623 (1.9802) lr 9.9726e-03 eta 2:24:21
epoch [2/30] batch [480/796] time 0.353 (0.383) data 0.000 (0.002) loss 1.5029 (1.9657) lr 9.9726e-03 eta 2:24:06
epoch [2/30] batch [500/796] time 0.384 (0.382) data 0.000 (0.002) loss 5.0547 (1.9826) lr 9.9726e-03 eta 2:23:58
epoch [2/30] batch [520/796] time 0.393 (0.383) data 0.000 (0.002) loss 1.2305 (1.9901) lr 9.9726e-03 eta 2:23:53
epoch [2/30] batch [540/796] time 0.414 (0.383) data 0.000 (0.001) loss 0.9727 (1.9707) lr 9.9726e-03 eta 2:23:45
epoch [2/30] batch [560/796] time 0.379 (0.382) data 0.000 (0.001) loss 4.5938 (1.9832) lr 9.9726e-03 eta 2:23:30
epoch [2/30] batch [580/796] time 0.373 (0.382) data 0.000 (0.001) loss 4.0781 (1.9799) lr 9.9726e-03 eta 2:23:18
epoch [2/30] batch [600/796] time 0.398 (0.382) data 0.000 (0.001) loss 1.6855 (1.9896) lr 9.9726e-03 eta 2:23:15
epoch [2/30] batch [620/796] time 0.391 (0.382) data 0.000 (0.001) loss 0.5186 (1.9828) lr 9.9726e-03 eta 2:23:03
epoch [2/30] batch [640/796] time 0.357 (0.382) data 0.000 (0.001) loss 2.6309 (1.9798) lr 9.9726e-03 eta 2:22:59
epoch [2/30] batch [660/796] time 0.367 (0.382) data 0.000 (0.001) loss 1.1172 (1.9786) lr 9.9726e-03 eta 2:22:46
epoch [2/30] batch [680/796] time 0.395 (0.382) data 0.000 (0.001) loss 1.6377 (1.9694) lr 9.9726e-03 eta 2:22:38
epoch [2/30] batch [700/796] time 0.389 (0.382) data 0.000 (0.001) loss 1.8232 (1.9708) lr 9.9726e-03 eta 2:22:30
epoch [2/30] batch [720/796] time 0.396 (0.382) data 0.000 (0.001) loss 1.2744 (1.9653) lr 9.9726e-03 eta 2:22:20
epoch [2/30] batch [740/796] time 0.405 (0.382) data 0.000 (0.001) loss 1.0850 (1.9639) lr 9.9726e-03 eta 2:22:12
epoch [2/30] batch [760/796] time 0.385 (0.382) data 0.000 (0.001) loss 5.1836 (1.9739) lr 9.9726e-03 eta 2:22:06
epoch [2/30] batch [780/796] time 0.342 (0.381) data 0.000 (0.001) loss 0.3672 (1.9795) lr 9.9726e-03 eta 2:21:43
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:49,  5.78s/it] 10%|█         | 2/20 [00:06<00:53,  2.95s/it] 15%|█▌        | 3/20 [00:07<00:29,  1.74s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.52it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:09<00:03,  2.74it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.05it/s] 60%|██████    | 12/20 [00:09<00:02,  3.39it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.60it/s] 70%|███████   | 14/20 [00:10<00:01,  3.73it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.95it/s] 80%|████████  | 16/20 [00:10<00:01,  3.83it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.83it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.11it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.44it/s]100%|██████████| 20/20 [00:11<00:00,  4.78it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,525
* accuracy: 76.6%
* error: 23.4%
* macro_f1: 75.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [3/30] batch [20/796] time 0.364 (0.421) data 0.000 (0.034) loss 3.8438 (1.7384) lr 9.8907e-03 eta 2:36:05
epoch [3/30] batch [40/796] time 0.371 (0.401) data 0.000 (0.017) loss 1.7764 (1.8566) lr 9.8907e-03 eta 2:28:34
epoch [3/30] batch [60/796] time 0.355 (0.394) data 0.000 (0.011) loss 1.4814 (1.9642) lr 9.8907e-03 eta 2:25:50
epoch [3/30] batch [80/796] time 0.391 (0.392) data 0.000 (0.009) loss 2.1973 (1.9793) lr 9.8907e-03 eta 2:25:07
epoch [3/30] batch [100/796] time 0.357 (0.389) data 0.000 (0.007) loss 3.2305 (1.9986) lr 9.8907e-03 eta 2:24:00
epoch [3/30] batch [120/796] time 0.359 (0.388) data 0.000 (0.006) loss 0.5137 (2.0475) lr 9.8907e-03 eta 2:23:28
epoch [3/30] batch [140/796] time 0.375 (0.387) data 0.000 (0.005) loss 3.5723 (2.0163) lr 9.8907e-03 eta 2:22:45
epoch [3/30] batch [160/796] time 0.412 (0.387) data 0.000 (0.004) loss 1.0869 (2.0473) lr 9.8907e-03 eta 2:22:46
epoch [3/30] batch [180/796] time 0.365 (0.386) data 0.000 (0.004) loss 1.4326 (2.0322) lr 9.8907e-03 eta 2:22:15
epoch [3/30] batch [200/796] time 0.366 (0.386) data 0.000 (0.004) loss 1.6699 (2.0075) lr 9.8907e-03 eta 2:21:57
epoch [3/30] batch [220/796] time 0.398 (0.385) data 0.000 (0.003) loss 3.9766 (2.0332) lr 9.8907e-03 eta 2:21:37
epoch [3/30] batch [240/796] time 0.381 (0.384) data 0.000 (0.003) loss 2.0469 (2.0092) lr 9.8907e-03 eta 2:21:09
epoch [3/30] batch [260/796] time 0.345 (0.384) data 0.000 (0.003) loss 4.6797 (2.0001) lr 9.8907e-03 eta 2:20:56
epoch [3/30] batch [280/796] time 0.375 (0.384) data 0.000 (0.003) loss 1.2598 (2.0373) lr 9.8907e-03 eta 2:20:44
epoch [3/30] batch [300/796] time 0.375 (0.383) data 0.000 (0.002) loss 0.3926 (2.0230) lr 9.8907e-03 eta 2:20:30
epoch [3/30] batch [320/796] time 0.421 (0.383) data 0.000 (0.002) loss 4.1406 (2.0178) lr 9.8907e-03 eta 2:20:12
epoch [3/30] batch [340/796] time 0.395 (0.383) data 0.000 (0.002) loss 0.2986 (1.9822) lr 9.8907e-03 eta 2:19:59
epoch [3/30] batch [360/796] time 0.383 (0.382) data 0.000 (0.002) loss 2.5898 (1.9663) lr 9.8907e-03 eta 2:19:42
epoch [3/30] batch [380/796] time 0.421 (0.382) data 0.000 (0.002) loss 1.0283 (1.9483) lr 9.8907e-03 eta 2:19:39
epoch [3/30] batch [400/796] time 0.393 (0.382) data 0.000 (0.002) loss 3.4473 (1.9574) lr 9.8907e-03 eta 2:19:26
epoch [3/30] batch [420/796] time 0.409 (0.382) data 0.000 (0.002) loss 0.4753 (1.9678) lr 9.8907e-03 eta 2:19:06
epoch [3/30] batch [440/796] time 0.361 (0.382) data 0.000 (0.002) loss 0.4482 (1.9534) lr 9.8907e-03 eta 2:18:56
epoch [3/30] batch [460/796] time 0.359 (0.381) data 0.000 (0.002) loss 1.0303 (1.9548) lr 9.8907e-03 eta 2:18:45
epoch [3/30] batch [480/796] time 0.406 (0.381) data 0.000 (0.002) loss 3.3965 (1.9578) lr 9.8907e-03 eta 2:18:33
epoch [3/30] batch [500/796] time 0.356 (0.381) data 0.000 (0.002) loss 3.2168 (1.9653) lr 9.8907e-03 eta 2:18:21
epoch [3/30] batch [520/796] time 0.360 (0.381) data 0.000 (0.002) loss 1.5254 (1.9560) lr 9.8907e-03 eta 2:18:11
epoch [3/30] batch [540/796] time 0.349 (0.381) data 0.000 (0.001) loss 3.2188 (1.9546) lr 9.8907e-03 eta 2:18:02
epoch [3/30] batch [560/796] time 0.393 (0.381) data 0.000 (0.001) loss 0.6328 (1.9771) lr 9.8907e-03 eta 2:17:56
epoch [3/30] batch [580/796] time 0.390 (0.381) data 0.000 (0.001) loss 5.1016 (1.9978) lr 9.8907e-03 eta 2:17:53
epoch [3/30] batch [600/796] time 0.347 (0.381) data 0.000 (0.001) loss 3.2461 (1.9900) lr 9.8907e-03 eta 2:17:44
epoch [3/30] batch [620/796] time 0.410 (0.381) data 0.000 (0.001) loss 2.0840 (1.9992) lr 9.8907e-03 eta 2:17:38
epoch [3/30] batch [640/796] time 0.398 (0.381) data 0.000 (0.001) loss 0.7720 (2.0007) lr 9.8907e-03 eta 2:17:28
epoch [3/30] batch [660/796] time 0.381 (0.381) data 0.000 (0.001) loss 1.1807 (1.9763) lr 9.8907e-03 eta 2:17:24
epoch [3/30] batch [680/796] time 0.388 (0.381) data 0.000 (0.001) loss 3.0742 (1.9685) lr 9.8907e-03 eta 2:17:16
epoch [3/30] batch [700/796] time 0.405 (0.381) data 0.000 (0.001) loss 1.8418 (1.9766) lr 9.8907e-03 eta 2:17:10
epoch [3/30] batch [720/796] time 0.377 (0.381) data 0.000 (0.001) loss 3.4453 (1.9794) lr 9.8907e-03 eta 2:17:01
epoch [3/30] batch [740/796] time 0.391 (0.381) data 0.000 (0.001) loss 1.0859 (1.9770) lr 9.8907e-03 eta 2:16:55
epoch [3/30] batch [760/796] time 0.370 (0.381) data 0.000 (0.001) loss 1.3398 (1.9734) lr 9.8907e-03 eta 2:16:47
epoch [3/30] batch [780/796] time 0.345 (0.381) data 0.000 (0.001) loss 3.1465 (1.9879) lr 9.8907e-03 eta 2:16:24
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.59s/it] 10%|█         | 2/20 [00:06<00:50,  2.83s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.67it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.91it/s] 60%|██████    | 12/20 [00:09<00:02,  3.16it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.35it/s] 70%|███████   | 14/20 [00:09<00:01,  3.47it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.75it/s] 80%|████████  | 16/20 [00:10<00:00,  4.02it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.19it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.13it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.46it/s]100%|██████████| 20/20 [00:11<00:00,  4.80it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,545
* accuracy: 77.6%
* error: 22.4%
* macro_f1: 76.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/796] time 0.372 (0.422) data 0.000 (0.037) loss 0.5771 (2.2083) lr 9.7553e-03 eta 2:31:00
epoch [4/30] batch [40/796] time 0.401 (0.402) data 0.000 (0.018) loss 1.5723 (2.2406) lr 9.7553e-03 eta 2:23:50
epoch [4/30] batch [60/796] time 0.368 (0.395) data 0.000 (0.012) loss 2.6035 (2.0434) lr 9.7553e-03 eta 2:21:13
epoch [4/30] batch [80/796] time 0.382 (0.390) data 0.000 (0.009) loss 4.8555 (2.1080) lr 9.7553e-03 eta 2:19:13
epoch [4/30] batch [100/796] time 0.351 (0.388) data 0.000 (0.008) loss 1.3672 (2.0408) lr 9.7553e-03 eta 2:18:19
epoch [4/30] batch [120/796] time 0.346 (0.385) data 0.000 (0.006) loss 3.6191 (2.0623) lr 9.7553e-03 eta 2:17:17
epoch [4/30] batch [140/796] time 0.349 (0.384) data 0.000 (0.005) loss 1.0166 (2.0212) lr 9.7553e-03 eta 2:16:49
epoch [4/30] batch [160/796] time 0.398 (0.384) data 0.000 (0.005) loss 3.6016 (1.9980) lr 9.7553e-03 eta 2:16:24
epoch [4/30] batch [180/796] time 0.360 (0.383) data 0.000 (0.004) loss 1.0234 (2.0225) lr 9.7553e-03 eta 2:15:54
epoch [4/30] batch [200/796] time 0.384 (0.383) data 0.000 (0.004) loss 1.0225 (2.0094) lr 9.7553e-03 eta 2:15:47
epoch [4/30] batch [220/796] time 0.394 (0.383) data 0.000 (0.004) loss 0.7344 (2.0281) lr 9.7553e-03 eta 2:15:37
epoch [4/30] batch [240/796] time 0.361 (0.382) data 0.000 (0.003) loss 2.6348 (2.0617) lr 9.7553e-03 eta 2:15:15
epoch [4/30] batch [260/796] time 0.391 (0.382) data 0.000 (0.003) loss 0.3162 (2.0324) lr 9.7553e-03 eta 2:15:04
epoch [4/30] batch [280/796] time 0.397 (0.381) data 0.000 (0.003) loss 1.2783 (2.0109) lr 9.7553e-03 eta 2:14:42
epoch [4/30] batch [300/796] time 0.384 (0.381) data 0.000 (0.003) loss 0.2507 (2.0019) lr 9.7553e-03 eta 2:14:40
epoch [4/30] batch [320/796] time 0.362 (0.381) data 0.000 (0.003) loss 1.1611 (2.0121) lr 9.7553e-03 eta 2:14:35
epoch [4/30] batch [340/796] time 0.373 (0.381) data 0.000 (0.002) loss 1.0859 (1.9735) lr 9.7553e-03 eta 2:14:21
epoch [4/30] batch [360/796] time 0.399 (0.381) data 0.000 (0.002) loss 4.6875 (1.9578) lr 9.7553e-03 eta 2:14:15
epoch [4/30] batch [380/796] time 0.395 (0.381) data 0.000 (0.002) loss 4.2461 (1.9981) lr 9.7553e-03 eta 2:14:11
epoch [4/30] batch [400/796] time 0.376 (0.381) data 0.000 (0.002) loss 1.5449 (1.9771) lr 9.7553e-03 eta 2:14:03
epoch [4/30] batch [420/796] time 0.363 (0.381) data 0.000 (0.002) loss 0.5098 (1.9642) lr 9.7553e-03 eta 2:13:52
epoch [4/30] batch [440/796] time 0.360 (0.382) data 0.000 (0.002) loss 1.8877 (1.9587) lr 9.7553e-03 eta 2:13:51
epoch [4/30] batch [460/796] time 0.398 (0.382) data 0.000 (0.002) loss 0.9619 (1.9661) lr 9.7553e-03 eta 2:13:48
epoch [4/30] batch [480/796] time 0.379 (0.382) data 0.000 (0.002) loss 2.9355 (1.9628) lr 9.7553e-03 eta 2:13:47
epoch [4/30] batch [500/796] time 0.388 (0.382) data 0.000 (0.002) loss 2.0801 (1.9664) lr 9.7553e-03 eta 2:13:34
epoch [4/30] batch [520/796] time 0.411 (0.382) data 0.000 (0.002) loss 0.6284 (1.9504) lr 9.7553e-03 eta 2:13:32
epoch [4/30] batch [540/796] time 0.379 (0.382) data 0.000 (0.002) loss 3.4902 (1.9463) lr 9.7553e-03 eta 2:13:23
epoch [4/30] batch [560/796] time 0.380 (0.382) data 0.000 (0.002) loss 1.4902 (1.9571) lr 9.7553e-03 eta 2:13:12
epoch [4/30] batch [580/796] time 0.382 (0.382) data 0.000 (0.002) loss 1.5869 (1.9460) lr 9.7553e-03 eta 2:13:00
epoch [4/30] batch [600/796] time 0.411 (0.382) data 0.000 (0.001) loss 2.0449 (1.9459) lr 9.7553e-03 eta 2:12:56
epoch [4/30] batch [620/796] time 0.348 (0.382) data 0.000 (0.001) loss 1.9150 (1.9427) lr 9.7553e-03 eta 2:12:48
epoch [4/30] batch [640/796] time 0.403 (0.382) data 0.000 (0.001) loss 1.5488 (1.9389) lr 9.7553e-03 eta 2:12:39
epoch [4/30] batch [660/796] time 0.352 (0.382) data 0.000 (0.001) loss 1.4619 (1.9262) lr 9.7553e-03 eta 2:12:30
epoch [4/30] batch [680/796] time 0.406 (0.381) data 0.000 (0.001) loss 3.4297 (1.9326) lr 9.7553e-03 eta 2:12:19
epoch [4/30] batch [700/796] time 0.405 (0.382) data 0.000 (0.001) loss 0.8354 (1.9191) lr 9.7553e-03 eta 2:12:14
epoch [4/30] batch [720/796] time 0.353 (0.382) data 0.000 (0.001) loss 4.2930 (1.9138) lr 9.7553e-03 eta 2:12:06
epoch [4/30] batch [740/796] time 0.405 (0.382) data 0.000 (0.001) loss 0.9038 (1.9138) lr 9.7553e-03 eta 2:11:57
epoch [4/30] batch [760/796] time 0.395 (0.382) data 0.000 (0.001) loss 0.6157 (1.8960) lr 9.7553e-03 eta 2:11:51
epoch [4/30] batch [780/796] time 0.345 (0.381) data 0.000 (0.001) loss 1.9727 (1.8977) lr 9.7553e-03 eta 2:11:28
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.59s/it] 10%|█         | 2/20 [00:06<00:52,  2.94s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.74s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.52it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.87it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.76it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.10it/s] 60%|██████    | 12/20 [00:09<00:02,  3.29it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.43it/s] 70%|███████   | 14/20 [00:09<00:01,  3.54it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.61it/s] 80%|████████  | 16/20 [00:10<00:01,  3.70it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.89it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.94it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.29it/s]100%|██████████| 20/20 [00:11<00:00,  4.66it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,552
* accuracy: 78.0%
* error: 22.0%
* macro_f1: 77.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/796] time 0.368 (0.428) data 0.000 (0.038) loss 1.4180 (1.9109) lr 9.5677e-03 eta 2:27:36
epoch [5/30] batch [40/796] time 0.403 (0.405) data 0.000 (0.019) loss 2.1094 (1.9611) lr 9.5677e-03 eta 2:19:26
epoch [5/30] batch [60/796] time 0.382 (0.398) data 0.000 (0.013) loss 1.8125 (2.1223) lr 9.5677e-03 eta 2:16:57
epoch [5/30] batch [80/796] time 0.360 (0.393) data 0.000 (0.010) loss 2.6289 (2.0622) lr 9.5677e-03 eta 2:14:53
epoch [5/30] batch [100/796] time 0.382 (0.390) data 0.000 (0.008) loss 2.1230 (1.9008) lr 9.5677e-03 eta 2:13:55
epoch [5/30] batch [120/796] time 0.414 (0.388) data 0.000 (0.007) loss 2.7793 (1.9053) lr 9.5677e-03 eta 2:12:55
epoch [5/30] batch [140/796] time 0.380 (0.386) data 0.000 (0.006) loss 0.3357 (1.8704) lr 9.5677e-03 eta 2:12:16
epoch [5/30] batch [160/796] time 0.408 (0.386) data 0.000 (0.005) loss 1.6592 (1.8931) lr 9.5677e-03 eta 2:12:14
epoch [5/30] batch [180/796] time 0.373 (0.385) data 0.000 (0.004) loss 1.9932 (1.8941) lr 9.5677e-03 eta 2:11:37
epoch [5/30] batch [200/796] time 0.401 (0.385) data 0.000 (0.004) loss 0.7271 (1.8898) lr 9.5677e-03 eta 2:11:30
epoch [5/30] batch [220/796] time 0.388 (0.385) data 0.000 (0.004) loss 0.5645 (1.8614) lr 9.5677e-03 eta 2:11:25
epoch [5/30] batch [240/796] time 0.384 (0.385) data 0.000 (0.003) loss 1.8652 (1.8343) lr 9.5677e-03 eta 2:11:12
epoch [5/30] batch [260/796] time 0.408 (0.384) data 0.000 (0.003) loss 2.1855 (1.8239) lr 9.5677e-03 eta 2:10:53
epoch [5/30] batch [280/796] time 0.413 (0.384) data 0.000 (0.003) loss 3.6094 (1.8505) lr 9.5677e-03 eta 2:10:47
epoch [5/30] batch [300/796] time 0.369 (0.384) data 0.000 (0.003) loss 2.7344 (1.8786) lr 9.5677e-03 eta 2:10:39
epoch [5/30] batch [320/796] time 0.401 (0.384) data 0.000 (0.003) loss 2.1309 (1.8910) lr 9.5677e-03 eta 2:10:17
epoch [5/30] batch [340/796] time 0.354 (0.384) data 0.000 (0.002) loss 0.9585 (1.9108) lr 9.5677e-03 eta 2:10:07
epoch [5/30] batch [360/796] time 0.359 (0.383) data 0.000 (0.002) loss 1.5869 (1.8829) lr 9.5677e-03 eta 2:09:54
epoch [5/30] batch [380/796] time 0.388 (0.383) data 0.000 (0.002) loss 3.3027 (1.8715) lr 9.5677e-03 eta 2:09:46
epoch [5/30] batch [400/796] time 0.399 (0.383) data 0.000 (0.002) loss 1.0010 (1.8461) lr 9.5677e-03 eta 2:09:35
epoch [5/30] batch [420/796] time 0.384 (0.383) data 0.000 (0.002) loss 2.3672 (1.8440) lr 9.5677e-03 eta 2:09:30
epoch [5/30] batch [440/796] time 0.387 (0.384) data 0.000 (0.002) loss 0.9551 (1.8379) lr 9.5677e-03 eta 2:09:28
epoch [5/30] batch [460/796] time 0.372 (0.383) data 0.000 (0.002) loss 1.6709 (1.8251) lr 9.5677e-03 eta 2:09:19
epoch [5/30] batch [480/796] time 0.358 (0.383) data 0.000 (0.002) loss 0.0188 (1.8103) lr 9.5677e-03 eta 2:09:06
epoch [5/30] batch [500/796] time 0.363 (0.383) data 0.000 (0.002) loss 3.1152 (1.8148) lr 9.5677e-03 eta 2:09:04
epoch [5/30] batch [520/796] time 0.390 (0.383) data 0.000 (0.002) loss 1.3506 (1.8348) lr 9.5677e-03 eta 2:08:56
epoch [5/30] batch [540/796] time 0.369 (0.383) data 0.000 (0.002) loss 2.9023 (1.8460) lr 9.5677e-03 eta 2:08:43
epoch [5/30] batch [560/796] time 0.392 (0.383) data 0.000 (0.002) loss 0.0522 (1.8329) lr 9.5677e-03 eta 2:08:32
epoch [5/30] batch [580/796] time 0.353 (0.383) data 0.000 (0.002) loss 1.7900 (1.8239) lr 9.5677e-03 eta 2:08:22
epoch [5/30] batch [600/796] time 0.373 (0.383) data 0.000 (0.002) loss 3.0293 (1.8319) lr 9.5677e-03 eta 2:08:15
epoch [5/30] batch [620/796] time 0.362 (0.383) data 0.000 (0.001) loss 1.5449 (1.8327) lr 9.5677e-03 eta 2:08:08
epoch [5/30] batch [640/796] time 0.402 (0.383) data 0.000 (0.001) loss 0.6177 (1.8326) lr 9.5677e-03 eta 2:08:04
epoch [5/30] batch [660/796] time 0.359 (0.383) data 0.000 (0.001) loss 1.0293 (1.8178) lr 9.5677e-03 eta 2:07:54
epoch [5/30] batch [680/796] time 0.385 (0.383) data 0.000 (0.001) loss 4.8711 (1.8118) lr 9.5677e-03 eta 2:07:45
epoch [5/30] batch [700/796] time 0.391 (0.383) data 0.000 (0.001) loss 2.7363 (1.8187) lr 9.5677e-03 eta 2:07:38
epoch [5/30] batch [720/796] time 0.357 (0.383) data 0.000 (0.001) loss 0.9946 (1.8179) lr 9.5677e-03 eta 2:07:28
epoch [5/30] batch [740/796] time 0.369 (0.383) data 0.000 (0.001) loss 1.9023 (1.8071) lr 9.5677e-03 eta 2:07:18
epoch [5/30] batch [760/796] time 0.354 (0.383) data 0.000 (0.001) loss 2.6387 (1.8122) lr 9.5677e-03 eta 2:07:08
epoch [5/30] batch [780/796] time 0.340 (0.382) data 0.000 (0.001) loss 1.0059 (1.8149) lr 9.5677e-03 eta 2:06:45
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:42,  5.37s/it] 10%|█         | 2/20 [00:06<00:52,  2.93s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.73s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.84it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.43it/s] 50%|█████     | 10/20 [00:08<00:03,  2.67it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.02it/s] 60%|██████    | 12/20 [00:09<00:02,  3.29it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.55it/s] 70%|███████   | 14/20 [00:09<00:01,  3.69it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.97it/s] 80%|████████  | 16/20 [00:10<00:00,  4.11it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.93it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.37it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.81it/s]100%|██████████| 20/20 [00:11<00:00,  4.25it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,552
* accuracy: 78.0%
* error: 22.0%
* macro_f1: 77.2%

epoch [6/30] batch [20/796] time 0.381 (0.426) data 0.000 (0.042) loss 5.0234 (2.1641) lr 9.3301e-03 eta 2:21:03
epoch [6/30] batch [40/796] time 0.368 (0.402) data 0.000 (0.021) loss 1.7021 (2.0078) lr 9.3301e-03 eta 2:12:55
epoch [6/30] batch [60/796] time 0.359 (0.394) data 0.000 (0.014) loss 1.3809 (1.8948) lr 9.3301e-03 eta 2:10:13
epoch [6/30] batch [80/796] time 0.379 (0.391) data 0.000 (0.011) loss 5.2227 (1.8265) lr 9.3301e-03 eta 2:09:16
epoch [6/30] batch [100/796] time 0.415 (0.389) data 0.000 (0.009) loss 1.7920 (1.8439) lr 9.3301e-03 eta 2:08:30
epoch [6/30] batch [120/796] time 0.359 (0.387) data 0.000 (0.007) loss 4.9805 (1.7566) lr 9.3301e-03 eta 2:07:34
epoch [6/30] batch [140/796] time 0.399 (0.387) data 0.000 (0.006) loss 1.3350 (1.7437) lr 9.3301e-03 eta 2:07:36
epoch [6/30] batch [160/796] time 0.381 (0.387) data 0.000 (0.005) loss 2.2148 (1.7465) lr 9.3301e-03 eta 2:07:22
epoch [6/30] batch [180/796] time 0.359 (0.387) data 0.000 (0.005) loss 0.6748 (1.7152) lr 9.3301e-03 eta 2:07:10
epoch [6/30] batch [200/796] time 0.356 (0.386) data 0.000 (0.004) loss 0.8999 (1.7023) lr 9.3301e-03 eta 2:06:36
epoch [6/30] batch [220/796] time 0.391 (0.385) data 0.000 (0.004) loss 4.6484 (1.7357) lr 9.3301e-03 eta 2:06:19
epoch [6/30] batch [240/796] time 0.373 (0.385) data 0.000 (0.004) loss 2.1426 (1.7331) lr 9.3301e-03 eta 2:06:00
epoch [6/30] batch [260/796] time 0.366 (0.384) data 0.000 (0.003) loss 0.1362 (1.7340) lr 9.3301e-03 eta 2:05:49
epoch [6/30] batch [280/796] time 0.360 (0.384) data 0.000 (0.003) loss 1.6768 (1.7183) lr 9.3301e-03 eta 2:05:28
epoch [6/30] batch [300/796] time 0.408 (0.384) data 0.000 (0.003) loss 1.1133 (1.7247) lr 9.3301e-03 eta 2:05:24
epoch [6/30] batch [320/796] time 0.388 (0.383) data 0.000 (0.003) loss 1.6738 (1.7000) lr 9.3301e-03 eta 2:05:08
epoch [6/30] batch [340/796] time 0.392 (0.383) data 0.000 (0.003) loss 0.1626 (1.7068) lr 9.3301e-03 eta 2:05:00
epoch [6/30] batch [360/796] time 0.376 (0.384) data 0.000 (0.003) loss 3.0254 (1.7162) lr 9.3301e-03 eta 2:04:56
epoch [6/30] batch [380/796] time 0.382 (0.383) data 0.000 (0.002) loss 0.9712 (1.7383) lr 9.3301e-03 eta 2:04:38
epoch [6/30] batch [400/796] time 0.386 (0.383) data 0.000 (0.002) loss 5.2656 (1.7317) lr 9.3301e-03 eta 2:04:34
epoch [6/30] batch [420/796] time 0.396 (0.383) data 0.000 (0.002) loss 2.7383 (1.7285) lr 9.3301e-03 eta 2:04:18
epoch [6/30] batch [440/796] time 0.381 (0.383) data 0.000 (0.002) loss 1.5322 (1.7395) lr 9.3301e-03 eta 2:04:10
epoch [6/30] batch [460/796] time 0.364 (0.383) data 0.000 (0.002) loss 3.2832 (1.7533) lr 9.3301e-03 eta 2:03:59
epoch [6/30] batch [480/796] time 0.395 (0.383) data 0.000 (0.002) loss 1.3535 (1.7484) lr 9.3301e-03 eta 2:03:49
epoch [6/30] batch [500/796] time 0.404 (0.383) data 0.000 (0.002) loss 1.1367 (1.7549) lr 9.3301e-03 eta 2:03:40
epoch [6/30] batch [520/796] time 0.352 (0.383) data 0.000 (0.002) loss 0.7227 (1.7626) lr 9.3301e-03 eta 2:03:34
epoch [6/30] batch [540/796] time 0.381 (0.383) data 0.000 (0.002) loss 0.2598 (1.7525) lr 9.3301e-03 eta 2:03:29
epoch [6/30] batch [560/796] time 0.398 (0.383) data 0.000 (0.002) loss 1.5879 (1.7654) lr 9.3301e-03 eta 2:03:18
epoch [6/30] batch [580/796] time 0.366 (0.383) data 0.000 (0.002) loss 0.4736 (1.7648) lr 9.3301e-03 eta 2:03:12
epoch [6/30] batch [600/796] time 0.386 (0.383) data 0.000 (0.002) loss 0.0989 (1.7608) lr 9.3301e-03 eta 2:03:04
epoch [6/30] batch [620/796] time 0.378 (0.383) data 0.000 (0.002) loss 2.6113 (1.7785) lr 9.3301e-03 eta 2:02:57
epoch [6/30] batch [640/796] time 0.351 (0.383) data 0.000 (0.002) loss 0.8555 (1.7615) lr 9.3301e-03 eta 2:02:47
epoch [6/30] batch [660/796] time 0.407 (0.382) data 0.000 (0.002) loss 1.8271 (1.7657) lr 9.3301e-03 eta 2:02:37
epoch [6/30] batch [680/796] time 0.352 (0.382) data 0.000 (0.001) loss 3.1641 (1.7681) lr 9.3301e-03 eta 2:02:30
epoch [6/30] batch [700/796] time 0.376 (0.383) data 0.000 (0.001) loss 0.3101 (1.7689) lr 9.3301e-03 eta 2:02:27
epoch [6/30] batch [720/796] time 0.396 (0.383) data 0.000 (0.001) loss 0.2798 (1.7749) lr 9.3301e-03 eta 2:02:21
epoch [6/30] batch [740/796] time 0.391 (0.383) data 0.000 (0.001) loss 1.2197 (1.7965) lr 9.3301e-03 eta 2:02:09
epoch [6/30] batch [760/796] time 0.397 (0.382) data 0.000 (0.001) loss 4.3281 (1.7964) lr 9.3301e-03 eta 2:01:57
epoch [6/30] batch [780/796] time 0.339 (0.382) data 0.000 (0.001) loss 0.5967 (1.7893) lr 9.3301e-03 eta 2:01:34
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.49s/it] 10%|█         | 2/20 [00:06<00:51,  2.84s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.90it/s] 60%|██████    | 12/20 [00:09<00:02,  3.13it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.40it/s] 70%|███████   | 14/20 [00:09<00:01,  3.71it/s] 75%|███████▌  | 15/20 [00:10<00:01,  4.01it/s] 80%|████████  | 16/20 [00:10<00:00,  4.32it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.41it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.02it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.49it/s]100%|██████████| 20/20 [00:11<00:00,  3.97it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,566
* accuracy: 78.7%
* error: 21.3%
* macro_f1: 77.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [7/30] batch [20/796] time 0.368 (0.427) data 0.000 (0.033) loss 0.9805 (1.8263) lr 9.0451e-03 eta 2:15:52
epoch [7/30] batch [40/796] time 0.354 (0.402) data 0.000 (0.017) loss 2.9961 (1.7073) lr 9.0451e-03 eta 2:07:51
epoch [7/30] batch [60/796] time 0.389 (0.396) data 0.000 (0.011) loss 2.5977 (1.7065) lr 9.0451e-03 eta 2:05:49
epoch [7/30] batch [80/796] time 0.354 (0.391) data 0.000 (0.008) loss 0.2568 (1.6815) lr 9.0451e-03 eta 2:04:05
epoch [7/30] batch [100/796] time 0.377 (0.387) data 0.000 (0.007) loss 1.8623 (1.7700) lr 9.0451e-03 eta 2:02:40
epoch [7/30] batch [120/796] time 0.350 (0.387) data 0.000 (0.006) loss 1.9023 (1.7115) lr 9.0451e-03 eta 2:02:23
epoch [7/30] batch [140/796] time 0.398 (0.387) data 0.000 (0.005) loss 1.4863 (1.7122) lr 9.0451e-03 eta 2:02:13
epoch [7/30] batch [160/796] time 0.407 (0.387) data 0.000 (0.004) loss 2.9727 (1.6936) lr 9.0451e-03 eta 2:02:08
epoch [7/30] batch [180/796] time 0.404 (0.386) data 0.000 (0.004) loss 3.1543 (1.7214) lr 9.0451e-03 eta 2:01:49
epoch [7/30] batch [200/796] time 0.351 (0.386) data 0.000 (0.004) loss 0.4255 (1.6736) lr 9.0451e-03 eta 2:01:30
epoch [7/30] batch [220/796] time 0.398 (0.386) data 0.000 (0.003) loss 4.0977 (1.7370) lr 9.0451e-03 eta 2:01:26
epoch [7/30] batch [240/796] time 0.401 (0.385) data 0.000 (0.003) loss 1.5605 (1.7148) lr 9.0451e-03 eta 2:01:08
epoch [7/30] batch [260/796] time 0.365 (0.385) data 0.000 (0.003) loss 0.5913 (1.7024) lr 9.0451e-03 eta 2:00:47
epoch [7/30] batch [280/796] time 0.403 (0.384) data 0.000 (0.003) loss 0.6899 (1.7282) lr 9.0451e-03 eta 2:00:35
epoch [7/30] batch [300/796] time 0.372 (0.384) data 0.000 (0.002) loss 1.8965 (1.7067) lr 9.0451e-03 eta 2:00:27
epoch [7/30] batch [320/796] time 0.409 (0.384) data 0.000 (0.002) loss 0.4812 (1.7535) lr 9.0451e-03 eta 2:00:11
epoch [7/30] batch [340/796] time 0.391 (0.383) data 0.000 (0.002) loss 2.7188 (1.7625) lr 9.0451e-03 eta 1:59:52
epoch [7/30] batch [360/796] time 0.403 (0.384) data 0.000 (0.002) loss 2.8535 (1.7433) lr 9.0451e-03 eta 1:59:51
epoch [7/30] batch [380/796] time 0.365 (0.384) data 0.001 (0.002) loss 2.6719 (1.7355) lr 9.0451e-03 eta 1:59:43
epoch [7/30] batch [400/796] time 0.363 (0.384) data 0.000 (0.002) loss 1.0479 (1.7455) lr 9.0451e-03 eta 1:59:38
epoch [7/30] batch [420/796] time 0.410 (0.384) data 0.000 (0.002) loss 2.9297 (1.7731) lr 9.0451e-03 eta 1:59:30
epoch [7/30] batch [440/796] time 0.350 (0.383) data 0.000 (0.002) loss 1.2998 (1.7732) lr 9.0451e-03 eta 1:59:16
epoch [7/30] batch [460/796] time 0.353 (0.383) data 0.000 (0.002) loss 1.0566 (1.7716) lr 9.0451e-03 eta 1:59:04
epoch [7/30] batch [480/796] time 0.397 (0.383) data 0.000 (0.002) loss 1.2061 (1.7663) lr 9.0451e-03 eta 1:58:57
epoch [7/30] batch [500/796] time 0.379 (0.384) data 0.000 (0.002) loss 3.8750 (1.7851) lr 9.0451e-03 eta 1:58:56
epoch [7/30] batch [520/796] time 0.382 (0.383) data 0.000 (0.002) loss 2.9590 (1.7938) lr 9.0451e-03 eta 1:58:43
epoch [7/30] batch [540/796] time 0.351 (0.383) data 0.000 (0.001) loss 0.4951 (1.7755) lr 9.0451e-03 eta 1:58:27
epoch [7/30] batch [560/796] time 0.362 (0.383) data 0.000 (0.001) loss 0.2649 (1.7809) lr 9.0451e-03 eta 1:58:14
epoch [7/30] batch [580/796] time 0.406 (0.383) data 0.000 (0.001) loss 2.3340 (1.7938) lr 9.0451e-03 eta 1:58:08
epoch [7/30] batch [600/796] time 0.394 (0.382) data 0.000 (0.001) loss 1.8682 (1.8142) lr 9.0451e-03 eta 1:57:57
epoch [7/30] batch [620/796] time 0.402 (0.382) data 0.000 (0.001) loss 1.2568 (1.8173) lr 9.0451e-03 eta 1:57:45
epoch [7/30] batch [640/796] time 0.371 (0.382) data 0.000 (0.001) loss 0.5269 (1.8157) lr 9.0451e-03 eta 1:57:36
epoch [7/30] batch [660/796] time 0.392 (0.382) data 0.000 (0.001) loss 3.5859 (1.8105) lr 9.0451e-03 eta 1:57:28
epoch [7/30] batch [680/796] time 0.409 (0.382) data 0.000 (0.001) loss 1.6621 (1.8135) lr 9.0451e-03 eta 1:57:23
epoch [7/30] batch [700/796] time 0.390 (0.382) data 0.000 (0.001) loss 0.3745 (1.8111) lr 9.0451e-03 eta 1:57:10
epoch [7/30] batch [720/796] time 0.366 (0.382) data 0.000 (0.001) loss 4.3984 (1.8120) lr 9.0451e-03 eta 1:56:59
epoch [7/30] batch [740/796] time 0.378 (0.382) data 0.000 (0.001) loss 3.2910 (1.8422) lr 9.0451e-03 eta 1:56:51
epoch [7/30] batch [760/796] time 0.354 (0.382) data 0.000 (0.001) loss 0.2834 (1.8373) lr 9.0451e-03 eta 1:56:43
epoch [7/30] batch [780/796] time 0.343 (0.381) data 0.000 (0.001) loss 0.8989 (1.8328) lr 9.0451e-03 eta 1:56:19
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:43,  5.47s/it] 10%|█         | 2/20 [00:06<00:50,  2.82s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.67s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.47it/s] 50%|█████     | 10/20 [00:08<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.92it/s] 60%|██████    | 12/20 [00:09<00:02,  3.16it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.35it/s] 70%|███████   | 14/20 [00:09<00:01,  3.70it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.72it/s] 80%|████████  | 16/20 [00:10<00:01,  3.72it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.85it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.22it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.54it/s]100%|██████████| 20/20 [00:11<00:00,  4.85it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,576
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 78.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [8/30] batch [20/796] time 0.486 (0.434) data 0.000 (0.036) loss 2.8672 (1.4476) lr 8.7157e-03 eta 2:12:17
epoch [8/30] batch [40/796] time 0.357 (0.408) data 0.000 (0.018) loss 1.1162 (1.7154) lr 8.7157e-03 eta 2:04:04
epoch [8/30] batch [60/796] time 0.361 (0.398) data 0.000 (0.012) loss 3.7734 (1.8924) lr 8.7157e-03 eta 2:01:04
epoch [8/30] batch [80/796] time 0.402 (0.392) data 0.000 (0.009) loss 1.7158 (1.7881) lr 8.7157e-03 eta 1:59:13
epoch [8/30] batch [100/796] time 0.368 (0.388) data 0.000 (0.007) loss 1.6279 (1.8251) lr 8.7157e-03 eta 1:57:36
epoch [8/30] batch [120/796] time 0.400 (0.385) data 0.000 (0.006) loss 1.7344 (1.7202) lr 8.7157e-03 eta 1:56:42
epoch [8/30] batch [140/796] time 0.373 (0.385) data 0.000 (0.005) loss 4.7930 (1.7710) lr 8.7157e-03 eta 1:56:40
epoch [8/30] batch [160/796] time 0.384 (0.385) data 0.000 (0.005) loss 1.0371 (1.7749) lr 8.7157e-03 eta 1:56:29
epoch [8/30] batch [180/796] time 0.398 (0.384) data 0.000 (0.004) loss 2.0977 (1.8433) lr 8.7157e-03 eta 1:56:01
epoch [8/30] batch [200/796] time 0.360 (0.383) data 0.000 (0.004) loss 1.7842 (1.7889) lr 8.7157e-03 eta 1:55:44
epoch [8/30] batch [220/796] time 0.395 (0.383) data 0.000 (0.003) loss 0.9404 (1.8128) lr 8.7157e-03 eta 1:55:31
epoch [8/30] batch [240/796] time 0.386 (0.383) data 0.000 (0.003) loss 3.8457 (1.7997) lr 8.7157e-03 eta 1:55:13
epoch [8/30] batch [260/796] time 0.399 (0.382) data 0.000 (0.003) loss 3.6562 (1.7872) lr 8.7157e-03 eta 1:54:54
epoch [8/30] batch [280/796] time 0.358 (0.382) data 0.000 (0.003) loss 1.5000 (1.7859) lr 8.7157e-03 eta 1:54:41
epoch [8/30] batch [300/796] time 0.365 (0.381) data 0.000 (0.003) loss 0.1277 (1.7695) lr 8.7157e-03 eta 1:54:28
epoch [8/30] batch [320/796] time 0.392 (0.382) data 0.000 (0.002) loss 2.3262 (1.7867) lr 8.7157e-03 eta 1:54:23
epoch [8/30] batch [340/796] time 0.407 (0.382) data 0.000 (0.002) loss 2.4766 (1.7966) lr 8.7157e-03 eta 1:54:16
epoch [8/30] batch [360/796] time 0.411 (0.382) data 0.000 (0.002) loss 2.4590 (1.7886) lr 8.7157e-03 eta 1:54:16
epoch [8/30] batch [380/796] time 0.387 (0.382) data 0.000 (0.002) loss 2.0879 (1.7989) lr 8.7157e-03 eta 1:54:03
epoch [8/30] batch [400/796] time 0.382 (0.381) data 0.000 (0.002) loss 0.6797 (1.7774) lr 8.7157e-03 eta 1:53:51
epoch [8/30] batch [420/796] time 0.392 (0.382) data 0.000 (0.002) loss 3.4141 (1.7848) lr 8.7157e-03 eta 1:53:47
epoch [8/30] batch [440/796] time 0.406 (0.382) data 0.000 (0.002) loss 0.9609 (1.7771) lr 8.7157e-03 eta 1:53:37
epoch [8/30] batch [460/796] time 0.365 (0.382) data 0.000 (0.002) loss 4.5625 (1.8041) lr 8.7157e-03 eta 1:53:29
epoch [8/30] batch [480/796] time 0.367 (0.382) data 0.000 (0.002) loss 1.1045 (1.8122) lr 8.7157e-03 eta 1:53:22
epoch [8/30] batch [500/796] time 0.363 (0.382) data 0.000 (0.002) loss 0.1194 (1.8039) lr 8.7157e-03 eta 1:53:15
epoch [8/30] batch [520/796] time 0.359 (0.381) data 0.000 (0.002) loss 2.1465 (1.7952) lr 8.7157e-03 eta 1:53:03
epoch [8/30] batch [540/796] time 0.391 (0.381) data 0.000 (0.002) loss 2.4883 (1.8086) lr 8.7157e-03 eta 1:52:53
epoch [8/30] batch [560/796] time 0.364 (0.381) data 0.000 (0.002) loss 1.8936 (1.8207) lr 8.7157e-03 eta 1:52:41
epoch [8/30] batch [580/796] time 0.360 (0.381) data 0.000 (0.001) loss 1.8477 (1.8036) lr 8.7157e-03 eta 1:52:28
epoch [8/30] batch [600/796] time 0.377 (0.381) data 0.000 (0.001) loss 1.2266 (1.7864) lr 8.7157e-03 eta 1:52:23
epoch [8/30] batch [620/796] time 0.401 (0.381) data 0.000 (0.001) loss 0.3669 (1.7929) lr 8.7157e-03 eta 1:52:20
epoch [8/30] batch [640/796] time 0.353 (0.381) data 0.000 (0.001) loss 0.5586 (1.7822) lr 8.7157e-03 eta 1:52:13
epoch [8/30] batch [660/796] time 0.408 (0.381) data 0.000 (0.001) loss 3.7793 (1.7763) lr 8.7157e-03 eta 1:52:04
epoch [8/30] batch [680/796] time 0.399 (0.381) data 0.000 (0.001) loss 2.0430 (1.7702) lr 8.7157e-03 eta 1:51:57
epoch [8/30] batch [700/796] time 0.372 (0.381) data 0.000 (0.001) loss 0.5029 (1.7463) lr 8.7157e-03 eta 1:51:48
epoch [8/30] batch [720/796] time 0.403 (0.381) data 0.000 (0.001) loss 1.4082 (1.7454) lr 8.7157e-03 eta 1:51:40
epoch [8/30] batch [740/796] time 0.382 (0.381) data 0.000 (0.001) loss 2.3848 (1.7495) lr 8.7157e-03 eta 1:51:35
epoch [8/30] batch [760/796] time 0.368 (0.381) data 0.000 (0.001) loss 2.6641 (1.7424) lr 8.7157e-03 eta 1:51:28
epoch [8/30] batch [780/796] time 0.343 (0.380) data 0.000 (0.001) loss 1.9199 (1.7436) lr 8.7157e-03 eta 1:51:06
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:43,  5.45s/it] 10%|█         | 2/20 [00:06<00:54,  3.01s/it] 15%|█▌        | 3/20 [00:07<00:30,  1.77s/it] 20%|██        | 4/20 [00:07<00:19,  1.19s/it] 25%|██▌       | 5/20 [00:07<00:13,  1.15it/s] 30%|███       | 6/20 [00:07<00:09,  1.47it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.81it/s] 40%|████      | 8/20 [00:08<00:05,  2.13it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.43it/s] 50%|█████     | 10/20 [00:09<00:03,  2.77it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.09it/s] 60%|██████    | 12/20 [00:09<00:02,  3.35it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.62it/s] 70%|███████   | 14/20 [00:10<00:01,  3.64it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.84it/s] 80%|████████  | 16/20 [00:10<00:00,  4.05it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.04it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.86it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.24it/s]100%|██████████| 20/20 [00:11<00:00,  4.62it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,569
* accuracy: 78.8%
* error: 21.2%
* macro_f1: 78.3%

epoch [9/30] batch [20/796] time 0.402 (0.441) data 0.000 (0.048) loss 0.8848 (1.3861) lr 8.3457e-03 eta 2:08:33
epoch [9/30] batch [40/796] time 0.414 (0.408) data 0.000 (0.024) loss 1.1162 (1.7031) lr 8.3457e-03 eta 1:58:54
epoch [9/30] batch [60/796] time 0.359 (0.401) data 0.000 (0.016) loss 0.2385 (1.6968) lr 8.3457e-03 eta 1:56:30
epoch [9/30] batch [80/796] time 0.356 (0.394) data 0.000 (0.012) loss 5.8320 (1.7653) lr 8.3457e-03 eta 1:54:35
epoch [9/30] batch [100/796] time 0.383 (0.391) data 0.000 (0.010) loss 1.3643 (1.7586) lr 8.3457e-03 eta 1:53:35
epoch [9/30] batch [120/796] time 0.394 (0.390) data 0.000 (0.008) loss 0.5068 (1.8089) lr 8.3457e-03 eta 1:52:56
epoch [9/30] batch [140/796] time 0.399 (0.388) data 0.000 (0.007) loss 2.7227 (1.8165) lr 8.3457e-03 eta 1:52:26
epoch [9/30] batch [160/796] time 0.387 (0.388) data 0.000 (0.006) loss 4.1523 (1.7970) lr 8.3457e-03 eta 1:52:09
epoch [9/30] batch [180/796] time 0.349 (0.387) data 0.000 (0.006) loss 0.3088 (1.7740) lr 8.3457e-03 eta 1:51:54
epoch [9/30] batch [200/796] time 0.390 (0.386) data 0.000 (0.005) loss 1.8555 (1.7617) lr 8.3457e-03 eta 1:51:30
epoch [9/30] batch [220/796] time 0.351 (0.386) data 0.000 (0.005) loss 0.8633 (1.7081) lr 8.3457e-03 eta 1:51:07
epoch [9/30] batch [240/796] time 0.398 (0.385) data 0.000 (0.004) loss 4.9336 (1.7846) lr 8.3457e-03 eta 1:50:54
epoch [9/30] batch [260/796] time 0.392 (0.385) data 0.000 (0.004) loss 1.4961 (1.7282) lr 8.3457e-03 eta 1:50:38
epoch [9/30] batch [280/796] time 0.358 (0.384) data 0.000 (0.004) loss 0.3320 (1.7203) lr 8.3457e-03 eta 1:50:22
epoch [9/30] batch [300/796] time 0.355 (0.384) data 0.000 (0.003) loss 1.8252 (1.7297) lr 8.3457e-03 eta 1:50:03
epoch [9/30] batch [320/796] time 0.397 (0.384) data 0.000 (0.003) loss 1.6074 (1.7299) lr 8.3457e-03 eta 1:49:55
epoch [9/30] batch [340/796] time 0.383 (0.383) data 0.000 (0.003) loss 0.1356 (1.7295) lr 8.3457e-03 eta 1:49:35
epoch [9/30] batch [360/796] time 0.357 (0.383) data 0.000 (0.003) loss 3.0312 (1.7236) lr 8.3457e-03 eta 1:49:20
epoch [9/30] batch [380/796] time 0.367 (0.382) data 0.000 (0.003) loss 0.3977 (1.7033) lr 8.3457e-03 eta 1:49:10
epoch [9/30] batch [400/796] time 0.383 (0.382) data 0.000 (0.003) loss 0.7441 (1.6959) lr 8.3457e-03 eta 1:49:02
epoch [9/30] batch [420/796] time 0.359 (0.382) data 0.000 (0.003) loss 1.5039 (1.6859) lr 8.3457e-03 eta 1:48:51
epoch [9/30] batch [440/796] time 0.358 (0.382) data 0.000 (0.002) loss 1.0586 (1.6838) lr 8.3457e-03 eta 1:48:43
epoch [9/30] batch [460/796] time 0.357 (0.382) data 0.000 (0.002) loss 1.7178 (1.6814) lr 8.3457e-03 eta 1:48:35
epoch [9/30] batch [480/796] time 0.394 (0.382) data 0.000 (0.002) loss 0.5957 (1.7057) lr 8.3457e-03 eta 1:48:30
epoch [9/30] batch [500/796] time 0.381 (0.383) data 0.000 (0.002) loss 0.5210 (1.7255) lr 8.3457e-03 eta 1:48:28
epoch [9/30] batch [520/796] time 0.386 (0.383) data 0.000 (0.002) loss 0.5566 (1.7168) lr 8.3457e-03 eta 1:48:21
epoch [9/30] batch [540/796] time 0.383 (0.383) data 0.000 (0.002) loss 1.6670 (1.7181) lr 8.3457e-03 eta 1:48:13
epoch [9/30] batch [560/796] time 0.396 (0.383) data 0.000 (0.002) loss 2.0781 (1.7207) lr 8.3457e-03 eta 1:48:05
epoch [9/30] batch [580/796] time 0.401 (0.383) data 0.000 (0.002) loss 1.6133 (1.7408) lr 8.3457e-03 eta 1:48:01
epoch [9/30] batch [600/796] time 0.390 (0.383) data 0.000 (0.002) loss 0.7422 (1.7389) lr 8.3457e-03 eta 1:47:51
epoch [9/30] batch [620/796] time 0.395 (0.383) data 0.000 (0.002) loss 1.0439 (1.7351) lr 8.3457e-03 eta 1:47:43
epoch [9/30] batch [640/796] time 0.349 (0.382) data 0.000 (0.002) loss 0.9199 (1.7455) lr 8.3457e-03 eta 1:47:32
epoch [9/30] batch [660/796] time 0.371 (0.382) data 0.000 (0.002) loss 2.5898 (1.7581) lr 8.3457e-03 eta 1:47:23
epoch [9/30] batch [680/796] time 0.369 (0.382) data 0.000 (0.002) loss 0.7300 (1.7571) lr 8.3457e-03 eta 1:47:16
epoch [9/30] batch [700/796] time 0.362 (0.382) data 0.000 (0.002) loss 1.4062 (1.7527) lr 8.3457e-03 eta 1:47:07
epoch [9/30] batch [720/796] time 0.373 (0.382) data 0.000 (0.002) loss 0.5020 (1.7559) lr 8.3457e-03 eta 1:46:54
epoch [9/30] batch [740/796] time 0.391 (0.382) data 0.000 (0.002) loss 0.5347 (1.7616) lr 8.3457e-03 eta 1:46:46
epoch [9/30] batch [760/796] time 0.356 (0.382) data 0.000 (0.002) loss 2.3574 (1.7660) lr 8.3457e-03 eta 1:46:38
epoch [9/30] batch [780/796] time 0.340 (0.381) data 0.000 (0.001) loss 1.7070 (1.7624) lr 8.3457e-03 eta 1:46:17
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.49s/it] 10%|█         | 2/20 [00:06<00:50,  2.81s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.66s/it] 20%|██        | 4/20 [00:07<00:17,  1.12s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:08<00:03,  2.71it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.96it/s] 60%|██████    | 12/20 [00:09<00:02,  3.14it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.29it/s] 70%|███████   | 14/20 [00:09<00:01,  3.42it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.74it/s] 80%|████████  | 16/20 [00:10<00:00,  4.05it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.96it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.09it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.43it/s]100%|██████████| 20/20 [00:11<00:00,  4.77it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,584
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 79.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [10/30] batch [20/796] time 0.398 (0.432) data 0.000 (0.041) loss 2.2266 (1.5648) lr 7.9389e-03 eta 2:00:12
epoch [10/30] batch [40/796] time 0.389 (0.404) data 0.000 (0.020) loss 1.3936 (1.6347) lr 7.9389e-03 eta 1:52:18
epoch [10/30] batch [60/796] time 0.360 (0.395) data 0.000 (0.014) loss 1.0439 (1.5955) lr 7.9389e-03 eta 1:49:33
epoch [10/30] batch [80/796] time 0.354 (0.392) data 0.000 (0.010) loss 0.6797 (1.5357) lr 7.9389e-03 eta 1:48:39
epoch [10/30] batch [100/796] time 0.396 (0.391) data 0.000 (0.008) loss 0.3987 (1.5444) lr 7.9389e-03 eta 1:48:10
epoch [10/30] batch [120/796] time 0.377 (0.390) data 0.000 (0.007) loss 3.1484 (1.5755) lr 7.9389e-03 eta 1:47:45
epoch [10/30] batch [140/796] time 0.359 (0.388) data 0.000 (0.006) loss 0.7939 (1.6167) lr 7.9389e-03 eta 1:47:10
epoch [10/30] batch [160/796] time 0.400 (0.386) data 0.000 (0.005) loss 0.6108 (1.5895) lr 7.9389e-03 eta 1:46:35
epoch [10/30] batch [180/796] time 0.368 (0.385) data 0.000 (0.005) loss 0.5093 (1.5747) lr 7.9389e-03 eta 1:46:13
epoch [10/30] batch [200/796] time 0.376 (0.384) data 0.000 (0.004) loss 3.6309 (1.6024) lr 7.9389e-03 eta 1:45:50
epoch [10/30] batch [220/796] time 0.381 (0.384) data 0.000 (0.004) loss 3.5371 (1.5899) lr 7.9389e-03 eta 1:45:37
epoch [10/30] batch [240/796] time 0.381 (0.384) data 0.000 (0.004) loss 2.0645 (1.5968) lr 7.9389e-03 eta 1:45:25
epoch [10/30] batch [260/796] time 0.410 (0.383) data 0.000 (0.003) loss 2.4551 (1.6036) lr 7.9389e-03 eta 1:45:06
epoch [10/30] batch [280/796] time 0.369 (0.383) data 0.000 (0.003) loss 0.9927 (1.5827) lr 7.9389e-03 eta 1:44:50
epoch [10/30] batch [300/796] time 0.407 (0.383) data 0.000 (0.003) loss 1.5811 (1.6020) lr 7.9389e-03 eta 1:44:42
epoch [10/30] batch [320/796] time 0.375 (0.383) data 0.000 (0.003) loss 1.1514 (1.6004) lr 7.9389e-03 eta 1:44:36
epoch [10/30] batch [340/796] time 0.390 (0.383) data 0.000 (0.003) loss 2.5234 (1.6213) lr 7.9389e-03 eta 1:44:24
epoch [10/30] batch [360/796] time 0.369 (0.382) data 0.000 (0.003) loss 1.8633 (1.6392) lr 7.9389e-03 eta 1:44:11
epoch [10/30] batch [380/796] time 0.388 (0.382) data 0.000 (0.002) loss 1.6455 (1.6366) lr 7.9389e-03 eta 1:43:57
epoch [10/30] batch [400/796] time 0.352 (0.382) data 0.000 (0.002) loss 3.8535 (1.6433) lr 7.9389e-03 eta 1:43:53
epoch [10/30] batch [420/796] time 0.409 (0.382) data 0.000 (0.002) loss 1.9150 (1.6481) lr 7.9389e-03 eta 1:43:52
epoch [10/30] batch [440/796] time 0.359 (0.382) data 0.000 (0.002) loss 0.3665 (1.6438) lr 7.9389e-03 eta 1:43:41
epoch [10/30] batch [460/796] time 0.375 (0.382) data 0.000 (0.002) loss 2.3027 (1.6533) lr 7.9389e-03 eta 1:43:32
epoch [10/30] batch [480/796] time 0.410 (0.382) data 0.000 (0.002) loss 3.4414 (1.6352) lr 7.9389e-03 eta 1:43:25
epoch [10/30] batch [500/796] time 0.400 (0.382) data 0.000 (0.002) loss 1.0117 (1.6603) lr 7.9389e-03 eta 1:43:21
epoch [10/30] batch [520/796] time 0.361 (0.382) data 0.000 (0.002) loss 1.3164 (1.6656) lr 7.9389e-03 eta 1:43:09
epoch [10/30] batch [540/796] time 0.374 (0.382) data 0.000 (0.002) loss 0.3240 (1.6673) lr 7.9389e-03 eta 1:43:01
epoch [10/30] batch [560/796] time 0.362 (0.382) data 0.000 (0.002) loss 1.5322 (1.6523) lr 7.9389e-03 eta 1:42:55
epoch [10/30] batch [580/796] time 0.351 (0.382) data 0.000 (0.002) loss 0.6621 (1.6455) lr 7.9389e-03 eta 1:42:44
epoch [10/30] batch [600/796] time 0.400 (0.382) data 0.000 (0.002) loss 1.2520 (1.6580) lr 7.9389e-03 eta 1:42:34
epoch [10/30] batch [620/796] time 0.426 (0.382) data 0.000 (0.002) loss 0.8696 (1.6354) lr 7.9389e-03 eta 1:42:24
epoch [10/30] batch [640/796] time 0.386 (0.382) data 0.000 (0.002) loss 1.0615 (1.6444) lr 7.9389e-03 eta 1:42:19
epoch [10/30] batch [660/796] time 0.382 (0.382) data 0.000 (0.001) loss 2.5449 (1.6455) lr 7.9389e-03 eta 1:42:12
epoch [10/30] batch [680/796] time 0.354 (0.382) data 0.000 (0.001) loss 1.0527 (1.6561) lr 7.9389e-03 eta 1:42:05
epoch [10/30] batch [700/796] time 0.391 (0.382) data 0.000 (0.001) loss 2.9316 (1.6806) lr 7.9389e-03 eta 1:41:56
epoch [10/30] batch [720/796] time 0.350 (0.382) data 0.000 (0.001) loss 2.2148 (1.6748) lr 7.9389e-03 eta 1:41:44
epoch [10/30] batch [740/796] time 0.357 (0.382) data 0.000 (0.001) loss 3.9180 (1.6807) lr 7.9389e-03 eta 1:41:37
epoch [10/30] batch [760/796] time 0.381 (0.381) data 0.000 (0.001) loss 4.1836 (1.6929) lr 7.9389e-03 eta 1:41:26
epoch [10/30] batch [780/796] time 0.346 (0.381) data 0.000 (0.001) loss 4.7383 (1.7057) lr 7.9389e-03 eta 1:41:06
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:42,  5.39s/it] 10%|█         | 2/20 [00:06<00:53,  2.98s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.75s/it] 20%|██        | 4/20 [00:07<00:18,  1.18s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.16it/s] 30%|███       | 6/20 [00:07<00:09,  1.50it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:09<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.03it/s] 60%|██████    | 12/20 [00:09<00:02,  3.24it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.34it/s] 70%|███████   | 14/20 [00:10<00:01,  3.54it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.54it/s] 80%|████████  | 16/20 [00:10<00:01,  3.72it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.73it/s] 90%|█████████ | 18/20 [00:11<00:00,  4.10it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.44it/s]100%|██████████| 20/20 [00:11<00:00,  4.78it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,574
* accuracy: 79.1%
* error: 20.9%
* macro_f1: 78.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-10

epoch [11/30] batch [20/796] time 0.353 (0.422) data 0.000 (0.035) loss 1.3936 (1.6651) lr 7.5000e-03 eta 1:51:45
epoch [11/30] batch [40/796] time 0.368 (0.402) data 0.000 (0.017) loss 0.5225 (1.5846) lr 7.5000e-03 eta 1:46:18
epoch [11/30] batch [60/796] time 0.396 (0.397) data 0.000 (0.012) loss 1.2705 (1.6199) lr 7.5000e-03 eta 1:44:55
epoch [11/30] batch [80/796] time 0.407 (0.392) data 0.000 (0.009) loss 1.5684 (1.5046) lr 7.5000e-03 eta 1:43:35
epoch [11/30] batch [100/796] time 0.406 (0.389) data 0.000 (0.007) loss 3.2227 (1.5787) lr 7.5000e-03 eta 1:42:26
epoch [11/30] batch [120/796] time 0.410 (0.387) data 0.000 (0.006) loss 0.5562 (1.5882) lr 7.5000e-03 eta 1:41:54
epoch [11/30] batch [140/796] time 0.412 (0.386) data 0.000 (0.005) loss 0.8154 (1.5659) lr 7.5000e-03 eta 1:41:33
epoch [11/30] batch [160/796] time 0.358 (0.386) data 0.000 (0.005) loss 0.7700 (1.5899) lr 7.5000e-03 eta 1:41:17
epoch [11/30] batch [180/796] time 0.401 (0.385) data 0.000 (0.004) loss 1.8574 (1.6035) lr 7.5000e-03 eta 1:40:58
epoch [11/30] batch [200/796] time 0.403 (0.385) data 0.000 (0.004) loss 4.0859 (1.6528) lr 7.5000e-03 eta 1:40:48
epoch [11/30] batch [220/796] time 0.349 (0.384) data 0.000 (0.003) loss 4.7188 (1.6595) lr 7.5000e-03 eta 1:40:29
epoch [11/30] batch [240/796] time 0.405 (0.383) data 0.000 (0.003) loss 1.2725 (1.6733) lr 7.5000e-03 eta 1:40:11
epoch [11/30] batch [260/796] time 0.360 (0.383) data 0.000 (0.003) loss 1.7871 (1.6621) lr 7.5000e-03 eta 1:39:56
epoch [11/30] batch [280/796] time 0.425 (0.383) data 0.000 (0.003) loss 4.4414 (1.6784) lr 7.5000e-03 eta 1:39:46
epoch [11/30] batch [300/796] time 0.356 (0.382) data 0.000 (0.003) loss 0.8223 (1.6780) lr 7.5000e-03 eta 1:39:33
epoch [11/30] batch [320/796] time 0.405 (0.383) data 0.000 (0.002) loss 2.5039 (1.6945) lr 7.5000e-03 eta 1:39:34
epoch [11/30] batch [340/796] time 0.360 (0.383) data 0.000 (0.002) loss 2.0352 (1.7138) lr 7.5000e-03 eta 1:39:23
epoch [11/30] batch [360/796] time 0.355 (0.382) data 0.000 (0.002) loss 1.0137 (1.6990) lr 7.5000e-03 eta 1:39:11
epoch [11/30] batch [380/796] time 0.387 (0.382) data 0.000 (0.002) loss 2.3008 (1.6979) lr 7.5000e-03 eta 1:39:01
epoch [11/30] batch [400/796] time 0.378 (0.382) data 0.000 (0.002) loss 0.8564 (1.6893) lr 7.5000e-03 eta 1:38:50
epoch [11/30] batch [420/796] time 0.378 (0.382) data 0.000 (0.002) loss 3.2188 (1.6686) lr 7.5000e-03 eta 1:38:43
epoch [11/30] batch [440/796] time 0.403 (0.383) data 0.000 (0.002) loss 0.0928 (1.6961) lr 7.5000e-03 eta 1:38:41
epoch [11/30] batch [460/796] time 0.365 (0.382) data 0.000 (0.002) loss 1.3643 (1.6691) lr 7.5000e-03 eta 1:38:33
epoch [11/30] batch [480/796] time 0.352 (0.382) data 0.000 (0.002) loss 1.4863 (1.6719) lr 7.5000e-03 eta 1:38:22
epoch [11/30] batch [500/796] time 0.348 (0.382) data 0.000 (0.002) loss 0.5190 (1.6525) lr 7.5000e-03 eta 1:38:13
epoch [11/30] batch [520/796] time 0.400 (0.382) data 0.000 (0.002) loss 1.0283 (1.6521) lr 7.5000e-03 eta 1:38:07
epoch [11/30] batch [540/796] time 0.403 (0.382) data 0.000 (0.002) loss 4.9883 (1.6431) lr 7.5000e-03 eta 1:38:00
epoch [11/30] batch [560/796] time 0.363 (0.382) data 0.000 (0.001) loss 1.6250 (1.6374) lr 7.5000e-03 eta 1:37:50
epoch [11/30] batch [580/796] time 0.387 (0.382) data 0.000 (0.001) loss 0.5972 (1.6497) lr 7.5000e-03 eta 1:37:43
epoch [11/30] batch [600/796] time 0.375 (0.382) data 0.000 (0.001) loss 2.5742 (1.6605) lr 7.5000e-03 eta 1:37:33
epoch [11/30] batch [620/796] time 0.389 (0.382) data 0.000 (0.001) loss 0.9023 (1.6691) lr 7.5000e-03 eta 1:37:26
epoch [11/30] batch [640/796] time 0.357 (0.382) data 0.000 (0.001) loss 1.2500 (1.6762) lr 7.5000e-03 eta 1:37:19
epoch [11/30] batch [660/796] time 0.362 (0.382) data 0.000 (0.001) loss 2.3730 (1.6844) lr 7.5000e-03 eta 1:37:15
epoch [11/30] batch [680/796] time 0.386 (0.382) data 0.000 (0.001) loss 0.7974 (1.6861) lr 7.5000e-03 eta 1:37:06
epoch [11/30] batch [700/796] time 0.396 (0.382) data 0.000 (0.001) loss 1.0479 (1.6924) lr 7.5000e-03 eta 1:36:56
epoch [11/30] batch [720/796] time 0.349 (0.382) data 0.000 (0.001) loss 0.7856 (1.6851) lr 7.5000e-03 eta 1:36:46
epoch [11/30] batch [740/796] time 0.405 (0.382) data 0.000 (0.001) loss 1.1211 (1.6790) lr 7.5000e-03 eta 1:36:42
epoch [11/30] batch [760/796] time 0.399 (0.382) data 0.000 (0.001) loss 2.5469 (1.6716) lr 7.5000e-03 eta 1:36:36
epoch [11/30] batch [780/796] time 0.344 (0.382) data 0.000 (0.001) loss 1.7910 (1.6779) lr 7.5000e-03 eta 1:36:16
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.62s/it] 10%|█         | 2/20 [00:06<00:53,  2.97s/it] 15%|█▌        | 3/20 [00:07<00:29,  1.75s/it] 20%|██        | 4/20 [00:07<00:18,  1.17s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.84it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:09<00:03,  2.77it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.99it/s] 60%|██████    | 12/20 [00:09<00:02,  3.21it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.52it/s] 70%|███████   | 14/20 [00:10<00:01,  3.68it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.93it/s] 80%|████████  | 16/20 [00:10<00:00,  4.20it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.11it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.63it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.04it/s]100%|██████████| 20/20 [00:11<00:00,  4.45it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,579
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 78.8%

epoch [12/30] batch [20/796] time 0.388 (0.433) data 0.000 (0.035) loss 1.0742 (1.7842) lr 7.0337e-03 eta 1:49:07
epoch [12/30] batch [40/796] time 0.410 (0.403) data 0.000 (0.018) loss 2.6797 (1.8849) lr 7.0337e-03 eta 1:41:19
epoch [12/30] batch [60/796] time 0.382 (0.395) data 0.000 (0.012) loss 1.0039 (1.7652) lr 7.0337e-03 eta 1:39:02
epoch [12/30] batch [80/796] time 0.405 (0.392) data 0.000 (0.009) loss 3.3242 (1.6411) lr 7.0337e-03 eta 1:38:18
epoch [12/30] batch [100/796] time 0.416 (0.388) data 0.000 (0.007) loss 1.3701 (1.6857) lr 7.0337e-03 eta 1:37:15
epoch [12/30] batch [120/796] time 0.386 (0.387) data 0.000 (0.006) loss 3.0488 (1.6938) lr 7.0337e-03 eta 1:36:45
epoch [12/30] batch [140/796] time 0.379 (0.386) data 0.000 (0.005) loss 3.2695 (1.7496) lr 7.0337e-03 eta 1:36:27
epoch [12/30] batch [160/796] time 0.354 (0.386) data 0.000 (0.005) loss 1.8086 (1.7765) lr 7.0337e-03 eta 1:36:11
epoch [12/30] batch [180/796] time 0.473 (0.386) data 0.000 (0.004) loss 3.1367 (1.7737) lr 7.0337e-03 eta 1:36:02
epoch [12/30] batch [200/796] time 0.367 (0.385) data 0.000 (0.004) loss 1.9355 (1.7975) lr 7.0337e-03 eta 1:35:41
epoch [12/30] batch [220/796] time 0.401 (0.384) data 0.000 (0.003) loss 1.0488 (1.7761) lr 7.0337e-03 eta 1:35:27
epoch [12/30] batch [240/796] time 0.373 (0.384) data 0.000 (0.003) loss 0.8359 (1.7721) lr 7.0337e-03 eta 1:35:21
epoch [12/30] batch [260/796] time 0.381 (0.384) data 0.000 (0.003) loss 0.9966 (1.7386) lr 7.0337e-03 eta 1:35:11
epoch [12/30] batch [280/796] time 0.354 (0.383) data 0.000 (0.003) loss 1.2910 (1.6996) lr 7.0337e-03 eta 1:34:52
epoch [12/30] batch [300/796] time 0.362 (0.383) data 0.000 (0.003) loss 0.0731 (1.7017) lr 7.0337e-03 eta 1:34:36
epoch [12/30] batch [320/796] time 0.393 (0.383) data 0.000 (0.002) loss 3.0156 (1.6758) lr 7.0337e-03 eta 1:34:33
epoch [12/30] batch [340/796] time 0.360 (0.383) data 0.000 (0.002) loss 2.6484 (1.6742) lr 7.0337e-03 eta 1:34:26
epoch [12/30] batch [360/796] time 0.386 (0.383) data 0.000 (0.002) loss 1.9453 (1.6954) lr 7.0337e-03 eta 1:34:14
epoch [12/30] batch [380/796] time 0.378 (0.383) data 0.000 (0.002) loss 1.8691 (1.7036) lr 7.0337e-03 eta 1:34:06
epoch [12/30] batch [400/796] time 0.358 (0.383) data 0.000 (0.002) loss 1.4502 (1.6926) lr 7.0337e-03 eta 1:34:00
epoch [12/30] batch [420/796] time 0.381 (0.383) data 0.000 (0.002) loss 1.3066 (1.6873) lr 7.0337e-03 eta 1:33:47
epoch [12/30] batch [440/796] time 0.395 (0.382) data 0.000 (0.002) loss 3.3770 (1.6889) lr 7.0337e-03 eta 1:33:34
epoch [12/30] batch [460/796] time 0.396 (0.383) data 0.000 (0.002) loss 1.6816 (1.6912) lr 7.0337e-03 eta 1:33:29
epoch [12/30] batch [480/796] time 0.382 (0.382) data 0.000 (0.002) loss 0.6274 (1.6954) lr 7.0337e-03 eta 1:33:18
epoch [12/30] batch [500/796] time 0.353 (0.382) data 0.000 (0.002) loss 3.3359 (1.7217) lr 7.0337e-03 eta 1:33:04
epoch [12/30] batch [520/796] time 0.379 (0.382) data 0.000 (0.002) loss 1.0615 (1.7322) lr 7.0337e-03 eta 1:32:55
epoch [12/30] batch [540/796] time 0.371 (0.382) data 0.000 (0.002) loss 0.4702 (1.7496) lr 7.0337e-03 eta 1:32:46
epoch [12/30] batch [560/796] time 0.396 (0.382) data 0.000 (0.002) loss 2.5723 (1.7488) lr 7.0337e-03 eta 1:32:39
epoch [12/30] batch [580/796] time 0.393 (0.382) data 0.000 (0.001) loss 1.3418 (1.7463) lr 7.0337e-03 eta 1:32:29
epoch [12/30] batch [600/796] time 0.392 (0.382) data 0.000 (0.001) loss 3.2676 (1.7348) lr 7.0337e-03 eta 1:32:21
epoch [12/30] batch [620/796] time 0.394 (0.382) data 0.000 (0.001) loss 2.8730 (1.7342) lr 7.0337e-03 eta 1:32:15
epoch [12/30] batch [640/796] time 0.385 (0.381) data 0.000 (0.001) loss 3.5391 (1.7347) lr 7.0337e-03 eta 1:32:03
epoch [12/30] batch [660/796] time 0.385 (0.381) data 0.000 (0.001) loss 4.4414 (1.7413) lr 7.0337e-03 eta 1:31:57
epoch [12/30] batch [680/796] time 0.410 (0.381) data 0.000 (0.001) loss 4.2383 (1.7284) lr 7.0337e-03 eta 1:31:50
epoch [12/30] batch [700/796] time 0.355 (0.382) data 0.000 (0.001) loss 4.4727 (1.7353) lr 7.0337e-03 eta 1:31:46
epoch [12/30] batch [720/796] time 0.358 (0.382) data 0.000 (0.001) loss 0.7080 (1.7392) lr 7.0337e-03 eta 1:31:38
epoch [12/30] batch [740/796] time 0.361 (0.382) data 0.000 (0.001) loss 0.8096 (1.7385) lr 7.0337e-03 eta 1:31:30
epoch [12/30] batch [760/796] time 0.357 (0.382) data 0.000 (0.001) loss 3.6348 (1.7437) lr 7.0337e-03 eta 1:31:21
epoch [12/30] batch [780/796] time 0.347 (0.381) data 0.000 (0.001) loss 5.1172 (1.7435) lr 7.0337e-03 eta 1:31:01
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:43,  5.45s/it] 10%|█         | 2/20 [00:06<00:53,  2.97s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.75s/it] 20%|██        | 4/20 [00:07<00:18,  1.18s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.50it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.81it/s] 40%|████      | 8/20 [00:08<00:05,  2.14it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.84it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.17it/s] 60%|██████    | 12/20 [00:09<00:02,  3.34it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.61it/s] 70%|███████   | 14/20 [00:09<00:01,  3.63it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.93it/s] 80%|████████  | 16/20 [00:10<00:00,  4.01it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.90it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.89it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.26it/s]100%|██████████| 20/20 [00:11<00:00,  4.63it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,579
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 78.8%

epoch [13/30] batch [20/796] time 0.388 (0.429) data 0.000 (0.043) loss 0.5981 (1.9056) lr 6.5451e-03 eta 1:42:17
epoch [13/30] batch [40/796] time 0.388 (0.404) data 0.000 (0.022) loss 1.1270 (1.8254) lr 6.5451e-03 eta 1:36:05
epoch [13/30] batch [60/796] time 0.354 (0.395) data 0.000 (0.015) loss 0.8047 (1.7301) lr 6.5451e-03 eta 1:33:59
epoch [13/30] batch [80/796] time 0.393 (0.392) data 0.000 (0.011) loss 0.3630 (1.6934) lr 6.5451e-03 eta 1:32:58
epoch [13/30] batch [100/796] time 0.359 (0.391) data 0.000 (0.009) loss 0.9067 (1.7327) lr 6.5451e-03 eta 1:32:37
epoch [13/30] batch [120/796] time 0.367 (0.389) data 0.000 (0.007) loss 0.2444 (1.7155) lr 6.5451e-03 eta 1:32:11
epoch [13/30] batch [140/796] time 0.383 (0.387) data 0.000 (0.006) loss 1.1260 (1.7233) lr 6.5451e-03 eta 1:31:31
epoch [13/30] batch [160/796] time 0.392 (0.386) data 0.000 (0.006) loss 1.3857 (1.7918) lr 6.5451e-03 eta 1:31:04
epoch [13/30] batch [180/796] time 0.402 (0.386) data 0.000 (0.005) loss 1.9219 (1.7785) lr 6.5451e-03 eta 1:30:58
epoch [13/30] batch [200/796] time 0.373 (0.385) data 0.000 (0.005) loss 0.2183 (1.7528) lr 6.5451e-03 eta 1:30:32
epoch [13/30] batch [220/796] time 0.368 (0.384) data 0.000 (0.004) loss 1.4863 (1.7815) lr 6.5451e-03 eta 1:30:15
epoch [13/30] batch [240/796] time 0.380 (0.383) data 0.000 (0.004) loss 1.0166 (1.7466) lr 6.5451e-03 eta 1:29:57
epoch [13/30] batch [260/796] time 0.390 (0.383) data 0.000 (0.004) loss 0.9507 (1.7638) lr 6.5451e-03 eta 1:29:43
epoch [13/30] batch [280/796] time 0.399 (0.383) data 0.000 (0.003) loss 0.4524 (1.7685) lr 6.5451e-03 eta 1:29:39
epoch [13/30] batch [300/796] time 0.359 (0.383) data 0.000 (0.003) loss 1.3057 (1.7342) lr 6.5451e-03 eta 1:29:28
epoch [13/30] batch [320/796] time 0.408 (0.383) data 0.000 (0.003) loss 1.3672 (1.7435) lr 6.5451e-03 eta 1:29:25
epoch [13/30] batch [340/796] time 0.402 (0.383) data 0.000 (0.003) loss 0.8916 (1.7284) lr 6.5451e-03 eta 1:29:16
epoch [13/30] batch [360/796] time 0.363 (0.383) data 0.000 (0.003) loss 1.2793 (1.7023) lr 6.5451e-03 eta 1:29:13
epoch [13/30] batch [380/796] time 0.355 (0.383) data 0.000 (0.003) loss 0.5215 (1.7178) lr 6.5451e-03 eta 1:29:01
epoch [13/30] batch [400/796] time 0.370 (0.383) data 0.000 (0.002) loss 4.7344 (1.7270) lr 6.5451e-03 eta 1:28:54
epoch [13/30] batch [420/796] time 0.393 (0.383) data 0.000 (0.002) loss 0.3887 (1.7207) lr 6.5451e-03 eta 1:28:46
epoch [13/30] batch [440/796] time 0.356 (0.383) data 0.000 (0.002) loss 2.9629 (1.7437) lr 6.5451e-03 eta 1:28:36
epoch [13/30] batch [460/796] time 0.362 (0.383) data 0.000 (0.002) loss 2.4414 (1.7397) lr 6.5451e-03 eta 1:28:27
epoch [13/30] batch [480/796] time 0.379 (0.383) data 0.000 (0.002) loss 0.6367 (1.7140) lr 6.5451e-03 eta 1:28:23
epoch [13/30] batch [500/796] time 0.385 (0.383) data 0.000 (0.002) loss 0.8110 (1.6932) lr 6.5451e-03 eta 1:28:19
epoch [13/30] batch [520/796] time 0.355 (0.383) data 0.000 (0.002) loss 3.1836 (1.6806) lr 6.5451e-03 eta 1:28:09
epoch [13/30] batch [540/796] time 0.352 (0.383) data 0.000 (0.002) loss 0.4873 (1.6595) lr 6.5451e-03 eta 1:28:01
epoch [13/30] batch [560/796] time 0.349 (0.383) data 0.000 (0.002) loss 1.1133 (1.6615) lr 6.5451e-03 eta 1:27:51
epoch [13/30] batch [580/796] time 0.401 (0.383) data 0.000 (0.002) loss 2.1680 (1.6806) lr 6.5451e-03 eta 1:27:44
epoch [13/30] batch [600/796] time 0.404 (0.383) data 0.000 (0.002) loss 4.6406 (1.6886) lr 6.5451e-03 eta 1:27:33
epoch [13/30] batch [620/796] time 0.382 (0.383) data 0.000 (0.002) loss 2.0996 (1.6846) lr 6.5451e-03 eta 1:27:25
epoch [13/30] batch [640/796] time 0.368 (0.383) data 0.000 (0.002) loss 5.4844 (1.6973) lr 6.5451e-03 eta 1:27:19
epoch [13/30] batch [660/796] time 0.363 (0.383) data 0.000 (0.002) loss 5.0000 (1.7027) lr 6.5451e-03 eta 1:27:13
epoch [13/30] batch [680/796] time 0.390 (0.383) data 0.000 (0.002) loss 0.5430 (1.6879) lr 6.5451e-03 eta 1:27:02
epoch [13/30] batch [700/796] time 0.380 (0.383) data 0.000 (0.001) loss 1.8223 (1.7026) lr 6.5451e-03 eta 1:26:55
epoch [13/30] batch [720/796] time 0.402 (0.383) data 0.000 (0.001) loss 2.1543 (1.7091) lr 6.5451e-03 eta 1:26:45
epoch [13/30] batch [740/796] time 0.394 (0.383) data 0.000 (0.001) loss 1.2520 (1.7027) lr 6.5451e-03 eta 1:26:40
epoch [13/30] batch [760/796] time 0.401 (0.383) data 0.000 (0.001) loss 3.3086 (1.7020) lr 6.5451e-03 eta 1:26:30
epoch [13/30] batch [780/796] time 0.347 (0.382) data 0.000 (0.001) loss 1.2100 (1.6938) lr 6.5451e-03 eta 1:26:12
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:42,  5.37s/it] 10%|█         | 2/20 [00:06<00:52,  2.93s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.73s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.52it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.71it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.05it/s] 60%|██████    | 12/20 [00:09<00:02,  3.31it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.44it/s] 70%|███████   | 14/20 [00:09<00:01,  3.56it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.71it/s] 80%|████████  | 16/20 [00:10<00:01,  3.84it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.83it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.95it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.31it/s]100%|██████████| 20/20 [00:11<00:00,  4.68it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,577
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 78.7%

epoch [14/30] batch [20/796] time 0.389 (0.418) data 0.000 (0.034) loss 0.2124 (1.9274) lr 6.0396e-03 eta 1:34:04
epoch [14/30] batch [40/796] time 0.411 (0.400) data 0.000 (0.017) loss 0.7231 (1.8940) lr 6.0396e-03 eta 1:29:51
epoch [14/30] batch [60/796] time 0.369 (0.394) data 0.000 (0.011) loss 0.9702 (2.0937) lr 6.0396e-03 eta 1:28:34
epoch [14/30] batch [80/796] time 0.381 (0.392) data 0.000 (0.009) loss 2.9844 (1.9678) lr 6.0396e-03 eta 1:27:48
epoch [14/30] batch [100/796] time 0.397 (0.389) data 0.000 (0.007) loss 2.5098 (1.8623) lr 6.0396e-03 eta 1:27:06
epoch [14/30] batch [120/796] time 0.354 (0.387) data 0.000 (0.006) loss 6.0742 (1.9178) lr 6.0396e-03 eta 1:26:30
epoch [14/30] batch [140/796] time 0.400 (0.386) data 0.000 (0.005) loss 2.1973 (1.9097) lr 6.0396e-03 eta 1:26:03
epoch [14/30] batch [160/796] time 0.417 (0.385) data 0.000 (0.004) loss 3.1328 (1.9286) lr 6.0396e-03 eta 1:25:47
epoch [14/30] batch [180/796] time 0.410 (0.384) data 0.000 (0.004) loss 3.6328 (1.9201) lr 6.0396e-03 eta 1:25:32
epoch [14/30] batch [200/796] time 0.376 (0.384) data 0.000 (0.004) loss 2.5371 (1.8779) lr 6.0396e-03 eta 1:25:22
epoch [14/30] batch [220/796] time 0.394 (0.385) data 0.000 (0.003) loss 0.4868 (1.8585) lr 6.0396e-03 eta 1:25:21
epoch [14/30] batch [240/796] time 0.374 (0.384) data 0.000 (0.003) loss 0.6299 (1.8492) lr 6.0396e-03 eta 1:25:05
epoch [14/30] batch [260/796] time 0.352 (0.384) data 0.000 (0.003) loss 0.9580 (1.7682) lr 6.0396e-03 eta 1:24:53
epoch [14/30] batch [280/796] time 0.384 (0.384) data 0.000 (0.003) loss 0.7861 (1.7562) lr 6.0396e-03 eta 1:24:49
epoch [14/30] batch [300/796] time 0.379 (0.384) data 0.000 (0.002) loss 3.4023 (1.7693) lr 6.0396e-03 eta 1:24:37
epoch [14/30] batch [320/796] time 0.371 (0.384) data 0.000 (0.002) loss 0.2769 (1.7853) lr 6.0396e-03 eta 1:24:29
epoch [14/30] batch [340/796] time 0.389 (0.383) data 0.000 (0.002) loss 2.4355 (1.7525) lr 6.0396e-03 eta 1:24:16
epoch [14/30] batch [360/796] time 0.398 (0.383) data 0.000 (0.002) loss 0.5645 (1.7481) lr 6.0396e-03 eta 1:24:07
epoch [14/30] batch [380/796] time 0.383 (0.383) data 0.000 (0.002) loss 1.0166 (1.7397) lr 6.0396e-03 eta 1:23:59
epoch [14/30] batch [400/796] time 0.457 (0.383) data 0.000 (0.002) loss 1.7627 (1.7328) lr 6.0396e-03 eta 1:23:49
epoch [14/30] batch [420/796] time 0.350 (0.383) data 0.000 (0.002) loss 4.4258 (1.7473) lr 6.0396e-03 eta 1:23:36
epoch [14/30] batch [440/796] time 0.387 (0.382) data 0.000 (0.002) loss 1.8213 (1.7333) lr 6.0396e-03 eta 1:23:23
epoch [14/30] batch [460/796] time 0.399 (0.382) data 0.000 (0.002) loss 0.5386 (1.7361) lr 6.0396e-03 eta 1:23:14
epoch [14/30] batch [480/796] time 0.395 (0.382) data 0.000 (0.002) loss 3.3555 (1.7295) lr 6.0396e-03 eta 1:23:03
epoch [14/30] batch [500/796] time 0.396 (0.382) data 0.000 (0.002) loss 0.5244 (1.7233) lr 6.0396e-03 eta 1:22:55
epoch [14/30] batch [520/796] time 0.398 (0.382) data 0.000 (0.002) loss 0.9785 (1.7240) lr 6.0396e-03 eta 1:22:46
epoch [14/30] batch [540/796] time 0.369 (0.382) data 0.000 (0.001) loss 1.1016 (1.7184) lr 6.0396e-03 eta 1:22:41
epoch [14/30] batch [560/796] time 0.368 (0.382) data 0.000 (0.001) loss 0.2183 (1.7161) lr 6.0396e-03 eta 1:22:33
epoch [14/30] batch [580/796] time 0.386 (0.382) data 0.000 (0.001) loss 1.9189 (1.7230) lr 6.0396e-03 eta 1:22:31
epoch [14/30] batch [600/796] time 0.391 (0.383) data 0.000 (0.001) loss 1.0381 (1.7086) lr 6.0396e-03 eta 1:22:27
epoch [14/30] batch [620/796] time 0.412 (0.383) data 0.000 (0.001) loss 2.7637 (1.6943) lr 6.0396e-03 eta 1:22:19
epoch [14/30] batch [640/796] time 0.390 (0.382) data 0.000 (0.001) loss 0.4380 (1.6974) lr 6.0396e-03 eta 1:22:07
epoch [14/30] batch [660/796] time 0.428 (0.382) data 0.000 (0.001) loss 0.4509 (1.6939) lr 6.0396e-03 eta 1:22:02
epoch [14/30] batch [680/796] time 0.356 (0.382) data 0.000 (0.001) loss 0.1506 (1.7033) lr 6.0396e-03 eta 1:21:54
epoch [14/30] batch [700/796] time 0.418 (0.382) data 0.000 (0.001) loss 1.1826 (1.6952) lr 6.0396e-03 eta 1:21:44
epoch [14/30] batch [720/796] time 0.396 (0.382) data 0.000 (0.001) loss 0.7896 (1.6856) lr 6.0396e-03 eta 1:21:37
epoch [14/30] batch [740/796] time 0.375 (0.382) data 0.000 (0.001) loss 0.5796 (1.6886) lr 6.0396e-03 eta 1:21:27
epoch [14/30] batch [760/796] time 0.349 (0.382) data 0.000 (0.001) loss 0.4355 (1.6819) lr 6.0396e-03 eta 1:21:19
epoch [14/30] batch [780/796] time 0.342 (0.381) data 0.000 (0.001) loss 0.2335 (1.6655) lr 6.0396e-03 eta 1:21:01
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:43,  5.47s/it] 10%|█         | 2/20 [00:06<00:51,  2.87s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.69s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.86it/s] 40%|████      | 8/20 [00:08<00:05,  2.17it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.44it/s] 50%|█████     | 10/20 [00:08<00:03,  2.65it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.89it/s] 60%|██████    | 12/20 [00:09<00:02,  3.16it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.39it/s] 70%|███████   | 14/20 [00:09<00:01,  3.65it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.61it/s] 80%|████████  | 16/20 [00:10<00:01,  3.78it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.84it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.22it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.53it/s]100%|██████████| 20/20 [00:11<00:00,  4.85it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,586
* accuracy: 79.7%
* error: 20.3%
* macro_f1: 79.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [15/30] batch [20/796] time 0.405 (0.425) data 0.000 (0.039) loss 1.3232 (1.1786) lr 5.5226e-03 eta 1:30:07
epoch [15/30] batch [40/796] time 0.399 (0.404) data 0.000 (0.019) loss 0.7134 (1.6296) lr 5.5226e-03 eta 1:25:31
epoch [15/30] batch [60/796] time 0.377 (0.397) data 0.000 (0.013) loss 0.0742 (1.6555) lr 5.5226e-03 eta 1:23:52
epoch [15/30] batch [80/796] time 0.405 (0.395) data 0.000 (0.010) loss 2.4277 (1.6570) lr 5.5226e-03 eta 1:23:15
epoch [15/30] batch [100/796] time 0.352 (0.391) data 0.000 (0.008) loss 2.9531 (1.5965) lr 5.5226e-03 eta 1:22:17
epoch [15/30] batch [120/796] time 0.395 (0.390) data 0.000 (0.007) loss 2.5293 (1.6969) lr 5.5226e-03 eta 1:21:55
epoch [15/30] batch [140/796] time 0.379 (0.388) data 0.000 (0.006) loss 0.2703 (1.6764) lr 5.5226e-03 eta 1:21:29
epoch [15/30] batch [160/796] time 0.402 (0.387) data 0.000 (0.005) loss 0.9453 (1.7265) lr 5.5226e-03 eta 1:21:11
epoch [15/30] batch [180/796] time 0.371 (0.387) data 0.000 (0.005) loss 0.6831 (1.6943) lr 5.5226e-03 eta 1:20:57
epoch [15/30] batch [200/796] time 0.397 (0.386) data 0.000 (0.004) loss 0.2932 (1.6772) lr 5.5226e-03 eta 1:20:39
epoch [15/30] batch [220/796] time 0.384 (0.385) data 0.000 (0.004) loss 0.3958 (1.6663) lr 5.5226e-03 eta 1:20:19
epoch [15/30] batch [240/796] time 0.355 (0.385) data 0.000 (0.003) loss 3.5156 (1.6685) lr 5.5226e-03 eta 1:20:07
epoch [15/30] batch [260/796] time 0.354 (0.384) data 0.000 (0.003) loss 1.3535 (1.6664) lr 5.5226e-03 eta 1:19:45
epoch [15/30] batch [280/796] time 0.399 (0.383) data 0.000 (0.003) loss 0.7002 (1.6950) lr 5.5226e-03 eta 1:19:34
epoch [15/30] batch [300/796] time 0.381 (0.383) data 0.000 (0.003) loss 0.1597 (1.6542) lr 5.5226e-03 eta 1:19:26
epoch [15/30] batch [320/796] time 0.381 (0.383) data 0.000 (0.003) loss 0.8223 (1.6545) lr 5.5226e-03 eta 1:19:20
epoch [15/30] batch [340/796] time 0.357 (0.383) data 0.000 (0.003) loss 1.3350 (1.6633) lr 5.5226e-03 eta 1:19:10
epoch [15/30] batch [360/796] time 0.392 (0.383) data 0.000 (0.002) loss 0.2988 (1.6591) lr 5.5226e-03 eta 1:19:02
epoch [15/30] batch [380/796] time 0.362 (0.383) data 0.000 (0.002) loss 4.1250 (1.6529) lr 5.5226e-03 eta 1:18:50
epoch [15/30] batch [400/796] time 0.383 (0.383) data 0.000 (0.002) loss 1.3008 (1.6576) lr 5.5226e-03 eta 1:18:38
epoch [15/30] batch [420/796] time 0.376 (0.382) data 0.000 (0.002) loss 0.1526 (1.6511) lr 5.5226e-03 eta 1:18:29
epoch [15/30] batch [440/796] time 0.363 (0.382) data 0.000 (0.002) loss 0.8091 (1.6475) lr 5.5226e-03 eta 1:18:20
epoch [15/30] batch [460/796] time 0.370 (0.382) data 0.000 (0.002) loss 1.5107 (1.6466) lr 5.5226e-03 eta 1:18:10
epoch [15/30] batch [480/796] time 0.409 (0.382) data 0.000 (0.002) loss 0.9824 (1.6309) lr 5.5226e-03 eta 1:18:01
epoch [15/30] batch [500/796] time 0.390 (0.382) data 0.000 (0.002) loss 5.3984 (1.6443) lr 5.5226e-03 eta 1:17:53
epoch [15/30] batch [520/796] time 0.360 (0.381) data 0.000 (0.002) loss 1.9053 (1.6347) lr 5.5226e-03 eta 1:17:40
epoch [15/30] batch [540/796] time 0.371 (0.382) data 0.000 (0.002) loss 0.3586 (1.6225) lr 5.5226e-03 eta 1:17:35
epoch [15/30] batch [560/796] time 0.396 (0.382) data 0.000 (0.002) loss 1.0283 (1.6179) lr 5.5226e-03 eta 1:17:29
epoch [15/30] batch [580/796] time 0.401 (0.382) data 0.000 (0.002) loss 0.7686 (1.6111) lr 5.5226e-03 eta 1:17:23
epoch [15/30] batch [600/796] time 0.369 (0.382) data 0.000 (0.002) loss 4.2969 (1.6206) lr 5.5226e-03 eta 1:17:14
epoch [15/30] batch [620/796] time 0.468 (0.382) data 0.000 (0.002) loss 1.9268 (1.6236) lr 5.5226e-03 eta 1:17:06
epoch [15/30] batch [640/796] time 0.404 (0.382) data 0.000 (0.001) loss 1.3359 (1.6094) lr 5.5226e-03 eta 1:16:56
epoch [15/30] batch [660/796] time 0.365 (0.381) data 0.000 (0.001) loss 0.8135 (1.6183) lr 5.5226e-03 eta 1:16:46
epoch [15/30] batch [680/796] time 0.376 (0.381) data 0.000 (0.001) loss 0.1890 (1.6139) lr 5.5226e-03 eta 1:16:38
epoch [15/30] batch [700/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.2505 (1.6064) lr 5.5226e-03 eta 1:16:30
epoch [15/30] batch [720/796] time 0.394 (0.381) data 0.000 (0.001) loss 0.3428 (1.6019) lr 5.5226e-03 eta 1:16:22
epoch [15/30] batch [740/796] time 0.361 (0.381) data 0.000 (0.001) loss 1.9326 (1.5923) lr 5.5226e-03 eta 1:16:14
epoch [15/30] batch [760/796] time 0.351 (0.381) data 0.000 (0.001) loss 1.7285 (1.5890) lr 5.5226e-03 eta 1:16:07
epoch [15/30] batch [780/796] time 0.341 (0.381) data 0.000 (0.001) loss 0.1068 (1.5783) lr 5.5226e-03 eta 1:15:51
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.57s/it] 10%|█         | 2/20 [00:06<00:48,  2.70s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.60s/it] 20%|██        | 4/20 [00:06<00:17,  1.09s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.25it/s] 30%|███       | 6/20 [00:07<00:08,  1.58it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.91it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.91it/s] 60%|██████    | 12/20 [00:09<00:02,  3.14it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.30it/s] 70%|███████   | 14/20 [00:09<00:01,  3.39it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.67it/s] 80%|████████  | 16/20 [00:10<00:01,  3.73it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.88it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.26it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.56it/s]100%|██████████| 20/20 [00:10<00:00,  4.87it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,577
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 78.7%

epoch [16/30] batch [20/796] time 0.378 (0.434) data 0.000 (0.043) loss 1.3145 (1.3975) lr 5.0000e-03 eta 1:26:18
epoch [16/30] batch [40/796] time 0.362 (0.408) data 0.000 (0.022) loss 0.2158 (1.6900) lr 5.0000e-03 eta 1:20:53
epoch [16/30] batch [60/796] time 0.348 (0.400) data 0.000 (0.015) loss 1.0195 (1.8066) lr 5.0000e-03 eta 1:19:16
epoch [16/30] batch [80/796] time 0.392 (0.395) data 0.000 (0.011) loss 4.2891 (1.7259) lr 5.0000e-03 eta 1:17:59
epoch [16/30] batch [100/796] time 0.385 (0.392) data 0.000 (0.009) loss 6.1133 (1.7284) lr 5.0000e-03 eta 1:17:21
epoch [16/30] batch [120/796] time 0.383 (0.391) data 0.000 (0.007) loss 4.1094 (1.6907) lr 5.0000e-03 eta 1:16:55
epoch [16/30] batch [140/796] time 0.381 (0.390) data 0.000 (0.006) loss 0.9927 (1.6403) lr 5.0000e-03 eta 1:16:41
epoch [16/30] batch [160/796] time 0.384 (0.388) data 0.000 (0.006) loss 1.4873 (1.6355) lr 5.0000e-03 eta 1:16:15
epoch [16/30] batch [180/796] time 0.354 (0.387) data 0.000 (0.005) loss 1.9121 (1.6360) lr 5.0000e-03 eta 1:15:54
epoch [16/30] batch [200/796] time 0.351 (0.387) data 0.000 (0.005) loss 6.0195 (1.6751) lr 5.0000e-03 eta 1:15:39
epoch [16/30] batch [220/796] time 0.375 (0.386) data 0.000 (0.004) loss 1.1602 (1.6957) lr 5.0000e-03 eta 1:15:24
epoch [16/30] batch [240/796] time 0.370 (0.385) data 0.000 (0.004) loss 1.2812 (1.7076) lr 5.0000e-03 eta 1:15:06
epoch [16/30] batch [260/796] time 0.365 (0.385) data 0.000 (0.004) loss 0.1357 (1.6736) lr 5.0000e-03 eta 1:14:51
epoch [16/30] batch [280/796] time 0.383 (0.384) data 0.000 (0.003) loss 0.4924 (1.6567) lr 5.0000e-03 eta 1:14:37
epoch [16/30] batch [300/796] time 0.397 (0.384) data 0.000 (0.003) loss 3.3223 (1.6910) lr 5.0000e-03 eta 1:14:27
epoch [16/30] batch [320/796] time 0.408 (0.384) data 0.000 (0.003) loss 2.3691 (1.7165) lr 5.0000e-03 eta 1:14:27
epoch [16/30] batch [340/796] time 0.365 (0.384) data 0.000 (0.003) loss 3.0957 (1.7336) lr 5.0000e-03 eta 1:14:19
epoch [16/30] batch [360/796] time 0.393 (0.384) data 0.000 (0.003) loss 3.3027 (1.6906) lr 5.0000e-03 eta 1:14:11
epoch [16/30] batch [380/796] time 0.402 (0.384) data 0.000 (0.003) loss 2.3633 (1.6673) lr 5.0000e-03 eta 1:13:57
epoch [16/30] batch [400/796] time 0.418 (0.383) data 0.000 (0.002) loss 1.3730 (1.6564) lr 5.0000e-03 eta 1:13:45
epoch [16/30] batch [420/796] time 0.413 (0.383) data 0.000 (0.002) loss 1.5469 (1.6545) lr 5.0000e-03 eta 1:13:37
epoch [16/30] batch [440/796] time 0.380 (0.383) data 0.000 (0.002) loss 0.3503 (1.6561) lr 5.0000e-03 eta 1:13:27
epoch [16/30] batch [460/796] time 0.379 (0.383) data 0.000 (0.002) loss 0.6855 (1.6611) lr 5.0000e-03 eta 1:13:19
epoch [16/30] batch [480/796] time 0.393 (0.383) data 0.000 (0.002) loss 0.3135 (1.6588) lr 5.0000e-03 eta 1:13:11
epoch [16/30] batch [500/796] time 0.402 (0.383) data 0.000 (0.002) loss 0.1921 (1.6589) lr 5.0000e-03 eta 1:13:03
epoch [16/30] batch [520/796] time 0.400 (0.383) data 0.000 (0.002) loss 0.4543 (1.6588) lr 5.0000e-03 eta 1:12:53
epoch [16/30] batch [540/796] time 0.394 (0.383) data 0.000 (0.002) loss 2.0449 (1.6679) lr 5.0000e-03 eta 1:12:45
epoch [16/30] batch [560/796] time 0.421 (0.383) data 0.000 (0.002) loss 1.1445 (1.6792) lr 5.0000e-03 eta 1:12:39
epoch [16/30] batch [580/796] time 0.389 (0.383) data 0.000 (0.002) loss 0.2703 (1.6787) lr 5.0000e-03 eta 1:12:27
epoch [16/30] batch [600/796] time 0.403 (0.383) data 0.000 (0.002) loss 2.9121 (1.6698) lr 5.0000e-03 eta 1:12:18
epoch [16/30] batch [620/796] time 0.382 (0.382) data 0.000 (0.002) loss 0.3730 (1.6690) lr 5.0000e-03 eta 1:12:08
epoch [16/30] batch [640/796] time 0.405 (0.382) data 0.000 (0.002) loss 1.8457 (1.6495) lr 5.0000e-03 eta 1:12:00
epoch [16/30] batch [660/796] time 0.379 (0.382) data 0.000 (0.002) loss 2.1719 (1.6333) lr 5.0000e-03 eta 1:11:53
epoch [16/30] batch [680/796] time 0.358 (0.382) data 0.000 (0.002) loss 0.3154 (1.6261) lr 5.0000e-03 eta 1:11:44
epoch [16/30] batch [700/796] time 0.357 (0.382) data 0.000 (0.001) loss 1.8643 (1.6177) lr 5.0000e-03 eta 1:11:35
epoch [16/30] batch [720/796] time 0.397 (0.382) data 0.000 (0.001) loss 1.9600 (1.6167) lr 5.0000e-03 eta 1:11:27
epoch [16/30] batch [740/796] time 0.388 (0.382) data 0.000 (0.001) loss 4.0898 (1.6230) lr 5.0000e-03 eta 1:11:21
epoch [16/30] batch [760/796] time 0.387 (0.382) data 0.000 (0.001) loss 0.6143 (1.6202) lr 5.0000e-03 eta 1:11:12
epoch [16/30] batch [780/796] time 0.341 (0.381) data 0.000 (0.001) loss 2.1836 (1.6227) lr 5.0000e-03 eta 1:10:56
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.66s/it] 10%|█         | 2/20 [00:06<00:53,  2.96s/it] 15%|█▌        | 3/20 [00:07<00:29,  1.75s/it] 20%|██        | 4/20 [00:07<00:18,  1.18s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.16it/s] 30%|███       | 6/20 [00:07<00:09,  1.50it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.83it/s] 40%|████      | 8/20 [00:08<00:05,  2.14it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.43it/s] 50%|█████     | 10/20 [00:09<00:03,  2.75it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.04it/s] 60%|██████    | 12/20 [00:09<00:02,  3.20it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.35it/s] 70%|███████   | 14/20 [00:10<00:01,  3.47it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.72it/s] 80%|████████  | 16/20 [00:10<00:01,  3.76it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.80it/s] 90%|█████████ | 18/20 [00:11<00:00,  4.16it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.48it/s]100%|██████████| 20/20 [00:11<00:00,  4.81it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,585
* accuracy: 79.6%
* error: 20.4%
* macro_f1: 79.2%

epoch [17/30] batch [20/796] time 0.353 (0.416) data 0.000 (0.039) loss 1.0801 (1.6460) lr 4.4774e-03 eta 1:17:04
epoch [17/30] batch [40/796] time 0.359 (0.400) data 0.000 (0.020) loss 2.9121 (1.6505) lr 4.4774e-03 eta 1:14:01
epoch [17/30] batch [60/796] time 0.367 (0.394) data 0.000 (0.013) loss 1.1260 (1.5486) lr 4.4774e-03 eta 1:12:42
epoch [17/30] batch [80/796] time 0.368 (0.392) data 0.000 (0.010) loss 1.1250 (1.5062) lr 4.4774e-03 eta 1:12:14
epoch [17/30] batch [100/796] time 0.366 (0.390) data 0.000 (0.008) loss 6.3008 (1.6159) lr 4.4774e-03 eta 1:11:50
epoch [17/30] batch [120/796] time 0.418 (0.388) data 0.000 (0.007) loss 1.6064 (1.6516) lr 4.4774e-03 eta 1:11:16
epoch [17/30] batch [140/796] time 0.377 (0.386) data 0.000 (0.006) loss 0.2595 (1.6192) lr 4.4774e-03 eta 1:10:49
epoch [17/30] batch [160/796] time 0.380 (0.385) data 0.000 (0.005) loss 1.6191 (1.6388) lr 4.4774e-03 eta 1:10:28
epoch [17/30] batch [180/796] time 0.402 (0.385) data 0.000 (0.005) loss 1.0830 (1.6192) lr 4.4774e-03 eta 1:10:16
epoch [17/30] batch [200/796] time 0.387 (0.385) data 0.000 (0.004) loss 1.0605 (1.6136) lr 4.4774e-03 eta 1:10:13
epoch [17/30] batch [220/796] time 0.404 (0.385) data 0.000 (0.004) loss 0.4006 (1.5910) lr 4.4774e-03 eta 1:10:02
epoch [17/30] batch [240/796] time 0.408 (0.385) data 0.000 (0.003) loss 0.2717 (1.5915) lr 4.4774e-03 eta 1:09:54
epoch [17/30] batch [260/796] time 0.369 (0.384) data 0.000 (0.003) loss 2.5332 (1.5966) lr 4.4774e-03 eta 1:09:39
epoch [17/30] batch [280/796] time 0.391 (0.384) data 0.000 (0.003) loss 1.1719 (1.6121) lr 4.4774e-03 eta 1:09:35
epoch [17/30] batch [300/796] time 0.396 (0.384) data 0.000 (0.003) loss 0.2615 (1.6028) lr 4.4774e-03 eta 1:09:29
epoch [17/30] batch [320/796] time 0.379 (0.384) data 0.000 (0.003) loss 0.1602 (1.6114) lr 4.4774e-03 eta 1:09:21
epoch [17/30] batch [340/796] time 0.358 (0.384) data 0.000 (0.003) loss 2.6602 (1.5874) lr 4.4774e-03 eta 1:09:12
epoch [17/30] batch [360/796] time 0.347 (0.384) data 0.000 (0.002) loss 4.7422 (1.6081) lr 4.4774e-03 eta 1:08:59
epoch [17/30] batch [380/796] time 0.389 (0.383) data 0.000 (0.002) loss 0.1746 (1.6317) lr 4.4774e-03 eta 1:08:47
epoch [17/30] batch [400/796] time 0.400 (0.383) data 0.000 (0.002) loss 0.4009 (1.6227) lr 4.4774e-03 eta 1:08:39
epoch [17/30] batch [420/796] time 0.404 (0.383) data 0.000 (0.002) loss 1.2676 (1.5984) lr 4.4774e-03 eta 1:08:32
epoch [17/30] batch [440/796] time 0.417 (0.383) data 0.000 (0.002) loss 1.9580 (1.5941) lr 4.4774e-03 eta 1:08:21
epoch [17/30] batch [460/796] time 0.387 (0.383) data 0.000 (0.002) loss 0.2028 (1.5717) lr 4.4774e-03 eta 1:08:15
epoch [17/30] batch [480/796] time 0.387 (0.383) data 0.000 (0.002) loss 2.0195 (1.5703) lr 4.4774e-03 eta 1:08:03
epoch [17/30] batch [500/796] time 0.355 (0.383) data 0.000 (0.002) loss 6.4805 (1.5682) lr 4.4774e-03 eta 1:07:53
epoch [17/30] batch [520/796] time 0.361 (0.383) data 0.000 (0.002) loss 1.7549 (1.5698) lr 4.4774e-03 eta 1:07:45
epoch [17/30] batch [540/796] time 0.362 (0.383) data 0.000 (0.002) loss 0.1503 (1.5629) lr 4.4774e-03 eta 1:07:37
epoch [17/30] batch [560/796] time 0.396 (0.383) data 0.000 (0.002) loss 0.2881 (1.5519) lr 4.4774e-03 eta 1:07:31
epoch [17/30] batch [580/796] time 0.383 (0.383) data 0.000 (0.002) loss 0.8022 (1.5556) lr 4.4774e-03 eta 1:07:21
epoch [17/30] batch [600/796] time 0.378 (0.382) data 0.000 (0.002) loss 1.8711 (1.5542) lr 4.4774e-03 eta 1:07:11
epoch [17/30] batch [620/796] time 0.365 (0.383) data 0.000 (0.002) loss 0.0731 (1.5565) lr 4.4774e-03 eta 1:07:06
epoch [17/30] batch [640/796] time 0.405 (0.383) data 0.000 (0.001) loss 1.6709 (1.5548) lr 4.4774e-03 eta 1:06:59
epoch [17/30] batch [660/796] time 0.398 (0.383) data 0.000 (0.001) loss 1.5352 (1.5549) lr 4.4774e-03 eta 1:06:52
epoch [17/30] batch [680/796] time 0.386 (0.383) data 0.000 (0.001) loss 0.8105 (1.5503) lr 4.4774e-03 eta 1:06:43
epoch [17/30] batch [700/796] time 0.413 (0.382) data 0.000 (0.001) loss 1.0176 (1.5519) lr 4.4774e-03 eta 1:06:34
epoch [17/30] batch [720/796] time 0.391 (0.382) data 0.000 (0.001) loss 0.5840 (1.5593) lr 4.4774e-03 eta 1:06:24
epoch [17/30] batch [740/796] time 0.377 (0.382) data 0.000 (0.001) loss 0.2100 (1.5534) lr 4.4774e-03 eta 1:06:15
epoch [17/30] batch [760/796] time 0.395 (0.382) data 0.000 (0.001) loss 0.2355 (1.5463) lr 4.4774e-03 eta 1:06:08
epoch [17/30] batch [780/796] time 0.342 (0.381) data 0.000 (0.001) loss 1.5234 (1.5521) lr 4.4774e-03 eta 1:05:52
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:47,  5.65s/it] 10%|█         | 2/20 [00:06<00:51,  2.88s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.70s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.22it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.52it/s] 50%|█████     | 10/20 [00:08<00:03,  2.75it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.90it/s] 60%|██████    | 12/20 [00:09<00:02,  3.20it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.41it/s] 70%|███████   | 14/20 [00:09<00:01,  3.59it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.88it/s] 80%|████████  | 16/20 [00:10<00:00,  4.09it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.32it/s] 90%|█████████ | 18/20 [00:11<00:00,  3.15it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.61it/s]100%|██████████| 20/20 [00:11<00:00,  4.08it/s]100%|██████████| 20/20 [00:11<00:00,  1.73it/s]=> result
* total: 1,990
* correct: 1,591
* accuracy: 79.9%
* error: 20.1%
* macro_f1: 79.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [18/30] batch [20/796] time 0.414 (0.427) data 0.000 (0.045) loss 1.6387 (1.2257) lr 3.9604e-03 eta 1:13:29
epoch [18/30] batch [40/796] time 0.376 (0.403) data 0.000 (0.023) loss 3.2305 (1.3325) lr 3.9604e-03 eta 1:09:19
epoch [18/30] batch [60/796] time 0.408 (0.393) data 0.000 (0.015) loss 1.6807 (1.2938) lr 3.9604e-03 eta 1:07:28
epoch [18/30] batch [80/796] time 0.398 (0.392) data 0.000 (0.011) loss 1.6758 (1.2228) lr 3.9604e-03 eta 1:07:04
epoch [18/30] batch [100/796] time 0.364 (0.389) data 0.000 (0.009) loss 2.4316 (1.2067) lr 3.9604e-03 eta 1:06:28
epoch [18/30] batch [120/796] time 0.398 (0.387) data 0.000 (0.008) loss 5.0898 (1.2759) lr 3.9604e-03 eta 1:06:00
epoch [18/30] batch [140/796] time 0.386 (0.386) data 0.000 (0.007) loss 0.6074 (1.2996) lr 3.9604e-03 eta 1:05:44
epoch [18/30] batch [160/796] time 0.406 (0.386) data 0.000 (0.006) loss 0.9619 (1.3114) lr 3.9604e-03 eta 1:05:31
epoch [18/30] batch [180/796] time 0.374 (0.386) data 0.000 (0.005) loss 3.9707 (1.3647) lr 3.9604e-03 eta 1:05:25
epoch [18/30] batch [200/796] time 0.391 (0.386) data 0.000 (0.005) loss 0.6089 (1.3721) lr 3.9604e-03 eta 1:05:19
epoch [18/30] batch [220/796] time 0.392 (0.385) data 0.000 (0.004) loss 0.4541 (1.3562) lr 3.9604e-03 eta 1:05:03
epoch [18/30] batch [240/796] time 0.400 (0.384) data 0.000 (0.004) loss 2.1602 (1.3783) lr 3.9604e-03 eta 1:04:45
epoch [18/30] batch [260/796] time 0.363 (0.385) data 0.000 (0.004) loss 0.6040 (1.3507) lr 3.9604e-03 eta 1:04:40
epoch [18/30] batch [280/796] time 0.357 (0.384) data 0.000 (0.003) loss 0.5469 (1.3703) lr 3.9604e-03 eta 1:04:28
epoch [18/30] batch [300/796] time 0.378 (0.384) data 0.000 (0.003) loss 2.7227 (1.3874) lr 3.9604e-03 eta 1:04:18
epoch [18/30] batch [320/796] time 0.350 (0.384) data 0.000 (0.003) loss 3.9414 (1.4032) lr 3.9604e-03 eta 1:04:10
epoch [18/30] batch [340/796] time 0.360 (0.384) data 0.000 (0.003) loss 0.5918 (1.4005) lr 3.9604e-03 eta 1:04:01
epoch [18/30] batch [360/796] time 0.390 (0.384) data 0.000 (0.003) loss 3.1992 (1.3931) lr 3.9604e-03 eta 1:03:55
epoch [18/30] batch [380/796] time 0.393 (0.384) data 0.000 (0.003) loss 0.7559 (1.4128) lr 3.9604e-03 eta 1:03:46
epoch [18/30] batch [400/796] time 0.389 (0.383) data 0.000 (0.002) loss 1.9033 (1.4197) lr 3.9604e-03 eta 1:03:33
epoch [18/30] batch [420/796] time 0.395 (0.383) data 0.000 (0.002) loss 1.0332 (1.4329) lr 3.9604e-03 eta 1:03:26
epoch [18/30] batch [440/796] time 0.403 (0.383) data 0.000 (0.002) loss 1.9717 (1.4326) lr 3.9604e-03 eta 1:03:18
epoch [18/30] batch [460/796] time 0.396 (0.383) data 0.000 (0.002) loss 3.7656 (1.4449) lr 3.9604e-03 eta 1:03:09
epoch [18/30] batch [480/796] time 0.395 (0.383) data 0.000 (0.002) loss 2.8340 (1.4423) lr 3.9604e-03 eta 1:02:57
epoch [18/30] batch [500/796] time 0.359 (0.383) data 0.000 (0.002) loss 1.5879 (1.4382) lr 3.9604e-03 eta 1:02:49
epoch [18/30] batch [520/796] time 0.401 (0.383) data 0.000 (0.002) loss 0.7363 (1.4508) lr 3.9604e-03 eta 1:02:40
epoch [18/30] batch [540/796] time 0.385 (0.383) data 0.000 (0.002) loss 2.3906 (1.4660) lr 3.9604e-03 eta 1:02:32
epoch [18/30] batch [560/796] time 0.348 (0.382) data 0.000 (0.002) loss 0.4319 (1.4623) lr 3.9604e-03 eta 1:02:21
epoch [18/30] batch [580/796] time 0.376 (0.382) data 0.000 (0.002) loss 0.4409 (1.4631) lr 3.9604e-03 eta 1:02:13
epoch [18/30] batch [600/796] time 0.379 (0.382) data 0.000 (0.002) loss 1.6367 (1.4649) lr 3.9604e-03 eta 1:02:06
epoch [18/30] batch [620/796] time 0.360 (0.382) data 0.000 (0.002) loss 2.6836 (1.4782) lr 3.9604e-03 eta 1:01:59
epoch [18/30] batch [640/796] time 0.385 (0.382) data 0.000 (0.002) loss 0.9526 (1.4838) lr 3.9604e-03 eta 1:01:50
epoch [18/30] batch [660/796] time 0.370 (0.382) data 0.000 (0.002) loss 0.2190 (1.4792) lr 3.9604e-03 eta 1:01:42
epoch [18/30] batch [680/796] time 0.387 (0.382) data 0.000 (0.002) loss 2.7422 (1.4851) lr 3.9604e-03 eta 1:01:35
epoch [18/30] batch [700/796] time 0.381 (0.382) data 0.000 (0.002) loss 1.9795 (1.4758) lr 3.9604e-03 eta 1:01:27
epoch [18/30] batch [720/796] time 0.371 (0.382) data 0.000 (0.001) loss 0.0236 (1.4794) lr 3.9604e-03 eta 1:01:20
epoch [18/30] batch [740/796] time 0.348 (0.382) data 0.000 (0.001) loss 0.2231 (1.4831) lr 3.9604e-03 eta 1:01:11
epoch [18/30] batch [760/796] time 0.370 (0.382) data 0.000 (0.001) loss 0.8208 (1.4778) lr 3.9604e-03 eta 1:01:05
epoch [18/30] batch [780/796] time 0.347 (0.382) data 0.000 (0.001) loss 2.5566 (1.4762) lr 3.9604e-03 eta 1:00:50
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.55s/it] 10%|█         | 2/20 [00:06<00:52,  2.90s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.71s/it] 20%|██        | 4/20 [00:07<00:18,  1.15s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.19it/s] 30%|███       | 6/20 [00:07<00:09,  1.53it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.46it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.09it/s] 60%|██████    | 12/20 [00:09<00:02,  3.38it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.54it/s] 70%|███████   | 14/20 [00:09<00:01,  3.61it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.88it/s] 80%|████████  | 16/20 [00:10<00:00,  4.10it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.03it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.72it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.12it/s]100%|██████████| 20/20 [00:11<00:00,  4.51it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,596
* accuracy: 80.2%
* error: 19.8%
* macro_f1: 79.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [19/30] batch [20/796] time 0.355 (0.433) data 0.000 (0.034) loss 1.1387 (1.1582) lr 3.4549e-03 eta 1:08:43
epoch [19/30] batch [40/796] time 0.369 (0.403) data 0.000 (0.017) loss 1.3213 (1.1852) lr 3.4549e-03 eta 1:03:57
epoch [19/30] batch [60/796] time 0.371 (0.398) data 0.000 (0.011) loss 0.1550 (1.3090) lr 3.4549e-03 eta 1:02:55
epoch [19/30] batch [80/796] time 0.392 (0.393) data 0.000 (0.009) loss 0.8613 (1.4519) lr 3.4549e-03 eta 1:02:05
epoch [19/30] batch [100/796] time 0.392 (0.391) data 0.000 (0.007) loss 0.4150 (1.4621) lr 3.4549e-03 eta 1:01:38
epoch [19/30] batch [120/796] time 0.358 (0.390) data 0.000 (0.006) loss 3.2930 (1.4674) lr 3.4549e-03 eta 1:01:23
epoch [19/30] batch [140/796] time 0.388 (0.388) data 0.000 (0.005) loss 0.7969 (1.4837) lr 3.4549e-03 eta 1:00:52
epoch [19/30] batch [160/796] time 0.388 (0.387) data 0.000 (0.004) loss 4.8281 (1.5638) lr 3.4549e-03 eta 1:00:38
epoch [19/30] batch [180/796] time 0.383 (0.387) data 0.000 (0.004) loss 0.9868 (1.5368) lr 3.4549e-03 eta 1:00:23
epoch [19/30] batch [200/796] time 0.397 (0.386) data 0.000 (0.004) loss 1.0410 (1.5509) lr 3.4549e-03 eta 1:00:10
epoch [19/30] batch [220/796] time 0.407 (0.386) data 0.000 (0.003) loss 1.2598 (1.5442) lr 3.4549e-03 eta 0:59:59
epoch [19/30] batch [240/796] time 0.393 (0.385) data 0.000 (0.003) loss 0.6636 (1.5302) lr 3.4549e-03 eta 0:59:47
epoch [19/30] batch [260/796] time 0.380 (0.385) data 0.000 (0.003) loss 1.0859 (1.5086) lr 3.4549e-03 eta 0:59:33
epoch [19/30] batch [280/796] time 0.351 (0.384) data 0.000 (0.003) loss 1.6377 (1.5330) lr 3.4549e-03 eta 0:59:18
epoch [19/30] batch [300/796] time 0.433 (0.384) data 0.000 (0.002) loss 4.4062 (1.5149) lr 3.4549e-03 eta 0:59:09
epoch [19/30] batch [320/796] time 0.355 (0.383) data 0.000 (0.002) loss 0.7598 (1.5071) lr 3.4549e-03 eta 0:59:00
epoch [19/30] batch [340/796] time 0.380 (0.383) data 0.000 (0.002) loss 7.6094 (1.5354) lr 3.4549e-03 eta 0:58:46
epoch [19/30] batch [360/796] time 0.369 (0.383) data 0.000 (0.002) loss 7.9609 (1.5513) lr 3.4549e-03 eta 0:58:37
epoch [19/30] batch [380/796] time 0.364 (0.383) data 0.000 (0.002) loss 1.4971 (1.5727) lr 3.4549e-03 eta 0:58:28
epoch [19/30] batch [400/796] time 0.399 (0.382) data 0.000 (0.002) loss 1.1348 (1.5514) lr 3.4549e-03 eta 0:58:17
epoch [19/30] batch [420/796] time 0.409 (0.382) data 0.000 (0.002) loss 1.1182 (1.5457) lr 3.4549e-03 eta 0:58:10
epoch [19/30] batch [440/796] time 0.372 (0.382) data 0.000 (0.002) loss 1.5518 (1.5587) lr 3.4549e-03 eta 0:58:00
epoch [19/30] batch [460/796] time 0.385 (0.382) data 0.000 (0.002) loss 0.1714 (1.5367) lr 3.4549e-03 eta 0:57:51
epoch [19/30] batch [480/796] time 0.409 (0.382) data 0.000 (0.002) loss 3.1777 (1.5324) lr 3.4549e-03 eta 0:57:45
epoch [19/30] batch [500/796] time 0.378 (0.382) data 0.000 (0.002) loss 2.0020 (1.5340) lr 3.4549e-03 eta 0:57:38
epoch [19/30] batch [520/796] time 0.371 (0.382) data 0.000 (0.002) loss 2.1113 (1.5422) lr 3.4549e-03 eta 0:57:28
epoch [19/30] batch [540/796] time 0.396 (0.382) data 0.000 (0.001) loss 0.2246 (1.5308) lr 3.4549e-03 eta 0:57:21
epoch [19/30] batch [560/796] time 0.383 (0.382) data 0.000 (0.001) loss 0.7490 (1.5178) lr 3.4549e-03 eta 0:57:14
epoch [19/30] batch [580/796] time 0.361 (0.382) data 0.000 (0.001) loss 0.4221 (1.5141) lr 3.4549e-03 eta 0:57:04
epoch [19/30] batch [600/796] time 0.382 (0.382) data 0.000 (0.001) loss 1.9697 (1.5062) lr 3.4549e-03 eta 0:56:56
epoch [19/30] batch [620/796] time 0.400 (0.382) data 0.000 (0.001) loss 0.7993 (1.5110) lr 3.4549e-03 eta 0:56:49
epoch [19/30] batch [640/796] time 0.398 (0.382) data 0.000 (0.001) loss 1.1904 (1.5037) lr 3.4549e-03 eta 0:56:41
epoch [19/30] batch [660/796] time 0.369 (0.381) data 0.000 (0.001) loss 0.6328 (1.5190) lr 3.4549e-03 eta 0:56:32
epoch [19/30] batch [680/796] time 0.345 (0.381) data 0.000 (0.001) loss 2.9336 (1.5209) lr 3.4549e-03 eta 0:56:24
epoch [19/30] batch [700/796] time 0.413 (0.382) data 0.000 (0.001) loss 0.6406 (1.5142) lr 3.4549e-03 eta 0:56:17
epoch [19/30] batch [720/796] time 0.370 (0.382) data 0.000 (0.001) loss 1.9170 (1.5087) lr 3.4549e-03 eta 0:56:09
epoch [19/30] batch [740/796] time 0.388 (0.382) data 0.000 (0.001) loss 1.3516 (1.5004) lr 3.4549e-03 eta 0:56:02
epoch [19/30] batch [760/796] time 0.390 (0.382) data 0.000 (0.001) loss 0.2637 (1.5105) lr 3.4549e-03 eta 0:55:55
epoch [19/30] batch [780/796] time 0.346 (0.381) data 0.000 (0.001) loss 3.4512 (1.5153) lr 3.4549e-03 eta 0:55:40
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:43,  5.47s/it] 10%|█         | 2/20 [00:06<00:53,  2.98s/it] 15%|█▌        | 3/20 [00:07<00:29,  1.76s/it] 20%|██        | 4/20 [00:07<00:18,  1.18s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.50it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.83it/s] 40%|████      | 8/20 [00:08<00:05,  2.14it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.43it/s] 50%|█████     | 10/20 [00:08<00:03,  2.82it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.13it/s] 60%|██████    | 12/20 [00:09<00:02,  3.29it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.51it/s] 70%|███████   | 14/20 [00:09<00:01,  3.67it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.88it/s] 80%|████████  | 16/20 [00:10<00:01,  3.86it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.81it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.20it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.51it/s]100%|██████████| 20/20 [00:11<00:00,  4.84it/s]100%|██████████| 20/20 [00:11<00:00,  1.75it/s]=> result
* total: 1,990
* correct: 1,594
* accuracy: 80.1%
* error: 19.9%
* macro_f1: 79.6%

epoch [20/30] batch [20/796] time 0.400 (0.423) data 0.000 (0.038) loss 2.0156 (1.9318) lr 2.9663e-03 eta 1:01:31
epoch [20/30] batch [40/796] time 0.347 (0.405) data 0.000 (0.019) loss 1.4443 (1.9153) lr 2.9663e-03 eta 0:58:47
epoch [20/30] batch [60/796] time 0.397 (0.397) data 0.000 (0.013) loss 0.3679 (1.7712) lr 2.9663e-03 eta 0:57:30
epoch [20/30] batch [80/796] time 0.399 (0.392) data 0.000 (0.010) loss 1.9531 (1.6362) lr 2.9663e-03 eta 0:56:36
epoch [20/30] batch [100/796] time 0.404 (0.388) data 0.000 (0.008) loss 1.0742 (1.5589) lr 2.9663e-03 eta 0:55:56
epoch [20/30] batch [120/796] time 0.355 (0.386) data 0.000 (0.007) loss 0.0857 (1.5019) lr 2.9663e-03 eta 0:55:36
epoch [20/30] batch [140/796] time 0.376 (0.386) data 0.000 (0.006) loss 0.8794 (1.5135) lr 2.9663e-03 eta 0:55:26
epoch [20/30] batch [160/796] time 0.355 (0.385) data 0.000 (0.005) loss 1.2666 (1.4944) lr 2.9663e-03 eta 0:55:11
epoch [20/30] batch [180/796] time 0.406 (0.385) data 0.000 (0.004) loss 3.7070 (1.4982) lr 2.9663e-03 eta 0:55:02
epoch [20/30] batch [200/796] time 0.385 (0.384) data 0.000 (0.004) loss 0.9961 (1.4626) lr 2.9663e-03 eta 0:54:48
epoch [20/30] batch [220/796] time 0.350 (0.384) data 0.000 (0.004) loss 1.1172 (1.4689) lr 2.9663e-03 eta 0:54:33
epoch [20/30] batch [240/796] time 0.385 (0.383) data 0.000 (0.003) loss 2.0234 (1.4933) lr 2.9663e-03 eta 0:54:25
epoch [20/30] batch [260/796] time 0.376 (0.383) data 0.000 (0.003) loss 0.8169 (1.5113) lr 2.9663e-03 eta 0:54:12
epoch [20/30] batch [280/796] time 0.383 (0.383) data 0.000 (0.003) loss 3.4199 (1.5150) lr 2.9663e-03 eta 0:54:02
epoch [20/30] batch [300/796] time 0.369 (0.382) data 0.000 (0.003) loss 1.1953 (1.5368) lr 2.9663e-03 eta 0:53:51
epoch [20/30] batch [320/796] time 0.381 (0.382) data 0.000 (0.003) loss 0.6987 (1.5334) lr 2.9663e-03 eta 0:53:39
epoch [20/30] batch [340/796] time 0.393 (0.381) data 0.000 (0.002) loss 1.5859 (1.5119) lr 2.9663e-03 eta 0:53:27
epoch [20/30] batch [360/796] time 0.415 (0.381) data 0.000 (0.002) loss 2.0020 (1.5111) lr 2.9663e-03 eta 0:53:20
epoch [20/30] batch [380/796] time 0.374 (0.381) data 0.000 (0.002) loss 0.4907 (1.5054) lr 2.9663e-03 eta 0:53:12
epoch [20/30] batch [400/796] time 0.367 (0.381) data 0.000 (0.002) loss 0.3359 (1.5045) lr 2.9663e-03 eta 0:53:06
epoch [20/30] batch [420/796] time 0.355 (0.381) data 0.000 (0.002) loss 0.3418 (1.5024) lr 2.9663e-03 eta 0:52:56
epoch [20/30] batch [440/796] time 0.344 (0.381) data 0.000 (0.002) loss 0.7720 (1.4993) lr 2.9663e-03 eta 0:52:46
epoch [20/30] batch [460/796] time 0.402 (0.381) data 0.000 (0.002) loss 0.9414 (1.4939) lr 2.9663e-03 eta 0:52:40
epoch [20/30] batch [480/796] time 0.401 (0.381) data 0.000 (0.002) loss 0.0505 (1.5059) lr 2.9663e-03 eta 0:52:31
epoch [20/30] batch [500/796] time 0.363 (0.381) data 0.000 (0.002) loss 0.6494 (1.4933) lr 2.9663e-03 eta 0:52:22
epoch [20/30] batch [520/796] time 0.364 (0.381) data 0.000 (0.002) loss 1.7285 (1.4906) lr 2.9663e-03 eta 0:52:14
epoch [20/30] batch [540/796] time 0.403 (0.381) data 0.000 (0.002) loss 2.3828 (1.4959) lr 2.9663e-03 eta 0:52:06
epoch [20/30] batch [560/796] time 0.400 (0.381) data 0.000 (0.002) loss 0.6616 (1.4883) lr 2.9663e-03 eta 0:51:58
epoch [20/30] batch [580/796] time 0.359 (0.380) data 0.000 (0.002) loss 4.7305 (1.4815) lr 2.9663e-03 eta 0:51:49
epoch [20/30] batch [600/796] time 0.399 (0.380) data 0.000 (0.002) loss 0.4478 (1.4862) lr 2.9663e-03 eta 0:51:41
epoch [20/30] batch [620/796] time 0.408 (0.380) data 0.000 (0.001) loss 0.7075 (1.4838) lr 2.9663e-03 eta 0:51:34
epoch [20/30] batch [640/796] time 0.363 (0.380) data 0.000 (0.001) loss 0.6470 (1.4855) lr 2.9663e-03 eta 0:51:25
epoch [20/30] batch [660/796] time 0.350 (0.380) data 0.000 (0.001) loss 0.1404 (1.4719) lr 2.9663e-03 eta 0:51:17
epoch [20/30] batch [680/796] time 0.374 (0.380) data 0.000 (0.001) loss 0.0580 (1.4730) lr 2.9663e-03 eta 0:51:11
epoch [20/30] batch [700/796] time 0.379 (0.380) data 0.000 (0.001) loss 0.1118 (1.4721) lr 2.9663e-03 eta 0:51:01
epoch [20/30] batch [720/796] time 0.356 (0.380) data 0.000 (0.001) loss 2.4980 (1.4710) lr 2.9663e-03 eta 0:50:55
epoch [20/30] batch [740/796] time 0.386 (0.380) data 0.000 (0.001) loss 1.1621 (1.4735) lr 2.9663e-03 eta 0:50:50
epoch [20/30] batch [760/796] time 0.399 (0.381) data 0.000 (0.001) loss 1.6953 (1.4731) lr 2.9663e-03 eta 0:50:44
epoch [20/30] batch [780/796] time 0.347 (0.380) data 0.000 (0.001) loss 0.1951 (1.4876) lr 2.9663e-03 eta 0:50:30
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.56s/it] 10%|█         | 2/20 [00:06<00:50,  2.81s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.66s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.19it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.47it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:09<00:03,  3.00it/s] 60%|██████    | 12/20 [00:09<00:02,  3.24it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.48it/s] 70%|███████   | 14/20 [00:09<00:01,  3.56it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.73it/s] 80%|████████  | 16/20 [00:10<00:01,  3.98it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.91it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.54it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.96it/s]100%|██████████| 20/20 [00:11<00:00,  4.38it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,606
* accuracy: 80.7%
* error: 19.3%
* macro_f1: 80.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-20

epoch [21/30] batch [20/796] time 0.360 (0.428) data 0.000 (0.036) loss 3.4043 (1.2295) lr 2.5000e-03 eta 0:56:35
epoch [21/30] batch [40/796] time 0.411 (0.403) data 0.000 (0.018) loss 1.8408 (1.3081) lr 2.5000e-03 eta 0:53:13
epoch [21/30] batch [60/796] time 0.404 (0.395) data 0.000 (0.012) loss 0.9976 (1.5198) lr 2.5000e-03 eta 0:51:59
epoch [21/30] batch [80/796] time 0.377 (0.390) data 0.000 (0.009) loss 3.3203 (1.4385) lr 2.5000e-03 eta 0:51:15
epoch [21/30] batch [100/796] time 0.390 (0.388) data 0.000 (0.007) loss 2.3242 (1.4353) lr 2.5000e-03 eta 0:50:52
epoch [21/30] batch [120/796] time 0.350 (0.386) data 0.000 (0.006) loss 0.4626 (1.3802) lr 2.5000e-03 eta 0:50:23
epoch [21/30] batch [140/796] time 0.405 (0.385) data 0.000 (0.005) loss 1.7549 (1.4094) lr 2.5000e-03 eta 0:50:12
epoch [21/30] batch [160/796] time 0.386 (0.385) data 0.000 (0.005) loss 0.6562 (1.4314) lr 2.5000e-03 eta 0:50:02
epoch [21/30] batch [180/796] time 0.441 (0.384) data 0.000 (0.004) loss 2.4805 (1.4114) lr 2.5000e-03 eta 0:49:50
epoch [21/30] batch [200/796] time 0.387 (0.384) data 0.000 (0.004) loss 0.4397 (1.3914) lr 2.5000e-03 eta 0:49:42
epoch [21/30] batch [220/796] time 0.369 (0.384) data 0.000 (0.004) loss 1.0078 (1.3820) lr 2.5000e-03 eta 0:49:30
epoch [21/30] batch [240/796] time 0.362 (0.384) data 0.000 (0.003) loss 0.1960 (1.3514) lr 2.5000e-03 eta 0:49:21
epoch [21/30] batch [260/796] time 0.377 (0.384) data 0.000 (0.003) loss 6.0352 (1.4064) lr 2.5000e-03 eta 0:49:13
epoch [21/30] batch [280/796] time 0.362 (0.383) data 0.000 (0.003) loss 1.5273 (1.4304) lr 2.5000e-03 eta 0:49:02
epoch [21/30] batch [300/796] time 0.385 (0.383) data 0.000 (0.003) loss 0.1361 (1.4451) lr 2.5000e-03 eta 0:48:54
epoch [21/30] batch [320/796] time 0.370 (0.383) data 0.000 (0.002) loss 2.0527 (1.4486) lr 2.5000e-03 eta 0:48:42
epoch [21/30] batch [340/796] time 0.376 (0.382) data 0.000 (0.002) loss 1.1113 (1.4459) lr 2.5000e-03 eta 0:48:33
epoch [21/30] batch [360/796] time 0.360 (0.382) data 0.000 (0.002) loss 0.3755 (1.4305) lr 2.5000e-03 eta 0:48:26
epoch [21/30] batch [380/796] time 0.353 (0.382) data 0.000 (0.002) loss 1.1006 (1.4270) lr 2.5000e-03 eta 0:48:16
epoch [21/30] batch [400/796] time 0.378 (0.382) data 0.000 (0.002) loss 0.8691 (1.4214) lr 2.5000e-03 eta 0:48:09
epoch [21/30] batch [420/796] time 0.358 (0.382) data 0.000 (0.002) loss 0.1698 (1.4213) lr 2.5000e-03 eta 0:47:59
epoch [21/30] batch [440/796] time 0.356 (0.382) data 0.000 (0.002) loss 1.4160 (1.4237) lr 2.5000e-03 eta 0:47:51
epoch [21/30] batch [460/796] time 0.402 (0.382) data 0.000 (0.002) loss 2.5703 (1.4308) lr 2.5000e-03 eta 0:47:45
epoch [21/30] batch [480/796] time 0.396 (0.382) data 0.000 (0.002) loss 0.3010 (1.4262) lr 2.5000e-03 eta 0:47:37
epoch [21/30] batch [500/796] time 0.369 (0.382) data 0.000 (0.002) loss 0.0275 (1.4441) lr 2.5000e-03 eta 0:47:27
epoch [21/30] batch [520/796] time 0.365 (0.382) data 0.000 (0.002) loss 0.9058 (1.4507) lr 2.5000e-03 eta 0:47:21
epoch [21/30] batch [540/796] time 0.368 (0.382) data 0.000 (0.002) loss 2.0684 (1.4490) lr 2.5000e-03 eta 0:47:13
epoch [21/30] batch [560/796] time 0.386 (0.382) data 0.000 (0.002) loss 0.3892 (1.4548) lr 2.5000e-03 eta 0:47:06
epoch [21/30] batch [580/796] time 0.394 (0.382) data 0.000 (0.001) loss 0.9717 (1.4595) lr 2.5000e-03 eta 0:46:57
epoch [21/30] batch [600/796] time 0.405 (0.382) data 0.000 (0.001) loss 2.7129 (1.4630) lr 2.5000e-03 eta 0:46:50
epoch [21/30] batch [620/796] time 0.377 (0.382) data 0.000 (0.001) loss 1.1240 (1.4696) lr 2.5000e-03 eta 0:46:43
epoch [21/30] batch [640/796] time 0.401 (0.382) data 0.000 (0.001) loss 0.1409 (1.4630) lr 2.5000e-03 eta 0:46:36
epoch [21/30] batch [660/796] time 0.358 (0.382) data 0.000 (0.001) loss 3.2012 (1.4602) lr 2.5000e-03 eta 0:46:28
epoch [21/30] batch [680/796] time 0.385 (0.382) data 0.000 (0.001) loss 3.3691 (1.4767) lr 2.5000e-03 eta 0:46:18
epoch [21/30] batch [700/796] time 0.405 (0.382) data 0.000 (0.001) loss 2.1387 (1.4896) lr 2.5000e-03 eta 0:46:10
epoch [21/30] batch [720/796] time 0.371 (0.381) data 0.000 (0.001) loss 0.2018 (1.4850) lr 2.5000e-03 eta 0:46:01
epoch [21/30] batch [740/796] time 0.366 (0.381) data 0.000 (0.001) loss 0.3787 (1.4795) lr 2.5000e-03 eta 0:45:54
epoch [21/30] batch [760/796] time 0.376 (0.381) data 0.000 (0.001) loss 0.8057 (1.4705) lr 2.5000e-03 eta 0:45:46
epoch [21/30] batch [780/796] time 0.343 (0.381) data 0.000 (0.001) loss 3.0938 (1.4737) lr 2.5000e-03 eta 0:45:32
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:42,  5.40s/it] 10%|█         | 2/20 [00:06<00:52,  2.92s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.73s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.50it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.85it/s] 40%|████      | 8/20 [00:08<00:05,  2.18it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.78it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.17it/s] 60%|██████    | 12/20 [00:09<00:02,  3.37it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.48it/s] 70%|███████   | 14/20 [00:09<00:01,  3.55it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.75it/s] 80%|████████  | 16/20 [00:10<00:01,  3.82it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.87it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.20it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.52it/s]100%|██████████| 20/20 [00:11<00:00,  4.83it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,604
* accuracy: 80.6%
* error: 19.4%
* macro_f1: 80.3%

epoch [22/30] batch [20/796] time 0.402 (0.427) data 0.000 (0.041) loss 1.2910 (1.6096) lr 2.0611e-03 eta 0:50:48
epoch [22/30] batch [40/796] time 0.373 (0.406) data 0.000 (0.021) loss 0.0390 (1.3787) lr 2.0611e-03 eta 0:48:13
epoch [22/30] batch [60/796] time 0.367 (0.399) data 0.000 (0.014) loss 0.6138 (1.3808) lr 2.0611e-03 eta 0:47:15
epoch [22/30] batch [80/796] time 0.394 (0.394) data 0.000 (0.011) loss 0.5913 (1.3675) lr 2.0611e-03 eta 0:46:33
epoch [22/30] batch [100/796] time 0.368 (0.391) data 0.000 (0.008) loss 8.1562 (1.4093) lr 2.0611e-03 eta 0:46:04
epoch [22/30] batch [120/796] time 0.373 (0.390) data 0.000 (0.007) loss 0.9468 (1.4357) lr 2.0611e-03 eta 0:45:46
epoch [22/30] batch [140/796] time 0.348 (0.388) data 0.000 (0.006) loss 3.3691 (1.3911) lr 2.0611e-03 eta 0:45:27
epoch [22/30] batch [160/796] time 0.371 (0.388) data 0.000 (0.005) loss 5.2891 (1.4325) lr 2.0611e-03 eta 0:45:18
epoch [22/30] batch [180/796] time 0.357 (0.387) data 0.000 (0.005) loss 0.4512 (1.4799) lr 2.0611e-03 eta 0:44:59
epoch [22/30] batch [200/796] time 0.388 (0.386) data 0.000 (0.004) loss 6.0742 (1.4794) lr 2.0611e-03 eta 0:44:49
epoch [22/30] batch [220/796] time 0.373 (0.385) data 0.000 (0.004) loss 1.3496 (1.5193) lr 2.0611e-03 eta 0:44:35
epoch [22/30] batch [240/796] time 0.386 (0.385) data 0.000 (0.004) loss 3.5059 (1.5563) lr 2.0611e-03 eta 0:44:23
epoch [22/30] batch [260/796] time 0.398 (0.385) data 0.000 (0.003) loss 2.8613 (1.5427) lr 2.0611e-03 eta 0:44:15
epoch [22/30] batch [280/796] time 0.365 (0.385) data 0.000 (0.003) loss 0.3208 (1.5156) lr 2.0611e-03 eta 0:44:07
epoch [22/30] batch [300/796] time 0.389 (0.385) data 0.000 (0.003) loss 0.8203 (1.5060) lr 2.0611e-03 eta 0:44:02
epoch [22/30] batch [320/796] time 0.361 (0.385) data 0.000 (0.003) loss 4.7734 (1.5255) lr 2.0611e-03 eta 0:43:54
epoch [22/30] batch [340/796] time 0.392 (0.385) data 0.000 (0.003) loss 3.2871 (1.4927) lr 2.0611e-03 eta 0:43:44
epoch [22/30] batch [360/796] time 0.354 (0.384) data 0.000 (0.003) loss 0.3601 (1.4689) lr 2.0611e-03 eta 0:43:34
epoch [22/30] batch [380/796] time 0.369 (0.384) data 0.000 (0.002) loss 1.4209 (1.4513) lr 2.0611e-03 eta 0:43:23
epoch [22/30] batch [400/796] time 0.348 (0.383) data 0.000 (0.002) loss 0.9971 (1.4491) lr 2.0611e-03 eta 0:43:12
epoch [22/30] batch [420/796] time 0.402 (0.383) data 0.000 (0.002) loss 1.6348 (1.4562) lr 2.0611e-03 eta 0:43:04
epoch [22/30] batch [440/796] time 0.388 (0.383) data 0.000 (0.002) loss 2.6133 (1.4455) lr 2.0611e-03 eta 0:42:52
epoch [22/30] batch [460/796] time 0.369 (0.382) data 0.000 (0.002) loss 5.2773 (1.4408) lr 2.0611e-03 eta 0:42:41
epoch [22/30] batch [480/796] time 0.408 (0.382) data 0.000 (0.002) loss 1.4375 (1.4472) lr 2.0611e-03 eta 0:42:33
epoch [22/30] batch [500/796] time 0.385 (0.382) data 0.000 (0.002) loss 1.4189 (1.4574) lr 2.0611e-03 eta 0:42:26
epoch [22/30] batch [520/796] time 0.412 (0.382) data 0.000 (0.002) loss 0.9272 (1.4360) lr 2.0611e-03 eta 0:42:18
epoch [22/30] batch [540/796] time 0.383 (0.382) data 0.000 (0.002) loss 0.5942 (1.4326) lr 2.0611e-03 eta 0:42:08
epoch [22/30] batch [560/796] time 0.364 (0.382) data 0.000 (0.002) loss 3.2246 (1.4251) lr 2.0611e-03 eta 0:42:00
epoch [22/30] batch [580/796] time 0.367 (0.382) data 0.000 (0.002) loss 2.2969 (1.4170) lr 2.0611e-03 eta 0:41:52
epoch [22/30] batch [600/796] time 0.379 (0.382) data 0.000 (0.002) loss 3.3770 (1.4189) lr 2.0611e-03 eta 0:41:44
epoch [22/30] batch [620/796] time 0.411 (0.381) data 0.000 (0.002) loss 1.8086 (1.4152) lr 2.0611e-03 eta 0:41:35
epoch [22/30] batch [640/796] time 0.386 (0.381) data 0.000 (0.002) loss 0.3818 (1.4170) lr 2.0611e-03 eta 0:41:27
epoch [22/30] batch [660/796] time 0.395 (0.381) data 0.000 (0.001) loss 2.5977 (1.4289) lr 2.0611e-03 eta 0:41:20
epoch [22/30] batch [680/796] time 0.381 (0.382) data 0.000 (0.001) loss 0.4209 (1.4260) lr 2.0611e-03 eta 0:41:13
epoch [22/30] batch [700/796] time 0.392 (0.381) data 0.000 (0.001) loss 0.6084 (1.4256) lr 2.0611e-03 eta 0:41:04
epoch [22/30] batch [720/796] time 0.401 (0.381) data 0.000 (0.001) loss 0.7671 (1.4200) lr 2.0611e-03 eta 0:40:56
epoch [22/30] batch [740/796] time 0.355 (0.381) data 0.000 (0.001) loss 0.7881 (1.4293) lr 2.0611e-03 eta 0:40:49
epoch [22/30] batch [760/796] time 0.355 (0.381) data 0.000 (0.001) loss 2.4141 (1.4288) lr 2.0611e-03 eta 0:40:42
epoch [22/30] batch [780/796] time 0.343 (0.381) data 0.000 (0.001) loss 2.2344 (1.4359) lr 2.0611e-03 eta 0:40:29
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.53s/it] 10%|█         | 2/20 [00:06<00:53,  2.97s/it] 15%|█▌        | 3/20 [00:07<00:29,  1.75s/it] 20%|██        | 4/20 [00:07<00:18,  1.18s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.17it/s] 30%|███       | 6/20 [00:07<00:09,  1.51it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.83it/s] 40%|████      | 8/20 [00:08<00:05,  2.15it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.41it/s] 50%|█████     | 10/20 [00:09<00:03,  2.68it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.00it/s] 60%|██████    | 12/20 [00:09<00:02,  3.26it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.40it/s] 70%|███████   | 14/20 [00:10<00:01,  3.53it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.63it/s] 80%|████████  | 16/20 [00:10<00:01,  3.69it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.84it/s] 90%|█████████ | 18/20 [00:11<00:00,  4.21it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.52it/s]100%|██████████| 20/20 [00:11<00:00,  4.82it/s]100%|██████████| 20/20 [00:11<00:00,  1.74it/s]=> result
* total: 1,990
* correct: 1,613
* accuracy: 81.1%
* error: 18.9%
* macro_f1: 80.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [23/30] batch [20/796] time 0.358 (0.431) data 0.000 (0.036) loss 3.8770 (1.7620) lr 1.6543e-03 eta 0:45:35
epoch [23/30] batch [40/796] time 0.352 (0.406) data 0.000 (0.018) loss 1.0049 (1.5343) lr 1.6543e-03 eta 0:42:51
epoch [23/30] batch [60/796] time 0.368 (0.398) data 0.000 (0.012) loss 0.2085 (1.4243) lr 1.6543e-03 eta 0:41:53
epoch [23/30] batch [80/796] time 0.371 (0.391) data 0.000 (0.009) loss 1.5527 (1.3854) lr 1.6543e-03 eta 0:41:00
epoch [23/30] batch [100/796] time 0.355 (0.389) data 0.000 (0.007) loss 2.7148 (1.3850) lr 1.6543e-03 eta 0:40:40
epoch [23/30] batch [120/796] time 0.373 (0.388) data 0.000 (0.006) loss 0.7593 (1.3933) lr 1.6543e-03 eta 0:40:21
epoch [23/30] batch [140/796] time 0.370 (0.386) data 0.000 (0.005) loss 0.5469 (1.3683) lr 1.6543e-03 eta 0:40:06
epoch [23/30] batch [160/796] time 0.373 (0.386) data 0.000 (0.005) loss 0.5635 (1.3628) lr 1.6543e-03 eta 0:39:58
epoch [23/30] batch [180/796] time 0.383 (0.385) data 0.000 (0.004) loss 0.5791 (1.3590) lr 1.6543e-03 eta 0:39:40
epoch [23/30] batch [200/796] time 0.410 (0.384) data 0.000 (0.004) loss 0.5537 (1.3516) lr 1.6543e-03 eta 0:39:30
epoch [23/30] batch [220/796] time 0.354 (0.384) data 0.000 (0.004) loss 0.2332 (1.3488) lr 1.6543e-03 eta 0:39:22
epoch [23/30] batch [240/796] time 0.383 (0.385) data 0.000 (0.003) loss 1.8516 (1.3513) lr 1.6543e-03 eta 0:39:16
epoch [23/30] batch [260/796] time 0.376 (0.384) data 0.000 (0.003) loss 3.7754 (1.3387) lr 1.6543e-03 eta 0:39:03
epoch [23/30] batch [280/796] time 0.354 (0.384) data 0.000 (0.003) loss 2.4922 (1.3170) lr 1.6543e-03 eta 0:38:55
epoch [23/30] batch [300/796] time 0.353 (0.383) data 0.000 (0.003) loss 0.6753 (1.2853) lr 1.6543e-03 eta 0:38:43
epoch [23/30] batch [320/796] time 0.355 (0.383) data 0.000 (0.003) loss 0.2727 (1.3097) lr 1.6543e-03 eta 0:38:34
epoch [23/30] batch [340/796] time 0.399 (0.383) data 0.000 (0.002) loss 0.2180 (1.2949) lr 1.6543e-03 eta 0:38:25
epoch [23/30] batch [360/796] time 0.364 (0.382) data 0.000 (0.002) loss 0.5884 (1.3189) lr 1.6543e-03 eta 0:38:17
epoch [23/30] batch [380/796] time 0.360 (0.382) data 0.000 (0.002) loss 1.9150 (1.3695) lr 1.6543e-03 eta 0:38:09
epoch [23/30] batch [400/796] time 0.356 (0.382) data 0.000 (0.002) loss 1.3779 (1.3639) lr 1.6543e-03 eta 0:38:01
epoch [23/30] batch [420/796] time 0.364 (0.382) data 0.000 (0.002) loss 1.4150 (1.3702) lr 1.6543e-03 eta 0:37:52
epoch [23/30] batch [440/796] time 0.388 (0.382) data 0.000 (0.002) loss 1.2217 (1.3835) lr 1.6543e-03 eta 0:37:44
epoch [23/30] batch [460/796] time 0.387 (0.382) data 0.000 (0.002) loss 0.3652 (1.3736) lr 1.6543e-03 eta 0:37:37
epoch [23/30] batch [480/796] time 0.394 (0.382) data 0.000 (0.002) loss 4.8516 (1.3703) lr 1.6543e-03 eta 0:37:29
epoch [23/30] batch [500/796] time 0.367 (0.382) data 0.000 (0.002) loss 0.7554 (1.3736) lr 1.6543e-03 eta 0:37:21
epoch [23/30] batch [520/796] time 0.446 (0.382) data 0.000 (0.002) loss 0.4380 (1.3682) lr 1.6543e-03 eta 0:37:11
epoch [23/30] batch [540/796] time 0.404 (0.381) data 0.000 (0.002) loss 1.1035 (1.3757) lr 1.6543e-03 eta 0:37:02
epoch [23/30] batch [560/796] time 0.352 (0.381) data 0.000 (0.002) loss 1.1328 (1.3750) lr 1.6543e-03 eta 0:36:53
epoch [23/30] batch [580/796] time 0.360 (0.381) data 0.000 (0.002) loss 1.8203 (1.3686) lr 1.6543e-03 eta 0:36:46
epoch [23/30] batch [600/796] time 0.411 (0.381) data 0.000 (0.001) loss 0.8013 (1.3890) lr 1.6543e-03 eta 0:36:38
epoch [23/30] batch [620/796] time 0.392 (0.381) data 0.000 (0.001) loss 2.4414 (1.3961) lr 1.6543e-03 eta 0:36:30
epoch [23/30] batch [640/796] time 0.367 (0.381) data 0.000 (0.001) loss 1.1221 (1.4037) lr 1.6543e-03 eta 0:36:23
epoch [23/30] batch [660/796] time 0.395 (0.381) data 0.000 (0.001) loss 0.9214 (1.4035) lr 1.6543e-03 eta 0:36:15
epoch [23/30] batch [680/796] time 0.350 (0.381) data 0.000 (0.001) loss 1.1797 (1.4203) lr 1.6543e-03 eta 0:36:07
epoch [23/30] batch [700/796] time 0.363 (0.381) data 0.000 (0.001) loss 1.0469 (1.4174) lr 1.6543e-03 eta 0:36:00
epoch [23/30] batch [720/796] time 0.385 (0.381) data 0.000 (0.001) loss 0.5156 (1.4157) lr 1.6543e-03 eta 0:35:52
epoch [23/30] batch [740/796] time 0.352 (0.381) data 0.000 (0.001) loss 0.6582 (1.4083) lr 1.6543e-03 eta 0:35:45
epoch [23/30] batch [760/796] time 0.368 (0.381) data 0.000 (0.001) loss 1.8584 (1.4161) lr 1.6543e-03 eta 0:35:37
epoch [23/30] batch [780/796] time 0.346 (0.380) data 0.000 (0.001) loss 0.2588 (1.4095) lr 1.6543e-03 eta 0:35:25
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:49,  5.75s/it] 10%|█         | 2/20 [00:06<00:48,  2.71s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.61s/it] 20%|██        | 4/20 [00:06<00:17,  1.09s/it] 25%|██▌       | 5/20 [00:07<00:11,  1.25it/s] 30%|███       | 6/20 [00:07<00:08,  1.59it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.92it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.52it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.86it/s] 60%|██████    | 12/20 [00:09<00:02,  3.07it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.24it/s] 70%|███████   | 14/20 [00:09<00:01,  3.39it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.66it/s] 80%|████████  | 16/20 [00:10<00:01,  3.89it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.04it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.23it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.54it/s]100%|██████████| 20/20 [00:11<00:00,  4.86it/s]100%|██████████| 20/20 [00:11<00:00,  1.79it/s]=> result
* total: 1,990
* correct: 1,601
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 80.0%

epoch [24/30] batch [20/796] time 0.360 (0.422) data 0.000 (0.033) loss 0.4861 (1.0573) lr 1.2843e-03 eta 0:39:01
epoch [24/30] batch [40/796] time 0.369 (0.398) data 0.000 (0.017) loss 0.7466 (1.4068) lr 1.2843e-03 eta 0:36:41
epoch [24/30] batch [60/796] time 0.356 (0.391) data 0.000 (0.011) loss 2.0645 (1.4111) lr 1.2843e-03 eta 0:35:57
epoch [24/30] batch [80/796] time 0.388 (0.388) data 0.000 (0.009) loss 0.1479 (1.4883) lr 1.2843e-03 eta 0:35:33
epoch [24/30] batch [100/796] time 0.360 (0.387) data 0.000 (0.007) loss 0.2744 (1.4276) lr 1.2843e-03 eta 0:35:18
epoch [24/30] batch [120/796] time 0.361 (0.386) data 0.000 (0.006) loss 2.5820 (1.4764) lr 1.2843e-03 eta 0:35:04
epoch [24/30] batch [140/796] time 0.400 (0.386) data 0.000 (0.005) loss 1.1738 (1.4587) lr 1.2843e-03 eta 0:34:56
epoch [24/30] batch [160/796] time 0.363 (0.385) data 0.000 (0.004) loss 0.5767 (1.3953) lr 1.2843e-03 eta 0:34:43
epoch [24/30] batch [180/796] time 0.369 (0.384) data 0.000 (0.004) loss 1.1016 (1.3819) lr 1.2843e-03 eta 0:34:33
epoch [24/30] batch [200/796] time 0.361 (0.385) data 0.000 (0.004) loss 0.7817 (1.3785) lr 1.2843e-03 eta 0:34:25
epoch [24/30] batch [220/796] time 0.358 (0.383) data 0.000 (0.003) loss 0.0303 (1.3989) lr 1.2843e-03 eta 0:34:10
epoch [24/30] batch [240/796] time 0.366 (0.384) data 0.000 (0.003) loss 1.8633 (1.4069) lr 1.2843e-03 eta 0:34:05
epoch [24/30] batch [260/796] time 0.395 (0.384) data 0.000 (0.003) loss 5.4648 (1.4278) lr 1.2843e-03 eta 0:33:58
epoch [24/30] batch [280/796] time 0.385 (0.383) data 0.000 (0.003) loss 1.0039 (1.4305) lr 1.2843e-03 eta 0:33:48
epoch [24/30] batch [300/796] time 0.354 (0.383) data 0.000 (0.002) loss 1.2295 (1.4252) lr 1.2843e-03 eta 0:33:39
epoch [24/30] batch [320/796] time 0.449 (0.383) data 0.000 (0.002) loss 0.7388 (1.4065) lr 1.2843e-03 eta 0:33:30
epoch [24/30] batch [340/796] time 0.373 (0.383) data 0.000 (0.002) loss 1.5859 (1.3877) lr 1.2843e-03 eta 0:33:21
epoch [24/30] batch [360/796] time 0.367 (0.383) data 0.000 (0.002) loss 0.9268 (1.3969) lr 1.2843e-03 eta 0:33:13
epoch [24/30] batch [380/796] time 0.388 (0.382) data 0.000 (0.002) loss 0.8267 (1.3809) lr 1.2843e-03 eta 0:33:05
epoch [24/30] batch [400/796] time 0.407 (0.383) data 0.000 (0.002) loss 0.2805 (1.3900) lr 1.2843e-03 eta 0:33:00
epoch [24/30] batch [420/796] time 0.401 (0.383) data 0.000 (0.002) loss 3.3203 (1.3778) lr 1.2843e-03 eta 0:32:51
epoch [24/30] batch [440/796] time 0.361 (0.382) data 0.000 (0.002) loss 0.5898 (1.3716) lr 1.2843e-03 eta 0:32:42
epoch [24/30] batch [460/796] time 0.408 (0.383) data 0.000 (0.002) loss 0.1776 (1.3805) lr 1.2843e-03 eta 0:32:35
epoch [24/30] batch [480/796] time 0.391 (0.382) data 0.000 (0.002) loss 0.2246 (1.3726) lr 1.2843e-03 eta 0:32:26
epoch [24/30] batch [500/796] time 0.371 (0.382) data 0.000 (0.002) loss 1.9580 (1.3766) lr 1.2843e-03 eta 0:32:18
epoch [24/30] batch [520/796] time 0.365 (0.382) data 0.000 (0.002) loss 1.8867 (1.3830) lr 1.2843e-03 eta 0:32:11
epoch [24/30] batch [540/796] time 0.354 (0.382) data 0.000 (0.001) loss 0.4336 (1.3879) lr 1.2843e-03 eta 0:32:02
epoch [24/30] batch [560/796] time 0.359 (0.382) data 0.000 (0.001) loss 1.8926 (1.4067) lr 1.2843e-03 eta 0:31:55
epoch [24/30] batch [580/796] time 0.358 (0.382) data 0.000 (0.001) loss 1.7773 (1.3957) lr 1.2843e-03 eta 0:31:48
epoch [24/30] batch [600/796] time 0.361 (0.382) data 0.000 (0.001) loss 1.0508 (1.4196) lr 1.2843e-03 eta 0:31:39
epoch [24/30] batch [620/796] time 0.364 (0.382) data 0.000 (0.001) loss 0.0348 (1.4222) lr 1.2843e-03 eta 0:31:31
epoch [24/30] batch [640/796] time 0.383 (0.382) data 0.000 (0.001) loss 1.7051 (1.4286) lr 1.2843e-03 eta 0:31:23
epoch [24/30] batch [660/796] time 0.383 (0.382) data 0.000 (0.001) loss 1.1289 (1.4275) lr 1.2843e-03 eta 0:31:15
epoch [24/30] batch [680/796] time 0.349 (0.382) data 0.000 (0.001) loss 3.4648 (1.4290) lr 1.2843e-03 eta 0:31:07
epoch [24/30] batch [700/796] time 0.389 (0.382) data 0.000 (0.001) loss 1.2236 (1.4284) lr 1.2843e-03 eta 0:31:00
epoch [24/30] batch [720/796] time 0.408 (0.382) data 0.000 (0.001) loss 0.7710 (1.4258) lr 1.2843e-03 eta 0:30:51
epoch [24/30] batch [740/796] time 0.360 (0.381) data 0.000 (0.001) loss 0.8018 (1.4291) lr 1.2843e-03 eta 0:30:43
epoch [24/30] batch [760/796] time 0.368 (0.381) data 0.000 (0.001) loss 1.1396 (1.4270) lr 1.2843e-03 eta 0:30:35
epoch [24/30] batch [780/796] time 0.346 (0.381) data 0.000 (0.001) loss 0.0968 (1.4279) lr 1.2843e-03 eta 0:30:24
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.51s/it] 10%|█         | 2/20 [00:06<00:50,  2.81s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.66s/it] 20%|██        | 4/20 [00:07<00:17,  1.12s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:08,  1.56it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.91it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.50it/s] 50%|█████     | 10/20 [00:08<00:03,  2.73it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.93it/s] 60%|██████    | 12/20 [00:09<00:02,  3.24it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.60it/s] 70%|███████   | 14/20 [00:09<00:01,  3.63it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.66it/s] 80%|████████  | 16/20 [00:10<00:01,  3.94it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.03it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.55it/s] 95%|█████████▌| 19/20 [00:10<00:00,  3.97it/s]100%|██████████| 20/20 [00:11<00:00,  4.39it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,611
* accuracy: 81.0%
* error: 19.0%
* macro_f1: 80.6%

epoch [25/30] batch [20/796] time 0.408 (0.431) data 0.000 (0.038) loss 1.7783 (1.8005) lr 9.5492e-04 eta 0:34:10
epoch [25/30] batch [40/796] time 0.365 (0.403) data 0.000 (0.019) loss 0.3970 (1.6340) lr 9.5492e-04 eta 0:31:50
epoch [25/30] batch [60/796] time 0.381 (0.398) data 0.000 (0.013) loss 3.8633 (1.4704) lr 9.5492e-04 eta 0:31:15
epoch [25/30] batch [80/796] time 0.380 (0.394) data 0.000 (0.010) loss 0.0929 (1.3238) lr 9.5492e-04 eta 0:30:48
epoch [25/30] batch [100/796] time 0.382 (0.392) data 0.000 (0.008) loss 0.0610 (1.3241) lr 9.5492e-04 eta 0:30:32
epoch [25/30] batch [120/796] time 0.378 (0.390) data 0.000 (0.007) loss 0.3987 (1.4189) lr 9.5492e-04 eta 0:30:15
epoch [25/30] batch [140/796] time 0.371 (0.389) data 0.000 (0.006) loss 1.2080 (1.4730) lr 9.5492e-04 eta 0:30:02
epoch [25/30] batch [160/796] time 0.383 (0.387) data 0.000 (0.005) loss 1.2129 (1.4881) lr 9.5492e-04 eta 0:29:47
epoch [25/30] batch [180/796] time 0.396 (0.386) data 0.000 (0.004) loss 1.9189 (1.4683) lr 9.5492e-04 eta 0:29:34
epoch [25/30] batch [200/796] time 0.350 (0.386) data 0.000 (0.004) loss 0.4963 (1.4582) lr 9.5492e-04 eta 0:29:24
epoch [25/30] batch [220/796] time 0.366 (0.385) data 0.000 (0.004) loss 5.2617 (1.4382) lr 9.5492e-04 eta 0:29:15
epoch [25/30] batch [240/796] time 0.387 (0.385) data 0.000 (0.003) loss 0.8018 (1.4053) lr 9.5492e-04 eta 0:29:05
epoch [25/30] batch [260/796] time 0.400 (0.384) data 0.000 (0.003) loss 2.1230 (1.3996) lr 9.5492e-04 eta 0:28:55
epoch [25/30] batch [280/796] time 0.387 (0.384) data 0.000 (0.003) loss 2.1016 (1.4297) lr 9.5492e-04 eta 0:28:45
epoch [25/30] batch [300/796] time 0.381 (0.384) data 0.000 (0.003) loss 0.8467 (1.4370) lr 9.5492e-04 eta 0:28:38
epoch [25/30] batch [320/796] time 0.402 (0.384) data 0.000 (0.003) loss 1.0439 (1.4392) lr 9.5492e-04 eta 0:28:31
epoch [25/30] batch [340/796] time 0.404 (0.384) data 0.000 (0.002) loss 0.8062 (1.4519) lr 9.5492e-04 eta 0:28:22
epoch [25/30] batch [360/796] time 0.401 (0.383) data 0.000 (0.002) loss 0.3738 (1.4188) lr 9.5492e-04 eta 0:28:13
epoch [25/30] batch [380/796] time 0.351 (0.383) data 0.000 (0.002) loss 0.9380 (1.4359) lr 9.5492e-04 eta 0:28:05
epoch [25/30] batch [400/796] time 0.385 (0.383) data 0.000 (0.002) loss 0.4143 (1.4283) lr 9.5492e-04 eta 0:27:56
epoch [25/30] batch [420/796] time 0.413 (0.383) data 0.000 (0.002) loss 0.4294 (1.4087) lr 9.5492e-04 eta 0:27:48
epoch [25/30] batch [440/796] time 0.420 (0.383) data 0.000 (0.002) loss 1.7734 (1.4165) lr 9.5492e-04 eta 0:27:40
epoch [25/30] batch [460/796] time 0.376 (0.383) data 0.000 (0.002) loss 0.4756 (1.4213) lr 9.5492e-04 eta 0:27:32
epoch [25/30] batch [480/796] time 0.397 (0.383) data 0.000 (0.002) loss 1.2041 (1.4150) lr 9.5492e-04 eta 0:27:24
epoch [25/30] batch [500/796] time 0.357 (0.383) data 0.000 (0.002) loss 0.9829 (1.4109) lr 9.5492e-04 eta 0:27:15
epoch [25/30] batch [520/796] time 0.408 (0.383) data 0.000 (0.002) loss 0.9570 (1.4127) lr 9.5492e-04 eta 0:27:09
epoch [25/30] batch [540/796] time 0.372 (0.383) data 0.000 (0.002) loss 1.1240 (1.4066) lr 9.5492e-04 eta 0:27:00
epoch [25/30] batch [560/796] time 0.388 (0.383) data 0.000 (0.002) loss 2.4199 (1.3959) lr 9.5492e-04 eta 0:26:53
epoch [25/30] batch [580/796] time 0.400 (0.383) data 0.000 (0.002) loss 0.8296 (1.3972) lr 9.5492e-04 eta 0:26:46
epoch [25/30] batch [600/796] time 0.386 (0.383) data 0.000 (0.002) loss 0.1848 (1.3856) lr 9.5492e-04 eta 0:26:39
epoch [25/30] batch [620/796] time 0.356 (0.383) data 0.000 (0.001) loss 0.9736 (1.3935) lr 9.5492e-04 eta 0:26:31
epoch [25/30] batch [640/796] time 0.393 (0.383) data 0.000 (0.001) loss 1.7549 (1.3943) lr 9.5492e-04 eta 0:26:23
epoch [25/30] batch [660/796] time 0.351 (0.383) data 0.000 (0.001) loss 0.2057 (1.3896) lr 9.5492e-04 eta 0:26:16
epoch [25/30] batch [680/796] time 0.395 (0.383) data 0.000 (0.001) loss 3.1387 (1.4032) lr 9.5492e-04 eta 0:26:07
epoch [25/30] batch [700/796] time 0.376 (0.383) data 0.000 (0.001) loss 2.9199 (1.4074) lr 9.5492e-04 eta 0:25:59
epoch [25/30] batch [720/796] time 0.395 (0.382) data 0.000 (0.001) loss 0.4656 (1.4067) lr 9.5492e-04 eta 0:25:50
epoch [25/30] batch [740/796] time 0.429 (0.382) data 0.000 (0.001) loss 2.3809 (1.4134) lr 9.5492e-04 eta 0:25:43
epoch [25/30] batch [760/796] time 0.376 (0.382) data 0.000 (0.001) loss 1.6855 (1.4202) lr 9.5492e-04 eta 0:25:35
epoch [25/30] batch [780/796] time 0.345 (0.381) data 0.000 (0.001) loss 3.2109 (1.4132) lr 9.5492e-04 eta 0:25:24
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.58s/it] 10%|█         | 2/20 [00:06<00:48,  2.71s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.60s/it] 20%|██        | 4/20 [00:06<00:17,  1.09s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.25it/s] 30%|███       | 6/20 [00:07<00:08,  1.59it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.92it/s] 40%|████      | 8/20 [00:08<00:05,  2.23it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.50it/s] 50%|█████     | 10/20 [00:08<00:03,  2.75it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.91it/s] 60%|██████    | 12/20 [00:09<00:02,  3.07it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.28it/s] 70%|███████   | 14/20 [00:09<00:01,  3.41it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.65it/s] 80%|████████  | 16/20 [00:10<00:01,  3.84it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.94it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.04it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.38it/s]100%|██████████| 20/20 [00:11<00:00,  4.73it/s]100%|██████████| 20/20 [00:11<00:00,  1.80it/s]=> result
* total: 1,990
* correct: 1,620
* accuracy: 81.4%
* error: 18.6%
* macro_f1: 81.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar

epoch [26/30] batch [20/796] time 0.367 (0.424) data 0.000 (0.042) loss 0.4326 (1.1988) lr 6.6987e-04 eta 0:28:00
epoch [26/30] batch [40/796] time 0.365 (0.403) data 0.000 (0.021) loss 0.6802 (1.3321) lr 6.6987e-04 eta 0:26:27
epoch [26/30] batch [60/796] time 0.359 (0.392) data 0.000 (0.014) loss 0.1318 (1.4777) lr 6.6987e-04 eta 0:25:36
epoch [26/30] batch [80/796] time 0.376 (0.390) data 0.000 (0.011) loss 1.4043 (1.5835) lr 6.6987e-04 eta 0:25:22
epoch [26/30] batch [100/796] time 0.390 (0.389) data 0.000 (0.009) loss 1.1738 (1.5391) lr 6.6987e-04 eta 0:25:09
epoch [26/30] batch [120/796] time 0.411 (0.389) data 0.000 (0.007) loss 2.7656 (1.4966) lr 6.6987e-04 eta 0:25:01
epoch [26/30] batch [140/796] time 0.399 (0.387) data 0.000 (0.006) loss 1.1777 (1.4944) lr 6.6987e-04 eta 0:24:46
epoch [26/30] batch [160/796] time 0.360 (0.386) data 0.000 (0.006) loss 0.7734 (1.5130) lr 6.6987e-04 eta 0:24:35
epoch [26/30] batch [180/796] time 0.367 (0.386) data 0.000 (0.005) loss 1.9150 (1.5012) lr 6.6987e-04 eta 0:24:25
epoch [26/30] batch [200/796] time 0.373 (0.386) data 0.000 (0.004) loss 1.3945 (1.4714) lr 6.6987e-04 eta 0:24:18
epoch [26/30] batch [220/796] time 0.357 (0.386) data 0.000 (0.004) loss 0.7422 (1.4788) lr 6.6987e-04 eta 0:24:09
epoch [26/30] batch [240/796] time 0.372 (0.385) data 0.000 (0.004) loss 0.4934 (1.4664) lr 6.6987e-04 eta 0:23:59
epoch [26/30] batch [260/796] time 0.374 (0.384) data 0.000 (0.004) loss 3.9297 (1.4794) lr 6.6987e-04 eta 0:23:49
epoch [26/30] batch [280/796] time 0.376 (0.384) data 0.000 (0.003) loss 0.5532 (1.4955) lr 6.6987e-04 eta 0:23:41
epoch [26/30] batch [300/796] time 0.395 (0.384) data 0.000 (0.003) loss 2.1738 (1.4894) lr 6.6987e-04 eta 0:23:33
epoch [26/30] batch [320/796] time 0.394 (0.384) data 0.000 (0.003) loss 0.9434 (1.4762) lr 6.6987e-04 eta 0:23:25
epoch [26/30] batch [340/796] time 0.367 (0.384) data 0.000 (0.003) loss 1.6475 (1.4814) lr 6.6987e-04 eta 0:23:17
epoch [26/30] batch [360/796] time 0.394 (0.384) data 0.000 (0.003) loss 1.7412 (1.4807) lr 6.6987e-04 eta 0:23:09
epoch [26/30] batch [380/796] time 0.410 (0.384) data 0.000 (0.002) loss 1.8018 (1.4747) lr 6.6987e-04 eta 0:23:02
epoch [26/30] batch [400/796] time 0.388 (0.384) data 0.000 (0.002) loss 2.3379 (1.4660) lr 6.6987e-04 eta 0:22:55
epoch [26/30] batch [420/796] time 0.365 (0.384) data 0.000 (0.002) loss 1.3389 (1.4633) lr 6.6987e-04 eta 0:22:46
epoch [26/30] batch [440/796] time 0.398 (0.384) data 0.000 (0.002) loss 3.3223 (1.4614) lr 6.6987e-04 eta 0:22:37
epoch [26/30] batch [460/796] time 0.398 (0.383) data 0.000 (0.002) loss 0.9795 (1.4508) lr 6.6987e-04 eta 0:22:29
epoch [26/30] batch [480/796] time 0.372 (0.383) data 0.000 (0.002) loss 0.1298 (1.4334) lr 6.6987e-04 eta 0:22:21
epoch [26/30] batch [500/796] time 0.382 (0.383) data 0.000 (0.002) loss 0.5757 (1.4465) lr 6.6987e-04 eta 0:22:13
epoch [26/30] batch [520/796] time 0.395 (0.383) data 0.000 (0.002) loss 1.1631 (1.4450) lr 6.6987e-04 eta 0:22:05
epoch [26/30] batch [540/796] time 0.357 (0.383) data 0.000 (0.002) loss 0.2053 (1.4352) lr 6.6987e-04 eta 0:21:57
epoch [26/30] batch [560/796] time 0.388 (0.383) data 0.000 (0.002) loss 1.0068 (1.4392) lr 6.6987e-04 eta 0:21:50
epoch [26/30] batch [580/796] time 0.389 (0.383) data 0.000 (0.002) loss 0.2832 (1.4388) lr 6.6987e-04 eta 0:21:42
epoch [26/30] batch [600/796] time 0.371 (0.383) data 0.000 (0.002) loss 0.4651 (1.4261) lr 6.6987e-04 eta 0:21:34
epoch [26/30] batch [620/796] time 0.405 (0.383) data 0.000 (0.002) loss 0.9575 (1.4318) lr 6.6987e-04 eta 0:21:26
epoch [26/30] batch [640/796] time 0.397 (0.383) data 0.000 (0.002) loss 1.0264 (1.4241) lr 6.6987e-04 eta 0:21:18
epoch [26/30] batch [660/796] time 0.395 (0.382) data 0.000 (0.002) loss 0.1890 (1.4149) lr 6.6987e-04 eta 0:21:09
epoch [26/30] batch [680/796] time 0.386 (0.382) data 0.000 (0.002) loss 0.6226 (1.4112) lr 6.6987e-04 eta 0:21:01
epoch [26/30] batch [700/796] time 0.366 (0.382) data 0.000 (0.001) loss 1.2012 (1.4046) lr 6.6987e-04 eta 0:20:54
epoch [26/30] batch [720/796] time 0.358 (0.382) data 0.000 (0.001) loss 0.4397 (1.4043) lr 6.6987e-04 eta 0:20:46
epoch [26/30] batch [740/796] time 0.366 (0.382) data 0.000 (0.001) loss 2.3574 (1.3960) lr 6.6987e-04 eta 0:20:38
epoch [26/30] batch [760/796] time 0.364 (0.382) data 0.000 (0.001) loss 1.6074 (1.4113) lr 6.6987e-04 eta 0:20:31
epoch [26/30] batch [780/796] time 0.343 (0.382) data 0.000 (0.001) loss 0.9336 (1.4086) lr 6.6987e-04 eta 0:20:20
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.62s/it] 10%|█         | 2/20 [00:06<00:51,  2.86s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.69s/it] 20%|██        | 4/20 [00:07<00:18,  1.14s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.20it/s] 30%|███       | 6/20 [00:07<00:09,  1.54it/s] 35%|███▌      | 7/20 [00:08<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.22it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.49it/s] 50%|█████     | 10/20 [00:08<00:03,  2.74it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.01it/s] 60%|██████    | 12/20 [00:09<00:02,  3.18it/s] 65%|██████▌   | 13/20 [00:09<00:01,  3.51it/s] 70%|███████   | 14/20 [00:09<00:01,  3.56it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.85it/s] 80%|████████  | 16/20 [00:10<00:01,  3.99it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.94it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.93it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.30it/s]100%|██████████| 20/20 [00:11<00:00,  4.66it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]=> result
* total: 1,990
* correct: 1,618
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 80.9%

epoch [27/30] batch [20/796] time 0.350 (0.413) data 0.000 (0.035) loss 0.5771 (0.9962) lr 4.3227e-04 eta 0:21:48
epoch [27/30] batch [40/796] time 0.408 (0.398) data 0.000 (0.018) loss 0.7549 (1.1652) lr 4.3227e-04 eta 0:20:50
epoch [27/30] batch [60/796] time 0.377 (0.395) data 0.000 (0.012) loss 1.7617 (1.2404) lr 4.3227e-04 eta 0:20:33
epoch [27/30] batch [80/796] time 0.367 (0.392) data 0.000 (0.009) loss 1.3154 (1.3023) lr 4.3227e-04 eta 0:20:16
epoch [27/30] batch [100/796] time 0.358 (0.389) data 0.000 (0.007) loss 0.2646 (1.2410) lr 4.3227e-04 eta 0:19:58
epoch [27/30] batch [120/796] time 0.359 (0.387) data 0.000 (0.006) loss 2.9277 (1.3244) lr 4.3227e-04 eta 0:19:45
epoch [27/30] batch [140/796] time 0.356 (0.386) data 0.000 (0.005) loss 1.1846 (1.3335) lr 4.3227e-04 eta 0:19:35
epoch [27/30] batch [160/796] time 0.413 (0.386) data 0.000 (0.005) loss 0.4463 (1.3360) lr 4.3227e-04 eta 0:19:27
epoch [27/30] batch [180/796] time 0.407 (0.386) data 0.000 (0.004) loss 0.8799 (1.3443) lr 4.3227e-04 eta 0:19:18
epoch [27/30] batch [200/796] time 0.399 (0.386) data 0.000 (0.004) loss 1.9434 (1.3360) lr 4.3227e-04 eta 0:19:10
epoch [27/30] batch [220/796] time 0.345 (0.385) data 0.000 (0.003) loss 1.4844 (1.3320) lr 4.3227e-04 eta 0:19:01
epoch [27/30] batch [240/796] time 0.386 (0.386) data 0.000 (0.003) loss 0.6191 (1.3334) lr 4.3227e-04 eta 0:18:55
epoch [27/30] batch [260/796] time 0.382 (0.385) data 0.000 (0.003) loss 2.8770 (1.3345) lr 4.3227e-04 eta 0:18:47
epoch [27/30] batch [280/796] time 0.364 (0.385) data 0.000 (0.003) loss 0.4529 (1.3378) lr 4.3227e-04 eta 0:18:36
epoch [27/30] batch [300/796] time 0.360 (0.384) data 0.000 (0.003) loss 0.5410 (1.3238) lr 4.3227e-04 eta 0:18:28
epoch [27/30] batch [320/796] time 0.364 (0.384) data 0.000 (0.002) loss 0.2012 (1.3455) lr 4.3227e-04 eta 0:18:19
epoch [27/30] batch [340/796] time 0.394 (0.384) data 0.000 (0.002) loss 0.0934 (1.3624) lr 4.3227e-04 eta 0:18:11
epoch [27/30] batch [360/796] time 0.377 (0.384) data 0.000 (0.002) loss 2.5176 (1.3740) lr 4.3227e-04 eta 0:18:03
epoch [27/30] batch [380/796] time 0.388 (0.383) data 0.000 (0.002) loss 1.1279 (1.3792) lr 4.3227e-04 eta 0:17:55
epoch [27/30] batch [400/796] time 0.364 (0.383) data 0.000 (0.002) loss 4.3516 (1.3874) lr 4.3227e-04 eta 0:17:45
epoch [27/30] batch [420/796] time 0.353 (0.383) data 0.000 (0.002) loss 0.5635 (1.3689) lr 4.3227e-04 eta 0:17:37
epoch [27/30] batch [440/796] time 0.393 (0.383) data 0.000 (0.002) loss 0.1677 (1.3714) lr 4.3227e-04 eta 0:17:30
epoch [27/30] batch [460/796] time 0.381 (0.383) data 0.000 (0.002) loss 0.7285 (1.3566) lr 4.3227e-04 eta 0:17:22
epoch [27/30] batch [480/796] time 0.400 (0.383) data 0.000 (0.002) loss 0.5234 (1.3576) lr 4.3227e-04 eta 0:17:14
epoch [27/30] batch [500/796] time 0.386 (0.383) data 0.000 (0.002) loss 0.4771 (1.3614) lr 4.3227e-04 eta 0:17:07
epoch [27/30] batch [520/796] time 0.371 (0.383) data 0.000 (0.002) loss 2.8301 (1.3627) lr 4.3227e-04 eta 0:16:59
epoch [27/30] batch [540/796] time 0.407 (0.383) data 0.000 (0.002) loss 0.5664 (1.3864) lr 4.3227e-04 eta 0:16:52
epoch [27/30] batch [560/796] time 0.356 (0.383) data 0.000 (0.001) loss 2.1914 (1.3880) lr 4.3227e-04 eta 0:16:43
epoch [27/30] batch [580/796] time 0.380 (0.382) data 0.000 (0.001) loss 0.8491 (1.3812) lr 4.3227e-04 eta 0:16:35
epoch [27/30] batch [600/796] time 0.359 (0.382) data 0.000 (0.001) loss 5.0312 (1.3967) lr 4.3227e-04 eta 0:16:27
epoch [27/30] batch [620/796] time 0.364 (0.382) data 0.000 (0.001) loss 1.6885 (1.3980) lr 4.3227e-04 eta 0:16:19
epoch [27/30] batch [640/796] time 0.405 (0.382) data 0.000 (0.001) loss 0.2891 (1.3954) lr 4.3227e-04 eta 0:16:11
epoch [27/30] batch [660/796] time 0.365 (0.382) data 0.000 (0.001) loss 1.3008 (1.3924) lr 4.3227e-04 eta 0:16:03
epoch [27/30] batch [680/796] time 0.368 (0.382) data 0.000 (0.001) loss 0.5532 (1.3925) lr 4.3227e-04 eta 0:15:56
epoch [27/30] batch [700/796] time 0.411 (0.382) data 0.000 (0.001) loss 4.0430 (1.3941) lr 4.3227e-04 eta 0:15:49
epoch [27/30] batch [720/796] time 0.362 (0.382) data 0.000 (0.001) loss 0.3008 (1.3989) lr 4.3227e-04 eta 0:15:41
epoch [27/30] batch [740/796] time 0.406 (0.382) data 0.000 (0.001) loss 0.1276 (1.3947) lr 4.3227e-04 eta 0:15:34
epoch [27/30] batch [760/796] time 0.351 (0.382) data 0.000 (0.001) loss 0.4297 (1.3873) lr 4.3227e-04 eta 0:15:26
epoch [27/30] batch [780/796] time 0.343 (0.382) data 0.000 (0.001) loss 0.6504 (1.3888) lr 4.3227e-04 eta 0:15:17
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:45,  5.54s/it] 10%|█         | 2/20 [00:06<00:50,  2.82s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.68s/it] 20%|██        | 4/20 [00:07<00:18,  1.13s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.21it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.88it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:09<00:02,  3.04it/s] 60%|██████    | 12/20 [00:09<00:02,  3.35it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.45it/s] 70%|███████   | 14/20 [00:09<00:01,  3.56it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.71it/s] 80%|████████  | 16/20 [00:10<00:01,  3.73it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.75it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.13it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.46it/s]100%|██████████| 20/20 [00:11<00:00,  4.79it/s]100%|██████████| 20/20 [00:11<00:00,  1.78it/s]=> result
* total: 1,990
* correct: 1,617
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 80.9%

epoch [28/30] batch [20/796] time 0.353 (0.427) data 0.000 (0.037) loss 3.8633 (1.0204) lr 2.4472e-04 eta 0:16:50
epoch [28/30] batch [40/796] time 0.361 (0.402) data 0.000 (0.019) loss 1.0283 (1.3251) lr 2.4472e-04 eta 0:15:43
epoch [28/30] batch [60/796] time 0.409 (0.397) data 0.000 (0.012) loss 1.3242 (1.3445) lr 2.4472e-04 eta 0:15:24
epoch [28/30] batch [80/796] time 0.396 (0.394) data 0.000 (0.009) loss 1.3086 (1.2696) lr 2.4472e-04 eta 0:15:08
epoch [28/30] batch [100/796] time 0.353 (0.391) data 0.000 (0.008) loss 0.5610 (1.3098) lr 2.4472e-04 eta 0:14:54
epoch [28/30] batch [120/796] time 0.373 (0.389) data 0.000 (0.006) loss 2.7383 (1.4107) lr 2.4472e-04 eta 0:14:42
epoch [28/30] batch [140/796] time 0.396 (0.387) data 0.000 (0.005) loss 2.9941 (1.3546) lr 2.4472e-04 eta 0:14:30
epoch [28/30] batch [160/796] time 0.352 (0.387) data 0.000 (0.005) loss 0.6357 (1.3123) lr 2.4472e-04 eta 0:14:22
epoch [28/30] batch [180/796] time 0.353 (0.386) data 0.000 (0.004) loss 2.7520 (1.3741) lr 2.4472e-04 eta 0:14:11
epoch [28/30] batch [200/796] time 0.387 (0.385) data 0.000 (0.004) loss 0.9287 (1.3337) lr 2.4472e-04 eta 0:14:01
epoch [28/30] batch [220/796] time 0.359 (0.384) data 0.000 (0.004) loss 6.4648 (1.3457) lr 2.4472e-04 eta 0:13:52
epoch [28/30] batch [240/796] time 0.364 (0.383) data 0.000 (0.003) loss 2.2793 (1.3630) lr 2.4472e-04 eta 0:13:43
epoch [28/30] batch [260/796] time 0.372 (0.383) data 0.000 (0.003) loss 0.2930 (1.3800) lr 2.4472e-04 eta 0:13:35
epoch [28/30] batch [280/796] time 0.363 (0.383) data 0.000 (0.003) loss 1.6523 (1.3814) lr 2.4472e-04 eta 0:13:26
epoch [28/30] batch [300/796] time 0.355 (0.383) data 0.000 (0.003) loss 2.3281 (1.3791) lr 2.4472e-04 eta 0:13:19
epoch [28/30] batch [320/796] time 0.385 (0.383) data 0.000 (0.003) loss 1.2529 (1.4021) lr 2.4472e-04 eta 0:13:11
epoch [28/30] batch [340/796] time 0.384 (0.383) data 0.000 (0.002) loss 0.8745 (1.3913) lr 2.4472e-04 eta 0:13:04
epoch [28/30] batch [360/796] time 0.409 (0.383) data 0.000 (0.002) loss 3.2715 (1.3849) lr 2.4472e-04 eta 0:12:56
epoch [28/30] batch [380/796] time 0.382 (0.384) data 0.000 (0.002) loss 0.5493 (1.3843) lr 2.4472e-04 eta 0:12:50
epoch [28/30] batch [400/796] time 0.404 (0.383) data 0.000 (0.002) loss 1.8389 (1.3768) lr 2.4472e-04 eta 0:12:41
epoch [28/30] batch [420/796] time 0.377 (0.383) data 0.000 (0.002) loss 0.9463 (1.3674) lr 2.4472e-04 eta 0:12:34
epoch [28/30] batch [440/796] time 0.365 (0.383) data 0.000 (0.002) loss 1.1191 (1.3644) lr 2.4472e-04 eta 0:12:26
epoch [28/30] batch [460/796] time 0.376 (0.383) data 0.000 (0.002) loss 0.0875 (1.3596) lr 2.4472e-04 eta 0:12:18
epoch [28/30] batch [480/796] time 0.384 (0.383) data 0.000 (0.002) loss 0.5073 (1.3684) lr 2.4472e-04 eta 0:12:10
epoch [28/30] batch [500/796] time 0.379 (0.383) data 0.000 (0.002) loss 0.7173 (1.3583) lr 2.4472e-04 eta 0:12:02
epoch [28/30] batch [520/796] time 0.386 (0.383) data 0.000 (0.002) loss 1.3330 (1.3727) lr 2.4472e-04 eta 0:11:54
epoch [28/30] batch [540/796] time 0.357 (0.383) data 0.000 (0.002) loss 1.7275 (1.3770) lr 2.4472e-04 eta 0:11:47
epoch [28/30] batch [560/796] time 0.359 (0.383) data 0.000 (0.002) loss 0.2190 (1.3752) lr 2.4472e-04 eta 0:11:39
epoch [28/30] batch [580/796] time 0.364 (0.383) data 0.000 (0.002) loss 0.5811 (1.3621) lr 2.4472e-04 eta 0:11:32
epoch [28/30] batch [600/796] time 0.362 (0.383) data 0.000 (0.001) loss 2.2754 (1.3689) lr 2.4472e-04 eta 0:11:24
epoch [28/30] batch [620/796] time 0.391 (0.383) data 0.000 (0.001) loss 2.0879 (1.3757) lr 2.4472e-04 eta 0:11:16
epoch [28/30] batch [640/796] time 0.390 (0.383) data 0.000 (0.001) loss 1.1963 (1.3868) lr 2.4472e-04 eta 0:11:08
epoch [28/30] batch [660/796] time 0.390 (0.382) data 0.000 (0.001) loss 1.2988 (1.3803) lr 2.4472e-04 eta 0:11:00
epoch [28/30] batch [680/796] time 0.393 (0.382) data 0.000 (0.001) loss 1.3330 (1.3758) lr 2.4472e-04 eta 0:10:53
epoch [28/30] batch [700/796] time 0.373 (0.382) data 0.000 (0.001) loss 0.2700 (1.3827) lr 2.4472e-04 eta 0:10:45
epoch [28/30] batch [720/796] time 0.365 (0.382) data 0.000 (0.001) loss 1.5410 (1.3709) lr 2.4472e-04 eta 0:10:37
epoch [28/30] batch [740/796] time 0.391 (0.382) data 0.000 (0.001) loss 1.9297 (1.3646) lr 2.4472e-04 eta 0:10:29
epoch [28/30] batch [760/796] time 0.383 (0.382) data 0.000 (0.001) loss 0.0598 (1.3737) lr 2.4472e-04 eta 0:10:22
epoch [28/30] batch [780/796] time 0.341 (0.381) data 0.000 (0.001) loss 0.3279 (1.3685) lr 2.4472e-04 eta 0:10:13
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.59s/it] 10%|█         | 2/20 [00:06<00:52,  2.93s/it] 15%|█▌        | 3/20 [00:06<00:29,  1.72s/it] 20%|██        | 4/20 [00:07<00:18,  1.16s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.18it/s] 30%|███       | 6/20 [00:07<00:09,  1.50it/s] 35%|███▌      | 7/20 [00:08<00:07,  1.84it/s] 40%|████      | 8/20 [00:08<00:05,  2.16it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.45it/s] 50%|█████     | 10/20 [00:08<00:03,  2.72it/s] 55%|█████▌    | 11/20 [00:09<00:03,  3.00it/s] 60%|██████    | 12/20 [00:09<00:02,  3.26it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.46it/s] 70%|███████   | 14/20 [00:10<00:01,  3.51it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.73it/s] 80%|████████  | 16/20 [00:10<00:01,  3.99it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.97it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.28it/s] 95%|█████████▌| 19/20 [00:11<00:00,  4.58it/s]100%|██████████| 20/20 [00:11<00:00,  4.89it/s]100%|██████████| 20/20 [00:11<00:00,  1.76it/s]=> result
* total: 1,990
* correct: 1,616
* accuracy: 81.2%
* error: 18.8%
* macro_f1: 80.8%

epoch [29/30] batch [20/796] time 0.390 (0.433) data 0.000 (0.041) loss 1.1885 (1.2235) lr 1.0926e-04 eta 0:11:21
epoch [29/30] batch [40/796] time 0.358 (0.407) data 0.000 (0.020) loss 1.0283 (1.3659) lr 1.0926e-04 eta 0:10:32
epoch [29/30] batch [60/796] time 0.349 (0.398) data 0.000 (0.014) loss 1.1572 (1.4034) lr 1.0926e-04 eta 0:10:09
epoch [29/30] batch [80/796] time 0.366 (0.393) data 0.000 (0.010) loss 0.1567 (1.3471) lr 1.0926e-04 eta 0:09:54
epoch [29/30] batch [100/796] time 0.396 (0.391) data 0.000 (0.008) loss 0.7744 (1.3373) lr 1.0926e-04 eta 0:09:43
epoch [29/30] batch [120/796] time 0.351 (0.388) data 0.000 (0.007) loss 2.2480 (1.3623) lr 1.0926e-04 eta 0:09:31
epoch [29/30] batch [140/796] time 0.402 (0.386) data 0.000 (0.006) loss 0.7656 (1.3067) lr 1.0926e-04 eta 0:09:20
epoch [29/30] batch [160/796] time 0.364 (0.385) data 0.000 (0.005) loss 0.2756 (1.2797) lr 1.0926e-04 eta 0:09:10
epoch [29/30] batch [180/796] time 0.356 (0.384) data 0.000 (0.005) loss 2.3906 (1.2954) lr 1.0926e-04 eta 0:09:02
epoch [29/30] batch [200/796] time 0.352 (0.382) data 0.000 (0.004) loss 0.4915 (1.2997) lr 1.0926e-04 eta 0:08:52
epoch [29/30] batch [220/796] time 0.373 (0.382) data 0.000 (0.004) loss 0.4634 (1.2990) lr 1.0926e-04 eta 0:08:44
epoch [29/30] batch [240/796] time 0.356 (0.382) data 0.000 (0.004) loss 0.7573 (1.3210) lr 1.0926e-04 eta 0:08:35
epoch [29/30] batch [260/796] time 0.364 (0.381) data 0.000 (0.003) loss 1.1367 (1.3334) lr 1.0926e-04 eta 0:08:28
epoch [29/30] batch [280/796] time 0.407 (0.382) data 0.000 (0.003) loss 2.2012 (1.3546) lr 1.0926e-04 eta 0:08:20
epoch [29/30] batch [300/796] time 0.403 (0.382) data 0.000 (0.003) loss 2.1953 (1.3459) lr 1.0926e-04 eta 0:08:13
epoch [29/30] batch [320/796] time 0.396 (0.382) data 0.000 (0.003) loss 3.0547 (1.3503) lr 1.0926e-04 eta 0:08:05
epoch [29/30] batch [340/796] time 0.387 (0.381) data 0.000 (0.003) loss 1.3906 (1.3604) lr 1.0926e-04 eta 0:07:57
epoch [29/30] batch [360/796] time 0.353 (0.381) data 0.000 (0.002) loss 1.7861 (1.3613) lr 1.0926e-04 eta 0:07:49
epoch [29/30] batch [380/796] time 0.358 (0.381) data 0.000 (0.002) loss 0.8110 (1.3668) lr 1.0926e-04 eta 0:07:42
epoch [29/30] batch [400/796] time 0.405 (0.382) data 0.000 (0.002) loss 2.4922 (1.3715) lr 1.0926e-04 eta 0:07:34
epoch [29/30] batch [420/796] time 0.361 (0.381) data 0.000 (0.002) loss 0.4021 (1.3558) lr 1.0926e-04 eta 0:07:26
epoch [29/30] batch [440/796] time 0.366 (0.381) data 0.000 (0.002) loss 1.0986 (1.3388) lr 1.0926e-04 eta 0:07:19
epoch [29/30] batch [460/796] time 0.371 (0.381) data 0.000 (0.002) loss 1.5000 (1.3437) lr 1.0926e-04 eta 0:07:11
epoch [29/30] batch [480/796] time 0.405 (0.381) data 0.000 (0.002) loss 2.6543 (1.3473) lr 1.0926e-04 eta 0:07:03
epoch [29/30] batch [500/796] time 0.366 (0.381) data 0.000 (0.002) loss 0.3643 (1.3584) lr 1.0926e-04 eta 0:06:56
epoch [29/30] batch [520/796] time 0.355 (0.381) data 0.000 (0.002) loss 1.3340 (1.3642) lr 1.0926e-04 eta 0:06:48
epoch [29/30] batch [540/796] time 0.408 (0.381) data 0.000 (0.002) loss 0.8726 (1.3731) lr 1.0926e-04 eta 0:06:41
epoch [29/30] batch [560/796] time 0.391 (0.381) data 0.000 (0.002) loss 2.9473 (1.3753) lr 1.0926e-04 eta 0:06:33
epoch [29/30] batch [580/796] time 0.363 (0.381) data 0.000 (0.002) loss 2.0312 (1.3781) lr 1.0926e-04 eta 0:06:25
epoch [29/30] batch [600/796] time 0.393 (0.381) data 0.000 (0.002) loss 0.4802 (1.3887) lr 1.0926e-04 eta 0:06:17
epoch [29/30] batch [620/796] time 0.366 (0.381) data 0.000 (0.002) loss 1.0049 (1.3992) lr 1.0926e-04 eta 0:06:10
epoch [29/30] batch [640/796] time 0.434 (0.381) data 0.000 (0.002) loss 0.5576 (1.4025) lr 1.0926e-04 eta 0:06:03
epoch [29/30] batch [660/796] time 0.401 (0.381) data 0.000 (0.001) loss 0.3284 (1.4000) lr 1.0926e-04 eta 0:05:55
epoch [29/30] batch [680/796] time 0.346 (0.381) data 0.000 (0.001) loss 1.5791 (1.3913) lr 1.0926e-04 eta 0:05:47
epoch [29/30] batch [700/796] time 0.379 (0.381) data 0.000 (0.001) loss 2.5449 (1.3854) lr 1.0926e-04 eta 0:05:40
epoch [29/30] batch [720/796] time 0.359 (0.381) data 0.000 (0.001) loss 0.3066 (1.3825) lr 1.0926e-04 eta 0:05:32
epoch [29/30] batch [740/796] time 0.390 (0.381) data 0.000 (0.001) loss 0.8647 (1.3777) lr 1.0926e-04 eta 0:05:24
epoch [29/30] batch [760/796] time 0.377 (0.381) data 0.000 (0.001) loss 1.0791 (1.3865) lr 1.0926e-04 eta 0:05:17
epoch [29/30] batch [780/796] time 0.340 (0.380) data 0.000 (0.001) loss 1.7832 (1.3897) lr 1.0926e-04 eta 0:05:08
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:44,  5.50s/it] 10%|█         | 2/20 [00:06<00:49,  2.72s/it] 15%|█▌        | 3/20 [00:06<00:27,  1.61s/it] 20%|██        | 4/20 [00:06<00:17,  1.09s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.25it/s] 30%|███       | 6/20 [00:07<00:08,  1.60it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.90it/s] 40%|████      | 8/20 [00:08<00:05,  2.20it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.48it/s] 50%|█████     | 10/20 [00:08<00:03,  2.70it/s] 55%|█████▌    | 11/20 [00:08<00:03,  2.94it/s] 60%|██████    | 12/20 [00:09<00:02,  3.13it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.30it/s] 70%|███████   | 14/20 [00:09<00:01,  3.63it/s] 75%|███████▌  | 15/20 [00:09<00:01,  3.63it/s] 80%|████████  | 16/20 [00:10<00:01,  3.82it/s] 85%|████████▌ | 17/20 [00:10<00:00,  3.90it/s] 90%|█████████ | 18/20 [00:10<00:00,  4.24it/s] 95%|█████████▌| 19/20 [00:10<00:00,  4.55it/s]100%|██████████| 20/20 [00:10<00:00,  4.87it/s]100%|██████████| 20/20 [00:11<00:00,  1.81it/s]=> result
* total: 1,990
* correct: 1,618
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 80.9%

epoch [30/30] batch [20/796] time 0.378 (0.429) data 0.000 (0.042) loss 0.6260 (1.1682) lr 2.7391e-05 eta 0:05:32
epoch [30/30] batch [40/796] time 0.400 (0.403) data 0.000 (0.021) loss 0.7124 (1.4442) lr 2.7391e-05 eta 0:05:04
epoch [30/30] batch [60/796] time 0.377 (0.396) data 0.000 (0.014) loss 0.2068 (1.5556) lr 2.7391e-05 eta 0:04:51
epoch [30/30] batch [80/796] time 0.400 (0.392) data 0.000 (0.011) loss 1.9238 (1.4121) lr 2.7391e-05 eta 0:04:40
epoch [30/30] batch [100/796] time 0.371 (0.391) data 0.000 (0.009) loss 4.0000 (1.3881) lr 2.7391e-05 eta 0:04:31
epoch [30/30] batch [120/796] time 0.405 (0.389) data 0.000 (0.007) loss 0.1451 (1.3299) lr 2.7391e-05 eta 0:04:23
epoch [30/30] batch [140/796] time 0.385 (0.388) data 0.000 (0.006) loss 1.3750 (1.3097) lr 2.7391e-05 eta 0:04:14
epoch [30/30] batch [160/796] time 0.354 (0.386) data 0.000 (0.005) loss 2.8340 (1.2973) lr 2.7391e-05 eta 0:04:05
epoch [30/30] batch [180/796] time 0.351 (0.385) data 0.000 (0.005) loss 2.2363 (1.3185) lr 2.7391e-05 eta 0:03:57
epoch [30/30] batch [200/796] time 0.410 (0.385) data 0.000 (0.004) loss 0.2981 (1.2852) lr 2.7391e-05 eta 0:03:49
epoch [30/30] batch [220/796] time 0.353 (0.385) data 0.000 (0.004) loss 0.3005 (1.2580) lr 2.7391e-05 eta 0:03:41
epoch [30/30] batch [240/796] time 0.375 (0.384) data 0.000 (0.004) loss 1.1250 (1.2697) lr 2.7391e-05 eta 0:03:33
epoch [30/30] batch [260/796] time 0.376 (0.384) data 0.000 (0.003) loss 0.9678 (1.2992) lr 2.7391e-05 eta 0:03:25
epoch [30/30] batch [280/796] time 0.387 (0.384) data 0.000 (0.003) loss 0.3860 (1.3076) lr 2.7391e-05 eta 0:03:18
epoch [30/30] batch [300/796] time 0.395 (0.384) data 0.000 (0.003) loss 1.7314 (1.3059) lr 2.7391e-05 eta 0:03:10
epoch [30/30] batch [320/796] time 0.387 (0.384) data 0.000 (0.003) loss 0.9604 (1.2993) lr 2.7391e-05 eta 0:03:02
epoch [30/30] batch [340/796] time 0.351 (0.384) data 0.000 (0.003) loss 1.0625 (1.2993) lr 2.7391e-05 eta 0:02:55
epoch [30/30] batch [360/796] time 0.397 (0.384) data 0.000 (0.003) loss 1.2129 (1.3042) lr 2.7391e-05 eta 0:02:47
epoch [30/30] batch [380/796] time 0.392 (0.384) data 0.000 (0.002) loss 2.8242 (1.2866) lr 2.7391e-05 eta 0:02:39
epoch [30/30] batch [400/796] time 0.407 (0.384) data 0.000 (0.002) loss 1.6406 (1.2971) lr 2.7391e-05 eta 0:02:31
epoch [30/30] batch [420/796] time 0.379 (0.383) data 0.000 (0.002) loss 2.8145 (1.2943) lr 2.7391e-05 eta 0:02:24
epoch [30/30] batch [440/796] time 0.371 (0.383) data 0.000 (0.002) loss 1.2822 (1.3038) lr 2.7391e-05 eta 0:02:16
epoch [30/30] batch [460/796] time 0.355 (0.383) data 0.000 (0.002) loss 0.2817 (1.3010) lr 2.7391e-05 eta 0:02:08
epoch [30/30] batch [480/796] time 0.361 (0.383) data 0.000 (0.002) loss 1.7715 (1.2913) lr 2.7391e-05 eta 0:02:00
epoch [30/30] batch [500/796] time 0.395 (0.383) data 0.000 (0.002) loss 1.3691 (1.2936) lr 2.7391e-05 eta 0:01:53
epoch [30/30] batch [520/796] time 0.354 (0.383) data 0.000 (0.002) loss 2.2500 (1.2959) lr 2.7391e-05 eta 0:01:45
epoch [30/30] batch [540/796] time 0.365 (0.383) data 0.000 (0.002) loss 0.8657 (1.2927) lr 2.7391e-05 eta 0:01:37
epoch [30/30] batch [560/796] time 0.417 (0.382) data 0.000 (0.002) loss 1.7764 (1.2910) lr 2.7391e-05 eta 0:01:30
epoch [30/30] batch [580/796] time 0.379 (0.382) data 0.000 (0.002) loss 0.2698 (1.2894) lr 2.7391e-05 eta 0:01:22
epoch [30/30] batch [600/796] time 0.360 (0.382) data 0.000 (0.002) loss 1.3027 (1.2966) lr 2.7391e-05 eta 0:01:14
epoch [30/30] batch [620/796] time 0.371 (0.382) data 0.000 (0.002) loss 0.5200 (1.3031) lr 2.7391e-05 eta 0:01:07
epoch [30/30] batch [640/796] time 0.396 (0.382) data 0.000 (0.002) loss 1.4482 (1.2970) lr 2.7391e-05 eta 0:00:59
epoch [30/30] batch [660/796] time 0.390 (0.382) data 0.000 (0.002) loss 0.4890 (1.2960) lr 2.7391e-05 eta 0:00:51
epoch [30/30] batch [680/796] time 0.402 (0.382) data 0.000 (0.001) loss 0.9600 (1.2958) lr 2.7391e-05 eta 0:00:44
epoch [30/30] batch [700/796] time 0.401 (0.382) data 0.000 (0.001) loss 1.2764 (1.2991) lr 2.7391e-05 eta 0:00:36
epoch [30/30] batch [720/796] time 0.356 (0.382) data 0.000 (0.001) loss 1.4375 (1.2975) lr 2.7391e-05 eta 0:00:29
epoch [30/30] batch [740/796] time 0.372 (0.382) data 0.000 (0.001) loss 0.2317 (1.2935) lr 2.7391e-05 eta 0:00:21
epoch [30/30] batch [760/796] time 0.361 (0.382) data 0.000 (0.001) loss 2.4180 (1.3030) lr 2.7391e-05 eta 0:00:13
epoch [30/30] batch [780/796] time 0.344 (0.381) data 0.000 (0.001) loss 1.0869 (1.2968) lr 2.7391e-05 eta 0:00:06
Evaluate on the *val* set
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:05<01:46,  5.60s/it] 10%|█         | 2/20 [00:06<00:50,  2.79s/it] 15%|█▌        | 3/20 [00:06<00:28,  1.65s/it] 20%|██        | 4/20 [00:07<00:17,  1.11s/it] 25%|██▌       | 5/20 [00:07<00:12,  1.22it/s] 30%|███       | 6/20 [00:07<00:09,  1.55it/s] 35%|███▌      | 7/20 [00:07<00:06,  1.89it/s] 40%|████      | 8/20 [00:08<00:05,  2.21it/s] 45%|████▌     | 9/20 [00:08<00:04,  2.47it/s] 50%|█████     | 10/20 [00:08<00:03,  2.69it/s] 55%|█████▌    | 11/20 [00:09<00:03,  2.91it/s] 60%|██████    | 12/20 [00:09<00:02,  3.22it/s] 65%|██████▌   | 13/20 [00:09<00:02,  3.48it/s] 70%|███████   | 14/20 [00:09<00:01,  3.54it/s] 75%|███████▌  | 15/20 [00:10<00:01,  3.87it/s] 80%|████████  | 16/20 [00:10<00:00,  4.13it/s] 85%|████████▌ | 17/20 [00:10<00:00,  4.31it/s] 90%|█████████ | 18/20 [00:10<00:00,  3.50it/s] 95%|█████████▌| 19/20 [00:11<00:00,  3.93it/s]100%|██████████| 20/20 [00:11<00:00,  4.36it/s]100%|██████████| 20/20 [00:11<00:00,  1.77it/s]
=> result
* total: 1,990
* correct: 1,617
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 80.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model.pth.tar-30
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:05<08:54,  5.40s/it]  2%|▏         | 2/100 [00:05<04:07,  2.53s/it]  3%|▎         | 3/100 [00:07<03:26,  2.13s/it]  4%|▍         | 4/100 [00:08<02:22,  1.49s/it]  5%|▌         | 5/100 [00:08<01:44,  1.10s/it]  6%|▌         | 6/100 [00:08<01:24,  1.12it/s]  7%|▋         | 7/100 [00:09<01:11,  1.31it/s]  8%|▊         | 8/100 [00:09<01:01,  1.49it/s]  9%|▉         | 9/100 [00:10<00:56,  1.62it/s] 10%|█         | 10/100 [00:10<00:52,  1.72it/s] 11%|█         | 11/100 [00:11<00:49,  1.79it/s] 12%|█▏        | 12/100 [00:11<00:46,  1.88it/s] 13%|█▎        | 13/100 [00:12<00:43,  1.99it/s] 14%|█▍        | 14/100 [00:12<00:42,  2.00it/s] 15%|█▌        | 15/100 [00:13<00:43,  1.93it/s] 16%|█▌        | 16/100 [00:14<00:45,  1.83it/s] 17%|█▋        | 17/100 [00:14<00:44,  1.88it/s] 18%|█▊        | 18/100 [00:15<00:42,  1.94it/s] 19%|█▉        | 19/100 [00:15<00:41,  1.97it/s] 20%|██        | 20/100 [00:15<00:38,  2.10it/s] 21%|██        | 21/100 [00:16<00:36,  2.19it/s] 22%|██▏       | 22/100 [00:16<00:34,  2.26it/s] 23%|██▎       | 23/100 [00:17<00:33,  2.30it/s] 24%|██▍       | 24/100 [00:17<00:32,  2.31it/s] 25%|██▌       | 25/100 [00:18<00:32,  2.27it/s] 26%|██▌       | 26/100 [00:18<00:33,  2.22it/s] 27%|██▋       | 27/100 [00:18<00:31,  2.31it/s] 28%|██▊       | 28/100 [00:19<00:31,  2.29it/s] 29%|██▉       | 29/100 [00:19<00:32,  2.22it/s] 30%|███       | 30/100 [00:20<00:31,  2.25it/s] 31%|███       | 31/100 [00:20<00:31,  2.19it/s] 32%|███▏      | 32/100 [00:21<00:30,  2.24it/s] 33%|███▎      | 33/100 [00:21<00:30,  2.20it/s] 34%|███▍      | 34/100 [00:22<00:31,  2.12it/s] 35%|███▌      | 35/100 [00:22<00:31,  2.10it/s] 36%|███▌      | 36/100 [00:23<00:29,  2.15it/s] 37%|███▋      | 37/100 [00:23<00:29,  2.15it/s] 38%|███▊      | 38/100 [00:23<00:27,  2.24it/s] 39%|███▉      | 39/100 [00:24<00:25,  2.37it/s] 40%|████      | 40/100 [00:24<00:25,  2.38it/s] 41%|████      | 41/100 [00:25<00:26,  2.27it/s] 42%|████▏     | 42/100 [00:25<00:24,  2.39it/s] 43%|████▎     | 43/100 [00:25<00:22,  2.49it/s] 44%|████▍     | 44/100 [00:26<00:21,  2.55it/s] 45%|████▌     | 45/100 [00:26<00:22,  2.45it/s] 46%|████▌     | 46/100 [00:27<00:21,  2.49it/s] 47%|████▋     | 47/100 [00:27<00:20,  2.57it/s] 48%|████▊     | 48/100 [00:27<00:20,  2.58it/s] 49%|████▉     | 49/100 [00:28<00:20,  2.48it/s] 50%|█████     | 50/100 [00:28<00:20,  2.41it/s] 51%|█████     | 51/100 [00:29<00:20,  2.37it/s] 52%|█████▏    | 52/100 [00:29<00:19,  2.49it/s] 53%|█████▎    | 53/100 [00:29<00:18,  2.52it/s] 54%|█████▍    | 54/100 [00:30<00:17,  2.56it/s] 55%|█████▌    | 55/100 [00:30<00:18,  2.48it/s] 56%|█████▌    | 56/100 [00:31<00:18,  2.40it/s] 57%|█████▋    | 57/100 [00:31<00:18,  2.38it/s] 58%|█████▊    | 58/100 [00:32<00:17,  2.35it/s] 59%|█████▉    | 59/100 [00:32<00:16,  2.45it/s] 60%|██████    | 60/100 [00:32<00:16,  2.48it/s] 61%|██████    | 61/100 [00:33<00:15,  2.52it/s] 62%|██████▏   | 62/100 [00:33<00:15,  2.46it/s] 63%|██████▎   | 63/100 [00:34<00:14,  2.53it/s] 64%|██████▍   | 64/100 [00:34<00:14,  2.47it/s] 65%|██████▌   | 65/100 [00:34<00:14,  2.37it/s] 66%|██████▌   | 66/100 [00:35<00:14,  2.34it/s] 67%|██████▋   | 67/100 [00:35<00:13,  2.36it/s] 68%|██████▊   | 68/100 [00:36<00:13,  2.31it/s] 69%|██████▉   | 69/100 [00:36<00:13,  2.38it/s] 70%|███████   | 70/100 [00:36<00:11,  2.54it/s] 71%|███████   | 71/100 [00:37<00:10,  2.64it/s] 72%|███████▏  | 72/100 [00:37<00:10,  2.77it/s] 73%|███████▎  | 73/100 [00:37<00:09,  2.85it/s] 74%|███████▍  | 74/100 [00:38<00:08,  2.91it/s] 75%|███████▌  | 75/100 [00:38<00:08,  2.97it/s] 76%|███████▌  | 76/100 [00:38<00:07,  3.01it/s] 77%|███████▋  | 77/100 [00:39<00:07,  3.07it/s] 78%|███████▊  | 78/100 [00:39<00:06,  3.15it/s] 79%|███████▉  | 79/100 [00:39<00:06,  3.18it/s] 80%|████████  | 80/100 [00:40<00:05,  3.41it/s] 81%|████████  | 81/100 [00:40<00:04,  3.85it/s] 82%|████████▏ | 82/100 [00:40<00:04,  4.23it/s] 83%|████████▎ | 83/100 [00:40<00:03,  4.54it/s] 84%|████████▍ | 84/100 [00:40<00:03,  4.79it/s] 85%|████████▌ | 85/100 [00:40<00:03,  4.98it/s] 86%|████████▌ | 86/100 [00:41<00:02,  5.12it/s] 87%|████████▋ | 87/100 [00:41<00:02,  5.23it/s] 88%|████████▊ | 88/100 [00:41<00:02,  5.30it/s] 89%|████████▉ | 89/100 [00:41<00:02,  5.36it/s] 90%|█████████ | 90/100 [00:41<00:01,  5.39it/s] 91%|█████████ | 91/100 [00:42<00:01,  5.42it/s] 92%|█████████▏| 92/100 [00:42<00:01,  5.44it/s] 93%|█████████▎| 93/100 [00:42<00:01,  5.45it/s] 94%|█████████▍| 94/100 [00:42<00:01,  5.46it/s] 95%|█████████▌| 95/100 [00:42<00:00,  5.47it/s] 96%|█████████▌| 96/100 [00:42<00:00,  5.47it/s] 97%|█████████▋| 97/100 [00:43<00:00,  5.48it/s] 98%|█████████▊| 98/100 [00:43<00:00,  5.48it/s] 99%|█████████▉| 99/100 [00:43<00:00,  5.48it/s]100%|██████████| 100/100 [00:43<00:00,  6.01it/s]100%|██████████| 100/100 [00:43<00:00,  2.29it/s]
=> result
* total: 9,950
* correct: 8,110
* accuracy: 81.5%
* error: 18.5%
* macro_f1: 81.3%
Elapsed: 2:37:54
+ sh scripts/rpo_prime/base2new_test_sdl.sh sun397 3 0 main_tmp1_0.1sdl 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/sun397.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: SUN397
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:SUN397
Loading dataset: SUN397
Reading split from /shared/s2/lab01/dataset/clip/sun397/split_zhou_SUN397.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/sun397/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
3168 1980 9900
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------
Dataset    SUN397
# classes  198
# train_x  3,168
# val      1,980
# test     9,900
---------  ------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/sun397/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed3/prompt_learner/model-best.pth.tar" (epoch = 25)
Evaluate on the *test* set
  0%|          | 0/99 [00:00<?, ?it/s]  1%|          | 1/99 [00:09<15:49,  9.69s/it]  2%|▏         | 2/99 [00:10<06:52,  4.26s/it]  3%|▎         | 3/99 [00:10<04:00,  2.50s/it]  4%|▍         | 4/99 [00:10<02:36,  1.64s/it]  5%|▌         | 5/99 [00:11<01:50,  1.18s/it]  6%|▌         | 6/99 [00:11<01:23,  1.12it/s]  7%|▋         | 7/99 [00:11<01:04,  1.42it/s]  8%|▊         | 8/99 [00:12<00:52,  1.73it/s]  9%|▉         | 9/99 [00:12<00:44,  2.01it/s] 10%|█         | 10/99 [00:12<00:39,  2.25it/s] 11%|█         | 11/99 [00:13<00:36,  2.41it/s] 12%|█▏        | 12/99 [00:13<00:34,  2.52it/s] 13%|█▎        | 13/99 [00:13<00:34,  2.47it/s] 14%|█▍        | 14/99 [00:14<00:34,  2.44it/s] 15%|█▌        | 15/99 [00:14<00:34,  2.40it/s] 16%|█▌        | 16/99 [00:15<00:36,  2.29it/s] 17%|█▋        | 17/99 [00:15<00:36,  2.24it/s] 18%|█▊        | 18/99 [00:16<00:35,  2.26it/s] 19%|█▉        | 19/99 [00:16<00:35,  2.23it/s] 20%|██        | 20/99 [00:17<00:34,  2.27it/s] 21%|██        | 21/99 [00:17<00:35,  2.18it/s] 22%|██▏       | 22/99 [00:18<00:35,  2.15it/s] 23%|██▎       | 23/99 [00:18<00:34,  2.23it/s] 24%|██▍       | 24/99 [00:18<00:32,  2.30it/s] 25%|██▌       | 25/99 [00:19<00:31,  2.33it/s] 26%|██▋       | 26/99 [00:19<00:29,  2.44it/s] 27%|██▋       | 27/99 [00:20<00:28,  2.52it/s] 28%|██▊       | 28/99 [00:20<00:27,  2.62it/s] 29%|██▉       | 29/99 [00:20<00:26,  2.68it/s] 30%|███       | 30/99 [00:21<00:24,  2.79it/s] 31%|███▏      | 31/99 [00:21<00:24,  2.83it/s] 32%|███▏      | 32/99 [00:21<00:24,  2.79it/s] 33%|███▎      | 33/99 [00:22<00:25,  2.63it/s] 34%|███▍      | 34/99 [00:22<00:24,  2.61it/s] 35%|███▌      | 35/99 [00:23<00:25,  2.53it/s] 36%|███▋      | 36/99 [00:23<00:25,  2.43it/s] 37%|███▋      | 37/99 [00:23<00:26,  2.36it/s] 38%|███▊      | 38/99 [00:24<00:25,  2.40it/s] 39%|███▉      | 39/99 [00:24<00:25,  2.37it/s] 40%|████      | 40/99 [00:25<00:24,  2.42it/s] 41%|████▏     | 41/99 [00:25<00:23,  2.48it/s] 42%|████▏     | 42/99 [00:25<00:22,  2.56it/s] 43%|████▎     | 43/99 [00:26<00:22,  2.50it/s] 44%|████▍     | 44/99 [00:26<00:22,  2.46it/s] 45%|████▌     | 45/99 [00:27<00:22,  2.42it/s] 46%|████▋     | 46/99 [00:27<00:21,  2.48it/s] 47%|████▋     | 47/99 [00:27<00:20,  2.53it/s] 48%|████▊     | 48/99 [00:28<00:20,  2.43it/s] 49%|████▉     | 49/99 [00:28<00:21,  2.37it/s] 51%|█████     | 50/99 [00:29<00:21,  2.32it/s] 52%|█████▏    | 51/99 [00:29<00:20,  2.33it/s] 53%|█████▎    | 52/99 [00:30<00:19,  2.37it/s] 54%|█████▎    | 53/99 [00:30<00:20,  2.29it/s] 55%|█████▍    | 54/99 [00:30<00:18,  2.41it/s] 56%|█████▌    | 55/99 [00:31<00:18,  2.38it/s] 57%|█████▋    | 56/99 [00:31<00:17,  2.41it/s] 58%|█████▊    | 57/99 [00:32<00:16,  2.50it/s] 59%|█████▊    | 58/99 [00:32<00:15,  2.62it/s] 60%|█████▉    | 59/99 [00:32<00:14,  2.67it/s] 61%|██████    | 60/99 [00:33<00:14,  2.68it/s] 62%|██████▏   | 61/99 [00:33<00:14,  2.59it/s] 63%|██████▎   | 62/99 [00:34<00:14,  2.49it/s] 64%|██████▎   | 63/99 [00:34<00:14,  2.41it/s] 65%|██████▍   | 64/99 [00:34<00:14,  2.35it/s] 66%|██████▌   | 65/99 [00:35<00:14,  2.34it/s] 67%|██████▋   | 66/99 [00:35<00:14,  2.33it/s] 68%|██████▊   | 67/99 [00:36<00:13,  2.39it/s] 69%|██████▊   | 68/99 [00:36<00:12,  2.45it/s] 70%|██████▉   | 69/99 [00:36<00:11,  2.57it/s] 71%|███████   | 70/99 [00:37<00:10,  2.67it/s] 72%|███████▏  | 71/99 [00:37<00:10,  2.80it/s] 73%|███████▎  | 72/99 [00:37<00:09,  2.92it/s] 74%|███████▎  | 73/99 [00:38<00:08,  3.00it/s] 75%|███████▍  | 74/99 [00:38<00:08,  3.11it/s] 76%|███████▌  | 75/99 [00:38<00:07,  3.16it/s] 77%|███████▋  | 76/99 [00:39<00:07,  3.27it/s] 78%|███████▊  | 77/99 [00:39<00:06,  3.31it/s] 79%|███████▉  | 78/99 [00:39<00:06,  3.44it/s] 80%|███████▉  | 79/99 [00:39<00:05,  3.74it/s] 81%|████████  | 80/99 [00:40<00:04,  3.92it/s] 82%|████████▏ | 81/99 [00:40<00:04,  3.90it/s] 83%|████████▎ | 82/99 [00:40<00:03,  4.28it/s] 84%|████████▍ | 83/99 [00:40<00:03,  4.59it/s] 85%|████████▍ | 84/99 [00:40<00:03,  4.83it/s] 86%|████████▌ | 85/99 [00:41<00:02,  5.02it/s] 87%|████████▋ | 86/99 [00:41<00:02,  5.16it/s] 88%|████████▊ | 87/99 [00:41<00:02,  5.26it/s] 89%|████████▉ | 88/99 [00:41<00:02,  5.31it/s] 90%|████████▉ | 89/99 [00:41<00:01,  5.37it/s] 91%|█████████ | 90/99 [00:41<00:01,  5.41it/s] 92%|█████████▏| 91/99 [00:42<00:01,  5.44it/s] 93%|█████████▎| 92/99 [00:42<00:01,  5.47it/s] 94%|█████████▍| 93/99 [00:42<00:01,  5.48it/s] 95%|█████████▍| 94/99 [00:42<00:00,  5.49it/s] 96%|█████████▌| 95/99 [00:42<00:00,  5.50it/s] 97%|█████████▋| 96/99 [00:43<00:00,  5.50it/s] 98%|█████████▊| 97/99 [00:43<00:00,  5.50it/s] 99%|█████████▉| 98/99 [00:43<00:00,  5.51it/s]100%|██████████| 99/99 [00:43<00:00,  5.51it/s]100%|██████████| 99/99 [00:43<00:00,  2.26it/s]
=> result
* total: 9,900
* correct: 7,808
* accuracy: 78.9%
* error: 21.1%
* macro_f1: 77.8%
+ for dataset in caltech101 sun397 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train_sdl.sh imagenet 1 0 main_tmp1_0.1sdl 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1_0.1sdl.yaml
dataset_config_file: configs/datasets/imagenet.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/imagenet/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime_sdl
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 16
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNet
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 30
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/imagenet/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime_sdl
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime_sdl
Loading trainer: RPO_prime_sdl
requested:ImageNet
Loading dataset: ImageNet
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/ImageNet/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  500
# train_x  8,000
# val      25,000
# test     25,000
---------  --------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/imagenet/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/30] batch [20/2000] time 0.578 (0.713) data 0.000 (0.060) loss 5.9648 (4.3603) lr 1.0000e-02 eta 11:52:44
epoch [1/30] batch [40/2000] time 0.584 (0.648) data 0.000 (0.030) loss 3.3672 (3.6566) lr 1.0000e-02 eta 10:47:39
epoch [1/30] batch [60/2000] time 0.578 (0.626) data 0.000 (0.020) loss 1.0791 (3.3503) lr 1.0000e-02 eta 10:25:25
epoch [1/30] batch [80/2000] time 0.579 (0.616) data 0.000 (0.015) loss 2.4590 (3.2889) lr 1.0000e-02 eta 10:15:27
epoch [1/30] batch [100/2000] time 0.580 (0.609) data 0.000 (0.012) loss 5.1367 (3.4152) lr 1.0000e-02 eta 10:08:28
epoch [1/30] batch [120/2000] time 0.573 (0.605) data 0.000 (0.010) loss 6.0391 (3.3903) lr 1.0000e-02 eta 10:03:37
epoch [1/30] batch [140/2000] time 0.579 (0.602) data 0.000 (0.009) loss 4.0586 (3.4342) lr 1.0000e-02 eta 10:00:21
epoch [1/30] batch [160/2000] time 0.586 (0.599) data 0.000 (0.008) loss 3.7188 (3.2799) lr 1.0000e-02 eta 9:57:50
epoch [1/30] batch [180/2000] time 0.606 (0.598) data 0.000 (0.007) loss 2.6855 (3.1538) lr 1.0000e-02 eta 9:56:10
epoch [1/30] batch [200/2000] time 0.613 (0.598) data 0.000 (0.006) loss 4.1367 (3.1808) lr 1.0000e-02 eta 9:55:30
epoch [1/30] batch [220/2000] time 0.597 (0.598) data 0.000 (0.006) loss 0.8628 (3.1656) lr 1.0000e-02 eta 9:55:40
epoch [1/30] batch [240/2000] time 0.597 (0.598) data 0.000 (0.005) loss 0.6816 (3.1404) lr 1.0000e-02 eta 9:55:48
epoch [1/30] batch [260/2000] time 0.612 (0.598) data 0.000 (0.005) loss 0.5278 (3.0424) lr 1.0000e-02 eta 9:55:48
epoch [1/30] batch [280/2000] time 0.599 (0.599) data 0.000 (0.005) loss 1.5693 (2.9858) lr 1.0000e-02 eta 9:56:31
epoch [1/30] batch [300/2000] time 0.597 (0.600) data 0.000 (0.004) loss 1.7803 (2.9590) lr 1.0000e-02 eta 9:56:33
epoch [1/30] batch [320/2000] time 0.600 (0.599) data 0.000 (0.004) loss 0.2007 (2.9621) lr 1.0000e-02 eta 9:56:17
epoch [1/30] batch [340/2000] time 0.600 (0.599) data 0.000 (0.004) loss 0.7666 (2.9027) lr 1.0000e-02 eta 9:56:00
epoch [1/30] batch [360/2000] time 0.594 (0.600) data 0.000 (0.004) loss 5.0781 (2.8899) lr 1.0000e-02 eta 9:56:00
epoch [1/30] batch [380/2000] time 0.594 (0.600) data 0.000 (0.003) loss 3.2246 (2.8973) lr 1.0000e-02 eta 9:55:48
epoch [1/30] batch [400/2000] time 0.605 (0.600) data 0.000 (0.003) loss 2.5137 (2.8501) lr 1.0000e-02 eta 9:55:36
epoch [1/30] batch [420/2000] time 0.608 (0.600) data 0.000 (0.003) loss 0.7754 (2.8144) lr 1.0000e-02 eta 9:55:41
epoch [1/30] batch [440/2000] time 0.596 (0.600) data 0.000 (0.003) loss 0.7183 (2.8144) lr 1.0000e-02 eta 9:55:30
epoch [1/30] batch [460/2000] time 0.596 (0.600) data 0.000 (0.003) loss 1.3984 (2.7836) lr 1.0000e-02 eta 9:55:20
epoch [1/30] batch [480/2000] time 0.595 (0.600) data 0.000 (0.003) loss 1.2734 (2.8269) lr 1.0000e-02 eta 9:55:05
epoch [1/30] batch [500/2000] time 0.596 (0.600) data 0.000 (0.003) loss 3.4355 (2.8844) lr 1.0000e-02 eta 9:54:57
epoch [1/30] batch [520/2000] time 0.598 (0.600) data 0.000 (0.003) loss 1.1611 (2.8620) lr 1.0000e-02 eta 9:54:43
epoch [1/30] batch [540/2000] time 0.596 (0.600) data 0.000 (0.002) loss 0.6284 (2.8583) lr 1.0000e-02 eta 9:54:28
epoch [1/30] batch [560/2000] time 0.605 (0.600) data 0.000 (0.002) loss 2.4863 (2.8661) lr 1.0000e-02 eta 9:54:16
epoch [1/30] batch [580/2000] time 0.606 (0.600) data 0.000 (0.002) loss 1.1162 (2.8751) lr 1.0000e-02 eta 9:54:04
epoch [1/30] batch [600/2000] time 0.602 (0.600) data 0.000 (0.002) loss 2.6738 (2.8596) lr 1.0000e-02 eta 9:53:59
epoch [1/30] batch [620/2000] time 0.666 (0.600) data 0.000 (0.002) loss 3.6836 (2.8639) lr 1.0000e-02 eta 9:53:53
epoch [1/30] batch [640/2000] time 0.594 (0.600) data 0.000 (0.002) loss 1.5664 (2.8668) lr 1.0000e-02 eta 9:53:44
epoch [1/30] batch [660/2000] time 0.604 (0.600) data 0.000 (0.002) loss 3.1719 (2.8562) lr 1.0000e-02 eta 9:53:35
epoch [1/30] batch [680/2000] time 0.598 (0.600) data 0.000 (0.002) loss 2.1934 (2.8573) lr 1.0000e-02 eta 9:53:24
epoch [1/30] batch [700/2000] time 0.655 (0.600) data 0.000 (0.002) loss 1.3037 (2.8589) lr 1.0000e-02 eta 9:53:20
epoch [1/30] batch [720/2000] time 0.595 (0.600) data 0.000 (0.002) loss 2.3281 (2.8587) lr 1.0000e-02 eta 9:53:06
epoch [1/30] batch [740/2000] time 0.614 (0.600) data 0.000 (0.002) loss 2.3926 (2.8549) lr 1.0000e-02 eta 9:53:05
epoch [1/30] batch [760/2000] time 0.667 (0.601) data 0.000 (0.002) loss 1.1348 (2.8652) lr 1.0000e-02 eta 9:52:56
epoch [1/30] batch [780/2000] time 0.595 (0.600) data 0.000 (0.002) loss 5.4688 (2.8773) lr 1.0000e-02 eta 9:52:40
epoch [1/30] batch [800/2000] time 0.608 (0.601) data 0.000 (0.002) loss 2.9434 (2.8905) lr 1.0000e-02 eta 9:52:30
epoch [1/30] batch [820/2000] time 0.597 (0.601) data 0.000 (0.002) loss 1.9277 (2.8986) lr 1.0000e-02 eta 9:52:21
epoch [1/30] batch [840/2000] time 0.603 (0.601) data 0.000 (0.002) loss 9.2266 (2.8975) lr 1.0000e-02 eta 9:52:12
epoch [1/30] batch [860/2000] time 0.599 (0.601) data 0.000 (0.002) loss 4.1797 (2.9045) lr 1.0000e-02 eta 9:52:00
epoch [1/30] batch [880/2000] time 0.598 (0.601) data 0.000 (0.002) loss 2.0586 (2.8964) lr 1.0000e-02 eta 9:51:49
epoch [1/30] batch [900/2000] time 0.590 (0.601) data 0.000 (0.002) loss 2.2344 (2.8869) lr 1.0000e-02 eta 9:51:42
epoch [1/30] batch [920/2000] time 0.600 (0.601) data 0.000 (0.002) loss 1.7725 (2.8819) lr 1.0000e-02 eta 9:51:30
epoch [1/30] batch [940/2000] time 0.595 (0.601) data 0.000 (0.002) loss 5.1172 (2.8918) lr 1.0000e-02 eta 9:51:20
epoch [1/30] batch [960/2000] time 0.604 (0.601) data 0.000 (0.002) loss 2.4746 (2.8914) lr 1.0000e-02 eta 9:51:07
epoch [1/30] batch [980/2000] time 0.596 (0.601) data 0.000 (0.001) loss 3.3145 (2.8828) lr 1.0000e-02 eta 9:50:51
epoch [1/30] batch [1000/2000] time 0.596 (0.601) data 0.000 (0.001) loss 0.9404 (2.8884) lr 1.0000e-02 eta 9:50:38
epoch [1/30] batch [1020/2000] time 0.594 (0.601) data 0.000 (0.001) loss 3.7598 (2.8941) lr 1.0000e-02 eta 9:50:27
epoch [1/30] batch [1040/2000] time 0.595 (0.601) data 0.000 (0.001) loss 2.2520 (2.8873) lr 1.0000e-02 eta 9:50:11
epoch [1/30] batch [1060/2000] time 0.600 (0.601) data 0.000 (0.001) loss 1.5156 (2.8838) lr 1.0000e-02 eta 9:49:57
epoch [1/30] batch [1080/2000] time 0.594 (0.601) data 0.000 (0.001) loss 4.9258 (2.8866) lr 1.0000e-02 eta 9:49:41
epoch [1/30] batch [1100/2000] time 0.595 (0.601) data 0.000 (0.001) loss 0.6470 (2.8923) lr 1.0000e-02 eta 9:49:35
epoch [1/30] batch [1120/2000] time 0.597 (0.601) data 0.000 (0.001) loss 1.8711 (2.8821) lr 1.0000e-02 eta 9:49:22
epoch [1/30] batch [1140/2000] time 0.599 (0.601) data 0.000 (0.001) loss 3.8867 (2.8784) lr 1.0000e-02 eta 9:49:11
epoch [1/30] batch [1160/2000] time 0.601 (0.601) data 0.000 (0.001) loss 2.5977 (2.8733) lr 1.0000e-02 eta 9:49:00
epoch [1/30] batch [1180/2000] time 0.598 (0.601) data 0.000 (0.001) loss 0.3035 (2.8655) lr 1.0000e-02 eta 9:48:46
epoch [1/30] batch [1200/2000] time 0.602 (0.601) data 0.000 (0.001) loss 3.4277 (2.8516) lr 1.0000e-02 eta 9:48:33
epoch [1/30] batch [1220/2000] time 0.592 (0.601) data 0.000 (0.001) loss 5.2305 (2.8437) lr 1.0000e-02 eta 9:48:23
epoch [1/30] batch [1240/2000] time 0.592 (0.601) data 0.000 (0.001) loss 5.6406 (2.8361) lr 1.0000e-02 eta 9:48:09
epoch [1/30] batch [1260/2000] time 0.593 (0.601) data 0.000 (0.001) loss 1.2178 (2.8352) lr 1.0000e-02 eta 9:47:55
epoch [1/30] batch [1280/2000] time 0.639 (0.601) data 0.000 (0.001) loss 4.6562 (2.8312) lr 1.0000e-02 eta 9:47:43
epoch [1/30] batch [1300/2000] time 0.596 (0.601) data 0.000 (0.001) loss 0.8691 (2.8214) lr 1.0000e-02 eta 9:47:33
epoch [1/30] batch [1320/2000] time 0.599 (0.601) data 0.000 (0.001) loss 4.9141 (2.8237) lr 1.0000e-02 eta 9:47:23
epoch [1/30] batch [1340/2000] time 0.601 (0.601) data 0.000 (0.001) loss 0.6548 (2.8243) lr 1.0000e-02 eta 9:47:08
epoch [1/30] batch [1360/2000] time 0.596 (0.601) data 0.000 (0.001) loss 3.5469 (2.8269) lr 1.0000e-02 eta 9:46:57
epoch [1/30] batch [1380/2000] time 0.599 (0.601) data 0.000 (0.001) loss 1.4707 (2.8358) lr 1.0000e-02 eta 9:46:44
epoch [1/30] batch [1400/2000] time 0.597 (0.601) data 0.000 (0.001) loss 1.1396 (2.8425) lr 1.0000e-02 eta 9:46:32
epoch [1/30] batch [1420/2000] time 0.605 (0.601) data 0.000 (0.001) loss 0.3821 (2.8500) lr 1.0000e-02 eta 9:46:18
epoch [1/30] batch [1440/2000] time 0.605 (0.601) data 0.000 (0.001) loss 2.6270 (2.8398) lr 1.0000e-02 eta 9:46:06
epoch [1/30] batch [1460/2000] time 0.601 (0.601) data 0.000 (0.001) loss 3.9512 (2.8403) lr 1.0000e-02 eta 9:45:53
epoch [1/30] batch [1480/2000] time 0.615 (0.601) data 0.000 (0.001) loss 1.9600 (2.8292) lr 1.0000e-02 eta 9:45:41
epoch [1/30] batch [1500/2000] time 0.593 (0.600) data 0.000 (0.001) loss 3.3105 (2.8339) lr 1.0000e-02 eta 9:45:28
epoch [1/30] batch [1520/2000] time 0.615 (0.600) data 0.000 (0.001) loss 1.1064 (2.8310) lr 1.0000e-02 eta 9:45:16
epoch [1/30] batch [1540/2000] time 0.625 (0.601) data 0.000 (0.001) loss 0.6709 (2.8213) lr 1.0000e-02 eta 9:45:06
epoch [1/30] batch [1560/2000] time 0.599 (0.601) data 0.000 (0.001) loss 1.6904 (2.8171) lr 1.0000e-02 eta 9:44:58
epoch [1/30] batch [1580/2000] time 0.596 (0.601) data 0.000 (0.001) loss 3.9355 (2.8261) lr 1.0000e-02 eta 9:44:47
epoch [1/30] batch [1600/2000] time 0.597 (0.601) data 0.000 (0.001) loss 2.6152 (2.8271) lr 1.0000e-02 eta 9:44:33
epoch [1/30] batch [1620/2000] time 0.596 (0.601) data 0.000 (0.001) loss 3.4121 (2.8264) lr 1.0000e-02 eta 9:44:21
epoch [1/30] batch [1640/2000] time 0.596 (0.601) data 0.000 (0.001) loss 1.5527 (2.8217) lr 1.0000e-02 eta 9:44:10
epoch [1/30] batch [1660/2000] time 0.596 (0.601) data 0.000 (0.001) loss 2.5078 (2.8215) lr 1.0000e-02 eta 9:43:58
epoch [1/30] batch [1680/2000] time 0.600 (0.601) data 0.000 (0.001) loss 1.5840 (2.8174) lr 1.0000e-02 eta 9:43:48
epoch [1/30] batch [1700/2000] time 0.602 (0.601) data 0.000 (0.001) loss 4.0547 (2.8143) lr 1.0000e-02 eta 9:43:36
epoch [1/30] batch [1720/2000] time 0.598 (0.601) data 0.000 (0.001) loss 4.1172 (2.8042) lr 1.0000e-02 eta 9:43:24
epoch [1/30] batch [1740/2000] time 0.598 (0.601) data 0.000 (0.001) loss 1.3789 (2.8091) lr 1.0000e-02 eta 9:43:12
epoch [1/30] batch [1760/2000] time 0.591 (0.601) data 0.000 (0.001) loss 2.6270 (2.8102) lr 1.0000e-02 eta 9:43:00
epoch [1/30] batch [1780/2000] time 0.604 (0.601) data 0.000 (0.001) loss 0.2832 (2.8115) lr 1.0000e-02 eta 9:42:48
epoch [1/30] batch [1800/2000] time 0.600 (0.601) data 0.000 (0.001) loss 0.7500 (2.8128) lr 1.0000e-02 eta 9:42:35
epoch [1/30] batch [1820/2000] time 0.601 (0.601) data 0.000 (0.001) loss 3.1641 (2.8142) lr 1.0000e-02 eta 9:42:24
epoch [1/30] batch [1840/2000] time 0.601 (0.601) data 0.000 (0.001) loss 1.8867 (2.8150) lr 1.0000e-02 eta 9:42:14
epoch [1/30] batch [1860/2000] time 0.592 (0.601) data 0.000 (0.001) loss 1.8916 (2.8167) lr 1.0000e-02 eta 9:42:00
epoch [1/30] batch [1880/2000] time 0.600 (0.601) data 0.000 (0.001) loss 1.2334 (2.8141) lr 1.0000e-02 eta 9:41:47
epoch [1/30] batch [1900/2000] time 0.594 (0.601) data 0.000 (0.001) loss 0.3625 (2.8158) lr 1.0000e-02 eta 9:41:34
epoch [1/30] batch [1920/2000] time 0.598 (0.601) data 0.000 (0.001) loss 1.3867 (2.8194) lr 1.0000e-02 eta 9:41:22
epoch [1/30] batch [1940/2000] time 0.597 (0.601) data 0.000 (0.001) loss 1.4160 (2.8175) lr 1.0000e-02 eta 9:41:09
epoch [1/30] batch [1960/2000] time 0.592 (0.601) data 0.000 (0.001) loss 5.9258 (2.8168) lr 1.0000e-02 eta 9:40:57
epoch [1/30] batch [1980/2000] time 0.592 (0.601) data 0.000 (0.001) loss 4.8984 (2.8179) lr 1.0000e-02 eta 9:40:41
epoch [1/30] batch [2000/2000] time 0.589 (0.600) data 0.000 (0.001) loss 1.8467 (2.8193) lr 9.9726e-03 eta 9:40:23
Evaluate on the *val* set
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:03<13:14,  3.19s/it]  1%|          | 2/250 [00:03<07:20,  1.77s/it]  1%|          | 3/250 [00:04<04:44,  1.15s/it]  2%|▏         | 4/250 [00:04<03:26,  1.19it/s]  2%|▏         | 5/250 [00:05<02:45,  1.48it/s]  2%|▏         | 6/250 [00:05<02:19,  1.74it/s]  3%|▎         | 7/250 [00:05<02:01,  2.00it/s]  3%|▎         | 8/250 [00:06<01:52,  2.15it/s]  4%|▎         | 9/250 [00:06<01:44,  2.31it/s]  4%|▍         | 10/250 [00:06<01:38,  2.44it/s]  4%|▍         | 11/250 [00:07<01:34,  2.52it/s]  5%|▍         | 12/250 [00:07<01:33,  2.55it/s]  5%|▌         | 13/250 [00:08<01:30,  2.61it/s]  6%|▌         | 14/250 [00:08<01:29,  2.64it/s]  6%|▌         | 15/250 [00:08<01:26,  2.71it/s]  6%|▋         | 16/250 [00:09<01:26,  2.72it/s]  7%|▋         | 17/250 [00:09<01:26,  2.69it/s]  7%|▋         | 18/250 [00:09<01:24,  2.73it/s]  8%|▊         | 19/250 [00:10<01:25,  2.71it/s]  8%|▊         | 20/250 [00:10<01:24,  2.71it/s]  8%|▊         | 21/250 [00:10<01:23,  2.75it/s]  9%|▉         | 22/250 [00:11<01:23,  2.73it/s]  9%|▉         | 23/250 [00:11<01:22,  2.77it/s] 10%|▉         | 24/250 [00:12<01:23,  2.71it/s] 10%|█         | 25/250 [00:12<01:22,  2.73it/s] 10%|█         | 26/250 [00:12<01:23,  2.69it/s] 11%|█         | 27/250 [00:13<01:22,  2.72it/s] 11%|█         | 28/250 [00:13<01:20,  2.74it/s] 12%|█▏        | 29/250 [00:13<01:20,  2.76it/s] 12%|█▏        | 30/250 [00:14<01:20,  2.74it/s] 12%|█▏        | 31/250 [00:14<01:19,  2.75it/s] 13%|█▎        | 32/250 [00:15<01:19,  2.75it/s] 13%|█▎        | 33/250 [00:15<01:19,  2.74it/s] 14%|█▎        | 34/250 [00:15<01:19,  2.73it/s] 14%|█▍        | 35/250 [00:16<01:18,  2.73it/s] 14%|█▍        | 36/250 [00:16<01:17,  2.75it/s] 15%|█▍        | 37/250 [00:16<01:18,  2.72it/s] 15%|█▌        | 38/250 [00:17<01:18,  2.69it/s] 16%|█▌        | 39/250 [00:17<01:17,  2.71it/s] 16%|█▌        | 40/250 [00:17<01:16,  2.74it/s] 16%|█▋        | 41/250 [00:18<01:16,  2.74it/s] 17%|█▋        | 42/250 [00:18<01:15,  2.76it/s] 17%|█▋        | 43/250 [00:19<01:15,  2.76it/s] 18%|█▊        | 44/250 [00:19<01:13,  2.81it/s] 18%|█▊        | 45/250 [00:19<01:12,  2.81it/s] 18%|█▊        | 46/250 [00:20<01:12,  2.80it/s] 19%|█▉        | 47/250 [00:20<01:13,  2.77it/s] 19%|█▉        | 48/250 [00:20<01:12,  2.77it/s] 20%|█▉        | 49/250 [00:21<01:12,  2.76it/s] 20%|██        | 50/250 [00:21<01:12,  2.77it/s] 20%|██        | 51/250 [00:21<01:13,  2.71it/s] 21%|██        | 52/250 [00:22<01:12,  2.75it/s] 21%|██        | 53/250 [00:22<01:12,  2.72it/s] 22%|██▏       | 54/250 [00:23<01:12,  2.72it/s] 22%|██▏       | 55/250 [00:23<01:12,  2.69it/s] 22%|██▏       | 56/250 [00:23<01:10,  2.74it/s] 23%|██▎       | 57/250 [00:24<01:10,  2.73it/s] 23%|██▎       | 58/250 [00:24<01:09,  2.76it/s] 24%|██▎       | 59/250 [00:24<01:09,  2.74it/s] 24%|██▍       | 60/250 [00:25<01:10,  2.68it/s] 24%|██▍       | 61/250 [00:25<01:10,  2.70it/s] 25%|██▍       | 62/250 [00:25<01:09,  2.72it/s] 25%|██▌       | 63/250 [00:26<01:08,  2.72it/s] 26%|██▌       | 64/250 [00:26<01:09,  2.69it/s] 26%|██▌       | 65/250 [00:27<01:08,  2.71it/s] 26%|██▋       | 66/250 [00:27<01:07,  2.71it/s] 27%|██▋       | 67/250 [00:27<01:07,  2.72it/s] 27%|██▋       | 68/250 [00:28<01:07,  2.69it/s] 28%|██▊       | 69/250 [00:28<01:06,  2.74it/s] 28%|██▊       | 70/250 [00:28<01:05,  2.75it/s] 28%|██▊       | 71/250 [00:29<01:05,  2.75it/s] 29%|██▉       | 72/250 [00:29<01:05,  2.72it/s] 29%|██▉       | 73/250 [00:30<01:05,  2.71it/s] 30%|██▉       | 74/250 [00:30<01:04,  2.72it/s] 30%|███       | 75/250 [00:30<01:05,  2.67it/s] 30%|███       | 76/250 [00:31<01:03,  2.73it/s] 31%|███       | 77/250 [00:31<01:04,  2.69it/s] 31%|███       | 78/250 [00:31<01:02,  2.73it/s] 32%|███▏      | 79/250 [00:32<01:02,  2.74it/s] 32%|███▏      | 80/250 [00:32<01:00,  2.81it/s] 32%|███▏      | 81/250 [00:32<01:00,  2.78it/s] 33%|███▎      | 82/250 [00:33<00:59,  2.82it/s] 33%|███▎      | 83/250 [00:33<01:00,  2.77it/s] 34%|███▎      | 84/250 [00:33<00:58,  2.82it/s] 34%|███▍      | 85/250 [00:34<00:56,  2.91it/s] 34%|███▍      | 86/250 [00:34<00:57,  2.86it/s] 35%|███▍      | 87/250 [00:35<00:57,  2.81it/s] 35%|███▌      | 88/250 [00:35<00:58,  2.78it/s] 36%|███▌      | 89/250 [00:35<00:57,  2.78it/s] 36%|███▌      | 90/250 [00:36<00:57,  2.76it/s] 36%|███▋      | 91/250 [00:36<00:57,  2.77it/s] 37%|███▋      | 92/250 [00:36<00:56,  2.78it/s] 37%|███▋      | 93/250 [00:37<00:56,  2.78it/s] 38%|███▊      | 94/250 [00:37<00:57,  2.71it/s] 38%|███▊      | 95/250 [00:37<00:57,  2.67it/s] 38%|███▊      | 96/250 [00:38<00:56,  2.70it/s] 39%|███▉      | 97/250 [00:38<00:56,  2.71it/s] 39%|███▉      | 98/250 [00:39<00:56,  2.70it/s] 40%|███▉      | 99/250 [00:39<00:56,  2.69it/s] 40%|████      | 100/250 [00:39<00:54,  2.74it/s] 40%|████      | 101/250 [00:40<00:54,  2.76it/s] 41%|████      | 102/250 [00:40<00:53,  2.75it/s] 41%|████      | 103/250 [00:40<00:53,  2.74it/s] 42%|████▏     | 104/250 [00:41<00:53,  2.74it/s] 42%|████▏     | 105/250 [00:41<00:52,  2.74it/s] 42%|████▏     | 106/250 [00:41<00:52,  2.75it/s] 43%|████▎     | 107/250 [00:42<00:52,  2.71it/s] 43%|████▎     | 108/250 [00:42<00:52,  2.71it/s] 44%|████▎     | 109/250 [00:43<00:52,  2.69it/s] 44%|████▍     | 110/250 [00:43<00:51,  2.71it/s] 44%|████▍     | 111/250 [00:43<00:51,  2.71it/s] 45%|████▍     | 112/250 [00:44<00:50,  2.72it/s] 45%|████▌     | 113/250 [00:44<00:50,  2.69it/s] 46%|████▌     | 114/250 [00:44<00:50,  2.69it/s] 46%|████▌     | 115/250 [00:45<00:49,  2.71it/s] 46%|████▋     | 116/250 [00:45<00:49,  2.71it/s] 47%|████▋     | 117/250 [00:46<00:48,  2.73it/s] 47%|████▋     | 118/250 [00:46<00:49,  2.69it/s] 48%|████▊     | 119/250 [00:46<00:48,  2.71it/s] 48%|████▊     | 120/250 [00:47<00:47,  2.73it/s] 48%|████▊     | 121/250 [00:47<00:46,  2.76it/s] 49%|████▉     | 122/250 [00:47<00:46,  2.73it/s] 49%|████▉     | 123/250 [00:48<00:46,  2.75it/s] 50%|████▉     | 124/250 [00:48<00:46,  2.70it/s] 50%|█████     | 125/250 [00:48<00:45,  2.72it/s] 50%|█████     | 126/250 [00:49<00:45,  2.71it/s] 51%|█████     | 127/250 [00:49<00:45,  2.68it/s] 51%|█████     | 128/250 [00:50<00:45,  2.67it/s] 52%|█████▏    | 129/250 [00:50<00:45,  2.65it/s] 52%|█████▏    | 130/250 [00:50<00:45,  2.64it/s] 52%|█████▏    | 131/250 [00:51<00:45,  2.61it/s] 53%|█████▎    | 132/250 [00:51<00:44,  2.63it/s] 53%|█████▎    | 133/250 [00:52<00:43,  2.67it/s] 54%|█████▎    | 134/250 [00:52<00:44,  2.63it/s] 54%|█████▍    | 135/250 [00:52<00:43,  2.64it/s] 54%|█████▍    | 136/250 [00:53<00:43,  2.64it/s] 55%|█████▍    | 137/250 [00:53<00:42,  2.65it/s] 55%|█████▌    | 138/250 [00:53<00:41,  2.70it/s] 56%|█████▌    | 139/250 [00:54<00:40,  2.73it/s] 56%|█████▌    | 140/250 [00:54<00:40,  2.74it/s] 56%|█████▋    | 141/250 [00:54<00:39,  2.77it/s] 57%|█████▋    | 142/250 [00:55<00:39,  2.74it/s] 57%|█████▋    | 143/250 [00:55<00:38,  2.75it/s] 58%|█████▊    | 144/250 [00:56<00:37,  2.80it/s] 58%|█████▊    | 145/250 [00:56<00:37,  2.77it/s] 58%|█████▊    | 146/250 [00:56<00:37,  2.77it/s] 59%|█████▉    | 147/250 [00:57<00:37,  2.77it/s] 59%|█████▉    | 148/250 [00:57<00:37,  2.71it/s] 60%|█████▉    | 149/250 [00:57<00:37,  2.71it/s] 60%|██████    | 150/250 [00:58<00:37,  2.69it/s] 60%|██████    | 151/250 [00:58<00:36,  2.68it/s] 61%|██████    | 152/250 [00:59<00:35,  2.72it/s] 61%|██████    | 153/250 [00:59<00:35,  2.73it/s] 62%|██████▏   | 154/250 [00:59<00:35,  2.71it/s] 62%|██████▏   | 155/250 [01:00<00:34,  2.72it/s] 62%|██████▏   | 156/250 [01:00<00:34,  2.72it/s] 63%|██████▎   | 157/250 [01:00<00:34,  2.69it/s] 63%|██████▎   | 158/250 [01:01<00:34,  2.70it/s] 64%|██████▎   | 159/250 [01:01<00:33,  2.70it/s] 64%|██████▍   | 160/250 [01:01<00:33,  2.73it/s] 64%|██████▍   | 161/250 [01:02<00:33,  2.66it/s] 65%|██████▍   | 162/250 [01:02<00:33,  2.61it/s] 65%|██████▌   | 163/250 [01:03<00:32,  2.64it/s] 66%|██████▌   | 164/250 [01:03<00:32,  2.68it/s] 66%|██████▌   | 165/250 [01:03<00:31,  2.68it/s] 66%|██████▋   | 166/250 [01:04<00:31,  2.69it/s] 67%|██████▋   | 167/250 [01:04<00:30,  2.70it/s] 67%|██████▋   | 168/250 [01:04<00:30,  2.72it/s] 68%|██████▊   | 169/250 [01:05<00:30,  2.70it/s] 68%|██████▊   | 170/250 [01:05<00:29,  2.67it/s] 68%|██████▊   | 171/250 [01:06<00:29,  2.70it/s] 69%|██████▉   | 172/250 [01:06<00:29,  2.68it/s] 69%|██████▉   | 173/250 [01:06<00:28,  2.71it/s] 70%|██████▉   | 174/250 [01:07<00:27,  2.73it/s] 70%|███████   | 175/250 [01:07<00:27,  2.74it/s] 70%|███████   | 176/250 [01:07<00:27,  2.69it/s] 71%|███████   | 177/250 [01:08<00:26,  2.72it/s] 71%|███████   | 178/250 [01:08<00:26,  2.75it/s] 72%|███████▏  | 179/250 [01:09<00:25,  2.74it/s] 72%|███████▏  | 180/250 [01:09<00:25,  2.79it/s] 72%|███████▏  | 181/250 [01:09<00:24,  2.79it/s] 73%|███████▎  | 182/250 [01:10<00:24,  2.74it/s] 73%|███████▎  | 183/250 [01:10<00:25,  2.66it/s] 74%|███████▎  | 184/250 [01:10<00:24,  2.71it/s] 74%|███████▍  | 185/250 [01:11<00:23,  2.74it/s] 74%|███████▍  | 186/250 [01:11<00:23,  2.77it/s] 75%|███████▍  | 187/250 [01:11<00:22,  2.75it/s] 75%|███████▌  | 188/250 [01:12<00:22,  2.79it/s] 76%|███████▌  | 189/250 [01:12<00:21,  2.78it/s] 76%|███████▌  | 190/250 [01:12<00:21,  2.75it/s] 76%|███████▋  | 191/250 [01:13<00:21,  2.75it/s] 77%|███████▋  | 192/250 [01:13<00:21,  2.74it/s] 77%|███████▋  | 193/250 [01:14<00:20,  2.77it/s] 78%|███████▊  | 194/250 [01:14<00:20,  2.72it/s] 78%|███████▊  | 195/250 [01:14<00:20,  2.73it/s] 78%|███████▊  | 196/250 [01:15<00:19,  2.73it/s] 79%|███████▉  | 197/250 [01:15<00:19,  2.69it/s] 79%|███████▉  | 198/250 [01:15<00:19,  2.68it/s] 80%|███████▉  | 199/250 [01:16<00:19,  2.68it/s] 80%|████████  | 200/250 [01:16<00:18,  2.71it/s] 80%|████████  | 201/250 [01:17<00:18,  2.70it/s] 81%|████████  | 202/250 [01:17<00:18,  2.66it/s] 81%|████████  | 203/250 [01:17<00:17,  2.67it/s] 82%|████████▏ | 204/250 [01:18<00:16,  2.71it/s] 82%|████████▏ | 205/250 [01:18<00:16,  2.69it/s] 82%|████████▏ | 206/250 [01:18<00:16,  2.69it/s] 83%|████████▎ | 207/250 [01:19<00:15,  2.71it/s] 83%|████████▎ | 208/250 [01:19<00:15,  2.73it/s] 84%|████████▎ | 209/250 [01:20<00:15,  2.72it/s] 84%|████████▍ | 210/250 [01:20<00:14,  2.72it/s] 84%|████████▍ | 211/250 [01:20<00:14,  2.72it/s] 85%|████████▍ | 212/250 [01:21<00:14,  2.71it/s] 85%|████████▌ | 213/250 [01:21<00:13,  2.74it/s] 86%|████████▌ | 214/250 [01:21<00:13,  2.77it/s] 86%|████████▌ | 215/250 [01:22<00:12,  2.80it/s] 86%|████████▋ | 216/250 [01:22<00:12,  2.79it/s] 87%|████████▋ | 217/250 [01:22<00:12,  2.74it/s] 87%|████████▋ | 218/250 [01:23<00:11,  2.76it/s] 88%|████████▊ | 219/250 [01:23<00:11,  2.80it/s] 88%|████████▊ | 220/250 [01:23<00:10,  2.87it/s] 88%|████████▊ | 221/250 [01:24<00:09,  2.92it/s] 89%|████████▉ | 222/250 [01:24<00:09,  3.04it/s] 89%|████████▉ | 223/250 [01:24<00:08,  3.13it/s] 90%|████████▉ | 224/250 [01:25<00:08,  3.20it/s] 90%|█████████ | 225/250 [01:25<00:07,  3.24it/s] 90%|█████████ | 226/250 [01:25<00:07,  3.28it/s] 91%|█████████ | 227/250 [01:26<00:06,  3.30it/s] 91%|█████████ | 228/250 [01:26<00:06,  3.32it/s] 92%|█████████▏| 229/250 [01:26<00:06,  3.31it/s] 92%|█████████▏| 230/250 [01:26<00:06,  3.32it/s] 92%|█████████▏| 231/250 [01:27<00:05,  3.33it/s] 93%|█████████▎| 232/250 [01:27<00:05,  3.34it/s] 93%|█████████▎| 233/250 [01:27<00:05,  3.34it/s] 94%|█████████▎| 234/250 [01:28<00:04,  3.35it/s] 94%|█████████▍| 235/250 [01:28<00:04,  3.35it/s] 94%|█████████▍| 236/250 [01:28<00:04,  3.35it/s] 95%|█████████▍| 237/250 [01:29<00:03,  3.35it/s] 95%|█████████▌| 238/250 [01:29<00:03,  3.35it/s] 96%|█████████▌| 239/250 [01:29<00:03,  3.35it/s] 96%|█████████▌| 240/250 [01:29<00:02,  3.35it/s] 96%|█████████▋| 241/250 [01:30<00:02,  3.35it/s] 97%|█████████▋| 242/250 [01:30<00:02,  3.35it/s] 97%|█████████▋| 243/250 [01:30<00:02,  3.35it/s] 98%|█████████▊| 244/250 [01:31<00:01,  3.33it/s] 98%|█████████▊| 245/250 [01:31<00:01,  3.33it/s] 98%|█████████▊| 246/250 [01:31<00:01,  3.33it/s] 99%|█████████▉| 247/250 [01:32<00:00,  3.33it/s] 99%|█████████▉| 248/250 [01:32<00:00,  3.34it/s]100%|█████████▉| 249/250 [01:32<00:00,  3.34it/s]100%|██████████| 250/250 [01:32<00:00,  3.34it/s]100%|██████████| 250/250 [01:33<00:00,  2.69it/s]=> result
* total: 25,000
* correct: 18,957
* accuracy: 75.8%
* error: 24.2%
* macro_f1: 75.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/imagenet/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [2/30] batch [20/2000] time 0.596 (0.646) data 0.000 (0.037) loss 1.6533 (2.7099) lr 9.9726e-03 eta 10:23:59
epoch [2/30] batch [40/2000] time 0.596 (0.622) data 0.000 (0.019) loss 0.9248 (2.7392) lr 9.9726e-03 eta 10:01:07
epoch [2/30] batch [60/2000] time 0.599 (0.616) data 0.000 (0.013) loss 3.4141 (2.9117) lr 9.9726e-03 eta 9:55:04
epoch [2/30] batch [80/2000] time 0.603 (0.614) data 0.000 (0.010) loss 2.2637 (3.0041) lr 9.9726e-03 eta 9:52:46
epoch [2/30] batch [100/2000] time 0.608 (0.611) data 0.000 (0.008) loss 2.1699 (2.7753) lr 9.9726e-03 eta 9:49:58
epoch [2/30] batch [120/2000] time 0.601 (0.609) data 0.000 (0.006) loss 0.4995 (2.6679) lr 9.9726e-03 eta 9:47:47
epoch [2/30] batch [140/2000] time 0.600 (0.608) data 0.000 (0.006) loss 0.8394 (2.6116) lr 9.9726e-03 eta 9:46:30
epoch [2/30] batch [160/2000] time 0.616 (0.608) data 0.000 (0.005) loss 3.8750 (2.6111) lr 9.9726e-03 eta 9:45:49
epoch [2/30] batch [180/2000] time 0.599 (0.607) data 0.000 (0.004) loss 8.1406 (2.6491) lr 9.9726e-03 eta 9:44:57
epoch [2/30] batch [200/2000] time 0.628 (0.607) data 0.000 (0.004) loss 3.5820 (2.6550) lr 9.9726e-03 eta 9:44:17
epoch [2/30] batch [220/2000] time 0.593 (0.606) data 0.000 (0.004) loss 1.8135 (2.6542) lr 9.9726e-03 eta 9:43:43
epoch [2/30] batch [240/2000] time 0.600 (0.606) data 0.000 (0.003) loss 4.4453 (2.5832) lr 9.9726e-03 eta 9:42:54
epoch [2/30] batch [260/2000] time 0.605 (0.605) data 0.000 (0.003) loss 2.2734 (2.6114) lr 9.9726e-03 eta 9:42:16
epoch [2/30] batch [280/2000] time 0.595 (0.605) data 0.000 (0.003) loss 0.4363 (2.6523) lr 9.9726e-03 eta 9:42:02
epoch [2/30] batch [300/2000] time 0.607 (0.605) data 0.000 (0.003) loss 3.1250 (2.6545) lr 9.9726e-03 eta 9:41:31
epoch [2/30] batch [320/2000] time 0.597 (0.604) data 0.000 (0.003) loss 0.6904 (2.6649) lr 9.9726e-03 eta 9:40:58
epoch [2/30] batch [340/2000] time 0.601 (0.604) data 0.000 (0.002) loss 1.0479 (2.6553) lr 9.9726e-03 eta 9:40:41
epoch [2/30] batch [360/2000] time 0.602 (0.604) data 0.000 (0.002) loss 4.0938 (2.6472) lr 9.9726e-03 eta 9:40:10
epoch [2/30] batch [380/2000] time 0.602 (0.604) data 0.000 (0.002) loss 2.5977 (2.6528) lr 9.9726e-03 eta 9:39:46
epoch [2/30] batch [400/2000] time 0.616 (0.604) data 0.000 (0.002) loss 7.4453 (2.6675) lr 9.9726e-03 eta 9:39:36
epoch [2/30] batch [420/2000] time 0.596 (0.604) data 0.000 (0.002) loss 1.5078 (2.6590) lr 9.9726e-03 eta 9:39:20
epoch [2/30] batch [440/2000] time 0.595 (0.604) data 0.000 (0.002) loss 1.7266 (2.6268) lr 9.9726e-03 eta 9:39:01
epoch [2/30] batch [460/2000] time 0.600 (0.603) data 0.000 (0.002) loss 5.2031 (2.6433) lr 9.9726e-03 eta 9:38:38
epoch [2/30] batch [480/2000] time 0.597 (0.603) data 0.000 (0.002) loss 2.6621 (2.6299) lr 9.9726e-03 eta 9:38:23
epoch [2/30] batch [500/2000] time 0.600 (0.603) data 0.000 (0.002) loss 1.6904 (2.6147) lr 9.9726e-03 eta 9:38:07
epoch [2/30] batch [520/2000] time 0.599 (0.603) data 0.000 (0.002) loss 2.7363 (2.6191) lr 9.9726e-03 eta 9:37:50
epoch [2/30] batch [540/2000] time 0.599 (0.603) data 0.000 (0.002) loss 3.9004 (2.6450) lr 9.9726e-03 eta 9:37:26
epoch [2/30] batch [560/2000] time 0.595 (0.603) data 0.000 (0.002) loss 3.2285 (2.6346) lr 9.9726e-03 eta 9:37:19
epoch [2/30] batch [580/2000] time 0.601 (0.603) data 0.000 (0.002) loss 2.8672 (2.6322) lr 9.9726e-03 eta 9:37:01
epoch [2/30] batch [600/2000] time 0.601 (0.603) data 0.000 (0.002) loss 1.2520 (2.6308) lr 9.9726e-03 eta 9:36:43
epoch [2/30] batch [620/2000] time 0.608 (0.603) data 0.000 (0.001) loss 1.0381 (2.6219) lr 9.9726e-03 eta 9:36:33
epoch [2/30] batch [640/2000] time 0.596 (0.603) data 0.000 (0.001) loss 5.8203 (2.6002) lr 9.9726e-03 eta 9:36:18
epoch [2/30] batch [660/2000] time 0.634 (0.603) data 0.000 (0.001) loss 0.5142 (2.6025) lr 9.9726e-03 eta 9:36:03
epoch [2/30] batch [680/2000] time 0.598 (0.603) data 0.000 (0.001) loss 2.6797 (2.6123) lr 9.9726e-03 eta 9:35:53
epoch [2/30] batch [700/2000] time 0.611 (0.603) data 0.000 (0.001) loss 0.5254 (2.6002) lr 9.9726e-03 eta 9:35:34
epoch [2/30] batch [720/2000] time 0.605 (0.603) data 0.000 (0.001) loss 2.6367 (2.6270) lr 9.9726e-03 eta 9:35:17
epoch [2/30] batch [740/2000] time 0.605 (0.602) data 0.000 (0.001) loss 2.8828 (2.6467) lr 9.9726e-03 eta 9:34:57
epoch [2/30] batch [760/2000] time 0.592 (0.603) data 0.000 (0.001) loss 0.9795 (2.6459) lr 9.9726e-03 eta 9:34:51
epoch [2/30] batch [780/2000] time 0.594 (0.603) data 0.000 (0.001) loss 0.8892 (2.6481) lr 9.9726e-03 eta 9:34:36
epoch [2/30] batch [800/2000] time 0.604 (0.602) data 0.000 (0.001) loss 1.8701 (2.6591) lr 9.9726e-03 eta 9:34:20
epoch [2/30] batch [820/2000] time 0.597 (0.603) data 0.000 (0.001) loss 3.1191 (2.6613) lr 9.9726e-03 eta 9:34:17
epoch [2/30] batch [840/2000] time 0.598 (0.603) data 0.000 (0.001) loss 0.7427 (2.6597) lr 9.9726e-03 eta 9:34:03
epoch [2/30] batch [860/2000] time 0.600 (0.603) data 0.000 (0.001) loss 5.0781 (2.6455) lr 9.9726e-03 eta 9:33:47
epoch [2/30] batch [880/2000] time 0.608 (0.603) data 0.000 (0.001) loss 1.1045 (2.6509) lr 9.9726e-03 eta 9:33:40
epoch [2/30] batch [900/2000] time 0.595 (0.603) data 0.000 (0.001) loss 3.1621 (2.6515) lr 9.9726e-03 eta 9:33:29
epoch [2/30] batch [920/2000] time 0.602 (0.603) data 0.000 (0.001) loss 5.1328 (2.6484) lr 9.9726e-03 eta 9:33:13
epoch [2/30] batch [940/2000] time 0.597 (0.602) data 0.000 (0.001) loss 1.3281 (2.6501) lr 9.9726e-03 eta 9:32:58
epoch [2/30] batch [960/2000] time 0.606 (0.603) data 0.000 (0.001) loss 1.2227 (2.6595) lr 9.9726e-03 eta 9:32:46
epoch [2/30] batch [980/2000] time 0.592 (0.602) data 0.000 (0.001) loss 5.4609 (2.6652) lr 9.9726e-03 eta 9:32:29
epoch [2/30] batch [1000/2000] time 0.639 (0.602) data 0.000 (0.001) loss 1.5166 (2.6699) lr 9.9726e-03 eta 9:32:15
epoch [2/30] batch [1020/2000] time 0.608 (0.602) data 0.000 (0.001) loss 5.6953 (2.6754) lr 9.9726e-03 eta 9:32:07
epoch [2/30] batch [1040/2000] time 0.598 (0.602) data 0.000 (0.001) loss 1.2070 (2.6759) lr 9.9726e-03 eta 9:31:54
epoch [2/30] batch [1060/2000] time 0.595 (0.602) data 0.000 (0.001) loss 3.9414 (2.6789) lr 9.9726e-03 eta 9:31:41
epoch [2/30] batch [1080/2000] time 0.599 (0.602) data 0.000 (0.001) loss 0.4165 (2.6735) lr 9.9726e-03 eta 9:31:23
epoch [2/30] batch [1100/2000] time 0.606 (0.602) data 0.000 (0.001) loss 2.6973 (2.6843) lr 9.9726e-03 eta 9:31:11
epoch [2/30] batch [1120/2000] time 0.593 (0.602) data 0.000 (0.001) loss 4.7227 (2.6810) lr 9.9726e-03 eta 9:30:57
epoch [2/30] batch [1140/2000] time 0.602 (0.602) data 0.000 (0.001) loss 4.3867 (2.6864) lr 9.9726e-03 eta 9:30:44
epoch [2/30] batch [1160/2000] time 0.598 (0.602) data 0.000 (0.001) loss 0.8975 (2.6796) lr 9.9726e-03 eta 9:30:28
epoch [2/30] batch [1180/2000] time 0.597 (0.602) data 0.000 (0.001) loss 2.9434 (2.6832) lr 9.9726e-03 eta 9:30:17
epoch [2/30] batch [1200/2000] time 0.603 (0.602) data 0.000 (0.001) loss 3.4629 (2.6901) lr 9.9726e-03 eta 9:30:01
epoch [2/30] batch [1220/2000] time 0.611 (0.602) data 0.000 (0.001) loss 2.2559 (2.6857) lr 9.9726e-03 eta 9:29:53
epoch [2/30] batch [1240/2000] time 0.606 (0.602) data 0.000 (0.001) loss 2.3496 (2.6862) lr 9.9726e-03 eta 9:29:39
epoch [2/30] batch [1260/2000] time 0.594 (0.602) data 0.000 (0.001) loss 1.5352 (2.6824) lr 9.9726e-03 eta 9:29:24
epoch [2/30] batch [1280/2000] time 0.637 (0.602) data 0.000 (0.001) loss 1.0176 (2.6849) lr 9.9726e-03 eta 9:29:10
epoch [2/30] batch [1300/2000] time 0.598 (0.602) data 0.000 (0.001) loss 0.9951 (2.6769) lr 9.9726e-03 eta 9:29:01
epoch [2/30] batch [1320/2000] time 0.597 (0.602) data 0.000 (0.001) loss 5.2617 (2.6763) lr 9.9726e-03 eta 9:28:49
epoch [2/30] batch [1340/2000] time 0.600 (0.602) data 0.000 (0.001) loss 1.7412 (2.6698) lr 9.9726e-03 eta 9:28:38
epoch [2/30] batch [1360/2000] time 0.597 (0.602) data 0.000 (0.001) loss 2.1309 (2.6680) lr 9.9726e-03 eta 9:28:28
epoch [2/30] batch [1380/2000] time 0.595 (0.602) data 0.000 (0.001) loss 1.9941 (2.6655) lr 9.9726e-03 eta 9:28:15
epoch [2/30] batch [1400/2000] time 0.602 (0.602) data 0.000 (0.001) loss 1.5986 (2.6645) lr 9.9726e-03 eta 9:28:01
epoch [2/30] batch [1420/2000] time 0.600 (0.602) data 0.000 (0.001) loss 3.5117 (2.6668) lr 9.9726e-03 eta 9:27:48
epoch [2/30] batch [1440/2000] time 0.608 (0.602) data 0.000 (0.001) loss 1.6699 (2.6640) lr 9.9726e-03 eta 9:27:37
epoch [2/30] batch [1460/2000] time 0.602 (0.602) data 0.000 (0.001) loss 9.6484 (2.6681) lr 9.9726e-03 eta 9:27:24
epoch [2/30] batch [1480/2000] time 0.597 (0.602) data 0.000 (0.001) loss 2.4785 (2.6638) lr 9.9726e-03 eta 9:27:13
epoch [2/30] batch [1500/2000] time 0.600 (0.602) data 0.000 (0.001) loss 2.2637 (2.6649) lr 9.9726e-03 eta 9:27:03
epoch [2/30] batch [1520/2000] time 0.594 (0.602) data 0.000 (0.001) loss 1.1641 (2.6622) lr 9.9726e-03 eta 9:26:48
epoch [2/30] batch [1540/2000] time 0.600 (0.602) data 0.000 (0.001) loss 4.1367 (2.6626) lr 9.9726e-03 eta 9:26:36
epoch [2/30] batch [1560/2000] time 0.608 (0.602) data 0.000 (0.001) loss 2.0449 (2.6578) lr 9.9726e-03 eta 9:26:25
epoch [2/30] batch [1580/2000] time 0.597 (0.602) data 0.000 (0.001) loss 6.3281 (2.6663) lr 9.9726e-03 eta 9:26:10
epoch [2/30] batch [1600/2000] time 0.602 (0.602) data 0.000 (0.001) loss 1.1836 (2.6614) lr 9.9726e-03 eta 9:26:00
epoch [2/30] batch [1620/2000] time 0.596 (0.602) data 0.000 (0.001) loss 6.7070 (2.6715) lr 9.9726e-03 eta 9:25:46
epoch [2/30] batch [1640/2000] time 0.600 (0.602) data 0.000 (0.001) loss 2.5566 (2.6827) lr 9.9726e-03 eta 9:25:31
epoch [2/30] batch [1660/2000] time 0.594 (0.602) data 0.000 (0.001) loss 1.4951 (2.6787) lr 9.9726e-03 eta 9:25:18
epoch [2/30] batch [1680/2000] time 0.609 (0.602) data 0.000 (0.001) loss 3.9141 (2.6737) lr 9.9726e-03 eta 9:25:04
epoch [2/30] batch [1700/2000] time 0.595 (0.602) data 0.000 (0.001) loss 2.3652 (2.6733) lr 9.9726e-03 eta 9:24:54
epoch [2/30] batch [1720/2000] time 0.597 (0.602) data 0.000 (0.001) loss 3.9980 (2.6704) lr 9.9726e-03 eta 9:24:45
epoch [2/30] batch [1740/2000] time 0.600 (0.602) data 0.000 (0.001) loss 1.2588 (2.6729) lr 9.9726e-03 eta 9:24:33
epoch [2/30] batch [1760/2000] time 0.595 (0.602) data 0.000 (0.001) loss 1.1826 (2.6784) lr 9.9726e-03 eta 9:24:24
epoch [2/30] batch [1780/2000] time 0.596 (0.602) data 0.000 (0.001) loss 0.6187 (2.6708) lr 9.9726e-03 eta 9:24:10
epoch [2/30] batch [1800/2000] time 0.677 (0.602) data 0.000 (0.001) loss 1.1221 (2.6748) lr 9.9726e-03 eta 9:23:57
epoch [2/30] batch [1820/2000] time 0.605 (0.602) data 0.000 (0.001) loss 1.3135 (2.6753) lr 9.9726e-03 eta 9:23:44
epoch [2/30] batch [1840/2000] time 0.618 (0.602) data 0.000 (0.001) loss 0.7480 (2.6723) lr 9.9726e-03 eta 9:23:32
epoch [2/30] batch [1860/2000] time 0.591 (0.602) data 0.000 (0.001) loss 4.1016 (2.6736) lr 9.9726e-03 eta 9:23:18
epoch [2/30] batch [1880/2000] time 0.600 (0.602) data 0.000 (0.001) loss 1.8193 (2.6718) lr 9.9726e-03 eta 9:23:07
epoch [2/30] batch [1900/2000] time 0.604 (0.602) data 0.000 (0.001) loss 2.6777 (2.6692) lr 9.9726e-03 eta 9:22:57
epoch [2/30] batch [1920/2000] time 0.604 (0.602) data 0.000 (0.001) loss 3.6816 (2.6672) lr 9.9726e-03 eta 9:22:46
epoch [2/30] batch [1940/2000] time 0.596 (0.602) data 0.000 (0.001) loss 4.4414 (2.6658) lr 9.9726e-03 eta 9:22:32
epoch [2/30] batch [1960/2000] time 0.601 (0.602) data 0.000 (0.001) loss 6.3984 (2.6726) lr 9.9726e-03 eta 9:22:22
epoch [2/30] batch [1980/2000] time 0.592 (0.602) data 0.000 (0.001) loss 1.0996 (2.6756) lr 9.9726e-03 eta 9:22:06
epoch [2/30] batch [2000/2000] time 0.593 (0.602) data 0.000 (0.001) loss 6.3047 (2.6838) lr 9.8907e-03 eta 9:21:50
Evaluate on the *val* set
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:02<11:14,  2.71s/it]  1%|          | 2/250 [00:03<05:59,  1.45s/it]  1%|          | 3/250 [00:03<04:07,  1.00s/it]  2%|▏         | 4/250 [00:04<03:15,  1.26it/s]  2%|▏         | 5/250 [00:04<02:36,  1.56it/s]  2%|▏         | 6/250 [00:04<02:14,  1.81it/s]  3%|▎         | 7/250 [00:05<02:01,  2.00it/s]  3%|▎         | 8/250 [00:05<01:52,  2.16it/s]  4%|▎         | 9/250 [00:06<01:45,  2.27it/s]  4%|▍         | 10/250 [00:06<01:40,  2.38it/s]  4%|▍         | 11/250 [00:06<01:36,  2.48it/s]  5%|▍         | 12/250 [00:07<01:33,  2.55it/s]  5%|▌         | 13/250 [00:07<01:31,  2.60it/s]  6%|▌         | 14/250 [00:07<01:28,  2.68it/s]  6%|▌         | 15/250 [00:08<01:27,  2.67it/s]  6%|▋         | 16/250 [00:08<01:25,  2.73it/s]  7%|▋         | 17/250 [00:09<01:25,  2.73it/s]  7%|▋         | 18/250 [00:09<01:24,  2.73it/s]  8%|▊         | 19/250 [00:09<01:24,  2.75it/s]  8%|▊         | 20/250 [00:10<01:23,  2.76it/s]  8%|▊         | 21/250 [00:10<01:22,  2.77it/s]  9%|▉         | 22/250 [00:10<01:21,  2.79it/s]  9%|▉         | 23/250 [00:11<01:21,  2.79it/s] 10%|▉         | 24/250 [00:11<01:22,  2.74it/s] 10%|█         | 25/250 [00:11<01:22,  2.73it/s] 10%|█         | 26/250 [00:12<01:22,  2.73it/s] 11%|█         | 27/250 [00:12<01:22,  2.71it/s] 11%|█         | 28/250 [00:13<01:22,  2.68it/s] 12%|█▏        | 29/250 [00:13<01:22,  2.68it/s] 12%|█▏        | 30/250 [00:13<01:23,  2.65it/s] 12%|█▏        | 31/250 [00:14<01:21,  2.68it/s] 13%|█▎        | 32/250 [00:14<01:21,  2.67it/s] 13%|█▎        | 33/250 [00:14<01:20,  2.70it/s] 14%|█▎        | 34/250 [00:15<01:19,  2.70it/s] 14%|█▍        | 35/250 [00:15<01:19,  2.72it/s] 14%|█▍        | 36/250 [00:16<01:18,  2.74it/s] 15%|█▍        | 37/250 [00:16<01:17,  2.74it/s] 15%|█▌        | 38/250 [00:16<01:16,  2.78it/s] 16%|█▌        | 39/250 [00:17<01:15,  2.81it/s] 16%|█▌        | 40/250 [00:17<01:16,  2.76it/s] 16%|█▋        | 41/250 [00:17<01:15,  2.75it/s] 17%|█▋        | 42/250 [00:18<01:15,  2.77it/s] 17%|█▋        | 43/250 [00:18<01:15,  2.76it/s] 18%|█▊        | 44/250 [00:18<01:15,  2.74it/s] 18%|█▊        | 45/250 [00:19<01:13,  2.78it/s] 18%|█▊        | 46/250 [00:19<01:13,  2.76it/s] 19%|█▉        | 47/250 [00:20<01:14,  2.74it/s] 19%|█▉        | 48/250 [00:20<01:12,  2.77it/s] 20%|█▉        | 49/250 [00:20<01:13,  2.75it/s] 20%|██        | 50/250 [00:21<01:13,  2.72it/s] 20%|██        | 51/250 [00:21<01:11,  2.77it/s] 21%|██        | 52/250 [00:21<01:12,  2.74it/s] 21%|██        | 53/250 [00:22<01:12,  2.73it/s] 22%|██▏       | 54/250 [00:22<01:12,  2.69it/s] 22%|██▏       | 55/250 [00:22<01:11,  2.72it/s] 22%|██▏       | 56/250 [00:23<01:10,  2.74it/s] 23%|██▎       | 57/250 [00:23<01:09,  2.77it/s] 23%|██▎       | 58/250 [00:23<01:08,  2.81it/s] 24%|██▎       | 59/250 [00:24<01:07,  2.82it/s] 24%|██▍       | 60/250 [00:24<01:08,  2.78it/s] 24%|██▍       | 61/250 [00:25<01:08,  2.77it/s] 25%|██▍       | 62/250 [00:25<01:08,  2.76it/s] 25%|██▌       | 63/250 [00:25<01:07,  2.76it/s] 26%|██▌       | 64/250 [00:26<01:05,  2.82it/s] 26%|██▌       | 65/250 [00:26<01:06,  2.78it/s] 26%|██▋       | 66/250 [00:26<01:06,  2.79it/s] 27%|██▋       | 67/250 [00:27<01:05,  2.81it/s] 27%|██▋       | 68/250 [00:27<01:05,  2.80it/s] 28%|██▊       | 69/250 [00:27<01:04,  2.82it/s] 28%|██▊       | 70/250 [00:28<01:05,  2.77it/s] 28%|██▊       | 71/250 [00:28<01:04,  2.77it/s] 29%|██▉       | 72/250 [00:29<01:04,  2.76it/s] 29%|██▉       | 73/250 [00:29<01:03,  2.78it/s] 30%|██▉       | 74/250 [00:29<01:03,  2.76it/s] 30%|███       | 75/250 [00:30<01:03,  2.77it/s] 30%|███       | 76/250 [00:30<01:02,  2.78it/s] 31%|███       | 77/250 [00:30<01:01,  2.80it/s] 31%|███       | 78/250 [00:31<01:01,  2.78it/s] 32%|███▏      | 79/250 [00:31<01:02,  2.75it/s] 32%|███▏      | 80/250 [00:31<01:01,  2.78it/s] 32%|███▏      | 81/250 [00:32<01:00,  2.81it/s] 33%|███▎      | 82/250 [00:32<00:59,  2.84it/s] 33%|███▎      | 83/250 [00:32<01:00,  2.77it/s] 34%|███▎      | 84/250 [00:33<00:59,  2.77it/s] 34%|███▍      | 85/250 [00:33<00:59,  2.75it/s] 34%|███▍      | 86/250 [00:34<00:59,  2.74it/s] 35%|███▍      | 87/250 [00:34<00:58,  2.78it/s] 35%|███▌      | 88/250 [00:34<00:57,  2.80it/s] 36%|███▌      | 89/250 [00:35<00:58,  2.75it/s] 36%|███▌      | 90/250 [00:35<00:58,  2.72it/s] 36%|███▋      | 91/250 [00:35<00:57,  2.75it/s] 37%|███▋      | 92/250 [00:36<00:59,  2.67it/s] 37%|███▋      | 93/250 [00:36<00:57,  2.73it/s] 38%|███▊      | 94/250 [00:37<00:57,  2.71it/s] 38%|███▊      | 95/250 [00:37<00:55,  2.78it/s] 38%|███▊      | 96/250 [00:37<00:54,  2.81it/s] 39%|███▉      | 97/250 [00:38<00:54,  2.79it/s] 39%|███▉      | 98/250 [00:38<00:54,  2.81it/s] 40%|███▉      | 99/250 [00:38<00:53,  2.82it/s] 40%|████      | 100/250 [00:39<00:53,  2.82it/s] 40%|████      | 101/250 [00:39<00:53,  2.77it/s] 41%|████      | 102/250 [00:39<00:53,  2.76it/s] 41%|████      | 103/250 [00:40<00:53,  2.74it/s] 42%|████▏     | 104/250 [00:40<00:53,  2.74it/s] 42%|████▏     | 105/250 [00:40<00:52,  2.74it/s] 42%|████▏     | 106/250 [00:41<00:53,  2.72it/s] 43%|████▎     | 107/250 [00:41<00:53,  2.67it/s] 43%|████▎     | 108/250 [00:42<00:52,  2.71it/s] 44%|████▎     | 109/250 [00:42<00:52,  2.69it/s] 44%|████▍     | 110/250 [00:42<00:51,  2.71it/s] 44%|████▍     | 111/250 [00:43<00:50,  2.76it/s] 45%|████▍     | 112/250 [00:43<00:49,  2.77it/s] 45%|████▌     | 113/250 [00:43<00:49,  2.75it/s] 46%|████▌     | 114/250 [00:44<00:49,  2.77it/s] 46%|████▌     | 115/250 [00:44<00:49,  2.73it/s] 46%|████▋     | 116/250 [00:44<00:48,  2.77it/s] 47%|████▋     | 117/250 [00:45<00:49,  2.71it/s] 47%|████▋     | 118/250 [00:45<00:48,  2.72it/s] 48%|████▊     | 119/250 [00:46<00:48,  2.69it/s] 48%|████▊     | 120/250 [00:46<00:48,  2.68it/s] 48%|████▊     | 121/250 [00:46<00:48,  2.68it/s] 49%|████▉     | 122/250 [00:47<00:48,  2.66it/s] 49%|████▉     | 123/250 [00:47<00:48,  2.64it/s] 50%|████▉     | 124/250 [00:48<00:47,  2.63it/s] 50%|█████     | 125/250 [00:48<00:46,  2.69it/s] 50%|█████     | 126/250 [00:48<00:45,  2.73it/s] 51%|█████     | 127/250 [00:49<00:45,  2.70it/s] 51%|█████     | 128/250 [00:49<00:44,  2.76it/s] 52%|█████▏    | 129/250 [00:49<00:43,  2.76it/s] 52%|█████▏    | 130/250 [00:50<00:43,  2.77it/s] 52%|█████▏    | 131/250 [00:50<00:43,  2.76it/s] 53%|█████▎    | 132/250 [00:50<00:42,  2.75it/s] 53%|█████▎    | 133/250 [00:51<00:42,  2.74it/s] 54%|█████▎    | 134/250 [00:51<00:44,  2.63it/s] 54%|█████▍    | 135/250 [00:52<00:43,  2.62it/s] 54%|█████▍    | 136/250 [00:52<00:43,  2.65it/s] 55%|█████▍    | 137/250 [00:52<00:43,  2.63it/s] 55%|█████▌    | 138/250 [00:53<00:42,  2.64it/s] 56%|█████▌    | 139/250 [00:53<00:41,  2.68it/s] 56%|█████▌    | 140/250 [00:53<00:40,  2.73it/s] 56%|█████▋    | 141/250 [00:54<00:39,  2.74it/s] 57%|█████▋    | 142/250 [00:54<00:39,  2.73it/s] 57%|█████▋    | 143/250 [00:54<00:38,  2.74it/s] 58%|█████▊    | 144/250 [00:55<00:39,  2.72it/s] 58%|█████▊    | 145/250 [00:55<00:38,  2.71it/s] 58%|█████▊    | 146/250 [00:56<00:38,  2.69it/s] 59%|█████▉    | 147/250 [00:56<00:38,  2.69it/s] 59%|█████▉    | 148/250 [00:56<00:37,  2.72it/s] 60%|█████▉    | 149/250 [00:57<00:37,  2.73it/s] 60%|██████    | 150/250 [00:57<00:37,  2.70it/s] 60%|██████    | 151/250 [00:57<00:36,  2.69it/s] 61%|██████    | 152/250 [00:58<00:36,  2.69it/s] 61%|██████    | 153/250 [00:58<00:35,  2.73it/s] 62%|██████▏   | 154/250 [00:59<00:35,  2.71it/s] 62%|██████▏   | 155/250 [00:59<00:35,  2.71it/s] 62%|██████▏   | 156/250 [00:59<00:34,  2.72it/s] 63%|██████▎   | 157/250 [01:00<00:33,  2.74it/s] 63%|██████▎   | 158/250 [01:00<00:34,  2.69it/s] 64%|██████▎   | 159/250 [01:00<00:33,  2.71it/s] 64%|██████▍   | 160/250 [01:01<00:33,  2.72it/s] 64%|██████▍   | 161/250 [01:01<00:33,  2.68it/s] 65%|██████▍   | 162/250 [01:02<00:32,  2.67it/s] 65%|██████▌   | 163/250 [01:02<00:32,  2.68it/s] 66%|██████▌   | 164/250 [01:02<00:32,  2.68it/s] 66%|██████▌   | 165/250 [01:03<00:31,  2.68it/s] 66%|██████▋   | 166/250 [01:03<00:31,  2.71it/s] 67%|██████▋   | 167/250 [01:03<00:30,  2.73it/s] 67%|██████▋   | 168/250 [01:04<00:29,  2.75it/s] 68%|██████▊   | 169/250 [01:04<00:29,  2.78it/s] 68%|██████▊   | 170/250 [01:04<00:28,  2.78it/s] 68%|██████▊   | 171/250 [01:05<00:28,  2.80it/s] 69%|██████▉   | 172/250 [01:05<00:28,  2.78it/s] 69%|██████▉   | 173/250 [01:06<00:27,  2.79it/s] 70%|██████▉   | 174/250 [01:06<00:27,  2.77it/s] 70%|███████   | 175/250 [01:06<00:27,  2.71it/s] 70%|███████   | 176/250 [01:07<00:26,  2.75it/s] 71%|███████   | 177/250 [01:07<00:26,  2.73it/s] 71%|███████   | 178/250 [01:07<00:26,  2.72it/s] 72%|███████▏  | 179/250 [01:08<00:25,  2.74it/s] 72%|███████▏  | 180/250 [01:08<00:25,  2.71it/s] 72%|███████▏  | 181/250 [01:08<00:25,  2.73it/s] 73%|███████▎  | 182/250 [01:09<00:24,  2.74it/s] 73%|███████▎  | 183/250 [01:09<00:24,  2.70it/s] 74%|███████▎  | 184/250 [01:10<00:23,  2.75it/s] 74%|███████▍  | 185/250 [01:10<00:23,  2.77it/s] 74%|███████▍  | 186/250 [01:10<00:23,  2.76it/s] 75%|███████▍  | 187/250 [01:11<00:23,  2.73it/s] 75%|███████▌  | 188/250 [01:11<00:22,  2.74it/s] 76%|███████▌  | 189/250 [01:11<00:22,  2.76it/s] 76%|███████▌  | 190/250 [01:12<00:22,  2.66it/s] 76%|███████▋  | 191/250 [01:12<00:22,  2.67it/s] 77%|███████▋  | 192/250 [01:13<00:21,  2.67it/s] 77%|███████▋  | 193/250 [01:13<00:21,  2.65it/s] 78%|███████▊  | 194/250 [01:13<00:21,  2.64it/s] 78%|███████▊  | 195/250 [01:14<00:20,  2.68it/s] 78%|███████▊  | 196/250 [01:14<00:20,  2.65it/s] 79%|███████▉  | 197/250 [01:14<00:20,  2.64it/s] 79%|███████▉  | 198/250 [01:15<00:19,  2.64it/s] 80%|███████▉  | 199/250 [01:15<00:19,  2.68it/s] 80%|████████  | 200/250 [01:16<00:18,  2.69it/s] 80%|████████  | 201/250 [01:16<00:18,  2.71it/s] 81%|████████  | 202/250 [01:16<00:17,  2.73it/s] 81%|████████  | 203/250 [01:17<00:17,  2.72it/s] 82%|████████▏ | 204/250 [01:17<00:16,  2.78it/s] 82%|████████▏ | 205/250 [01:17<00:16,  2.73it/s] 82%|████████▏ | 206/250 [01:18<00:16,  2.71it/s] 83%|████████▎ | 207/250 [01:18<00:15,  2.71it/s] 83%|████████▎ | 208/250 [01:18<00:15,  2.75it/s] 84%|████████▎ | 209/250 [01:19<00:14,  2.77it/s] 84%|████████▍ | 210/250 [01:19<00:14,  2.74it/s] 84%|████████▍ | 211/250 [01:20<00:14,  2.69it/s] 85%|████████▍ | 212/250 [01:20<00:13,  2.73it/s] 85%|████████▌ | 213/250 [01:20<00:13,  2.68it/s] 86%|████████▌ | 214/250 [01:21<00:13,  2.72it/s] 86%|████████▌ | 215/250 [01:21<00:12,  2.77it/s] 86%|████████▋ | 216/250 [01:21<00:12,  2.75it/s] 87%|████████▋ | 217/250 [01:22<00:12,  2.73it/s] 87%|████████▋ | 218/250 [01:22<00:11,  2.71it/s] 88%|████████▊ | 219/250 [01:22<00:11,  2.69it/s] 88%|████████▊ | 220/250 [01:23<00:10,  2.73it/s] 88%|████████▊ | 221/250 [01:23<00:10,  2.84it/s] 89%|████████▉ | 222/250 [01:23<00:09,  2.98it/s] 89%|████████▉ | 223/250 [01:24<00:08,  3.08it/s] 90%|████████▉ | 224/250 [01:24<00:08,  3.16it/s] 90%|█████████ | 225/250 [01:24<00:07,  3.22it/s] 90%|█████████ | 226/250 [01:25<00:07,  3.26it/s] 91%|█████████ | 227/250 [01:25<00:07,  3.28it/s] 91%|█████████ | 228/250 [01:25<00:06,  3.30it/s] 92%|█████████▏| 229/250 [01:26<00:06,  3.32it/s] 92%|█████████▏| 230/250 [01:26<00:06,  3.33it/s] 92%|█████████▏| 231/250 [01:26<00:05,  3.33it/s] 93%|█████████▎| 232/250 [01:26<00:05,  3.33it/s] 93%|█████████▎| 233/250 [01:27<00:05,  3.33it/s] 94%|█████████▎| 234/250 [01:27<00:04,  3.33it/s] 94%|█████████▍| 235/250 [01:27<00:04,  3.34it/s] 94%|█████████▍| 236/250 [01:28<00:04,  3.34it/s] 95%|█████████▍| 237/250 [01:28<00:03,  3.31it/s] 95%|█████████▌| 238/250 [01:28<00:03,  3.32it/s] 96%|█████████▌| 239/250 [01:29<00:03,  3.33it/s] 96%|█████████▌| 240/250 [01:29<00:02,  3.34it/s] 96%|█████████▋| 241/250 [01:29<00:02,  3.34it/s] 97%|█████████▋| 242/250 [01:29<00:02,  3.35it/s] 97%|█████████▋| 243/250 [01:30<00:02,  3.34it/s] 98%|█████████▊| 244/250 [01:30<00:01,  3.34it/s] 98%|█████████▊| 245/250 [01:30<00:01,  3.35it/s] 98%|█████████▊| 246/250 [01:31<00:01,  3.35it/s] 99%|█████████▉| 247/250 [01:31<00:00,  3.35it/s] 99%|█████████▉| 248/250 [01:31<00:00,  3.36it/s]100%|█████████▉| 249/250 [01:32<00:00,  3.36it/s]100%|██████████| 250/250 [01:32<00:00,  3.36it/s]100%|██████████| 250/250 [01:32<00:00,  2.70it/s]=> result
* total: 25,000
* correct: 18,944
* accuracy: 75.8%
* error: 24.2%
* macro_f1: 75.3%

epoch [3/30] batch [20/2000] time 0.601 (0.646) data 0.000 (0.039) loss 2.9766 (2.1865) lr 9.8907e-03 eta 10:02:20
epoch [3/30] batch [40/2000] time 0.612 (0.625) data 0.000 (0.020) loss 0.2925 (2.4551) lr 9.8907e-03 eta 9:42:33
epoch [3/30] batch [60/2000] time 0.596 (0.615) data 0.000 (0.013) loss 0.7178 (2.5921) lr 9.8907e-03 eta 9:33:42
epoch [3/30] batch [80/2000] time 0.605 (0.614) data 0.000 (0.010) loss 1.4893 (2.6099) lr 9.8907e-03 eta 9:32:40
epoch [3/30] batch [100/2000] time 0.610 (0.612) data 0.000 (0.008) loss 3.0840 (2.5530) lr 9.8907e-03 eta 9:29:59
epoch [3/30] batch [120/2000] time 0.617 (0.610) data 0.000 (0.007) loss 1.1328 (2.6180) lr 9.8907e-03 eta 9:28:04
epoch [3/30] batch [140/2000] time 0.598 (0.609) data 0.000 (0.006) loss 3.1348 (2.5959) lr 9.8907e-03 eta 9:27:03
epoch [3/30] batch [160/2000] time 0.605 (0.608) data 0.000 (0.005) loss 1.4551 (2.5449) lr 9.8907e-03 eta 9:25:53
epoch [3/30] batch [180/2000] time 0.591 (0.607) data 0.000 (0.005) loss 0.8574 (2.5271) lr 9.8907e-03 eta 9:24:54
epoch [3/30] batch [200/2000] time 0.608 (0.607) data 0.000 (0.004) loss 0.8584 (2.5212) lr 9.8907e-03 eta 9:24:24
epoch [3/30] batch [220/2000] time 0.599 (0.606) data 0.000 (0.004) loss 6.6289 (2.5635) lr 9.8907e-03 eta 9:23:47
epoch [3/30] batch [240/2000] time 0.611 (0.606) data 0.000 (0.003) loss 1.3984 (2.5917) lr 9.8907e-03 eta 9:23:14
epoch [3/30] batch [260/2000] time 0.613 (0.606) data 0.000 (0.003) loss 1.3594 (2.5769) lr 9.8907e-03 eta 9:22:44
epoch [3/30] batch [280/2000] time 0.605 (0.606) data 0.000 (0.003) loss 3.3418 (2.5830) lr 9.8907e-03 eta 9:22:24
epoch [3/30] batch [300/2000] time 0.600 (0.605) data 0.000 (0.003) loss 3.5879 (2.6211) lr 9.8907e-03 eta 9:21:51
epoch [3/30] batch [320/2000] time 0.599 (0.605) data 0.000 (0.003) loss 0.5947 (2.6638) lr 9.8907e-03 eta 9:21:22
epoch [3/30] batch [340/2000] time 0.595 (0.605) data 0.000 (0.003) loss 5.8398 (2.6992) lr 9.8907e-03 eta 9:21:17
epoch [3/30] batch [360/2000] time 0.594 (0.605) data 0.000 (0.002) loss 3.0156 (2.6721) lr 9.8907e-03 eta 9:20:43
epoch [3/30] batch [380/2000] time 0.606 (0.605) data 0.000 (0.002) loss 2.6074 (2.6588) lr 9.8907e-03 eta 9:20:26
epoch [3/30] batch [400/2000] time 0.602 (0.604) data 0.000 (0.002) loss 1.7510 (2.6659) lr 9.8907e-03 eta 9:20:10
epoch [3/30] batch [420/2000] time 0.596 (0.604) data 0.000 (0.002) loss 3.7461 (2.6319) lr 9.8907e-03 eta 9:19:46
epoch [3/30] batch [440/2000] time 0.591 (0.604) data 0.000 (0.002) loss 0.5840 (2.6149) lr 9.8907e-03 eta 9:19:25
epoch [3/30] batch [460/2000] time 0.598 (0.604) data 0.000 (0.002) loss 3.1680 (2.6247) lr 9.8907e-03 eta 9:19:10
epoch [3/30] batch [480/2000] time 0.600 (0.604) data 0.000 (0.002) loss 0.3760 (2.6393) lr 9.8907e-03 eta 9:18:49
epoch [3/30] batch [500/2000] time 0.613 (0.604) data 0.000 (0.002) loss 1.8262 (2.6109) lr 9.8907e-03 eta 9:18:40
epoch [3/30] batch [520/2000] time 0.603 (0.604) data 0.000 (0.002) loss 0.1155 (2.5976) lr 9.8907e-03 eta 9:18:20
epoch [3/30] batch [540/2000] time 0.597 (0.604) data 0.000 (0.002) loss 5.6484 (2.5995) lr 9.8907e-03 eta 9:18:13
epoch [3/30] batch [560/2000] time 0.603 (0.604) data 0.000 (0.002) loss 1.8154 (2.5961) lr 9.8907e-03 eta 9:18:00
epoch [3/30] batch [580/2000] time 0.592 (0.604) data 0.000 (0.002) loss 1.5342 (2.5807) lr 9.8907e-03 eta 9:17:41
epoch [3/30] batch [600/2000] time 0.600 (0.604) data 0.000 (0.002) loss 5.4922 (2.5845) lr 9.8907e-03 eta 9:17:35
epoch [3/30] batch [620/2000] time 0.597 (0.604) data 0.000 (0.002) loss 0.6758 (2.5721) lr 9.8907e-03 eta 9:17:15
epoch [3/30] batch [640/2000] time 0.594 (0.604) data 0.000 (0.001) loss 0.9600 (2.5708) lr 9.8907e-03 eta 9:16:53
epoch [3/30] batch [660/2000] time 0.594 (0.603) data 0.000 (0.001) loss 3.5762 (2.5869) lr 9.8907e-03 eta 9:16:31
epoch [3/30] batch [680/2000] time 0.597 (0.603) data 0.000 (0.001) loss 0.0138 (2.5822) lr 9.8907e-03 eta 9:16:20
epoch [3/30] batch [700/2000] time 0.599 (0.603) data 0.000 (0.001) loss 0.6660 (2.5782) lr 9.8907e-03 eta 9:16:07
epoch [3/30] batch [720/2000] time 0.602 (0.603) data 0.000 (0.001) loss 1.4521 (2.5928) lr 9.8907e-03 eta 9:15:48
epoch [3/30] batch [740/2000] time 0.598 (0.603) data 0.000 (0.001) loss 2.7559 (2.5899) lr 9.8907e-03 eta 9:15:30
epoch [3/30] batch [760/2000] time 0.604 (0.603) data 0.000 (0.001) loss 2.1914 (2.5858) lr 9.8907e-03 eta 9:15:13
epoch [3/30] batch [780/2000] time 0.599 (0.603) data 0.000 (0.001) loss 4.6992 (2.5785) lr 9.8907e-03 eta 9:14:59
epoch [3/30] batch [800/2000] time 0.608 (0.603) data 0.000 (0.001) loss 0.8188 (2.5657) lr 9.8907e-03 eta 9:14:47
epoch [3/30] batch [820/2000] time 0.594 (0.603) data 0.000 (0.001) loss 4.7812 (2.5610) lr 9.8907e-03 eta 9:14:36
epoch [3/30] batch [840/2000] time 0.602 (0.603) data 0.000 (0.001) loss 3.8926 (2.5573) lr 9.8907e-03 eta 9:14:18
epoch [3/30] batch [860/2000] time 0.600 (0.603) data 0.000 (0.001) loss 1.9355 (2.5492) lr 9.8907e-03 eta 9:14:03
epoch [3/30] batch [880/2000] time 0.596 (0.603) data 0.000 (0.001) loss 2.0332 (2.5502) lr 9.8907e-03 eta 9:13:53
epoch [3/30] batch [900/2000] time 0.599 (0.603) data 0.000 (0.001) loss 2.1367 (2.5518) lr 9.8907e-03 eta 9:13:37
epoch [3/30] batch [920/2000] time 0.596 (0.603) data 0.000 (0.001) loss 1.1426 (2.5529) lr 9.8907e-03 eta 9:13:23
epoch [3/30] batch [940/2000] time 0.595 (0.603) data 0.000 (0.001) loss 0.2595 (2.5550) lr 9.8907e-03 eta 9:13:06
epoch [3/30] batch [960/2000] time 0.592 (0.603) data 0.000 (0.001) loss 0.0601 (2.5587) lr 9.8907e-03 eta 9:12:57
epoch [3/30] batch [980/2000] time 0.592 (0.603) data 0.000 (0.001) loss 0.8945 (2.5499) lr 9.8907e-03 eta 9:12:40
epoch [3/30] batch [1000/2000] time 0.596 (0.603) data 0.000 (0.001) loss 0.3652 (2.5573) lr 9.8907e-03 eta 9:12:29
epoch [3/30] batch [1020/2000] time 0.599 (0.603) data 0.000 (0.001) loss 1.9561 (2.5531) lr 9.8907e-03 eta 9:12:16
epoch [3/30] batch [1040/2000] time 0.594 (0.603) data 0.000 (0.001) loss 0.7603 (2.5600) lr 9.8907e-03 eta 9:12:04
epoch [3/30] batch [1060/2000] time 0.596 (0.603) data 0.000 (0.001) loss 2.2852 (2.5477) lr 9.8907e-03 eta 9:11:53
epoch [3/30] batch [1080/2000] time 0.598 (0.603) data 0.000 (0.001) loss 0.6333 (2.5519) lr 9.8907e-03 eta 9:11:42
epoch [3/30] batch [1100/2000] time 0.602 (0.603) data 0.000 (0.001) loss 3.0781 (2.5393) lr 9.8907e-03 eta 9:11:28
epoch [3/30] batch [1120/2000] time 0.601 (0.603) data 0.000 (0.001) loss 3.7754 (2.5453) lr 9.8907e-03 eta 9:11:14
epoch [3/30] batch [1140/2000] time 0.604 (0.603) data 0.000 (0.001) loss 0.7285 (2.5413) lr 9.8907e-03 eta 9:11:00
epoch [3/30] batch [1160/2000] time 0.598 (0.603) data 0.000 (0.001) loss 3.0625 (2.5391) lr 9.8907e-03 eta 9:10:44
epoch [3/30] batch [1180/2000] time 0.591 (0.603) data 0.000 (0.001) loss 1.0762 (2.5306) lr 9.8907e-03 eta 9:10:29
epoch [3/30] batch [1200/2000] time 0.599 (0.602) data 0.000 (0.001) loss 1.1973 (2.5394) lr 9.8907e-03 eta 9:10:16
epoch [3/30] batch [1220/2000] time 0.607 (0.602) data 0.000 (0.001) loss 4.0703 (2.5405) lr 9.8907e-03 eta 9:10:01
epoch [3/30] batch [1240/2000] time 0.597 (0.602) data 0.000 (0.001) loss 1.5625 (2.5536) lr 9.8907e-03 eta 9:09:46
epoch [3/30] batch [1260/2000] time 0.602 (0.602) data 0.000 (0.001) loss 2.8691 (2.5524) lr 9.8907e-03 eta 9:09:32
epoch [3/30] batch [1280/2000] time 0.593 (0.602) data 0.000 (0.001) loss 0.8560 (2.5544) lr 9.8907e-03 eta 9:09:19
epoch [3/30] batch [1300/2000] time 0.600 (0.602) data 0.000 (0.001) loss 0.9736 (2.5463) lr 9.8907e-03 eta 9:09:05
epoch [3/30] batch [1320/2000] time 0.599 (0.602) data 0.000 (0.001) loss 5.9414 (2.5577) lr 9.8907e-03 eta 9:08:53
epoch [3/30] batch [1340/2000] time 0.608 (0.602) data 0.000 (0.001) loss 2.9941 (2.5570) lr 9.8907e-03 eta 9:08:43
epoch [3/30] batch [1360/2000] time 0.594 (0.602) data 0.000 (0.001) loss 1.6045 (2.5531) lr 9.8907e-03 eta 9:08:30
epoch [3/30] batch [1380/2000] time 0.600 (0.602) data 0.000 (0.001) loss 0.4897 (2.5428) lr 9.8907e-03 eta 9:08:16
epoch [3/30] batch [1400/2000] time 0.595 (0.602) data 0.000 (0.001) loss 2.2168 (2.5376) lr 9.8907e-03 eta 9:08:05
epoch [3/30] batch [1420/2000] time 0.598 (0.602) data 0.000 (0.001) loss 0.9849 (2.5333) lr 9.8907e-03 eta 9:07:52
epoch [3/30] batch [1440/2000] time 0.602 (0.602) data 0.000 (0.001) loss 1.7598 (2.5428) lr 9.8907e-03 eta 9:07:38
epoch [3/30] batch [1460/2000] time 0.600 (0.602) data 0.000 (0.001) loss 0.8613 (2.5526) lr 9.8907e-03 eta 9:07:26
epoch [3/30] batch [1480/2000] time 0.603 (0.602) data 0.000 (0.001) loss 5.2227 (2.5622) lr 9.8907e-03 eta 9:07:18
epoch [3/30] batch [1500/2000] time 0.598 (0.602) data 0.000 (0.001) loss 3.5352 (2.5711) lr 9.8907e-03 eta 9:07:03
epoch [3/30] batch [1520/2000] time 0.636 (0.602) data 0.000 (0.001) loss 7.0000 (2.5806) lr 9.8907e-03 eta 9:06:52
epoch [3/30] batch [1540/2000] time 0.598 (0.602) data 0.000 (0.001) loss 1.7061 (2.5782) lr 9.8907e-03 eta 9:06:39
epoch [3/30] batch [1560/2000] time 0.603 (0.602) data 0.000 (0.001) loss 4.4727 (2.5754) lr 9.8907e-03 eta 9:06:26
epoch [3/30] batch [1580/2000] time 0.596 (0.602) data 0.000 (0.001) loss 2.6543 (2.5705) lr 9.8907e-03 eta 9:06:11
epoch [3/30] batch [1600/2000] time 0.615 (0.602) data 0.000 (0.001) loss 3.2305 (2.5764) lr 9.8907e-03 eta 9:05:58
epoch [3/30] batch [1620/2000] time 0.594 (0.602) data 0.000 (0.001) loss 2.0645 (2.5697) lr 9.8907e-03 eta 9:05:47
epoch [3/30] batch [1640/2000] time 0.599 (0.602) data 0.000 (0.001) loss 1.0879 (2.5643) lr 9.8907e-03 eta 9:05:33
epoch [3/30] batch [1660/2000] time 0.599 (0.602) data 0.000 (0.001) loss 0.6650 (2.5650) lr 9.8907e-03 eta 9:05:18
epoch [3/30] batch [1680/2000] time 0.599 (0.602) data 0.000 (0.001) loss 3.7344 (2.5744) lr 9.8907e-03 eta 9:05:04
epoch [3/30] batch [1700/2000] time 0.599 (0.602) data 0.000 (0.001) loss 1.0635 (2.5717) lr 9.8907e-03 eta 9:04:50
epoch [3/30] batch [1720/2000] time 0.596 (0.602) data 0.000 (0.001) loss 4.1289 (2.5750) lr 9.8907e-03 eta 9:04:39
epoch [3/30] batch [1740/2000] time 0.595 (0.602) data 0.000 (0.001) loss 1.7783 (2.5818) lr 9.8907e-03 eta 9:04:28
epoch [3/30] batch [1760/2000] time 0.594 (0.602) data 0.000 (0.001) loss 0.3181 (2.5866) lr 9.8907e-03 eta 9:04:15
epoch [3/30] batch [1780/2000] time 0.592 (0.602) data 0.000 (0.001) loss 5.1719 (2.5880) lr 9.8907e-03 eta 9:04:01
epoch [3/30] batch [1800/2000] time 0.596 (0.602) data 0.000 (0.001) loss 2.0586 (2.5930) lr 9.8907e-03 eta 9:03:49
epoch [3/30] batch [1820/2000] time 0.598 (0.602) data 0.000 (0.001) loss 3.8379 (2.6010) lr 9.8907e-03 eta 9:03:39
epoch [3/30] batch [1840/2000] time 0.596 (0.602) data 0.000 (0.001) loss 0.1443 (2.6023) lr 9.8907e-03 eta 9:03:27
epoch [3/30] batch [1860/2000] time 0.607 (0.602) data 0.000 (0.001) loss 2.5566 (2.6011) lr 9.8907e-03 eta 9:03:18
epoch [3/30] batch [1880/2000] time 0.600 (0.602) data 0.000 (0.001) loss 5.1484 (2.6056) lr 9.8907e-03 eta 9:03:03
epoch [3/30] batch [1900/2000] time 0.601 (0.602) data 0.000 (0.001) loss 0.9990 (2.6002) lr 9.8907e-03 eta 9:02:50
epoch [3/30] batch [1920/2000] time 0.595 (0.602) data 0.000 (0.001) loss 5.8594 (2.6047) lr 9.8907e-03 eta 9:02:40
epoch [3/30] batch [1940/2000] time 0.613 (0.602) data 0.000 (0.001) loss 3.0859 (2.6053) lr 9.8907e-03 eta 9:02:29
epoch [3/30] batch [1960/2000] time 0.597 (0.602) data 0.000 (0.001) loss 1.6475 (2.6053) lr 9.8907e-03 eta 9:02:16
epoch [3/30] batch [1980/2000] time 0.589 (0.602) data 0.000 (0.001) loss 0.1182 (2.6038) lr 9.8907e-03 eta 9:02:00
epoch [3/30] batch [2000/2000] time 0.590 (0.602) data 0.000 (0.001) loss 2.9727 (2.6036) lr 9.7553e-03 eta 9:01:42
Evaluate on the *val* set
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:06<28:46,  6.93s/it]  1%|          | 2/250 [00:07<12:39,  3.06s/it]  1%|          | 3/250 [00:07<07:32,  1.83s/it]  2%|▏         | 4/250 [00:08<05:08,  1.25s/it]  2%|▏         | 5/250 [00:08<03:50,  1.06it/s]  2%|▏         | 6/250 [00:08<03:02,  1.34it/s]  3%|▎         | 7/250 [00:09<02:30,  1.61it/s]  3%|▎         | 8/250 [00:09<02:09,  1.87it/s]  4%|▎         | 9/250 [00:09<01:57,  2.05it/s]  4%|▍         | 10/250 [00:10<01:50,  2.18it/s]  4%|▍         | 11/250 [00:10<01:43,  2.30it/s]  5%|▍         | 12/250 [00:11<01:38,  2.42it/s]  5%|▌         | 13/250 [00:11<01:36,  2.46it/s]  6%|▌         | 14/250 [00:11<01:32,  2.55it/s]  6%|▌         | 15/250 [00:12<01:31,  2.57it/s]  6%|▋         | 16/250 [00:12<01:29,  2.61it/s]  7%|▋         | 17/250 [00:12<01:27,  2.67it/s]  7%|▋         | 18/250 [00:13<01:26,  2.68it/s]  8%|▊         | 19/250 [00:13<01:27,  2.65it/s]  8%|▊         | 20/250 [00:13<01:26,  2.67it/s]  8%|▊         | 21/250 [00:14<01:26,  2.64it/s]  9%|▉         | 22/250 [00:14<01:24,  2.70it/s]  9%|▉         | 23/250 [00:15<01:24,  2.67it/s] 10%|▉         | 24/250 [00:15<01:22,  2.73it/s] 10%|█         | 25/250 [00:15<01:21,  2.75it/s] 10%|█         | 26/250 [00:16<01:21,  2.74it/s] 11%|█         | 27/250 [00:16<01:21,  2.75it/s] 11%|█         | 28/250 [00:16<01:20,  2.75it/s] 12%|█▏        | 29/250 [00:17<01:20,  2.75it/s] 12%|█▏        | 30/250 [00:17<01:20,  2.74it/s] 12%|█▏        | 31/250 [00:18<01:19,  2.75it/s] 13%|█▎        | 32/250 [00:18<01:19,  2.74it/s] 13%|█▎        | 33/250 [00:18<01:20,  2.71it/s] 14%|█▎        | 34/250 [00:19<01:20,  2.70it/s] 14%|█▍        | 35/250 [00:19<01:21,  2.65it/s] 14%|█▍        | 36/250 [00:19<01:19,  2.69it/s] 15%|█▍        | 37/250 [00:20<01:19,  2.69it/s] 15%|█▌        | 38/250 [00:20<01:19,  2.68it/s] 16%|█▌        | 39/250 [00:20<01:18,  2.68it/s] 16%|█▌        | 40/250 [00:21<01:17,  2.71it/s] 16%|█▋        | 41/250 [00:21<01:17,  2.71it/s] 17%|█▋        | 42/250 [00:22<01:17,  2.69it/s] 17%|█▋        | 43/250 [00:22<01:16,  2.71it/s] 18%|█▊        | 44/250 [00:22<01:15,  2.72it/s] 18%|█▊        | 45/250 [00:23<01:14,  2.75it/s] 18%|█▊        | 46/250 [00:23<01:14,  2.75it/s] 19%|█▉        | 47/250 [00:23<01:14,  2.73it/s] 19%|█▉        | 48/250 [00:24<01:13,  2.74it/s] 20%|█▉        | 49/250 [00:24<01:13,  2.72it/s] 20%|██        | 50/250 [00:25<01:12,  2.75it/s] 20%|██        | 51/250 [00:25<01:12,  2.74it/s] 21%|██        | 52/250 [00:25<01:12,  2.74it/s] 21%|██        | 53/250 [00:26<01:11,  2.77it/s] 22%|██▏       | 54/250 [00:26<01:10,  2.77it/s] 22%|██▏       | 55/250 [00:26<01:12,  2.69it/s] 22%|██▏       | 56/250 [00:27<01:11,  2.71it/s] 23%|██▎       | 57/250 [00:27<01:10,  2.73it/s] 23%|██▎       | 58/250 [00:27<01:11,  2.70it/s] 24%|██▎       | 59/250 [00:28<01:10,  2.69it/s] 24%|██▍       | 60/250 [00:28<01:10,  2.68it/s] 24%|██▍       | 61/250 [00:29<01:09,  2.70it/s] 25%|██▍       | 62/250 [00:29<01:09,  2.70it/s] 25%|██▌       | 63/250 [00:29<01:08,  2.72it/s] 26%|██▌       | 64/250 [00:30<01:08,  2.72it/s] 26%|██▌       | 65/250 [00:30<01:08,  2.69it/s] 26%|██▋       | 66/250 [00:30<01:07,  2.71it/s] 27%|██▋       | 67/250 [00:31<01:07,  2.70it/s] 27%|██▋       | 68/250 [00:31<01:06,  2.72it/s] 28%|██▊       | 69/250 [00:32<01:06,  2.73it/s] 28%|██▊       | 70/250 [00:32<01:06,  2.72it/s] 28%|██▊       | 71/250 [00:32<01:05,  2.73it/s] 29%|██▉       | 72/250 [00:33<01:05,  2.72it/s] 29%|██▉       | 73/250 [00:33<01:05,  2.72it/s] 30%|██▉       | 74/250 [00:33<01:04,  2.71it/s] 30%|███       | 75/250 [00:34<01:03,  2.73it/s] 30%|███       | 76/250 [00:34<01:03,  2.74it/s] 31%|███       | 77/250 [00:34<01:02,  2.78it/s] 31%|███       | 78/250 [00:35<01:02,  2.76it/s] 32%|███▏      | 79/250 [00:35<01:02,  2.72it/s] 32%|███▏      | 80/250 [00:36<01:02,  2.73it/s] 32%|███▏      | 81/250 [00:36<01:03,  2.67it/s] 33%|███▎      | 82/250 [00:36<01:02,  2.69it/s] 33%|███▎      | 83/250 [00:37<01:01,  2.72it/s] 34%|███▎      | 84/250 [00:37<01:00,  2.74it/s] 34%|███▍      | 85/250 [00:37<00:59,  2.76it/s] 34%|███▍      | 86/250 [00:38<00:59,  2.74it/s] 35%|███▍      | 87/250 [00:38<01:00,  2.68it/s] 35%|███▌      | 88/250 [00:38<00:59,  2.71it/s] 36%|███▌      | 89/250 [00:39<00:58,  2.73it/s] 36%|███▌      | 90/250 [00:39<00:57,  2.76it/s] 36%|███▋      | 91/250 [00:40<00:57,  2.76it/s] 37%|███▋      | 92/250 [00:40<00:57,  2.74it/s] 37%|███▋      | 93/250 [00:40<00:57,  2.72it/s] 38%|███▊      | 94/250 [00:41<00:57,  2.73it/s] 38%|███▊      | 95/250 [00:41<00:56,  2.75it/s] 38%|███▊      | 96/250 [00:41<00:56,  2.74it/s] 39%|███▉      | 97/250 [00:42<00:56,  2.69it/s] 39%|███▉      | 98/250 [00:42<00:56,  2.70it/s] 40%|███▉      | 99/250 [00:43<00:55,  2.73it/s] 40%|████      | 100/250 [00:43<00:54,  2.73it/s] 40%|████      | 101/250 [00:43<00:54,  2.73it/s] 41%|████      | 102/250 [00:44<00:53,  2.78it/s] 41%|████      | 103/250 [00:44<00:53,  2.76it/s] 42%|████▏     | 104/250 [00:44<00:53,  2.71it/s] 42%|████▏     | 105/250 [00:45<00:53,  2.72it/s] 42%|████▏     | 106/250 [00:45<00:53,  2.68it/s] 43%|████▎     | 107/250 [00:45<00:52,  2.71it/s] 43%|████▎     | 108/250 [00:46<00:52,  2.70it/s] 44%|████▎     | 109/250 [00:46<00:51,  2.72it/s] 44%|████▍     | 110/250 [00:47<00:52,  2.67it/s] 44%|████▍     | 111/250 [00:47<00:51,  2.70it/s] 45%|████▍     | 112/250 [00:47<00:50,  2.71it/s] 45%|████▌     | 113/250 [00:48<00:50,  2.71it/s] 46%|████▌     | 114/250 [00:48<00:50,  2.69it/s] 46%|████▌     | 115/250 [00:48<00:49,  2.74it/s] 46%|████▋     | 116/250 [00:49<00:48,  2.77it/s] 47%|████▋     | 117/250 [00:49<00:48,  2.76it/s] 47%|████▋     | 118/250 [00:49<00:48,  2.73it/s] 48%|████▊     | 119/250 [00:50<00:50,  2.62it/s] 48%|████▊     | 120/250 [00:50<00:48,  2.66it/s] 48%|████▊     | 121/250 [00:51<00:48,  2.65it/s] 49%|████▉     | 122/250 [00:51<00:48,  2.62it/s] 49%|████▉     | 123/250 [00:51<00:47,  2.67it/s] 50%|████▉     | 124/250 [00:52<00:47,  2.65it/s] 50%|█████     | 125/250 [00:52<00:47,  2.63it/s] 50%|█████     | 126/250 [00:53<00:46,  2.69it/s] 51%|█████     | 127/250 [00:53<00:45,  2.72it/s] 51%|█████     | 128/250 [00:53<00:44,  2.74it/s] 52%|█████▏    | 129/250 [00:54<00:45,  2.65it/s] 52%|█████▏    | 130/250 [00:54<00:45,  2.65it/s] 52%|█████▏    | 131/250 [00:54<00:45,  2.64it/s] 53%|█████▎    | 132/250 [00:55<00:44,  2.67it/s] 53%|█████▎    | 133/250 [00:55<00:43,  2.67it/s] 54%|█████▎    | 134/250 [00:56<00:44,  2.62it/s] 54%|█████▍    | 135/250 [00:56<00:43,  2.62it/s] 54%|█████▍    | 136/250 [00:56<00:42,  2.68it/s] 55%|█████▍    | 137/250 [00:57<00:42,  2.65it/s] 55%|█████▌    | 138/250 [00:57<00:41,  2.70it/s] 56%|█████▌    | 139/250 [00:57<00:40,  2.72it/s] 56%|█████▌    | 140/250 [00:58<00:40,  2.75it/s] 56%|█████▋    | 141/250 [00:58<00:40,  2.72it/s] 57%|█████▋    | 142/250 [00:58<00:39,  2.74it/s] 57%|█████▋    | 143/250 [00:59<00:39,  2.72it/s] 58%|█████▊    | 144/250 [00:59<00:38,  2.72it/s] 58%|█████▊    | 145/250 [01:00<00:38,  2.72it/s] 58%|█████▊    | 146/250 [01:00<00:39,  2.65it/s] 59%|█████▉    | 147/250 [01:00<00:38,  2.68it/s] 59%|█████▉    | 148/250 [01:01<00:38,  2.67it/s] 60%|█████▉    | 149/250 [01:01<00:38,  2.65it/s] 60%|██████    | 150/250 [01:01<00:37,  2.69it/s] 60%|██████    | 151/250 [01:02<00:36,  2.73it/s] 61%|██████    | 152/250 [01:02<00:36,  2.70it/s] 61%|██████    | 153/250 [01:03<00:36,  2.64it/s] 62%|██████▏   | 154/250 [01:03<00:36,  2.63it/s] 62%|██████▏   | 155/250 [01:03<00:36,  2.60it/s] 62%|██████▏   | 156/250 [01:04<00:35,  2.62it/s] 63%|██████▎   | 157/250 [01:04<00:34,  2.66it/s] 63%|██████▎   | 158/250 [01:04<00:34,  2.67it/s] 64%|██████▎   | 159/250 [01:05<00:34,  2.67it/s] 64%|██████▍   | 160/250 [01:05<00:33,  2.65it/s] 64%|██████▍   | 161/250 [01:06<00:34,  2.57it/s] 65%|██████▍   | 162/250 [01:06<00:34,  2.56it/s] 65%|██████▌   | 163/250 [01:06<00:34,  2.55it/s] 66%|██████▌   | 164/250 [01:07<00:32,  2.62it/s] 66%|██████▌   | 165/250 [01:07<00:32,  2.62it/s] 66%|██████▋   | 166/250 [01:08<00:32,  2.59it/s] 67%|██████▋   | 167/250 [01:08<00:31,  2.59it/s] 67%|██████▋   | 168/250 [01:08<00:31,  2.62it/s] 68%|██████▊   | 169/250 [01:09<00:31,  2.61it/s] 68%|██████▊   | 170/250 [01:09<00:30,  2.61it/s] 68%|██████▊   | 171/250 [01:10<00:30,  2.59it/s] 69%|██████▉   | 172/250 [01:10<00:29,  2.65it/s] 69%|██████▉   | 173/250 [01:10<00:28,  2.71it/s] 70%|██████▉   | 174/250 [01:11<00:28,  2.69it/s] 70%|███████   | 175/250 [01:11<00:27,  2.72it/s] 70%|███████   | 176/250 [01:11<00:26,  2.74it/s] 71%|███████   | 177/250 [01:12<00:26,  2.74it/s] 71%|███████   | 178/250 [01:12<00:26,  2.72it/s] 72%|███████▏  | 179/250 [01:12<00:26,  2.70it/s] 72%|███████▏  | 180/250 [01:13<00:25,  2.70it/s] 72%|███████▏  | 181/250 [01:13<00:25,  2.73it/s] 73%|███████▎  | 182/250 [01:14<00:24,  2.74it/s] 73%|███████▎  | 183/250 [01:14<00:24,  2.75it/s] 74%|███████▎  | 184/250 [01:14<00:24,  2.70it/s] 74%|███████▍  | 185/250 [01:15<00:24,  2.70it/s] 74%|███████▍  | 186/250 [01:15<00:23,  2.71it/s] 75%|███████▍  | 187/250 [01:15<00:23,  2.70it/s] 75%|███████▌  | 188/250 [01:16<00:23,  2.69it/s] 76%|███████▌  | 189/250 [01:16<00:22,  2.71it/s] 76%|███████▌  | 190/250 [01:16<00:21,  2.75it/s] 76%|███████▋  | 191/250 [01:17<00:21,  2.74it/s] 77%|███████▋  | 192/250 [01:17<00:21,  2.74it/s] 77%|███████▋  | 193/250 [01:18<00:20,  2.72it/s] 78%|███████▊  | 194/250 [01:18<00:20,  2.74it/s] 78%|███████▊  | 195/250 [01:18<00:20,  2.72it/s] 78%|███████▊  | 196/250 [01:19<00:19,  2.72it/s] 79%|███████▉  | 197/250 [01:19<00:19,  2.73it/s] 79%|███████▉  | 198/250 [01:19<00:19,  2.70it/s] 80%|███████▉  | 199/250 [01:20<00:18,  2.70it/s] 80%|████████  | 200/250 [01:20<00:18,  2.71it/s] 80%|████████  | 201/250 [01:21<00:18,  2.72it/s] 81%|████████  | 202/250 [01:21<00:17,  2.71it/s] 81%|████████  | 203/250 [01:21<00:17,  2.68it/s] 82%|████████▏ | 204/250 [01:22<00:17,  2.66it/s] 82%|████████▏ | 205/250 [01:22<00:17,  2.64it/s] 82%|████████▏ | 206/250 [01:22<00:16,  2.63it/s] 83%|████████▎ | 207/250 [01:23<00:16,  2.64it/s] 83%|████████▎ | 208/250 [01:23<00:15,  2.65it/s] 84%|████████▎ | 209/250 [01:24<00:15,  2.63it/s] 84%|████████▍ | 210/250 [01:24<00:15,  2.65it/s] 84%|████████▍ | 211/250 [01:24<00:14,  2.65it/s] 85%|████████▍ | 212/250 [01:25<00:14,  2.64it/s] 85%|████████▌ | 213/250 [01:25<00:13,  2.66it/s] 86%|████████▌ | 214/250 [01:25<00:13,  2.65it/s] 86%|████████▌ | 215/250 [01:26<00:12,  2.70it/s] 86%|████████▋ | 216/250 [01:26<00:12,  2.67it/s] 87%|████████▋ | 217/250 [01:27<00:12,  2.69it/s] 87%|████████▋ | 218/250 [01:27<00:11,  2.74it/s] 88%|████████▊ | 219/250 [01:27<00:11,  2.77it/s] 88%|████████▊ | 220/250 [01:28<00:10,  2.80it/s] 88%|████████▊ | 221/250 [01:28<00:10,  2.88it/s] 89%|████████▉ | 222/250 [01:28<00:09,  3.00it/s] 89%|████████▉ | 223/250 [01:29<00:08,  3.09it/s] 90%|████████▉ | 224/250 [01:29<00:08,  3.08it/s] 90%|█████████ | 225/250 [01:29<00:07,  3.15it/s] 90%|█████████ | 226/250 [01:29<00:07,  3.20it/s] 91%|█████████ | 227/250 [01:30<00:07,  3.23it/s] 91%|█████████ | 228/250 [01:30<00:06,  3.25it/s] 92%|█████████▏| 229/250 [01:30<00:06,  3.27it/s] 92%|█████████▏| 230/250 [01:31<00:06,  3.29it/s] 92%|█████████▏| 231/250 [01:31<00:05,  3.30it/s] 93%|█████████▎| 232/250 [01:31<00:05,  3.31it/s] 93%|█████████▎| 233/250 [01:32<00:05,  3.31it/s] 94%|█████████▎| 234/250 [01:32<00:04,  3.32it/s] 94%|█████████▍| 235/250 [01:32<00:04,  3.32it/s] 94%|█████████▍| 236/250 [01:32<00:04,  3.32it/s] 95%|█████████▍| 237/250 [01:33<00:03,  3.33it/s] 95%|█████████▌| 238/250 [01:33<00:03,  3.24it/s] 96%|█████████▌| 239/250 [01:33<00:03,  3.26it/s] 96%|█████████▌| 240/250 [01:34<00:03,  3.27it/s] 96%|█████████▋| 241/250 [01:34<00:02,  3.29it/s] 97%|█████████▋| 242/250 [01:34<00:02,  3.30it/s] 97%|█████████▋| 243/250 [01:35<00:02,  3.30it/s] 98%|█████████▊| 244/250 [01:35<00:01,  3.31it/s] 98%|█████████▊| 245/250 [01:35<00:01,  3.31it/s] 98%|█████████▊| 246/250 [01:35<00:01,  3.30it/s] 99%|█████████▉| 247/250 [01:36<00:00,  3.30it/s] 99%|█████████▉| 248/250 [01:36<00:00,  3.31it/s]100%|█████████▉| 249/250 [01:36<00:00,  3.31it/s]100%|██████████| 250/250 [01:37<00:00,  3.22it/s]100%|██████████| 250/250 [01:37<00:00,  2.57it/s]=> result
* total: 25,000
* correct: 19,046
* accuracy: 76.2%
* error: 23.8%
* macro_f1: 75.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/imagenet/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [4/30] batch [20/2000] time 0.602 (0.648) data 0.000 (0.037) loss 2.4277 (2.3480) lr 9.7553e-03 eta 9:42:39
epoch [4/30] batch [40/2000] time 0.598 (0.624) data 0.000 (0.018) loss 3.5840 (2.3500) lr 9.7553e-03 eta 9:21:03
epoch [4/30] batch [60/2000] time 0.593 (0.617) data 0.000 (0.012) loss 2.6133 (2.4080) lr 9.7553e-03 eta 9:14:21
epoch [4/30] batch [80/2000] time 0.600 (0.613) data 0.000 (0.009) loss 6.4609 (2.4568) lr 9.7553e-03 eta 9:10:49
epoch [4/30] batch [100/2000] time 0.673 (0.612) data 0.000 (0.008) loss 2.6582 (2.5830) lr 9.7553e-03 eta 9:09:49
epoch [4/30] batch [120/2000] time 0.599 (0.610) data 0.000 (0.006) loss 7.2227 (2.6258) lr 9.7553e-03 eta 9:08:08
epoch [4/30] batch [140/2000] time 0.599 (0.610) data 0.000 (0.005) loss 0.9126 (2.6517) lr 9.7553e-03 eta 9:07:10
epoch [4/30] batch [160/2000] time 0.601 (0.609) data 0.000 (0.005) loss 0.6436 (2.6688) lr 9.7553e-03 eta 9:06:24
epoch [4/30] batch [180/2000] time 0.595 (0.608) data 0.000 (0.004) loss 0.1570 (2.6703) lr 9.7553e-03 eta 9:05:20
epoch [4/30] batch [200/2000] time 0.610 (0.607) data 0.000 (0.004) loss 1.2070 (2.6685) lr 9.7553e-03 eta 9:04:36
epoch [4/30] batch [220/2000] time 0.597 (0.607) data 0.000 (0.004) loss 4.0938 (2.6289) lr 9.7553e-03 eta 9:03:54
epoch [4/30] batch [240/2000] time 0.605 (0.606) data 0.000 (0.003) loss 4.2344 (2.6092) lr 9.7553e-03 eta 9:03:08
epoch [4/30] batch [260/2000] time 0.603 (0.606) data 0.000 (0.003) loss 2.4473 (2.6013) lr 9.7553e-03 eta 9:02:51
epoch [4/30] batch [280/2000] time 0.594 (0.606) data 0.000 (0.003) loss 4.2617 (2.5773) lr 9.7553e-03 eta 9:02:19
epoch [4/30] batch [300/2000] time 0.605 (0.605) data 0.000 (0.003) loss 2.4492 (2.6428) lr 9.7553e-03 eta 9:01:43
epoch [4/30] batch [320/2000] time 0.602 (0.605) data 0.000 (0.003) loss 3.2637 (2.6539) lr 9.7553e-03 eta 9:01:07
epoch [4/30] batch [340/2000] time 0.591 (0.605) data 0.000 (0.002) loss 2.4512 (2.6489) lr 9.7553e-03 eta 9:00:46
epoch [4/30] batch [360/2000] time 0.600 (0.605) data 0.000 (0.002) loss 2.4180 (2.6680) lr 9.7553e-03 eta 9:00:29
epoch [4/30] batch [380/2000] time 0.595 (0.604) data 0.000 (0.002) loss 2.6406 (2.6642) lr 9.7553e-03 eta 9:00:11
epoch [4/30] batch [400/2000] time 0.606 (0.604) data 0.000 (0.002) loss 2.4453 (2.6514) lr 9.7553e-03 eta 8:59:55
epoch [4/30] batch [420/2000] time 0.596 (0.604) data 0.000 (0.002) loss 4.6055 (2.6652) lr 9.7553e-03 eta 8:59:34
epoch [4/30] batch [440/2000] time 0.603 (0.604) data 0.000 (0.002) loss 5.3711 (2.6885) lr 9.7553e-03 eta 8:59:34
epoch [4/30] batch [460/2000] time 0.598 (0.604) data 0.000 (0.002) loss 0.6162 (2.6996) lr 9.7553e-03 eta 8:59:10
epoch [4/30] batch [480/2000] time 0.601 (0.604) data 0.000 (0.002) loss 3.3340 (2.7003) lr 9.7553e-03 eta 8:59:03
epoch [4/30] batch [500/2000] time 0.596 (0.604) data 0.000 (0.002) loss 2.4746 (2.6814) lr 9.7553e-03 eta 8:58:44
epoch [4/30] batch [520/2000] time 0.607 (0.604) data 0.000 (0.002) loss 6.4805 (2.6769) lr 9.7553e-03 eta 8:58:19
epoch [4/30] batch [540/2000] time 0.599 (0.604) data 0.000 (0.002) loss 4.9141 (2.6643) lr 9.7553e-03 eta 8:57:59
epoch [4/30] batch [560/2000] time 0.599 (0.604) data 0.000 (0.002) loss 3.0879 (2.6469) lr 9.7553e-03 eta 8:57:51
epoch [4/30] batch [580/2000] time 0.596 (0.604) data 0.000 (0.002) loss 0.1611 (2.6482) lr 9.7553e-03 eta 8:57:33
epoch [4/30] batch [600/2000] time 0.602 (0.604) data 0.000 (0.001) loss 0.5938 (2.6585) lr 9.7553e-03 eta 8:57:14
epoch [4/30] batch [620/2000] time 0.605 (0.603) data 0.000 (0.001) loss 1.8213 (2.6640) lr 9.7553e-03 eta 8:56:53
epoch [4/30] batch [640/2000] time 0.596 (0.604) data 0.000 (0.001) loss 1.3916 (2.6616) lr 9.7553e-03 eta 8:56:47
epoch [4/30] batch [660/2000] time 0.605 (0.604) data 0.000 (0.001) loss 1.8125 (2.6686) lr 9.7553e-03 eta 8:56:35
epoch [4/30] batch [680/2000] time 0.599 (0.603) data 0.000 (0.001) loss 2.6309 (2.6833) lr 9.7553e-03 eta 8:56:17
epoch [4/30] batch [700/2000] time 0.597 (0.603) data 0.000 (0.001) loss 9.2656 (2.6813) lr 9.7553e-03 eta 8:56:02
epoch [4/30] batch [720/2000] time 0.594 (0.603) data 0.000 (0.001) loss 2.7793 (2.6766) lr 9.7553e-03 eta 8:55:47
epoch [4/30] batch [740/2000] time 0.600 (0.603) data 0.000 (0.001) loss 0.4587 (2.6954) lr 9.7553e-03 eta 8:55:27
epoch [4/30] batch [760/2000] time 0.609 (0.603) data 0.000 (0.001) loss 5.0117 (2.7014) lr 9.7553e-03 eta 8:55:10
epoch [4/30] batch [780/2000] time 0.602 (0.603) data 0.000 (0.001) loss 4.4531 (2.7024) lr 9.7553e-03 eta 8:54:59
epoch [4/30] batch [800/2000] time 0.597 (0.603) data 0.000 (0.001) loss 3.4902 (2.6894) lr 9.7553e-03 eta 8:54:43
epoch [4/30] batch [820/2000] time 0.599 (0.603) data 0.000 (0.001) loss 5.7109 (2.6925) lr 9.7553e-03 eta 8:54:28
epoch [4/30] batch [840/2000] time 0.595 (0.603) data 0.000 (0.001) loss 2.2305 (2.7033) lr 9.7553e-03 eta 8:54:15
epoch [4/30] batch [860/2000] time 0.595 (0.603) data 0.000 (0.001) loss 2.6777 (2.6997) lr 9.7553e-03 eta 8:53:58
epoch [4/30] batch [880/2000] time 0.606 (0.603) data 0.000 (0.001) loss 6.4609 (2.6937) lr 9.7553e-03 eta 8:53:47
epoch [4/30] batch [900/2000] time 0.630 (0.603) data 0.000 (0.001) loss 0.6611 (2.6893) lr 9.7553e-03 eta 8:53:33
epoch [4/30] batch [920/2000] time 0.596 (0.603) data 0.000 (0.001) loss 2.7832 (2.6845) lr 9.7553e-03 eta 8:53:18
epoch [4/30] batch [940/2000] time 0.602 (0.603) data 0.000 (0.001) loss 0.8584 (2.6781) lr 9.7553e-03 eta 8:53:04
epoch [4/30] batch [960/2000] time 0.597 (0.603) data 0.000 (0.001) loss 5.0234 (2.6713) lr 9.7553e-03 eta 8:52:55
epoch [4/30] batch [980/2000] time 0.601 (0.603) data 0.000 (0.001) loss 3.1582 (2.6787) lr 9.7553e-03 eta 8:52:38
epoch [4/30] batch [1000/2000] time 0.593 (0.603) data 0.000 (0.001) loss 1.2139 (2.6734) lr 9.7553e-03 eta 8:52:23
epoch [4/30] batch [1020/2000] time 0.606 (0.603) data 0.000 (0.001) loss 0.7861 (2.6744) lr 9.7553e-03 eta 8:52:06
epoch [4/30] batch [1040/2000] time 0.597 (0.603) data 0.000 (0.001) loss 2.8594 (2.6668) lr 9.7553e-03 eta 8:51:58
epoch [4/30] batch [1060/2000] time 0.600 (0.603) data 0.000 (0.001) loss 0.8408 (2.6687) lr 9.7553e-03 eta 8:51:42
epoch [4/30] batch [1080/2000] time 0.603 (0.603) data 0.000 (0.001) loss 2.2520 (2.6731) lr 9.7553e-03 eta 8:51:26
epoch [4/30] batch [1100/2000] time 0.600 (0.603) data 0.000 (0.001) loss 1.4785 (2.6765) lr 9.7553e-03 eta 8:51:16
epoch [4/30] batch [1120/2000] time 0.622 (0.603) data 0.000 (0.001) loss 1.8428 (2.6763) lr 9.7553e-03 eta 8:51:06
epoch [4/30] batch [1140/2000] time 0.604 (0.603) data 0.000 (0.001) loss 2.5957 (2.6817) lr 9.7553e-03 eta 8:50:52
epoch [4/30] batch [1160/2000] time 0.596 (0.603) data 0.000 (0.001) loss 2.4688 (2.6930) lr 9.7553e-03 eta 8:50:39
epoch [4/30] batch [1180/2000] time 0.607 (0.603) data 0.000 (0.001) loss 3.0059 (2.6998) lr 9.7553e-03 eta 8:50:25
epoch [4/30] batch [1200/2000] time 0.593 (0.602) data 0.000 (0.001) loss 3.7031 (2.6994) lr 9.7553e-03 eta 8:50:10
epoch [4/30] batch [1220/2000] time 0.597 (0.602) data 0.000 (0.001) loss 3.6426 (2.7151) lr 9.7553e-03 eta 8:49:57
epoch [4/30] batch [1240/2000] time 0.597 (0.602) data 0.000 (0.001) loss 0.2466 (2.7093) lr 9.7553e-03 eta 8:49:46
epoch [4/30] batch [1260/2000] time 0.603 (0.602) data 0.000 (0.001) loss 1.0068 (2.7132) lr 9.7553e-03 eta 8:49:32
epoch [4/30] batch [1280/2000] time 0.593 (0.602) data 0.000 (0.001) loss 0.1873 (2.7089) lr 9.7553e-03 eta 8:49:17
epoch [4/30] batch [1300/2000] time 0.593 (0.602) data 0.000 (0.001) loss 4.0859 (2.7085) lr 9.7553e-03 eta 8:49:05
epoch [4/30] batch [1320/2000] time 0.595 (0.602) data 0.000 (0.001) loss 0.5405 (2.6913) lr 9.7553e-03 eta 8:48:54
epoch [4/30] batch [1340/2000] time 0.599 (0.602) data 0.000 (0.001) loss 3.5371 (2.6927) lr 9.7553e-03 eta 8:48:39
epoch [4/30] batch [1360/2000] time 0.600 (0.602) data 0.000 (0.001) loss 0.9795 (2.6911) lr 9.7553e-03 eta 8:48:28
epoch [4/30] batch [1380/2000] time 0.597 (0.602) data 0.000 (0.001) loss 0.4685 (2.6842) lr 9.7553e-03 eta 8:48:15
epoch [4/30] batch [1400/2000] time 0.595 (0.602) data 0.000 (0.001) loss 4.6562 (2.6841) lr 9.7553e-03 eta 8:48:00
epoch [4/30] batch [1420/2000] time 0.603 (0.602) data 0.000 (0.001) loss 1.7217 (2.6815) lr 9.7553e-03 eta 8:47:50
epoch [4/30] batch [1440/2000] time 0.601 (0.602) data 0.000 (0.001) loss 4.1367 (2.6859) lr 9.7553e-03 eta 8:47:39
epoch [4/30] batch [1460/2000] time 0.603 (0.602) data 0.000 (0.001) loss 3.1289 (2.6905) lr 9.7553e-03 eta 8:47:26
epoch [4/30] batch [1480/2000] time 0.593 (0.602) data 0.000 (0.001) loss 1.0195 (2.6952) lr 9.7553e-03 eta 8:47:12
epoch [4/30] batch [1500/2000] time 0.605 (0.602) data 0.000 (0.001) loss 4.5977 (2.6983) lr 9.7553e-03 eta 8:47:03
epoch [4/30] batch [1520/2000] time 0.598 (0.602) data 0.000 (0.001) loss 2.6582 (2.6929) lr 9.7553e-03 eta 8:46:50
epoch [4/30] batch [1540/2000] time 0.604 (0.602) data 0.000 (0.001) loss 1.1631 (2.6880) lr 9.7553e-03 eta 8:46:36
epoch [4/30] batch [1560/2000] time 0.595 (0.602) data 0.000 (0.001) loss 1.4551 (2.6836) lr 9.7553e-03 eta 8:46:24
epoch [4/30] batch [1580/2000] time 0.598 (0.602) data 0.000 (0.001) loss 0.6147 (2.6738) lr 9.7553e-03 eta 8:46:12
epoch [4/30] batch [1600/2000] time 0.603 (0.602) data 0.000 (0.001) loss 3.0918 (2.6712) lr 9.7553e-03 eta 8:45:58
epoch [4/30] batch [1620/2000] time 0.600 (0.602) data 0.000 (0.001) loss 2.4688 (2.6656) lr 9.7553e-03 eta 8:45:45
epoch [4/30] batch [1640/2000] time 0.599 (0.602) data 0.000 (0.001) loss 0.8999 (2.6618) lr 9.7553e-03 eta 8:45:31
epoch [4/30] batch [1660/2000] time 0.591 (0.602) data 0.000 (0.001) loss 0.3711 (2.6555) lr 9.7553e-03 eta 8:45:17
epoch [4/30] batch [1680/2000] time 0.596 (0.602) data 0.000 (0.001) loss 4.1055 (2.6556) lr 9.7553e-03 eta 8:45:03
epoch [4/30] batch [1700/2000] time 0.608 (0.602) data 0.000 (0.001) loss 5.0898 (2.6544) lr 9.7553e-03 eta 8:44:50
epoch [4/30] batch [1720/2000] time 0.600 (0.602) data 0.000 (0.001) loss 1.9131 (2.6535) lr 9.7553e-03 eta 8:44:36
epoch [4/30] batch [1740/2000] time 0.603 (0.602) data 0.000 (0.001) loss 4.1875 (2.6504) lr 9.7553e-03 eta 8:44:23
epoch [4/30] batch [1760/2000] time 0.598 (0.602) data 0.000 (0.001) loss 3.1914 (2.6517) lr 9.7553e-03 eta 8:44:09
epoch [4/30] batch [1780/2000] time 0.598 (0.602) data 0.000 (0.001) loss 1.7119 (2.6544) lr 9.7553e-03 eta 8:43:57
epoch [4/30] batch [1800/2000] time 0.598 (0.602) data 0.000 (0.001) loss 1.7451 (2.6532) lr 9.7553e-03 eta 8:43:45
epoch [4/30] batch [1820/2000] time 0.615 (0.602) data 0.000 (0.001) loss 4.8555 (2.6478) lr 9.7553e-03 eta 8:43:32
epoch [4/30] batch [1840/2000] time 0.599 (0.602) data 0.000 (0.001) loss 2.0957 (2.6435) lr 9.7553e-03 eta 8:43:19
epoch [4/30] batch [1860/2000] time 0.597 (0.602) data 0.000 (0.001) loss 2.4434 (2.6482) lr 9.7553e-03 eta 8:43:06
epoch [4/30] batch [1880/2000] time 0.605 (0.602) data 0.000 (0.001) loss 4.0391 (2.6496) lr 9.7553e-03 eta 8:42:56
epoch [4/30] batch [1900/2000] time 0.607 (0.602) data 0.000 (0.001) loss 4.0859 (2.6538) lr 9.7553e-03 eta 8:42:45
epoch [4/30] batch [1920/2000] time 0.596 (0.602) data 0.000 (0.001) loss 4.4727 (2.6498) lr 9.7553e-03 eta 8:42:33
epoch [4/30] batch [1940/2000] time 0.597 (0.602) data 0.000 (0.001) loss 3.4395 (2.6540) lr 9.7553e-03 eta 8:42:20
epoch [4/30] batch [1960/2000] time 0.599 (0.602) data 0.000 (0.001) loss 0.6909 (2.6564) lr 9.7553e-03 eta 8:42:09
epoch [4/30] batch [1980/2000] time 0.590 (0.602) data 0.000 (0.001) loss 0.0347 (2.6557) lr 9.7553e-03 eta 8:41:55
epoch [4/30] batch [2000/2000] time 0.592 (0.602) data 0.000 (0.001) loss 4.3594 (2.6571) lr 9.5677e-03 eta 8:41:38
Evaluate on the *val* set
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:02<11:29,  2.77s/it]  1%|          | 2/250 [00:03<06:26,  1.56s/it]  1%|          | 3/250 [00:03<04:21,  1.06s/it]  2%|▏         | 4/250 [00:04<03:14,  1.26it/s]  2%|▏         | 5/250 [00:04<02:38,  1.55it/s]  2%|▏         | 6/250 [00:05<02:14,  1.81it/s]  3%|▎         | 7/250 [00:05<02:02,  1.99it/s]  3%|▎         | 8/250 [00:05<01:53,  2.13it/s]  4%|▎         | 9/250 [00:06<01:45,  2.28it/s]  4%|▍         | 10/250 [00:06<01:40,  2.38it/s]  4%|▍         | 11/250 [00:06<01:36,  2.47it/s]  5%|▍         | 12/250 [00:07<01:33,  2.54it/s]  5%|▌         | 13/250 [00:07<01:32,  2.55it/s]  6%|▌         | 14/250 [00:08<01:30,  2.62it/s]  6%|▌         | 15/250 [00:08<01:29,  2.62it/s]  6%|▋         | 16/250 [00:08<01:28,  2.64it/s]  7%|▋         | 17/250 [00:09<01:28,  2.64it/s]  7%|▋         | 18/250 [00:09<01:26,  2.67it/s]  8%|▊         | 19/250 [00:09<01:24,  2.74it/s]  8%|▊         | 20/250 [00:10<01:23,  2.77it/s]  8%|▊         | 21/250 [00:10<01:23,  2.73it/s]  9%|▉         | 22/250 [00:11<01:22,  2.76it/s]  9%|▉         | 23/250 [00:11<01:22,  2.75it/s] 10%|▉         | 24/250 [00:11<01:23,  2.72it/s] 10%|█         | 25/250 [00:12<01:22,  2.73it/s] 10%|█         | 26/250 [00:12<01:21,  2.75it/s] 11%|█         | 27/250 [00:12<01:20,  2.77it/s] 11%|█         | 28/250 [00:13<01:20,  2.76it/s] 12%|█▏        | 29/250 [00:13<01:20,  2.73it/s] 12%|█▏        | 30/250 [00:13<01:19,  2.75it/s] 12%|█▏        | 31/250 [00:14<01:18,  2.77it/s] 13%|█▎        | 32/250 [00:14<01:19,  2.74it/s] 13%|█▎        | 33/250 [00:15<01:18,  2.76it/s] 14%|█▎        | 34/250 [00:15<01:19,  2.71it/s] 14%|█▍        | 35/250 [00:15<01:18,  2.73it/s] 14%|█▍        | 36/250 [00:16<01:17,  2.76it/s] 15%|█▍        | 37/250 [00:16<01:19,  2.68it/s] 15%|█▌        | 38/250 [00:16<01:19,  2.65it/s] 16%|█▌        | 39/250 [00:17<01:20,  2.64it/s] 16%|█▌        | 40/250 [00:17<01:18,  2.66it/s] 16%|█▋        | 41/250 [00:18<01:18,  2.65it/s] 17%|█▋        | 42/250 [00:18<01:17,  2.69it/s] 17%|█▋        | 43/250 [00:18<01:16,  2.71it/s] 18%|█▊        | 44/250 [00:19<01:15,  2.72it/s] 18%|█▊        | 45/250 [00:19<01:17,  2.65it/s] 18%|█▊        | 46/250 [00:19<01:16,  2.68it/s] 19%|█▉        | 47/250 [00:20<01:14,  2.73it/s] 19%|█▉        | 48/250 [00:20<01:14,  2.73it/s] 20%|█▉        | 49/250 [00:20<01:13,  2.74it/s] 20%|██        | 50/250 [00:21<01:12,  2.77it/s] 20%|██        | 51/250 [00:21<01:11,  2.79it/s] 21%|██        | 52/250 [00:22<01:11,  2.78it/s] 21%|██        | 53/250 [00:22<01:11,  2.75it/s] 22%|██▏       | 54/250 [00:22<01:11,  2.72it/s] 22%|██▏       | 55/250 [00:23<01:11,  2.72it/s] 22%|██▏       | 56/250 [00:23<01:12,  2.68it/s] 23%|██▎       | 57/250 [00:23<01:12,  2.66it/s] 23%|██▎       | 58/250 [00:24<01:12,  2.63it/s] 24%|██▎       | 59/250 [00:24<01:13,  2.59it/s] 24%|██▍       | 60/250 [00:25<01:11,  2.64it/s] 24%|██▍       | 61/250 [00:25<01:10,  2.68it/s] 25%|██▍       | 62/250 [00:25<01:08,  2.73it/s] 25%|██▌       | 63/250 [00:26<01:08,  2.73it/s] 26%|██▌       | 64/250 [00:26<01:07,  2.74it/s] 26%|██▌       | 65/250 [00:26<01:07,  2.72it/s] 26%|██▋       | 66/250 [00:27<01:07,  2.72it/s] 27%|██▋       | 67/250 [00:27<01:06,  2.73it/s] 27%|██▋       | 68/250 [00:27<01:05,  2.77it/s] 28%|██▊       | 69/250 [00:28<01:05,  2.78it/s] 28%|██▊       | 70/250 [00:28<01:04,  2.79it/s] 28%|██▊       | 71/250 [00:29<01:04,  2.77it/s] 29%|██▉       | 72/250 [00:29<01:04,  2.76it/s] 29%|██▉       | 73/250 [00:29<01:04,  2.75it/s] 30%|██▉       | 74/250 [00:30<01:04,  2.74it/s] 30%|███       | 75/250 [00:30<01:03,  2.74it/s] 30%|███       | 76/250 [00:30<01:03,  2.76it/s] 31%|███       | 77/250 [00:31<01:02,  2.77it/s] 31%|███       | 78/250 [00:31<01:01,  2.78it/s] 32%|███▏      | 79/250 [00:31<01:01,  2.78it/s] 32%|███▏      | 80/250 [00:32<01:01,  2.78it/s] 32%|███▏      | 81/250 [00:32<01:01,  2.75it/s] 33%|███▎      | 82/250 [00:33<01:01,  2.73it/s] 33%|███▎      | 83/250 [00:33<01:00,  2.74it/s] 34%|███▎      | 84/250 [00:33<01:00,  2.76it/s] 34%|███▍      | 85/250 [00:34<00:59,  2.76it/s] 34%|███▍      | 86/250 [00:34<01:00,  2.69it/s] 35%|███▍      | 87/250 [00:34<01:01,  2.66it/s] 35%|███▌      | 88/250 [00:35<01:00,  2.70it/s] 36%|███▌      | 89/250 [00:35<00:59,  2.73it/s] 36%|███▌      | 90/250 [00:35<00:58,  2.74it/s] 36%|███▋      | 91/250 [00:36<00:58,  2.73it/s] 37%|███▋      | 92/250 [00:36<00:57,  2.75it/s] 37%|███▋      | 93/250 [00:37<00:56,  2.78it/s] 38%|███▊      | 94/250 [00:37<00:55,  2.79it/s] 38%|███▊      | 95/250 [00:37<00:56,  2.76it/s] 38%|███▊      | 96/250 [00:38<00:55,  2.76it/s] 39%|███▉      | 97/250 [00:38<00:54,  2.78it/s] 39%|███▉      | 98/250 [00:38<00:55,  2.75it/s] 40%|███▉      | 99/250 [00:39<00:53,  2.80it/s] 40%|████      | 100/250 [00:39<00:53,  2.78it/s] 40%|████      | 101/250 [00:39<00:54,  2.72it/s] 41%|████      | 102/250 [00:40<00:54,  2.72it/s] 41%|████      | 103/250 [00:40<00:53,  2.74it/s] 42%|████▏     | 104/250 [00:41<00:53,  2.74it/s] 42%|████▏     | 105/250 [00:41<00:52,  2.74it/s] 42%|████▏     | 106/250 [00:41<00:52,  2.74it/s] 43%|████▎     | 107/250 [00:42<00:52,  2.73it/s] 43%|████▎     | 108/250 [00:42<00:52,  2.69it/s] 44%|████▎     | 109/250 [00:42<00:52,  2.68it/s] 44%|████▍     | 110/250 [00:43<00:52,  2.68it/s] 44%|████▍     | 111/250 [00:43<00:51,  2.68it/s] 45%|████▍     | 112/250 [00:44<00:50,  2.72it/s] 45%|████▌     | 113/250 [00:44<00:51,  2.66it/s] 46%|████▌     | 114/250 [00:44<00:51,  2.66it/s] 46%|████▌     | 115/250 [00:45<00:50,  2.69it/s] 46%|████▋     | 116/250 [00:45<00:50,  2.66it/s] 47%|████▋     | 117/250 [00:45<00:49,  2.69it/s] 47%|████▋     | 118/250 [00:46<00:49,  2.68it/s] 48%|████▊     | 119/250 [00:46<00:49,  2.65it/s] 48%|████▊     | 120/250 [00:47<00:48,  2.66it/s] 48%|████▊     | 121/250 [00:47<00:48,  2.66it/s] 49%|████▉     | 122/250 [00:47<00:48,  2.66it/s] 49%|████▉     | 123/250 [00:48<00:47,  2.65it/s] 50%|████▉     | 124/250 [00:48<00:47,  2.68it/s] 50%|█████     | 125/250 [00:48<00:46,  2.71it/s] 50%|█████     | 126/250 [00:49<00:45,  2.71it/s] 51%|█████     | 127/250 [00:49<00:46,  2.67it/s] 51%|█████     | 128/250 [00:50<00:45,  2.65it/s] 52%|█████▏    | 129/250 [00:50<00:45,  2.68it/s] 52%|█████▏    | 130/250 [00:50<00:44,  2.68it/s] 52%|█████▏    | 131/250 [00:51<00:43,  2.71it/s] 53%|█████▎    | 132/250 [00:51<00:43,  2.72it/s] 53%|█████▎    | 133/250 [00:51<00:43,  2.72it/s] 54%|█████▎    | 134/250 [00:52<00:42,  2.71it/s] 54%|█████▍    | 135/250 [00:52<00:42,  2.72it/s] 54%|█████▍    | 136/250 [00:53<00:42,  2.66it/s] 55%|█████▍    | 137/250 [00:53<00:42,  2.65it/s] 55%|█████▌    | 138/250 [00:53<00:41,  2.70it/s] 56%|█████▌    | 139/250 [00:54<00:40,  2.74it/s] 56%|█████▌    | 140/250 [00:54<00:40,  2.70it/s] 56%|█████▋    | 141/250 [00:54<00:40,  2.70it/s] 57%|█████▋    | 142/250 [00:55<00:40,  2.66it/s] 57%|█████▋    | 143/250 [00:55<00:39,  2.69it/s] 58%|█████▊    | 144/250 [00:55<00:38,  2.72it/s] 58%|█████▊    | 145/250 [00:56<00:38,  2.76it/s] 58%|█████▊    | 146/250 [00:56<00:37,  2.74it/s] 59%|█████▉    | 147/250 [00:57<00:37,  2.76it/s] 59%|█████▉    | 148/250 [00:57<00:36,  2.76it/s] 60%|█████▉    | 149/250 [00:57<00:37,  2.70it/s] 60%|██████    | 150/250 [00:58<00:37,  2.69it/s] 60%|██████    | 151/250 [00:58<00:36,  2.69it/s] 61%|██████    | 152/250 [00:58<00:35,  2.73it/s] 61%|██████    | 153/250 [00:59<00:35,  2.73it/s] 62%|██████▏   | 154/250 [00:59<00:34,  2.76it/s] 62%|██████▏   | 155/250 [00:59<00:35,  2.69it/s] 62%|██████▏   | 156/250 [01:00<00:34,  2.69it/s] 63%|██████▎   | 157/250 [01:00<00:34,  2.69it/s] 63%|██████▎   | 158/250 [01:01<00:33,  2.72it/s] 64%|██████▎   | 159/250 [01:01<00:33,  2.73it/s] 64%|██████▍   | 160/250 [01:01<00:33,  2.71it/s] 64%|██████▍   | 161/250 [01:02<00:32,  2.70it/s] 65%|██████▍   | 162/250 [01:02<00:33,  2.63it/s] 65%|██████▌   | 163/250 [01:02<00:32,  2.66it/s] 66%|██████▌   | 164/250 [01:03<00:32,  2.64it/s] 66%|██████▌   | 165/250 [01:03<00:32,  2.64it/s] 66%|██████▋   | 166/250 [01:04<00:31,  2.66it/s] 67%|██████▋   | 167/250 [01:04<00:30,  2.69it/s] 67%|██████▋   | 168/250 [01:04<00:30,  2.67it/s] 68%|██████▊   | 169/250 [01:05<00:30,  2.64it/s] 68%|██████▊   | 170/250 [01:05<00:29,  2.68it/s] 68%|██████▊   | 171/250 [01:05<00:29,  2.65it/s] 69%|██████▉   | 172/250 [01:06<00:29,  2.69it/s] 69%|██████▉   | 173/250 [01:06<00:28,  2.70it/s] 70%|██████▉   | 174/250 [01:07<00:27,  2.72it/s] 70%|███████   | 175/250 [01:07<00:27,  2.73it/s] 70%|███████   | 176/250 [01:07<00:27,  2.70it/s] 71%|███████   | 177/250 [01:08<00:26,  2.75it/s] 71%|███████   | 178/250 [01:08<00:26,  2.73it/s] 72%|███████▏  | 179/250 [01:08<00:25,  2.75it/s] 72%|███████▏  | 180/250 [01:09<00:25,  2.72it/s] 72%|███████▏  | 181/250 [01:09<00:25,  2.74it/s] 73%|███████▎  | 182/250 [01:09<00:24,  2.75it/s] 73%|███████▎  | 183/250 [01:10<00:24,  2.71it/s] 74%|███████▎  | 184/250 [01:10<00:24,  2.71it/s] 74%|███████▍  | 185/250 [01:11<00:23,  2.74it/s] 74%|███████▍  | 186/250 [01:11<00:23,  2.73it/s] 75%|███████▍  | 187/250 [01:11<00:23,  2.73it/s] 75%|███████▌  | 188/250 [01:12<00:22,  2.71it/s] 76%|███████▌  | 189/250 [01:12<00:22,  2.71it/s] 76%|███████▌  | 190/250 [01:12<00:21,  2.76it/s] 76%|███████▋  | 191/250 [01:13<00:21,  2.77it/s] 77%|███████▋  | 192/250 [01:13<00:21,  2.76it/s] 77%|███████▋  | 193/250 [01:14<00:20,  2.77it/s] 78%|███████▊  | 194/250 [01:14<00:20,  2.79it/s] 78%|███████▊  | 195/250 [01:14<00:19,  2.77it/s] 78%|███████▊  | 196/250 [01:15<00:19,  2.77it/s] 79%|███████▉  | 197/250 [01:15<00:19,  2.70it/s] 79%|███████▉  | 198/250 [01:15<00:19,  2.63it/s] 80%|███████▉  | 199/250 [01:16<00:19,  2.60it/s] 80%|████████  | 200/250 [01:16<00:19,  2.63it/s] 80%|████████  | 201/250 [01:17<00:18,  2.66it/s] 81%|████████  | 202/250 [01:17<00:17,  2.71it/s] 81%|████████  | 203/250 [01:17<00:17,  2.65it/s] 82%|████████▏ | 204/250 [01:18<00:17,  2.68it/s] 82%|████████▏ | 205/250 [01:18<00:16,  2.71it/s] 82%|████████▏ | 206/250 [01:18<00:16,  2.65it/s] 83%|████████▎ | 207/250 [01:19<00:16,  2.68it/s] 83%|████████▎ | 208/250 [01:19<00:15,  2.69it/s] 84%|████████▎ | 209/250 [01:20<00:15,  2.67it/s] 84%|████████▍ | 210/250 [01:20<00:14,  2.71it/s] 84%|████████▍ | 211/250 [01:20<00:14,  2.68it/s] 85%|████████▍ | 212/250 [01:21<00:13,  2.77it/s] 85%|████████▌ | 213/250 [01:21<00:13,  2.75it/s] 86%|████████▌ | 214/250 [01:21<00:13,  2.74it/s] 86%|████████▌ | 215/250 [01:22<00:12,  2.76it/s] 86%|████████▋ | 216/250 [01:22<00:12,  2.77it/s] 87%|████████▋ | 217/250 [01:22<00:11,  2.77it/s] 87%|████████▋ | 218/250 [01:23<00:11,  2.77it/s] 88%|████████▊ | 219/250 [01:23<00:11,  2.75it/s] 88%|████████▊ | 220/250 [01:23<00:10,  2.82it/s] 88%|████████▊ | 221/250 [01:24<00:10,  2.88it/s] 89%|████████▉ | 222/250 [01:24<00:09,  2.98it/s] 89%|████████▉ | 223/250 [01:24<00:08,  3.07it/s] 90%|████████▉ | 224/250 [01:25<00:08,  3.14it/s] 90%|█████████ | 225/250 [01:25<00:07,  3.19it/s] 90%|█████████ | 226/250 [01:25<00:07,  3.21it/s] 91%|█████████ | 227/250 [01:26<00:07,  3.23it/s] 91%|█████████ | 228/250 [01:26<00:06,  3.25it/s] 92%|█████████▏| 229/250 [01:26<00:06,  3.27it/s] 92%|█████████▏| 230/250 [01:27<00:06,  3.28it/s] 92%|█████████▏| 231/250 [01:27<00:05,  3.29it/s] 93%|█████████▎| 232/250 [01:27<00:05,  3.30it/s] 93%|█████████▎| 233/250 [01:27<00:05,  3.30it/s] 94%|█████████▎| 234/250 [01:28<00:04,  3.30it/s] 94%|█████████▍| 235/250 [01:28<00:04,  3.29it/s] 94%|█████████▍| 236/250 [01:28<00:04,  3.30it/s] 95%|█████████▍| 237/250 [01:29<00:03,  3.30it/s] 95%|█████████▌| 238/250 [01:29<00:03,  3.30it/s] 96%|█████████▌| 239/250 [01:29<00:03,  3.30it/s] 96%|█████████▌| 240/250 [01:30<00:03,  3.31it/s] 96%|█████████▋| 241/250 [01:30<00:02,  3.31it/s] 97%|█████████▋| 242/250 [01:30<00:02,  3.31it/s] 97%|█████████▋| 243/250 [01:30<00:02,  3.31it/s] 98%|█████████▊| 244/250 [01:31<00:01,  3.31it/s] 98%|█████████▊| 245/250 [01:31<00:01,  3.31it/s] 98%|█████████▊| 246/250 [01:31<00:01,  3.31it/s] 99%|█████████▉| 247/250 [01:32<00:00,  3.31it/s] 99%|█████████▉| 248/250 [01:32<00:00,  3.31it/s]100%|█████████▉| 249/250 [01:32<00:00,  3.31it/s]100%|██████████| 250/250 [01:33<00:00,  3.32it/s]100%|██████████| 250/250 [01:33<00:00,  2.68it/s]=> result
* total: 25,000
* correct: 19,102
* accuracy: 76.4%
* error: 23.6%
* macro_f1: 75.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/imagenet/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [5/30] batch [20/2000] time 0.600 (0.643) data 0.000 (0.039) loss 2.5879 (2.7792) lr 9.5677e-03 eta 9:17:02
epoch [5/30] batch [40/2000] time 0.597 (0.623) data 0.000 (0.019) loss 1.7891 (2.8056) lr 9.5677e-03 eta 8:59:13
epoch [5/30] batch [60/2000] time 0.598 (0.618) data 0.000 (0.013) loss 1.4238 (2.9990) lr 9.5677e-03 eta 8:54:33
epoch [5/30] batch [80/2000] time 0.606 (0.613) data 0.000 (0.010) loss 1.5596 (2.7811) lr 9.5677e-03 eta 8:50:49
epoch [5/30] batch [100/2000] time 0.604 (0.611) data 0.000 (0.008) loss 1.7178 (2.7389) lr 9.5677e-03 eta 8:48:46
epoch [5/30] batch [120/2000] time 0.595 (0.609) data 0.000 (0.007) loss 3.3594 (2.6933) lr 9.5677e-03 eta 8:46:45
epoch [5/30] batch [140/2000] time 0.603 (0.609) data 0.000 (0.006) loss 1.0420 (2.6255) lr 9.5677e-03 eta 8:46:28
epoch [5/30] batch [160/2000] time 0.591 (0.608) data 0.000 (0.005) loss 1.6045 (2.6589) lr 9.5677e-03 eta 8:45:16
epoch [5/30] batch [180/2000] time 0.600 (0.607) data 0.000 (0.005) loss 3.4023 (2.6599) lr 9.5677e-03 eta 8:44:22
epoch [5/30] batch [200/2000] time 0.608 (0.607) data 0.000 (0.004) loss 1.2646 (2.6861) lr 9.5677e-03 eta 8:43:42
epoch [5/30] batch [220/2000] time 0.611 (0.606) data 0.000 (0.004) loss 0.8789 (2.6863) lr 9.5677e-03 eta 8:43:09
epoch [5/30] batch [240/2000] time 0.596 (0.606) data 0.000 (0.003) loss 1.4072 (2.6951) lr 9.5677e-03 eta 8:42:42
epoch [5/30] batch [260/2000] time 0.595 (0.605) data 0.000 (0.003) loss 4.4375 (2.6795) lr 9.5677e-03 eta 8:42:06
epoch [5/30] batch [280/2000] time 0.632 (0.605) data 0.000 (0.003) loss 0.7031 (2.6838) lr 9.5677e-03 eta 8:41:48
epoch [5/30] batch [300/2000] time 0.595 (0.605) data 0.000 (0.003) loss 1.5586 (2.6386) lr 9.5677e-03 eta 8:41:06
epoch [5/30] batch [320/2000] time 0.599 (0.604) data 0.000 (0.003) loss 0.1915 (2.5998) lr 9.5677e-03 eta 8:40:34
epoch [5/30] batch [340/2000] time 0.610 (0.604) data 0.000 (0.003) loss 0.6099 (2.6349) lr 9.5677e-03 eta 8:40:19
epoch [5/30] batch [360/2000] time 0.593 (0.604) data 0.000 (0.002) loss 3.9570 (2.6449) lr 9.5677e-03 eta 8:39:49
epoch [5/30] batch [380/2000] time 0.599 (0.604) data 0.000 (0.002) loss 0.8862 (2.6476) lr 9.5677e-03 eta 8:39:29
epoch [5/30] batch [400/2000] time 0.600 (0.604) data 0.000 (0.002) loss 0.4502 (2.6592) lr 9.5677e-03 eta 8:39:05
epoch [5/30] batch [420/2000] time 0.604 (0.604) data 0.000 (0.002) loss 5.3828 (2.6764) lr 9.5677e-03 eta 8:38:50
epoch [5/30] batch [440/2000] time 0.606 (0.603) data 0.000 (0.002) loss 3.4160 (2.6430) lr 9.5677e-03 eta 8:38:28
epoch [5/30] batch [460/2000] time 0.597 (0.603) data 0.000 (0.002) loss 2.4531 (2.6354) lr 9.5677e-03 eta 8:38:04
epoch [5/30] batch [480/2000] time 0.599 (0.603) data 0.000 (0.002) loss 0.7002 (2.6430) lr 9.5677e-03 eta 8:37:42
epoch [5/30] batch [500/2000] time 0.600 (0.603) data 0.000 (0.002) loss 1.0479 (2.6571) lr 9.5677e-03 eta 8:37:26
epoch [5/30] batch [520/2000] time 0.597 (0.603) data 0.000 (0.002) loss 6.3086 (2.6633) lr 9.5677e-03 eta 8:37:16
epoch [5/30] batch [540/2000] time 0.595 (0.603) data 0.000 (0.002) loss 3.1484 (2.6873) lr 9.5677e-03 eta 8:36:53
epoch [5/30] batch [560/2000] time 0.593 (0.603) data 0.000 (0.002) loss 1.7061 (2.6847) lr 9.5677e-03 eta 8:36:33
epoch [5/30] batch [580/2000] time 0.595 (0.603) data 0.000 (0.002) loss 3.5234 (2.6718) lr 9.5677e-03 eta 8:36:23
epoch [5/30] batch [600/2000] time 0.608 (0.602) data 0.000 (0.002) loss 2.8926 (2.6744) lr 9.5677e-03 eta 8:36:06
epoch [5/30] batch [620/2000] time 0.611 (0.603) data 0.000 (0.001) loss 0.7065 (2.6770) lr 9.5677e-03 eta 8:35:57
epoch [5/30] batch [640/2000] time 0.594 (0.602) data 0.000 (0.001) loss 0.8755 (2.6747) lr 9.5677e-03 eta 8:35:41
epoch [5/30] batch [660/2000] time 0.604 (0.602) data 0.000 (0.001) loss 1.6143 (2.6918) lr 9.5677e-03 eta 8:35:23
epoch [5/30] batch [680/2000] time 0.598 (0.602) data 0.000 (0.001) loss 0.4001 (2.6820) lr 9.5677e-03 eta 8:35:11
epoch [5/30] batch [700/2000] time 0.607 (0.602) data 0.000 (0.001) loss 2.6816 (2.6854) lr 9.5677e-03 eta 8:34:56
epoch [5/30] batch [720/2000] time 0.596 (0.602) data 0.000 (0.001) loss 2.2480 (2.6745) lr 9.5677e-03 eta 8:34:37
epoch [5/30] batch [740/2000] time 0.595 (0.602) data 0.000 (0.001) loss 4.6914 (2.6814) lr 9.5677e-03 eta 8:34:32
epoch [5/30] batch [760/2000] time 0.592 (0.602) data 0.000 (0.001) loss 5.6484 (2.6732) lr 9.5677e-03 eta 8:34:20
epoch [5/30] batch [780/2000] time 0.602 (0.602) data 0.000 (0.001) loss 0.5234 (2.6573) lr 9.5677e-03 eta 8:34:07
epoch [5/30] batch [800/2000] time 0.597 (0.602) data 0.000 (0.001) loss 7.0742 (2.6466) lr 9.5677e-03 eta 8:33:59
epoch [5/30] batch [820/2000] time 0.602 (0.602) data 0.000 (0.001) loss 3.0723 (2.6557) lr 9.5677e-03 eta 8:33:47
epoch [5/30] batch [840/2000] time 0.599 (0.602) data 0.000 (0.001) loss 2.3105 (2.6422) lr 9.5677e-03 eta 8:33:33
epoch [5/30] batch [860/2000] time 0.596 (0.602) data 0.000 (0.001) loss 1.3271 (2.6401) lr 9.5677e-03 eta 8:33:17
epoch [5/30] batch [880/2000] time 0.602 (0.602) data 0.000 (0.001) loss 2.2715 (2.6320) lr 9.5677e-03 eta 8:33:07
epoch [5/30] batch [900/2000] time 0.594 (0.602) data 0.000 (0.001) loss 0.4595 (2.6239) lr 9.5677e-03 eta 8:33:01
epoch [5/30] batch [920/2000] time 0.601 (0.602) data 0.000 (0.001) loss 2.1543 (2.6267) lr 9.5677e-03 eta 8:32:48
epoch [5/30] batch [940/2000] time 0.595 (0.602) data 0.000 (0.001) loss 1.8145 (2.6261) lr 9.5677e-03 eta 8:32:37
epoch [5/30] batch [960/2000] time 0.601 (0.602) data 0.000 (0.001) loss 1.1641 (2.6216) lr 9.5677e-03 eta 8:32:26
epoch [5/30] batch [980/2000] time 0.595 (0.602) data 0.000 (0.001) loss 0.7705 (2.6328) lr 9.5677e-03 eta 8:32:10
epoch [5/30] batch [1000/2000] time 0.598 (0.602) data 0.000 (0.001) loss 5.0234 (2.6366) lr 9.5677e-03 eta 8:32:02
epoch [5/30] batch [1020/2000] time 0.629 (0.602) data 0.000 (0.001) loss 0.9819 (2.6308) lr 9.5677e-03 eta 8:31:48
epoch [5/30] batch [1040/2000] time 0.614 (0.602) data 0.000 (0.001) loss 5.1289 (2.6279) lr 9.5677e-03 eta 8:31:36
epoch [5/30] batch [1060/2000] time 0.600 (0.602) data 0.000 (0.001) loss 4.4453 (2.6146) lr 9.5677e-03 eta 8:31:24
epoch [5/30] batch [1080/2000] time 0.603 (0.602) data 0.000 (0.001) loss 2.2871 (2.6041) lr 9.5677e-03 eta 8:31:13
epoch [5/30] batch [1100/2000] time 0.595 (0.602) data 0.000 (0.001) loss 3.1777 (2.6025) lr 9.5677e-03 eta 8:31:05
epoch [5/30] batch [1120/2000] time 0.599 (0.602) data 0.000 (0.001) loss 2.2910 (2.5982) lr 9.5677e-03 eta 8:30:51
epoch [5/30] batch [1140/2000] time 0.597 (0.602) data 0.000 (0.001) loss 1.9053 (2.5924) lr 9.5677e-03 eta 8:30:39
epoch [5/30] batch [1160/2000] time 0.592 (0.602) data 0.000 (0.001) loss 1.6836 (2.5871) lr 9.5677e-03 eta 8:30:24
epoch [5/30] batch [1180/2000] time 0.610 (0.602) data 0.000 (0.001) loss 1.4053 (2.5973) lr 9.5677e-03 eta 8:30:11
epoch [5/30] batch [1200/2000] time 0.597 (0.602) data 0.000 (0.001) loss 0.1515 (2.6005) lr 9.5677e-03 eta 8:29:56
epoch [5/30] batch [1220/2000] time 0.591 (0.602) data 0.000 (0.001) loss 0.4734 (2.5909) lr 9.5677e-03 eta 8:29:40
epoch [5/30] batch [1240/2000] time 0.595 (0.602) data 0.000 (0.001) loss 5.7891 (2.5957) lr 9.5677e-03 eta 8:29:25
epoch [5/30] batch [1260/2000] time 0.596 (0.602) data 0.000 (0.001) loss 0.6606 (2.5910) lr 9.5677e-03 eta 8:29:10
epoch [5/30] batch [1280/2000] time 0.596 (0.602) data 0.000 (0.001) loss 3.1973 (2.5913) lr 9.5677e-03 eta 8:28:55
epoch [5/30] batch [1300/2000] time 0.600 (0.602) data 0.000 (0.001) loss 1.7422 (2.5795) lr 9.5677e-03 eta 8:28:42
epoch [5/30] batch [1320/2000] time 0.601 (0.602) data 0.000 (0.001) loss 1.6787 (2.5827) lr 9.5677e-03 eta 8:28:28
epoch [5/30] batch [1340/2000] time 0.667 (0.602) data 0.000 (0.001) loss 6.1523 (2.5837) lr 9.5677e-03 eta 8:28:19
epoch [5/30] batch [1360/2000] time 0.605 (0.602) data 0.000 (0.001) loss 2.7695 (2.5849) lr 9.5677e-03 eta 8:28:05
epoch [5/30] batch [1380/2000] time 0.601 (0.602) data 0.000 (0.001) loss 0.8687 (2.5844) lr 9.5677e-03 eta 8:27:51
epoch [5/30] batch [1400/2000] time 0.592 (0.602) data 0.000 (0.001) loss 1.5410 (2.5814) lr 9.5677e-03 eta 8:27:38
epoch [5/30] batch [1420/2000] time 0.591 (0.602) data 0.000 (0.001) loss 2.0840 (2.5737) lr 9.5677e-03 eta 8:27:24
epoch [5/30] batch [1440/2000] time 0.602 (0.602) data 0.000 (0.001) loss 1.3418 (2.5728) lr 9.5677e-03 eta 8:27:11
epoch [5/30] batch [1460/2000] time 0.597 (0.602) data 0.000 (0.001) loss 3.9570 (2.5802) lr 9.5677e-03 eta 8:27:02
epoch [5/30] batch [1480/2000] time 0.596 (0.602) data 0.000 (0.001) loss 4.0234 (2.5772) lr 9.5677e-03 eta 8:26:47
epoch [5/30] batch [1500/2000] time 0.594 (0.602) data 0.000 (0.001) loss 5.9922 (2.5677) lr 9.5677e-03 eta 8:26:35
epoch [5/30] batch [1520/2000] time 0.597 (0.602) data 0.000 (0.001) loss 2.1348 (2.5628) lr 9.5677e-03 eta 8:26:22
epoch [5/30] batch [1540/2000] time 0.602 (0.602) data 0.000 (0.001) loss 2.5332 (2.5603) lr 9.5677e-03 eta 8:26:08
epoch [5/30] batch [1560/2000] time 0.594 (0.602) data 0.000 (0.001) loss 2.1426 (2.5586) lr 9.5677e-03 eta 8:25:59
epoch [5/30] batch [1580/2000] time 0.601 (0.602) data 0.000 (0.001) loss 3.1230 (2.5537) lr 9.5677e-03 eta 8:25:46
epoch [5/30] batch [1600/2000] time 0.596 (0.602) data 0.000 (0.001) loss 10.4219 (2.5682) lr 9.5677e-03 eta 8:25:32
epoch [5/30] batch [1620/2000] time 0.594 (0.602) data 0.000 (0.001) loss 3.3848 (2.5683) lr 9.5677e-03 eta 8:25:20
epoch [5/30] batch [1640/2000] time 0.601 (0.602) data 0.000 (0.001) loss 6.0156 (2.5711) lr 9.5677e-03 eta 8:25:06
epoch [5/30] batch [1660/2000] time 0.625 (0.602) data 0.000 (0.001) loss 2.1602 (2.5751) lr 9.5677e-03 eta 8:24:53
epoch [5/30] batch [1680/2000] time 0.597 (0.602) data 0.000 (0.001) loss 0.7593 (2.5747) lr 9.5677e-03 eta 8:24:39
epoch [5/30] batch [1700/2000] time 0.605 (0.602) data 0.000 (0.001) loss 1.5537 (2.5783) lr 9.5677e-03 eta 8:24:28
epoch [5/30] batch [1720/2000] time 0.606 (0.602) data 0.000 (0.001) loss 3.6836 (2.5844) lr 9.5677e-03 eta 8:24:15
epoch [5/30] batch [1740/2000] time 0.593 (0.602) data 0.000 (0.001) loss 3.8242 (2.5892) lr 9.5677e-03 eta 8:24:02
epoch [5/30] batch [1760/2000] time 0.597 (0.602) data 0.000 (0.001) loss 8.9375 (2.5865) lr 9.5677e-03 eta 8:23:49
epoch [5/30] batch [1780/2000] time 0.611 (0.602) data 0.000 (0.001) loss 6.2969 (2.5792) lr 9.5677e-03 eta 8:23:36
epoch [5/30] batch [1800/2000] time 0.604 (0.602) data 0.000 (0.001) loss 0.7241 (2.5761) lr 9.5677e-03 eta 8:23:25
epoch [5/30] batch [1820/2000] time 0.595 (0.602) data 0.000 (0.001) loss 1.9443 (2.5727) lr 9.5677e-03 eta 8:23:13
epoch [5/30] batch [1840/2000] time 0.592 (0.602) data 0.000 (0.001) loss 3.2246 (2.5774) lr 9.5677e-03 eta 8:22:59
epoch [5/30] batch [1860/2000] time 0.597 (0.602) data 0.000 (0.001) loss 0.4780 (2.5766) lr 9.5677e-03 eta 8:22:46
epoch [5/30] batch [1880/2000] time 0.604 (0.602) data 0.000 (0.001) loss 5.1758 (2.5784) lr 9.5677e-03 eta 8:22:32
epoch [5/30] batch [1900/2000] time 0.601 (0.602) data 0.000 (0.001) loss 0.9048 (2.5775) lr 9.5677e-03 eta 8:22:19
epoch [5/30] batch [1920/2000] time 0.604 (0.602) data 0.000 (0.001) loss 3.8184 (2.5809) lr 9.5677e-03 eta 8:22:07
epoch [5/30] batch [1940/2000] time 0.600 (0.602) data 0.000 (0.001) loss 2.6113 (2.5792) lr 9.5677e-03 eta 8:21:55
epoch [5/30] batch [1960/2000] time 0.594 (0.602) data 0.000 (0.001) loss 0.3152 (2.5780) lr 9.5677e-03 eta 8:21:43
epoch [5/30] batch [1980/2000] time 0.589 (0.602) data 0.000 (0.001) loss 2.1797 (2.5716) lr 9.5677e-03 eta 8:21:27
epoch [5/30] batch [2000/2000] time 0.593 (0.601) data 0.000 (0.001) loss 0.9077 (2.5683) lr 9.3301e-03 eta 8:21:09
Evaluate on the *val* set
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:02<11:12,  2.70s/it]  1%|          | 2/250 [00:03<06:03,  1.47s/it]  1%|          | 3/250 [00:03<04:30,  1.09s/it]  2%|▏         | 4/250 [00:04<03:20,  1.22it/s]  2%|▏         | 5/250 [00:04<02:43,  1.50it/s]  2%|▏         | 6/250 [00:05<02:20,  1.74it/s]  3%|▎         | 7/250 [00:05<02:04,  1.96it/s]  3%|▎         | 8/250 [00:05<01:53,  2.14it/s]  4%|▎         | 9/250 [00:06<01:44,  2.30it/s]  4%|▍         | 10/250 [00:06<01:40,  2.39it/s]  4%|▍         | 11/250 [00:07<01:35,  2.49it/s]  5%|▍         | 12/250 [00:07<01:33,  2.56it/s]  5%|▌         | 13/250 [00:07<01:30,  2.61it/s]  6%|▌         | 14/250 [00:08<01:28,  2.67it/s]  6%|▌         | 15/250 [00:08<01:28,  2.64it/s]  6%|▋         | 16/250 [00:08<01:28,  2.64it/s]  7%|▋         | 17/250 [00:09<01:27,  2.66it/s]  7%|▋         | 18/250 [00:09<01:24,  2.74it/s]  8%|▊         | 19/250 [00:09<01:24,  2.73it/s]  8%|▊         | 20/250 [00:10<01:24,  2.72it/s]  8%|▊         | 21/250 [00:10<01:24,  2.71it/s]  9%|▉         | 22/250 [00:11<01:23,  2.72it/s]  9%|▉         | 23/250 [00:11<01:24,  2.67it/s] 10%|▉         | 24/250 [00:11<01:25,  2.64it/s] 10%|█         | 25/250 [00:12<01:25,  2.63it/s] 10%|█         | 26/250 [00:12<01:23,  2.67it/s] 11%|█         | 27/250 [00:12<01:22,  2.70it/s] 11%|█         | 28/250 [00:13<01:22,  2.68it/s] 12%|█▏        | 29/250 [00:13<01:22,  2.67it/s] 12%|█▏        | 30/250 [00:14<01:21,  2.69it/s] 12%|█▏        | 31/250 [00:14<01:20,  2.71it/s] 13%|█▎        | 32/250 [00:14<01:20,  2.71it/s] 13%|█▎        | 33/250 [00:15<01:20,  2.70it/s] 14%|█▎        | 34/250 [00:15<01:20,  2.69it/s] 14%|█▍        | 35/250 [00:15<01:20,  2.67it/s] 14%|█▍        | 36/250 [00:16<01:18,  2.72it/s] 15%|█▍        | 37/250 [00:16<01:18,  2.72it/s] 15%|█▌        | 38/250 [00:17<01:17,  2.72it/s] 16%|█▌        | 39/250 [00:17<01:17,  2.72it/s] 16%|█▌        | 40/250 [00:17<01:19,  2.64it/s] 16%|█▋        | 41/250 [00:18<01:19,  2.63it/s] 17%|█▋        | 42/250 [00:18<01:18,  2.64it/s] 17%|█▋        | 43/250 [00:18<01:19,  2.62it/s] 18%|█▊        | 44/250 [00:19<01:18,  2.64it/s] 18%|█▊        | 45/250 [00:19<01:17,  2.66it/s] 18%|█▊        | 46/250 [00:20<01:15,  2.69it/s] 19%|█▉        | 47/250 [00:20<01:14,  2.73it/s] 19%|█▉        | 48/250 [00:20<01:13,  2.74it/s] 20%|█▉        | 49/250 [00:21<01:14,  2.71it/s] 20%|██        | 50/250 [00:21<01:13,  2.74it/s] 20%|██        | 51/250 [00:21<01:14,  2.66it/s] 21%|██        | 52/250 [00:22<01:13,  2.70it/s] 21%|██        | 53/250 [00:22<01:13,  2.67it/s] 22%|██▏       | 54/250 [00:22<01:12,  2.71it/s] 22%|██▏       | 55/250 [00:23<01:12,  2.68it/s] 22%|██▏       | 56/250 [00:23<01:12,  2.68it/s] 23%|██▎       | 57/250 [00:24<01:13,  2.62it/s] 23%|██▎       | 58/250 [00:24<01:12,  2.66it/s] 24%|██▎       | 59/250 [00:24<01:11,  2.66it/s] 24%|██▍       | 60/250 [00:25<01:11,  2.67it/s] 24%|██▍       | 61/250 [00:25<01:10,  2.68it/s] 25%|██▍       | 62/250 [00:26<01:11,  2.64it/s] 25%|██▌       | 63/250 [00:26<01:10,  2.67it/s] 26%|██▌       | 64/250 [00:26<01:08,  2.71it/s] 26%|██▌       | 65/250 [00:27<01:08,  2.71it/s] 26%|██▋       | 66/250 [00:27<01:07,  2.72it/s] 27%|██▋       | 67/250 [00:27<01:07,  2.70it/s] 27%|██▋       | 68/250 [00:28<01:08,  2.66it/s] 28%|██▊       | 69/250 [00:28<01:07,  2.69it/s] 28%|██▊       | 70/250 [00:28<01:06,  2.73it/s] 28%|██▊       | 71/250 [00:29<01:05,  2.74it/s] 29%|██▉       | 72/250 [00:29<01:05,  2.72it/s] 29%|██▉       | 73/250 [00:30<01:05,  2.70it/s] 30%|██▉       | 74/250 [00:30<01:05,  2.69it/s] 30%|███       | 75/250 [00:30<01:04,  2.70it/s] 30%|███       | 76/250 [00:31<01:04,  2.70it/s] 31%|███       | 77/250 [00:31<01:03,  2.71it/s] 31%|███       | 78/250 [00:31<01:04,  2.67it/s] 32%|███▏      | 79/250 [00:32<01:04,  2.65it/s] 32%|███▏      | 80/250 [00:32<01:03,  2.66it/s] 32%|███▏      | 81/250 [00:33<01:03,  2.68it/s] 33%|███▎      | 82/250 [00:33<01:02,  2.71it/s] 33%|███▎      | 83/250 [00:33<01:01,  2.72it/s] 34%|███▎      | 84/250 [00:34<01:00,  2.73it/s] 34%|███▍      | 85/250 [00:34<01:00,  2.74it/s] 34%|███▍      | 86/250 [00:34<00:59,  2.74it/s] 35%|███▍      | 87/250 [00:35<00:59,  2.74it/s] 35%|███▌      | 88/250 [00:35<00:58,  2.76it/s] 36%|███▌      | 89/250 [00:35<00:57,  2.78it/s] 36%|███▌      | 90/250 [00:36<00:57,  2.79it/s] 36%|███▋      | 91/250 [00:36<00:56,  2.80it/s] 37%|███▋      | 92/250 [00:37<00:57,  2.76it/s] 37%|███▋      | 93/250 [00:37<00:57,  2.75it/s] 38%|███▊      | 94/250 [00:37<00:56,  2.76it/s] 38%|███▊      | 95/250 [00:38<00:55,  2.79it/s] 38%|███▊      | 96/250 [00:38<00:55,  2.80it/s] 39%|███▉      | 97/250 [00:38<00:54,  2.81it/s] 39%|███▉      | 98/250 [00:39<00:54,  2.77it/s] 40%|███▉      | 99/250 [00:39<00:54,  2.80it/s] 40%|████      | 100/250 [00:39<00:53,  2.78it/s] 40%|████      | 101/250 [00:40<00:53,  2.77it/s] 41%|████      | 102/250 [00:40<00:53,  2.79it/s] 41%|████      | 103/250 [00:40<00:53,  2.76it/s] 42%|████▏     | 104/250 [00:41<00:53,  2.75it/s] 42%|████▏     | 105/250 [00:41<00:53,  2.72it/s] 42%|████▏     | 106/250 [00:42<00:53,  2.67it/s] 43%|████▎     | 107/250 [00:42<00:54,  2.62it/s] 43%|████▎     | 108/250 [00:42<00:53,  2.64it/s] 44%|████▎     | 109/250 [00:43<00:53,  2.65it/s] 44%|████▍     | 110/250 [00:43<00:53,  2.62it/s] 44%|████▍     | 111/250 [00:43<00:51,  2.69it/s] 45%|████▍     | 112/250 [00:44<00:50,  2.74it/s] 45%|████▌     | 113/250 [00:44<00:51,  2.68it/s] 46%|████▌     | 114/250 [00:45<00:49,  2.73it/s] 46%|████▌     | 115/250 [00:45<00:48,  2.76it/s] 46%|████▋     | 116/250 [00:45<00:48,  2.75it/s] 47%|████▋     | 117/250 [00:46<00:49,  2.70it/s] 47%|████▋     | 118/250 [00:46<00:50,  2.64it/s] 48%|████▊     | 119/250 [00:46<00:50,  2.61it/s] 48%|████▊     | 120/250 [00:47<00:50,  2.58it/s] 48%|████▊     | 121/250 [00:47<00:49,  2.59it/s] 49%|████▉     | 122/250 [00:48<00:49,  2.59it/s] 49%|████▉     | 123/250 [00:48<00:48,  2.62it/s] 50%|████▉     | 124/250 [00:48<00:48,  2.61it/s] 50%|█████     | 125/250 [00:49<00:47,  2.64it/s] 50%|█████     | 126/250 [00:49<00:47,  2.63it/s] 51%|█████     | 127/250 [00:50<00:46,  2.62it/s] 51%|█████     | 128/250 [00:50<00:45,  2.67it/s] 52%|█████▏    | 129/250 [00:50<00:45,  2.66it/s] 52%|█████▏    | 130/250 [00:51<00:44,  2.67it/s] 52%|█████▏    | 131/250 [00:51<00:45,  2.64it/s] 53%|█████▎    | 132/250 [00:51<00:44,  2.68it/s] 53%|█████▎    | 133/250 [00:52<00:43,  2.70it/s] 54%|█████▎    | 134/250 [00:52<00:43,  2.68it/s] 54%|█████▍    | 135/250 [00:53<00:42,  2.68it/s] 54%|█████▍    | 136/250 [00:53<00:42,  2.66it/s] 55%|█████▍    | 137/250 [00:53<00:42,  2.67it/s] 55%|█████▌    | 138/250 [00:54<00:42,  2.66it/s] 56%|█████▌    | 139/250 [00:54<00:41,  2.66it/s] 56%|█████▌    | 140/250 [00:54<00:41,  2.67it/s] 56%|█████▋    | 141/250 [00:55<00:40,  2.69it/s] 57%|█████▋    | 142/250 [00:55<00:40,  2.69it/s] 57%|█████▋    | 143/250 [00:56<00:40,  2.66it/s] 58%|█████▊    | 144/250 [00:56<00:39,  2.65it/s] 58%|█████▊    | 145/250 [00:56<00:39,  2.67it/s] 58%|█████▊    | 146/250 [00:57<00:38,  2.67it/s] 59%|█████▉    | 147/250 [00:57<00:38,  2.67it/s] 59%|█████▉    | 148/250 [00:57<00:38,  2.65it/s] 60%|█████▉    | 149/250 [00:58<00:37,  2.68it/s] 60%|██████    | 150/250 [00:58<00:37,  2.69it/s] 60%|██████    | 151/250 [00:58<00:36,  2.71it/s] 61%|██████    | 152/250 [00:59<00:36,  2.71it/s] 61%|██████    | 153/250 [00:59<00:35,  2.74it/s] 62%|██████▏   | 154/250 [01:00<00:35,  2.71it/s] 62%|██████▏   | 155/250 [01:00<00:35,  2.71it/s] 62%|██████▏   | 156/250 [01:00<00:34,  2.71it/s] 63%|██████▎   | 157/250 [01:01<00:33,  2.76it/s] 63%|██████▎   | 158/250 [01:01<00:33,  2.78it/s] 64%|██████▎   | 159/250 [01:01<00:33,  2.74it/s] 64%|██████▍   | 160/250 [01:02<00:33,  2.66it/s] 64%|██████▍   | 161/250 [01:02<00:34,  2.62it/s] 65%|██████▍   | 162/250 [01:03<00:33,  2.60it/s] 65%|██████▌   | 163/250 [01:03<00:33,  2.62it/s] 66%|██████▌   | 164/250 [01:03<00:32,  2.64it/s] 66%|██████▌   | 165/250 [01:04<00:32,  2.60it/s] 66%|██████▋   | 166/250 [01:04<00:32,  2.62it/s] 67%|██████▋   | 167/250 [01:04<00:31,  2.65it/s] 67%|██████▋   | 168/250 [01:05<00:30,  2.68it/s] 68%|██████▊   | 169/250 [01:05<00:30,  2.69it/s] 68%|██████▊   | 170/250 [01:06<00:29,  2.73it/s] 68%|██████▊   | 171/250 [01:06<00:29,  2.70it/s] 69%|██████▉   | 172/250 [01:06<00:29,  2.69it/s] 69%|██████▉   | 173/250 [01:07<00:28,  2.68it/s] 70%|██████▉   | 174/250 [01:07<00:27,  2.75it/s] 70%|███████   | 175/250 [01:07<00:27,  2.76it/s] 70%|███████   | 176/250 [01:08<00:27,  2.67it/s] 71%|███████   | 177/250 [01:08<00:27,  2.69it/s] 71%|███████   | 178/250 [01:09<00:26,  2.71it/s] 72%|███████▏  | 179/250 [01:09<00:26,  2.70it/s] 72%|███████▏  | 180/250 [01:09<00:25,  2.70it/s] 72%|███████▏  | 181/250 [01:10<00:25,  2.72it/s] 73%|███████▎  | 182/250 [01:10<00:24,  2.72it/s] 73%|███████▎  | 183/250 [01:10<00:24,  2.73it/s] 74%|███████▎  | 184/250 [01:11<00:24,  2.72it/s] 74%|███████▍  | 185/250 [01:11<00:23,  2.72it/s] 74%|███████▍  | 186/250 [01:11<00:23,  2.74it/s] 75%|███████▍  | 187/250 [01:12<00:22,  2.77it/s] 75%|███████▌  | 188/250 [01:12<00:22,  2.74it/s] 76%|███████▌  | 189/250 [01:13<00:22,  2.75it/s] 76%|███████▌  | 190/250 [01:13<00:21,  2.78it/s] 76%|███████▋  | 191/250 [01:13<00:21,  2.77it/s] 77%|███████▋  | 192/250 [01:14<00:21,  2.76it/s] 77%|███████▋  | 193/250 [01:14<00:20,  2.77it/s] 78%|███████▊  | 194/250 [01:14<00:20,  2.74it/s] 78%|███████▊  | 195/250 [01:15<00:19,  2.76it/s] 78%|███████▊  | 196/250 [01:15<00:19,  2.76it/s] 79%|███████▉  | 197/250 [01:15<00:19,  2.73it/s] 79%|███████▉  | 198/250 [01:16<00:18,  2.75it/s] 80%|███████▉  | 199/250 [01:16<00:18,  2.75it/s] 80%|████████  | 200/250 [01:17<00:18,  2.71it/s] 80%|████████  | 201/250 [01:17<00:18,  2.67it/s] 81%|████████  | 202/250 [01:17<00:17,  2.69it/s] 81%|████████  | 203/250 [01:18<00:17,  2.67it/s] 82%|████████▏ | 204/250 [01:18<00:17,  2.65it/s] 82%|████████▏ | 205/250 [01:18<00:17,  2.63it/s] 82%|████████▏ | 206/250 [01:19<00:16,  2.63it/s] 83%|████████▎ | 207/250 [01:19<00:16,  2.63it/s] 83%|████████▎ | 208/250 [01:20<00:15,  2.66it/s] 84%|████████▎ | 209/250 [01:20<00:15,  2.66it/s] 84%|████████▍ | 210/250 [01:20<00:14,  2.70it/s] 84%|████████▍ | 211/250 [01:21<00:14,  2.67it/s] 85%|████████▍ | 212/250 [01:21<00:14,  2.67it/s] 85%|████████▌ | 213/250 [01:21<00:13,  2.68it/s] 86%|████████▌ | 214/250 [01:22<00:13,  2.68it/s] 86%|████████▌ | 215/250 [01:22<00:12,  2.71it/s] 86%|████████▋ | 216/250 [01:23<00:12,  2.69it/s] 87%|████████▋ | 217/250 [01:23<00:12,  2.71it/s] 87%|████████▋ | 218/250 [01:23<00:11,  2.70it/s] 88%|████████▊ | 219/250 [01:24<00:11,  2.71it/s] 88%|████████▊ | 220/250 [01:24<00:10,  2.75it/s] 88%|████████▊ | 221/250 [01:24<00:10,  2.83it/s] 89%|████████▉ | 222/250 [01:25<00:09,  2.96it/s] 89%|████████▉ | 223/250 [01:25<00:08,  3.06it/s] 90%|████████▉ | 224/250 [01:25<00:08,  3.13it/s] 90%|█████████ | 225/250 [01:26<00:07,  3.18it/s] 90%|█████████ | 226/250 [01:26<00:07,  3.22it/s] 91%|█████████ | 227/250 [01:26<00:07,  3.24it/s] 91%|█████████ | 228/250 [01:26<00:06,  3.26it/s] 92%|█████████▏| 229/250 [01:27<00:06,  3.28it/s] 92%|█████████▏| 230/250 [01:27<00:06,  3.29it/s] 92%|█████████▏| 231/250 [01:27<00:05,  3.29it/s] 93%|█████████▎| 232/250 [01:28<00:05,  3.29it/s] 93%|█████████▎| 233/250 [01:28<00:05,  3.29it/s] 94%|█████████▎| 234/250 [01:28<00:04,  3.30it/s] 94%|█████████▍| 235/250 [01:29<00:04,  3.30it/s] 94%|█████████▍| 236/250 [01:29<00:04,  3.30it/s] 95%|█████████▍| 237/250 [01:29<00:03,  3.31it/s] 95%|█████████▌| 238/250 [01:29<00:03,  3.31it/s] 96%|█████████▌| 239/250 [01:30<00:03,  3.31it/s] 96%|█████████▌| 240/250 [01:30<00:03,  3.31it/s] 96%|█████████▋| 241/250 [01:30<00:02,  3.31it/s] 97%|█████████▋| 242/250 [01:31<00:02,  3.31it/s] 97%|█████████▋| 243/250 [01:31<00:02,  3.31it/s] 98%|█████████▊| 244/250 [01:31<00:01,  3.31it/s] 98%|█████████▊| 245/250 [01:32<00:01,  3.30it/s] 98%|█████████▊| 246/250 [01:32<00:01,  3.26it/s] 99%|█████████▉| 247/250 [01:32<00:00,  3.27it/s] 99%|█████████▉| 248/250 [01:33<00:00,  3.28it/s]100%|█████████▉| 249/250 [01:33<00:00,  3.21it/s]100%|██████████| 250/250 [01:33<00:00,  3.22it/s]100%|██████████| 250/250 [01:33<00:00,  2.67it/s]=> result
* total: 25,000
* correct: 19,112
* accuracy: 76.4%
* error: 23.6%
* macro_f1: 76.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/imagenet/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

epoch [6/30] batch [20/2000] time 0.601 (0.645) data 0.000 (0.037) loss 3.2207 (2.6820) lr 9.3301e-03 eta 8:57:07
epoch [6/30] batch [40/2000] time 0.612 (0.623) data 0.000 (0.019) loss 0.7451 (2.4547) lr 9.3301e-03 eta 8:39:07
epoch [6/30] batch [60/2000] time 0.602 (0.617) data 0.000 (0.013) loss 2.1582 (2.6262) lr 9.3301e-03 eta 8:33:10
epoch [6/30] batch [80/2000] time 0.602 (0.613) data 0.000 (0.010) loss 4.3125 (2.4595) lr 9.3301e-03 eta 8:29:48
epoch [6/30] batch [100/2000] time 0.607 (0.611) data 0.000 (0.008) loss 1.9287 (2.4940) lr 9.3301e-03 eta 8:27:52
epoch [6/30] batch [120/2000] time 0.594 (0.610) data 0.000 (0.006) loss 1.9521 (2.4494) lr 9.3301e-03 eta 8:26:45
epoch [6/30] batch [140/2000] time 0.596 (0.609) data 0.000 (0.006) loss 4.0508 (2.4444) lr 9.3301e-03 eta 8:25:55
epoch [6/30] batch [160/2000] time 0.609 (0.608) data 0.000 (0.005) loss 4.7344 (2.4798) lr 9.3301e-03 eta 8:25:07
epoch [6/30] batch [180/2000] time 0.606 (0.607) data 0.000 (0.004) loss 3.0859 (2.5626) lr 9.3301e-03 eta 8:24:17
epoch [6/30] batch [200/2000] time 0.612 (0.606) data 0.000 (0.004) loss 0.8745 (2.5575) lr 9.3301e-03 eta 8:23:17
epoch [6/30] batch [220/2000] time 0.677 (0.606) data 0.000 (0.004) loss 1.4375 (2.5868) lr 9.3301e-03 eta 8:23:08
epoch [6/30] batch [240/2000] time 0.617 (0.606) data 0.000 (0.003) loss 5.8203 (2.6185) lr 9.3301e-03 eta 8:22:53
epoch [6/30] batch [260/2000] time 0.599 (0.606) data 0.000 (0.003) loss 4.9648 (2.5390) lr 9.3301e-03 eta 8:22:20
epoch [6/30] batch [280/2000] time 0.600 (0.606) data 0.000 (0.003) loss 1.4746 (2.5433) lr 9.3301e-03 eta 8:21:52
epoch [6/30] batch [300/2000] time 0.598 (0.605) data 0.000 (0.003) loss 0.1658 (2.5654) lr 9.3301e-03 eta 8:21:30
epoch [6/30] batch [320/2000] time 0.593 (0.605) data 0.000 (0.003) loss 0.5962 (2.5777) lr 9.3301e-03 eta 8:21:20
epoch [6/30] batch [340/2000] time 0.597 (0.605) data 0.000 (0.002) loss 1.6709 (2.5768) lr 9.3301e-03 eta 8:20:48
epoch [6/30] batch [360/2000] time 0.601 (0.605) data 0.000 (0.002) loss 3.0352 (2.6209) lr 9.3301e-03 eta 8:20:28
epoch [6/30] batch [380/2000] time 0.595 (0.605) data 0.000 (0.002) loss 2.9434 (2.6231) lr 9.3301e-03 eta 8:20:00
epoch [6/30] batch [400/2000] time 0.604 (0.605) data 0.000 (0.002) loss 3.6191 (2.6127) lr 9.3301e-03 eta 8:19:49
epoch [6/30] batch [420/2000] time 0.615 (0.604) data 0.000 (0.002) loss 4.1797 (2.5937) lr 9.3301e-03 eta 8:19:27
epoch [6/30] batch [440/2000] time 0.605 (0.604) data 0.000 (0.002) loss 1.0752 (2.5812) lr 9.3301e-03 eta 8:19:11
epoch [6/30] batch [460/2000] time 0.598 (0.604) data 0.000 (0.002) loss 0.8633 (2.5591) lr 9.3301e-03 eta 8:18:49
epoch [6/30] batch [480/2000] time 0.598 (0.604) data 0.000 (0.002) loss 0.9644 (2.5355) lr 9.3301e-03 eta 8:18:25
epoch [6/30] batch [500/2000] time 0.600 (0.604) data 0.000 (0.002) loss 5.5898 (2.5318) lr 9.3301e-03 eta 8:18:19
epoch [6/30] batch [520/2000] time 0.594 (0.604) data 0.000 (0.002) loss 0.7100 (2.5218) lr 9.3301e-03 eta 8:17:58
epoch [6/30] batch [540/2000] time 0.599 (0.604) data 0.000 (0.002) loss 5.0664 (2.5225) lr 9.3301e-03 eta 8:17:38
epoch [6/30] batch [560/2000] time 0.594 (0.604) data 0.000 (0.002) loss 0.6157 (2.5346) lr 9.3301e-03 eta 8:17:19
epoch [6/30] batch [580/2000] time 0.600 (0.603) data 0.000 (0.002) loss 2.2168 (2.5199) lr 9.3301e-03 eta 8:17:04
epoch [6/30] batch [600/2000] time 0.620 (0.603) data 0.000 (0.002) loss 2.4219 (2.5370) lr 9.3301e-03 eta 8:16:48
epoch [6/30] batch [620/2000] time 0.595 (0.603) data 0.000 (0.001) loss 2.8379 (2.5432) lr 9.3301e-03 eta 8:16:33
epoch [6/30] batch [640/2000] time 0.608 (0.603) data 0.000 (0.001) loss 0.5713 (2.5216) lr 9.3301e-03 eta 8:16:11
epoch [6/30] batch [660/2000] time 0.614 (0.603) data 0.000 (0.001) loss 2.7227 (2.5349) lr 9.3301e-03 eta 8:15:56
epoch [6/30] batch [680/2000] time 0.595 (0.603) data 0.000 (0.001) loss 0.6973 (2.5276) lr 9.3301e-03 eta 8:15:39
epoch [6/30] batch [700/2000] time 0.596 (0.603) data 0.000 (0.001) loss 2.0352 (2.5362) lr 9.3301e-03 eta 8:15:30
epoch [6/30] batch [720/2000] time 0.600 (0.603) data 0.000 (0.001) loss 4.0977 (2.5464) lr 9.3301e-03 eta 8:15:11
epoch [6/30] batch [740/2000] time 0.602 (0.603) data 0.000 (0.001) loss 3.3594 (2.5398) lr 9.3301e-03 eta 8:14:57
epoch [6/30] batch [760/2000] time 0.607 (0.603) data 0.000 (0.001) loss 2.4648 (2.5576) lr 9.3301e-03 eta 8:14:46
epoch [6/30] batch [780/2000] time 0.632 (0.603) data 0.000 (0.001) loss 2.0312 (2.5560) lr 9.3301e-03 eta 8:14:32
epoch [6/30] batch [800/2000] time 0.597 (0.603) data 0.000 (0.001) loss 3.3398 (2.5571) lr 9.3301e-03 eta 8:14:19
epoch [6/30] batch [820/2000] time 0.598 (0.603) data 0.000 (0.001) loss 2.6562 (2.5506) lr 9.3301e-03 eta 8:14:02
epoch [6/30] batch [840/2000] time 0.598 (0.603) data 0.000 (0.001) loss 3.2891 (2.5490) lr 9.3301e-03 eta 8:13:50
epoch [6/30] batch [860/2000] time 0.594 (0.603) data 0.000 (0.001) loss 1.6396 (2.5487) lr 9.3301e-03 eta 8:13:34
epoch [6/30] batch [880/2000] time 0.597 (0.603) data 0.000 (0.001) loss 11.2656 (2.5497) lr 9.3301e-03 eta 8:13:19
epoch [6/30] batch [900/2000] time 0.604 (0.603) data 0.000 (0.001) loss 1.8477 (2.5488) lr 9.3301e-03 eta 8:13:07
epoch [6/30] batch [920/2000] time 0.594 (0.603) data 0.000 (0.001) loss 4.2109 (2.5385) lr 9.3301e-03 eta 8:12:52
epoch [6/30] batch [940/2000] time 0.599 (0.603) data 0.000 (0.001) loss 1.3926 (2.5483) lr 9.3301e-03 eta 8:12:41
epoch [6/30] batch [960/2000] time 0.604 (0.603) data 0.000 (0.001) loss 5.3242 (2.5499) lr 9.3301e-03 eta 8:12:31
epoch [6/30] batch [980/2000] time 0.611 (0.603) data 0.000 (0.001) loss 5.0664 (2.5555) lr 9.3301e-03 eta 8:12:16
epoch [6/30] batch [1000/2000] time 0.600 (0.603) data 0.000 (0.001) loss 2.9180 (2.5650) lr 9.3301e-03 eta 8:12:05
epoch [6/30] batch [1020/2000] time 0.596 (0.603) data 0.000 (0.001) loss 4.3906 (2.5631) lr 9.3301e-03 eta 8:11:52
epoch [6/30] batch [1040/2000] time 0.596 (0.602) data 0.000 (0.001) loss 2.6973 (2.5618) lr 9.3301e-03 eta 8:11:37
epoch [6/30] batch [1060/2000] time 0.595 (0.602) data 0.000 (0.001) loss 3.3965 (2.5606) lr 9.3301e-03 eta 8:11:24
epoch [6/30] batch [1080/2000] time 0.599 (0.603) data 0.000 (0.001) loss 2.6953 (2.5481) lr 9.3301e-03 eta 8:11:14
epoch [6/30] batch [1100/2000] time 0.606 (0.602) data 0.000 (0.001) loss 3.6211 (2.5318) lr 9.3301e-03 eta 8:11:00
epoch [6/30] batch [1120/2000] time 0.598 (0.602) data 0.000 (0.001) loss 2.1055 (2.5199) lr 9.3301e-03 eta 8:10:47
epoch [6/30] batch [1140/2000] time 0.593 (0.602) data 0.000 (0.001) loss 0.7817 (2.5201) lr 9.3301e-03 eta 8:10:34
epoch [6/30] batch [1160/2000] time 0.615 (0.602) data 0.000 (0.001) loss 5.8125 (2.5210) lr 9.3301e-03 eta 8:10:23
epoch [6/30] batch [1180/2000] time 0.601 (0.602) data 0.000 (0.001) loss 3.5879 (2.5322) lr 9.3301e-03 eta 8:10:08
epoch [6/30] batch [1200/2000] time 0.598 (0.602) data 0.000 (0.001) loss 1.5332 (2.5288) lr 9.3301e-03 eta 8:09:56
epoch [6/30] batch [1220/2000] time 0.590 (0.602) data 0.000 (0.001) loss 3.8906 (2.5306) lr 9.3301e-03 eta 8:09:42
epoch [6/30] batch [1240/2000] time 0.603 (0.602) data 0.000 (0.001) loss 7.0977 (2.5430) lr 9.3301e-03 eta 8:09:31
epoch [6/30] batch [1260/2000] time 0.600 (0.602) data 0.000 (0.001) loss 2.2441 (2.5471) lr 9.3301e-03 eta 8:09:20
epoch [6/30] batch [1280/2000] time 0.633 (0.602) data 0.000 (0.001) loss 4.5703 (2.5457) lr 9.3301e-03 eta 8:09:08
epoch [6/30] batch [1300/2000] time 0.596 (0.602) data 0.000 (0.001) loss 7.0469 (2.5473) lr 9.3301e-03 eta 8:08:55
epoch [6/30] batch [1320/2000] time 0.596 (0.602) data 0.000 (0.001) loss 1.0391 (2.5581) lr 9.3301e-03 eta 8:08:41
epoch [6/30] batch [1340/2000] time 0.595 (0.602) data 0.000 (0.001) loss 3.5293 (2.5565) lr 9.3301e-03 eta 8:08:28
epoch [6/30] batch [1360/2000] time 0.595 (0.602) data 0.000 (0.001) loss 0.5601 (2.5474) lr 9.3301e-03 eta 8:08:14
epoch [6/30] batch [1380/2000] time 0.604 (0.602) data 0.000 (0.001) loss 0.6880 (2.5491) lr 9.3301e-03 eta 8:08:02
epoch [6/30] batch [1400/2000] time 0.599 (0.602) data 0.000 (0.001) loss 2.8242 (2.5409) lr 9.3301e-03 eta 8:07:48
epoch [6/30] batch [1420/2000] time 0.600 (0.602) data 0.000 (0.001) loss 2.7383 (2.5426) lr 9.3301e-03 eta 8:07:34
epoch [6/30] batch [1440/2000] time 0.656 (0.602) data 0.000 (0.001) loss 6.3047 (2.5484) lr 9.3301e-03 eta 8:07:25
epoch [6/30] batch [1460/2000] time 0.592 (0.602) data 0.000 (0.001) loss 0.5811 (2.5479) lr 9.3301e-03 eta 8:07:10
epoch [6/30] batch [1480/2000] time 0.595 (0.602) data 0.000 (0.001) loss 1.1230 (2.5458) lr 9.3301e-03 eta 8:06:58
epoch [6/30] batch [1500/2000] time 0.610 (0.602) data 0.000 (0.001) loss 5.1211 (2.5508) lr 9.3301e-03 eta 8:06:44
epoch [6/30] batch [1520/2000] time 0.593 (0.602) data 0.000 (0.001) loss 3.2363 (2.5466) lr 9.3301e-03 eta 8:06:32
epoch [6/30] batch [1540/2000] time 0.596 (0.602) data 0.000 (0.001) loss 2.4434 (2.5509) lr 9.3301e-03 eta 8:06:18
epoch [6/30] batch [1560/2000] time 0.592 (0.602) data 0.000 (0.001) loss 2.4160 (2.5469) lr 9.3301e-03 eta 8:06:08
epoch [6/30] batch [1580/2000] time 0.606 (0.602) data 0.000 (0.001) loss 0.4944 (2.5413) lr 9.3301e-03 eta 8:05:56
epoch [6/30] batch [1600/2000] time 0.600 (0.602) data 0.000 (0.001) loss 0.8970 (2.5425) lr 9.3301e-03 eta 8:05:42
epoch [6/30] batch [1620/2000] time 0.597 (0.602) data 0.000 (0.001) loss 4.2695 (2.5445) lr 9.3301e-03 eta 8:05:28
epoch [6/30] batch [1640/2000] time 0.597 (0.602) data 0.000 (0.001) loss 0.4663 (2.5561) lr 9.3301e-03 eta 8:05:17
epoch [6/30] batch [1660/2000] time 0.593 (0.602) data 0.000 (0.001) loss 3.3711 (2.5624) lr 9.3301e-03 eta 8:05:04
epoch [6/30] batch [1680/2000] time 0.602 (0.602) data 0.000 (0.001) loss 2.1836 (2.5555) lr 9.3301e-03 eta 8:04:52
epoch [6/30] batch [1700/2000] time 0.602 (0.602) data 0.000 (0.001) loss 3.0293 (2.5541) lr 9.3301e-03 eta 8:04:43
epoch [6/30] batch [1720/2000] time 0.598 (0.602) data 0.000 (0.001) loss 2.3887 (2.5531) lr 9.3301e-03 eta 8:04:31
epoch [6/30] batch [1740/2000] time 0.599 (0.602) data 0.000 (0.001) loss 0.1877 (2.5471) lr 9.3301e-03 eta 8:04:17
epoch [6/30] batch [1760/2000] time 0.605 (0.602) data 0.000 (0.001) loss 3.8945 (2.5470) lr 9.3301e-03 eta 8:04:05
epoch [6/30] batch [1780/2000] time 0.599 (0.602) data 0.000 (0.001) loss 4.8594 (2.5488) lr 9.3301e-03 eta 8:03:52
epoch [6/30] batch [1800/2000] time 0.596 (0.602) data 0.000 (0.001) loss 0.7900 (2.5511) lr 9.3301e-03 eta 8:03:39
epoch [6/30] batch [1820/2000] time 0.618 (0.602) data 0.000 (0.001) loss 1.1494 (2.5492) lr 9.3301e-03 eta 8:03:26
epoch [6/30] batch [1840/2000] time 0.597 (0.602) data 0.000 (0.001) loss 1.8633 (2.5504) lr 9.3301e-03 eta 8:03:15
epoch [6/30] batch [1860/2000] time 0.600 (0.602) data 0.000 (0.001) loss 2.2832 (2.5498) lr 9.3301e-03 eta 8:03:01
epoch [6/30] batch [1880/2000] time 0.597 (0.602) data 0.000 (0.001) loss 0.2087 (2.5470) lr 9.3301e-03 eta 8:02:47
epoch [6/30] batch [1900/2000] time 0.604 (0.602) data 0.000 (0.001) loss 0.9175 (2.5427) lr 9.3301e-03 eta 8:02:35
epoch [6/30] batch [1920/2000] time 0.607 (0.602) data 0.000 (0.001) loss 1.4248 (2.5489) lr 9.3301e-03 eta 8:02:27
epoch [6/30] batch [1940/2000] time 0.599 (0.602) data 0.000 (0.001) loss 0.4973 (2.5485) lr 9.3301e-03 eta 8:02:14
epoch [6/30] batch [1960/2000] time 0.591 (0.602) data 0.000 (0.001) loss 1.1875 (2.5502) lr 9.3301e-03 eta 8:02:00
epoch [6/30] batch [1980/2000] time 0.589 (0.602) data 0.000 (0.001) loss 1.9375 (2.5542) lr 9.3301e-03 eta 8:01:44
epoch [6/30] batch [2000/2000] time 0.597 (0.602) data 0.000 (0.001) loss 3.1934 (2.5481) lr 9.0451e-03 eta 8:01:26
Evaluate on the *val* set
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:02<11:20,  2.73s/it]  1%|          | 2/250 [00:03<06:16,  1.52s/it]  1%|          | 3/250 [00:03<04:24,  1.07s/it]  2%|▏         | 4/250 [00:04<03:15,  1.26it/s]  2%|▏         | 5/250 [00:04<02:39,  1.54it/s]  2%|▏         | 6/250 [00:05<02:16,  1.79it/s]  3%|▎         | 7/250 [00:05<02:01,  2.01it/s]  3%|▎         | 8/250 [00:05<01:53,  2.13it/s]  4%|▎         | 9/250 [00:06<01:44,  2.30it/s]  4%|▍         | 10/250 [00:06<01:39,  2.42it/s]  4%|▍         | 11/250 [00:06<01:36,  2.49it/s]  5%|▍         | 12/250 [00:07<01:32,  2.56it/s]  5%|▌         | 13/250 [00:07<01:30,  2.61it/s]  6%|▌         | 14/250 [00:08<01:28,  2.66it/s]  6%|▌         | 15/250 [00:08<01:26,  2.71it/s]  6%|▋         | 16/250 [00:08<01:27,  2.67it/s]  7%|▋         | 17/250 [00:09<01:27,  2.66it/s]  7%|▋         | 18/250 [00:09<01:26,  2.68it/s]  8%|▊         | 19/250 [00:09<01:25,  2.71it/s]  8%|▊         | 20/250 [00:10<01:24,  2.73it/s]  8%|▊         | 21/250 [00:10<01:24,  2.71it/s]  9%|▉         | 22/250 [00:11<01:24,  2.68it/s]  9%|▉         | 23/250 [00:11<01:23,  2.71it/s] 10%|▉         | 24/250 [00:11<01:23,  2.71it/s] 10%|█         | 25/250 [00:12<01:24,  2.67it/s] 10%|█         | 26/250 [00:12<01:23,  2.67it/s] 11%|█         | 27/250 [00:12<01:21,  2.72it/s] 11%|█         | 28/250 [00:13<01:21,  2.72it/s] 12%|█▏        | 29/250 [00:13<01:22,  2.69it/s] 12%|█▏        | 30/250 [00:13<01:21,  2.70it/s] 12%|█▏        | 31/250 [00:14<01:20,  2.73it/s] 13%|█▎        | 32/250 [00:14<01:18,  2.76it/s] 13%|█▎        | 33/250 [00:15<01:19,  2.75it/s] 14%|█▎        | 34/250 [00:15<01:19,  2.73it/s] 14%|█▍        | 35/250 [00:15<01:19,  2.70it/s] 14%|█▍        | 36/250 [00:16<01:18,  2.72it/s] 15%|█▍        | 37/250 [00:16<01:18,  2.71it/s] 15%|█▌        | 38/250 [00:16<01:19,  2.65it/s] 16%|█▌        | 39/250 [00:17<01:19,  2.65it/s] 16%|█▌        | 40/250 [00:17<01:18,  2.66it/s] 16%|█▋        | 41/250 [00:18<01:18,  2.65it/s] 17%|█▋        | 42/250 [00:18<01:17,  2.69it/s] 17%|█▋        | 43/250 [00:18<01:16,  2.69it/s] 18%|█▊        | 44/250 [00:19<01:16,  2.68it/s] 18%|█▊        | 45/250 [00:19<01:16,  2.68it/s] 18%|█▊        | 46/250 [00:19<01:15,  2.69it/s] 19%|█▉        | 47/250 [00:20<01:15,  2.69it/s] 19%|█▉        | 48/250 [00:20<01:14,  2.70it/s] 20%|█▉        | 49/250 [00:21<01:13,  2.75it/s] 20%|██        | 50/250 [00:21<01:12,  2.76it/s] 20%|██        | 51/250 [00:21<01:12,  2.75it/s] 21%|██        | 52/250 [00:22<01:12,  2.73it/s] 21%|██        | 53/250 [00:22<01:11,  2.75it/s] 22%|██▏       | 54/250 [00:22<01:11,  2.73it/s] 22%|██▏       | 55/250 [00:23<01:11,  2.72it/s] 22%|██▏       | 56/250 [00:23<01:10,  2.75it/s] 23%|██▎       | 57/250 [00:23<01:10,  2.73it/s] 23%|██▎       | 58/250 [00:24<01:10,  2.74it/s] 24%|██▎       | 59/250 [00:24<01:09,  2.73it/s] 24%|██▍       | 60/250 [00:25<01:10,  2.69it/s] 24%|██▍       | 61/250 [00:25<01:09,  2.70it/s] 25%|██▍       | 62/250 [00:25<01:09,  2.72it/s] 25%|██▌       | 63/250 [00:26<01:09,  2.70it/s] 26%|██▌       | 64/250 [00:26<01:09,  2.69it/s] 26%|██▌       | 65/250 [00:26<01:08,  2.69it/s] 26%|██▋       | 66/250 [00:27<01:08,  2.68it/s] 27%|██▋       | 67/250 [00:27<01:07,  2.70it/s] 27%|██▋       | 68/250 [00:28<01:08,  2.67it/s] 28%|██▊       | 69/250 [00:28<01:06,  2.73it/s] 28%|██▊       | 70/250 [00:28<01:06,  2.72it/s] 28%|██▊       | 71/250 [00:29<01:05,  2.74it/s] 29%|██▉       | 72/250 [00:29<01:04,  2.76it/s] 29%|██▉       | 73/250 [00:29<01:03,  2.78it/s] 30%|██▉       | 74/250 [00:30<01:05,  2.70it/s] 30%|███       | 75/250 [00:30<01:03,  2.75it/s] 30%|███       | 76/250 [00:30<01:03,  2.74it/s] 31%|███       | 77/250 [00:31<01:04,  2.69it/s] 31%|███       | 78/250 [00:31<01:04,  2.66it/s] 32%|███▏      | 79/250 [00:32<01:03,  2.68it/s] 32%|███▏      | 80/250 [00:32<01:02,  2.70it/s] 32%|███▏      | 81/250 [00:32<01:02,  2.68it/s] 33%|███▎      | 82/250 [00:33<01:02,  2.69it/s] 33%|███▎      | 83/250 [00:33<01:00,  2.75it/s] 34%|███▎      | 84/250 [00:33<01:00,  2.75it/s] 34%|███▍      | 85/250 [00:34<01:00,  2.74it/s] 34%|███▍      | 86/250 [00:34<00:58,  2.80it/s] 35%|███▍      | 87/250 [00:34<00:59,  2.74it/s] 35%|███▌      | 88/250 [00:35<00:59,  2.71it/s] 36%|███▌      | 89/250 [00:35<00:59,  2.70it/s] 36%|███▌      | 90/250 [00:36<00:59,  2.68it/s] 36%|███▋      | 91/250 [00:36<00:59,  2.68it/s] 37%|███▋      | 92/250 [00:36<00:58,  2.69it/s] 37%|███▋      | 93/250 [00:37<00:57,  2.74it/s] 38%|███▊      | 94/250 [00:37<00:57,  2.73it/s] 38%|███▊      | 95/250 [00:37<00:56,  2.74it/s] 38%|███▊      | 96/250 [00:38<00:55,  2.76it/s] 39%|███▉      | 97/250 [00:38<00:56,  2.72it/s] 39%|███▉      | 98/250 [00:39<00:55,  2.72it/s] 40%|███▉      | 99/250 [00:39<00:56,  2.69it/s] 40%|████      | 100/250 [00:39<00:55,  2.71it/s] 40%|████      | 101/250 [00:40<00:54,  2.73it/s] 41%|████      | 102/250 [00:40<00:53,  2.76it/s] 41%|████      | 103/250 [00:40<00:53,  2.74it/s] 42%|████▏     | 104/250 [00:41<00:52,  2.76it/s] 42%|████▏     | 105/250 [00:41<00:52,  2.74it/s] 42%|████▏     | 106/250 [00:41<00:52,  2.74it/s] 43%|████▎     | 107/250 [00:42<00:52,  2.71it/s] 43%|████▎     | 108/250 [00:42<00:52,  2.71it/s] 44%|████▎     | 109/250 [00:43<00:51,  2.72it/s] 44%|████▍     | 110/250 [00:43<00:51,  2.70it/s] 44%|████▍     | 111/250 [00:43<00:50,  2.74it/s] 45%|████▍     | 112/250 [00:44<00:50,  2.75it/s] 45%|████▌     | 113/250 [00:44<00:50,  2.70it/s] 46%|████▌     | 114/250 [00:44<00:50,  2.71it/s] 46%|████▌     | 115/250 [00:45<00:50,  2.70it/s] 46%|████▋     | 116/250 [00:45<00:49,  2.71it/s] 47%|████▋     | 117/250 [00:46<00:49,  2.70it/s] 47%|████▋     | 118/250 [00:46<00:49,  2.65it/s] 48%|████▊     | 119/250 [00:46<00:50,  2.59it/s] 48%|████▊     | 120/250 [00:47<00:49,  2.60it/s] 48%|████▊     | 121/250 [00:47<00:48,  2.64it/s] 49%|████▉     | 122/250 [00:47<00:48,  2.63it/s] 49%|████▉     | 123/250 [00:48<00:47,  2.66it/s] 50%|████▉     | 124/250 [00:48<00:46,  2.69it/s] 50%|█████     | 125/250 [00:49<00:46,  2.70it/s] 50%|█████     | 126/250 [00:49<00:46,  2.69it/s] 51%|█████     | 127/250 [00:49<00:45,  2.69it/s] 51%|█████     | 128/250 [00:50<00:45,  2.71it/s] 52%|█████▏    | 129/250 [00:50<00:45,  2.67it/s] 52%|█████▏    | 130/250 [00:50<00:44,  2.68it/s] 52%|█████▏    | 131/250 [00:51<00:44,  2.66it/s] 53%|█████▎    | 132/250 [00:51<00:44,  2.63it/s] 53%|█████▎    | 133/250 [00:52<00:43,  2.69it/s] 54%|█████▎    | 134/250 [00:52<00:43,  2.68it/s] 54%|█████▍    | 135/250 [00:52<00:43,  2.65it/s] 54%|█████▍    | 136/250 [00:53<00:42,  2.65it/s] 55%|█████▍    | 137/250 [00:53<00:42,  2.65it/s] 55%|█████▌    | 138/250 [00:53<00:43,  2.60it/s] 56%|█████▌    | 139/250 [00:54<00:42,  2.64it/s] 56%|█████▌    | 140/250 [00:54<00:42,  2.60it/s] 56%|█████▋    | 141/250 [00:55<00:40,  2.67it/s] 57%|█████▋    | 142/250 [00:55<00:39,  2.74it/s] 57%|█████▋    | 143/250 [00:55<00:38,  2.77it/s] 58%|█████▊    | 144/250 [00:56<00:39,  2.70it/s] 58%|█████▊    | 145/250 [00:56<00:39,  2.69it/s] 58%|█████▊    | 146/250 [00:56<00:38,  2.70it/s] 59%|█████▉    | 147/250 [00:57<00:37,  2.76it/s] 59%|█████▉    | 148/250 [00:57<00:36,  2.76it/s] 60%|█████▉    | 149/250 [00:57<00:37,  2.71it/s] 60%|██████    | 150/250 [00:58<00:37,  2.68it/s] 60%|██████    | 151/250 [00:58<00:37,  2.64it/s] 61%|██████    | 152/250 [00:59<00:36,  2.68it/s] 61%|██████    | 153/250 [00:59<00:36,  2.68it/s] 62%|██████▏   | 154/250 [00:59<00:35,  2.71it/s] 62%|██████▏   | 155/250 [01:00<00:35,  2.67it/s] 62%|██████▏   | 156/250 [01:00<00:34,  2.70it/s] 63%|██████▎   | 157/250 [01:00<00:33,  2.75it/s] 63%|██████▎   | 158/250 [01:01<00:32,  2.81it/s] 64%|██████▎   | 159/250 [01:01<00:33,  2.73it/s] 64%|██████▍   | 160/250 [01:02<00:33,  2.72it/s] 64%|██████▍   | 161/250 [01:02<00:33,  2.64it/s] 65%|██████▍   | 162/250 [01:02<00:33,  2.63it/s] 65%|██████▌   | 163/250 [01:03<00:32,  2.66it/s] 66%|██████▌   | 164/250 [01:03<00:32,  2.66it/s] 66%|██████▌   | 165/250 [01:03<00:32,  2.64it/s] 66%|██████▋   | 166/250 [01:04<00:31,  2.68it/s] 67%|██████▋   | 167/250 [01:04<00:30,  2.72it/s] 67%|██████▋   | 168/250 [01:05<00:30,  2.72it/s] 68%|██████▊   | 169/250 [01:05<00:29,  2.73it/s] 68%|██████▊   | 170/250 [01:05<00:29,  2.73it/s] 68%|██████▊   | 171/250 [01:06<00:28,  2.78it/s] 69%|██████▉   | 172/250 [01:06<00:27,  2.81it/s] 69%|██████▉   | 173/250 [01:06<00:27,  2.78it/s] 70%|██████▉   | 174/250 [01:07<00:27,  2.78it/s] 70%|███████   | 175/250 [01:07<00:27,  2.75it/s] 70%|███████   | 176/250 [01:07<00:27,  2.70it/s] 71%|███████   | 177/250 [01:08<00:27,  2.69it/s] 71%|███████   | 178/250 [01:08<00:26,  2.71it/s] 72%|███████▏  | 179/250 [01:09<00:26,  2.70it/s] 72%|███████▏  | 180/250 [01:09<00:25,  2.73it/s] 72%|███████▏  | 181/250 [01:09<00:25,  2.70it/s] 73%|███████▎  | 182/250 [01:10<00:25,  2.65it/s] 73%|███████▎  | 183/250 [01:10<00:25,  2.64it/s] 74%|███████▎  | 184/250 [01:10<00:24,  2.64it/s] 74%|███████▍  | 185/250 [01:11<00:24,  2.71it/s] 74%|███████▍  | 186/250 [01:11<00:23,  2.71it/s] 75%|███████▍  | 187/250 [01:12<00:23,  2.70it/s] 75%|███████▌  | 188/250 [01:12<00:23,  2.69it/s] 76%|███████▌  | 189/250 [01:12<00:22,  2.75it/s] 76%|███████▌  | 190/250 [01:13<00:21,  2.74it/s] 76%|███████▋  | 191/250 [01:13<00:21,  2.75it/s] 77%|███████▋  | 192/250 [01:13<00:21,  2.74it/s] 77%|███████▋  | 193/250 [01:14<00:21,  2.71it/s] 78%|███████▊  | 194/250 [01:14<00:20,  2.68it/s] 78%|███████▊  | 195/250 [01:14<00:20,  2.72it/s] 78%|███████▊  | 196/250 [01:15<00:19,  2.71it/s] 79%|███████▉  | 197/250 [01:15<00:19,  2.72it/s] 79%|███████▉  | 198/250 [01:16<00:19,  2.65it/s] 80%|███████▉  | 199/250 [01:16<00:19,  2.65it/s] 80%|████████  | 200/250 [01:16<00:19,  2.63it/s] 80%|████████  | 201/250 [01:17<00:18,  2.67it/s] 81%|████████  | 202/250 [01:17<00:17,  2.68it/s] 81%|████████  | 203/250 [01:17<00:17,  2.73it/s] 82%|████████▏ | 204/250 [01:18<00:17,  2.67it/s] 82%|████████▏ | 205/250 [01:18<00:16,  2.67it/s] 82%|████████▏ | 206/250 [01:19<00:16,  2.69it/s] 83%|████████▎ | 207/250 [01:19<00:15,  2.72it/s] 83%|████████▎ | 208/250 [01:19<00:15,  2.72it/s] 84%|████████▎ | 209/250 [01:20<00:15,  2.73it/s] 84%|████████▍ | 210/250 [01:20<00:14,  2.70it/s] 84%|████████▍ | 211/250 [01:20<00:14,  2.70it/s] 85%|████████▍ | 212/250 [01:21<00:14,  2.70it/s] 85%|████████▌ | 213/250 [01:21<00:13,  2.71it/s] 86%|████████▌ | 214/250 [01:22<00:13,  2.73it/s] 86%|████████▌ | 215/250 [01:22<00:13,  2.68it/s] 86%|████████▋ | 216/250 [01:22<00:12,  2.74it/s] 87%|████████▋ | 217/250 [01:23<00:11,  2.75it/s] 87%|████████▋ | 218/250 [01:23<00:11,  2.78it/s] 88%|████████▊ | 219/250 [01:23<00:11,  2.78it/s] 88%|████████▊ | 220/250 [01:24<00:10,  2.81it/s] 88%|████████▊ | 221/250 [01:24<00:09,  2.91it/s] 89%|████████▉ | 222/250 [01:24<00:09,  3.03it/s] 89%|████████▉ | 223/250 [01:25<00:08,  3.12it/s] 90%|████████▉ | 224/250 [01:25<00:08,  3.19it/s] 90%|█████████ | 225/250 [01:25<00:07,  3.24it/s] 90%|█████████ | 226/250 [01:25<00:07,  3.27it/s] 91%|█████████ | 227/250 [01:26<00:06,  3.30it/s] 91%|█████████ | 228/250 [01:26<00:06,  3.32it/s] 92%|█████████▏| 229/250 [01:26<00:06,  3.33it/s] 92%|█████████▏| 230/250 [01:27<00:05,  3.34it/s] 92%|█████████▏| 231/250 [01:27<00:05,  3.34it/s] 93%|█████████▎| 232/250 [01:27<00:05,  3.35it/s] 93%|█████████▎| 233/250 [01:28<00:05,  3.35it/s] 94%|█████████▎| 234/250 [01:28<00:04,  3.36it/s] 94%|█████████▍| 235/250 [01:28<00:04,  3.35it/s] 94%|█████████▍| 236/250 [01:28<00:04,  3.35it/s] 95%|█████████▍| 237/250 [01:29<00:03,  3.35it/s] 95%|█████████▌| 238/250 [01:29<00:03,  3.35it/s] 96%|█████████▌| 239/250 [01:29<00:03,  3.36it/s] 96%|█████████▌| 240/250 [01:30<00:02,  3.36it/s] 96%|█████████▋| 241/250 [01:30<00:02,  3.36it/s] 97%|█████████▋| 242/250 [01:30<00:02,  3.36it/s] 97%|█████████▋| 243/250 [01:31<00:02,  3.36it/s] 98%|█████████▊| 244/250 [01:31<00:01,  3.36it/s] 98%|█████████▊| 245/250 [01:31<00:01,  3.34it/s] 98%|█████████▊| 246/250 [01:31<00:01,  3.35it/s] 99%|█████████▉| 247/250 [01:32<00:00,  3.35it/s] 99%|█████████▉| 248/250 [01:32<00:00,  3.35it/s]100%|█████████▉| 249/250 [01:32<00:00,  3.36it/s]100%|██████████| 250/250 [01:33<00:00,  3.35it/s]100%|██████████| 250/250 [01:33<00:00,  2.68it/s]=> result
* total: 25,000
* correct: 19,083
* accuracy: 76.3%
* error: 23.7%
* macro_f1: 75.9%

epoch [7/30] batch [20/2000] time 0.603 (0.646) data 0.000 (0.038) loss 2.3613 (3.1332) lr 9.0451e-03 eta 8:36:34
epoch [7/30] batch [40/2000] time 0.604 (0.623) data 0.000 (0.019) loss 6.1250 (2.9741) lr 9.0451e-03 eta 8:18:10
epoch [7/30] batch [60/2000] time 0.598 (0.615) data 0.000 (0.013) loss 1.6289 (2.9874) lr 9.0451e-03 eta 8:11:22
epoch [7/30] batch [80/2000] time 0.604 (0.611) data 0.000 (0.010) loss 3.5312 (2.8830) lr 9.0451e-03 eta 8:07:59
epoch [7/30] batch [100/2000] time 0.591 (0.608) data 0.000 (0.008) loss 0.8906 (2.8172) lr 9.0451e-03 eta 8:05:47
epoch [7/30] batch [120/2000] time 0.598 (0.607) data 0.000 (0.007) loss 0.8804 (2.7267) lr 9.0451e-03 eta 8:04:31
epoch [7/30] batch [140/2000] time 0.611 (0.606) data 0.000 (0.006) loss 1.9082 (2.8519) lr 9.0451e-03 eta 8:03:18
epoch [7/30] batch [160/2000] time 0.598 (0.605) data 0.000 (0.005) loss 4.2930 (2.7698) lr 9.0451e-03 eta 8:02:40
epoch [7/30] batch [180/2000] time 0.608 (0.605) data 0.000 (0.004) loss 6.7773 (2.7300) lr 9.0451e-03 eta 8:02:11
epoch [7/30] batch [200/2000] time 0.598 (0.604) data 0.000 (0.004) loss 0.7539 (2.6966) lr 9.0451e-03 eta 8:01:29
epoch [7/30] batch [220/2000] time 0.599 (0.604) data 0.000 (0.004) loss 3.1426 (2.7493) lr 9.0451e-03 eta 8:01:20
epoch [7/30] batch [240/2000] time 0.595 (0.604) data 0.000 (0.003) loss 1.4248 (2.6932) lr 9.0451e-03 eta 8:01:08
epoch [7/30] batch [260/2000] time 0.600 (0.604) data 0.000 (0.003) loss 1.0664 (2.6424) lr 9.0451e-03 eta 8:00:40
epoch [7/30] batch [280/2000] time 0.615 (0.604) data 0.000 (0.003) loss 1.6367 (2.6924) lr 9.0451e-03 eta 8:00:16
epoch [7/30] batch [300/2000] time 0.593 (0.604) data 0.000 (0.003) loss 1.2480 (2.6980) lr 9.0451e-03 eta 7:59:48
epoch [7/30] batch [320/2000] time 0.597 (0.604) data 0.000 (0.003) loss 4.3398 (2.6837) lr 9.0451e-03 eta 7:59:42
epoch [7/30] batch [340/2000] time 0.604 (0.604) data 0.000 (0.003) loss 1.5586 (2.7035) lr 9.0451e-03 eta 7:59:36
epoch [7/30] batch [360/2000] time 0.603 (0.604) data 0.000 (0.002) loss 6.8359 (2.7124) lr 9.0451e-03 eta 7:59:16
epoch [7/30] batch [380/2000] time 0.600 (0.603) data 0.000 (0.002) loss 11.8750 (2.7602) lr 9.0451e-03 eta 7:58:51
epoch [7/30] batch [400/2000] time 0.600 (0.603) data 0.000 (0.002) loss 5.2031 (2.7816) lr 9.0451e-03 eta 7:58:30
epoch [7/30] batch [420/2000] time 0.598 (0.603) data 0.000 (0.002) loss 3.1641 (2.7392) lr 9.0451e-03 eta 7:58:29
epoch [7/30] batch [440/2000] time 0.593 (0.603) data 0.000 (0.002) loss 2.3398 (2.7303) lr 9.0451e-03 eta 7:58:14
epoch [7/30] batch [460/2000] time 0.594 (0.603) data 0.000 (0.002) loss 6.2500 (2.7582) lr 9.0451e-03 eta 7:57:54
epoch [7/30] batch [480/2000] time 0.592 (0.603) data 0.000 (0.002) loss 2.4238 (2.7532) lr 9.0451e-03 eta 7:57:44
epoch [7/30] batch [500/2000] time 0.598 (0.603) data 0.000 (0.002) loss 2.8145 (2.7577) lr 9.0451e-03 eta 7:57:22
epoch [7/30] batch [520/2000] time 0.598 (0.603) data 0.000 (0.002) loss 2.2520 (2.7283) lr 9.0451e-03 eta 7:57:07
epoch [7/30] batch [540/2000] time 0.600 (0.603) data 0.000 (0.002) loss 2.5254 (2.7294) lr 9.0451e-03 eta 7:56:48
epoch [7/30] batch [560/2000] time 0.605 (0.603) data 0.000 (0.002) loss 4.9297 (2.7331) lr 9.0451e-03 eta 7:56:32
epoch [7/30] batch [580/2000] time 0.608 (0.603) data 0.000 (0.002) loss 1.9385 (2.7147) lr 9.0451e-03 eta 7:56:14
epoch [7/30] batch [600/2000] time 0.600 (0.602) data 0.000 (0.002) loss 3.9434 (2.7286) lr 9.0451e-03 eta 7:55:57
epoch [7/30] batch [620/2000] time 0.601 (0.603) data 0.000 (0.002) loss 1.1396 (2.7225) lr 9.0451e-03 eta 7:55:47
epoch [7/30] batch [640/2000] time 0.593 (0.602) data 0.000 (0.001) loss 1.8359 (2.7103) lr 9.0451e-03 eta 7:55:33
epoch [7/30] batch [660/2000] time 0.600 (0.602) data 0.000 (0.001) loss 2.3203 (2.7063) lr 9.0451e-03 eta 7:55:11
epoch [7/30] batch [680/2000] time 0.594 (0.602) data 0.000 (0.001) loss 1.1836 (2.6974) lr 9.0451e-03 eta 7:54:59
epoch [7/30] batch [700/2000] time 0.594 (0.602) data 0.000 (0.001) loss 4.7461 (2.6907) lr 9.0451e-03 eta 7:54:42
epoch [7/30] batch [720/2000] time 0.596 (0.602) data 0.000 (0.001) loss 4.2656 (2.7035) lr 9.0451e-03 eta 7:54:25
epoch [7/30] batch [740/2000] time 0.596 (0.602) data 0.000 (0.001) loss 3.7422 (2.6822) lr 9.0451e-03 eta 7:54:08
epoch [7/30] batch [760/2000] time 0.597 (0.602) data 0.000 (0.001) loss 5.0742 (2.7022) lr 9.0451e-03 eta 7:53:51
epoch [7/30] batch [780/2000] time 0.592 (0.602) data 0.000 (0.001) loss 5.6211 (2.7250) lr 9.0451e-03 eta 7:53:38
epoch [7/30] batch [800/2000] time 0.598 (0.602) data 0.000 (0.001) loss 0.9272 (2.7360) lr 9.0451e-03 eta 7:53:28
epoch [7/30] batch [820/2000] time 0.600 (0.602) data 0.000 (0.001) loss 5.2578 (2.7382) lr 9.0451e-03 eta 7:53:16
epoch [7/30] batch [840/2000] time 0.596 (0.602) data 0.000 (0.001) loss 1.1279 (2.7350) lr 9.0451e-03 eta 7:53:02
epoch [7/30] batch [860/2000] time 0.599 (0.602) data 0.000 (0.001) loss 2.5527 (2.7450) lr 9.0451e-03 eta 7:52:48
epoch [7/30] batch [880/2000] time 0.594 (0.602) data 0.000 (0.001) loss 3.8398 (2.7306) lr 9.0451e-03 eta 7:52:36
epoch [7/30] batch [900/2000] time 0.606 (0.602) data 0.000 (0.001) loss 0.5352 (2.7221) lr 9.0451e-03 eta 7:52:23
epoch [7/30] batch [920/2000] time 0.596 (0.602) data 0.000 (0.001) loss 1.3311 (2.7182) lr 9.0451e-03 eta 7:52:09
epoch [7/30] batch [940/2000] time 0.601 (0.602) data 0.000 (0.001) loss 0.8652 (2.7087) lr 9.0451e-03 eta 7:51:55
epoch [7/30] batch [960/2000] time 0.596 (0.602) data 0.000 (0.001) loss 0.6548 (2.7040) lr 9.0451e-03 eta 7:51:47
epoch [7/30] batch [980/2000] time 0.602 (0.602) data 0.000 (0.001) loss 2.6152 (2.6969) lr 9.0451e-03 eta 7:51:41
epoch [7/30] batch [1000/2000] time 0.599 (0.602) data 0.000 (0.001) loss 0.1428 (2.6937) lr 9.0451e-03 eta 7:51:27
epoch [7/30] batch [1020/2000] time 0.591 (0.602) data 0.000 (0.001) loss 2.6426 (2.6958) lr 9.0451e-03 eta 7:51:12
epoch [7/30] batch [1040/2000] time 0.600 (0.602) data 0.000 (0.001) loss 0.8345 (2.6969) lr 9.0451e-03 eta 7:50:57
epoch [7/30] batch [1060/2000] time 0.592 (0.602) data 0.000 (0.001) loss 0.1514 (2.6816) lr 9.0451e-03 eta 7:50:41
epoch [7/30] batch [1080/2000] time 0.612 (0.602) data 0.000 (0.001) loss 2.3848 (2.6832) lr 9.0451e-03 eta 7:50:27
epoch [7/30] batch [1100/2000] time 0.600 (0.602) data 0.000 (0.001) loss 3.7637 (2.6725) lr 9.0451e-03 eta 7:50:13
epoch [7/30] batch [1120/2000] time 0.603 (0.602) data 0.000 (0.001) loss 1.7490 (2.6677) lr 9.0451e-03 eta 7:50:00
epoch [7/30] batch [1140/2000] time 0.603 (0.602) data 0.000 (0.001) loss 3.3145 (2.6683) lr 9.0451e-03 eta 7:49:48
epoch [7/30] batch [1160/2000] time 0.595 (0.602) data 0.000 (0.001) loss 4.0938 (2.6662) lr 9.0451e-03 eta 7:49:40
epoch [7/30] batch [1180/2000] time 0.596 (0.602) data 0.000 (0.001) loss 0.7490 (2.6693) lr 9.0451e-03 eta 7:49:28
epoch [7/30] batch [1200/2000] time 0.605 (0.602) data 0.000 (0.001) loss 2.5840 (2.6708) lr 9.0451e-03 eta 7:49:14
epoch [7/30] batch [1220/2000] time 0.600 (0.602) data 0.000 (0.001) loss 2.7773 (2.6698) lr 9.0451e-03 eta 7:49:02
epoch [7/30] batch [1240/2000] time 0.595 (0.602) data 0.000 (0.001) loss 2.8105 (2.6741) lr 9.0451e-03 eta 7:48:48
epoch [7/30] batch [1260/2000] time 0.603 (0.602) data 0.000 (0.001) loss 4.8438 (2.6770) lr 9.0451e-03 eta 7:48:36
epoch [7/30] batch [1280/2000] time 0.600 (0.602) data 0.000 (0.001) loss 1.0830 (2.6680) lr 9.0451e-03 eta 7:48:27
epoch [7/30] batch [1300/2000] time 0.600 (0.602) data 0.000 (0.001) loss 4.0781 (2.6626) lr 9.0451e-03 eta 7:48:14
epoch [7/30] batch [1320/2000] time 0.599 (0.602) data 0.000 (0.001) loss 1.3623 (2.6597) lr 9.0451e-03 eta 7:48:00
epoch [7/30] batch [1340/2000] time 0.595 (0.602) data 0.000 (0.001) loss 4.3828 (2.6494) lr 9.0451e-03 eta 7:47:46
epoch [7/30] batch [1360/2000] time 0.597 (0.602) data 0.000 (0.001) loss 9.5391 (2.6515) lr 9.0451e-03 eta 7:47:36
epoch [7/30] batch [1380/2000] time 0.601 (0.601) data 0.000 (0.001) loss 2.7324 (2.6488) lr 9.0451e-03 eta 7:47:21
epoch [7/30] batch [1400/2000] time 0.600 (0.602) data 0.000 (0.001) loss 3.7520 (2.6510) lr 9.0451e-03 eta 7:47:10
epoch [7/30] batch [1420/2000] time 0.602 (0.602) data 0.000 (0.001) loss 0.9263 (2.6465) lr 9.0451e-03 eta 7:46:58
epoch [7/30] batch [1440/2000] time 0.612 (0.602) data 0.000 (0.001) loss 2.3613 (2.6492) lr 9.0451e-03 eta 7:46:46
epoch [7/30] batch [1460/2000] time 0.596 (0.602) data 0.000 (0.001) loss 5.8047 (2.6485) lr 9.0451e-03 eta 7:46:35
epoch [7/30] batch [1480/2000] time 0.602 (0.602) data 0.000 (0.001) loss 7.2930 (2.6483) lr 9.0451e-03 eta 7:46:24
epoch [7/30] batch [1500/2000] time 0.600 (0.602) data 0.000 (0.001) loss 3.4590 (2.6493) lr 9.0451e-03 eta 7:46:11
epoch [7/30] batch [1520/2000] time 0.599 (0.602) data 0.000 (0.001) loss 4.5977 (2.6430) lr 9.0451e-03 eta 7:46:02
epoch [7/30] batch [1540/2000] time 0.595 (0.602) data 0.000 (0.001) loss 3.2129 (2.6410) lr 9.0451e-03 eta 7:45:50
epoch [7/30] batch [1560/2000] time 0.598 (0.602) data 0.000 (0.001) loss 1.6846 (2.6425) lr 9.0451e-03 eta 7:45:36
epoch [7/30] batch [1580/2000] time 0.598 (0.602) data 0.000 (0.001) loss 0.1064 (2.6353) lr 9.0451e-03 eta 7:45:25
epoch [7/30] batch [1600/2000] time 0.615 (0.602) data 0.000 (0.001) loss 0.6001 (2.6310) lr 9.0451e-03 eta 7:45:12
epoch [7/30] batch [1620/2000] time 0.597 (0.602) data 0.000 (0.001) loss 4.7031 (2.6339) lr 9.0451e-03 eta 7:45:03
epoch [7/30] batch [1640/2000] time 0.594 (0.602) data 0.000 (0.001) loss 2.5293 (2.6288) lr 9.0451e-03 eta 7:44:49
epoch [7/30] batch [1660/2000] time 0.595 (0.602) data 0.000 (0.001) loss 2.8008 (2.6325) lr 9.0451e-03 eta 7:44:36
epoch [7/30] batch [1680/2000] time 0.598 (0.602) data 0.000 (0.001) loss 4.2188 (2.6441) lr 9.0451e-03 eta 7:44:24
epoch [7/30] batch [1700/2000] time 0.606 (0.602) data 0.000 (0.001) loss 3.6426 (2.6496) lr 9.0451e-03 eta 7:44:13
epoch [7/30] batch [1720/2000] time 0.594 (0.602) data 0.000 (0.001) loss 3.2930 (2.6540) lr 9.0451e-03 eta 7:44:02
epoch [7/30] batch [1740/2000] time 0.595 (0.602) data 0.000 (0.001) loss 2.6035 (2.6518) lr 9.0451e-03 eta 7:43:51
epoch [7/30] batch [1760/2000] time 0.594 (0.602) data 0.000 (0.001) loss 1.1709 (2.6438) lr 9.0451e-03 eta 7:43:39
epoch [7/30] batch [1780/2000] time 0.599 (0.602) data 0.000 (0.001) loss 5.0430 (2.6440) lr 9.0451e-03 eta 7:43:28
epoch [7/30] batch [1800/2000] time 0.616 (0.602) data 0.001 (0.001) loss 4.9883 (2.6424) lr 9.0451e-03 eta 7:43:16
epoch [7/30] batch [1820/2000] time 0.596 (0.602) data 0.000 (0.001) loss 1.9297 (2.6422) lr 9.0451e-03 eta 7:43:06
epoch [7/30] batch [1840/2000] time 0.616 (0.602) data 0.000 (0.001) loss 4.9141 (2.6428) lr 9.0451e-03 eta 7:42:53
epoch [7/30] batch [1860/2000] time 0.621 (0.602) data 0.000 (0.001) loss 3.5488 (2.6500) lr 9.0451e-03 eta 7:42:43
epoch [7/30] batch [1880/2000] time 0.604 (0.602) data 0.000 (0.001) loss 1.9219 (2.6487) lr 9.0451e-03 eta 7:42:31
epoch [7/30] batch [1900/2000] time 0.611 (0.602) data 0.000 (0.001) loss 3.4648 (2.6423) lr 9.0451e-03 eta 7:42:20
epoch [7/30] batch [1920/2000] time 0.593 (0.602) data 0.000 (0.001) loss 3.0840 (2.6409) lr 9.0451e-03 eta 7:42:07
epoch [7/30] batch [1940/2000] time 0.594 (0.602) data 0.000 (0.001) loss 5.1328 (2.6389) lr 9.0451e-03 eta 7:41:53
epoch [7/30] batch [1960/2000] time 0.593 (0.602) data 0.000 (0.001) loss 0.4163 (2.6374) lr 9.0451e-03 eta 7:41:40
epoch [7/30] batch [1980/2000] time 0.590 (0.602) data 0.000 (0.001) loss 3.2578 (2.6329) lr 9.0451e-03 eta 7:41:26
epoch [7/30] batch [2000/2000] time 0.607 (0.602) data 0.000 (0.001) loss 0.7847 (2.6284) lr 8.7157e-03 eta 7:41:09
Evaluate on the *val* set
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:02<11:26,  2.76s/it]  1%|          | 2/250 [00:03<06:24,  1.55s/it]  1%|          | 3/250 [00:03<04:20,  1.05s/it]  2%|▏         | 4/250 [00:04<03:14,  1.27it/s]  2%|▏         | 5/250 [00:04<02:37,  1.55it/s]  2%|▏         | 6/250 [00:05<02:15,  1.80it/s]  3%|▎         | 7/250 [00:05<02:03,  1.96it/s]  3%|▎         | 8/250 [00:05<01:53,  2.14it/s]  4%|▎         | 9/250 [00:06<01:46,  2.27it/s]  4%|▍         | 10/250 [00:06<01:39,  2.41it/s]  4%|▍         | 11/250 [00:06<01:35,  2.50it/s]  5%|▍         | 12/250 [00:07<01:32,  2.57it/s]  5%|▌         | 13/250 [00:07<01:30,  2.62it/s]  6%|▌         | 14/250 [00:08<01:28,  2.66it/s]  6%|▌         | 15/250 [00:08<01:27,  2.68it/s]  6%|▋         | 16/250 [00:08<01:26,  2.69it/s]  7%|▋         | 17/250 [00:09<01:26,  2.70it/s]  7%|▋         | 18/250 [00:09<01:25,  2.70it/s]  8%|▊         | 19/250 [00:09<01:23,  2.76it/s]  8%|▊         | 20/250 [00:10<01:24,  2.73it/s]  8%|▊         | 21/250 [00:10<01:26,  2.66it/s]  9%|▉         | 22/250 [00:11<01:24,  2.69it/s]  9%|▉         | 23/250 [00:11<01:24,  2.68it/s] 10%|▉         | 24/250 [00:11<01:23,  2.69it/s] 10%|█         | 25/250 [00:12<01:22,  2.74it/s] 10%|█         | 26/250 [00:12<01:21,  2.76it/s] 11%|█         | 27/250 [00:12<01:20,  2.79it/s] 11%|█         | 28/250 [00:13<01:19,  2.79it/s] 12%|█▏        | 29/250 [00:13<01:19,  2.77it/s] 12%|█▏        | 30/250 [00:13<01:19,  2.75it/s] 12%|█▏        | 31/250 [00:14<01:20,  2.71it/s] 13%|█▎        | 32/250 [00:14<01:20,  2.72it/s] 13%|█▎        | 33/250 [00:15<01:20,  2.68it/s] 14%|█▎        | 34/250 [00:15<01:19,  2.72it/s] 14%|█▍        | 35/250 [00:15<01:20,  2.69it/s] 14%|█▍        | 36/250 [00:16<01:18,  2.72it/s] 15%|█▍        | 37/250 [00:16<01:17,  2.75it/s] 15%|█▌        | 38/250 [00:16<01:17,  2.72it/s] 16%|█▌        | 39/250 [00:17<01:18,  2.69it/s] 16%|█▌        | 40/250 [00:17<01:17,  2.70it/s] 16%|█▋        | 41/250 [00:17<01:16,  2.74it/s] 17%|█▋        | 42/250 [00:18<01:14,  2.79it/s] 17%|█▋        | 43/250 [00:18<01:13,  2.80it/s] 18%|█▊        | 44/250 [00:19<01:13,  2.79it/s] 18%|█▊        | 45/250 [00:19<01:13,  2.78it/s] 18%|█▊        | 46/250 [00:19<01:13,  2.77it/s] 19%|█▉        | 47/250 [00:20<01:13,  2.78it/s] 19%|█▉        | 48/250 [00:20<01:12,  2.78it/s] 20%|█▉        | 49/250 [00:20<01:12,  2.78it/s] 20%|██        | 50/250 [00:21<01:11,  2.80it/s] 20%|██        | 51/250 [00:21<01:10,  2.83it/s] 21%|██        | 52/250 [00:21<01:10,  2.80it/s] 21%|██        | 53/250 [00:22<01:10,  2.80it/s] 22%|██▏       | 54/250 [00:22<01:11,  2.74it/s] 22%|██▏       | 55/250 [00:22<01:11,  2.74it/s] 22%|██▏       | 56/250 [00:23<01:11,  2.72it/s] 23%|██▎       | 57/250 [00:23<01:09,  2.77it/s] 23%|██▎       | 58/250 [00:24<01:10,  2.73it/s] 24%|██▎       | 59/250 [00:24<01:10,  2.73it/s] 24%|██▍       | 60/250 [00:24<01:09,  2.72it/s] 24%|██▍       | 61/250 [00:25<01:09,  2.74it/s] 25%|██▍       | 62/250 [00:25<01:08,  2.76it/s] 25%|██▌       | 63/250 [00:25<01:06,  2.82it/s] 26%|██▌       | 64/250 [00:26<01:06,  2.80it/s] 26%|██▌       | 65/250 [00:26<01:06,  2.78it/s] 26%|██▋       | 66/250 [00:26<01:06,  2.76it/s] 27%|██▋       | 67/250 [00:27<01:06,  2.74it/s] 27%|██▋       | 68/250 [00:27<01:06,  2.74it/s] 28%|██▊       | 69/250 [00:28<01:05,  2.76it/s] 28%|██▊       | 70/250 [00:28<01:05,  2.76it/s] 28%|██▊       | 71/250 [00:28<01:04,  2.75it/s] 29%|██▉       | 72/250 [00:29<01:04,  2.76it/s] 29%|██▉       | 73/250 [00:29<01:05,  2.71it/s] 30%|██▉       | 74/250 [00:29<01:05,  2.71it/s] 30%|███       | 75/250 [00:30<01:04,  2.72it/s] 30%|███       | 76/250 [00:30<01:04,  2.71it/s] 31%|███       | 77/250 [00:31<01:03,  2.71it/s] 31%|███       | 78/250 [00:31<01:04,  2.69it/s] 32%|███▏      | 79/250 [00:31<01:02,  2.73it/s] 32%|███▏      | 80/250 [00:32<01:01,  2.77it/s] 32%|███▏      | 81/250 [00:32<01:01,  2.76it/s] 33%|███▎      | 82/250 [00:32<01:00,  2.78it/s] 33%|███▎      | 83/250 [00:33<00:59,  2.80it/s] 34%|███▎      | 84/250 [00:33<00:59,  2.79it/s] 34%|███▍      | 85/250 [00:33<00:58,  2.80it/s] 34%|███▍      | 86/250 [00:34<00:59,  2.77it/s] 35%|███▍      | 87/250 [00:34<00:59,  2.75it/s] 35%|███▌      | 88/250 [00:34<00:59,  2.74it/s] 36%|███▌      | 89/250 [00:35<00:58,  2.75it/s] 36%|███▌      | 90/250 [00:35<00:57,  2.79it/s] 36%|███▋      | 91/250 [00:36<00:56,  2.79it/s] 37%|███▋      | 92/250 [00:36<00:57,  2.75it/s] 37%|███▋      | 93/250 [00:36<00:57,  2.75it/s] 38%|███▊      | 94/250 [00:37<00:55,  2.79it/s] 38%|███▊      | 95/250 [00:37<00:55,  2.82it/s] 38%|███▊      | 96/250 [00:37<00:54,  2.83it/s] 39%|███▉      | 97/250 [00:38<00:55,  2.78it/s] 39%|███▉      | 98/250 [00:38<00:54,  2.77it/s] 40%|███▉      | 99/250 [00:38<00:54,  2.76it/s] 40%|████      | 100/250 [00:39<00:54,  2.76it/s] 40%|████      | 101/250 [00:39<00:54,  2.73it/s] 41%|████      | 102/250 [00:40<00:54,  2.70it/s] 41%|████      | 103/250 [00:40<00:55,  2.64it/s] 42%|████▏     | 104/250 [00:40<00:55,  2.64it/s] 42%|████▏     | 105/250 [00:41<00:53,  2.70it/s] 42%|████▏     | 106/250 [00:41<00:54,  2.66it/s] 43%|████▎     | 107/250 [00:41<00:53,  2.69it/s] 43%|████▎     | 108/250 [00:42<00:53,  2.65it/s] 44%|████▎     | 109/250 [00:42<00:52,  2.67it/s] 44%|████▍     | 110/250 [00:43<00:51,  2.71it/s] 44%|████▍     | 111/250 [00:43<00:51,  2.68it/s] 45%|████▍     | 112/250 [00:43<00:51,  2.67it/s] 45%|████▌     | 113/250 [00:44<00:51,  2.68it/s] 46%|████▌     | 114/250 [00:44<00:49,  2.75it/s] 46%|████▌     | 115/250 [00:44<00:49,  2.71it/s] 46%|████▋     | 116/250 [00:45<00:49,  2.73it/s] 47%|████▋     | 117/250 [00:45<00:49,  2.71it/s] 47%|████▋     | 118/250 [00:46<00:49,  2.66it/s] 48%|████▊     | 119/250 [00:46<00:49,  2.63it/s] 48%|████▊     | 120/250 [00:46<00:49,  2.62it/s] 48%|████▊     | 121/250 [00:47<00:49,  2.59it/s] 49%|████▉     | 122/250 [00:47<00:48,  2.63it/s] 49%|████▉     | 123/250 [00:47<00:47,  2.66it/s] 50%|████▉     | 124/250 [00:48<00:45,  2.74it/s] 50%|█████     | 125/250 [00:48<00:45,  2.74it/s] 50%|█████     | 126/250 [00:48<00:44,  2.77it/s] 51%|█████     | 127/250 [00:49<00:44,  2.76it/s] 51%|█████     | 128/250 [00:49<00:44,  2.71it/s] 52%|█████▏    | 129/250 [00:50<00:44,  2.69it/s] 52%|█████▏    | 130/250 [00:50<00:45,  2.64it/s] 52%|█████▏    | 131/250 [00:50<00:44,  2.69it/s] 53%|█████▎    | 132/250 [00:51<00:42,  2.75it/s] 53%|█████▎    | 133/250 [00:51<00:42,  2.77it/s] 54%|█████▎    | 134/250 [00:51<00:42,  2.75it/s] 54%|█████▍    | 135/250 [00:52<00:42,  2.73it/s] 54%|█████▍    | 136/250 [00:52<00:42,  2.69it/s] 55%|█████▍    | 137/250 [00:53<00:42,  2.66it/s] 55%|█████▌    | 138/250 [00:53<00:42,  2.64it/s] 56%|█████▌    | 139/250 [00:53<00:41,  2.67it/s] 56%|█████▌    | 140/250 [00:54<00:41,  2.68it/s] 56%|█████▋    | 141/250 [00:54<00:40,  2.69it/s] 57%|█████▋    | 142/250 [00:54<00:40,  2.68it/s] 57%|█████▋    | 143/250 [00:55<00:39,  2.69it/s] 58%|█████▊    | 144/250 [00:55<00:39,  2.71it/s] 58%|█████▊    | 145/250 [00:56<00:38,  2.73it/s] 58%|█████▊    | 146/250 [00:56<00:37,  2.76it/s] 59%|█████▉    | 147/250 [00:56<00:37,  2.76it/s] 59%|█████▉    | 148/250 [00:57<00:36,  2.77it/s] 60%|█████▉    | 149/250 [00:57<00:36,  2.77it/s] 60%|██████    | 150/250 [00:57<00:36,  2.75it/s] 60%|██████    | 151/250 [00:58<00:36,  2.73it/s] 61%|██████    | 152/250 [00:58<00:35,  2.74it/s] 61%|██████    | 153/250 [00:58<00:34,  2.80it/s] 62%|██████▏   | 154/250 [00:59<00:34,  2.77it/s] 62%|██████▏   | 155/250 [00:59<00:34,  2.72it/s] 62%|██████▏   | 156/250 [01:00<00:34,  2.75it/s] 63%|██████▎   | 157/250 [01:00<00:33,  2.74it/s] 63%|██████▎   | 158/250 [01:00<00:33,  2.72it/s] 64%|██████▎   | 159/250 [01:01<00:34,  2.67it/s] 64%|██████▍   | 160/250 [01:01<00:33,  2.69it/s] 64%|██████▍   | 161/250 [01:01<00:34,  2.61it/s] 65%|██████▍   | 162/250 [01:02<00:33,  2.61it/s] 65%|██████▌   | 163/250 [01:02<00:33,  2.62it/s] 66%|██████▌   | 164/250 [01:03<00:32,  2.65it/s] 66%|██████▌   | 165/250 [01:03<00:31,  2.69it/s] 66%|██████▋   | 166/250 [01:03<00:31,  2.69it/s] 67%|██████▋   | 167/250 [01:04<00:30,  2.69it/s] 67%|██████▋   | 168/250 [01:04<00:30,  2.69it/s] 68%|██████▊   | 169/250 [01:04<00:30,  2.67it/s] 68%|██████▊   | 170/250 [01:05<00:29,  2.71it/s] 68%|██████▊   | 171/250 [01:05<00:29,  2.71it/s] 69%|██████▉   | 172/250 [01:06<00:28,  2.73it/s] 69%|██████▉   | 173/250 [01:06<00:27,  2.76it/s] 70%|██████▉   | 174/250 [01:06<00:27,  2.78it/s] 70%|███████   | 175/250 [01:07<00:27,  2.74it/s] 70%|███████   | 176/250 [01:07<00:27,  2.70it/s] 71%|███████   | 177/250 [01:07<00:26,  2.75it/s] 71%|███████   | 178/250 [01:08<00:26,  2.74it/s] 72%|███████▏  | 179/250 [01:08<00:26,  2.73it/s] 72%|███████▏  | 180/250 [01:08<00:26,  2.69it/s] 72%|███████▏  | 181/250 [01:09<00:25,  2.68it/s] 73%|███████▎  | 182/250 [01:09<00:25,  2.70it/s] 73%|███████▎  | 183/250 [01:10<00:24,  2.70it/s] 74%|███████▎  | 184/250 [01:10<00:24,  2.67it/s] 74%|███████▍  | 185/250 [01:10<00:23,  2.71it/s] 74%|███████▍  | 186/250 [01:11<00:23,  2.71it/s] 75%|███████▍  | 187/250 [01:11<00:23,  2.73it/s] 75%|███████▌  | 188/250 [01:11<00:22,  2.74it/s] 76%|███████▌  | 189/250 [01:12<00:22,  2.74it/s] 76%|███████▌  | 190/250 [01:12<00:21,  2.78it/s] 76%|███████▋  | 191/250 [01:12<00:21,  2.81it/s] 77%|███████▋  | 192/250 [01:13<00:20,  2.80it/s] 77%|███████▋  | 193/250 [01:13<00:20,  2.74it/s] 78%|███████▊  | 194/250 [01:14<00:20,  2.70it/s] 78%|███████▊  | 195/250 [01:14<00:20,  2.72it/s] 78%|███████▊  | 196/250 [01:14<00:19,  2.72it/s] 79%|███████▉  | 197/250 [01:15<00:19,  2.69it/s] 79%|███████▉  | 198/250 [01:15<00:19,  2.69it/s] 80%|███████▉  | 199/250 [01:15<00:18,  2.73it/s] 80%|████████  | 200/250 [01:16<00:18,  2.78it/s] 80%|████████  | 201/250 [01:16<00:17,  2.76it/s] 81%|████████  | 202/250 [01:17<00:17,  2.72it/s] 81%|████████  | 203/250 [01:17<00:17,  2.70it/s] 82%|████████▏ | 204/250 [01:17<00:17,  2.69it/s] 82%|████████▏ | 205/250 [01:18<00:16,  2.70it/s] 82%|████████▏ | 206/250 [01:18<00:16,  2.67it/s] 83%|████████▎ | 207/250 [01:18<00:16,  2.67it/s] 83%|████████▎ | 208/250 [01:19<00:15,  2.69it/s] 84%|████████▎ | 209/250 [01:19<00:15,  2.70it/s] 84%|████████▍ | 210/250 [01:19<00:14,  2.70it/s] 84%|████████▍ | 211/250 [01:20<00:14,  2.69it/s] 85%|████████▍ | 212/250 [01:20<00:14,  2.71it/s] 85%|████████▌ | 213/250 [01:21<00:13,  2.73it/s] 86%|████████▌ | 214/250 [01:21<00:13,  2.67it/s] 86%|████████▌ | 215/250 [01:21<00:13,  2.69it/s] 86%|████████▋ | 216/250 [01:22<00:12,  2.70it/s] 87%|████████▋ | 217/250 [01:22<00:12,  2.67it/s] 87%|████████▋ | 218/250 [01:22<00:11,  2.70it/s] 88%|████████▊ | 219/250 [01:23<00:11,  2.73it/s] 88%|████████▊ | 220/250 [01:23<00:10,  2.76it/s] 88%|████████▊ | 221/250 [01:23<00:10,  2.84it/s] 89%|████████▉ | 222/250 [01:24<00:09,  2.97it/s] 89%|████████▉ | 223/250 [01:24<00:08,  3.08it/s] 90%|████████▉ | 224/250 [01:24<00:08,  3.15it/s] 90%|█████████ | 225/250 [01:25<00:07,  3.21it/s] 90%|█████████ | 226/250 [01:25<00:07,  3.22it/s] 91%|█████████ | 227/250 [01:25<00:07,  3.25it/s] 91%|█████████ | 228/250 [01:26<00:06,  3.28it/s] 92%|█████████▏| 229/250 [01:26<00:06,  3.30it/s] 92%|█████████▏| 230/250 [01:26<00:06,  3.32it/s] 92%|█████████▏| 231/250 [01:26<00:05,  3.33it/s] 93%|█████████▎| 232/250 [01:27<00:05,  3.34it/s] 93%|█████████▎| 233/250 [01:27<00:05,  3.35it/s] 94%|█████████▎| 234/250 [01:27<00:04,  3.35it/s] 94%|█████████▍| 235/250 [01:28<00:04,  3.35it/s] 94%|█████████▍| 236/250 [01:28<00:04,  3.35it/s] 95%|█████████▍| 237/250 [01:28<00:03,  3.36it/s] 95%|█████████▌| 238/250 [01:29<00:03,  3.36it/s] 96%|█████████▌| 239/250 [01:29<00:03,  3.36it/s] 96%|█████████▌| 240/250 [01:29<00:02,  3.36it/s] 96%|█████████▋| 241/250 [01:29<00:02,  3.36it/s] 97%|█████████▋| 242/250 [01:30<00:02,  3.36it/s] 97%|█████████▋| 243/250 [01:30<00:02,  3.35it/s] 98%|█████████▊| 244/250 [01:30<00:01,  3.36it/s] 98%|█████████▊| 245/250 [01:31<00:01,  3.35it/s] 98%|█████████▊| 246/250 [01:31<00:01,  3.35it/s] 99%|█████████▉| 247/250 [01:31<00:00,  3.35it/s] 99%|█████████▉| 248/250 [01:32<00:00,  3.36it/s]100%|█████████▉| 249/250 [01:32<00:00,  3.36it/s]100%|██████████| 250/250 [01:32<00:00,  3.36it/s]100%|██████████| 250/250 [01:32<00:00,  2.69it/s]=> result
* total: 25,000
* correct: 19,146
* accuracy: 76.6%
* error: 23.4%
* macro_f1: 76.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/imagenet/shots_16/RPO_prime_sdl/main_tmp1_0.1sdl/seed1/prompt_learner/model-best.pth.tar

slurmstepd: error: *** JOB 396012 ON b19 CANCELLED AT 2024-02-29T12:20:21 DUE TO TIME LIMIT ***

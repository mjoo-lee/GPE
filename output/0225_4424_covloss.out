set -e
set -x

eval "$(conda shell.bash hook)"
++ conda shell.bash hook
+ eval 'export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We're not allowing PS1 to be unbound. It must at least be set.
    # However, we're not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi
++ '[' -z x ']'

conda activate base
++ conda activate base
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate base
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate base
+++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate base
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(base) '
+++ PS1='(base) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
+++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
+++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda'
+++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda
+++ CONDA_PREFIX=/home/s2/mjoolee/anaconda
export CONDA_SHLVL='3'
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
export CONDA_DEFAULT_ENV='base'
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
export CONDA_PROMPT_MODIFIER='(base) '
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
export CONDA_PREFIX_2='/home/s2/mjoolee/anaconda/envs/dassl'
+++ export CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
+++ CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
+++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
+++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
+++ export _CE_M=
+++ _CE_M=
export _CE_CONDA=''
+++ export _CE_CONDA=
+++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
+++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
conda activate dassl
+ conda activate dassl
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate dassl
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate dassl
++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate dassl
+ ask_conda='PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
+ eval 'PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(dassl) '
++ PS1='(dassl) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda/envs/dassl'
++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
++ CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_SHLVL='4'
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
export CONDA_DEFAULT_ENV='dassl'
++ export CONDA_DEFAULT_ENV=dassl
++ CONDA_DEFAULT_ENV=dassl
export CONDA_PROMPT_MODIFIER='(dassl) '
++ export 'CONDA_PROMPT_MODIFIER=(dassl) '
++ CONDA_PROMPT_MODIFIER='(dassl) '
export CONDA_PREFIX_3='/home/s2/mjoolee/anaconda'
++ export CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
++ CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r

GPU=0
+ GPU=0
SHOT=16
+ SHOT=16

for dataset in oxford_flowers stanford_cars oxford_pets food101 eurosat dtd sun397 ucf101 caltech101 imagenet
do
    for seed in 1 2 3
    do
    sh scripts/rpo_prime/base2new_train.sh ${dataset} ${seed} ${GPU} main_tmp1 ${SHOT}
    #sh scripts/rpo_prime/base2new_test.sh ${dataset} ${seed} ${GPU} main_9_9 ${SHOT} base
    sh scripts/rpo_prime/base2new_test.sh ${dataset} ${seed} ${GPU} main_tmp1 ${SHOT} new
    done
done
+ for dataset in oxford_flowers stanford_cars oxford_pets food101 eurosat dtd sun397 ucf101 caltech101 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train.sh oxford_flowers 1 0 main_tmp1 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
816 696 1053
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      696
# test     1,053
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/50] batch [2/12] time 0.394 (2.568) data 0.000 (0.968) loss 3.0234 (3.2520) lr 1.0000e-01 eta 0:25:35
epoch [1/50] batch [4/12] time 0.399 (1.484) data 0.000 (0.484) loss 3.2441 (3.2012) lr 1.0000e-01 eta 0:14:44
epoch [1/50] batch [6/12] time 0.393 (1.120) data 0.000 (0.323) loss 2.7012 (3.0648) lr 1.0000e-01 eta 0:11:05
epoch [1/50] batch [8/12] time 0.393 (0.939) data 0.000 (0.242) loss 2.1348 (2.8833) lr 1.0000e-01 eta 0:09:15
epoch [1/50] batch [10/12] time 0.393 (0.830) data 0.000 (0.194) loss 2.3398 (2.7969) lr 1.0000e-01 eta 0:08:09
epoch [1/50] batch [12/12] time 0.402 (0.758) data 0.000 (0.161) loss 2.2070 (2.7038) lr 9.9901e-02 eta 0:07:25
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:03<00:11,  3.82s/it] 50%|█████     | 2/4 [00:04<00:03,  1.72s/it] 75%|███████▌  | 3/4 [00:04<00:01,  1.04s/it]100%|██████████| 4/4 [00:04<00:00,  1.45it/s]100%|██████████| 4/4 [00:04<00:00,  1.14s/it]=> result
* total: 696
* correct: 503
* accuracy: 72.3%
* error: 27.7%
* macro_f1: 65.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [2/50] batch [2/12] time 0.392 (1.031) data 0.000 (0.614) loss 2.0977 (2.2041) lr 9.9901e-02 eta 0:10:04
epoch [2/50] batch [4/12] time 0.391 (0.711) data 0.000 (0.307) loss 2.3086 (2.2632) lr 9.9901e-02 eta 0:06:55
epoch [2/50] batch [6/12] time 0.392 (0.605) data 0.000 (0.205) loss 2.0723 (2.1982) lr 9.9901e-02 eta 0:05:52
epoch [2/50] batch [8/12] time 0.392 (0.552) data 0.000 (0.154) loss 2.2656 (2.1670) lr 9.9901e-02 eta 0:05:20
epoch [2/50] batch [10/12] time 0.392 (0.520) data 0.000 (0.123) loss 1.9355 (2.1553) lr 9.9901e-02 eta 0:05:00
epoch [2/50] batch [12/12] time 0.392 (0.499) data 0.000 (0.102) loss 1.9199 (2.1346) lr 9.9606e-02 eta 0:04:47
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 501
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 66.0%

epoch [3/50] batch [2/12] time 0.393 (1.036) data 0.000 (0.630) loss 2.0371 (2.0898) lr 9.9606e-02 eta 0:09:54
epoch [3/50] batch [4/12] time 0.399 (0.717) data 0.000 (0.315) loss 1.9238 (2.1201) lr 9.9606e-02 eta 0:06:49
epoch [3/50] batch [6/12] time 0.392 (0.609) data 0.000 (0.210) loss 2.0449 (2.0868) lr 9.9606e-02 eta 0:05:47
epoch [3/50] batch [8/12] time 0.393 (0.555) data 0.000 (0.158) loss 1.9951 (2.0713) lr 9.9606e-02 eta 0:05:15
epoch [3/50] batch [10/12] time 0.395 (0.523) data 0.000 (0.126) loss 2.0039 (2.0725) lr 9.9606e-02 eta 0:04:55
epoch [3/50] batch [12/12] time 0.391 (0.501) data 0.000 (0.105) loss 1.8398 (2.0500) lr 9.9114e-02 eta 0:04:42
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.58s/it] 50%|█████     | 2/4 [00:02<00:02,  1.20s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.31it/s]100%|██████████| 4/4 [00:03<00:00,  1.92it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 508
* accuracy: 73.0%
* error: 27.0%
* macro_f1: 66.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [4/50] batch [2/12] time 0.395 (1.040) data 0.000 (0.639) loss 2.0039 (1.9497) lr 9.9114e-02 eta 0:09:44
epoch [4/50] batch [4/12] time 0.394 (0.717) data 0.000 (0.319) loss 1.7812 (1.9553) lr 9.9114e-02 eta 0:06:41
epoch [4/50] batch [6/12] time 0.391 (0.608) data 0.000 (0.213) loss 1.7354 (1.9362) lr 9.9114e-02 eta 0:05:39
epoch [4/50] batch [8/12] time 0.395 (0.554) data 0.000 (0.160) loss 2.0156 (1.9480) lr 9.9114e-02 eta 0:05:08
epoch [4/50] batch [10/12] time 0.391 (0.522) data 0.000 (0.128) loss 2.2266 (1.9772) lr 9.9114e-02 eta 0:04:49
epoch [4/50] batch [12/12] time 0.391 (0.500) data 0.000 (0.107) loss 1.9531 (1.9722) lr 9.8429e-02 eta 0:04:36
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.57s/it] 50%|█████     | 2/4 [00:02<00:02,  1.20s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.31it/s]100%|██████████| 4/4 [00:03<00:00,  1.92it/s]100%|██████████| 4/4 [00:03<00:00,  1.20it/s]=> result
* total: 696
* correct: 517
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 68.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [5/50] batch [2/12] time 0.401 (1.022) data 0.000 (0.559) loss 2.1914 (2.0728) lr 9.8429e-02 eta 0:09:22
epoch [5/50] batch [4/12] time 0.394 (0.708) data 0.000 (0.280) loss 1.9326 (2.0542) lr 9.8429e-02 eta 0:06:27
epoch [5/50] batch [6/12] time 0.395 (0.604) data 0.000 (0.187) loss 1.7617 (2.0036) lr 9.8429e-02 eta 0:05:29
epoch [5/50] batch [8/12] time 0.395 (0.551) data 0.000 (0.140) loss 1.7568 (1.9688) lr 9.8429e-02 eta 0:04:59
epoch [5/50] batch [10/12] time 0.393 (0.520) data 0.000 (0.112) loss 1.8506 (1.9439) lr 9.8429e-02 eta 0:04:41
epoch [5/50] batch [12/12] time 0.395 (0.499) data 0.000 (0.093) loss 1.9541 (1.9332) lr 9.7553e-02 eta 0:04:29
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 521
* accuracy: 74.9%
* error: 25.1%
* macro_f1: 69.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [6/50] batch [2/12] time 0.399 (1.032) data 0.000 (0.626) loss 1.7568 (1.8677) lr 9.7553e-02 eta 0:09:14
epoch [6/50] batch [4/12] time 0.391 (0.712) data 0.000 (0.313) loss 2.2031 (1.9661) lr 9.7553e-02 eta 0:06:21
epoch [6/50] batch [6/12] time 0.392 (0.605) data 0.000 (0.209) loss 1.8213 (1.9076) lr 9.7553e-02 eta 0:05:23
epoch [6/50] batch [8/12] time 0.402 (0.553) data 0.000 (0.156) loss 1.9717 (1.9061) lr 9.7553e-02 eta 0:04:54
epoch [6/50] batch [10/12] time 0.394 (0.521) data 0.000 (0.125) loss 1.8496 (1.9021) lr 9.7553e-02 eta 0:04:36
epoch [6/50] batch [12/12] time 0.397 (0.501) data 0.000 (0.104) loss 1.8447 (1.9041) lr 9.6489e-02 eta 0:04:24
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.61s/it] 50%|█████     | 2/4 [00:02<00:02,  1.22s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.29it/s]100%|██████████| 4/4 [00:03<00:00,  1.90it/s]100%|██████████| 4/4 [00:03<00:00,  1.20it/s]=> result
* total: 696
* correct: 526
* accuracy: 75.6%
* error: 24.4%
* macro_f1: 70.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [7/50] batch [2/12] time 0.392 (1.012) data 0.000 (0.585) loss 1.9971 (1.9731) lr 9.6489e-02 eta 0:08:52
epoch [7/50] batch [4/12] time 0.392 (0.703) data 0.000 (0.293) loss 1.8867 (1.9192) lr 9.6489e-02 eta 0:06:08
epoch [7/50] batch [6/12] time 0.396 (0.601) data 0.000 (0.195) loss 1.5918 (1.9041) lr 9.6489e-02 eta 0:05:13
epoch [7/50] batch [8/12] time 0.393 (0.549) data 0.000 (0.146) loss 1.6104 (1.8732) lr 9.6489e-02 eta 0:04:45
epoch [7/50] batch [10/12] time 0.394 (0.518) data 0.000 (0.117) loss 1.9268 (1.8688) lr 9.6489e-02 eta 0:04:28
epoch [7/50] batch [12/12] time 0.395 (0.498) data 0.000 (0.098) loss 1.9648 (1.8888) lr 9.5241e-02 eta 0:04:16
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 524
* accuracy: 75.3%
* error: 24.7%
* macro_f1: 70.4%

epoch [8/50] batch [2/12] time 0.393 (1.012) data 0.000 (0.562) loss 2.0762 (1.9785) lr 9.5241e-02 eta 0:08:40
epoch [8/50] batch [4/12] time 0.398 (0.704) data 0.000 (0.281) loss 1.5264 (1.8130) lr 9.5241e-02 eta 0:06:00
epoch [8/50] batch [6/12] time 0.393 (0.600) data 0.000 (0.187) loss 1.7422 (1.8281) lr 9.5241e-02 eta 0:05:06
epoch [8/50] batch [8/12] time 0.393 (0.560) data 0.000 (0.141) loss 1.9844 (1.8397) lr 9.5241e-02 eta 0:04:44
epoch [8/50] batch [10/12] time 0.397 (0.527) data 0.000 (0.113) loss 1.7656 (1.8460) lr 9.5241e-02 eta 0:04:26
epoch [8/50] batch [12/12] time 0.393 (0.505) data 0.000 (0.094) loss 1.9561 (1.8559) lr 9.3815e-02 eta 0:04:14
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 535
* accuracy: 76.9%
* error: 23.1%
* macro_f1: 73.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [9/50] batch [2/12] time 0.409 (1.012) data 0.000 (0.520) loss 1.7510 (1.6685) lr 9.3815e-02 eta 0:08:27
epoch [9/50] batch [4/12] time 0.395 (0.704) data 0.000 (0.260) loss 1.7021 (1.7056) lr 9.3815e-02 eta 0:05:52
epoch [9/50] batch [6/12] time 0.397 (0.602) data 0.000 (0.173) loss 1.9531 (1.7601) lr 9.3815e-02 eta 0:04:59
epoch [9/50] batch [8/12] time 0.394 (0.550) data 0.000 (0.130) loss 1.8672 (1.7659) lr 9.3815e-02 eta 0:04:32
epoch [9/50] batch [10/12] time 0.394 (0.519) data 0.000 (0.104) loss 1.9678 (1.7949) lr 9.3815e-02 eta 0:04:16
epoch [9/50] batch [12/12] time 0.396 (0.498) data 0.000 (0.087) loss 1.9600 (1.8231) lr 9.2216e-02 eta 0:04:05
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 533
* accuracy: 76.6%
* error: 23.4%
* macro_f1: 72.3%

epoch [10/50] batch [2/12] time 0.394 (1.005) data 0.000 (0.527) loss 1.7676 (1.7871) lr 9.2216e-02 eta 0:08:12
epoch [10/50] batch [4/12] time 0.396 (0.700) data 0.000 (0.264) loss 1.7324 (1.8025) lr 9.2216e-02 eta 0:05:41
epoch [10/50] batch [6/12] time 0.394 (0.598) data 0.000 (0.176) loss 1.8545 (1.7882) lr 9.2216e-02 eta 0:04:50
epoch [10/50] batch [8/12] time 0.393 (0.547) data 0.000 (0.132) loss 1.8828 (1.7919) lr 9.2216e-02 eta 0:04:24
epoch [10/50] batch [10/12] time 0.396 (0.517) data 0.000 (0.106) loss 1.8486 (1.7997) lr 9.2216e-02 eta 0:04:09
epoch [10/50] batch [12/12] time 0.393 (0.496) data 0.000 (0.088) loss 2.1250 (1.8248) lr 9.0451e-02 eta 0:03:58
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 543
* accuracy: 78.0%
* error: 22.0%
* macro_f1: 74.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model.pth.tar-10

epoch [11/50] batch [2/12] time 0.398 (1.030) data 0.000 (0.622) loss 1.5977 (1.6748) lr 9.0451e-02 eta 0:08:12
epoch [11/50] batch [4/12] time 0.392 (0.711) data 0.000 (0.311) loss 1.6748 (1.7063) lr 9.0451e-02 eta 0:05:38
epoch [11/50] batch [6/12] time 0.393 (0.606) data 0.000 (0.208) loss 1.9795 (1.7816) lr 9.0451e-02 eta 0:04:47
epoch [11/50] batch [8/12] time 0.396 (0.553) data 0.000 (0.156) loss 1.9180 (1.8079) lr 9.0451e-02 eta 0:04:20
epoch [11/50] batch [10/12] time 0.392 (0.521) data 0.000 (0.125) loss 1.7910 (1.8052) lr 9.0451e-02 eta 0:04:04
epoch [11/50] batch [12/12] time 0.392 (0.500) data 0.000 (0.104) loss 1.7744 (1.8050) lr 8.8526e-02 eta 0:03:53
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 537
* accuracy: 77.2%
* error: 22.8%
* macro_f1: 73.4%

epoch [12/50] batch [2/12] time 0.401 (0.993) data 0.000 (0.512) loss 1.7920 (1.7441) lr 8.8526e-02 eta 0:07:42
epoch [12/50] batch [4/12] time 0.394 (0.693) data 0.000 (0.256) loss 1.5928 (1.7288) lr 8.8526e-02 eta 0:05:21
epoch [12/50] batch [6/12] time 0.397 (0.594) data 0.000 (0.171) loss 1.6553 (1.7576) lr 8.8526e-02 eta 0:04:34
epoch [12/50] batch [8/12] time 0.394 (0.544) data 0.000 (0.128) loss 1.9775 (1.7749) lr 8.8526e-02 eta 0:04:10
epoch [12/50] batch [10/12] time 0.394 (0.514) data 0.000 (0.103) loss 1.5811 (1.7548) lr 8.8526e-02 eta 0:03:55
epoch [12/50] batch [12/12] time 0.393 (0.494) data 0.000 (0.085) loss 2.0879 (1.7775) lr 8.6448e-02 eta 0:03:45
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 544
* accuracy: 78.2%
* error: 21.8%
* macro_f1: 74.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [13/50] batch [2/12] time 0.413 (0.985) data 0.000 (0.507) loss 1.9766 (1.9531) lr 8.6448e-02 eta 0:07:27
epoch [13/50] batch [4/12] time 0.397 (0.690) data 0.000 (0.254) loss 1.5996 (1.8386) lr 8.6448e-02 eta 0:05:11
epoch [13/50] batch [6/12] time 0.394 (0.592) data 0.000 (0.169) loss 1.8428 (1.8215) lr 8.6448e-02 eta 0:04:26
epoch [13/50] batch [8/12] time 0.394 (0.542) data 0.000 (0.127) loss 1.7070 (1.7809) lr 8.6448e-02 eta 0:04:02
epoch [13/50] batch [10/12] time 0.394 (0.513) data 0.000 (0.102) loss 1.6953 (1.7666) lr 8.6448e-02 eta 0:03:48
epoch [13/50] batch [12/12] time 0.394 (0.493) data 0.000 (0.085) loss 1.9033 (1.7668) lr 8.4227e-02 eta 0:03:38
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 547
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 74.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [14/50] batch [2/12] time 0.395 (1.047) data 0.000 (0.635) loss 1.7441 (1.7925) lr 8.4227e-02 eta 0:07:42
epoch [14/50] batch [4/12] time 0.396 (0.722) data 0.000 (0.318) loss 1.6621 (1.7188) lr 8.4227e-02 eta 0:05:17
epoch [14/50] batch [6/12] time 0.395 (0.613) data 0.000 (0.212) loss 1.8398 (1.7438) lr 8.4227e-02 eta 0:04:28
epoch [14/50] batch [8/12] time 0.395 (0.559) data 0.000 (0.159) loss 1.8252 (1.7567) lr 8.4227e-02 eta 0:04:03
epoch [14/50] batch [10/12] time 0.395 (0.526) data 0.000 (0.127) loss 1.6709 (1.7386) lr 8.4227e-02 eta 0:03:48
epoch [14/50] batch [12/12] time 0.395 (0.504) data 0.000 (0.106) loss 1.6309 (1.7379) lr 8.1871e-02 eta 0:03:37
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.55s/it] 50%|█████     | 2/4 [00:02<00:02,  1.20s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.31it/s]100%|██████████| 4/4 [00:03<00:00,  1.92it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 553
* accuracy: 79.5%
* error: 20.5%
* macro_f1: 76.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [15/50] batch [2/12] time 0.395 (1.020) data 0.000 (0.565) loss 1.7354 (1.7612) lr 8.1871e-02 eta 0:07:18
epoch [15/50] batch [4/12] time 0.393 (0.707) data 0.000 (0.283) loss 1.7646 (1.7727) lr 8.1871e-02 eta 0:05:02
epoch [15/50] batch [6/12] time 0.394 (0.603) data 0.000 (0.188) loss 1.6709 (1.7410) lr 8.1871e-02 eta 0:04:16
epoch [15/50] batch [8/12] time 0.400 (0.551) data 0.000 (0.141) loss 1.6855 (1.7483) lr 8.1871e-02 eta 0:03:53
epoch [15/50] batch [10/12] time 0.398 (0.520) data 0.000 (0.113) loss 1.7305 (1.7645) lr 8.1871e-02 eta 0:03:39
epoch [15/50] batch [12/12] time 0.394 (0.499) data 0.000 (0.094) loss 1.7676 (1.7538) lr 7.9389e-02 eta 0:03:29
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 563
* accuracy: 80.9%
* error: 19.1%
* macro_f1: 78.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [16/50] batch [2/12] time 0.394 (0.997) data 0.000 (0.522) loss 1.7168 (1.7534) lr 7.9389e-02 eta 0:06:56
epoch [16/50] batch [4/12] time 0.395 (0.697) data 0.000 (0.261) loss 1.8779 (1.7825) lr 7.9389e-02 eta 0:04:49
epoch [16/50] batch [6/12] time 0.394 (0.596) data 0.000 (0.174) loss 1.5830 (1.7074) lr 7.9389e-02 eta 0:04:06
epoch [16/50] batch [8/12] time 0.394 (0.545) data 0.000 (0.130) loss 1.7422 (1.7083) lr 7.9389e-02 eta 0:03:44
epoch [16/50] batch [10/12] time 0.394 (0.515) data 0.000 (0.104) loss 1.6484 (1.7057) lr 7.9389e-02 eta 0:03:31
epoch [16/50] batch [12/12] time 0.400 (0.496) data 0.000 (0.087) loss 1.8867 (1.7113) lr 7.6791e-02 eta 0:03:22
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 560
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 77.6%

epoch [17/50] batch [2/12] time 0.400 (1.022) data 0.000 (0.579) loss 1.6396 (1.7070) lr 7.6791e-02 eta 0:06:54
epoch [17/50] batch [4/12] time 0.393 (0.708) data 0.000 (0.290) loss 1.7021 (1.7288) lr 7.6791e-02 eta 0:04:46
epoch [17/50] batch [6/12] time 0.393 (0.603) data 0.000 (0.193) loss 1.7510 (1.7342) lr 7.6791e-02 eta 0:04:02
epoch [17/50] batch [8/12] time 0.392 (0.550) data 0.000 (0.145) loss 1.9678 (1.7771) lr 7.6791e-02 eta 0:03:40
epoch [17/50] batch [10/12] time 0.392 (0.519) data 0.000 (0.116) loss 1.4844 (1.7412) lr 7.6791e-02 eta 0:03:26
epoch [17/50] batch [12/12] time 0.479 (0.505) data 0.000 (0.097) loss 1.6133 (1.7355) lr 7.4088e-02 eta 0:03:19
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 576
* accuracy: 82.8%
* error: 17.2%
* macro_f1: 80.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [18/50] batch [2/12] time 0.401 (1.024) data 0.000 (0.555) loss 1.7090 (1.7559) lr 7.4088e-02 eta 0:06:43
epoch [18/50] batch [4/12] time 0.394 (0.709) data 0.000 (0.278) loss 1.5215 (1.6821) lr 7.4088e-02 eta 0:04:37
epoch [18/50] batch [6/12] time 0.396 (0.605) data 0.000 (0.185) loss 1.6826 (1.6761) lr 7.4088e-02 eta 0:03:55
epoch [18/50] batch [8/12] time 0.394 (0.552) data 0.000 (0.139) loss 1.5508 (1.6584) lr 7.4088e-02 eta 0:03:34
epoch [18/50] batch [10/12] time 0.395 (0.520) data 0.000 (0.111) loss 1.8027 (1.6880) lr 7.4088e-02 eta 0:03:20
epoch [18/50] batch [12/12] time 0.394 (0.499) data 0.000 (0.093) loss 1.6748 (1.6711) lr 7.1289e-02 eta 0:03:11
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 589
* accuracy: 84.6%
* error: 15.4%
* macro_f1: 81.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [19/50] batch [2/12] time 0.393 (1.023) data 0.000 (0.599) loss 1.6250 (1.7905) lr 7.1289e-02 eta 0:06:30
epoch [19/50] batch [4/12] time 0.392 (0.708) data 0.000 (0.299) loss 1.6641 (1.7451) lr 7.1289e-02 eta 0:04:28
epoch [19/50] batch [6/12] time 0.396 (0.603) data 0.000 (0.200) loss 1.5312 (1.7337) lr 7.1289e-02 eta 0:03:47
epoch [19/50] batch [8/12] time 0.392 (0.550) data 0.000 (0.150) loss 1.6367 (1.7045) lr 7.1289e-02 eta 0:03:26
epoch [19/50] batch [10/12] time 0.398 (0.519) data 0.000 (0.120) loss 1.7021 (1.6993) lr 7.1289e-02 eta 0:03:14
epoch [19/50] batch [12/12] time 0.392 (0.498) data 0.000 (0.100) loss 1.6104 (1.6855) lr 6.8406e-02 eta 0:03:05
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 588
* accuracy: 84.5%
* error: 15.5%
* macro_f1: 81.4%

epoch [20/50] batch [2/12] time 0.395 (1.027) data 0.000 (0.616) loss 1.6318 (1.7070) lr 6.8406e-02 eta 0:06:20
epoch [20/50] batch [4/12] time 0.393 (0.710) data 0.000 (0.308) loss 1.5010 (1.6499) lr 6.8406e-02 eta 0:04:21
epoch [20/50] batch [6/12] time 0.397 (0.606) data 0.000 (0.205) loss 1.7812 (1.6471) lr 6.8406e-02 eta 0:03:41
epoch [20/50] batch [8/12] time 0.400 (0.553) data 0.000 (0.154) loss 1.6885 (1.6389) lr 6.8406e-02 eta 0:03:21
epoch [20/50] batch [10/12] time 0.393 (0.521) data 0.000 (0.123) loss 1.6777 (1.6477) lr 6.8406e-02 eta 0:03:08
epoch [20/50] batch [12/12] time 0.394 (0.500) data 0.000 (0.103) loss 1.6875 (1.6629) lr 6.5451e-02 eta 0:03:00
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 603
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 84.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model.pth.tar-20

epoch [21/50] batch [2/12] time 0.395 (1.003) data 0.000 (0.560) loss 1.6768 (1.7231) lr 6.5451e-02 eta 0:05:59
epoch [21/50] batch [4/12] time 0.394 (0.699) data 0.000 (0.280) loss 1.6260 (1.6526) lr 6.5451e-02 eta 0:04:08
epoch [21/50] batch [6/12] time 0.394 (0.597) data 0.000 (0.187) loss 1.6367 (1.6587) lr 6.5451e-02 eta 0:03:31
epoch [21/50] batch [8/12] time 0.394 (0.546) data 0.000 (0.140) loss 1.7051 (1.6553) lr 6.5451e-02 eta 0:03:12
epoch [21/50] batch [10/12] time 0.394 (0.516) data 0.000 (0.112) loss 1.6982 (1.6694) lr 6.5451e-02 eta 0:03:00
epoch [21/50] batch [12/12] time 0.394 (0.496) data 0.000 (0.094) loss 1.5684 (1.6584) lr 6.2434e-02 eta 0:02:52
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.54s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 599
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 84.2%

epoch [22/50] batch [2/12] time 0.406 (0.991) data 0.000 (0.511) loss 1.5176 (1.6001) lr 6.2434e-02 eta 0:05:42
epoch [22/50] batch [4/12] time 0.394 (0.692) data 0.000 (0.256) loss 1.6699 (1.5967) lr 6.2434e-02 eta 0:03:58
epoch [22/50] batch [6/12] time 0.393 (0.592) data 0.000 (0.170) loss 1.6992 (1.6294) lr 6.2434e-02 eta 0:03:22
epoch [22/50] batch [8/12] time 0.396 (0.543) data 0.000 (0.128) loss 1.6650 (1.6270) lr 6.2434e-02 eta 0:03:04
epoch [22/50] batch [10/12] time 0.394 (0.513) data 0.000 (0.102) loss 1.5898 (1.6196) lr 6.2434e-02 eta 0:02:53
epoch [22/50] batch [12/12] time 0.393 (0.493) data 0.000 (0.085) loss 1.7080 (1.6368) lr 5.9369e-02 eta 0:02:45
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:08,  2.69s/it] 50%|█████     | 2/4 [00:02<00:02,  1.25s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.26it/s]100%|██████████| 4/4 [00:03<00:00,  1.86it/s]100%|██████████| 4/4 [00:03<00:00,  1.16it/s]=> result
* total: 696
* correct: 604
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 84.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [23/50] batch [2/12] time 0.395 (1.003) data 0.000 (0.517) loss 1.5127 (1.5581) lr 5.9369e-02 eta 0:05:34
epoch [23/50] batch [4/12] time 0.393 (0.697) data 0.000 (0.259) loss 1.8105 (1.6326) lr 5.9369e-02 eta 0:03:51
epoch [23/50] batch [6/12] time 0.392 (0.596) data 0.000 (0.172) loss 1.5889 (1.6309) lr 5.9369e-02 eta 0:03:16
epoch [23/50] batch [8/12] time 0.408 (0.547) data 0.000 (0.129) loss 1.6621 (1.6306) lr 5.9369e-02 eta 0:02:59
epoch [23/50] batch [10/12] time 0.394 (0.516) data 0.000 (0.104) loss 1.5654 (1.6100) lr 5.9369e-02 eta 0:02:48
epoch [23/50] batch [12/12] time 0.398 (0.496) data 0.000 (0.086) loss 1.7354 (1.6202) lr 5.6267e-02 eta 0:02:40
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 606
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 84.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [24/50] batch [2/12] time 0.395 (1.000) data 0.000 (0.524) loss 1.4941 (1.5688) lr 5.6267e-02 eta 0:05:21
epoch [24/50] batch [4/12] time 0.393 (0.696) data 0.000 (0.262) loss 1.5869 (1.5835) lr 5.6267e-02 eta 0:03:42
epoch [24/50] batch [6/12] time 0.393 (0.595) data 0.000 (0.175) loss 1.5713 (1.5604) lr 5.6267e-02 eta 0:03:09
epoch [24/50] batch [8/12] time 0.393 (0.544) data 0.000 (0.131) loss 1.7568 (1.5997) lr 5.6267e-02 eta 0:02:52
epoch [24/50] batch [10/12] time 0.393 (0.514) data 0.000 (0.105) loss 1.6367 (1.6103) lr 5.6267e-02 eta 0:02:41
epoch [24/50] batch [12/12] time 0.393 (0.494) data 0.000 (0.088) loss 1.5098 (1.5974) lr 5.3140e-02 eta 0:02:34
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 613
* accuracy: 88.1%
* error: 11.9%
* macro_f1: 85.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [25/50] batch [2/12] time 0.392 (1.011) data 0.000 (0.564) loss 1.4248 (1.5415) lr 5.3140e-02 eta 0:05:13
epoch [25/50] batch [4/12] time 0.399 (0.704) data 0.000 (0.282) loss 1.5625 (1.5896) lr 5.3140e-02 eta 0:03:36
epoch [25/50] batch [6/12] time 0.393 (0.601) data 0.000 (0.188) loss 1.6064 (1.6118) lr 5.3140e-02 eta 0:03:03
epoch [25/50] batch [8/12] time 0.393 (0.549) data 0.000 (0.141) loss 1.5127 (1.5891) lr 5.3140e-02 eta 0:02:46
epoch [25/50] batch [10/12] time 0.392 (0.517) data 0.000 (0.113) loss 1.4824 (1.5910) lr 5.3140e-02 eta 0:02:36
epoch [25/50] batch [12/12] time 0.392 (0.497) data 0.000 (0.094) loss 1.5762 (1.5823) lr 5.0000e-02 eta 0:02:28
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.54s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 614
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 85.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [26/50] batch [2/12] time 0.407 (1.057) data 0.000 (0.599) loss 1.6533 (1.5869) lr 5.0000e-02 eta 0:05:14
epoch [26/50] batch [4/12] time 0.399 (0.726) data 0.000 (0.299) loss 1.5400 (1.5688) lr 5.0000e-02 eta 0:03:34
epoch [26/50] batch [6/12] time 0.398 (0.617) data 0.000 (0.200) loss 1.5879 (1.5605) lr 5.0000e-02 eta 0:03:01
epoch [26/50] batch [8/12] time 0.395 (0.561) data 0.000 (0.150) loss 1.5361 (1.5507) lr 5.0000e-02 eta 0:02:43
epoch [26/50] batch [10/12] time 0.396 (0.527) data 0.000 (0.120) loss 1.5713 (1.5563) lr 5.0000e-02 eta 0:02:32
epoch [26/50] batch [12/12] time 0.393 (0.505) data 0.000 (0.100) loss 1.4619 (1.5444) lr 4.6860e-02 eta 0:02:25
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.54s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.31it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 615
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 86.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [27/50] batch [2/12] time 0.395 (1.026) data 0.000 (0.619) loss 1.4668 (1.4478) lr 4.6860e-02 eta 0:04:53
epoch [27/50] batch [4/12] time 0.394 (0.710) data 0.000 (0.310) loss 1.5898 (1.4929) lr 4.6860e-02 eta 0:03:21
epoch [27/50] batch [6/12] time 0.394 (0.605) data 0.000 (0.207) loss 1.5117 (1.5265) lr 4.6860e-02 eta 0:02:50
epoch [27/50] batch [8/12] time 0.480 (0.563) data 0.000 (0.155) loss 1.6367 (1.5573) lr 4.6860e-02 eta 0:02:37
epoch [27/50] batch [10/12] time 0.395 (0.529) data 0.000 (0.124) loss 1.5781 (1.5591) lr 4.6860e-02 eta 0:02:27
epoch [27/50] batch [12/12] time 0.395 (0.507) data 0.000 (0.103) loss 1.4346 (1.5436) lr 4.3733e-02 eta 0:02:20
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 621
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 87.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [28/50] batch [2/12] time 0.398 (1.037) data 0.000 (0.611) loss 1.6641 (1.6289) lr 4.3733e-02 eta 0:04:44
epoch [28/50] batch [4/12] time 0.393 (0.715) data 0.000 (0.305) loss 1.5664 (1.5979) lr 4.3733e-02 eta 0:03:14
epoch [28/50] batch [6/12] time 0.392 (0.607) data 0.000 (0.204) loss 1.5986 (1.5666) lr 4.3733e-02 eta 0:02:43
epoch [28/50] batch [8/12] time 0.395 (0.555) data 0.000 (0.153) loss 1.5127 (1.5681) lr 4.3733e-02 eta 0:02:28
epoch [28/50] batch [10/12] time 0.393 (0.522) data 0.000 (0.122) loss 1.6797 (1.5853) lr 4.3733e-02 eta 0:02:18
epoch [28/50] batch [12/12] time 0.405 (0.502) data 0.000 (0.102) loss 1.5918 (1.5920) lr 4.0631e-02 eta 0:02:12
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.55s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.31it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 630
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 88.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [29/50] batch [2/12] time 0.392 (1.033) data 0.000 (0.624) loss 1.4375 (1.5508) lr 4.0631e-02 eta 0:04:30
epoch [29/50] batch [4/12] time 0.393 (0.713) data 0.000 (0.312) loss 1.6182 (1.5657) lr 4.0631e-02 eta 0:03:05
epoch [29/50] batch [6/12] time 0.398 (0.607) data 0.000 (0.208) loss 1.6074 (1.5680) lr 4.0631e-02 eta 0:02:36
epoch [29/50] batch [8/12] time 0.393 (0.553) data 0.000 (0.156) loss 1.5723 (1.5757) lr 4.0631e-02 eta 0:02:21
epoch [29/50] batch [10/12] time 0.394 (0.521) data 0.000 (0.125) loss 1.5059 (1.5785) lr 4.0631e-02 eta 0:02:12
epoch [29/50] batch [12/12] time 0.393 (0.500) data 0.000 (0.104) loss 1.5527 (1.5632) lr 3.7566e-02 eta 0:02:05
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 628
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 87.6%

epoch [30/50] batch [2/12] time 0.394 (1.015) data 0.000 (0.575) loss 1.4648 (1.5396) lr 3.7566e-02 eta 0:04:13
epoch [30/50] batch [4/12] time 0.394 (0.705) data 0.000 (0.288) loss 1.5723 (1.5181) lr 3.7566e-02 eta 0:02:54
epoch [30/50] batch [6/12] time 0.399 (0.602) data 0.000 (0.192) loss 1.6064 (1.5215) lr 3.7566e-02 eta 0:02:28
epoch [30/50] batch [8/12] time 0.394 (0.550) data 0.000 (0.144) loss 1.5928 (1.5320) lr 3.7566e-02 eta 0:02:14
epoch [30/50] batch [10/12] time 0.399 (0.520) data 0.000 (0.115) loss 1.5469 (1.5260) lr 3.7566e-02 eta 0:02:05
epoch [30/50] batch [12/12] time 0.395 (0.499) data 0.000 (0.096) loss 1.5127 (1.5215) lr 3.4549e-02 eta 0:01:59
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 634
* accuracy: 91.1%
* error: 8.9%
* macro_f1: 88.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model.pth.tar-30

epoch [31/50] batch [2/12] time 0.394 (1.031) data 0.000 (0.621) loss 1.4502 (1.4536) lr 3.4549e-02 eta 0:04:05
epoch [31/50] batch [4/12] time 0.396 (0.713) data 0.000 (0.310) loss 1.5146 (1.4785) lr 3.4549e-02 eta 0:02:48
epoch [31/50] batch [6/12] time 0.392 (0.606) data 0.000 (0.207) loss 1.5859 (1.5119) lr 3.4549e-02 eta 0:02:21
epoch [31/50] batch [8/12] time 0.393 (0.552) data 0.000 (0.155) loss 1.5420 (1.5292) lr 3.4549e-02 eta 0:02:08
epoch [31/50] batch [10/12] time 0.393 (0.521) data 0.000 (0.124) loss 1.4346 (1.5190) lr 3.4549e-02 eta 0:01:59
epoch [31/50] batch [12/12] time 0.392 (0.500) data 0.000 (0.104) loss 1.6162 (1.5357) lr 3.1594e-02 eta 0:01:54
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 623
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 87.2%

epoch [32/50] batch [2/12] time 0.408 (1.024) data 0.000 (0.539) loss 1.5010 (1.6470) lr 3.1594e-02 eta 0:03:51
epoch [32/50] batch [4/12] time 0.392 (0.708) data 0.000 (0.269) loss 1.3848 (1.5959) lr 3.1594e-02 eta 0:02:38
epoch [32/50] batch [6/12] time 0.392 (0.603) data 0.000 (0.180) loss 1.4082 (1.5679) lr 3.1594e-02 eta 0:02:13
epoch [32/50] batch [8/12] time 0.393 (0.550) data 0.000 (0.135) loss 1.4629 (1.5414) lr 3.1594e-02 eta 0:02:01
epoch [32/50] batch [10/12] time 0.393 (0.519) data 0.000 (0.108) loss 1.4492 (1.5283) lr 3.1594e-02 eta 0:01:53
epoch [32/50] batch [12/12] time 0.392 (0.498) data 0.000 (0.090) loss 1.5371 (1.5209) lr 2.8711e-02 eta 0:01:47
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 628
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 88.0%

epoch [33/50] batch [2/12] time 0.400 (1.011) data 0.000 (0.540) loss 1.3916 (1.4727) lr 2.8711e-02 eta 0:03:36
epoch [33/50] batch [4/12] time 0.398 (0.704) data 0.000 (0.270) loss 1.5430 (1.5103) lr 2.8711e-02 eta 0:02:29
epoch [33/50] batch [6/12] time 0.394 (0.600) data 0.000 (0.180) loss 1.3613 (1.5059) lr 2.8711e-02 eta 0:02:06
epoch [33/50] batch [8/12] time 0.394 (0.549) data 0.000 (0.135) loss 1.6514 (1.5101) lr 2.8711e-02 eta 0:01:54
epoch [33/50] batch [10/12] time 0.394 (0.518) data 0.000 (0.108) loss 1.4600 (1.5175) lr 2.8711e-02 eta 0:01:46
epoch [33/50] batch [12/12] time 0.394 (0.498) data 0.000 (0.090) loss 1.5293 (1.5139) lr 2.5912e-02 eta 0:01:41
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 635
* accuracy: 91.2%
* error: 8.8%
* macro_f1: 89.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [34/50] batch [2/12] time 0.400 (1.036) data 0.000 (0.621) loss 1.3750 (1.4014) lr 2.5912e-02 eta 0:03:29
epoch [34/50] batch [4/12] time 0.393 (0.714) data 0.000 (0.311) loss 1.5723 (1.5056) lr 2.5912e-02 eta 0:02:22
epoch [34/50] batch [6/12] time 0.400 (0.608) data 0.000 (0.207) loss 1.3135 (1.4972) lr 2.5912e-02 eta 0:02:00
epoch [34/50] batch [8/12] time 0.392 (0.554) data 0.000 (0.155) loss 1.6562 (1.5229) lr 2.5912e-02 eta 0:01:48
epoch [34/50] batch [10/12] time 0.393 (0.522) data 0.000 (0.124) loss 1.4609 (1.5082) lr 2.5912e-02 eta 0:01:41
epoch [34/50] batch [12/12] time 0.393 (0.501) data 0.000 (0.104) loss 1.4678 (1.5030) lr 2.3209e-02 eta 0:01:36
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 633
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 88.5%

epoch [35/50] batch [2/12] time 0.415 (0.997) data 0.000 (0.516) loss 1.5879 (1.5190) lr 2.3209e-02 eta 0:03:09
epoch [35/50] batch [4/12] time 0.393 (0.695) data 0.000 (0.258) loss 1.3867 (1.4702) lr 2.3209e-02 eta 0:02:10
epoch [35/50] batch [6/12] time 0.394 (0.595) data 0.000 (0.172) loss 1.5049 (1.4987) lr 2.3209e-02 eta 0:01:50
epoch [35/50] batch [8/12] time 0.394 (0.545) data 0.000 (0.129) loss 1.3271 (1.4790) lr 2.3209e-02 eta 0:01:40
epoch [35/50] batch [10/12] time 0.397 (0.515) data 0.000 (0.103) loss 1.4033 (1.4862) lr 2.3209e-02 eta 0:01:33
epoch [35/50] batch [12/12] time 0.394 (0.495) data 0.000 (0.086) loss 1.4688 (1.4745) lr 2.0611e-02 eta 0:01:29
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 637
* accuracy: 91.5%
* error: 8.5%
* macro_f1: 89.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [36/50] batch [2/12] time 0.398 (1.006) data 0.000 (0.538) loss 1.4355 (1.4990) lr 2.0611e-02 eta 0:02:59
epoch [36/50] batch [4/12] time 0.393 (0.699) data 0.000 (0.269) loss 1.4268 (1.4790) lr 2.0611e-02 eta 0:02:03
epoch [36/50] batch [6/12] time 0.392 (0.597) data 0.000 (0.179) loss 1.4180 (1.4811) lr 2.0611e-02 eta 0:01:43
epoch [36/50] batch [8/12] time 0.393 (0.546) data 0.000 (0.134) loss 1.5107 (1.4863) lr 2.0611e-02 eta 0:01:33
epoch [36/50] batch [10/12] time 0.399 (0.516) data 0.000 (0.108) loss 1.4248 (1.4688) lr 2.0611e-02 eta 0:01:27
epoch [36/50] batch [12/12] time 0.398 (0.497) data 0.000 (0.090) loss 1.4795 (1.4701) lr 1.8129e-02 eta 0:01:23
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 641
* accuracy: 92.1%
* error: 7.9%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [37/50] batch [2/12] time 0.394 (1.067) data 0.000 (0.589) loss 1.5771 (1.5264) lr 1.8129e-02 eta 0:02:57
epoch [37/50] batch [4/12] time 0.403 (0.733) data 0.000 (0.294) loss 1.3994 (1.4771) lr 1.8129e-02 eta 0:02:00
epoch [37/50] batch [6/12] time 0.393 (0.620) data 0.000 (0.196) loss 1.4609 (1.4622) lr 1.8129e-02 eta 0:01:40
epoch [37/50] batch [8/12] time 0.393 (0.563) data 0.000 (0.147) loss 1.3926 (1.4724) lr 1.8129e-02 eta 0:01:30
epoch [37/50] batch [10/12] time 0.394 (0.529) data 0.000 (0.118) loss 1.5781 (1.4840) lr 1.8129e-02 eta 0:01:23
epoch [37/50] batch [12/12] time 0.394 (0.506) data 0.000 (0.098) loss 1.6406 (1.4976) lr 1.5773e-02 eta 0:01:19
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 636
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 89.5%

epoch [38/50] batch [2/12] time 0.428 (1.006) data 0.000 (0.509) loss 1.5176 (1.4717) lr 1.5773e-02 eta 0:02:34
epoch [38/50] batch [4/12] time 0.392 (0.699) data 0.000 (0.255) loss 1.4932 (1.5149) lr 1.5773e-02 eta 0:01:46
epoch [38/50] batch [6/12] time 0.392 (0.597) data 0.000 (0.170) loss 1.3662 (1.4850) lr 1.5773e-02 eta 0:01:29
epoch [38/50] batch [8/12] time 0.397 (0.546) data 0.000 (0.127) loss 1.6328 (1.4982) lr 1.5773e-02 eta 0:01:20
epoch [38/50] batch [10/12] time 0.392 (0.515) data 0.000 (0.102) loss 1.4268 (1.4878) lr 1.5773e-02 eta 0:01:15
epoch [38/50] batch [12/12] time 0.393 (0.495) data 0.000 (0.085) loss 1.5322 (1.4989) lr 1.3552e-02 eta 0:01:11
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 639
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 89.9%

epoch [39/50] batch [2/12] time 0.393 (1.021) data 0.000 (0.586) loss 1.6025 (1.5645) lr 1.3552e-02 eta 0:02:25
epoch [39/50] batch [4/12] time 0.392 (0.707) data 0.000 (0.293) loss 1.4971 (1.5227) lr 1.3552e-02 eta 0:01:38
epoch [39/50] batch [6/12] time 0.392 (0.602) data 0.000 (0.195) loss 1.4189 (1.5120) lr 1.3552e-02 eta 0:01:23
epoch [39/50] batch [8/12] time 0.392 (0.550) data 0.000 (0.147) loss 1.2930 (1.4779) lr 1.3552e-02 eta 0:01:14
epoch [39/50] batch [10/12] time 0.392 (0.518) data 0.000 (0.117) loss 1.6094 (1.5050) lr 1.3552e-02 eta 0:01:09
epoch [39/50] batch [12/12] time 0.398 (0.498) data 0.000 (0.098) loss 1.3145 (1.4809) lr 1.1474e-02 eta 0:01:05
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 644
* accuracy: 92.5%
* error: 7.5%
* macro_f1: 90.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [40/50] batch [2/12] time 0.398 (1.000) data 0.000 (0.530) loss 1.5273 (1.4990) lr 1.1474e-02 eta 0:02:10
epoch [40/50] batch [4/12] time 0.394 (0.698) data 0.000 (0.265) loss 1.4707 (1.5005) lr 1.1474e-02 eta 0:01:29
epoch [40/50] batch [6/12] time 0.394 (0.597) data 0.000 (0.177) loss 1.4453 (1.4868) lr 1.1474e-02 eta 0:01:15
epoch [40/50] batch [8/12] time 0.394 (0.546) data 0.000 (0.133) loss 1.5469 (1.4915) lr 1.1474e-02 eta 0:01:07
epoch [40/50] batch [10/12] time 0.394 (0.516) data 0.000 (0.106) loss 1.4717 (1.4908) lr 1.1474e-02 eta 0:01:02
epoch [40/50] batch [12/12] time 0.394 (0.496) data 0.000 (0.088) loss 1.4287 (1.4874) lr 9.5492e-03 eta 0:00:59
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 643
* accuracy: 92.4%
* error: 7.6%
* macro_f1: 90.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model.pth.tar-40

epoch [41/50] batch [2/12] time 0.394 (1.028) data 0.000 (0.611) loss 1.5547 (1.5234) lr 9.5492e-03 eta 0:02:01
epoch [41/50] batch [4/12] time 0.392 (0.711) data 0.000 (0.306) loss 1.3164 (1.4734) lr 9.5492e-03 eta 0:01:22
epoch [41/50] batch [6/12] time 0.393 (0.605) data 0.000 (0.204) loss 1.5000 (1.4788) lr 9.5492e-03 eta 0:01:08
epoch [41/50] batch [8/12] time 0.392 (0.552) data 0.000 (0.153) loss 1.3428 (1.4650) lr 9.5492e-03 eta 0:01:01
epoch [41/50] batch [10/12] time 0.394 (0.520) data 0.000 (0.122) loss 1.5889 (1.4599) lr 9.5492e-03 eta 0:00:57
epoch [41/50] batch [12/12] time 0.399 (0.500) data 0.000 (0.102) loss 1.5127 (1.4682) lr 7.7836e-03 eta 0:00:53
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 644
* accuracy: 92.5%
* error: 7.5%
* macro_f1: 90.7%

epoch [42/50] batch [2/12] time 0.394 (1.032) data 0.000 (0.629) loss 1.5947 (1.4854) lr 7.7836e-03 eta 0:01:49
epoch [42/50] batch [4/12] time 0.395 (0.713) data 0.000 (0.315) loss 1.3984 (1.4683) lr 7.7836e-03 eta 0:01:14
epoch [42/50] batch [6/12] time 0.399 (0.608) data 0.000 (0.210) loss 1.4541 (1.4816) lr 7.7836e-03 eta 0:01:01
epoch [42/50] batch [8/12] time 0.395 (0.555) data 0.000 (0.157) loss 1.3916 (1.4640) lr 7.7836e-03 eta 0:00:55
epoch [42/50] batch [10/12] time 0.397 (0.523) data 0.000 (0.126) loss 1.5381 (1.4628) lr 7.7836e-03 eta 0:00:51
epoch [42/50] batch [12/12] time 0.394 (0.501) data 0.000 (0.105) loss 1.4951 (1.4743) lr 6.1847e-03 eta 0:00:48
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 645
* accuracy: 92.7%
* error: 7.3%
* macro_f1: 90.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [43/50] batch [2/12] time 0.402 (1.012) data 0.000 (0.550) loss 1.5029 (1.5049) lr 6.1847e-03 eta 0:01:35
epoch [43/50] batch [4/12] time 0.393 (0.703) data 0.000 (0.275) loss 1.4502 (1.4766) lr 6.1847e-03 eta 0:01:04
epoch [43/50] batch [6/12] time 0.401 (0.602) data 0.000 (0.184) loss 1.4639 (1.4587) lr 6.1847e-03 eta 0:00:54
epoch [43/50] batch [8/12] time 0.394 (0.550) data 0.000 (0.138) loss 1.2939 (1.4457) lr 6.1847e-03 eta 0:00:48
epoch [43/50] batch [10/12] time 0.400 (0.520) data 0.000 (0.110) loss 1.3301 (1.4521) lr 6.1847e-03 eta 0:00:44
epoch [43/50] batch [12/12] time 0.400 (0.499) data 0.000 (0.092) loss 1.5889 (1.4711) lr 4.7586e-03 eta 0:00:41
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 644
* accuracy: 92.5%
* error: 7.5%
* macro_f1: 90.6%

epoch [44/50] batch [2/12] time 0.397 (1.007) data 0.000 (0.533) loss 1.4229 (1.4731) lr 4.7586e-03 eta 0:01:22
epoch [44/50] batch [4/12] time 0.397 (0.701) data 0.000 (0.267) loss 1.3945 (1.4250) lr 4.7586e-03 eta 0:00:56
epoch [44/50] batch [6/12] time 0.394 (0.599) data 0.000 (0.178) loss 1.5068 (1.4478) lr 4.7586e-03 eta 0:00:46
epoch [44/50] batch [8/12] time 0.400 (0.548) data 0.000 (0.133) loss 1.4668 (1.4758) lr 4.7586e-03 eta 0:00:41
epoch [44/50] batch [10/12] time 0.396 (0.518) data 0.000 (0.107) loss 1.4473 (1.4618) lr 4.7586e-03 eta 0:00:38
epoch [44/50] batch [12/12] time 0.397 (0.497) data 0.000 (0.089) loss 1.4971 (1.4637) lr 3.5112e-03 eta 0:00:35
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 646
* accuracy: 92.8%
* error: 7.2%
* macro_f1: 90.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [45/50] batch [2/12] time 0.397 (1.019) data 0.000 (0.578) loss 1.3945 (1.4331) lr 3.5112e-03 eta 0:01:11
epoch [45/50] batch [4/12] time 0.397 (0.708) data 0.000 (0.289) loss 1.4736 (1.5085) lr 3.5112e-03 eta 0:00:48
epoch [45/50] batch [6/12] time 0.393 (0.603) data 0.000 (0.193) loss 1.4668 (1.5068) lr 3.5112e-03 eta 0:00:39
epoch [45/50] batch [8/12] time 0.397 (0.552) data 0.000 (0.145) loss 1.4561 (1.4913) lr 3.5112e-03 eta 0:00:35
epoch [45/50] batch [10/12] time 0.393 (0.520) data 0.000 (0.116) loss 1.3740 (1.4669) lr 3.5112e-03 eta 0:00:32
epoch [45/50] batch [12/12] time 0.394 (0.499) data 0.000 (0.096) loss 1.4023 (1.4489) lr 2.4472e-03 eta 0:00:29
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 647
* accuracy: 93.0%
* error: 7.0%
* macro_f1: 91.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [46/50] batch [2/12] time 0.403 (1.100) data 0.000 (0.596) loss 1.3633 (1.4370) lr 2.4472e-03 eta 0:01:03
epoch [46/50] batch [4/12] time 0.394 (0.747) data 0.000 (0.298) loss 1.4043 (1.4307) lr 2.4472e-03 eta 0:00:41
epoch [46/50] batch [6/12] time 0.395 (0.631) data 0.000 (0.199) loss 1.4229 (1.4305) lr 2.4472e-03 eta 0:00:34
epoch [46/50] batch [8/12] time 0.396 (0.572) data 0.000 (0.149) loss 1.6152 (1.4545) lr 2.4472e-03 eta 0:00:29
epoch [46/50] batch [10/12] time 0.395 (0.536) data 0.000 (0.119) loss 1.3857 (1.4501) lr 2.4472e-03 eta 0:00:26
epoch [46/50] batch [12/12] time 0.394 (0.513) data 0.000 (0.099) loss 1.4648 (1.4453) lr 1.5708e-03 eta 0:00:24
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.55s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.31it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 647
* accuracy: 93.0%
* error: 7.0%
* macro_f1: 91.1%

epoch [47/50] batch [2/12] time 0.395 (0.988) data 0.000 (0.503) loss 1.4766 (1.5581) lr 1.5708e-03 eta 0:00:45
epoch [47/50] batch [4/12] time 0.394 (0.691) data 0.000 (0.251) loss 1.5098 (1.5161) lr 1.5708e-03 eta 0:00:30
epoch [47/50] batch [6/12] time 0.393 (0.592) data 0.000 (0.168) loss 1.4561 (1.5078) lr 1.5708e-03 eta 0:00:24
epoch [47/50] batch [8/12] time 0.398 (0.543) data 0.000 (0.126) loss 1.5068 (1.5013) lr 1.5708e-03 eta 0:00:21
epoch [47/50] batch [10/12] time 0.394 (0.514) data 0.000 (0.101) loss 1.4932 (1.4849) lr 1.5708e-03 eta 0:00:19
epoch [47/50] batch [12/12] time 0.394 (0.494) data 0.000 (0.084) loss 1.4736 (1.4849) lr 8.8564e-04 eta 0:00:17
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.45s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 647
* accuracy: 93.0%
* error: 7.0%
* macro_f1: 91.1%

epoch [48/50] batch [2/12] time 0.399 (1.023) data 0.000 (0.563) loss 1.4180 (1.4263) lr 8.8564e-04 eta 0:00:34
epoch [48/50] batch [4/12] time 0.397 (0.710) data 0.000 (0.281) loss 1.4111 (1.4011) lr 8.8564e-04 eta 0:00:22
epoch [48/50] batch [6/12] time 0.397 (0.606) data 0.000 (0.188) loss 1.3486 (1.4315) lr 8.8564e-04 eta 0:00:18
epoch [48/50] batch [8/12] time 0.396 (0.553) data 0.000 (0.141) loss 1.6016 (1.4597) lr 8.8564e-04 eta 0:00:15
epoch [48/50] batch [10/12] time 0.399 (0.522) data 0.000 (0.113) loss 1.4170 (1.4492) lr 8.8564e-04 eta 0:00:13
epoch [48/50] batch [12/12] time 0.393 (0.501) data 0.000 (0.094) loss 1.4180 (1.4408) lr 3.9426e-04 eta 0:00:12
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.46s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 647
* accuracy: 93.0%
* error: 7.0%
* macro_f1: 91.1%

epoch [49/50] batch [2/12] time 0.394 (1.014) data 0.000 (0.561) loss 1.5566 (1.5049) lr 3.9426e-04 eta 0:00:22
epoch [49/50] batch [4/12] time 0.397 (0.705) data 0.000 (0.280) loss 1.4717 (1.4807) lr 3.9426e-04 eta 0:00:14
epoch [49/50] batch [6/12] time 0.394 (0.601) data 0.000 (0.187) loss 1.4814 (1.4785) lr 3.9426e-04 eta 0:00:10
epoch [49/50] batch [8/12] time 0.393 (0.549) data 0.000 (0.140) loss 1.3330 (1.4614) lr 3.9426e-04 eta 0:00:08
epoch [49/50] batch [10/12] time 0.393 (0.518) data 0.000 (0.112) loss 1.3711 (1.4475) lr 3.9426e-04 eta 0:00:07
epoch [49/50] batch [12/12] time 0.393 (0.497) data 0.000 (0.094) loss 1.5371 (1.4553) lr 9.8664e-05 eta 0:00:05
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 647
* accuracy: 93.0%
* error: 7.0%
* macro_f1: 91.1%

epoch [50/50] batch [2/12] time 0.393 (1.029) data 0.000 (0.596) loss 1.4072 (1.4648) lr 9.8664e-05 eta 0:00:10
epoch [50/50] batch [4/12] time 0.392 (0.711) data 0.000 (0.298) loss 1.4414 (1.4360) lr 9.8664e-05 eta 0:00:05
epoch [50/50] batch [6/12] time 0.395 (0.606) data 0.000 (0.199) loss 1.6104 (1.4888) lr 9.8664e-05 eta 0:00:03
epoch [50/50] batch [8/12] time 0.392 (0.553) data 0.000 (0.149) loss 1.4541 (1.4784) lr 9.8664e-05 eta 0:00:02
epoch [50/50] batch [10/12] time 0.392 (0.521) data 0.000 (0.119) loss 1.4814 (1.4856) lr 9.8664e-05 eta 0:00:01
epoch [50/50] batch [12/12] time 0.393 (0.499) data 0.000 (0.100) loss 1.4971 (1.4744) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]
=> result
* total: 696
* correct: 647
* accuracy: 93.0%
* error: 7.0%
* macro_f1: 91.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model.pth.tar-50
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar" (epoch = 45)
Evaluate on the *test* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:03<00:18,  3.70s/it] 33%|███▎      | 2/6 [00:03<00:06,  1.67s/it] 50%|█████     | 3/6 [00:04<00:03,  1.02s/it] 67%|██████▋   | 4/6 [00:04<00:01,  1.40it/s] 83%|████████▎ | 5/6 [00:04<00:00,  1.83it/s]100%|██████████| 6/6 [00:04<00:00,  2.52it/s]100%|██████████| 6/6 [00:04<00:00,  1.23it/s]
=> result
* total: 1,053
* correct: 1,004
* accuracy: 95.3%
* error: 4.7%
* macro_f1: 95.1%
Elapsed: 0:07:59
+ sh scripts/rpo_prime/base2new_test.sh oxford_flowers 1 0 main_tmp1 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
816 937 1410
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      937
# test     1,410
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar" (epoch = 45)
Evaluate on the *test* set
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:05<00:40,  5.79s/it] 25%|██▌       | 2/8 [00:06<00:15,  2.53s/it] 38%|███▊      | 3/8 [00:06<00:07,  1.49s/it] 50%|█████     | 4/8 [00:06<00:03,  1.00it/s] 62%|██████▎   | 5/8 [00:06<00:02,  1.38it/s] 75%|███████▌  | 6/8 [00:07<00:01,  1.78it/s] 88%|████████▊ | 7/8 [00:07<00:00,  2.19it/s]100%|██████████| 8/8 [00:07<00:00,  1.08it/s]
=> result
* total: 1,410
* correct: 1,065
* accuracy: 75.5%
* error: 24.5%
* macro_f1: 70.8%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train.sh oxford_flowers 2 0 main_tmp1 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
816 696 1053
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      696
# test     1,053
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/50] batch [2/12] time 0.394 (2.017) data 0.000 (0.881) loss 2.5625 (2.7314) lr 1.0000e-01 eta 0:20:06
epoch [1/50] batch [4/12] time 0.394 (1.207) data 0.000 (0.441) loss 2.3633 (2.5298) lr 1.0000e-01 eta 0:11:59
epoch [1/50] batch [6/12] time 0.400 (0.938) data 0.000 (0.294) loss 2.2578 (2.4655) lr 1.0000e-01 eta 0:09:17
epoch [1/50] batch [8/12] time 0.393 (0.802) data 0.000 (0.220) loss 2.2168 (2.4390) lr 1.0000e-01 eta 0:07:54
epoch [1/50] batch [10/12] time 0.400 (0.721) data 0.000 (0.176) loss 2.2266 (2.4094) lr 1.0000e-01 eta 0:07:05
epoch [1/50] batch [12/12] time 0.393 (0.666) data 0.000 (0.147) loss 1.9746 (2.3835) lr 9.9901e-02 eta 0:06:31
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.65s/it] 50%|█████     | 2/4 [00:02<00:02,  1.24s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.28it/s]100%|██████████| 4/4 [00:03<00:00,  1.88it/s]100%|██████████| 4/4 [00:03<00:00,  1.18it/s]=> result
* total: 696
* correct: 502
* accuracy: 72.1%
* error: 27.9%
* macro_f1: 65.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [2/50] batch [2/12] time 0.396 (1.052) data 0.000 (0.643) loss 2.0723 (2.0220) lr 9.9901e-02 eta 0:10:16
epoch [2/50] batch [4/12] time 0.392 (0.722) data 0.000 (0.321) loss 2.2578 (2.0498) lr 9.9901e-02 eta 0:07:01
epoch [2/50] batch [6/12] time 0.397 (0.613) data 0.000 (0.214) loss 2.1387 (2.0602) lr 9.9901e-02 eta 0:05:56
epoch [2/50] batch [8/12] time 0.393 (0.558) data 0.000 (0.161) loss 2.1230 (2.0842) lr 9.9901e-02 eta 0:05:23
epoch [2/50] batch [10/12] time 0.392 (0.526) data 0.000 (0.129) loss 2.0020 (2.0583) lr 9.9901e-02 eta 0:05:03
epoch [2/50] batch [12/12] time 0.392 (0.504) data 0.000 (0.107) loss 2.0879 (2.0655) lr 9.9606e-02 eta 0:04:50
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 496
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 65.0%

epoch [3/50] batch [2/12] time 0.397 (1.032) data 0.000 (0.625) loss 2.1055 (1.9429) lr 9.9606e-02 eta 0:09:52
epoch [3/50] batch [4/12] time 0.393 (0.712) data 0.000 (0.312) loss 1.8760 (1.9087) lr 9.9606e-02 eta 0:06:47
epoch [3/50] batch [6/12] time 0.394 (0.606) data 0.000 (0.208) loss 2.0879 (1.9172) lr 9.9606e-02 eta 0:05:45
epoch [3/50] batch [8/12] time 0.393 (0.553) data 0.000 (0.156) loss 1.8164 (1.9584) lr 9.9606e-02 eta 0:05:14
epoch [3/50] batch [10/12] time 0.397 (0.522) data 0.000 (0.125) loss 2.1113 (2.0108) lr 9.9606e-02 eta 0:04:55
epoch [3/50] batch [12/12] time 0.393 (0.500) data 0.000 (0.104) loss 1.9111 (1.9906) lr 9.9114e-02 eta 0:04:42
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 508
* accuracy: 73.0%
* error: 27.0%
* macro_f1: 67.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [4/50] batch [2/12] time 0.395 (1.012) data 0.000 (0.534) loss 2.1309 (2.1455) lr 9.9114e-02 eta 0:09:28
epoch [4/50] batch [4/12] time 0.395 (0.703) data 0.000 (0.267) loss 2.2598 (2.1145) lr 9.9114e-02 eta 0:06:33
epoch [4/50] batch [6/12] time 0.395 (0.601) data 0.000 (0.178) loss 2.0410 (2.0337) lr 9.9114e-02 eta 0:05:35
epoch [4/50] batch [8/12] time 0.396 (0.550) data 0.000 (0.134) loss 2.0801 (2.0414) lr 9.9114e-02 eta 0:05:05
epoch [4/50] batch [10/12] time 0.394 (0.519) data 0.000 (0.107) loss 1.7832 (1.9960) lr 9.9114e-02 eta 0:04:47
epoch [4/50] batch [12/12] time 0.395 (0.499) data 0.000 (0.089) loss 2.0684 (1.9855) lr 9.8429e-02 eta 0:04:35
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 507
* accuracy: 72.8%
* error: 27.2%
* macro_f1: 66.9%

epoch [5/50] batch [2/12] time 0.397 (1.019) data 0.000 (0.551) loss 1.8887 (1.7900) lr 9.8429e-02 eta 0:09:20
epoch [5/50] batch [4/12] time 0.399 (0.708) data 0.000 (0.276) loss 1.9053 (1.9041) lr 9.8429e-02 eta 0:06:27
epoch [5/50] batch [6/12] time 0.393 (0.603) data 0.000 (0.184) loss 1.9482 (1.9414) lr 9.8429e-02 eta 0:05:29
epoch [5/50] batch [8/12] time 0.393 (0.550) data 0.000 (0.138) loss 1.8467 (1.9191) lr 9.8429e-02 eta 0:04:59
epoch [5/50] batch [10/12] time 0.393 (0.519) data 0.000 (0.110) loss 1.9209 (1.9281) lr 9.8429e-02 eta 0:04:41
epoch [5/50] batch [12/12] time 0.393 (0.498) data 0.000 (0.092) loss 1.8574 (1.9167) lr 9.7553e-02 eta 0:04:29
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 515
* accuracy: 74.0%
* error: 26.0%
* macro_f1: 68.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [6/50] batch [2/12] time 0.396 (1.037) data 0.000 (0.626) loss 1.9775 (1.9443) lr 9.7553e-02 eta 0:09:17
epoch [6/50] batch [4/12] time 0.400 (0.718) data 0.000 (0.313) loss 1.8662 (1.8799) lr 9.7553e-02 eta 0:06:24
epoch [6/50] batch [6/12] time 0.393 (0.610) data 0.000 (0.209) loss 1.9756 (1.9422) lr 9.7553e-02 eta 0:05:25
epoch [6/50] batch [8/12] time 0.400 (0.558) data 0.000 (0.157) loss 2.1094 (1.9713) lr 9.7553e-02 eta 0:04:56
epoch [6/50] batch [10/12] time 0.394 (0.525) data 0.000 (0.125) loss 1.8174 (1.9695) lr 9.7553e-02 eta 0:04:38
epoch [6/50] batch [12/12] time 0.394 (0.503) data 0.000 (0.104) loss 1.9072 (1.9597) lr 9.6489e-02 eta 0:04:25
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 511
* accuracy: 73.4%
* error: 26.6%
* macro_f1: 67.6%

epoch [7/50] batch [2/12] time 0.399 (1.056) data 0.000 (0.641) loss 2.0117 (1.8965) lr 9.6489e-02 eta 0:09:15
epoch [7/50] batch [4/12] time 0.393 (0.749) data 0.000 (0.321) loss 2.0859 (2.0127) lr 9.6489e-02 eta 0:06:32
epoch [7/50] batch [6/12] time 0.397 (0.631) data 0.000 (0.214) loss 1.7852 (1.9313) lr 9.6489e-02 eta 0:05:29
epoch [7/50] batch [8/12] time 0.400 (0.573) data 0.000 (0.160) loss 2.0293 (1.9403) lr 9.6489e-02 eta 0:04:57
epoch [7/50] batch [10/12] time 0.394 (0.537) data 0.000 (0.128) loss 1.8604 (1.9330) lr 9.6489e-02 eta 0:04:38
epoch [7/50] batch [12/12] time 0.397 (0.513) data 0.000 (0.107) loss 1.7666 (1.9227) lr 9.5241e-02 eta 0:04:24
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 520
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 69.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [8/50] batch [2/12] time 0.396 (1.032) data 0.000 (0.625) loss 1.8848 (1.8193) lr 9.5241e-02 eta 0:08:50
epoch [8/50] batch [4/12] time 0.399 (0.714) data 0.000 (0.312) loss 1.8545 (1.8481) lr 9.5241e-02 eta 0:06:05
epoch [8/50] batch [6/12] time 0.395 (0.608) data 0.000 (0.208) loss 1.8555 (1.8475) lr 9.5241e-02 eta 0:05:09
epoch [8/50] batch [8/12] time 0.394 (0.554) data 0.000 (0.156) loss 1.7793 (1.8446) lr 9.5241e-02 eta 0:04:41
epoch [8/50] batch [10/12] time 0.400 (0.523) data 0.000 (0.125) loss 2.0371 (1.8614) lr 9.5241e-02 eta 0:04:24
epoch [8/50] batch [12/12] time 0.395 (0.502) data 0.000 (0.104) loss 1.7412 (1.8568) lr 9.3815e-02 eta 0:04:12
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 525
* accuracy: 75.4%
* error: 24.6%
* macro_f1: 71.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [9/50] batch [2/12] time 0.396 (1.065) data 0.000 (0.658) loss 1.8984 (1.9658) lr 9.3815e-02 eta 0:08:54
epoch [9/50] batch [4/12] time 0.393 (0.729) data 0.000 (0.329) loss 1.8359 (1.8967) lr 9.3815e-02 eta 0:06:04
epoch [9/50] batch [6/12] time 0.393 (0.617) data 0.000 (0.219) loss 1.7539 (1.8817) lr 9.3815e-02 eta 0:05:07
epoch [9/50] batch [8/12] time 0.394 (0.561) data 0.000 (0.165) loss 1.8535 (1.8468) lr 9.3815e-02 eta 0:04:38
epoch [9/50] batch [10/12] time 0.394 (0.528) data 0.000 (0.132) loss 1.9990 (1.8697) lr 9.3815e-02 eta 0:04:20
epoch [9/50] batch [12/12] time 0.397 (0.506) data 0.000 (0.110) loss 1.5518 (1.8416) lr 9.2216e-02 eta 0:04:08
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 529
* accuracy: 76.0%
* error: 24.0%
* macro_f1: 71.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [10/50] batch [2/12] time 0.396 (1.006) data 0.000 (0.548) loss 1.9043 (1.8452) lr 9.2216e-02 eta 0:08:13
epoch [10/50] batch [4/12] time 0.394 (0.700) data 0.000 (0.274) loss 1.9580 (1.8955) lr 9.2216e-02 eta 0:05:41
epoch [10/50] batch [6/12] time 0.394 (0.598) data 0.000 (0.183) loss 1.8711 (1.8717) lr 9.2216e-02 eta 0:04:50
epoch [10/50] batch [8/12] time 0.396 (0.548) data 0.000 (0.137) loss 1.6299 (1.8324) lr 9.2216e-02 eta 0:04:25
epoch [10/50] batch [10/12] time 0.396 (0.517) data 0.000 (0.110) loss 2.1387 (1.8615) lr 9.2216e-02 eta 0:04:09
epoch [10/50] batch [12/12] time 0.394 (0.497) data 0.000 (0.092) loss 1.7881 (1.8460) lr 9.0451e-02 eta 0:03:58
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 528
* accuracy: 75.9%
* error: 24.1%
* macro_f1: 71.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model.pth.tar-10

epoch [11/50] batch [2/12] time 0.396 (1.044) data 0.000 (0.635) loss 1.7285 (1.7769) lr 9.0451e-02 eta 0:08:18
epoch [11/50] batch [4/12] time 0.394 (0.719) data 0.000 (0.318) loss 1.8750 (1.7593) lr 9.0451e-02 eta 0:05:42
epoch [11/50] batch [6/12] time 0.394 (0.611) data 0.000 (0.212) loss 1.9600 (1.8075) lr 9.0451e-02 eta 0:04:49
epoch [11/50] batch [8/12] time 0.394 (0.557) data 0.000 (0.159) loss 1.7021 (1.8082) lr 9.0451e-02 eta 0:04:22
epoch [11/50] batch [10/12] time 0.394 (0.525) data 0.000 (0.127) loss 1.7285 (1.7830) lr 9.0451e-02 eta 0:04:06
epoch [11/50] batch [12/12] time 0.396 (0.504) data 0.000 (0.106) loss 1.6924 (1.7813) lr 8.8526e-02 eta 0:03:55
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.54s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.31it/s]100%|██████████| 4/4 [00:03<00:00,  1.92it/s]100%|██████████| 4/4 [00:03<00:00,  1.20it/s]=> result
* total: 696
* correct: 540
* accuracy: 77.6%
* error: 22.4%
* macro_f1: 73.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [12/50] batch [2/12] time 0.395 (1.022) data 0.000 (0.615) loss 1.9326 (1.9673) lr 8.8526e-02 eta 0:07:56
epoch [12/50] batch [4/12] time 0.394 (0.708) data 0.000 (0.307) loss 1.7578 (1.8574) lr 8.8526e-02 eta 0:05:28
epoch [12/50] batch [6/12] time 0.397 (0.604) data 0.000 (0.205) loss 1.9619 (1.8190) lr 8.8526e-02 eta 0:04:39
epoch [12/50] batch [8/12] time 0.393 (0.551) data 0.000 (0.154) loss 2.0098 (1.8203) lr 8.8526e-02 eta 0:04:13
epoch [12/50] batch [10/12] time 0.395 (0.520) data 0.000 (0.123) loss 1.7490 (1.7989) lr 8.8526e-02 eta 0:03:58
epoch [12/50] batch [12/12] time 0.399 (0.500) data 0.000 (0.103) loss 1.7832 (1.8006) lr 8.6448e-02 eta 0:03:47
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 539
* accuracy: 77.4%
* error: 22.6%
* macro_f1: 74.3%

epoch [13/50] batch [2/12] time 0.395 (1.057) data 0.000 (0.632) loss 1.5791 (1.7173) lr 8.6448e-02 eta 0:07:59
epoch [13/50] batch [4/12] time 0.395 (0.726) data 0.000 (0.316) loss 1.7295 (1.7849) lr 8.6448e-02 eta 0:05:28
epoch [13/50] batch [6/12] time 0.400 (0.616) data 0.000 (0.211) loss 1.7402 (1.7905) lr 8.6448e-02 eta 0:04:37
epoch [13/50] batch [8/12] time 0.395 (0.561) data 0.000 (0.158) loss 1.7217 (1.8037) lr 8.6448e-02 eta 0:04:11
epoch [13/50] batch [10/12] time 0.394 (0.528) data 0.000 (0.127) loss 1.6182 (1.7841) lr 8.6448e-02 eta 0:03:55
epoch [13/50] batch [12/12] time 0.394 (0.505) data 0.000 (0.106) loss 1.6543 (1.7795) lr 8.4227e-02 eta 0:03:44
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 551
* accuracy: 79.2%
* error: 20.8%
* macro_f1: 75.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [14/50] batch [2/12] time 0.395 (1.025) data 0.000 (0.582) loss 1.8975 (1.8750) lr 8.4227e-02 eta 0:07:33
epoch [14/50] batch [4/12] time 0.395 (0.711) data 0.000 (0.291) loss 1.6426 (1.7820) lr 8.4227e-02 eta 0:05:13
epoch [14/50] batch [6/12] time 0.395 (0.606) data 0.000 (0.194) loss 1.7422 (1.7458) lr 8.4227e-02 eta 0:04:25
epoch [14/50] batch [8/12] time 0.397 (0.553) data 0.000 (0.146) loss 1.6904 (1.7124) lr 8.4227e-02 eta 0:04:01
epoch [14/50] batch [10/12] time 0.395 (0.522) data 0.000 (0.116) loss 1.6475 (1.7174) lr 8.4227e-02 eta 0:03:46
epoch [14/50] batch [12/12] time 0.395 (0.500) data 0.000 (0.097) loss 1.5996 (1.7031) lr 8.1871e-02 eta 0:03:36
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 552
* accuracy: 79.3%
* error: 20.7%
* macro_f1: 76.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [15/50] batch [2/12] time 0.395 (1.021) data 0.000 (0.603) loss 1.8223 (1.7524) lr 8.1871e-02 eta 0:07:18
epoch [15/50] batch [4/12] time 0.393 (0.707) data 0.000 (0.302) loss 1.7988 (1.7153) lr 8.1871e-02 eta 0:05:02
epoch [15/50] batch [6/12] time 0.394 (0.603) data 0.000 (0.201) loss 1.8135 (1.7183) lr 8.1871e-02 eta 0:04:16
epoch [15/50] batch [8/12] time 0.394 (0.551) data 0.000 (0.151) loss 1.6191 (1.7147) lr 8.1871e-02 eta 0:03:53
epoch [15/50] batch [10/12] time 0.394 (0.519) data 0.000 (0.121) loss 1.8418 (1.7255) lr 8.1871e-02 eta 0:03:39
epoch [15/50] batch [12/12] time 0.394 (0.498) data 0.000 (0.101) loss 1.5723 (1.7121) lr 7.9389e-02 eta 0:03:29
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 560
* accuracy: 80.5%
* error: 19.5%
* macro_f1: 77.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [16/50] batch [2/12] time 0.404 (1.057) data 0.000 (0.612) loss 1.7852 (1.6982) lr 7.9389e-02 eta 0:07:21
epoch [16/50] batch [4/12] time 0.394 (0.726) data 0.000 (0.306) loss 1.6777 (1.7319) lr 7.9389e-02 eta 0:05:01
epoch [16/50] batch [6/12] time 0.394 (0.615) data 0.000 (0.204) loss 1.6592 (1.7391) lr 7.9389e-02 eta 0:04:14
epoch [16/50] batch [8/12] time 0.397 (0.560) data 0.000 (0.153) loss 1.7646 (1.7388) lr 7.9389e-02 eta 0:03:50
epoch [16/50] batch [10/12] time 0.394 (0.527) data 0.000 (0.123) loss 1.7686 (1.7280) lr 7.9389e-02 eta 0:03:36
epoch [16/50] batch [12/12] time 0.484 (0.512) data 0.000 (0.102) loss 1.6191 (1.7241) lr 7.6791e-02 eta 0:03:29
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 571
* accuracy: 82.0%
* error: 18.0%
* macro_f1: 79.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [17/50] batch [2/12] time 0.395 (1.027) data 0.000 (0.612) loss 1.6514 (1.6392) lr 7.6791e-02 eta 0:06:56
epoch [17/50] batch [4/12] time 0.398 (0.712) data 0.000 (0.306) loss 1.6484 (1.6370) lr 7.6791e-02 eta 0:04:47
epoch [17/50] batch [6/12] time 0.395 (0.606) data 0.000 (0.204) loss 1.5635 (1.6436) lr 7.6791e-02 eta 0:04:03
epoch [17/50] batch [8/12] time 0.393 (0.553) data 0.000 (0.153) loss 1.5850 (1.6688) lr 7.6791e-02 eta 0:03:41
epoch [17/50] batch [10/12] time 0.395 (0.521) data 0.000 (0.123) loss 1.5342 (1.6535) lr 7.6791e-02 eta 0:03:27
epoch [17/50] batch [12/12] time 0.398 (0.501) data 0.000 (0.102) loss 1.7744 (1.6712) lr 7.4088e-02 eta 0:03:18
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 583
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 81.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [18/50] batch [2/12] time 0.396 (1.029) data 0.000 (0.621) loss 1.5693 (1.5767) lr 7.4088e-02 eta 0:06:45
epoch [18/50] batch [4/12] time 0.394 (0.712) data 0.000 (0.310) loss 1.6230 (1.5874) lr 7.4088e-02 eta 0:04:39
epoch [18/50] batch [6/12] time 0.394 (0.606) data 0.000 (0.207) loss 1.5918 (1.6022) lr 7.4088e-02 eta 0:03:56
epoch [18/50] batch [8/12] time 0.395 (0.553) data 0.000 (0.155) loss 1.5742 (1.6201) lr 7.4088e-02 eta 0:03:34
epoch [18/50] batch [10/12] time 0.394 (0.521) data 0.000 (0.124) loss 1.7666 (1.6484) lr 7.4088e-02 eta 0:03:21
epoch [18/50] batch [12/12] time 0.394 (0.500) data 0.000 (0.104) loss 1.6807 (1.6594) lr 7.1289e-02 eta 0:03:12
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 583
* accuracy: 83.8%
* error: 16.2%
* macro_f1: 82.0%

epoch [19/50] batch [2/12] time 0.395 (1.012) data 0.000 (0.598) loss 1.6221 (1.5459) lr 7.1289e-02 eta 0:06:26
epoch [19/50] batch [4/12] time 0.392 (0.703) data 0.000 (0.299) loss 1.4326 (1.5308) lr 7.1289e-02 eta 0:04:27
epoch [19/50] batch [6/12] time 0.398 (0.601) data 0.000 (0.199) loss 1.5869 (1.6165) lr 7.1289e-02 eta 0:03:47
epoch [19/50] batch [8/12] time 0.394 (0.549) data 0.000 (0.150) loss 1.6592 (1.6306) lr 7.1289e-02 eta 0:03:26
epoch [19/50] batch [10/12] time 0.398 (0.518) data 0.000 (0.120) loss 1.7754 (1.6546) lr 7.1289e-02 eta 0:03:13
epoch [19/50] batch [12/12] time 0.393 (0.497) data 0.000 (0.100) loss 1.8711 (1.6890) lr 6.8406e-02 eta 0:03:04
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.56s/it] 50%|█████     | 2/4 [00:02<00:02,  1.21s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.30it/s]100%|██████████| 4/4 [00:03<00:00,  1.91it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 586
* accuracy: 84.2%
* error: 15.8%
* macro_f1: 82.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [20/50] batch [2/12] time 0.393 (1.001) data 0.000 (0.569) loss 1.6553 (1.6172) lr 6.8406e-02 eta 0:06:10
epoch [20/50] batch [4/12] time 0.393 (0.697) data 0.000 (0.285) loss 1.6865 (1.6355) lr 6.8406e-02 eta 0:04:16
epoch [20/50] batch [6/12] time 0.396 (0.597) data 0.000 (0.190) loss 1.7285 (1.6470) lr 6.8406e-02 eta 0:03:38
epoch [20/50] batch [8/12] time 0.393 (0.546) data 0.000 (0.142) loss 1.6992 (1.6510) lr 6.8406e-02 eta 0:03:18
epoch [20/50] batch [10/12] time 0.394 (0.515) data 0.000 (0.114) loss 1.7334 (1.6502) lr 6.8406e-02 eta 0:03:06
epoch [20/50] batch [12/12] time 0.394 (0.495) data 0.000 (0.095) loss 1.5879 (1.6395) lr 6.5451e-02 eta 0:02:58
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 606
* accuracy: 87.1%
* error: 12.9%
* macro_f1: 85.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model.pth.tar-20

epoch [21/50] batch [2/12] time 0.394 (1.036) data 0.000 (0.623) loss 1.5430 (1.6768) lr 6.5451e-02 eta 0:06:10
epoch [21/50] batch [4/12] time 0.394 (0.715) data 0.000 (0.312) loss 1.6797 (1.6741) lr 6.5451e-02 eta 0:04:14
epoch [21/50] batch [6/12] time 0.396 (0.609) data 0.000 (0.208) loss 1.7324 (1.6603) lr 6.5451e-02 eta 0:03:35
epoch [21/50] batch [8/12] time 0.394 (0.555) data 0.000 (0.156) loss 1.6191 (1.6364) lr 6.5451e-02 eta 0:03:15
epoch [21/50] batch [10/12] time 0.395 (0.523) data 0.000 (0.125) loss 1.6543 (1.6354) lr 6.5451e-02 eta 0:03:03
epoch [21/50] batch [12/12] time 0.398 (0.502) data 0.000 (0.104) loss 1.6982 (1.6479) lr 6.2434e-02 eta 0:02:54
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 592
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 82.7%

epoch [22/50] batch [2/12] time 0.394 (1.011) data 0.000 (0.568) loss 1.4541 (1.5674) lr 6.2434e-02 eta 0:05:49
epoch [22/50] batch [4/12] time 0.403 (0.705) data 0.000 (0.284) loss 1.6582 (1.6128) lr 6.2434e-02 eta 0:04:02
epoch [22/50] batch [6/12] time 0.394 (0.601) data 0.000 (0.189) loss 1.4834 (1.5827) lr 6.2434e-02 eta 0:03:25
epoch [22/50] batch [8/12] time 0.394 (0.549) data 0.000 (0.142) loss 1.3643 (1.5581) lr 6.2434e-02 eta 0:03:06
epoch [22/50] batch [10/12] time 0.394 (0.518) data 0.000 (0.114) loss 1.7080 (1.6100) lr 6.2434e-02 eta 0:02:55
epoch [22/50] batch [12/12] time 0.394 (0.498) data 0.000 (0.095) loss 1.8125 (1.6354) lr 5.9369e-02 eta 0:02:47
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 610
* accuracy: 87.6%
* error: 12.4%
* macro_f1: 85.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [23/50] batch [2/12] time 0.393 (1.032) data 0.000 (0.624) loss 1.5410 (1.5435) lr 5.9369e-02 eta 0:05:44
epoch [23/50] batch [4/12] time 0.392 (0.712) data 0.000 (0.312) loss 1.6533 (1.5774) lr 5.9369e-02 eta 0:03:56
epoch [23/50] batch [6/12] time 0.393 (0.607) data 0.000 (0.208) loss 1.8232 (1.6447) lr 5.9369e-02 eta 0:03:20
epoch [23/50] batch [8/12] time 0.399 (0.554) data 0.000 (0.156) loss 1.5918 (1.6287) lr 5.9369e-02 eta 0:03:01
epoch [23/50] batch [10/12] time 0.393 (0.522) data 0.000 (0.125) loss 1.5527 (1.6210) lr 5.9369e-02 eta 0:02:50
epoch [23/50] batch [12/12] time 0.392 (0.500) data 0.000 (0.104) loss 1.5166 (1.5970) lr 5.6267e-02 eta 0:02:42
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 620
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 87.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [24/50] batch [2/12] time 0.394 (1.028) data 0.000 (0.625) loss 1.5264 (1.5659) lr 5.6267e-02 eta 0:05:30
epoch [24/50] batch [4/12] time 0.393 (0.710) data 0.000 (0.313) loss 1.5898 (1.5725) lr 5.6267e-02 eta 0:03:47
epoch [24/50] batch [6/12] time 0.397 (0.605) data 0.000 (0.208) loss 1.3408 (1.5666) lr 5.6267e-02 eta 0:03:12
epoch [24/50] batch [8/12] time 0.392 (0.552) data 0.000 (0.156) loss 1.7178 (1.5940) lr 5.6267e-02 eta 0:02:54
epoch [24/50] batch [10/12] time 0.393 (0.520) data 0.000 (0.125) loss 1.7969 (1.6277) lr 5.6267e-02 eta 0:02:43
epoch [24/50] batch [12/12] time 0.395 (0.499) data 0.000 (0.104) loss 1.5488 (1.6188) lr 5.3140e-02 eta 0:02:35
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 603
* accuracy: 86.6%
* error: 13.4%
* macro_f1: 84.6%

epoch [25/50] batch [2/12] time 0.480 (1.090) data 0.000 (0.631) loss 1.8145 (1.7241) lr 5.3140e-02 eta 0:05:37
epoch [25/50] batch [4/12] time 0.392 (0.742) data 0.000 (0.316) loss 1.4990 (1.7087) lr 5.3140e-02 eta 0:03:48
epoch [25/50] batch [6/12] time 0.392 (0.626) data 0.000 (0.210) loss 1.6299 (1.6759) lr 5.3140e-02 eta 0:03:11
epoch [25/50] batch [8/12] time 0.393 (0.568) data 0.000 (0.158) loss 1.7598 (1.6862) lr 5.3140e-02 eta 0:02:52
epoch [25/50] batch [10/12] time 0.393 (0.533) data 0.000 (0.126) loss 1.4053 (1.6375) lr 5.3140e-02 eta 0:02:40
epoch [25/50] batch [12/12] time 0.393 (0.510) data 0.000 (0.105) loss 1.7080 (1.6288) lr 5.0000e-02 eta 0:02:32
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 616
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 86.1%

epoch [26/50] batch [2/12] time 0.393 (0.994) data 0.000 (0.513) loss 1.6045 (1.6333) lr 5.0000e-02 eta 0:04:56
epoch [26/50] batch [4/12] time 0.392 (0.693) data 0.000 (0.257) loss 1.5117 (1.5981) lr 5.0000e-02 eta 0:03:25
epoch [26/50] batch [6/12] time 0.393 (0.593) data 0.000 (0.171) loss 1.6104 (1.6025) lr 5.0000e-02 eta 0:02:54
epoch [26/50] batch [8/12] time 0.393 (0.543) data 0.000 (0.128) loss 1.7188 (1.6342) lr 5.0000e-02 eta 0:02:38
epoch [26/50] batch [10/12] time 0.393 (0.513) data 0.000 (0.103) loss 1.6328 (1.6350) lr 5.0000e-02 eta 0:02:28
epoch [26/50] batch [12/12] time 0.393 (0.493) data 0.000 (0.086) loss 1.4277 (1.5958) lr 4.6860e-02 eta 0:02:21
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 614
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 85.8%

epoch [27/50] batch [2/12] time 0.393 (1.015) data 0.000 (0.565) loss 1.5439 (1.4956) lr 4.6860e-02 eta 0:04:50
epoch [27/50] batch [4/12] time 0.394 (0.704) data 0.000 (0.283) loss 1.6504 (1.5388) lr 4.6860e-02 eta 0:03:19
epoch [27/50] batch [6/12] time 0.393 (0.601) data 0.000 (0.189) loss 1.5967 (1.5439) lr 4.6860e-02 eta 0:02:49
epoch [27/50] batch [8/12] time 0.394 (0.549) data 0.000 (0.141) loss 1.6807 (1.5525) lr 4.6860e-02 eta 0:02:33
epoch [27/50] batch [10/12] time 0.393 (0.518) data 0.000 (0.113) loss 1.5547 (1.5599) lr 4.6860e-02 eta 0:02:23
epoch [27/50] batch [12/12] time 0.393 (0.497) data 0.000 (0.094) loss 1.6064 (1.5752) lr 4.3733e-02 eta 0:02:17
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 625
* accuracy: 89.8%
* error: 10.2%
* macro_f1: 87.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [28/50] batch [2/12] time 0.393 (1.020) data 0.000 (0.617) loss 1.4863 (1.5635) lr 4.3733e-02 eta 0:04:39
epoch [28/50] batch [4/12] time 0.403 (0.709) data 0.000 (0.309) loss 1.6064 (1.5981) lr 4.3733e-02 eta 0:03:12
epoch [28/50] batch [6/12] time 0.393 (0.604) data 0.000 (0.206) loss 1.4512 (1.5938) lr 4.3733e-02 eta 0:02:43
epoch [28/50] batch [8/12] time 0.393 (0.551) data 0.000 (0.154) loss 1.6123 (1.5752) lr 4.3733e-02 eta 0:02:27
epoch [28/50] batch [10/12] time 0.393 (0.520) data 0.000 (0.124) loss 1.4746 (1.5648) lr 4.3733e-02 eta 0:02:18
epoch [28/50] batch [12/12] time 0.400 (0.499) data 0.000 (0.103) loss 1.4961 (1.5559) lr 4.0631e-02 eta 0:02:11
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 614
* accuracy: 88.2%
* error: 11.8%
* macro_f1: 86.2%

epoch [29/50] batch [2/12] time 0.395 (1.023) data 0.000 (0.608) loss 1.6562 (1.6748) lr 4.0631e-02 eta 0:04:28
epoch [29/50] batch [4/12] time 0.395 (0.709) data 0.000 (0.304) loss 1.5742 (1.6128) lr 4.0631e-02 eta 0:03:04
epoch [29/50] batch [6/12] time 0.394 (0.604) data 0.000 (0.203) loss 1.6484 (1.6030) lr 4.0631e-02 eta 0:02:35
epoch [29/50] batch [8/12] time 0.399 (0.552) data 0.000 (0.152) loss 1.4893 (1.5876) lr 4.0631e-02 eta 0:02:21
epoch [29/50] batch [10/12] time 0.397 (0.521) data 0.000 (0.122) loss 1.4873 (1.5668) lr 4.0631e-02 eta 0:02:12
epoch [29/50] batch [12/12] time 0.394 (0.500) data 0.000 (0.101) loss 1.5273 (1.5481) lr 3.7566e-02 eta 0:02:05
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 623
* accuracy: 89.5%
* error: 10.5%
* macro_f1: 87.5%

epoch [30/50] batch [2/12] time 0.393 (1.052) data 0.000 (0.647) loss 1.6553 (1.5483) lr 3.7566e-02 eta 0:04:22
epoch [30/50] batch [4/12] time 0.393 (0.723) data 0.000 (0.324) loss 1.5312 (1.5681) lr 3.7566e-02 eta 0:02:59
epoch [30/50] batch [6/12] time 0.394 (0.613) data 0.000 (0.216) loss 1.6387 (1.5721) lr 3.7566e-02 eta 0:02:30
epoch [30/50] batch [8/12] time 0.394 (0.558) data 0.000 (0.162) loss 1.5625 (1.5439) lr 3.7566e-02 eta 0:02:16
epoch [30/50] batch [10/12] time 0.394 (0.525) data 0.000 (0.130) loss 1.7305 (1.5504) lr 3.7566e-02 eta 0:02:07
epoch [30/50] batch [12/12] time 0.394 (0.503) data 0.000 (0.108) loss 1.6514 (1.5557) lr 3.4549e-02 eta 0:02:00
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 628
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 88.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model.pth.tar-30

epoch [31/50] batch [2/12] time 0.394 (1.008) data 0.000 (0.554) loss 1.4561 (1.5215) lr 3.4549e-02 eta 0:03:59
epoch [31/50] batch [4/12] time 0.397 (0.702) data 0.000 (0.277) loss 1.5469 (1.5251) lr 3.4549e-02 eta 0:02:45
epoch [31/50] batch [6/12] time 0.395 (0.599) data 0.000 (0.185) loss 1.3994 (1.5008) lr 3.4549e-02 eta 0:02:20
epoch [31/50] batch [8/12] time 0.395 (0.548) data 0.000 (0.139) loss 1.6982 (1.5293) lr 3.4549e-02 eta 0:02:07
epoch [31/50] batch [10/12] time 0.393 (0.517) data 0.000 (0.111) loss 1.4229 (1.5228) lr 3.4549e-02 eta 0:01:58
epoch [31/50] batch [12/12] time 0.393 (0.496) data 0.000 (0.092) loss 1.5889 (1.5341) lr 3.1594e-02 eta 0:01:53
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 631
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 88.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [32/50] batch [2/12] time 0.407 (1.011) data 0.000 (0.530) loss 1.5264 (1.5947) lr 3.1594e-02 eta 0:03:48
epoch [32/50] batch [4/12] time 0.394 (0.702) data 0.000 (0.265) loss 1.5869 (1.5679) lr 3.1594e-02 eta 0:02:37
epoch [32/50] batch [6/12] time 0.398 (0.600) data 0.000 (0.177) loss 1.8213 (1.5915) lr 3.1594e-02 eta 0:02:13
epoch [32/50] batch [8/12] time 0.395 (0.549) data 0.000 (0.133) loss 1.6104 (1.6150) lr 3.1594e-02 eta 0:02:00
epoch [32/50] batch [10/12] time 0.395 (0.518) data 0.000 (0.106) loss 1.4014 (1.5857) lr 3.1594e-02 eta 0:01:52
epoch [32/50] batch [12/12] time 0.409 (0.499) data 0.000 (0.088) loss 1.4062 (1.5527) lr 2.8711e-02 eta 0:01:47
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 640
* accuracy: 92.0%
* error: 8.0%
* macro_f1: 90.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [33/50] batch [2/12] time 0.396 (1.009) data 0.000 (0.549) loss 1.4531 (1.4326) lr 2.8711e-02 eta 0:03:35
epoch [33/50] batch [4/12] time 0.393 (0.701) data 0.000 (0.275) loss 1.6377 (1.5220) lr 2.8711e-02 eta 0:02:28
epoch [33/50] batch [6/12] time 0.394 (0.599) data 0.000 (0.183) loss 1.5176 (1.5291) lr 2.8711e-02 eta 0:02:05
epoch [33/50] batch [8/12] time 0.394 (0.547) data 0.000 (0.137) loss 1.3916 (1.5031) lr 2.8711e-02 eta 0:01:53
epoch [33/50] batch [10/12] time 0.397 (0.518) data 0.000 (0.110) loss 1.6865 (1.5183) lr 2.8711e-02 eta 0:01:46
epoch [33/50] batch [12/12] time 0.394 (0.497) data 0.000 (0.092) loss 1.5273 (1.5137) lr 2.5912e-02 eta 0:01:41
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 638
* accuracy: 91.7%
* error: 8.3%
* macro_f1: 89.4%

epoch [34/50] batch [2/12] time 0.397 (1.009) data 0.000 (0.554) loss 1.4609 (1.4751) lr 2.5912e-02 eta 0:03:23
epoch [34/50] batch [4/12] time 0.393 (0.701) data 0.000 (0.277) loss 1.4424 (1.4929) lr 2.5912e-02 eta 0:02:20
epoch [34/50] batch [6/12] time 0.392 (0.598) data 0.000 (0.185) loss 1.5518 (1.5042) lr 2.5912e-02 eta 0:01:58
epoch [34/50] batch [8/12] time 0.399 (0.549) data 0.000 (0.139) loss 1.5088 (1.5043) lr 2.5912e-02 eta 0:01:47
epoch [34/50] batch [10/12] time 0.394 (0.518) data 0.000 (0.111) loss 1.4453 (1.4971) lr 2.5912e-02 eta 0:01:40
epoch [34/50] batch [12/12] time 0.393 (0.497) data 0.000 (0.092) loss 1.5312 (1.5006) lr 2.3209e-02 eta 0:01:35
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 636
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 89.4%

epoch [35/50] batch [2/12] time 0.394 (1.012) data 0.000 (0.572) loss 1.5166 (1.4839) lr 2.3209e-02 eta 0:03:12
epoch [35/50] batch [4/12] time 0.479 (0.724) data 0.000 (0.286) loss 1.5576 (1.4880) lr 2.3209e-02 eta 0:02:16
epoch [35/50] batch [6/12] time 0.394 (0.614) data 0.000 (0.191) loss 1.3975 (1.4621) lr 2.3209e-02 eta 0:01:54
epoch [35/50] batch [8/12] time 0.394 (0.559) data 0.000 (0.143) loss 1.5078 (1.4760) lr 2.3209e-02 eta 0:01:42
epoch [35/50] batch [10/12] time 0.395 (0.526) data 0.000 (0.115) loss 1.5977 (1.4913) lr 2.3209e-02 eta 0:01:35
epoch [35/50] batch [12/12] time 0.394 (0.504) data 0.000 (0.096) loss 1.5010 (1.4801) lr 2.0611e-02 eta 0:01:30
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 636
* accuracy: 91.4%
* error: 8.6%
* macro_f1: 89.2%

epoch [36/50] batch [2/12] time 0.394 (1.025) data 0.000 (0.608) loss 1.4922 (1.4829) lr 2.0611e-02 eta 0:03:02
epoch [36/50] batch [4/12] time 0.393 (0.709) data 0.000 (0.304) loss 1.4385 (1.4631) lr 2.0611e-02 eta 0:02:04
epoch [36/50] batch [6/12] time 0.397 (0.605) data 0.000 (0.203) loss 1.5029 (1.4948) lr 2.0611e-02 eta 0:01:45
epoch [36/50] batch [8/12] time 0.394 (0.552) data 0.000 (0.152) loss 1.5918 (1.4899) lr 2.0611e-02 eta 0:01:34
epoch [36/50] batch [10/12] time 0.393 (0.520) data 0.000 (0.122) loss 1.5693 (1.5026) lr 2.0611e-02 eta 0:01:28
epoch [36/50] batch [12/12] time 0.393 (0.500) data 0.000 (0.101) loss 1.4951 (1.4924) lr 1.8129e-02 eta 0:01:23
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 640
* accuracy: 92.0%
* error: 8.0%
* macro_f1: 90.0%

epoch [37/50] batch [2/12] time 0.401 (1.011) data 0.000 (0.525) loss 1.4502 (1.4453) lr 1.8129e-02 eta 0:02:47
epoch [37/50] batch [4/12] time 0.393 (0.702) data 0.000 (0.263) loss 1.6270 (1.4841) lr 1.8129e-02 eta 0:01:55
epoch [37/50] batch [6/12] time 0.394 (0.599) data 0.000 (0.175) loss 1.3975 (1.4590) lr 1.8129e-02 eta 0:01:37
epoch [37/50] batch [8/12] time 0.393 (0.548) data 0.000 (0.131) loss 1.5342 (1.4609) lr 1.8129e-02 eta 0:01:27
epoch [37/50] batch [10/12] time 0.393 (0.517) data 0.000 (0.105) loss 1.4199 (1.4451) lr 1.8129e-02 eta 0:01:21
epoch [37/50] batch [12/12] time 0.395 (0.496) data 0.000 (0.088) loss 1.4736 (1.4560) lr 1.5773e-02 eta 0:01:17
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 639
* accuracy: 91.8%
* error: 8.2%
* macro_f1: 90.3%

epoch [38/50] batch [2/12] time 0.404 (1.008) data 0.000 (0.531) loss 1.4863 (1.4844) lr 1.5773e-02 eta 0:02:35
epoch [38/50] batch [4/12] time 0.393 (0.701) data 0.000 (0.266) loss 1.5264 (1.4805) lr 1.5773e-02 eta 0:01:46
epoch [38/50] batch [6/12] time 0.396 (0.599) data 0.000 (0.177) loss 1.3066 (1.4391) lr 1.5773e-02 eta 0:01:29
epoch [38/50] batch [8/12] time 0.394 (0.548) data 0.000 (0.133) loss 1.4463 (1.4465) lr 1.5773e-02 eta 0:01:21
epoch [38/50] batch [10/12] time 0.397 (0.518) data 0.000 (0.106) loss 1.4912 (1.4531) lr 1.5773e-02 eta 0:01:15
epoch [38/50] batch [12/12] time 0.395 (0.497) data 0.000 (0.089) loss 1.4121 (1.4498) lr 1.3552e-02 eta 0:01:11
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 647
* accuracy: 93.0%
* error: 7.0%
* macro_f1: 90.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [39/50] batch [2/12] time 0.393 (1.016) data 0.000 (0.593) loss 1.4551 (1.4795) lr 1.3552e-02 eta 0:02:24
epoch [39/50] batch [4/12] time 0.392 (0.705) data 0.000 (0.297) loss 1.6543 (1.5115) lr 1.3552e-02 eta 0:01:38
epoch [39/50] batch [6/12] time 0.397 (0.602) data 0.000 (0.198) loss 1.4492 (1.4946) lr 1.3552e-02 eta 0:01:23
epoch [39/50] batch [8/12] time 0.393 (0.550) data 0.000 (0.148) loss 1.4551 (1.4873) lr 1.3552e-02 eta 0:01:14
epoch [39/50] batch [10/12] time 0.393 (0.519) data 0.000 (0.119) loss 1.5449 (1.4784) lr 1.3552e-02 eta 0:01:09
epoch [39/50] batch [12/12] time 0.394 (0.498) data 0.000 (0.099) loss 1.3730 (1.4755) lr 1.1474e-02 eta 0:01:05
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 646
* accuracy: 92.8%
* error: 7.2%
* macro_f1: 90.7%

epoch [40/50] batch [2/12] time 0.408 (0.994) data 0.000 (0.505) loss 1.6455 (1.6069) lr 1.1474e-02 eta 0:02:09
epoch [40/50] batch [4/12] time 0.400 (0.695) data 0.000 (0.253) loss 1.5615 (1.5632) lr 1.1474e-02 eta 0:01:28
epoch [40/50] batch [6/12] time 0.393 (0.595) data 0.000 (0.169) loss 1.4043 (1.5236) lr 1.1474e-02 eta 0:01:14
epoch [40/50] batch [8/12] time 0.394 (0.545) data 0.000 (0.126) loss 1.4834 (1.5214) lr 1.1474e-02 eta 0:01:07
epoch [40/50] batch [10/12] time 0.396 (0.515) data 0.000 (0.101) loss 1.4512 (1.5139) lr 1.1474e-02 eta 0:01:02
epoch [40/50] batch [12/12] time 0.394 (0.495) data 0.000 (0.084) loss 1.4316 (1.4996) lr 9.5492e-03 eta 0:00:59
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 650
* accuracy: 93.4%
* error: 6.6%
* macro_f1: 91.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model.pth.tar-40

epoch [41/50] batch [2/12] time 0.393 (0.998) data 0.000 (0.529) loss 1.3340 (1.3320) lr 9.5492e-03 eta 0:01:57
epoch [41/50] batch [4/12] time 0.393 (0.695) data 0.000 (0.264) loss 1.3633 (1.3652) lr 9.5492e-03 eta 0:01:20
epoch [41/50] batch [6/12] time 0.392 (0.595) data 0.000 (0.176) loss 1.4648 (1.4007) lr 9.5492e-03 eta 0:01:07
epoch [41/50] batch [8/12] time 0.399 (0.545) data 0.000 (0.132) loss 1.4209 (1.4030) lr 9.5492e-03 eta 0:01:01
epoch [41/50] batch [10/12] time 0.394 (0.515) data 0.000 (0.106) loss 1.4775 (1.4076) lr 9.5492e-03 eta 0:00:56
epoch [41/50] batch [12/12] time 0.394 (0.495) data 0.000 (0.088) loss 1.5850 (1.4351) lr 7.7836e-03 eta 0:00:53
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 648
* accuracy: 93.1%
* error: 6.9%
* macro_f1: 91.5%

epoch [42/50] batch [2/12] time 0.397 (1.031) data 0.000 (0.587) loss 1.3857 (1.4429) lr 7.7836e-03 eta 0:01:49
epoch [42/50] batch [4/12] time 0.392 (0.712) data 0.000 (0.294) loss 1.4258 (1.4531) lr 7.7836e-03 eta 0:01:14
epoch [42/50] batch [6/12] time 0.397 (0.606) data 0.000 (0.196) loss 1.4795 (1.4453) lr 7.7836e-03 eta 0:01:01
epoch [42/50] batch [8/12] time 0.392 (0.553) data 0.000 (0.147) loss 1.4883 (1.4594) lr 7.7836e-03 eta 0:00:55
epoch [42/50] batch [10/12] time 0.392 (0.521) data 0.000 (0.118) loss 1.4229 (1.4504) lr 7.7836e-03 eta 0:00:51
epoch [42/50] batch [12/12] time 0.392 (0.499) data 0.000 (0.098) loss 1.3633 (1.4430) lr 6.1847e-03 eta 0:00:47
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 645
* accuracy: 92.7%
* error: 7.3%
* macro_f1: 91.1%

epoch [43/50] batch [2/12] time 0.397 (1.012) data 0.000 (0.565) loss 1.3926 (1.4175) lr 6.1847e-03 eta 0:01:35
epoch [43/50] batch [4/12] time 0.395 (0.704) data 0.000 (0.283) loss 1.4912 (1.4446) lr 6.1847e-03 eta 0:01:04
epoch [43/50] batch [6/12] time 0.393 (0.600) data 0.000 (0.189) loss 1.4707 (1.4482) lr 6.1847e-03 eta 0:00:54
epoch [43/50] batch [8/12] time 0.395 (0.549) data 0.000 (0.141) loss 1.4141 (1.4215) lr 6.1847e-03 eta 0:00:48
epoch [43/50] batch [10/12] time 0.396 (0.519) data 0.000 (0.113) loss 1.3496 (1.4171) lr 6.1847e-03 eta 0:00:44
epoch [43/50] batch [12/12] time 0.392 (0.498) data 0.000 (0.094) loss 1.3857 (1.4219) lr 4.7586e-03 eta 0:00:41
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 646
* accuracy: 92.8%
* error: 7.2%
* macro_f1: 91.2%

epoch [44/50] batch [2/12] time 0.394 (1.009) data 0.000 (0.575) loss 1.4424 (1.4062) lr 4.7586e-03 eta 0:01:22
epoch [44/50] batch [4/12] time 0.393 (0.702) data 0.000 (0.287) loss 1.6523 (1.5017) lr 4.7586e-03 eta 0:00:56
epoch [44/50] batch [6/12] time 0.393 (0.599) data 0.000 (0.192) loss 1.3525 (1.4600) lr 4.7586e-03 eta 0:00:46
epoch [44/50] batch [8/12] time 0.393 (0.547) data 0.000 (0.144) loss 1.4170 (1.4551) lr 4.7586e-03 eta 0:00:41
epoch [44/50] batch [10/12] time 0.393 (0.517) data 0.000 (0.115) loss 1.4375 (1.4448) lr 4.7586e-03 eta 0:00:38
epoch [44/50] batch [12/12] time 0.393 (0.496) data 0.000 (0.096) loss 1.4668 (1.4504) lr 3.5112e-03 eta 0:00:35
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 651
* accuracy: 93.5%
* error: 6.5%
* macro_f1: 92.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [45/50] batch [2/12] time 0.400 (1.001) data 0.000 (0.524) loss 1.3691 (1.3315) lr 3.5112e-03 eta 0:01:10
epoch [45/50] batch [4/12] time 0.480 (0.719) data 0.000 (0.262) loss 1.3770 (1.3621) lr 3.5112e-03 eta 0:00:48
epoch [45/50] batch [6/12] time 0.395 (0.611) data 0.000 (0.175) loss 1.3672 (1.3729) lr 3.5112e-03 eta 0:00:40
epoch [45/50] batch [8/12] time 0.394 (0.557) data 0.000 (0.131) loss 1.4453 (1.3906) lr 3.5112e-03 eta 0:00:35
epoch [45/50] batch [10/12] time 0.395 (0.525) data 0.000 (0.105) loss 1.5361 (1.4129) lr 3.5112e-03 eta 0:00:32
epoch [45/50] batch [12/12] time 0.397 (0.504) data 0.000 (0.088) loss 1.3467 (1.4131) lr 2.4472e-03 eta 0:00:30
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.21it/s]=> result
* total: 696
* correct: 648
* accuracy: 93.1%
* error: 6.9%
* macro_f1: 91.8%

epoch [46/50] batch [2/12] time 0.394 (1.001) data 0.000 (0.567) loss 1.5059 (1.4067) lr 2.4472e-03 eta 0:00:58
epoch [46/50] batch [4/12] time 0.394 (0.698) data 0.000 (0.284) loss 1.3936 (1.4272) lr 2.4472e-03 eta 0:00:39
epoch [46/50] batch [6/12] time 0.394 (0.596) data 0.000 (0.189) loss 1.5391 (1.4601) lr 2.4472e-03 eta 0:00:32
epoch [46/50] batch [8/12] time 0.396 (0.546) data 0.000 (0.142) loss 1.3574 (1.4397) lr 2.4472e-03 eta 0:00:28
epoch [46/50] batch [10/12] time 0.394 (0.516) data 0.000 (0.114) loss 1.5635 (1.4513) lr 2.4472e-03 eta 0:00:25
epoch [46/50] batch [12/12] time 0.395 (0.496) data 0.000 (0.095) loss 1.4746 (1.4573) lr 1.5708e-03 eta 0:00:23
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 651
* accuracy: 93.5%
* error: 6.5%
* macro_f1: 92.2%

epoch [47/50] batch [2/12] time 0.402 (1.024) data 0.000 (0.569) loss 1.4541 (1.4272) lr 1.5708e-03 eta 0:00:47
epoch [47/50] batch [4/12] time 0.393 (0.709) data 0.000 (0.285) loss 1.4160 (1.4456) lr 1.5708e-03 eta 0:00:31
epoch [47/50] batch [6/12] time 0.393 (0.604) data 0.000 (0.190) loss 1.3711 (1.4242) lr 1.5708e-03 eta 0:00:25
epoch [47/50] batch [8/12] time 0.393 (0.551) data 0.000 (0.143) loss 1.4609 (1.4186) lr 1.5708e-03 eta 0:00:22
epoch [47/50] batch [10/12] time 0.394 (0.520) data 0.000 (0.114) loss 1.4775 (1.4313) lr 1.5708e-03 eta 0:00:19
epoch [47/50] batch [12/12] time 0.394 (0.499) data 0.000 (0.095) loss 1.4814 (1.4437) lr 8.8564e-04 eta 0:00:17
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.54s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 648
* accuracy: 93.1%
* error: 6.9%
* macro_f1: 91.5%

epoch [48/50] batch [2/12] time 0.395 (1.042) data 0.000 (0.612) loss 1.4971 (1.4429) lr 8.8564e-04 eta 0:00:35
epoch [48/50] batch [4/12] time 0.394 (0.718) data 0.000 (0.306) loss 1.4590 (1.4329) lr 8.8564e-04 eta 0:00:22
epoch [48/50] batch [6/12] time 0.394 (0.610) data 0.000 (0.204) loss 1.4336 (1.4318) lr 8.8564e-04 eta 0:00:18
epoch [48/50] batch [8/12] time 0.393 (0.556) data 0.000 (0.153) loss 1.2637 (1.4062) lr 8.8564e-04 eta 0:00:15
epoch [48/50] batch [10/12] time 0.394 (0.523) data 0.000 (0.123) loss 1.4170 (1.4079) lr 8.8564e-04 eta 0:00:13
epoch [48/50] batch [12/12] time 0.394 (0.502) data 0.000 (0.102) loss 1.4609 (1.4186) lr 3.9426e-04 eta 0:00:12
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 649
* accuracy: 93.2%
* error: 6.8%
* macro_f1: 91.7%

epoch [49/50] batch [2/12] time 0.393 (1.038) data 0.000 (0.626) loss 1.4717 (1.4712) lr 3.9426e-04 eta 0:00:22
epoch [49/50] batch [4/12] time 0.396 (0.716) data 0.000 (0.313) loss 1.4883 (1.4551) lr 3.9426e-04 eta 0:00:14
epoch [49/50] batch [6/12] time 0.393 (0.609) data 0.000 (0.209) loss 1.5801 (1.4482) lr 3.9426e-04 eta 0:00:10
epoch [49/50] batch [8/12] time 0.393 (0.555) data 0.000 (0.157) loss 1.4180 (1.4329) lr 3.9426e-04 eta 0:00:08
epoch [49/50] batch [10/12] time 0.393 (0.522) data 0.000 (0.125) loss 1.3555 (1.4267) lr 3.9426e-04 eta 0:00:07
epoch [49/50] batch [12/12] time 0.393 (0.501) data 0.000 (0.104) loss 1.4062 (1.4196) lr 9.8664e-05 eta 0:00:06
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.52s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 649
* accuracy: 93.2%
* error: 6.8%
* macro_f1: 91.7%

epoch [50/50] batch [2/12] time 0.394 (1.025) data 0.000 (0.605) loss 1.4902 (1.3872) lr 9.8664e-05 eta 0:00:10
epoch [50/50] batch [4/12] time 0.393 (0.709) data 0.000 (0.302) loss 1.4395 (1.4226) lr 9.8664e-05 eta 0:00:05
epoch [50/50] batch [6/12] time 0.397 (0.605) data 0.000 (0.202) loss 1.3545 (1.4128) lr 9.8664e-05 eta 0:00:03
epoch [50/50] batch [8/12] time 0.396 (0.552) data 0.000 (0.151) loss 1.4961 (1.4296) lr 9.8664e-05 eta 0:00:02
epoch [50/50] batch [10/12] time 0.393 (0.520) data 0.000 (0.121) loss 1.4893 (1.4340) lr 9.8664e-05 eta 0:00:01
epoch [50/50] batch [12/12] time 0.405 (0.500) data 0.000 (0.101) loss 1.5303 (1.4354) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]
=> result
* total: 696
* correct: 649
* accuracy: 93.2%
* error: 6.8%
* macro_f1: 91.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model.pth.tar-50
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar" (epoch = 44)
Evaluate on the *test* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:02<00:14,  2.93s/it] 33%|███▎      | 2/6 [00:03<00:05,  1.36s/it] 50%|█████     | 3/6 [00:03<00:02,  1.18it/s] 67%|██████▋   | 4/6 [00:03<00:01,  1.64it/s] 83%|████████▎ | 5/6 [00:03<00:00,  2.08it/s]100%|██████████| 6/6 [00:04<00:00,  2.83it/s]100%|██████████| 6/6 [00:04<00:00,  1.44it/s]
=> result
* total: 1,053
* correct: 1,000
* accuracy: 95.0%
* error: 5.0%
* macro_f1: 94.7%
Elapsed: 0:07:57
+ sh scripts/rpo_prime/base2new_test.sh oxford_flowers 2 0 main_tmp1 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
816 937 1410
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      937
# test     1,410
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar" (epoch = 44)
Evaluate on the *test* set
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:04<00:34,  4.87s/it] 25%|██▌       | 2/8 [00:05<00:12,  2.15s/it] 38%|███▊      | 3/8 [00:05<00:06,  1.28s/it] 50%|█████     | 4/8 [00:05<00:03,  1.15it/s] 62%|██████▎   | 5/8 [00:05<00:01,  1.55it/s] 75%|███████▌  | 6/8 [00:06<00:01,  1.97it/s] 88%|████████▊ | 7/8 [00:06<00:00,  2.37it/s]100%|██████████| 8/8 [00:06<00:00,  1.24it/s]
=> result
* total: 1,410
* correct: 1,046
* accuracy: 74.2%
* error: 25.8%
* macro_f1: 69.0%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train.sh oxford_flowers 3 0 main_tmp1 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
816 696 1053
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      696
# test     1,053
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/50] batch [2/12] time 0.402 (1.947) data 0.000 (0.822) loss 3.2324 (3.2598) lr 1.0000e-01 eta 0:19:24
epoch [1/50] batch [4/12] time 0.393 (1.170) data 0.000 (0.411) loss 2.6953 (3.0566) lr 1.0000e-01 eta 0:11:37
epoch [1/50] batch [6/12] time 0.392 (0.911) data 0.000 (0.274) loss 2.3887 (2.8005) lr 1.0000e-01 eta 0:09:01
epoch [1/50] batch [8/12] time 0.392 (0.781) data 0.000 (0.206) loss 2.2832 (2.6244) lr 1.0000e-01 eta 0:07:42
epoch [1/50] batch [10/12] time 0.394 (0.704) data 0.000 (0.164) loss 2.3965 (2.5411) lr 1.0000e-01 eta 0:06:55
epoch [1/50] batch [12/12] time 0.396 (0.653) data 0.000 (0.137) loss 2.1973 (2.4947) lr 9.9901e-02 eta 0:06:24
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.63s/it] 50%|█████     | 2/4 [00:02<00:02,  1.23s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.28it/s]100%|██████████| 4/4 [00:03<00:00,  1.89it/s]100%|██████████| 4/4 [00:03<00:00,  1.18it/s]=> result
* total: 696
* correct: 501
* accuracy: 72.0%
* error: 28.0%
* macro_f1: 65.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [2/50] batch [2/12] time 0.396 (0.999) data 0.000 (0.531) loss 2.2715 (2.2100) lr 9.9901e-02 eta 0:09:45
epoch [2/50] batch [4/12] time 0.393 (0.696) data 0.000 (0.266) loss 2.0176 (2.1304) lr 9.9901e-02 eta 0:06:46
epoch [2/50] batch [6/12] time 0.397 (0.596) data 0.000 (0.177) loss 2.3867 (2.1758) lr 9.9901e-02 eta 0:05:46
epoch [2/50] batch [8/12] time 0.393 (0.545) data 0.000 (0.133) loss 1.8516 (2.1274) lr 9.9901e-02 eta 0:05:16
epoch [2/50] batch [10/12] time 0.397 (0.515) data 0.000 (0.106) loss 2.0879 (2.1162) lr 9.9901e-02 eta 0:04:57
epoch [2/50] batch [12/12] time 0.393 (0.495) data 0.000 (0.089) loss 2.2656 (2.1125) lr 9.9606e-02 eta 0:04:45
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 506
* accuracy: 72.7%
* error: 27.3%
* macro_f1: 65.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [3/50] batch [2/12] time 0.396 (1.010) data 0.000 (0.596) loss 1.8711 (1.9238) lr 9.9606e-02 eta 0:09:39
epoch [3/50] batch [4/12] time 0.395 (0.701) data 0.000 (0.298) loss 2.0117 (2.0151) lr 9.9606e-02 eta 0:06:41
epoch [3/50] batch [6/12] time 0.399 (0.599) data 0.000 (0.199) loss 1.9912 (1.9808) lr 9.9606e-02 eta 0:05:41
epoch [3/50] batch [8/12] time 0.397 (0.548) data 0.000 (0.149) loss 2.0625 (1.9895) lr 9.9606e-02 eta 0:05:11
epoch [3/50] batch [10/12] time 0.395 (0.517) data 0.000 (0.119) loss 2.2285 (2.0271) lr 9.9606e-02 eta 0:04:52
epoch [3/50] batch [12/12] time 0.397 (0.497) data 0.001 (0.100) loss 1.8506 (2.0146) lr 9.9114e-02 eta 0:04:40
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 507
* accuracy: 72.8%
* error: 27.2%
* macro_f1: 66.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [4/50] batch [2/12] time 0.394 (1.014) data 0.000 (0.598) loss 1.9688 (1.9238) lr 9.9114e-02 eta 0:09:30
epoch [4/50] batch [4/12] time 0.395 (0.706) data 0.000 (0.299) loss 1.9756 (1.9138) lr 9.9114e-02 eta 0:06:35
epoch [4/50] batch [6/12] time 0.396 (0.602) data 0.000 (0.199) loss 1.9658 (1.9759) lr 9.9114e-02 eta 0:05:36
epoch [4/50] batch [8/12] time 0.395 (0.550) data 0.000 (0.150) loss 1.8975 (2.0035) lr 9.9114e-02 eta 0:05:06
epoch [4/50] batch [10/12] time 0.397 (0.520) data 0.000 (0.120) loss 2.2500 (2.0321) lr 9.9114e-02 eta 0:04:48
epoch [4/50] batch [12/12] time 0.394 (0.499) data 0.000 (0.100) loss 1.9287 (2.0121) lr 9.8429e-02 eta 0:04:35
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.45s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 513
* accuracy: 73.7%
* error: 26.3%
* macro_f1: 67.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [5/50] batch [2/12] time 0.394 (1.033) data 0.000 (0.622) loss 1.8408 (1.8315) lr 9.8429e-02 eta 0:09:28
epoch [5/50] batch [4/12] time 0.398 (0.716) data 0.000 (0.311) loss 1.9209 (1.8823) lr 9.8429e-02 eta 0:06:32
epoch [5/50] batch [6/12] time 0.394 (0.608) data 0.000 (0.207) loss 1.9688 (1.8727) lr 9.8429e-02 eta 0:05:32
epoch [5/50] batch [8/12] time 0.393 (0.555) data 0.000 (0.156) loss 1.8555 (1.8707) lr 9.8429e-02 eta 0:05:01
epoch [5/50] batch [10/12] time 0.394 (0.522) data 0.000 (0.124) loss 1.6846 (1.8719) lr 9.8429e-02 eta 0:04:43
epoch [5/50] batch [12/12] time 0.394 (0.501) data 0.000 (0.104) loss 1.9922 (1.9276) lr 9.7553e-02 eta 0:04:30
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 514
* accuracy: 73.9%
* error: 26.1%
* macro_f1: 67.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [6/50] batch [2/12] time 0.399 (1.007) data 0.000 (0.564) loss 1.9756 (1.9829) lr 9.7553e-02 eta 0:09:01
epoch [6/50] batch [4/12] time 0.393 (0.700) data 0.000 (0.282) loss 1.8428 (1.9131) lr 9.7553e-02 eta 0:06:15
epoch [6/50] batch [6/12] time 0.397 (0.599) data 0.000 (0.188) loss 2.0840 (1.9520) lr 9.7553e-02 eta 0:05:19
epoch [6/50] batch [8/12] time 0.393 (0.548) data 0.000 (0.141) loss 1.9072 (1.9199) lr 9.7553e-02 eta 0:04:51
epoch [6/50] batch [10/12] time 0.393 (0.517) data 0.000 (0.113) loss 1.7373 (1.8813) lr 9.7553e-02 eta 0:04:33
epoch [6/50] batch [12/12] time 0.394 (0.496) data 0.000 (0.094) loss 2.0391 (1.9103) lr 9.6489e-02 eta 0:04:22
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 520
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 68.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [7/50] batch [2/12] time 0.393 (1.000) data 0.000 (0.592) loss 1.7490 (1.8379) lr 9.6489e-02 eta 0:08:45
epoch [7/50] batch [4/12] time 0.393 (0.697) data 0.000 (0.296) loss 1.7852 (1.8440) lr 9.6489e-02 eta 0:06:05
epoch [7/50] batch [6/12] time 0.393 (0.596) data 0.000 (0.197) loss 2.1035 (1.8727) lr 9.6489e-02 eta 0:05:10
epoch [7/50] batch [8/12] time 0.393 (0.545) data 0.000 (0.148) loss 2.0430 (1.9028) lr 9.6489e-02 eta 0:04:43
epoch [7/50] batch [10/12] time 0.394 (0.517) data 0.000 (0.118) loss 1.8516 (1.8953) lr 9.6489e-02 eta 0:04:27
epoch [7/50] batch [12/12] time 0.396 (0.496) data 0.000 (0.099) loss 1.8359 (1.8988) lr 9.5241e-02 eta 0:04:15
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 520
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 69.5%

epoch [8/50] batch [2/12] time 0.393 (0.976) data 0.000 (0.503) loss 2.0586 (1.9590) lr 9.5241e-02 eta 0:08:21
epoch [8/50] batch [4/12] time 0.394 (0.685) data 0.000 (0.251) loss 1.5020 (1.8259) lr 9.5241e-02 eta 0:05:50
epoch [8/50] batch [6/12] time 0.398 (0.588) data 0.000 (0.168) loss 2.0488 (1.8745) lr 9.5241e-02 eta 0:05:00
epoch [8/50] batch [8/12] time 0.393 (0.540) data 0.000 (0.126) loss 1.6895 (1.8746) lr 9.5241e-02 eta 0:04:34
epoch [8/50] batch [10/12] time 0.394 (0.510) data 0.000 (0.101) loss 1.8359 (1.8775) lr 9.5241e-02 eta 0:04:18
epoch [8/50] batch [12/12] time 0.488 (0.499) data 0.000 (0.084) loss 1.8545 (1.8941) lr 9.3815e-02 eta 0:04:11
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 520
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 69.3%

epoch [9/50] batch [2/12] time 0.395 (1.031) data 0.000 (0.625) loss 1.9414 (1.8047) lr 9.3815e-02 eta 0:08:37
epoch [9/50] batch [4/12] time 0.394 (0.714) data 0.000 (0.313) loss 1.7861 (1.8748) lr 9.3815e-02 eta 0:05:57
epoch [9/50] batch [6/12] time 0.398 (0.608) data 0.000 (0.209) loss 1.9307 (1.8911) lr 9.3815e-02 eta 0:05:02
epoch [9/50] batch [8/12] time 0.393 (0.555) data 0.000 (0.156) loss 1.9951 (1.9086) lr 9.3815e-02 eta 0:04:35
epoch [9/50] batch [10/12] time 0.394 (0.523) data 0.000 (0.125) loss 1.8936 (1.9062) lr 9.3815e-02 eta 0:04:18
epoch [9/50] batch [12/12] time 0.394 (0.501) data 0.000 (0.104) loss 1.7451 (1.8876) lr 9.2216e-02 eta 0:04:06
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.46s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 520
* accuracy: 74.7%
* error: 25.3%
* macro_f1: 69.9%

epoch [10/50] batch [2/12] time 0.397 (1.003) data 0.000 (0.538) loss 1.8008 (1.8525) lr 9.2216e-02 eta 0:08:11
epoch [10/50] batch [4/12] time 0.395 (0.698) data 0.000 (0.269) loss 1.6816 (1.8284) lr 9.2216e-02 eta 0:05:40
epoch [10/50] batch [6/12] time 0.394 (0.598) data 0.000 (0.180) loss 1.6680 (1.8065) lr 9.2216e-02 eta 0:04:50
epoch [10/50] batch [8/12] time 0.398 (0.547) data 0.000 (0.135) loss 1.7627 (1.8154) lr 9.2216e-02 eta 0:04:24
epoch [10/50] batch [10/12] time 0.399 (0.517) data 0.000 (0.108) loss 1.8340 (1.8469) lr 9.2216e-02 eta 0:04:09
epoch [10/50] batch [12/12] time 0.398 (0.497) data 0.000 (0.090) loss 1.9092 (1.8464) lr 9.0451e-02 eta 0:03:58
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.44s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.36it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 532
* accuracy: 76.4%
* error: 23.6%
* macro_f1: 71.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model.pth.tar-10

epoch [11/50] batch [2/12] time 0.399 (1.019) data 0.000 (0.540) loss 1.7559 (1.8984) lr 9.0451e-02 eta 0:08:07
epoch [11/50] batch [4/12] time 0.393 (0.706) data 0.000 (0.270) loss 1.7090 (1.8281) lr 9.0451e-02 eta 0:05:36
epoch [11/50] batch [6/12] time 0.393 (0.602) data 0.000 (0.180) loss 1.7344 (1.8646) lr 9.0451e-02 eta 0:04:45
epoch [11/50] batch [8/12] time 0.392 (0.549) data 0.000 (0.135) loss 1.9268 (1.8430) lr 9.0451e-02 eta 0:04:19
epoch [11/50] batch [10/12] time 0.392 (0.518) data 0.000 (0.108) loss 1.8789 (1.8511) lr 9.0451e-02 eta 0:04:03
epoch [11/50] batch [12/12] time 0.393 (0.497) data 0.000 (0.090) loss 1.8691 (1.8767) lr 8.8526e-02 eta 0:03:52
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.94it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 530
* accuracy: 76.1%
* error: 23.9%
* macro_f1: 71.3%

epoch [12/50] batch [2/12] time 0.406 (1.003) data 0.000 (0.537) loss 1.8086 (1.8584) lr 8.8526e-02 eta 0:07:47
epoch [12/50] batch [4/12] time 0.394 (0.698) data 0.000 (0.269) loss 1.7725 (1.8550) lr 8.8526e-02 eta 0:05:23
epoch [12/50] batch [6/12] time 0.394 (0.597) data 0.000 (0.179) loss 1.9043 (1.8210) lr 8.8526e-02 eta 0:04:35
epoch [12/50] batch [8/12] time 0.396 (0.546) data 0.000 (0.134) loss 1.7539 (1.8110) lr 8.8526e-02 eta 0:04:11
epoch [12/50] batch [10/12] time 0.393 (0.516) data 0.000 (0.108) loss 1.6260 (1.7812) lr 8.8526e-02 eta 0:03:56
epoch [12/50] batch [12/12] time 0.393 (0.496) data 0.000 (0.090) loss 1.9775 (1.8114) lr 8.6448e-02 eta 0:03:45
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 538
* accuracy: 77.3%
* error: 22.7%
* macro_f1: 72.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [13/50] batch [2/12] time 0.400 (0.983) data 0.000 (0.500) loss 1.9082 (1.8594) lr 8.6448e-02 eta 0:07:26
epoch [13/50] batch [4/12] time 0.392 (0.688) data 0.000 (0.250) loss 1.8691 (1.8940) lr 8.6448e-02 eta 0:05:10
epoch [13/50] batch [6/12] time 0.392 (0.589) data 0.000 (0.167) loss 1.8809 (1.8405) lr 8.6448e-02 eta 0:04:25
epoch [13/50] batch [8/12] time 0.392 (0.540) data 0.000 (0.125) loss 1.8965 (1.8447) lr 8.6448e-02 eta 0:04:01
epoch [13/50] batch [10/12] time 0.392 (0.511) data 0.000 (0.100) loss 1.7949 (1.8339) lr 8.6448e-02 eta 0:03:47
epoch [13/50] batch [12/12] time 0.392 (0.491) data 0.000 (0.084) loss 1.6904 (1.8082) lr 8.4227e-02 eta 0:03:38
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.46s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 542
* accuracy: 77.9%
* error: 22.1%
* macro_f1: 73.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [14/50] batch [2/12] time 0.399 (0.984) data 0.000 (0.501) loss 1.7500 (1.7803) lr 8.4227e-02 eta 0:07:14
epoch [14/50] batch [4/12] time 0.392 (0.688) data 0.000 (0.251) loss 1.7646 (1.7681) lr 8.4227e-02 eta 0:05:02
epoch [14/50] batch [6/12] time 0.392 (0.589) data 0.000 (0.167) loss 1.8857 (1.8280) lr 8.4227e-02 eta 0:04:18
epoch [14/50] batch [8/12] time 0.392 (0.540) data 0.000 (0.125) loss 1.8096 (1.7996) lr 8.4227e-02 eta 0:03:55
epoch [14/50] batch [10/12] time 0.392 (0.511) data 0.000 (0.100) loss 1.6553 (1.7803) lr 8.4227e-02 eta 0:03:41
epoch [14/50] batch [12/12] time 0.392 (0.491) data 0.000 (0.084) loss 1.8848 (1.7799) lr 8.1871e-02 eta 0:03:32
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 546
* accuracy: 78.4%
* error: 21.6%
* macro_f1: 74.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [15/50] batch [2/12] time 0.395 (1.009) data 0.000 (0.581) loss 1.8506 (1.8740) lr 8.1871e-02 eta 0:07:13
epoch [15/50] batch [4/12] time 0.392 (0.701) data 0.000 (0.291) loss 1.6104 (1.7861) lr 8.1871e-02 eta 0:04:59
epoch [15/50] batch [6/12] time 0.392 (0.598) data 0.000 (0.194) loss 1.8516 (1.8013) lr 8.1871e-02 eta 0:04:14
epoch [15/50] batch [8/12] time 0.392 (0.547) data 0.000 (0.145) loss 1.6816 (1.7927) lr 8.1871e-02 eta 0:03:51
epoch [15/50] batch [10/12] time 0.393 (0.516) data 0.000 (0.116) loss 1.6035 (1.7695) lr 8.1871e-02 eta 0:03:37
epoch [15/50] batch [12/12] time 0.393 (0.495) data 0.000 (0.097) loss 1.9521 (1.7812) lr 7.9389e-02 eta 0:03:28
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.46s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 549
* accuracy: 78.9%
* error: 21.1%
* macro_f1: 74.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [16/50] batch [2/12] time 0.399 (1.050) data 0.000 (0.635) loss 1.6826 (1.6943) lr 7.9389e-02 eta 0:07:19
epoch [16/50] batch [4/12] time 0.395 (0.723) data 0.000 (0.318) loss 1.6279 (1.6868) lr 7.9389e-02 eta 0:05:00
epoch [16/50] batch [6/12] time 0.394 (0.613) data 0.000 (0.212) loss 1.8301 (1.7179) lr 7.9389e-02 eta 0:04:13
epoch [16/50] batch [8/12] time 0.394 (0.558) data 0.000 (0.159) loss 1.7773 (1.7296) lr 7.9389e-02 eta 0:03:50
epoch [16/50] batch [10/12] time 0.395 (0.525) data 0.000 (0.127) loss 1.7412 (1.7429) lr 7.9389e-02 eta 0:03:35
epoch [16/50] batch [12/12] time 0.396 (0.504) data 0.000 (0.106) loss 1.5967 (1.7340) lr 7.6791e-02 eta 0:03:25
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.46s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 547
* accuracy: 78.6%
* error: 21.4%
* macro_f1: 74.7%

epoch [17/50] batch [2/12] time 0.393 (0.987) data 0.000 (0.550) loss 1.8330 (1.7373) lr 7.6791e-02 eta 0:06:40
epoch [17/50] batch [4/12] time 0.393 (0.691) data 0.000 (0.275) loss 1.7275 (1.6860) lr 7.6791e-02 eta 0:04:39
epoch [17/50] batch [6/12] time 0.479 (0.606) data 0.000 (0.183) loss 1.7637 (1.7279) lr 7.6791e-02 eta 0:04:03
epoch [17/50] batch [8/12] time 0.392 (0.553) data 0.000 (0.137) loss 1.7061 (1.7504) lr 7.6791e-02 eta 0:03:41
epoch [17/50] batch [10/12] time 0.393 (0.521) data 0.000 (0.110) loss 1.7881 (1.7639) lr 7.6791e-02 eta 0:03:27
epoch [17/50] batch [12/12] time 0.392 (0.499) data 0.000 (0.092) loss 1.7676 (1.7675) lr 7.4088e-02 eta 0:03:17
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 558
* accuracy: 80.2%
* error: 19.8%
* macro_f1: 76.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [18/50] batch [2/12] time 0.397 (1.003) data 0.000 (0.579) loss 1.6543 (1.6748) lr 7.4088e-02 eta 0:06:35
epoch [18/50] batch [4/12] time 0.395 (0.699) data 0.000 (0.290) loss 1.7129 (1.6890) lr 7.4088e-02 eta 0:04:33
epoch [18/50] batch [6/12] time 0.394 (0.597) data 0.000 (0.193) loss 1.8066 (1.7682) lr 7.4088e-02 eta 0:03:53
epoch [18/50] batch [8/12] time 0.398 (0.547) data 0.000 (0.145) loss 1.5898 (1.7189) lr 7.4088e-02 eta 0:03:32
epoch [18/50] batch [10/12] time 0.394 (0.517) data 0.000 (0.116) loss 1.7451 (1.7219) lr 7.4088e-02 eta 0:03:19
epoch [18/50] batch [12/12] time 0.394 (0.498) data 0.000 (0.097) loss 2.0234 (1.7421) lr 7.1289e-02 eta 0:03:11
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.44s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.36it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 546
* accuracy: 78.4%
* error: 21.6%
* macro_f1: 75.0%

epoch [19/50] batch [2/12] time 0.399 (0.997) data 0.000 (0.507) loss 1.7119 (1.6841) lr 7.1289e-02 eta 0:06:20
epoch [19/50] batch [4/12] time 0.397 (0.696) data 0.000 (0.254) loss 1.7637 (1.7041) lr 7.1289e-02 eta 0:04:24
epoch [19/50] batch [6/12] time 0.393 (0.595) data 0.000 (0.169) loss 1.7500 (1.7251) lr 7.1289e-02 eta 0:03:44
epoch [19/50] batch [8/12] time 0.398 (0.545) data 0.000 (0.127) loss 1.8066 (1.7401) lr 7.1289e-02 eta 0:03:25
epoch [19/50] batch [10/12] time 0.395 (0.515) data 0.000 (0.102) loss 1.6074 (1.7248) lr 7.1289e-02 eta 0:03:12
epoch [19/50] batch [12/12] time 0.395 (0.495) data 0.000 (0.085) loss 1.6396 (1.7161) lr 6.8406e-02 eta 0:03:04
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 566
* accuracy: 81.3%
* error: 18.7%
* macro_f1: 77.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [20/50] batch [2/12] time 0.395 (1.014) data 0.000 (0.611) loss 1.7129 (1.7480) lr 6.8406e-02 eta 0:06:15
epoch [20/50] batch [4/12] time 0.395 (0.704) data 0.000 (0.306) loss 1.8164 (1.7585) lr 6.8406e-02 eta 0:04:19
epoch [20/50] batch [6/12] time 0.395 (0.601) data 0.000 (0.204) loss 1.5469 (1.7314) lr 6.8406e-02 eta 0:03:40
epoch [20/50] batch [8/12] time 0.404 (0.551) data 0.000 (0.153) loss 1.8916 (1.7302) lr 6.8406e-02 eta 0:03:20
epoch [20/50] batch [10/12] time 0.393 (0.519) data 0.000 (0.122) loss 1.8174 (1.7255) lr 6.8406e-02 eta 0:03:07
epoch [20/50] batch [12/12] time 0.392 (0.498) data 0.000 (0.102) loss 1.7324 (1.7262) lr 6.5451e-02 eta 0:02:59
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 569
* accuracy: 81.8%
* error: 18.2%
* macro_f1: 78.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model.pth.tar-20

epoch [21/50] batch [2/12] time 0.395 (1.039) data 0.000 (0.626) loss 1.5303 (1.5776) lr 6.5451e-02 eta 0:06:11
epoch [21/50] batch [4/12] time 0.394 (0.717) data 0.000 (0.313) loss 1.6631 (1.6372) lr 6.5451e-02 eta 0:04:15
epoch [21/50] batch [6/12] time 0.394 (0.609) data 0.000 (0.209) loss 1.7861 (1.6769) lr 6.5451e-02 eta 0:03:35
epoch [21/50] batch [8/12] time 0.397 (0.556) data 0.000 (0.157) loss 1.6543 (1.7095) lr 6.5451e-02 eta 0:03:15
epoch [21/50] batch [10/12] time 0.394 (0.524) data 0.000 (0.125) loss 1.6377 (1.7137) lr 6.5451e-02 eta 0:03:03
epoch [21/50] batch [12/12] time 0.399 (0.502) data 0.000 (0.104) loss 1.6943 (1.7004) lr 6.2434e-02 eta 0:02:54
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.44s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.36it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.26it/s]=> result
* total: 696
* correct: 573
* accuracy: 82.3%
* error: 17.7%
* macro_f1: 78.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [22/50] batch [2/12] time 0.397 (0.988) data 0.000 (0.509) loss 1.6641 (1.7178) lr 6.2434e-02 eta 0:05:41
epoch [22/50] batch [4/12] time 0.394 (0.691) data 0.000 (0.255) loss 1.6562 (1.7261) lr 6.2434e-02 eta 0:03:57
epoch [22/50] batch [6/12] time 0.398 (0.593) data 0.000 (0.170) loss 1.7061 (1.7077) lr 6.2434e-02 eta 0:03:22
epoch [22/50] batch [8/12] time 0.394 (0.543) data 0.000 (0.127) loss 1.9824 (1.7490) lr 6.2434e-02 eta 0:03:04
epoch [22/50] batch [10/12] time 0.393 (0.513) data 0.000 (0.102) loss 1.6123 (1.7416) lr 6.2434e-02 eta 0:02:53
epoch [22/50] batch [12/12] time 0.393 (0.493) data 0.000 (0.085) loss 1.9346 (1.7572) lr 5.9369e-02 eta 0:02:45
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 592
* accuracy: 85.1%
* error: 14.9%
* macro_f1: 82.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [23/50] batch [2/12] time 0.395 (1.003) data 0.000 (0.585) loss 1.7402 (1.6606) lr 5.9369e-02 eta 0:05:34
epoch [23/50] batch [4/12] time 0.398 (0.706) data 0.000 (0.293) loss 1.5410 (1.6321) lr 5.9369e-02 eta 0:03:54
epoch [23/50] batch [6/12] time 0.394 (0.602) data 0.000 (0.195) loss 1.5322 (1.6112) lr 5.9369e-02 eta 0:03:18
epoch [23/50] batch [8/12] time 0.395 (0.550) data 0.000 (0.146) loss 1.7500 (1.6362) lr 5.9369e-02 eta 0:03:00
epoch [23/50] batch [10/12] time 0.396 (0.519) data 0.000 (0.117) loss 1.9004 (1.6477) lr 5.9369e-02 eta 0:02:49
epoch [23/50] batch [12/12] time 0.394 (0.498) data 0.000 (0.098) loss 1.8311 (1.6646) lr 5.6267e-02 eta 0:02:41
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.50s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 599
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 83.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [24/50] batch [2/12] time 0.399 (0.998) data 0.000 (0.549) loss 1.6396 (1.6587) lr 5.6267e-02 eta 0:05:21
epoch [24/50] batch [4/12] time 0.392 (0.695) data 0.000 (0.275) loss 1.5186 (1.6406) lr 5.6267e-02 eta 0:03:42
epoch [24/50] batch [6/12] time 0.392 (0.594) data 0.000 (0.183) loss 1.6787 (1.6545) lr 5.6267e-02 eta 0:03:09
epoch [24/50] batch [8/12] time 0.393 (0.544) data 0.000 (0.137) loss 1.5273 (1.6458) lr 5.6267e-02 eta 0:02:51
epoch [24/50] batch [10/12] time 0.393 (0.514) data 0.000 (0.110) loss 1.6260 (1.6373) lr 5.6267e-02 eta 0:02:41
epoch [24/50] batch [12/12] time 0.393 (0.493) data 0.000 (0.092) loss 1.6064 (1.6299) lr 5.3140e-02 eta 0:02:33
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 604
* accuracy: 86.8%
* error: 13.2%
* macro_f1: 84.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [25/50] batch [2/12] time 0.392 (0.999) data 0.000 (0.591) loss 1.6787 (1.6777) lr 5.3140e-02 eta 0:05:09
epoch [25/50] batch [4/12] time 0.392 (0.696) data 0.000 (0.295) loss 1.7305 (1.6726) lr 5.3140e-02 eta 0:03:34
epoch [25/50] batch [6/12] time 0.392 (0.595) data 0.000 (0.197) loss 1.7031 (1.6540) lr 5.3140e-02 eta 0:03:01
epoch [25/50] batch [8/12] time 0.392 (0.544) data 0.000 (0.148) loss 1.6240 (1.6404) lr 5.3140e-02 eta 0:02:45
epoch [25/50] batch [10/12] time 0.392 (0.514) data 0.000 (0.118) loss 1.7197 (1.6389) lr 5.3140e-02 eta 0:02:35
epoch [25/50] batch [12/12] time 0.393 (0.494) data 0.000 (0.099) loss 1.6230 (1.6420) lr 5.0000e-02 eta 0:02:28
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 599
* accuracy: 86.1%
* error: 13.9%
* macro_f1: 83.6%

epoch [26/50] batch [2/12] time 0.392 (0.982) data 0.000 (0.495) loss 1.5547 (1.7148) lr 5.0000e-02 eta 0:04:52
epoch [26/50] batch [4/12] time 0.392 (0.687) data 0.000 (0.248) loss 1.5479 (1.6443) lr 5.0000e-02 eta 0:03:23
epoch [26/50] batch [6/12] time 0.392 (0.589) data 0.000 (0.165) loss 1.8477 (1.6711) lr 5.0000e-02 eta 0:02:53
epoch [26/50] batch [8/12] time 0.392 (0.540) data 0.000 (0.124) loss 1.7588 (1.6812) lr 5.0000e-02 eta 0:02:37
epoch [26/50] batch [10/12] time 0.393 (0.510) data 0.000 (0.099) loss 1.5146 (1.6605) lr 5.0000e-02 eta 0:02:27
epoch [26/50] batch [12/12] time 0.405 (0.492) data 0.000 (0.083) loss 1.5742 (1.6576) lr 4.6860e-02 eta 0:02:21
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.45s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 601
* accuracy: 86.4%
* error: 13.6%
* macro_f1: 84.0%

epoch [27/50] batch [2/12] time 0.396 (1.022) data 0.000 (0.591) loss 1.6895 (1.6519) lr 4.6860e-02 eta 0:04:52
epoch [27/50] batch [4/12] time 0.394 (0.708) data 0.000 (0.295) loss 1.7920 (1.6660) lr 4.6860e-02 eta 0:03:20
epoch [27/50] batch [6/12] time 0.394 (0.603) data 0.000 (0.197) loss 1.7266 (1.6756) lr 4.6860e-02 eta 0:02:50
epoch [27/50] batch [8/12] time 0.395 (0.551) data 0.000 (0.148) loss 1.6113 (1.6582) lr 4.6860e-02 eta 0:02:34
epoch [27/50] batch [10/12] time 0.394 (0.520) data 0.000 (0.118) loss 1.4648 (1.6512) lr 4.6860e-02 eta 0:02:24
epoch [27/50] batch [12/12] time 0.394 (0.499) data 0.000 (0.099) loss 1.6523 (1.6478) lr 4.3733e-02 eta 0:02:17
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 602
* accuracy: 86.5%
* error: 13.5%
* macro_f1: 84.3%

epoch [28/50] batch [2/12] time 0.405 (1.022) data 0.000 (0.495) loss 1.7061 (1.6729) lr 4.3733e-02 eta 0:04:40
epoch [28/50] batch [4/12] time 0.392 (0.708) data 0.000 (0.247) loss 1.5596 (1.6165) lr 4.3733e-02 eta 0:03:12
epoch [28/50] batch [6/12] time 0.392 (0.602) data 0.000 (0.165) loss 1.7158 (1.6276) lr 4.3733e-02 eta 0:02:42
epoch [28/50] batch [8/12] time 0.392 (0.550) data 0.000 (0.124) loss 1.4727 (1.6064) lr 4.3733e-02 eta 0:02:27
epoch [28/50] batch [10/12] time 0.392 (0.518) data 0.000 (0.099) loss 1.6367 (1.6049) lr 4.3733e-02 eta 0:02:17
epoch [28/50] batch [12/12] time 0.392 (0.497) data 0.000 (0.083) loss 2.0684 (1.6345) lr 4.0631e-02 eta 0:02:11
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.44s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.36it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 607
* accuracy: 87.2%
* error: 12.8%
* macro_f1: 85.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [29/50] batch [2/12] time 0.392 (1.003) data 0.000 (0.594) loss 1.7891 (1.6865) lr 4.0631e-02 eta 0:04:22
epoch [29/50] batch [4/12] time 0.394 (0.698) data 0.000 (0.297) loss 1.6836 (1.6658) lr 4.0631e-02 eta 0:03:01
epoch [29/50] batch [6/12] time 0.392 (0.596) data 0.000 (0.198) loss 1.5479 (1.6126) lr 4.0631e-02 eta 0:02:33
epoch [29/50] batch [8/12] time 0.393 (0.545) data 0.000 (0.149) loss 1.5820 (1.5933) lr 4.0631e-02 eta 0:02:19
epoch [29/50] batch [10/12] time 0.392 (0.515) data 0.000 (0.119) loss 1.7725 (1.6122) lr 4.0631e-02 eta 0:02:10
epoch [29/50] batch [12/12] time 0.393 (0.494) data 0.000 (0.099) loss 1.5889 (1.6093) lr 3.7566e-02 eta 0:02:04
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 611
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 85.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [30/50] batch [2/12] time 0.392 (1.026) data 0.000 (0.612) loss 1.6572 (1.6392) lr 3.7566e-02 eta 0:04:16
epoch [30/50] batch [4/12] time 0.392 (0.709) data 0.000 (0.306) loss 1.5293 (1.5901) lr 3.7566e-02 eta 0:02:55
epoch [30/50] batch [6/12] time 0.392 (0.603) data 0.000 (0.204) loss 1.5449 (1.5833) lr 3.7566e-02 eta 0:02:28
epoch [30/50] batch [8/12] time 0.392 (0.551) data 0.000 (0.153) loss 1.7529 (1.6122) lr 3.7566e-02 eta 0:02:14
epoch [30/50] batch [10/12] time 0.393 (0.519) data 0.000 (0.123) loss 1.6348 (1.6078) lr 3.7566e-02 eta 0:02:05
epoch [30/50] batch [12/12] time 0.393 (0.498) data 0.000 (0.102) loss 1.7256 (1.6159) lr 3.4549e-02 eta 0:01:59
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 621
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 87.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model.pth.tar-30

epoch [31/50] batch [2/12] time 0.394 (1.032) data 0.000 (0.627) loss 1.5430 (1.6328) lr 3.4549e-02 eta 0:04:05
epoch [31/50] batch [4/12] time 0.393 (0.712) data 0.000 (0.313) loss 1.8359 (1.7017) lr 3.4549e-02 eta 0:02:48
epoch [31/50] batch [6/12] time 0.392 (0.606) data 0.000 (0.209) loss 1.6279 (1.6610) lr 3.4549e-02 eta 0:02:21
epoch [31/50] batch [8/12] time 0.395 (0.553) data 0.000 (0.157) loss 1.6045 (1.6367) lr 3.4549e-02 eta 0:02:08
epoch [31/50] batch [10/12] time 0.393 (0.521) data 0.000 (0.126) loss 1.6650 (1.6326) lr 3.4549e-02 eta 0:01:59
epoch [31/50] batch [12/12] time 0.393 (0.499) data 0.000 (0.105) loss 1.5889 (1.6176) lr 3.1594e-02 eta 0:01:53
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.51s/it] 50%|█████     | 2/4 [00:02<00:02,  1.18s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.33it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 621
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 87.4%

epoch [32/50] batch [2/12] time 0.395 (1.008) data 0.000 (0.594) loss 1.7129 (1.6006) lr 3.1594e-02 eta 0:03:47
epoch [32/50] batch [4/12] time 0.392 (0.701) data 0.000 (0.297) loss 1.5625 (1.5769) lr 3.1594e-02 eta 0:02:36
epoch [32/50] batch [6/12] time 0.392 (0.598) data 0.000 (0.198) loss 1.5215 (1.5669) lr 3.1594e-02 eta 0:02:12
epoch [32/50] batch [8/12] time 0.392 (0.546) data 0.000 (0.149) loss 1.6309 (1.5939) lr 3.1594e-02 eta 0:02:00
epoch [32/50] batch [10/12] time 0.393 (0.516) data 0.000 (0.119) loss 1.4424 (1.5787) lr 3.1594e-02 eta 0:01:52
epoch [32/50] batch [12/12] time 0.393 (0.495) data 0.000 (0.099) loss 1.8721 (1.6077) lr 2.8711e-02 eta 0:01:46
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.44s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.36it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.26it/s]=> result
* total: 696
* correct: 615
* accuracy: 88.4%
* error: 11.6%
* macro_f1: 86.4%

epoch [33/50] batch [2/12] time 0.404 (0.994) data 0.000 (0.518) loss 1.5605 (1.5747) lr 2.8711e-02 eta 0:03:32
epoch [33/50] batch [4/12] time 0.394 (0.693) data 0.000 (0.259) loss 1.6152 (1.6003) lr 2.8711e-02 eta 0:02:27
epoch [33/50] batch [6/12] time 0.395 (0.594) data 0.000 (0.173) loss 1.7744 (1.6396) lr 2.8711e-02 eta 0:02:04
epoch [33/50] batch [8/12] time 0.392 (0.544) data 0.000 (0.130) loss 1.7432 (1.6354) lr 2.8711e-02 eta 0:01:53
epoch [33/50] batch [10/12] time 0.393 (0.513) data 0.000 (0.104) loss 1.5127 (1.6170) lr 2.8711e-02 eta 0:01:45
epoch [33/50] batch [12/12] time 0.393 (0.493) data 0.000 (0.087) loss 1.5830 (1.6091) lr 2.5912e-02 eta 0:01:40
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.23it/s]=> result
* total: 696
* correct: 611
* accuracy: 87.8%
* error: 12.2%
* macro_f1: 85.5%

epoch [34/50] batch [2/12] time 0.394 (1.014) data 0.000 (0.592) loss 1.4082 (1.5527) lr 2.5912e-02 eta 0:03:24
epoch [34/50] batch [4/12] time 0.394 (0.704) data 0.000 (0.296) loss 1.5391 (1.5530) lr 2.5912e-02 eta 0:02:20
epoch [34/50] batch [6/12] time 0.394 (0.601) data 0.000 (0.197) loss 1.5869 (1.5578) lr 2.5912e-02 eta 0:01:58
epoch [34/50] batch [8/12] time 0.394 (0.549) data 0.000 (0.148) loss 1.6436 (1.5699) lr 2.5912e-02 eta 0:01:47
epoch [34/50] batch [10/12] time 0.393 (0.518) data 0.000 (0.118) loss 1.4932 (1.5740) lr 2.5912e-02 eta 0:01:40
epoch [34/50] batch [12/12] time 0.394 (0.498) data 0.000 (0.099) loss 1.6074 (1.5748) lr 2.3209e-02 eta 0:01:35
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.44s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 621
* accuracy: 89.2%
* error: 10.8%
* macro_f1: 87.1%

epoch [35/50] batch [2/12] time 0.398 (0.998) data 0.000 (0.552) loss 1.3389 (1.4395) lr 2.3209e-02 eta 0:03:09
epoch [35/50] batch [4/12] time 0.396 (0.696) data 0.000 (0.276) loss 1.5625 (1.4946) lr 2.3209e-02 eta 0:02:10
epoch [35/50] batch [6/12] time 0.396 (0.595) data 0.000 (0.184) loss 1.5156 (1.5259) lr 2.3209e-02 eta 0:01:50
epoch [35/50] batch [8/12] time 0.393 (0.545) data 0.000 (0.138) loss 1.8330 (1.5560) lr 2.3209e-02 eta 0:01:40
epoch [35/50] batch [10/12] time 0.392 (0.515) data 0.000 (0.111) loss 1.5488 (1.5497) lr 2.3209e-02 eta 0:01:33
epoch [35/50] batch [12/12] time 0.393 (0.494) data 0.000 (0.092) loss 1.5586 (1.5544) lr 2.0611e-02 eta 0:01:28
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.49s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.95it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 616
* accuracy: 88.5%
* error: 11.5%
* macro_f1: 86.7%

epoch [36/50] batch [2/12] time 0.392 (1.004) data 0.000 (0.604) loss 1.4648 (1.5879) lr 2.0611e-02 eta 0:02:58
epoch [36/50] batch [4/12] time 0.396 (0.699) data 0.000 (0.302) loss 1.6074 (1.5879) lr 2.0611e-02 eta 0:02:03
epoch [36/50] batch [6/12] time 0.393 (0.597) data 0.000 (0.201) loss 1.5312 (1.5910) lr 2.0611e-02 eta 0:01:43
epoch [36/50] batch [8/12] time 0.392 (0.546) data 0.000 (0.151) loss 1.5156 (1.5929) lr 2.0611e-02 eta 0:01:33
epoch [36/50] batch [10/12] time 0.393 (0.515) data 0.000 (0.121) loss 1.3711 (1.5657) lr 2.0611e-02 eta 0:01:27
epoch [36/50] batch [12/12] time 0.478 (0.502) data 0.000 (0.101) loss 1.5156 (1.5770) lr 1.8129e-02 eta 0:01:24
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 628
* accuracy: 90.2%
* error: 9.8%
* macro_f1: 88.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [37/50] batch [2/12] time 0.392 (1.015) data 0.000 (0.600) loss 1.5547 (1.5073) lr 1.8129e-02 eta 0:02:48
epoch [37/50] batch [4/12] time 0.392 (0.704) data 0.000 (0.300) loss 1.7002 (1.6118) lr 1.8129e-02 eta 0:01:55
epoch [37/50] batch [6/12] time 0.392 (0.600) data 0.000 (0.200) loss 1.5947 (1.5952) lr 1.8129e-02 eta 0:01:37
epoch [37/50] batch [8/12] time 0.393 (0.548) data 0.000 (0.150) loss 1.5957 (1.5984) lr 1.8129e-02 eta 0:01:27
epoch [37/50] batch [10/12] time 0.393 (0.517) data 0.000 (0.120) loss 1.6602 (1.5934) lr 1.8129e-02 eta 0:01:21
epoch [37/50] batch [12/12] time 0.392 (0.497) data 0.000 (0.100) loss 1.4365 (1.5804) lr 1.5773e-02 eta 0:01:17
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 618
* accuracy: 88.8%
* error: 11.2%
* macro_f1: 86.7%

epoch [38/50] batch [2/12] time 0.402 (0.985) data 0.000 (0.520) loss 1.6885 (1.6338) lr 1.5773e-02 eta 0:02:31
epoch [38/50] batch [4/12] time 0.392 (0.689) data 0.000 (0.260) loss 1.4805 (1.5928) lr 1.5773e-02 eta 0:01:44
epoch [38/50] batch [6/12] time 0.392 (0.590) data 0.000 (0.173) loss 1.5703 (1.6014) lr 1.5773e-02 eta 0:01:28
epoch [38/50] batch [8/12] time 0.397 (0.541) data 0.000 (0.130) loss 1.4854 (1.5649) lr 1.5773e-02 eta 0:01:20
epoch [38/50] batch [10/12] time 0.392 (0.511) data 0.000 (0.104) loss 1.4951 (1.5640) lr 1.5773e-02 eta 0:01:14
epoch [38/50] batch [12/12] time 0.391 (0.491) data 0.000 (0.087) loss 1.5078 (1.5597) lr 1.3552e-02 eta 0:01:10
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it] 50%|█████     | 2/4 [00:02<00:02,  1.19s/it] 75%|███████▌  | 3/4 [00:03<00:00,  1.32it/s]100%|██████████| 4/4 [00:03<00:00,  1.93it/s]100%|██████████| 4/4 [00:03<00:00,  1.22it/s]=> result
* total: 696
* correct: 620
* accuracy: 89.1%
* error: 10.9%
* macro_f1: 87.7%

epoch [39/50] batch [2/12] time 0.395 (1.014) data 0.000 (0.595) loss 1.5654 (1.5093) lr 1.3552e-02 eta 0:02:24
epoch [39/50] batch [4/12] time 0.394 (0.704) data 0.000 (0.297) loss 1.5527 (1.5500) lr 1.3552e-02 eta 0:01:38
epoch [39/50] batch [6/12] time 0.395 (0.602) data 0.000 (0.198) loss 1.5176 (1.5464) lr 1.3552e-02 eta 0:01:23
epoch [39/50] batch [8/12] time 0.396 (0.550) data 0.000 (0.149) loss 1.5088 (1.5502) lr 1.3552e-02 eta 0:01:14
epoch [39/50] batch [10/12] time 0.396 (0.519) data 0.000 (0.119) loss 1.6045 (1.5677) lr 1.3552e-02 eta 0:01:09
epoch [39/50] batch [12/12] time 0.394 (0.499) data 0.000 (0.099) loss 1.5234 (1.5575) lr 1.1474e-02 eta 0:01:05
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 629
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 88.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [40/50] batch [2/12] time 0.413 (1.027) data 0.000 (0.576) loss 1.5225 (1.4849) lr 1.1474e-02 eta 0:02:13
epoch [40/50] batch [4/12] time 0.397 (0.712) data 0.000 (0.288) loss 1.5703 (1.4871) lr 1.1474e-02 eta 0:01:31
epoch [40/50] batch [6/12] time 0.396 (0.607) data 0.000 (0.192) loss 1.5898 (1.5234) lr 1.1474e-02 eta 0:01:16
epoch [40/50] batch [8/12] time 0.395 (0.554) data 0.000 (0.144) loss 1.4307 (1.5117) lr 1.1474e-02 eta 0:01:08
epoch [40/50] batch [10/12] time 0.394 (0.522) data 0.000 (0.115) loss 1.4863 (1.4975) lr 1.1474e-02 eta 0:01:03
epoch [40/50] batch [12/12] time 0.396 (0.501) data 0.000 (0.096) loss 1.5596 (1.5127) lr 9.5492e-03 eta 0:01:00
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 631
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 88.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model.pth.tar-40

epoch [41/50] batch [2/12] time 0.414 (0.990) data 0.000 (0.500) loss 1.6514 (1.6133) lr 9.5492e-03 eta 0:01:56
epoch [41/50] batch [4/12] time 0.394 (0.692) data 0.000 (0.250) loss 1.6191 (1.6096) lr 9.5492e-03 eta 0:01:20
epoch [41/50] batch [6/12] time 0.397 (0.593) data 0.000 (0.167) loss 1.5938 (1.6027) lr 9.5492e-03 eta 0:01:07
epoch [41/50] batch [8/12] time 0.397 (0.544) data 0.000 (0.125) loss 1.4570 (1.5552) lr 9.5492e-03 eta 0:01:00
epoch [41/50] batch [10/12] time 0.393 (0.514) data 0.000 (0.100) loss 1.4893 (1.5437) lr 9.5492e-03 eta 0:00:56
epoch [41/50] batch [12/12] time 0.393 (0.494) data 0.000 (0.084) loss 1.6221 (1.5484) lr 7.7836e-03 eta 0:00:53
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.44s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.26it/s]=> result
* total: 696
* correct: 630
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.0%

epoch [42/50] batch [2/12] time 0.393 (1.014) data 0.000 (0.610) loss 1.4004 (1.5078) lr 7.7836e-03 eta 0:01:47
epoch [42/50] batch [4/12] time 0.393 (0.704) data 0.000 (0.305) loss 1.5244 (1.5188) lr 7.7836e-03 eta 0:01:13
epoch [42/50] batch [6/12] time 0.393 (0.600) data 0.000 (0.203) loss 1.5957 (1.5272) lr 7.7836e-03 eta 0:01:01
epoch [42/50] batch [8/12] time 0.394 (0.549) data 0.000 (0.153) loss 1.5693 (1.5404) lr 7.7836e-03 eta 0:00:54
epoch [42/50] batch [10/12] time 0.393 (0.518) data 0.000 (0.122) loss 1.6387 (1.5511) lr 7.7836e-03 eta 0:00:50
epoch [42/50] batch [12/12] time 0.393 (0.497) data 0.000 (0.102) loss 1.6211 (1.5645) lr 6.1847e-03 eta 0:00:47
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.17s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 630
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.1%

epoch [43/50] batch [2/12] time 0.394 (0.997) data 0.000 (0.573) loss 1.4971 (1.5249) lr 6.1847e-03 eta 0:01:33
epoch [43/50] batch [4/12] time 0.393 (0.695) data 0.000 (0.286) loss 1.4795 (1.5374) lr 6.1847e-03 eta 0:01:03
epoch [43/50] batch [6/12] time 0.394 (0.595) data 0.000 (0.191) loss 1.5107 (1.5404) lr 6.1847e-03 eta 0:00:53
epoch [43/50] batch [8/12] time 0.393 (0.545) data 0.000 (0.143) loss 1.4678 (1.5378) lr 6.1847e-03 eta 0:00:47
epoch [43/50] batch [10/12] time 0.394 (0.514) data 0.000 (0.115) loss 1.5000 (1.5195) lr 6.1847e-03 eta 0:00:44
epoch [43/50] batch [12/12] time 0.395 (0.494) data 0.000 (0.096) loss 1.4824 (1.5094) lr 4.7586e-03 eta 0:00:41
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.46s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 629
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 88.9%

epoch [44/50] batch [2/12] time 0.395 (1.000) data 0.000 (0.571) loss 1.6230 (1.6030) lr 4.7586e-03 eta 0:01:21
epoch [44/50] batch [4/12] time 0.396 (0.697) data 0.000 (0.286) loss 1.5635 (1.5317) lr 4.7586e-03 eta 0:00:55
epoch [44/50] batch [6/12] time 0.394 (0.596) data 0.000 (0.190) loss 1.4609 (1.4987) lr 4.7586e-03 eta 0:00:46
epoch [44/50] batch [8/12] time 0.394 (0.546) data 0.000 (0.143) loss 1.6494 (1.5236) lr 4.7586e-03 eta 0:00:41
epoch [44/50] batch [10/12] time 0.394 (0.515) data 0.000 (0.114) loss 1.7422 (1.5453) lr 4.7586e-03 eta 0:00:38
epoch [44/50] batch [12/12] time 0.394 (0.495) data 0.000 (0.095) loss 1.4824 (1.5422) lr 3.5112e-03 eta 0:00:35
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.44s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 633
* accuracy: 90.9%
* error: 9.1%
* macro_f1: 89.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [45/50] batch [2/12] time 0.394 (1.006) data 0.000 (0.577) loss 1.5186 (1.5063) lr 3.5112e-03 eta 0:01:10
epoch [45/50] batch [4/12] time 0.393 (0.700) data 0.000 (0.289) loss 1.4404 (1.5117) lr 3.5112e-03 eta 0:00:47
epoch [45/50] batch [6/12] time 0.394 (0.598) data 0.000 (0.192) loss 1.4844 (1.5003) lr 3.5112e-03 eta 0:00:39
epoch [45/50] batch [8/12] time 0.396 (0.547) data 0.000 (0.144) loss 1.5293 (1.4905) lr 3.5112e-03 eta 0:00:35
epoch [45/50] batch [10/12] time 0.395 (0.517) data 0.000 (0.116) loss 1.6582 (1.5164) lr 3.5112e-03 eta 0:00:32
epoch [45/50] batch [12/12] time 0.395 (0.497) data 0.000 (0.096) loss 1.7217 (1.5278) lr 2.4472e-03 eta 0:00:29
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.45s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 629
* accuracy: 90.4%
* error: 9.6%
* macro_f1: 89.0%

epoch [46/50] batch [2/12] time 0.394 (1.101) data 0.000 (0.632) loss 1.5713 (1.5435) lr 2.4472e-03 eta 0:01:03
epoch [46/50] batch [4/12] time 0.394 (0.747) data 0.000 (0.316) loss 1.4561 (1.4883) lr 2.4472e-03 eta 0:00:41
epoch [46/50] batch [6/12] time 0.394 (0.630) data 0.000 (0.211) loss 1.4707 (1.5291) lr 2.4472e-03 eta 0:00:34
epoch [46/50] batch [8/12] time 0.397 (0.571) data 0.000 (0.158) loss 1.4912 (1.5311) lr 2.4472e-03 eta 0:00:29
epoch [46/50] batch [10/12] time 0.394 (0.536) data 0.000 (0.127) loss 1.4287 (1.5236) lr 2.4472e-03 eta 0:00:26
epoch [46/50] batch [12/12] time 0.394 (0.512) data 0.000 (0.105) loss 1.6191 (1.5321) lr 1.5708e-03 eta 0:00:24
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.48s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 631
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.4%

epoch [47/50] batch [2/12] time 0.401 (0.978) data 0.000 (0.497) loss 1.5098 (1.6099) lr 1.5708e-03 eta 0:00:44
epoch [47/50] batch [4/12] time 0.394 (0.686) data 0.000 (0.249) loss 1.5283 (1.5967) lr 1.5708e-03 eta 0:00:30
epoch [47/50] batch [6/12] time 0.393 (0.588) data 0.000 (0.166) loss 1.6338 (1.6024) lr 1.5708e-03 eta 0:00:24
epoch [47/50] batch [8/12] time 0.394 (0.540) data 0.000 (0.124) loss 1.6348 (1.5892) lr 1.5708e-03 eta 0:00:21
epoch [47/50] batch [10/12] time 0.394 (0.511) data 0.000 (0.100) loss 1.5713 (1.5902) lr 1.5708e-03 eta 0:00:19
epoch [47/50] batch [12/12] time 0.394 (0.491) data 0.000 (0.083) loss 1.5254 (1.5835) lr 8.8564e-04 eta 0:00:17
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.45s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.35it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.25it/s]=> result
* total: 696
* correct: 631
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.4%

epoch [48/50] batch [2/12] time 0.395 (1.015) data 0.000 (0.610) loss 1.5713 (1.5776) lr 8.8564e-04 eta 0:00:34
epoch [48/50] batch [4/12] time 0.396 (0.705) data 0.000 (0.305) loss 1.5312 (1.5342) lr 8.8564e-04 eta 0:00:22
epoch [48/50] batch [6/12] time 0.394 (0.601) data 0.000 (0.203) loss 1.5811 (1.5524) lr 8.8564e-04 eta 0:00:18
epoch [48/50] batch [8/12] time 0.394 (0.549) data 0.000 (0.153) loss 1.4277 (1.5298) lr 8.8564e-04 eta 0:00:15
epoch [48/50] batch [10/12] time 0.398 (0.519) data 0.000 (0.122) loss 1.4453 (1.5179) lr 8.8564e-04 eta 0:00:13
epoch [48/50] batch [12/12] time 0.399 (0.498) data 0.000 (0.102) loss 1.4062 (1.5112) lr 3.9426e-04 eta 0:00:11
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.44s/it] 50%|█████     | 2/4 [00:02<00:02,  1.15s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.36it/s]100%|██████████| 4/4 [00:03<00:00,  1.98it/s]100%|██████████| 4/4 [00:03<00:00,  1.26it/s]=> result
* total: 696
* correct: 630
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.3%

epoch [49/50] batch [2/12] time 0.397 (1.006) data 0.000 (0.584) loss 1.4775 (1.5186) lr 3.9426e-04 eta 0:00:22
epoch [49/50] batch [4/12] time 0.396 (0.701) data 0.000 (0.292) loss 1.6348 (1.5352) lr 3.9426e-04 eta 0:00:14
epoch [49/50] batch [6/12] time 0.395 (0.599) data 0.000 (0.195) loss 1.4746 (1.5290) lr 3.9426e-04 eta 0:00:10
epoch [49/50] batch [8/12] time 0.394 (0.548) data 0.000 (0.146) loss 1.5020 (1.5266) lr 3.9426e-04 eta 0:00:08
epoch [49/50] batch [10/12] time 0.396 (0.517) data 0.000 (0.117) loss 1.6133 (1.5412) lr 3.9426e-04 eta 0:00:07
epoch [49/50] batch [12/12] time 0.394 (0.497) data 0.000 (0.098) loss 1.7178 (1.5470) lr 9.8664e-05 eta 0:00:05
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.97it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]=> result
* total: 696
* correct: 630
* accuracy: 90.5%
* error: 9.5%
* macro_f1: 89.3%

epoch [50/50] batch [2/12] time 0.396 (1.009) data 0.000 (0.572) loss 1.4365 (1.5093) lr 9.8664e-05 eta 0:00:10
epoch [50/50] batch [4/12] time 0.392 (0.701) data 0.000 (0.286) loss 1.5322 (1.5750) lr 9.8664e-05 eta 0:00:05
epoch [50/50] batch [6/12] time 0.393 (0.598) data 0.000 (0.191) loss 1.4170 (1.5402) lr 9.8664e-05 eta 0:00:03
epoch [50/50] batch [8/12] time 0.392 (0.547) data 0.000 (0.143) loss 1.6162 (1.5547) lr 9.8664e-05 eta 0:00:02
epoch [50/50] batch [10/12] time 0.399 (0.516) data 0.002 (0.115) loss 1.4150 (1.5416) lr 9.8664e-05 eta 0:00:01
epoch [50/50] batch [12/12] time 0.396 (0.496) data 0.000 (0.096) loss 1.4336 (1.5208) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:02<00:07,  2.47s/it] 50%|█████     | 2/4 [00:02<00:02,  1.16s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]100%|██████████| 4/4 [00:03<00:00,  1.96it/s]100%|██████████| 4/4 [00:03<00:00,  1.24it/s]
=> result
* total: 696
* correct: 631
* accuracy: 90.7%
* error: 9.3%
* macro_f1: 89.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model.pth.tar-50
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar" (epoch = 44)
Evaluate on the *test* set
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:03<00:18,  3.70s/it] 33%|███▎      | 2/6 [00:03<00:06,  1.67s/it] 50%|█████     | 3/6 [00:04<00:03,  1.02s/it] 67%|██████▋   | 4/6 [00:04<00:01,  1.40it/s] 83%|████████▎ | 5/6 [00:04<00:00,  1.83it/s]100%|██████████| 6/6 [00:04<00:00,  2.53it/s]100%|██████████| 6/6 [00:04<00:00,  1.22it/s]
=> result
* total: 1,053
* correct: 989
* accuracy: 93.9%
* error: 6.1%
* macro_f1: 93.2%
Elapsed: 0:07:53
+ sh scripts/rpo_prime/base2new_test.sh oxford_flowers 3 0 main_tmp1 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/oxford_flowers.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordFlowers
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:OxfordFlowers
Loading dataset: OxfordFlowers
Reading split from /shared/s2/lab01/dataset/clip/oxford_flowers/split_zhou_OxfordFlowers.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_flowers/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
816 937 1410
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------
Dataset    OxfordFlowers
# classes  51
# train_x  816
# val      937
# test     1,410
---------  -------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/oxford_flowers/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar" (epoch = 44)
Evaluate on the *test* set
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:05<00:38,  5.50s/it] 25%|██▌       | 2/8 [00:05<00:14,  2.41s/it] 38%|███▊      | 3/8 [00:05<00:07,  1.42s/it] 50%|█████     | 4/8 [00:06<00:03,  1.05it/s] 62%|██████▎   | 5/8 [00:06<00:02,  1.43it/s] 75%|███████▌  | 6/8 [00:06<00:01,  1.84it/s] 88%|████████▊ | 7/8 [00:06<00:00,  2.24it/s]100%|██████████| 8/8 [00:07<00:00,  1.12it/s]
=> result
* total: 1,410
* correct: 1,048
* accuracy: 74.3%
* error: 25.7%
* macro_f1: 69.3%
+ for dataset in oxford_flowers stanford_cars oxford_pets food101 eurosat dtd sun397 ucf101 caltech101 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train.sh stanford_cars 1 0 main_tmp1 16
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE BASE CLASSES!
1568 812 4002
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      812
# test     4,002
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/50] batch [2/24] time 0.455 (2.290) data 0.001 (0.746) loss 2.7168 (3.0713) lr 1.0000e-01 eta 0:45:42
epoch [1/50] batch [4/24] time 0.425 (1.358) data 0.000 (0.373) loss 2.6680 (2.8564) lr 1.0000e-01 eta 0:27:04
epoch [1/50] batch [6/24] time 0.425 (1.047) data 0.000 (0.249) loss 2.4141 (2.7549) lr 1.0000e-01 eta 0:20:50
epoch [1/50] batch [8/24] time 0.425 (0.892) data 0.000 (0.187) loss 2.6367 (2.7202) lr 1.0000e-01 eta 0:17:42
epoch [1/50] batch [10/24] time 0.425 (0.799) data 0.000 (0.149) loss 2.3223 (2.6408) lr 1.0000e-01 eta 0:15:50
epoch [1/50] batch [12/24] time 0.426 (0.736) data 0.000 (0.125) loss 2.4961 (2.6149) lr 1.0000e-01 eta 0:14:34
epoch [1/50] batch [14/24] time 0.426 (0.693) data 0.000 (0.107) loss 2.4824 (2.5961) lr 1.0000e-01 eta 0:13:41
epoch [1/50] batch [16/24] time 0.429 (0.660) data 0.000 (0.093) loss 2.4160 (2.5847) lr 1.0000e-01 eta 0:13:01
epoch [1/50] batch [18/24] time 0.429 (0.634) data 0.000 (0.083) loss 2.3672 (2.5650) lr 1.0000e-01 eta 0:12:29
epoch [1/50] batch [20/24] time 0.428 (0.614) data 0.000 (0.075) loss 2.6309 (2.5623) lr 1.0000e-01 eta 0:12:04
epoch [1/50] batch [22/24] time 0.427 (0.597) data 0.000 (0.068) loss 2.6895 (2.5598) lr 1.0000e-01 eta 0:11:42
epoch [1/50] batch [24/24] time 0.430 (0.583) data 0.000 (0.062) loss 2.4531 (2.5557) lr 9.9901e-02 eta 0:11:25
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:04<00:18,  4.53s/it] 40%|████      | 2/5 [00:04<00:06,  2.02s/it] 60%|██████    | 3/5 [00:05<00:02,  1.22s/it] 80%|████████  | 4/5 [00:05<00:00,  1.19it/s]100%|██████████| 5/5 [00:05<00:00,  1.09s/it]=> result
* total: 812
* correct: 523
* accuracy: 64.4%
* error: 35.6%
* macro_f1: 62.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [2/50] batch [2/24] time 0.643 (1.304) data 0.000 (0.622) loss 2.3535 (2.4014) lr 9.9901e-02 eta 0:25:30
epoch [2/50] batch [4/24] time 0.423 (0.870) data 0.000 (0.311) loss 2.6211 (2.4883) lr 9.9901e-02 eta 0:16:59
epoch [2/50] batch [6/24] time 0.423 (0.721) data 0.000 (0.208) loss 2.4414 (2.4701) lr 9.9901e-02 eta 0:14:03
epoch [2/50] batch [8/24] time 0.423 (0.647) data 0.000 (0.156) loss 2.6797 (2.4924) lr 9.9901e-02 eta 0:12:35
epoch [2/50] batch [10/24] time 0.428 (0.604) data 0.000 (0.125) loss 2.4395 (2.4857) lr 9.9901e-02 eta 0:11:43
epoch [2/50] batch [12/24] time 0.424 (0.574) data 0.000 (0.104) loss 2.2754 (2.4751) lr 9.9901e-02 eta 0:11:07
epoch [2/50] batch [14/24] time 0.425 (0.553) data 0.000 (0.089) loss 2.6758 (2.4855) lr 9.9901e-02 eta 0:10:42
epoch [2/50] batch [16/24] time 0.427 (0.537) data 0.000 (0.078) loss 2.5781 (2.4875) lr 9.9901e-02 eta 0:10:22
epoch [2/50] batch [18/24] time 0.429 (0.525) data 0.000 (0.069) loss 2.4902 (2.4873) lr 9.9901e-02 eta 0:10:07
epoch [2/50] batch [20/24] time 0.427 (0.515) data 0.000 (0.062) loss 2.4062 (2.4753) lr 9.9901e-02 eta 0:09:55
epoch [2/50] batch [22/24] time 0.425 (0.507) data 0.000 (0.057) loss 2.4980 (2.4698) lr 9.9901e-02 eta 0:09:44
epoch [2/50] batch [24/24] time 0.424 (0.500) data 0.000 (0.052) loss 2.5938 (2.4730) lr 9.9606e-02 eta 0:09:36
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:13,  3.32s/it] 40%|████      | 2/5 [00:03<00:04,  1.53s/it] 60%|██████    | 3/5 [00:03<00:01,  1.05it/s] 80%|████████  | 4/5 [00:04<00:00,  1.48it/s]100%|██████████| 5/5 [00:04<00:00,  1.16it/s]=> result
* total: 812
* correct: 521
* accuracy: 64.2%
* error: 35.8%
* macro_f1: 62.3%

epoch [3/50] batch [2/24] time 0.642 (1.323) data 0.001 (0.620) loss 2.3633 (2.3613) lr 9.9606e-02 eta 0:25:20
epoch [3/50] batch [4/24] time 0.424 (0.875) data 0.000 (0.310) loss 2.3184 (2.3540) lr 9.9606e-02 eta 0:16:44
epoch [3/50] batch [6/24] time 0.534 (0.743) data 0.000 (0.207) loss 2.3555 (2.3646) lr 9.9606e-02 eta 0:14:11
epoch [3/50] batch [8/24] time 0.424 (0.664) data 0.000 (0.155) loss 2.3340 (2.3604) lr 9.9606e-02 eta 0:12:39
epoch [3/50] batch [10/24] time 0.425 (0.616) data 0.000 (0.124) loss 2.5566 (2.3896) lr 9.9606e-02 eta 0:11:43
epoch [3/50] batch [12/24] time 0.425 (0.584) data 0.000 (0.103) loss 2.5176 (2.4028) lr 9.9606e-02 eta 0:11:05
epoch [3/50] batch [14/24] time 0.424 (0.561) data 0.000 (0.089) loss 2.2617 (2.3870) lr 9.9606e-02 eta 0:10:38
epoch [3/50] batch [16/24] time 0.424 (0.544) data 0.000 (0.078) loss 2.5117 (2.4008) lr 9.9606e-02 eta 0:10:18
epoch [3/50] batch [18/24] time 0.431 (0.531) data 0.000 (0.069) loss 2.3340 (2.3870) lr 9.9606e-02 eta 0:10:02
epoch [3/50] batch [20/24] time 0.424 (0.521) data 0.000 (0.062) loss 2.4160 (2.3782) lr 9.9606e-02 eta 0:09:49
epoch [3/50] batch [22/24] time 0.428 (0.512) data 0.000 (0.057) loss 2.3887 (2.3876) lr 9.9606e-02 eta 0:09:38
epoch [3/50] batch [24/24] time 0.424 (0.505) data 0.000 (0.052) loss 2.3496 (2.3787) lr 9.9114e-02 eta 0:09:29
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.22s/it] 40%|████      | 2/5 [00:03<00:04,  1.52s/it] 60%|██████    | 3/5 [00:03<00:01,  1.06it/s] 80%|████████  | 4/5 [00:04<00:00,  1.48it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 517
* accuracy: 63.7%
* error: 36.3%
* macro_f1: 61.7%

epoch [4/50] batch [2/24] time 0.525 (1.358) data 0.000 (0.713) loss 2.2598 (2.2852) lr 9.9114e-02 eta 0:25:29
epoch [4/50] batch [4/24] time 0.426 (0.892) data 0.000 (0.356) loss 2.2402 (2.3867) lr 9.9114e-02 eta 0:16:42
epoch [4/50] batch [6/24] time 0.426 (0.737) data 0.000 (0.238) loss 2.4805 (2.4007) lr 9.9114e-02 eta 0:13:46
epoch [4/50] batch [8/24] time 0.424 (0.658) data 0.000 (0.178) loss 2.3184 (2.3896) lr 9.9114e-02 eta 0:12:17
epoch [4/50] batch [10/24] time 0.424 (0.612) data 0.000 (0.143) loss 2.2031 (2.3803) lr 9.9114e-02 eta 0:11:23
epoch [4/50] batch [12/24] time 0.425 (0.580) data 0.000 (0.119) loss 2.2695 (2.3805) lr 9.9114e-02 eta 0:10:47
epoch [4/50] batch [14/24] time 0.424 (0.558) data 0.000 (0.102) loss 2.4297 (2.3747) lr 9.9114e-02 eta 0:10:21
epoch [4/50] batch [16/24] time 0.424 (0.542) data 0.000 (0.089) loss 2.4199 (2.3850) lr 9.9114e-02 eta 0:10:02
epoch [4/50] batch [18/24] time 0.424 (0.529) data 0.000 (0.079) loss 2.3203 (2.3830) lr 9.9114e-02 eta 0:09:46
epoch [4/50] batch [20/24] time 0.425 (0.518) data 0.000 (0.071) loss 2.6562 (2.3942) lr 9.9114e-02 eta 0:09:34
epoch [4/50] batch [22/24] time 0.431 (0.510) data 0.000 (0.065) loss 2.4062 (2.4018) lr 9.9114e-02 eta 0:09:24
epoch [4/50] batch [24/24] time 0.425 (0.503) data 0.000 (0.060) loss 2.3105 (2.3997) lr 9.8429e-02 eta 0:09:15
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:13,  3.27s/it] 40%|████      | 2/5 [00:03<00:04,  1.50s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.49it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 528
* accuracy: 65.0%
* error: 35.0%
* macro_f1: 63.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [5/50] batch [2/24] time 0.439 (1.397) data 0.000 (0.821) loss 2.4160 (2.4404) lr 9.8429e-02 eta 0:25:39
epoch [5/50] batch [4/24] time 0.434 (0.913) data 0.000 (0.411) loss 2.5215 (2.3960) lr 9.8429e-02 eta 0:16:44
epoch [5/50] batch [6/24] time 0.426 (0.751) data 0.000 (0.274) loss 2.6035 (2.3994) lr 9.8429e-02 eta 0:13:44
epoch [5/50] batch [8/24] time 0.426 (0.670) data 0.000 (0.205) loss 2.1758 (2.3936) lr 9.8429e-02 eta 0:12:14
epoch [5/50] batch [10/24] time 0.430 (0.621) data 0.000 (0.164) loss 2.2168 (2.3631) lr 9.8429e-02 eta 0:11:19
epoch [5/50] batch [12/24] time 0.425 (0.589) data 0.000 (0.137) loss 2.5234 (2.3690) lr 9.8429e-02 eta 0:10:42
epoch [5/50] batch [14/24] time 0.429 (0.566) data 0.000 (0.117) loss 2.1543 (2.3412) lr 9.8429e-02 eta 0:10:16
epoch [5/50] batch [16/24] time 0.426 (0.548) data 0.000 (0.103) loss 2.4512 (2.3494) lr 9.8429e-02 eta 0:09:56
epoch [5/50] batch [18/24] time 0.432 (0.535) data 0.000 (0.091) loss 2.2305 (2.3420) lr 9.8429e-02 eta 0:09:41
epoch [5/50] batch [20/24] time 0.425 (0.524) data 0.000 (0.082) loss 2.3223 (2.3399) lr 9.8429e-02 eta 0:09:28
epoch [5/50] batch [22/24] time 0.434 (0.516) data 0.000 (0.075) loss 2.1992 (2.3263) lr 9.8429e-02 eta 0:09:17
epoch [5/50] batch [24/24] time 0.426 (0.508) data 0.000 (0.069) loss 2.3301 (2.3288) lr 9.7553e-02 eta 0:09:08
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 531
* accuracy: 65.4%
* error: 34.6%
* macro_f1: 63.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [6/50] batch [2/24] time 0.670 (1.281) data 0.000 (0.555) loss 2.2598 (2.3027) lr 9.7553e-02 eta 0:23:00
epoch [6/50] batch [4/24] time 0.426 (0.868) data 0.000 (0.277) loss 2.2988 (2.3203) lr 9.7553e-02 eta 0:15:33
epoch [6/50] batch [6/24] time 0.427 (0.721) data 0.000 (0.185) loss 2.3340 (2.3105) lr 9.7553e-02 eta 0:12:54
epoch [6/50] batch [8/24] time 0.428 (0.648) data 0.000 (0.139) loss 2.3203 (2.3118) lr 9.7553e-02 eta 0:11:34
epoch [6/50] batch [10/24] time 0.426 (0.604) data 0.000 (0.111) loss 2.3301 (2.3055) lr 9.7553e-02 eta 0:10:45
epoch [6/50] batch [12/24] time 0.426 (0.574) data 0.000 (0.093) loss 2.4355 (2.3177) lr 9.7553e-02 eta 0:10:13
epoch [6/50] batch [14/24] time 0.426 (0.553) data 0.000 (0.079) loss 2.5156 (2.3237) lr 9.7553e-02 eta 0:09:49
epoch [6/50] batch [16/24] time 0.425 (0.537) data 0.000 (0.070) loss 2.3379 (2.3219) lr 9.7553e-02 eta 0:09:31
epoch [6/50] batch [18/24] time 0.431 (0.525) data 0.000 (0.062) loss 2.3594 (2.3273) lr 9.7553e-02 eta 0:09:17
epoch [6/50] batch [20/24] time 0.427 (0.515) data 0.000 (0.056) loss 2.1719 (2.3164) lr 9.7553e-02 eta 0:09:06
epoch [6/50] batch [22/24] time 0.426 (0.507) data 0.000 (0.051) loss 2.4043 (2.3236) lr 9.7553e-02 eta 0:08:56
epoch [6/50] batch [24/24] time 0.426 (0.501) data 0.000 (0.046) loss 2.2930 (2.3101) lr 9.6489e-02 eta 0:08:48
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 536
* accuracy: 66.0%
* error: 34.0%
* macro_f1: 64.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [7/50] batch [2/24] time 0.586 (1.331) data 0.000 (0.661) loss 2.4121 (2.3652) lr 9.6489e-02 eta 0:23:22
epoch [7/50] batch [4/24] time 0.426 (0.883) data 0.000 (0.330) loss 2.2324 (2.3262) lr 9.6489e-02 eta 0:15:28
epoch [7/50] batch [6/24] time 0.429 (0.732) data 0.000 (0.220) loss 2.3418 (2.3158) lr 9.6489e-02 eta 0:12:48
epoch [7/50] batch [8/24] time 0.426 (0.656) data 0.000 (0.165) loss 2.3535 (2.3293) lr 9.6489e-02 eta 0:11:27
epoch [7/50] batch [10/24] time 0.426 (0.610) data 0.000 (0.132) loss 2.4141 (2.3451) lr 9.6489e-02 eta 0:10:37
epoch [7/50] batch [12/24] time 0.427 (0.579) data 0.000 (0.110) loss 2.5098 (2.3517) lr 9.6489e-02 eta 0:10:04
epoch [7/50] batch [14/24] time 0.426 (0.558) data 0.000 (0.095) loss 2.5586 (2.3577) lr 9.6489e-02 eta 0:09:41
epoch [7/50] batch [16/24] time 0.511 (0.546) data 0.000 (0.083) loss 2.2207 (2.3435) lr 9.6489e-02 eta 0:09:28
epoch [7/50] batch [18/24] time 0.426 (0.533) data 0.000 (0.074) loss 2.4238 (2.3439) lr 9.6489e-02 eta 0:09:13
epoch [7/50] batch [20/24] time 0.426 (0.523) data 0.000 (0.066) loss 2.5117 (2.3577) lr 9.6489e-02 eta 0:09:01
epoch [7/50] batch [22/24] time 0.426 (0.514) data 0.000 (0.060) loss 2.4902 (2.3685) lr 9.6489e-02 eta 0:08:51
epoch [7/50] batch [24/24] time 0.427 (0.507) data 0.000 (0.055) loss 2.5039 (2.3707) lr 9.5241e-02 eta 0:08:42
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 530
* accuracy: 65.3%
* error: 34.7%
* macro_f1: 63.4%

epoch [8/50] batch [2/24] time 0.633 (1.259) data 0.000 (0.579) loss 2.4199 (2.4922) lr 9.5241e-02 eta 0:21:36
epoch [8/50] batch [4/24] time 0.427 (0.845) data 0.000 (0.289) loss 2.5156 (2.4546) lr 9.5241e-02 eta 0:14:28
epoch [8/50] batch [6/24] time 0.431 (0.706) data 0.000 (0.193) loss 2.1523 (2.3750) lr 9.5241e-02 eta 0:12:04
epoch [8/50] batch [8/24] time 0.426 (0.636) data 0.000 (0.145) loss 2.2148 (2.3228) lr 9.5241e-02 eta 0:10:51
epoch [8/50] batch [10/24] time 0.425 (0.594) data 0.000 (0.116) loss 2.2305 (2.3229) lr 9.5241e-02 eta 0:10:07
epoch [8/50] batch [12/24] time 0.427 (0.566) data 0.000 (0.097) loss 2.3262 (2.3255) lr 9.5241e-02 eta 0:09:37
epoch [8/50] batch [14/24] time 0.425 (0.546) data 0.000 (0.083) loss 2.1855 (2.3184) lr 9.5241e-02 eta 0:09:15
epoch [8/50] batch [16/24] time 0.425 (0.531) data 0.000 (0.073) loss 2.2695 (2.3143) lr 9.5241e-02 eta 0:08:59
epoch [8/50] batch [18/24] time 0.434 (0.520) data 0.000 (0.064) loss 2.2871 (2.3065) lr 9.5241e-02 eta 0:08:47
epoch [8/50] batch [20/24] time 0.425 (0.510) data 0.000 (0.058) loss 2.2520 (2.3042) lr 9.5241e-02 eta 0:08:36
epoch [8/50] batch [22/24] time 0.426 (0.503) data 0.000 (0.053) loss 2.2305 (2.2980) lr 9.5241e-02 eta 0:08:27
epoch [8/50] batch [24/24] time 0.426 (0.496) data 0.000 (0.048) loss 2.3965 (2.3079) lr 9.3815e-02 eta 0:08:20
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 547
* accuracy: 67.4%
* error: 32.6%
* macro_f1: 65.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [9/50] batch [2/24] time 0.575 (1.326) data 0.000 (0.668) loss 2.2324 (2.2373) lr 9.3815e-02 eta 0:22:13
epoch [9/50] batch [4/24] time 0.427 (0.877) data 0.000 (0.334) loss 2.1914 (2.2334) lr 9.3815e-02 eta 0:14:40
epoch [9/50] batch [6/24] time 0.426 (0.727) data 0.000 (0.223) loss 2.3242 (2.2721) lr 9.3815e-02 eta 0:12:08
epoch [9/50] batch [8/24] time 0.432 (0.653) data 0.000 (0.167) loss 2.4590 (2.2930) lr 9.3815e-02 eta 0:10:52
epoch [9/50] batch [10/24] time 0.429 (0.608) data 0.000 (0.134) loss 2.1875 (2.2734) lr 9.3815e-02 eta 0:10:06
epoch [9/50] batch [12/24] time 0.428 (0.578) data 0.000 (0.111) loss 2.3105 (2.2925) lr 9.3815e-02 eta 0:09:35
epoch [9/50] batch [14/24] time 0.428 (0.556) data 0.000 (0.096) loss 2.2363 (2.2842) lr 9.3815e-02 eta 0:09:12
epoch [9/50] batch [16/24] time 0.427 (0.540) data 0.000 (0.084) loss 2.4902 (2.2999) lr 9.3815e-02 eta 0:08:55
epoch [9/50] batch [18/24] time 0.425 (0.527) data 0.000 (0.074) loss 2.4102 (2.3127) lr 9.3815e-02 eta 0:08:41
epoch [9/50] batch [20/24] time 0.428 (0.517) data 0.000 (0.067) loss 2.1387 (2.3031) lr 9.3815e-02 eta 0:08:31
epoch [9/50] batch [22/24] time 0.426 (0.509) data 0.000 (0.061) loss 2.2305 (2.2950) lr 9.3815e-02 eta 0:08:21
epoch [9/50] batch [24/24] time 0.425 (0.502) data 0.000 (0.056) loss 2.4883 (2.3114) lr 9.2216e-02 eta 0:08:14
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 537
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 64.4%

epoch [10/50] batch [2/24] time 0.679 (1.264) data 0.000 (0.543) loss 2.2754 (2.4004) lr 9.2216e-02 eta 0:20:41
epoch [10/50] batch [4/24] time 0.426 (0.850) data 0.000 (0.271) loss 2.4062 (2.3984) lr 9.2216e-02 eta 0:13:52
epoch [10/50] batch [6/24] time 0.426 (0.708) data 0.000 (0.181) loss 2.1836 (2.3216) lr 9.2216e-02 eta 0:11:32
epoch [10/50] batch [8/24] time 0.426 (0.638) data 0.000 (0.136) loss 2.3379 (2.3145) lr 9.2216e-02 eta 0:10:22
epoch [10/50] batch [10/24] time 0.428 (0.596) data 0.000 (0.109) loss 2.2598 (2.3047) lr 9.2216e-02 eta 0:09:40
epoch [10/50] batch [12/24] time 0.426 (0.567) data 0.000 (0.091) loss 2.3398 (2.3068) lr 9.2216e-02 eta 0:09:11
epoch [10/50] batch [14/24] time 0.428 (0.547) data 0.000 (0.078) loss 2.2656 (2.2980) lr 9.2216e-02 eta 0:08:51
epoch [10/50] batch [16/24] time 0.425 (0.532) data 0.000 (0.068) loss 2.2285 (2.2838) lr 9.2216e-02 eta 0:08:35
epoch [10/50] batch [18/24] time 0.426 (0.521) data 0.000 (0.060) loss 2.1445 (2.2742) lr 9.2216e-02 eta 0:08:22
epoch [10/50] batch [20/24] time 0.425 (0.511) data 0.000 (0.054) loss 2.3184 (2.2808) lr 9.2216e-02 eta 0:08:12
epoch [10/50] batch [22/24] time 0.426 (0.503) data 0.000 (0.050) loss 2.2207 (2.2810) lr 9.2216e-02 eta 0:08:04
epoch [10/50] batch [24/24] time 0.427 (0.497) data 0.000 (0.045) loss 2.3125 (2.2911) lr 9.0451e-02 eta 0:07:57
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.50s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 543
* accuracy: 66.9%
* error: 33.1%
* macro_f1: 65.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model.pth.tar-10

epoch [11/50] batch [2/24] time 0.441 (1.475) data 0.000 (0.960) loss 2.4121 (2.3906) lr 9.0451e-02 eta 0:23:32
epoch [11/50] batch [4/24] time 0.425 (0.951) data 0.000 (0.480) loss 2.2578 (2.3198) lr 9.0451e-02 eta 0:15:09
epoch [11/50] batch [6/24] time 0.425 (0.776) data 0.000 (0.320) loss 2.5352 (2.3571) lr 9.0451e-02 eta 0:12:20
epoch [11/50] batch [8/24] time 0.425 (0.688) data 0.000 (0.240) loss 2.2852 (2.3406) lr 9.0451e-02 eta 0:10:54
epoch [11/50] batch [10/24] time 0.425 (0.636) data 0.000 (0.192) loss 2.4258 (2.3605) lr 9.0451e-02 eta 0:10:04
epoch [11/50] batch [12/24] time 0.425 (0.601) data 0.000 (0.160) loss 2.3477 (2.3685) lr 9.0451e-02 eta 0:09:29
epoch [11/50] batch [14/24] time 0.425 (0.576) data 0.000 (0.137) loss 2.2793 (2.3605) lr 9.0451e-02 eta 0:09:04
epoch [11/50] batch [16/24] time 0.426 (0.557) data 0.000 (0.120) loss 2.2031 (2.3473) lr 9.0451e-02 eta 0:08:45
epoch [11/50] batch [18/24] time 0.425 (0.542) data 0.000 (0.107) loss 2.4141 (2.3492) lr 9.0451e-02 eta 0:08:30
epoch [11/50] batch [20/24] time 0.424 (0.531) data 0.000 (0.096) loss 2.2422 (2.3317) lr 9.0451e-02 eta 0:08:18
epoch [11/50] batch [22/24] time 0.424 (0.521) data 0.000 (0.087) loss 2.3301 (2.3293) lr 9.0451e-02 eta 0:08:08
epoch [11/50] batch [24/24] time 0.434 (0.513) data 0.000 (0.080) loss 2.4336 (2.3351) lr 8.8526e-02 eta 0:08:00
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 550
* accuracy: 67.7%
* error: 32.3%
* macro_f1: 66.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [12/50] batch [2/24] time 0.529 (1.438) data 0.000 (0.857) loss 2.2402 (2.1885) lr 8.8526e-02 eta 0:22:23
epoch [12/50] batch [4/24] time 0.424 (0.933) data 0.000 (0.429) loss 2.2832 (2.2725) lr 8.8526e-02 eta 0:14:29
epoch [12/50] batch [6/24] time 0.425 (0.764) data 0.000 (0.286) loss 2.3027 (2.2783) lr 8.8526e-02 eta 0:11:50
epoch [12/50] batch [8/24] time 0.424 (0.680) data 0.000 (0.214) loss 2.4023 (2.2991) lr 8.8526e-02 eta 0:10:30
epoch [12/50] batch [10/24] time 0.425 (0.629) data 0.000 (0.172) loss 2.3887 (2.3090) lr 8.8526e-02 eta 0:09:42
epoch [12/50] batch [12/24] time 0.427 (0.595) data 0.000 (0.143) loss 2.3555 (2.3018) lr 8.8526e-02 eta 0:09:09
epoch [12/50] batch [14/24] time 0.428 (0.571) data 0.000 (0.123) loss 2.2324 (2.2892) lr 8.8526e-02 eta 0:08:46
epoch [12/50] batch [16/24] time 0.424 (0.552) data 0.000 (0.107) loss 2.2988 (2.2889) lr 8.8526e-02 eta 0:08:28
epoch [12/50] batch [18/24] time 0.424 (0.538) data 0.000 (0.095) loss 2.2812 (2.2828) lr 8.8526e-02 eta 0:08:14
epoch [12/50] batch [20/24] time 0.424 (0.527) data 0.000 (0.086) loss 2.1270 (2.2752) lr 8.8526e-02 eta 0:08:02
epoch [12/50] batch [22/24] time 0.424 (0.518) data 0.000 (0.078) loss 2.0977 (2.2749) lr 8.8526e-02 eta 0:07:53
epoch [12/50] batch [24/24] time 0.428 (0.510) data 0.000 (0.072) loss 2.4141 (2.2932) lr 8.6448e-02 eta 0:07:45
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 547
* accuracy: 67.4%
* error: 32.6%
* macro_f1: 65.5%

epoch [13/50] batch [2/24] time 0.537 (1.330) data 0.001 (0.685) loss 2.4883 (2.4248) lr 8.6448e-02 eta 0:20:09
epoch [13/50] batch [4/24] time 0.427 (0.907) data 0.000 (0.343) loss 2.2695 (2.3589) lr 8.6448e-02 eta 0:13:43
epoch [13/50] batch [6/24] time 0.426 (0.747) data 0.000 (0.229) loss 2.2715 (2.3643) lr 8.6448e-02 eta 0:11:16
epoch [13/50] batch [8/24] time 0.425 (0.666) data 0.000 (0.171) loss 2.2637 (2.3440) lr 8.6448e-02 eta 0:10:02
epoch [13/50] batch [10/24] time 0.427 (0.618) data 0.000 (0.137) loss 2.2461 (2.3383) lr 8.6448e-02 eta 0:09:17
epoch [13/50] batch [12/24] time 0.425 (0.586) data 0.000 (0.114) loss 2.2539 (2.3224) lr 8.6448e-02 eta 0:08:47
epoch [13/50] batch [14/24] time 0.425 (0.563) data 0.000 (0.098) loss 2.2617 (2.3167) lr 8.6448e-02 eta 0:08:25
epoch [13/50] batch [16/24] time 0.426 (0.546) data 0.000 (0.086) loss 2.3359 (2.3065) lr 8.6448e-02 eta 0:08:09
epoch [13/50] batch [18/24] time 0.425 (0.533) data 0.000 (0.076) loss 2.2344 (2.2925) lr 8.6448e-02 eta 0:07:56
epoch [13/50] batch [20/24] time 0.429 (0.522) data 0.000 (0.069) loss 2.3887 (2.2966) lr 8.6448e-02 eta 0:07:45
epoch [13/50] batch [22/24] time 0.426 (0.513) data 0.000 (0.062) loss 2.4219 (2.2940) lr 8.6448e-02 eta 0:07:36
epoch [13/50] batch [24/24] time 0.426 (0.506) data 0.000 (0.057) loss 2.4062 (2.2974) lr 8.4227e-02 eta 0:07:29
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 550
* accuracy: 67.7%
* error: 32.3%
* macro_f1: 66.1%

epoch [14/50] batch [2/24] time 0.507 (1.375) data 0.000 (0.733) loss 2.4004 (2.3096) lr 8.4227e-02 eta 0:20:17
epoch [14/50] batch [4/24] time 0.424 (0.900) data 0.000 (0.367) loss 2.0703 (2.2427) lr 8.4227e-02 eta 0:13:15
epoch [14/50] batch [6/24] time 0.424 (0.741) data 0.000 (0.244) loss 2.2949 (2.2744) lr 8.4227e-02 eta 0:10:53
epoch [14/50] batch [8/24] time 0.428 (0.663) data 0.000 (0.183) loss 2.1621 (2.2708) lr 8.4227e-02 eta 0:09:43
epoch [14/50] batch [10/24] time 0.428 (0.616) data 0.000 (0.147) loss 2.3711 (2.2715) lr 8.4227e-02 eta 0:09:00
epoch [14/50] batch [12/24] time 0.432 (0.584) data 0.000 (0.122) loss 2.2793 (2.2697) lr 8.4227e-02 eta 0:08:31
epoch [14/50] batch [14/24] time 0.424 (0.562) data 0.000 (0.105) loss 2.3184 (2.2716) lr 8.4227e-02 eta 0:08:10
epoch [14/50] batch [16/24] time 0.424 (0.544) data 0.000 (0.092) loss 2.2266 (2.2751) lr 8.4227e-02 eta 0:07:54
epoch [14/50] batch [18/24] time 0.424 (0.531) data 0.000 (0.082) loss 2.3691 (2.2900) lr 8.4227e-02 eta 0:07:42
epoch [14/50] batch [20/24] time 0.424 (0.520) data 0.000 (0.073) loss 2.2266 (2.2926) lr 8.4227e-02 eta 0:07:31
epoch [14/50] batch [22/24] time 0.424 (0.512) data 0.000 (0.067) loss 2.4277 (2.3022) lr 8.4227e-02 eta 0:07:23
epoch [14/50] batch [24/24] time 0.430 (0.505) data 0.000 (0.061) loss 2.2305 (2.2990) lr 8.1871e-02 eta 0:07:15
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 549
* accuracy: 67.6%
* error: 32.4%
* macro_f1: 66.1%

epoch [15/50] batch [2/24] time 0.621 (1.206) data 0.000 (0.532) loss 2.1816 (2.2100) lr 8.1871e-02 eta 0:17:19
epoch [15/50] batch [4/24] time 0.432 (0.838) data 0.000 (0.266) loss 2.4082 (2.3511) lr 8.1871e-02 eta 0:12:00
epoch [15/50] batch [6/24] time 0.429 (0.702) data 0.000 (0.177) loss 2.3516 (2.3516) lr 8.1871e-02 eta 0:10:02
epoch [15/50] batch [8/24] time 0.425 (0.633) data 0.000 (0.133) loss 2.3965 (2.3608) lr 8.1871e-02 eta 0:09:01
epoch [15/50] batch [10/24] time 0.427 (0.591) data 0.000 (0.106) loss 2.3438 (2.3336) lr 8.1871e-02 eta 0:08:25
epoch [15/50] batch [12/24] time 0.428 (0.565) data 0.000 (0.089) loss 2.3945 (2.3405) lr 8.1871e-02 eta 0:08:01
epoch [15/50] batch [14/24] time 0.425 (0.545) data 0.000 (0.076) loss 2.3223 (2.3424) lr 8.1871e-02 eta 0:07:43
epoch [15/50] batch [16/24] time 0.426 (0.530) data 0.000 (0.067) loss 2.3340 (2.3367) lr 8.1871e-02 eta 0:07:29
epoch [15/50] batch [18/24] time 0.426 (0.518) data 0.000 (0.059) loss 2.2402 (2.3350) lr 8.1871e-02 eta 0:07:18
epoch [15/50] batch [20/24] time 0.428 (0.509) data 0.000 (0.053) loss 2.2422 (2.3334) lr 8.1871e-02 eta 0:07:09
epoch [15/50] batch [22/24] time 0.426 (0.502) data 0.000 (0.049) loss 2.3359 (2.3360) lr 8.1871e-02 eta 0:07:02
epoch [15/50] batch [24/24] time 0.425 (0.495) data 0.000 (0.044) loss 2.4551 (2.3361) lr 7.9389e-02 eta 0:06:56
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 548
* accuracy: 67.5%
* error: 32.5%
* macro_f1: 66.0%

epoch [16/50] batch [2/24] time 0.494 (1.371) data 0.000 (0.730) loss 2.3359 (2.2471) lr 7.9389e-02 eta 0:19:09
epoch [16/50] batch [4/24] time 0.429 (0.902) data 0.000 (0.365) loss 2.3027 (2.2646) lr 7.9389e-02 eta 0:12:33
epoch [16/50] batch [6/24] time 0.426 (0.743) data 0.000 (0.243) loss 2.0820 (2.2152) lr 7.9389e-02 eta 0:10:19
epoch [16/50] batch [8/24] time 0.425 (0.664) data 0.000 (0.183) loss 2.2012 (2.2112) lr 7.9389e-02 eta 0:09:12
epoch [16/50] batch [10/24] time 0.427 (0.616) data 0.000 (0.146) loss 2.3770 (2.2322) lr 7.9389e-02 eta 0:08:31
epoch [16/50] batch [12/24] time 0.425 (0.584) data 0.000 (0.122) loss 2.1914 (2.2189) lr 7.9389e-02 eta 0:08:03
epoch [16/50] batch [14/24] time 0.426 (0.562) data 0.000 (0.104) loss 2.4043 (2.2397) lr 7.9389e-02 eta 0:07:44
epoch [16/50] batch [16/24] time 0.426 (0.545) data 0.000 (0.091) loss 2.3047 (2.2323) lr 7.9389e-02 eta 0:07:28
epoch [16/50] batch [18/24] time 0.427 (0.532) data 0.000 (0.081) loss 2.4668 (2.2528) lr 7.9389e-02 eta 0:07:17
epoch [16/50] batch [20/24] time 0.426 (0.521) data 0.000 (0.073) loss 2.0508 (2.2499) lr 7.9389e-02 eta 0:07:07
epoch [16/50] batch [22/24] time 0.425 (0.512) data 0.000 (0.067) loss 2.3516 (2.2621) lr 7.9389e-02 eta 0:06:59
epoch [16/50] batch [24/24] time 0.426 (0.505) data 0.000 (0.061) loss 2.4121 (2.2757) lr 7.6791e-02 eta 0:06:52
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.23s/it] 40%|████      | 2/5 [00:03<00:04,  1.50s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.49it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 552
* accuracy: 68.0%
* error: 32.0%
* macro_f1: 66.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [17/50] batch [2/24] time 0.548 (1.323) data 0.000 (0.647) loss 2.1328 (2.3096) lr 7.6791e-02 eta 0:17:57
epoch [17/50] batch [4/24] time 0.425 (0.876) data 0.000 (0.323) loss 2.3359 (2.3301) lr 7.6791e-02 eta 0:11:51
epoch [17/50] batch [6/24] time 0.428 (0.727) data 0.000 (0.216) loss 2.1875 (2.3154) lr 7.6791e-02 eta 0:09:48
epoch [17/50] batch [8/24] time 0.426 (0.652) data 0.000 (0.162) loss 2.1484 (2.2791) lr 7.6791e-02 eta 0:08:46
epoch [17/50] batch [10/24] time 0.426 (0.607) data 0.000 (0.129) loss 2.2871 (2.3133) lr 7.6791e-02 eta 0:08:08
epoch [17/50] batch [12/24] time 0.426 (0.577) data 0.000 (0.108) loss 2.2480 (2.3052) lr 7.6791e-02 eta 0:07:43
epoch [17/50] batch [14/24] time 0.427 (0.555) data 0.000 (0.093) loss 2.3398 (2.3182) lr 7.6791e-02 eta 0:07:25
epoch [17/50] batch [16/24] time 0.427 (0.539) data 0.000 (0.081) loss 2.3242 (2.3196) lr 7.6791e-02 eta 0:07:11
epoch [17/50] batch [18/24] time 0.428 (0.527) data 0.000 (0.072) loss 2.3418 (2.3175) lr 7.6791e-02 eta 0:07:00
epoch [17/50] batch [20/24] time 0.426 (0.517) data 0.000 (0.065) loss 2.2207 (2.2970) lr 7.6791e-02 eta 0:06:51
epoch [17/50] batch [22/24] time 0.426 (0.509) data 0.000 (0.059) loss 2.1445 (2.2895) lr 7.6791e-02 eta 0:06:43
epoch [17/50] batch [24/24] time 0.429 (0.502) data 0.000 (0.054) loss 2.3438 (2.2948) lr 7.4088e-02 eta 0:06:37
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 546
* accuracy: 67.2%
* error: 32.8%
* macro_f1: 65.9%

epoch [18/50] batch [2/24] time 0.678 (1.213) data 0.001 (0.510) loss 2.3789 (2.4336) lr 7.4088e-02 eta 0:15:58
epoch [18/50] batch [4/24] time 0.433 (0.840) data 0.000 (0.255) loss 2.3223 (2.3784) lr 7.4088e-02 eta 0:11:01
epoch [18/50] batch [6/24] time 0.426 (0.702) data 0.000 (0.170) loss 2.1660 (2.3363) lr 7.4088e-02 eta 0:09:11
epoch [18/50] batch [8/24] time 0.426 (0.633) data 0.000 (0.128) loss 2.1016 (2.3030) lr 7.4088e-02 eta 0:08:16
epoch [18/50] batch [10/24] time 0.427 (0.592) data 0.000 (0.102) loss 2.3066 (2.3172) lr 7.4088e-02 eta 0:07:42
epoch [18/50] batch [12/24] time 0.425 (0.564) data 0.000 (0.085) loss 2.1133 (2.3076) lr 7.4088e-02 eta 0:07:19
epoch [18/50] batch [14/24] time 0.432 (0.545) data 0.000 (0.073) loss 2.5547 (2.3195) lr 7.4088e-02 eta 0:07:03
epoch [18/50] batch [16/24] time 0.425 (0.530) data 0.000 (0.064) loss 2.1504 (2.3016) lr 7.4088e-02 eta 0:06:51
epoch [18/50] batch [18/24] time 0.425 (0.518) data 0.000 (0.057) loss 2.3535 (2.3016) lr 7.4088e-02 eta 0:06:41
epoch [18/50] batch [20/24] time 0.513 (0.513) data 0.000 (0.051) loss 2.2363 (2.2959) lr 7.4088e-02 eta 0:06:36
epoch [18/50] batch [22/24] time 0.426 (0.505) data 0.000 (0.047) loss 2.1602 (2.2830) lr 7.4088e-02 eta 0:06:29
epoch [18/50] batch [24/24] time 0.426 (0.499) data 0.000 (0.043) loss 2.4102 (2.2795) lr 7.1289e-02 eta 0:06:22
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 557
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 67.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [19/50] batch [2/24] time 0.569 (1.330) data 0.000 (0.644) loss 2.2500 (2.1865) lr 7.1289e-02 eta 0:16:58
epoch [19/50] batch [4/24] time 0.426 (0.879) data 0.000 (0.322) loss 2.4570 (2.2646) lr 7.1289e-02 eta 0:11:11
epoch [19/50] batch [6/24] time 0.428 (0.728) data 0.000 (0.215) loss 2.2520 (2.2464) lr 7.1289e-02 eta 0:09:14
epoch [19/50] batch [8/24] time 0.424 (0.652) data 0.000 (0.161) loss 2.4844 (2.2954) lr 7.1289e-02 eta 0:08:15
epoch [19/50] batch [10/24] time 0.424 (0.607) data 0.000 (0.129) loss 2.4043 (2.2943) lr 7.1289e-02 eta 0:07:40
epoch [19/50] batch [12/24] time 0.427 (0.577) data 0.000 (0.107) loss 2.2812 (2.2882) lr 7.1289e-02 eta 0:07:16
epoch [19/50] batch [14/24] time 0.430 (0.555) data 0.000 (0.092) loss 2.3398 (2.2930) lr 7.1289e-02 eta 0:06:58
epoch [19/50] batch [16/24] time 0.424 (0.539) data 0.000 (0.081) loss 2.3574 (2.3003) lr 7.1289e-02 eta 0:06:45
epoch [19/50] batch [18/24] time 0.424 (0.526) data 0.000 (0.072) loss 2.1270 (2.2959) lr 7.1289e-02 eta 0:06:34
epoch [19/50] batch [20/24] time 0.430 (0.516) data 0.000 (0.065) loss 2.1680 (2.2875) lr 7.1289e-02 eta 0:06:26
epoch [19/50] batch [22/24] time 0.428 (0.508) data 0.000 (0.059) loss 2.5918 (2.2955) lr 7.1289e-02 eta 0:06:19
epoch [19/50] batch [24/24] time 0.428 (0.501) data 0.000 (0.054) loss 2.3047 (2.2964) lr 6.8406e-02 eta 0:06:13
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 554
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 66.9%

epoch [20/50] batch [2/24] time 0.573 (1.272) data 0.001 (0.631) loss 2.0273 (2.1123) lr 6.8406e-02 eta 0:15:43
epoch [20/50] batch [4/24] time 0.432 (0.866) data 0.000 (0.316) loss 2.2793 (2.2227) lr 6.8406e-02 eta 0:10:40
epoch [20/50] batch [6/24] time 0.428 (0.719) data 0.000 (0.211) loss 2.3613 (2.2500) lr 6.8406e-02 eta 0:08:50
epoch [20/50] batch [8/24] time 0.424 (0.646) data 0.000 (0.158) loss 2.1855 (2.2485) lr 6.8406e-02 eta 0:07:55
epoch [20/50] batch [10/24] time 0.424 (0.601) data 0.000 (0.126) loss 2.2734 (2.2693) lr 6.8406e-02 eta 0:07:21
epoch [20/50] batch [12/24] time 0.427 (0.572) data 0.000 (0.105) loss 2.2910 (2.2731) lr 6.8406e-02 eta 0:06:58
epoch [20/50] batch [14/24] time 0.429 (0.551) data 0.000 (0.090) loss 2.2500 (2.2698) lr 6.8406e-02 eta 0:06:42
epoch [20/50] batch [16/24] time 0.425 (0.536) data 0.000 (0.079) loss 2.3047 (2.2709) lr 6.8406e-02 eta 0:06:30
epoch [20/50] batch [18/24] time 0.426 (0.524) data 0.000 (0.070) loss 2.2090 (2.2613) lr 6.8406e-02 eta 0:06:20
epoch [20/50] batch [20/24] time 0.425 (0.514) data 0.000 (0.063) loss 2.2246 (2.2600) lr 6.8406e-02 eta 0:06:11
epoch [20/50] batch [22/24] time 0.424 (0.506) data 0.000 (0.058) loss 2.2441 (2.2607) lr 6.8406e-02 eta 0:06:04
epoch [20/50] batch [24/24] time 0.424 (0.499) data 0.000 (0.053) loss 2.4629 (2.2773) lr 6.5451e-02 eta 0:05:59
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.51s/it] 60%|██████    | 3/5 [00:03<00:01,  1.05it/s] 80%|████████  | 4/5 [00:04<00:00,  1.48it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 557
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 66.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model.pth.tar-20

epoch [21/50] batch [2/24] time 0.599 (1.276) data 0.000 (0.566) loss 2.3262 (2.2842) lr 6.5451e-02 eta 0:15:16
epoch [21/50] batch [4/24] time 0.426 (0.858) data 0.000 (0.283) loss 2.3281 (2.2915) lr 6.5451e-02 eta 0:10:14
epoch [21/50] batch [6/24] time 0.427 (0.715) data 0.000 (0.189) loss 2.2676 (2.2581) lr 6.5451e-02 eta 0:08:30
epoch [21/50] batch [8/24] time 0.431 (0.643) data 0.000 (0.142) loss 2.0254 (2.2144) lr 6.5451e-02 eta 0:07:37
epoch [21/50] batch [10/24] time 0.426 (0.600) data 0.000 (0.113) loss 2.2910 (2.2381) lr 6.5451e-02 eta 0:07:05
epoch [21/50] batch [12/24] time 0.430 (0.571) data 0.000 (0.094) loss 2.3516 (2.2428) lr 6.5451e-02 eta 0:06:44
epoch [21/50] batch [14/24] time 0.429 (0.551) data 0.000 (0.081) loss 2.1074 (2.2432) lr 6.5451e-02 eta 0:06:28
epoch [21/50] batch [16/24] time 0.431 (0.536) data 0.000 (0.071) loss 2.2520 (2.2290) lr 6.5451e-02 eta 0:06:17
epoch [21/50] batch [18/24] time 0.428 (0.524) data 0.000 (0.063) loss 2.2969 (2.2357) lr 6.5451e-02 eta 0:06:07
epoch [21/50] batch [20/24] time 0.426 (0.514) data 0.000 (0.057) loss 2.2598 (2.2377) lr 6.5451e-02 eta 0:05:59
epoch [21/50] batch [22/24] time 0.426 (0.506) data 0.000 (0.052) loss 2.1621 (2.2409) lr 6.5451e-02 eta 0:05:53
epoch [21/50] batch [24/24] time 0.429 (0.500) data 0.000 (0.047) loss 2.2715 (2.2381) lr 6.2434e-02 eta 0:05:47
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.25s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 562
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 67.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [22/50] batch [2/24] time 0.529 (1.378) data 0.000 (0.739) loss 2.1699 (2.2451) lr 6.2434e-02 eta 0:15:56
epoch [22/50] batch [4/24] time 0.428 (0.904) data 0.000 (0.370) loss 2.5098 (2.2891) lr 6.2434e-02 eta 0:10:25
epoch [22/50] batch [6/24] time 0.426 (0.745) data 0.000 (0.246) loss 2.2578 (2.2962) lr 6.2434e-02 eta 0:08:33
epoch [22/50] batch [8/24] time 0.426 (0.665) data 0.000 (0.185) loss 2.2246 (2.2661) lr 6.2434e-02 eta 0:07:37
epoch [22/50] batch [10/24] time 0.424 (0.617) data 0.000 (0.148) loss 2.4004 (2.2824) lr 6.2434e-02 eta 0:07:03
epoch [22/50] batch [12/24] time 0.426 (0.585) data 0.000 (0.123) loss 2.3027 (2.2826) lr 6.2434e-02 eta 0:06:40
epoch [22/50] batch [14/24] time 0.428 (0.563) data 0.000 (0.106) loss 2.5488 (2.2916) lr 6.2434e-02 eta 0:06:23
epoch [22/50] batch [16/24] time 0.427 (0.546) data 0.000 (0.093) loss 2.1719 (2.2858) lr 6.2434e-02 eta 0:06:11
epoch [22/50] batch [18/24] time 0.423 (0.533) data 0.000 (0.082) loss 2.3262 (2.2771) lr 6.2434e-02 eta 0:06:01
epoch [22/50] batch [20/24] time 0.423 (0.522) data 0.000 (0.074) loss 2.1895 (2.2761) lr 6.2434e-02 eta 0:05:53
epoch [22/50] batch [22/24] time 0.428 (0.517) data 0.000 (0.067) loss 2.1484 (2.2757) lr 6.2434e-02 eta 0:05:48
epoch [22/50] batch [24/24] time 0.425 (0.510) data 0.000 (0.062) loss 2.1582 (2.2760) lr 5.9369e-02 eta 0:05:42
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 559
* accuracy: 68.8%
* error: 31.2%
* macro_f1: 67.5%

epoch [23/50] batch [2/24] time 0.567 (1.315) data 0.000 (0.638) loss 2.2695 (2.2090) lr 5.9369e-02 eta 0:14:40
epoch [23/50] batch [4/24] time 0.436 (0.887) data 0.000 (0.319) loss 2.4980 (2.2559) lr 5.9369e-02 eta 0:09:52
epoch [23/50] batch [6/24] time 0.426 (0.733) data 0.000 (0.213) loss 2.1348 (2.2467) lr 5.9369e-02 eta 0:08:08
epoch [23/50] batch [8/24] time 0.425 (0.656) data 0.000 (0.160) loss 2.4043 (2.2375) lr 5.9369e-02 eta 0:07:15
epoch [23/50] batch [10/24] time 0.427 (0.610) data 0.000 (0.128) loss 2.3398 (2.2314) lr 5.9369e-02 eta 0:06:43
epoch [23/50] batch [12/24] time 0.425 (0.579) data 0.000 (0.107) loss 2.2539 (2.2472) lr 5.9369e-02 eta 0:06:22
epoch [23/50] batch [14/24] time 0.425 (0.557) data 0.000 (0.091) loss 2.1230 (2.2390) lr 5.9369e-02 eta 0:06:06
epoch [23/50] batch [16/24] time 0.425 (0.540) data 0.000 (0.080) loss 2.3906 (2.2550) lr 5.9369e-02 eta 0:05:54
epoch [23/50] batch [18/24] time 0.426 (0.528) data 0.000 (0.071) loss 2.3535 (2.2593) lr 5.9369e-02 eta 0:05:45
epoch [23/50] batch [20/24] time 0.424 (0.517) data 0.000 (0.064) loss 2.2754 (2.2674) lr 5.9369e-02 eta 0:05:37
epoch [23/50] batch [22/24] time 0.424 (0.509) data 0.000 (0.058) loss 2.2910 (2.2650) lr 5.9369e-02 eta 0:05:30
epoch [23/50] batch [24/24] time 0.424 (0.502) data 0.000 (0.053) loss 2.2480 (2.2667) lr 5.6267e-02 eta 0:05:25
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.25s/it] 40%|████      | 2/5 [00:03<00:04,  1.50s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.49it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 552
* accuracy: 68.0%
* error: 32.0%
* macro_f1: 66.2%

epoch [24/50] batch [2/24] time 0.526 (1.322) data 0.000 (0.646) loss 2.1309 (2.1836) lr 5.6267e-02 eta 0:14:14
epoch [24/50] batch [4/24] time 0.424 (0.877) data 0.000 (0.323) loss 2.3848 (2.2632) lr 5.6267e-02 eta 0:09:24
epoch [24/50] batch [6/24] time 0.425 (0.726) data 0.000 (0.215) loss 2.1953 (2.2585) lr 5.6267e-02 eta 0:07:46
epoch [24/50] batch [8/24] time 0.424 (0.651) data 0.000 (0.162) loss 2.2051 (2.2336) lr 5.6267e-02 eta 0:06:56
epoch [24/50] batch [10/24] time 0.424 (0.605) data 0.000 (0.129) loss 2.1914 (2.2309) lr 5.6267e-02 eta 0:06:26
epoch [24/50] batch [12/24] time 0.424 (0.575) data 0.000 (0.108) loss 2.3125 (2.2326) lr 5.6267e-02 eta 0:06:05
epoch [24/50] batch [14/24] time 0.427 (0.554) data 0.000 (0.092) loss 2.3965 (2.2418) lr 5.6267e-02 eta 0:05:51
epoch [24/50] batch [16/24] time 0.424 (0.538) data 0.000 (0.081) loss 2.2246 (2.2582) lr 5.6267e-02 eta 0:05:39
epoch [24/50] batch [18/24] time 0.424 (0.525) data 0.000 (0.072) loss 2.3477 (2.2594) lr 5.6267e-02 eta 0:05:30
epoch [24/50] batch [20/24] time 0.427 (0.515) data 0.000 (0.065) loss 2.1875 (2.2648) lr 5.6267e-02 eta 0:05:23
epoch [24/50] batch [22/24] time 0.424 (0.507) data 0.000 (0.059) loss 2.2793 (2.2691) lr 5.6267e-02 eta 0:05:17
epoch [24/50] batch [24/24] time 0.424 (0.500) data 0.000 (0.054) loss 2.4043 (2.2836) lr 5.3140e-02 eta 0:05:12
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 569
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 68.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [25/50] batch [2/24] time 0.596 (1.288) data 0.000 (0.588) loss 2.2168 (2.2578) lr 5.3140e-02 eta 0:13:20
epoch [25/50] batch [4/24] time 0.426 (0.859) data 0.000 (0.294) loss 2.2812 (2.2642) lr 5.3140e-02 eta 0:08:52
epoch [25/50] batch [6/24] time 0.425 (0.715) data 0.000 (0.196) loss 2.4316 (2.2933) lr 5.3140e-02 eta 0:07:21
epoch [25/50] batch [8/24] time 0.427 (0.643) data 0.000 (0.147) loss 2.1270 (2.2871) lr 5.3140e-02 eta 0:06:35
epoch [25/50] batch [10/24] time 0.431 (0.600) data 0.000 (0.118) loss 2.1230 (2.2615) lr 5.3140e-02 eta 0:06:08
epoch [25/50] batch [12/24] time 0.426 (0.571) data 0.000 (0.098) loss 2.1875 (2.2466) lr 5.3140e-02 eta 0:05:49
epoch [25/50] batch [14/24] time 0.426 (0.550) data 0.000 (0.084) loss 2.1992 (2.2384) lr 5.3140e-02 eta 0:05:35
epoch [25/50] batch [16/24] time 0.425 (0.535) data 0.000 (0.074) loss 2.3750 (2.2517) lr 5.3140e-02 eta 0:05:25
epoch [25/50] batch [18/24] time 0.426 (0.523) data 0.000 (0.065) loss 2.2930 (2.2550) lr 5.3140e-02 eta 0:05:16
epoch [25/50] batch [20/24] time 0.426 (0.513) data 0.000 (0.059) loss 2.2285 (2.2530) lr 5.3140e-02 eta 0:05:09
epoch [25/50] batch [22/24] time 0.426 (0.505) data 0.000 (0.054) loss 2.1621 (2.2452) lr 5.3140e-02 eta 0:05:04
epoch [25/50] batch [24/24] time 0.446 (0.500) data 0.000 (0.049) loss 2.2480 (2.2435) lr 5.0000e-02 eta 0:04:59
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 552
* accuracy: 68.0%
* error: 32.0%
* macro_f1: 66.3%

epoch [26/50] batch [2/24] time 0.526 (1.363) data 0.000 (0.717) loss 2.1172 (2.1738) lr 5.0000e-02 eta 0:13:34
epoch [26/50] batch [4/24] time 0.424 (0.894) data 0.000 (0.359) loss 2.2734 (2.2290) lr 5.0000e-02 eta 0:08:52
epoch [26/50] batch [6/24] time 0.431 (0.738) data 0.000 (0.239) loss 2.4590 (2.2962) lr 5.0000e-02 eta 0:07:18
epoch [26/50] batch [8/24] time 0.424 (0.660) data 0.000 (0.179) loss 2.2051 (2.2998) lr 5.0000e-02 eta 0:06:30
epoch [26/50] batch [10/24] time 0.424 (0.613) data 0.000 (0.144) loss 2.5020 (2.3250) lr 5.0000e-02 eta 0:06:01
epoch [26/50] batch [12/24] time 0.424 (0.581) data 0.000 (0.120) loss 2.3359 (2.3083) lr 5.0000e-02 eta 0:05:41
epoch [26/50] batch [14/24] time 0.425 (0.559) data 0.000 (0.103) loss 2.2812 (2.3029) lr 5.0000e-02 eta 0:05:27
epoch [26/50] batch [16/24] time 0.425 (0.542) data 0.000 (0.090) loss 2.1426 (2.3004) lr 5.0000e-02 eta 0:05:16
epoch [26/50] batch [18/24] time 0.426 (0.529) data 0.000 (0.080) loss 2.1484 (2.2835) lr 5.0000e-02 eta 0:05:08
epoch [26/50] batch [20/24] time 0.424 (0.519) data 0.000 (0.072) loss 2.2637 (2.2823) lr 5.0000e-02 eta 0:05:01
epoch [26/50] batch [22/24] time 0.425 (0.511) data 0.000 (0.065) loss 2.1426 (2.2800) lr 5.0000e-02 eta 0:04:55
epoch [26/50] batch [24/24] time 0.428 (0.504) data 0.000 (0.060) loss 2.2363 (2.2685) lr 4.6860e-02 eta 0:04:50
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 558
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 67.2%

epoch [27/50] batch [2/24] time 0.573 (1.285) data 0.000 (0.638) loss 2.2715 (2.3359) lr 4.6860e-02 eta 0:12:17
epoch [27/50] batch [4/24] time 0.427 (0.860) data 0.000 (0.319) loss 2.2500 (2.2983) lr 4.6860e-02 eta 0:08:11
epoch [27/50] batch [6/24] time 0.426 (0.715) data 0.000 (0.213) loss 2.3379 (2.2656) lr 4.6860e-02 eta 0:06:47
epoch [27/50] batch [8/24] time 0.426 (0.644) data 0.000 (0.160) loss 2.2812 (2.2571) lr 4.6860e-02 eta 0:06:05
epoch [27/50] batch [10/24] time 0.425 (0.600) data 0.000 (0.128) loss 2.1543 (2.2564) lr 4.6860e-02 eta 0:05:39
epoch [27/50] batch [12/24] time 0.425 (0.571) data 0.000 (0.106) loss 2.2227 (2.2679) lr 4.6860e-02 eta 0:05:22
epoch [27/50] batch [14/24] time 0.425 (0.550) data 0.000 (0.091) loss 1.9434 (2.2479) lr 4.6860e-02 eta 0:05:09
epoch [27/50] batch [16/24] time 0.425 (0.535) data 0.000 (0.080) loss 2.3145 (2.2611) lr 4.6860e-02 eta 0:04:59
epoch [27/50] batch [18/24] time 0.425 (0.523) data 0.000 (0.071) loss 2.0879 (2.2567) lr 4.6860e-02 eta 0:04:51
epoch [27/50] batch [20/24] time 0.429 (0.513) data 0.000 (0.064) loss 2.1660 (2.2582) lr 4.6860e-02 eta 0:04:45
epoch [27/50] batch [22/24] time 0.425 (0.509) data 0.000 (0.058) loss 2.1348 (2.2485) lr 4.6860e-02 eta 0:04:41
epoch [27/50] batch [24/24] time 0.425 (0.502) data 0.000 (0.053) loss 2.1602 (2.2429) lr 4.3733e-02 eta 0:04:37
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 556
* accuracy: 68.5%
* error: 31.5%
* macro_f1: 67.1%

epoch [28/50] batch [2/24] time 0.533 (1.365) data 0.000 (0.693) loss 2.4004 (2.3770) lr 4.3733e-02 eta 0:12:30
epoch [28/50] batch [4/24] time 0.425 (0.895) data 0.000 (0.347) loss 2.3125 (2.3408) lr 4.3733e-02 eta 0:08:10
epoch [28/50] batch [6/24] time 0.427 (0.739) data 0.000 (0.231) loss 2.1348 (2.2992) lr 4.3733e-02 eta 0:06:43
epoch [28/50] batch [8/24] time 0.425 (0.661) data 0.000 (0.173) loss 2.2188 (2.2812) lr 4.3733e-02 eta 0:05:59
epoch [28/50] batch [10/24] time 0.425 (0.614) data 0.000 (0.139) loss 2.3438 (2.2803) lr 4.3733e-02 eta 0:05:32
epoch [28/50] batch [12/24] time 0.426 (0.582) data 0.000 (0.116) loss 2.3086 (2.2687) lr 4.3733e-02 eta 0:05:14
epoch [28/50] batch [14/24] time 0.426 (0.560) data 0.000 (0.099) loss 2.3984 (2.2803) lr 4.3733e-02 eta 0:05:01
epoch [28/50] batch [16/24] time 0.432 (0.544) data 0.000 (0.087) loss 2.2207 (2.2830) lr 4.3733e-02 eta 0:04:51
epoch [28/50] batch [18/24] time 0.430 (0.531) data 0.000 (0.077) loss 2.0996 (2.2610) lr 4.3733e-02 eta 0:04:43
epoch [28/50] batch [20/24] time 0.428 (0.521) data 0.000 (0.069) loss 2.1309 (2.2458) lr 4.3733e-02 eta 0:04:37
epoch [28/50] batch [22/24] time 0.427 (0.512) data 0.000 (0.063) loss 2.1777 (2.2455) lr 4.3733e-02 eta 0:04:31
epoch [28/50] batch [24/24] time 0.424 (0.506) data 0.000 (0.058) loss 2.2559 (2.2524) lr 4.0631e-02 eta 0:04:26
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 556
* accuracy: 68.5%
* error: 31.5%
* macro_f1: 67.4%

epoch [29/50] batch [2/24] time 0.612 (1.292) data 0.000 (0.613) loss 2.0684 (2.2061) lr 4.0631e-02 eta 0:11:19
epoch [29/50] batch [4/24] time 0.425 (0.862) data 0.000 (0.307) loss 2.1191 (2.2412) lr 4.0631e-02 eta 0:07:31
epoch [29/50] batch [6/24] time 0.430 (0.718) data 0.000 (0.204) loss 2.3926 (2.2568) lr 4.0631e-02 eta 0:06:14
epoch [29/50] batch [8/24] time 0.428 (0.645) data 0.000 (0.153) loss 2.1973 (2.2349) lr 4.0631e-02 eta 0:05:35
epoch [29/50] batch [10/24] time 0.427 (0.602) data 0.000 (0.123) loss 2.2402 (2.2547) lr 4.0631e-02 eta 0:05:11
epoch [29/50] batch [12/24] time 0.428 (0.573) data 0.000 (0.102) loss 2.3672 (2.2637) lr 4.0631e-02 eta 0:04:55
epoch [29/50] batch [14/24] time 0.430 (0.552) data 0.000 (0.088) loss 2.1895 (2.2511) lr 4.0631e-02 eta 0:04:43
epoch [29/50] batch [16/24] time 0.434 (0.537) data 0.000 (0.077) loss 2.2246 (2.2489) lr 4.0631e-02 eta 0:04:34
epoch [29/50] batch [18/24] time 0.427 (0.525) data 0.000 (0.068) loss 2.1895 (2.2431) lr 4.0631e-02 eta 0:04:27
epoch [29/50] batch [20/24] time 0.427 (0.515) data 0.000 (0.061) loss 2.2383 (2.2324) lr 4.0631e-02 eta 0:04:21
epoch [29/50] batch [22/24] time 0.432 (0.507) data 0.000 (0.056) loss 2.2227 (2.2409) lr 4.0631e-02 eta 0:04:16
epoch [29/50] batch [24/24] time 0.430 (0.500) data 0.000 (0.051) loss 2.0801 (2.2315) lr 3.7566e-02 eta 0:04:12
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.51s/it] 60%|██████    | 3/5 [00:03<00:01,  1.06it/s] 80%|████████  | 4/5 [00:04<00:00,  1.48it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 568
* accuracy: 70.0%
* error: 30.0%
* macro_f1: 68.8%

epoch [30/50] batch [2/24] time 0.543 (1.344) data 0.000 (0.692) loss 2.0723 (2.1309) lr 3.7566e-02 eta 0:11:14
epoch [30/50] batch [4/24] time 0.425 (0.888) data 0.000 (0.346) loss 2.3184 (2.1880) lr 3.7566e-02 eta 0:07:24
epoch [30/50] batch [6/24] time 0.426 (0.734) data 0.000 (0.231) loss 2.0664 (2.1738) lr 3.7566e-02 eta 0:06:05
epoch [30/50] batch [8/24] time 0.424 (0.657) data 0.000 (0.173) loss 2.2969 (2.1936) lr 3.7566e-02 eta 0:05:25
epoch [30/50] batch [10/24] time 0.423 (0.610) data 0.000 (0.139) loss 2.3809 (2.2131) lr 3.7566e-02 eta 0:05:01
epoch [30/50] batch [12/24] time 0.423 (0.579) data 0.000 (0.115) loss 2.2910 (2.2113) lr 3.7566e-02 eta 0:04:44
epoch [30/50] batch [14/24] time 0.431 (0.558) data 0.000 (0.099) loss 2.1348 (2.2069) lr 3.7566e-02 eta 0:04:33
epoch [30/50] batch [16/24] time 0.425 (0.541) data 0.000 (0.087) loss 2.4102 (2.2323) lr 3.7566e-02 eta 0:04:24
epoch [30/50] batch [18/24] time 0.425 (0.529) data 0.000 (0.077) loss 2.1777 (2.2324) lr 3.7566e-02 eta 0:04:16
epoch [30/50] batch [20/24] time 0.425 (0.518) data 0.000 (0.069) loss 2.2520 (2.2477) lr 3.7566e-02 eta 0:04:10
epoch [30/50] batch [22/24] time 0.429 (0.511) data 0.000 (0.063) loss 2.2871 (2.2530) lr 3.7566e-02 eta 0:04:06
epoch [30/50] batch [24/24] time 0.425 (0.504) data 0.000 (0.058) loss 2.1738 (2.2471) lr 3.4549e-02 eta 0:04:01
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 567
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 68.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model.pth.tar-30

epoch [31/50] batch [2/24] time 0.525 (1.304) data 0.000 (0.636) loss 2.3828 (2.3301) lr 3.4549e-02 eta 0:10:23
epoch [31/50] batch [4/24] time 0.434 (0.883) data 0.000 (0.318) loss 2.3086 (2.2466) lr 3.4549e-02 eta 0:07:00
epoch [31/50] batch [6/24] time 0.426 (0.730) data 0.000 (0.212) loss 2.2188 (2.2262) lr 3.4549e-02 eta 0:05:46
epoch [31/50] batch [8/24] time 0.424 (0.654) data 0.000 (0.159) loss 2.3203 (2.2407) lr 3.4549e-02 eta 0:05:08
epoch [31/50] batch [10/24] time 0.424 (0.608) data 0.000 (0.127) loss 2.1055 (2.2223) lr 3.4549e-02 eta 0:04:45
epoch [31/50] batch [12/24] time 0.430 (0.578) data 0.000 (0.106) loss 2.2500 (2.2259) lr 3.4549e-02 eta 0:04:30
epoch [31/50] batch [14/24] time 0.427 (0.556) data 0.000 (0.091) loss 2.2871 (2.2133) lr 3.4549e-02 eta 0:04:19
epoch [31/50] batch [16/24] time 0.424 (0.540) data 0.000 (0.080) loss 2.1230 (2.2054) lr 3.4549e-02 eta 0:04:10
epoch [31/50] batch [18/24] time 0.435 (0.528) data 0.000 (0.071) loss 2.1660 (2.2037) lr 3.4549e-02 eta 0:04:03
epoch [31/50] batch [20/24] time 0.425 (0.518) data 0.000 (0.064) loss 2.3730 (2.2255) lr 3.4549e-02 eta 0:03:58
epoch [31/50] batch [22/24] time 0.424 (0.509) data 0.000 (0.058) loss 2.3281 (2.2280) lr 3.4549e-02 eta 0:03:53
epoch [31/50] batch [24/24] time 0.429 (0.503) data 0.000 (0.053) loss 2.1641 (2.2162) lr 3.1594e-02 eta 0:03:49
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.22s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 567
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 68.6%

epoch [32/50] batch [2/24] time 0.534 (1.390) data 0.000 (0.795) loss 2.2793 (2.2832) lr 3.1594e-02 eta 0:10:31
epoch [32/50] batch [4/24] time 0.428 (0.912) data 0.000 (0.398) loss 2.3125 (2.2705) lr 3.1594e-02 eta 0:06:52
epoch [32/50] batch [6/24] time 0.426 (0.750) data 0.000 (0.265) loss 2.2031 (2.2510) lr 3.1594e-02 eta 0:05:37
epoch [32/50] batch [8/24] time 0.425 (0.669) data 0.000 (0.199) loss 2.0391 (2.2161) lr 3.1594e-02 eta 0:04:59
epoch [32/50] batch [10/24] time 0.424 (0.620) data 0.000 (0.159) loss 2.1445 (2.2217) lr 3.1594e-02 eta 0:04:36
epoch [32/50] batch [12/24] time 0.426 (0.588) data 0.000 (0.133) loss 2.1504 (2.2170) lr 3.1594e-02 eta 0:04:20
epoch [32/50] batch [14/24] time 0.426 (0.565) data 0.000 (0.114) loss 2.3125 (2.2176) lr 3.1594e-02 eta 0:04:09
epoch [32/50] batch [16/24] time 0.429 (0.548) data 0.000 (0.100) loss 2.4453 (2.2400) lr 3.1594e-02 eta 0:04:01
epoch [32/50] batch [18/24] time 0.426 (0.534) data 0.000 (0.088) loss 2.3359 (2.2525) lr 3.1594e-02 eta 0:03:54
epoch [32/50] batch [20/24] time 0.426 (0.524) data 0.000 (0.080) loss 1.9688 (2.2333) lr 3.1594e-02 eta 0:03:48
epoch [32/50] batch [22/24] time 0.426 (0.515) data 0.000 (0.072) loss 2.4746 (2.2481) lr 3.1594e-02 eta 0:03:43
epoch [32/50] batch [24/24] time 0.428 (0.508) data 0.000 (0.066) loss 2.1836 (2.2437) lr 2.8711e-02 eta 0:03:39
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.12s/it] 40%|████      | 2/5 [00:03<00:04,  1.50s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.49it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 569
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 68.7%

epoch [33/50] batch [2/24] time 0.664 (1.267) data 0.000 (0.532) loss 2.1406 (2.1465) lr 2.8711e-02 eta 0:09:04
epoch [33/50] batch [4/24] time 0.426 (0.848) data 0.000 (0.266) loss 2.1953 (2.1533) lr 2.8711e-02 eta 0:06:03
epoch [33/50] batch [6/24] time 0.425 (0.707) data 0.000 (0.177) loss 2.0898 (2.1911) lr 2.8711e-02 eta 0:05:01
epoch [33/50] batch [8/24] time 0.426 (0.637) data 0.000 (0.133) loss 2.0273 (2.1555) lr 2.8711e-02 eta 0:04:30
epoch [33/50] batch [10/24] time 0.426 (0.595) data 0.000 (0.107) loss 2.1426 (2.1775) lr 2.8711e-02 eta 0:04:11
epoch [33/50] batch [12/24] time 0.426 (0.567) data 0.000 (0.089) loss 2.3145 (2.1875) lr 2.8711e-02 eta 0:03:58
epoch [33/50] batch [14/24] time 0.427 (0.547) data 0.000 (0.076) loss 2.1484 (2.1893) lr 2.8711e-02 eta 0:03:48
epoch [33/50] batch [16/24] time 0.426 (0.532) data 0.000 (0.067) loss 2.3262 (2.1998) lr 2.8711e-02 eta 0:03:41
epoch [33/50] batch [18/24] time 0.429 (0.520) data 0.000 (0.059) loss 2.2539 (2.2180) lr 2.8711e-02 eta 0:03:35
epoch [33/50] batch [20/24] time 0.425 (0.511) data 0.000 (0.053) loss 2.2559 (2.2285) lr 2.8711e-02 eta 0:03:30
epoch [33/50] batch [22/24] time 0.426 (0.503) data 0.000 (0.049) loss 2.1094 (2.2165) lr 2.8711e-02 eta 0:03:26
epoch [33/50] batch [24/24] time 0.434 (0.497) data 0.000 (0.044) loss 2.0684 (2.2104) lr 2.5912e-02 eta 0:03:22
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 572
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 69.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [34/50] batch [2/24] time 0.680 (1.250) data 0.000 (0.538) loss 2.2227 (2.2070) lr 2.5912e-02 eta 0:08:27
epoch [34/50] batch [4/24] time 0.428 (0.845) data 0.000 (0.269) loss 2.1465 (2.2202) lr 2.5912e-02 eta 0:05:41
epoch [34/50] batch [6/24] time 0.426 (0.705) data 0.000 (0.179) loss 2.2266 (2.2269) lr 2.5912e-02 eta 0:04:43
epoch [34/50] batch [8/24] time 0.428 (0.636) data 0.000 (0.135) loss 2.2090 (2.2222) lr 2.5912e-02 eta 0:04:14
epoch [34/50] batch [10/24] time 0.426 (0.594) data 0.000 (0.108) loss 2.4043 (2.2473) lr 2.5912e-02 eta 0:03:56
epoch [34/50] batch [12/24] time 0.508 (0.573) data 0.000 (0.090) loss 2.2578 (2.2427) lr 2.5912e-02 eta 0:03:46
epoch [34/50] batch [14/24] time 0.427 (0.552) data 0.000 (0.077) loss 2.1875 (2.2348) lr 2.5912e-02 eta 0:03:37
epoch [34/50] batch [16/24] time 0.427 (0.536) data 0.000 (0.067) loss 2.4102 (2.2426) lr 2.5912e-02 eta 0:03:30
epoch [34/50] batch [18/24] time 0.426 (0.524) data 0.000 (0.060) loss 2.2930 (2.2436) lr 2.5912e-02 eta 0:03:24
epoch [34/50] batch [20/24] time 0.426 (0.514) data 0.000 (0.054) loss 2.1465 (2.2450) lr 2.5912e-02 eta 0:03:19
epoch [34/50] batch [22/24] time 0.429 (0.506) data 0.000 (0.049) loss 2.1152 (2.2342) lr 2.5912e-02 eta 0:03:15
epoch [34/50] batch [24/24] time 0.428 (0.500) data 0.000 (0.045) loss 2.1875 (2.2187) lr 2.3209e-02 eta 0:03:11
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 569
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 68.8%

epoch [35/50] batch [2/24] time 0.520 (1.393) data 0.000 (0.767) loss 2.2910 (2.1450) lr 2.3209e-02 eta 0:08:52
epoch [35/50] batch [4/24] time 0.425 (0.910) data 0.000 (0.384) loss 2.2031 (2.1526) lr 2.3209e-02 eta 0:05:45
epoch [35/50] batch [6/24] time 0.427 (0.750) data 0.000 (0.256) loss 2.1836 (2.1737) lr 2.3209e-02 eta 0:04:43
epoch [35/50] batch [8/24] time 0.424 (0.668) data 0.000 (0.192) loss 2.2617 (2.1976) lr 2.3209e-02 eta 0:04:11
epoch [35/50] batch [10/24] time 0.425 (0.619) data 0.000 (0.154) loss 2.1680 (2.2042) lr 2.3209e-02 eta 0:03:51
epoch [35/50] batch [12/24] time 0.427 (0.587) data 0.000 (0.128) loss 2.0293 (2.1943) lr 2.3209e-02 eta 0:03:38
epoch [35/50] batch [14/24] time 0.430 (0.565) data 0.000 (0.110) loss 2.1035 (2.2045) lr 2.3209e-02 eta 0:03:28
epoch [35/50] batch [16/24] time 0.425 (0.547) data 0.000 (0.096) loss 2.2070 (2.2031) lr 2.3209e-02 eta 0:03:21
epoch [35/50] batch [18/24] time 0.429 (0.534) data 0.000 (0.085) loss 2.3887 (2.2114) lr 2.3209e-02 eta 0:03:15
epoch [35/50] batch [20/24] time 0.428 (0.523) data 0.000 (0.077) loss 2.1895 (2.2097) lr 2.3209e-02 eta 0:03:10
epoch [35/50] batch [22/24] time 0.424 (0.514) data 0.000 (0.070) loss 2.3145 (2.2193) lr 2.3209e-02 eta 0:03:06
epoch [35/50] batch [24/24] time 0.428 (0.507) data 0.000 (0.064) loss 2.2852 (2.2146) lr 2.0611e-02 eta 0:03:02
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:13,  3.31s/it] 40%|████      | 2/5 [00:03<00:04,  1.52s/it] 60%|██████    | 3/5 [00:03<00:01,  1.06it/s] 80%|████████  | 4/5 [00:04<00:00,  1.48it/s]100%|██████████| 5/5 [00:04<00:00,  1.17it/s]=> result
* total: 812
* correct: 567
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 68.5%

epoch [36/50] batch [2/24] time 0.627 (1.297) data 0.000 (0.599) loss 2.2344 (2.2324) lr 2.0611e-02 eta 0:07:44
epoch [36/50] batch [4/24] time 0.426 (0.868) data 0.000 (0.299) loss 2.2988 (2.2300) lr 2.0611e-02 eta 0:05:08
epoch [36/50] batch [6/24] time 0.428 (0.721) data 0.000 (0.200) loss 2.0742 (2.2145) lr 2.0611e-02 eta 0:04:15
epoch [36/50] batch [8/24] time 0.429 (0.647) data 0.000 (0.150) loss 2.0645 (2.1833) lr 2.0611e-02 eta 0:03:47
epoch [36/50] batch [10/24] time 0.426 (0.603) data 0.000 (0.120) loss 2.1074 (2.1688) lr 2.0611e-02 eta 0:03:31
epoch [36/50] batch [12/24] time 0.426 (0.574) data 0.000 (0.100) loss 2.4434 (2.1989) lr 2.0611e-02 eta 0:03:19
epoch [36/50] batch [14/24] time 0.429 (0.553) data 0.000 (0.086) loss 2.1719 (2.1955) lr 2.0611e-02 eta 0:03:11
epoch [36/50] batch [16/24] time 0.426 (0.537) data 0.000 (0.075) loss 2.2559 (2.1849) lr 2.0611e-02 eta 0:03:04
epoch [36/50] batch [18/24] time 0.425 (0.525) data 0.000 (0.067) loss 2.3027 (2.2033) lr 2.0611e-02 eta 0:02:59
epoch [36/50] batch [20/24] time 0.426 (0.515) data 0.000 (0.060) loss 2.1680 (2.2089) lr 2.0611e-02 eta 0:02:55
epoch [36/50] batch [22/24] time 0.426 (0.507) data 0.000 (0.055) loss 2.0684 (2.2108) lr 2.0611e-02 eta 0:02:51
epoch [36/50] batch [24/24] time 0.427 (0.501) data 0.000 (0.050) loss 2.0176 (2.2142) lr 1.8129e-02 eta 0:02:48
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 572
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 69.4%

epoch [37/50] batch [2/24] time 0.582 (1.266) data 0.000 (0.607) loss 2.2832 (2.2100) lr 1.8129e-02 eta 0:07:02
epoch [37/50] batch [4/24] time 0.429 (0.850) data 0.000 (0.304) loss 2.1719 (2.2046) lr 1.8129e-02 eta 0:04:42
epoch [37/50] batch [6/24] time 0.426 (0.709) data 0.000 (0.203) loss 2.3828 (2.2555) lr 1.8129e-02 eta 0:03:53
epoch [37/50] batch [8/24] time 0.429 (0.638) data 0.000 (0.152) loss 2.4414 (2.2800) lr 1.8129e-02 eta 0:03:29
epoch [37/50] batch [10/24] time 0.426 (0.596) data 0.000 (0.122) loss 2.2422 (2.2654) lr 1.8129e-02 eta 0:03:14
epoch [37/50] batch [12/24] time 0.425 (0.568) data 0.000 (0.101) loss 2.5273 (2.2944) lr 1.8129e-02 eta 0:03:04
epoch [37/50] batch [14/24] time 0.427 (0.548) data 0.000 (0.087) loss 2.3789 (2.3040) lr 1.8129e-02 eta 0:02:56
epoch [37/50] batch [16/24] time 0.424 (0.532) data 0.000 (0.076) loss 2.2520 (2.3031) lr 1.8129e-02 eta 0:02:50
epoch [37/50] batch [18/24] time 0.423 (0.520) data 0.000 (0.068) loss 2.2148 (2.2849) lr 1.8129e-02 eta 0:02:45
epoch [37/50] batch [20/24] time 0.423 (0.510) data 0.000 (0.061) loss 2.2207 (2.2846) lr 1.8129e-02 eta 0:02:41
epoch [37/50] batch [22/24] time 0.430 (0.503) data 0.000 (0.055) loss 2.2500 (2.2851) lr 1.8129e-02 eta 0:02:37
epoch [37/50] batch [24/24] time 0.424 (0.496) data 0.000 (0.051) loss 2.1309 (2.2747) lr 1.5773e-02 eta 0:02:34
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:13,  3.33s/it] 40%|████      | 2/5 [00:03<00:04,  1.53s/it] 60%|██████    | 3/5 [00:03<00:01,  1.05it/s] 80%|████████  | 4/5 [00:04<00:00,  1.48it/s]100%|██████████| 5/5 [00:04<00:00,  1.17it/s]=> result
* total: 812
* correct: 570
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 68.7%

epoch [38/50] batch [2/24] time 0.480 (1.424) data 0.000 (0.828) loss 2.3105 (2.1406) lr 1.5773e-02 eta 0:07:21
epoch [38/50] batch [4/24] time 0.428 (0.926) data 0.000 (0.414) loss 2.3613 (2.2021) lr 1.5773e-02 eta 0:04:45
epoch [38/50] batch [6/24] time 0.432 (0.761) data 0.000 (0.276) loss 2.1895 (2.2044) lr 1.5773e-02 eta 0:03:52
epoch [38/50] batch [8/24] time 0.425 (0.677) data 0.000 (0.207) loss 2.4004 (2.2202) lr 1.5773e-02 eta 0:03:25
epoch [38/50] batch [10/24] time 0.426 (0.627) data 0.000 (0.166) loss 2.0781 (2.1965) lr 1.5773e-02 eta 0:03:09
epoch [38/50] batch [12/24] time 0.428 (0.593) data 0.000 (0.138) loss 2.3145 (2.1994) lr 1.5773e-02 eta 0:02:58
epoch [38/50] batch [14/24] time 0.425 (0.570) data 0.000 (0.118) loss 2.3418 (2.2331) lr 1.5773e-02 eta 0:02:49
epoch [38/50] batch [16/24] time 0.426 (0.552) data 0.000 (0.104) loss 2.0684 (2.2279) lr 1.5773e-02 eta 0:02:43
epoch [38/50] batch [18/24] time 0.426 (0.538) data 0.000 (0.092) loss 2.1562 (2.2145) lr 1.5773e-02 eta 0:02:38
epoch [38/50] batch [20/24] time 0.426 (0.526) data 0.000 (0.083) loss 2.3711 (2.2214) lr 1.5773e-02 eta 0:02:33
epoch [38/50] batch [22/24] time 0.427 (0.517) data 0.000 (0.075) loss 2.3496 (2.2301) lr 1.5773e-02 eta 0:02:30
epoch [38/50] batch [24/24] time 0.426 (0.510) data 0.000 (0.069) loss 2.2266 (2.2334) lr 1.3552e-02 eta 0:02:26
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 578
* accuracy: 71.2%
* error: 28.8%
* macro_f1: 70.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar

epoch [39/50] batch [2/24] time 0.694 (1.269) data 0.000 (0.525) loss 2.1738 (2.2188) lr 1.3552e-02 eta 0:06:03
epoch [39/50] batch [4/24] time 0.424 (0.855) data 0.000 (0.263) loss 2.3359 (2.2344) lr 1.3552e-02 eta 0:04:02
epoch [39/50] batch [6/24] time 0.427 (0.712) data 0.000 (0.175) loss 2.2480 (2.2210) lr 1.3552e-02 eta 0:03:20
epoch [39/50] batch [8/24] time 0.512 (0.651) data 0.000 (0.131) loss 2.1855 (2.2078) lr 1.3552e-02 eta 0:03:02
epoch [39/50] batch [10/24] time 0.425 (0.606) data 0.000 (0.105) loss 2.2949 (2.2162) lr 1.3552e-02 eta 0:02:48
epoch [39/50] batch [12/24] time 0.424 (0.576) data 0.000 (0.088) loss 2.1895 (2.1987) lr 1.3552e-02 eta 0:02:38
epoch [39/50] batch [14/24] time 0.427 (0.554) data 0.000 (0.075) loss 2.3945 (2.2077) lr 1.3552e-02 eta 0:02:31
epoch [39/50] batch [16/24] time 0.425 (0.538) data 0.000 (0.066) loss 2.1230 (2.1973) lr 1.3552e-02 eta 0:02:26
epoch [39/50] batch [18/24] time 0.425 (0.526) data 0.000 (0.059) loss 2.3184 (2.2113) lr 1.3552e-02 eta 0:02:21
epoch [39/50] batch [20/24] time 0.425 (0.516) data 0.000 (0.053) loss 2.2891 (2.2202) lr 1.3552e-02 eta 0:02:18
epoch [39/50] batch [22/24] time 0.424 (0.507) data 0.000 (0.048) loss 2.3066 (2.2235) lr 1.3552e-02 eta 0:02:14
epoch [39/50] batch [24/24] time 0.425 (0.501) data 0.000 (0.044) loss 2.1191 (2.2173) lr 1.1474e-02 eta 0:02:12
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 574
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 69.7%

epoch [40/50] batch [2/24] time 0.587 (1.267) data 0.000 (0.598) loss 2.2246 (2.2344) lr 1.1474e-02 eta 0:05:31
epoch [40/50] batch [4/24] time 0.424 (0.851) data 0.000 (0.299) loss 2.2148 (2.2344) lr 1.1474e-02 eta 0:03:41
epoch [40/50] batch [6/24] time 0.425 (0.709) data 0.000 (0.199) loss 2.2031 (2.1891) lr 1.1474e-02 eta 0:03:02
epoch [40/50] batch [8/24] time 0.424 (0.638) data 0.000 (0.150) loss 2.3008 (2.2068) lr 1.1474e-02 eta 0:02:43
epoch [40/50] batch [10/24] time 0.425 (0.596) data 0.000 (0.120) loss 2.1270 (2.2068) lr 1.1474e-02 eta 0:02:31
epoch [40/50] batch [12/24] time 0.427 (0.567) data 0.000 (0.100) loss 2.3418 (2.2254) lr 1.1474e-02 eta 0:02:22
epoch [40/50] batch [14/24] time 0.426 (0.547) data 0.000 (0.086) loss 2.1543 (2.2042) lr 1.1474e-02 eta 0:02:16
epoch [40/50] batch [16/24] time 0.425 (0.532) data 0.000 (0.075) loss 2.4082 (2.2156) lr 1.1474e-02 eta 0:02:11
epoch [40/50] batch [18/24] time 0.424 (0.520) data 0.000 (0.067) loss 2.2383 (2.2212) lr 1.1474e-02 eta 0:02:07
epoch [40/50] batch [20/24] time 0.424 (0.511) data 0.000 (0.060) loss 2.2480 (2.2208) lr 1.1474e-02 eta 0:02:04
epoch [40/50] batch [22/24] time 0.425 (0.503) data 0.000 (0.055) loss 2.4102 (2.2217) lr 1.1474e-02 eta 0:02:01
epoch [40/50] batch [24/24] time 0.426 (0.497) data 0.000 (0.050) loss 2.1992 (2.2182) lr 9.5492e-03 eta 0:01:59
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 571
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 69.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model.pth.tar-40

epoch [41/50] batch [2/24] time 0.541 (1.307) data 0.000 (0.634) loss 2.2051 (2.2695) lr 9.5492e-03 eta 0:05:11
epoch [41/50] batch [4/24] time 0.427 (0.872) data 0.000 (0.317) loss 2.1973 (2.2090) lr 9.5492e-03 eta 0:03:25
epoch [41/50] batch [6/24] time 0.427 (0.724) data 0.000 (0.211) loss 2.4727 (2.2406) lr 9.5492e-03 eta 0:02:49
epoch [41/50] batch [8/24] time 0.428 (0.650) data 0.000 (0.159) loss 2.3418 (2.2703) lr 9.5492e-03 eta 0:02:30
epoch [41/50] batch [10/24] time 0.427 (0.605) data 0.000 (0.127) loss 2.1660 (2.2654) lr 9.5492e-03 eta 0:02:19
epoch [41/50] batch [12/24] time 0.432 (0.576) data 0.000 (0.106) loss 2.2773 (2.2645) lr 9.5492e-03 eta 0:02:11
epoch [41/50] batch [14/24] time 0.427 (0.555) data 0.000 (0.091) loss 2.0605 (2.2472) lr 9.5492e-03 eta 0:02:05
epoch [41/50] batch [16/24] time 0.427 (0.539) data 0.000 (0.079) loss 2.3613 (2.2534) lr 9.5492e-03 eta 0:02:00
epoch [41/50] batch [18/24] time 0.426 (0.526) data 0.000 (0.071) loss 2.3242 (2.2561) lr 9.5492e-03 eta 0:01:56
epoch [41/50] batch [20/24] time 0.426 (0.516) data 0.000 (0.064) loss 2.2227 (2.2590) lr 9.5492e-03 eta 0:01:53
epoch [41/50] batch [22/24] time 0.428 (0.508) data 0.000 (0.058) loss 2.1914 (2.2588) lr 9.5492e-03 eta 0:01:50
epoch [41/50] batch [24/24] time 0.427 (0.501) data 0.000 (0.053) loss 2.2188 (2.2478) lr 7.7836e-03 eta 0:01:48
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:13,  3.28s/it] 40%|████      | 2/5 [00:03<00:04,  1.50s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.49it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 565
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 68.5%

epoch [42/50] batch [2/24] time 0.666 (1.227) data 0.000 (0.508) loss 2.0352 (2.2070) lr 7.7836e-03 eta 0:04:22
epoch [42/50] batch [4/24] time 0.430 (0.842) data 0.000 (0.254) loss 2.1426 (2.2144) lr 7.7836e-03 eta 0:02:58
epoch [42/50] batch [6/24] time 0.430 (0.704) data 0.000 (0.170) loss 2.1895 (2.2018) lr 7.7836e-03 eta 0:02:27
epoch [42/50] batch [8/24] time 0.430 (0.636) data 0.000 (0.127) loss 2.0820 (2.1812) lr 7.7836e-03 eta 0:02:12
epoch [42/50] batch [10/24] time 0.429 (0.595) data 0.000 (0.102) loss 2.1016 (2.1740) lr 7.7836e-03 eta 0:02:02
epoch [42/50] batch [12/24] time 0.426 (0.567) data 0.000 (0.085) loss 2.1953 (2.1681) lr 7.7836e-03 eta 0:01:55
epoch [42/50] batch [14/24] time 0.426 (0.547) data 0.000 (0.073) loss 2.0742 (2.1586) lr 7.7836e-03 eta 0:01:50
epoch [42/50] batch [16/24] time 0.429 (0.532) data 0.000 (0.064) loss 2.1758 (2.1632) lr 7.7836e-03 eta 0:01:46
epoch [42/50] batch [18/24] time 0.427 (0.520) data 0.000 (0.057) loss 2.2148 (2.1695) lr 7.7836e-03 eta 0:01:42
epoch [42/50] batch [20/24] time 0.426 (0.511) data 0.000 (0.051) loss 2.1836 (2.1780) lr 7.7836e-03 eta 0:01:40
epoch [42/50] batch [22/24] time 0.433 (0.503) data 0.006 (0.047) loss 2.3867 (2.1826) lr 7.7836e-03 eta 0:01:37
epoch [42/50] batch [24/24] time 0.427 (0.497) data 0.000 (0.043) loss 2.0273 (2.1697) lr 6.1847e-03 eta 0:01:35
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 571
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 69.3%

epoch [43/50] batch [2/24] time 0.573 (1.316) data 0.000 (0.625) loss 2.1270 (2.1279) lr 6.1847e-03 eta 0:04:09
epoch [43/50] batch [4/24] time 0.425 (0.870) data 0.000 (0.313) loss 2.3125 (2.1880) lr 6.1847e-03 eta 0:02:43
epoch [43/50] batch [6/24] time 0.425 (0.722) data 0.000 (0.209) loss 1.9902 (2.1540) lr 6.1847e-03 eta 0:02:14
epoch [43/50] batch [8/24] time 0.425 (0.648) data 0.000 (0.157) loss 2.4629 (2.2036) lr 6.1847e-03 eta 0:01:59
epoch [43/50] batch [10/24] time 0.427 (0.603) data 0.000 (0.125) loss 2.1816 (2.2102) lr 6.1847e-03 eta 0:01:49
epoch [43/50] batch [12/24] time 0.425 (0.574) data 0.000 (0.104) loss 2.1406 (2.2065) lr 6.1847e-03 eta 0:01:43
epoch [43/50] batch [14/24] time 0.425 (0.553) data 0.000 (0.090) loss 2.1074 (2.1966) lr 6.1847e-03 eta 0:01:38
epoch [43/50] batch [16/24] time 0.428 (0.537) data 0.000 (0.078) loss 2.3750 (2.2057) lr 6.1847e-03 eta 0:01:34
epoch [43/50] batch [18/24] time 0.426 (0.524) data 0.000 (0.070) loss 2.4824 (2.2246) lr 6.1847e-03 eta 0:01:31
epoch [43/50] batch [20/24] time 0.424 (0.515) data 0.000 (0.063) loss 2.1895 (2.2232) lr 6.1847e-03 eta 0:01:28
epoch [43/50] batch [22/24] time 0.425 (0.507) data 0.000 (0.057) loss 2.0996 (2.2178) lr 6.1847e-03 eta 0:01:26
epoch [43/50] batch [24/24] time 0.427 (0.500) data 0.000 (0.052) loss 2.0117 (2.2131) lr 4.7586e-03 eta 0:01:23
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 577
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 70.0%

epoch [44/50] batch [2/24] time 0.488 (1.371) data 0.000 (0.760) loss 2.3281 (2.2363) lr 4.7586e-03 eta 0:03:47
epoch [44/50] batch [4/24] time 0.426 (0.898) data 0.000 (0.380) loss 2.1797 (2.2144) lr 4.7586e-03 eta 0:02:27
epoch [44/50] batch [6/24] time 0.425 (0.741) data 0.000 (0.253) loss 2.2148 (2.2074) lr 4.7586e-03 eta 0:01:59
epoch [44/50] batch [8/24] time 0.424 (0.662) data 0.000 (0.190) loss 2.2500 (2.2007) lr 4.7586e-03 eta 0:01:45
epoch [44/50] batch [10/24] time 0.427 (0.615) data 0.000 (0.152) loss 2.3223 (2.2107) lr 4.7586e-03 eta 0:01:37
epoch [44/50] batch [12/24] time 0.425 (0.583) data 0.000 (0.127) loss 2.0996 (2.2249) lr 4.7586e-03 eta 0:01:30
epoch [44/50] batch [14/24] time 0.472 (0.564) data 0.000 (0.109) loss 2.2422 (2.2296) lr 4.7586e-03 eta 0:01:26
epoch [44/50] batch [16/24] time 0.424 (0.547) data 0.000 (0.095) loss 2.1973 (2.2180) lr 4.7586e-03 eta 0:01:23
epoch [44/50] batch [18/24] time 0.425 (0.533) data 0.000 (0.085) loss 2.2773 (2.2199) lr 4.7586e-03 eta 0:01:19
epoch [44/50] batch [20/24] time 0.425 (0.522) data 0.000 (0.076) loss 2.2910 (2.2251) lr 4.7586e-03 eta 0:01:17
epoch [44/50] batch [22/24] time 0.424 (0.514) data 0.000 (0.069) loss 2.2344 (2.2297) lr 4.7586e-03 eta 0:01:14
epoch [44/50] batch [24/24] time 0.431 (0.506) data 0.000 (0.063) loss 2.1562 (2.2239) lr 3.5112e-03 eta 0:01:12
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 570
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 69.1%

epoch [45/50] batch [2/24] time 0.490 (1.405) data 0.000 (0.817) loss 2.2148 (2.2178) lr 3.5112e-03 eta 0:03:19
epoch [45/50] batch [4/24] time 0.427 (0.916) data 0.000 (0.409) loss 2.4023 (2.2676) lr 3.5112e-03 eta 0:02:08
epoch [45/50] batch [6/24] time 0.426 (0.753) data 0.000 (0.273) loss 2.1211 (2.2520) lr 3.5112e-03 eta 0:01:43
epoch [45/50] batch [8/24] time 0.426 (0.671) data 0.000 (0.205) loss 2.1973 (2.2605) lr 3.5112e-03 eta 0:01:31
epoch [45/50] batch [10/24] time 0.426 (0.623) data 0.000 (0.164) loss 2.2266 (2.2527) lr 3.5112e-03 eta 0:01:23
epoch [45/50] batch [12/24] time 0.426 (0.597) data 0.000 (0.136) loss 2.2871 (2.2358) lr 3.5112e-03 eta 0:01:18
epoch [45/50] batch [14/24] time 0.426 (0.573) data 0.000 (0.117) loss 2.2637 (2.2289) lr 3.5112e-03 eta 0:01:14
epoch [45/50] batch [16/24] time 0.426 (0.555) data 0.000 (0.102) loss 2.0391 (2.2156) lr 3.5112e-03 eta 0:01:10
epoch [45/50] batch [18/24] time 0.427 (0.540) data 0.000 (0.091) loss 2.2812 (2.2133) lr 3.5112e-03 eta 0:01:08
epoch [45/50] batch [20/24] time 0.426 (0.529) data 0.000 (0.082) loss 2.3027 (2.2170) lr 3.5112e-03 eta 0:01:05
epoch [45/50] batch [22/24] time 0.427 (0.520) data 0.000 (0.075) loss 2.1738 (2.2135) lr 3.5112e-03 eta 0:01:03
epoch [45/50] batch [24/24] time 0.425 (0.512) data 0.000 (0.068) loss 2.2148 (2.2093) lr 2.4472e-03 eta 0:01:01
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.23s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 576
* accuracy: 70.9%
* error: 29.1%
* macro_f1: 69.9%

epoch [46/50] batch [2/24] time 0.568 (1.299) data 0.000 (0.628) loss 2.2168 (2.1602) lr 2.4472e-03 eta 0:02:33
epoch [46/50] batch [4/24] time 0.427 (0.865) data 0.000 (0.314) loss 2.2305 (2.1890) lr 2.4472e-03 eta 0:01:40
epoch [46/50] batch [6/24] time 0.424 (0.718) data 0.000 (0.209) loss 2.1191 (2.1855) lr 2.4472e-03 eta 0:01:21
epoch [46/50] batch [8/24] time 0.424 (0.645) data 0.000 (0.157) loss 2.2129 (2.1926) lr 2.4472e-03 eta 0:01:12
epoch [46/50] batch [10/24] time 0.427 (0.601) data 0.000 (0.126) loss 2.3457 (2.2076) lr 2.4472e-03 eta 0:01:06
epoch [46/50] batch [12/24] time 0.427 (0.572) data 0.000 (0.105) loss 2.2598 (2.2173) lr 2.4472e-03 eta 0:01:01
epoch [46/50] batch [14/24] time 0.425 (0.551) data 0.000 (0.090) loss 2.1699 (2.2088) lr 2.4472e-03 eta 0:00:58
epoch [46/50] batch [16/24] time 0.424 (0.535) data 0.000 (0.079) loss 2.1621 (2.2113) lr 2.4472e-03 eta 0:00:55
epoch [46/50] batch [18/24] time 0.425 (0.523) data 0.000 (0.070) loss 2.2383 (2.2076) lr 2.4472e-03 eta 0:00:53
epoch [46/50] batch [20/24] time 0.425 (0.513) data 0.000 (0.063) loss 2.2090 (2.2135) lr 2.4472e-03 eta 0:00:51
epoch [46/50] batch [22/24] time 0.424 (0.505) data 0.000 (0.057) loss 2.0781 (2.2107) lr 2.4472e-03 eta 0:00:49
epoch [46/50] batch [24/24] time 0.425 (0.499) data 0.000 (0.053) loss 2.0742 (2.2141) lr 1.5708e-03 eta 0:00:47
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 576
* accuracy: 70.9%
* error: 29.1%
* macro_f1: 69.7%

epoch [47/50] batch [2/24] time 0.624 (1.226) data 0.000 (0.549) loss 2.0879 (2.1260) lr 1.5708e-03 eta 0:01:55
epoch [47/50] batch [4/24] time 0.425 (0.842) data 0.000 (0.275) loss 2.1270 (2.1187) lr 1.5708e-03 eta 0:01:17
epoch [47/50] batch [6/24] time 0.426 (0.703) data 0.000 (0.183) loss 2.2656 (2.1875) lr 1.5708e-03 eta 0:01:03
epoch [47/50] batch [8/24] time 0.425 (0.634) data 0.000 (0.137) loss 2.1777 (2.1987) lr 1.5708e-03 eta 0:00:55
epoch [47/50] batch [10/24] time 0.426 (0.592) data 0.000 (0.110) loss 2.1953 (2.1771) lr 1.5708e-03 eta 0:00:50
epoch [47/50] batch [12/24] time 0.425 (0.564) data 0.000 (0.092) loss 2.2344 (2.1961) lr 1.5708e-03 eta 0:00:47
epoch [47/50] batch [14/24] time 0.427 (0.545) data 0.000 (0.079) loss 2.1387 (2.1982) lr 1.5708e-03 eta 0:00:44
epoch [47/50] batch [16/24] time 0.425 (0.530) data 0.000 (0.069) loss 2.3379 (2.2058) lr 1.5708e-03 eta 0:00:42
epoch [47/50] batch [18/24] time 0.425 (0.518) data 0.000 (0.061) loss 2.1953 (2.2054) lr 1.5708e-03 eta 0:00:40
epoch [47/50] batch [20/24] time 0.433 (0.509) data 0.000 (0.055) loss 2.2461 (2.2070) lr 1.5708e-03 eta 0:00:38
epoch [47/50] batch [22/24] time 0.425 (0.501) data 0.000 (0.050) loss 2.2715 (2.2101) lr 1.5708e-03 eta 0:00:37
epoch [47/50] batch [24/24] time 0.428 (0.495) data 0.000 (0.046) loss 2.2539 (2.2119) lr 8.8564e-04 eta 0:00:35
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.22s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 575
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 69.7%

epoch [48/50] batch [2/24] time 0.508 (1.384) data 0.000 (0.783) loss 2.1523 (2.2002) lr 8.8564e-04 eta 0:01:36
epoch [48/50] batch [4/24] time 0.426 (0.907) data 0.000 (0.392) loss 2.1973 (2.2080) lr 8.8564e-04 eta 0:01:01
epoch [48/50] batch [6/24] time 0.429 (0.748) data 0.000 (0.261) loss 2.1445 (2.1904) lr 8.8564e-04 eta 0:00:49
epoch [48/50] batch [8/24] time 0.426 (0.667) data 0.000 (0.196) loss 2.2441 (2.2075) lr 8.8564e-04 eta 0:00:42
epoch [48/50] batch [10/24] time 0.427 (0.619) data 0.000 (0.157) loss 2.2891 (2.2180) lr 8.8564e-04 eta 0:00:38
epoch [48/50] batch [12/24] time 0.431 (0.588) data 0.000 (0.131) loss 2.0059 (2.1807) lr 8.8564e-04 eta 0:00:35
epoch [48/50] batch [14/24] time 0.427 (0.565) data 0.000 (0.112) loss 2.1973 (2.1779) lr 8.8564e-04 eta 0:00:32
epoch [48/50] batch [16/24] time 0.425 (0.548) data 0.000 (0.098) loss 2.1191 (2.1776) lr 8.8564e-04 eta 0:00:30
epoch [48/50] batch [18/24] time 0.425 (0.534) data 0.000 (0.087) loss 2.1660 (2.1702) lr 8.8564e-04 eta 0:00:28
epoch [48/50] batch [20/24] time 0.428 (0.523) data 0.000 (0.078) loss 2.1523 (2.1735) lr 8.8564e-04 eta 0:00:27
epoch [48/50] batch [22/24] time 0.427 (0.515) data 0.000 (0.071) loss 2.3809 (2.1743) lr 8.8564e-04 eta 0:00:25
epoch [48/50] batch [24/24] time 0.427 (0.507) data 0.000 (0.065) loss 2.2090 (2.1858) lr 3.9426e-04 eta 0:00:24
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 577
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 70.0%

epoch [49/50] batch [2/24] time 0.640 (1.285) data 0.001 (0.577) loss 2.3438 (2.2529) lr 3.9426e-04 eta 0:00:59
epoch [49/50] batch [4/24] time 0.426 (0.857) data 0.000 (0.289) loss 2.0840 (2.2280) lr 3.9426e-04 eta 0:00:37
epoch [49/50] batch [6/24] time 0.426 (0.713) data 0.000 (0.193) loss 2.1992 (2.2002) lr 3.9426e-04 eta 0:00:29
epoch [49/50] batch [8/24] time 0.426 (0.642) data 0.000 (0.144) loss 2.1328 (2.1741) lr 3.9426e-04 eta 0:00:25
epoch [49/50] batch [10/24] time 0.426 (0.598) data 0.000 (0.116) loss 2.0742 (2.1564) lr 3.9426e-04 eta 0:00:22
epoch [49/50] batch [12/24] time 0.436 (0.571) data 0.000 (0.096) loss 2.0918 (2.1706) lr 3.9426e-04 eta 0:00:20
epoch [49/50] batch [14/24] time 0.427 (0.550) data 0.000 (0.083) loss 2.2188 (2.1756) lr 3.9426e-04 eta 0:00:18
epoch [49/50] batch [16/24] time 0.426 (0.535) data 0.000 (0.072) loss 2.1016 (2.1642) lr 3.9426e-04 eta 0:00:17
epoch [49/50] batch [18/24] time 0.428 (0.523) data 0.000 (0.064) loss 2.2402 (2.1736) lr 3.9426e-04 eta 0:00:15
epoch [49/50] batch [20/24] time 0.426 (0.513) data 0.000 (0.058) loss 2.3945 (2.1883) lr 3.9426e-04 eta 0:00:14
epoch [49/50] batch [22/24] time 0.430 (0.505) data 0.000 (0.053) loss 2.3613 (2.1976) lr 3.9426e-04 eta 0:00:13
epoch [49/50] batch [24/24] time 0.428 (0.499) data 0.000 (0.048) loss 2.3320 (2.2068) lr 9.8664e-05 eta 0:00:11
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 575
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 69.7%

epoch [50/50] batch [2/24] time 0.611 (1.281) data 0.000 (0.599) loss 2.0977 (2.1455) lr 9.8664e-05 eta 0:00:28
epoch [50/50] batch [4/24] time 0.425 (0.857) data 0.000 (0.300) loss 2.0625 (2.0972) lr 9.8664e-05 eta 0:00:17
epoch [50/50] batch [6/24] time 0.427 (0.713) data 0.000 (0.200) loss 2.2285 (2.1494) lr 9.8664e-05 eta 0:00:12
epoch [50/50] batch [8/24] time 0.426 (0.642) data 0.000 (0.150) loss 2.1465 (2.1470) lr 9.8664e-05 eta 0:00:10
epoch [50/50] batch [10/24] time 0.427 (0.598) data 0.000 (0.120) loss 2.2715 (2.1941) lr 9.8664e-05 eta 0:00:08
epoch [50/50] batch [12/24] time 0.425 (0.570) data 0.000 (0.100) loss 2.2715 (2.1859) lr 9.8664e-05 eta 0:00:06
epoch [50/50] batch [14/24] time 0.427 (0.549) data 0.000 (0.086) loss 2.1484 (2.1881) lr 9.8664e-05 eta 0:00:05
epoch [50/50] batch [16/24] time 0.426 (0.534) data 0.000 (0.075) loss 2.2559 (2.1997) lr 9.8664e-05 eta 0:00:04
epoch [50/50] batch [18/24] time 0.426 (0.522) data 0.000 (0.067) loss 2.0684 (2.1969) lr 9.8664e-05 eta 0:00:03
epoch [50/50] batch [20/24] time 0.425 (0.512) data 0.000 (0.060) loss 2.2734 (2.2009) lr 9.8664e-05 eta 0:00:02
epoch [50/50] batch [22/24] time 0.430 (0.504) data 0.000 (0.055) loss 2.2031 (2.2002) lr 9.8664e-05 eta 0:00:01
epoch [50/50] batch [24/24] time 0.425 (0.501) data 0.000 (0.050) loss 2.0605 (2.1962) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.22s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]
=> result
* total: 812
* correct: 576
* accuracy: 70.9%
* error: 29.1%
* macro_f1: 69.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model.pth.tar-50
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar" (epoch = 38)
Evaluate on the *test* set
  0%|          | 0/21 [00:00<?, ?it/s]  5%|▍         | 1/21 [00:03<01:05,  3.26s/it] 10%|▉         | 2/21 [00:04<00:37,  1.95s/it] 14%|█▍        | 3/21 [00:05<00:25,  1.42s/it] 19%|█▉        | 4/21 [00:05<00:17,  1.02s/it] 24%|██▍       | 5/21 [00:05<00:12,  1.25it/s] 29%|██▊       | 6/21 [00:06<00:09,  1.50it/s] 33%|███▎      | 7/21 [00:06<00:08,  1.68it/s] 38%|███▊      | 8/21 [00:07<00:07,  1.85it/s] 43%|████▎     | 9/21 [00:07<00:05,  2.08it/s] 48%|████▊     | 10/21 [00:07<00:04,  2.23it/s] 52%|█████▏    | 11/21 [00:08<00:03,  2.55it/s] 57%|█████▋    | 12/21 [00:08<00:03,  2.84it/s] 62%|██████▏   | 13/21 [00:08<00:02,  3.08it/s] 67%|██████▋   | 14/21 [00:08<00:02,  3.27it/s] 71%|███████▏  | 15/21 [00:09<00:01,  3.42it/s] 76%|███████▌  | 16/21 [00:09<00:01,  3.53it/s] 81%|████████  | 17/21 [00:09<00:01,  3.61it/s] 86%|████████▌ | 18/21 [00:09<00:00,  3.67it/s] 90%|█████████ | 19/21 [00:10<00:00,  3.72it/s] 95%|█████████▌| 20/21 [00:10<00:00,  3.74it/s]100%|██████████| 21/21 [00:10<00:00,  4.40it/s]100%|██████████| 21/21 [00:10<00:00,  1.95it/s]
=> result
* total: 4,002
* correct: 2,896
* accuracy: 72.4%
* error: 27.6%
* macro_f1: 71.7%
Elapsed: 0:13:52
+ sh scripts/rpo_prime/base2new_test.sh stanford_cars 1 0 main_tmp1 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_1.pkl
SUBSAMPLE NEW CLASSES!
1568 823 4039
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      823
# test     4,039
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed1/prompt_learner/model-best.pth.tar" (epoch = 38)
Evaluate on the *test* set
  0%|          | 0/21 [00:00<?, ?it/s]  5%|▍         | 1/21 [00:07<02:21,  7.05s/it] 10%|▉         | 2/21 [00:07<01:00,  3.21s/it] 14%|█▍        | 3/21 [00:07<00:34,  1.93s/it] 19%|█▉        | 4/21 [00:08<00:22,  1.32s/it] 24%|██▍       | 5/21 [00:08<00:15,  1.06it/s] 29%|██▊       | 6/21 [00:08<00:10,  1.41it/s] 33%|███▎      | 7/21 [00:09<00:07,  1.78it/s] 38%|███▊      | 8/21 [00:09<00:06,  2.15it/s] 43%|████▎     | 9/21 [00:09<00:04,  2.49it/s] 48%|████▊     | 10/21 [00:09<00:03,  2.80it/s] 52%|█████▏    | 11/21 [00:10<00:03,  3.05it/s] 57%|█████▋    | 12/21 [00:10<00:02,  3.26it/s] 62%|██████▏   | 13/21 [00:10<00:02,  3.42it/s] 67%|██████▋   | 14/21 [00:10<00:01,  3.54it/s] 71%|███████▏  | 15/21 [00:11<00:01,  3.63it/s] 76%|███████▌  | 16/21 [00:11<00:01,  3.66it/s] 81%|████████  | 17/21 [00:11<00:01,  3.72it/s] 86%|████████▌ | 18/21 [00:12<00:00,  3.75it/s] 90%|█████████ | 19/21 [00:12<00:00,  3.78it/s] 95%|█████████▌| 20/21 [00:12<00:00,  3.80it/s]100%|██████████| 21/21 [00:12<00:00,  4.23it/s]100%|██████████| 21/21 [00:12<00:00,  1.64it/s]
=> result
* total: 4,039
* correct: 2,959
* accuracy: 73.3%
* error: 26.7%
* macro_f1: 72.1%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train.sh stanford_cars 2 0 main_tmp1 16
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
1568 812 4002
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      812
# test     4,002
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/50] batch [2/24] time 0.428 (2.294) data 0.000 (0.913) loss 2.7969 (3.0059) lr 1.0000e-01 eta 0:45:47
epoch [1/50] batch [4/24] time 0.426 (1.359) data 0.000 (0.457) loss 2.9512 (2.9092) lr 1.0000e-01 eta 0:27:05
epoch [1/50] batch [6/24] time 0.424 (1.049) data 0.000 (0.304) loss 2.8691 (2.9089) lr 1.0000e-01 eta 0:20:52
epoch [1/50] batch [8/24] time 0.426 (0.893) data 0.000 (0.228) loss 2.8789 (2.8823) lr 1.0000e-01 eta 0:17:44
epoch [1/50] batch [10/24] time 0.429 (0.801) data 0.000 (0.183) loss 2.7441 (2.8426) lr 1.0000e-01 eta 0:15:53
epoch [1/50] batch [12/24] time 0.428 (0.739) data 0.000 (0.152) loss 2.6543 (2.8192) lr 1.0000e-01 eta 0:14:37
epoch [1/50] batch [14/24] time 0.423 (0.694) data 0.000 (0.131) loss 2.5488 (2.7875) lr 1.0000e-01 eta 0:13:43
epoch [1/50] batch [16/24] time 0.429 (0.661) data 0.000 (0.114) loss 2.6348 (2.7700) lr 1.0000e-01 eta 0:13:02
epoch [1/50] batch [18/24] time 0.429 (0.635) data 0.000 (0.102) loss 2.4551 (2.7425) lr 1.0000e-01 eta 0:12:31
epoch [1/50] batch [20/24] time 0.424 (0.614) data 0.000 (0.091) loss 2.4297 (2.7139) lr 1.0000e-01 eta 0:12:05
epoch [1/50] batch [22/24] time 0.430 (0.597) data 0.000 (0.083) loss 2.4238 (2.6910) lr 1.0000e-01 eta 0:11:43
epoch [1/50] batch [24/24] time 0.424 (0.583) data 0.000 (0.076) loss 2.3906 (2.6651) lr 9.9901e-02 eta 0:11:25
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 530
* accuracy: 65.3%
* error: 34.7%
* macro_f1: 63.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [2/50] batch [2/24] time 0.502 (1.378) data 0.000 (0.749) loss 2.5547 (2.5557) lr 9.9901e-02 eta 0:26:57
epoch [2/50] batch [4/24] time 0.425 (0.904) data 0.000 (0.375) loss 2.4961 (2.5264) lr 9.9901e-02 eta 0:17:39
epoch [2/50] batch [6/24] time 0.483 (0.755) data 0.000 (0.250) loss 2.3770 (2.4769) lr 9.9901e-02 eta 0:14:43
epoch [2/50] batch [8/24] time 0.425 (0.673) data 0.000 (0.187) loss 2.5547 (2.4783) lr 9.9901e-02 eta 0:13:05
epoch [2/50] batch [10/24] time 0.425 (0.623) data 0.000 (0.150) loss 2.4902 (2.4727) lr 9.9901e-02 eta 0:12:06
epoch [2/50] batch [12/24] time 0.423 (0.590) data 0.000 (0.125) loss 2.6074 (2.4744) lr 9.9901e-02 eta 0:11:26
epoch [2/50] batch [14/24] time 0.427 (0.567) data 0.000 (0.107) loss 2.4648 (2.4676) lr 9.9901e-02 eta 0:10:58
epoch [2/50] batch [16/24] time 0.426 (0.549) data 0.000 (0.094) loss 2.6855 (2.4707) lr 9.9901e-02 eta 0:10:36
epoch [2/50] batch [18/24] time 0.428 (0.536) data 0.000 (0.083) loss 2.3984 (2.4757) lr 9.9901e-02 eta 0:10:20
epoch [2/50] batch [20/24] time 0.426 (0.525) data 0.000 (0.075) loss 2.4160 (2.4694) lr 9.9901e-02 eta 0:10:06
epoch [2/50] batch [22/24] time 0.434 (0.517) data 0.000 (0.068) loss 2.3770 (2.4613) lr 9.9901e-02 eta 0:09:56
epoch [2/50] batch [24/24] time 0.430 (0.509) data 0.000 (0.063) loss 2.5156 (2.4587) lr 9.9606e-02 eta 0:09:46
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 534
* accuracy: 65.8%
* error: 34.2%
* macro_f1: 64.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [3/50] batch [2/24] time 0.631 (1.278) data 0.000 (0.570) loss 2.5605 (2.6592) lr 9.9606e-02 eta 0:24:29
epoch [3/50] batch [4/24] time 0.427 (0.880) data 0.000 (0.285) loss 2.3164 (2.5176) lr 9.9606e-02 eta 0:16:49
epoch [3/50] batch [6/24] time 0.438 (0.731) data 0.000 (0.190) loss 2.2500 (2.4635) lr 9.9606e-02 eta 0:13:57
epoch [3/50] batch [8/24] time 0.424 (0.654) data 0.000 (0.143) loss 2.5020 (2.4568) lr 9.9606e-02 eta 0:12:28
epoch [3/50] batch [10/24] time 0.425 (0.608) data 0.000 (0.114) loss 2.4941 (2.4666) lr 9.9606e-02 eta 0:11:34
epoch [3/50] batch [12/24] time 0.434 (0.578) data 0.000 (0.095) loss 2.4961 (2.4603) lr 9.9606e-02 eta 0:10:59
epoch [3/50] batch [14/24] time 0.426 (0.557) data 0.000 (0.082) loss 2.5898 (2.4640) lr 9.9606e-02 eta 0:10:33
epoch [3/50] batch [16/24] time 0.428 (0.541) data 0.000 (0.071) loss 2.3887 (2.4447) lr 9.9606e-02 eta 0:10:14
epoch [3/50] batch [18/24] time 0.428 (0.528) data 0.000 (0.064) loss 2.4707 (2.4448) lr 9.9606e-02 eta 0:09:58
epoch [3/50] batch [20/24] time 0.426 (0.518) data 0.000 (0.057) loss 2.3555 (2.4415) lr 9.9606e-02 eta 0:09:46
epoch [3/50] batch [22/24] time 0.429 (0.510) data 0.000 (0.052) loss 2.4512 (2.4353) lr 9.9606e-02 eta 0:09:35
epoch [3/50] batch [24/24] time 0.430 (0.503) data 0.000 (0.048) loss 2.4473 (2.4345) lr 9.9114e-02 eta 0:09:27
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.11s/it] 40%|████      | 2/5 [00:03<00:04,  1.44s/it] 60%|██████    | 3/5 [00:03<00:01,  1.11it/s] 80%|████████  | 4/5 [00:03<00:00,  1.54it/s]100%|██████████| 5/5 [00:04<00:00,  1.23it/s]=> result
* total: 812
* correct: 534
* accuracy: 65.8%
* error: 34.2%
* macro_f1: 63.5%

epoch [4/50] batch [2/24] time 0.584 (1.339) data 0.000 (0.667) loss 2.5117 (2.4180) lr 9.9114e-02 eta 0:25:07
epoch [4/50] batch [4/24] time 0.432 (0.887) data 0.000 (0.334) loss 2.3906 (2.4155) lr 9.9114e-02 eta 0:16:37
epoch [4/50] batch [6/24] time 0.440 (0.738) data 0.000 (0.223) loss 2.4961 (2.4294) lr 9.9114e-02 eta 0:13:48
epoch [4/50] batch [8/24] time 0.426 (0.660) data 0.000 (0.167) loss 2.2871 (2.4470) lr 9.9114e-02 eta 0:12:19
epoch [4/50] batch [10/24] time 0.432 (0.615) data 0.000 (0.134) loss 2.3184 (2.4234) lr 9.9114e-02 eta 0:11:27
epoch [4/50] batch [12/24] time 0.426 (0.584) data 0.000 (0.111) loss 2.3770 (2.4181) lr 9.9114e-02 eta 0:10:51
epoch [4/50] batch [14/24] time 0.432 (0.562) data 0.000 (0.096) loss 2.2305 (2.4086) lr 9.9114e-02 eta 0:10:25
epoch [4/50] batch [16/24] time 0.433 (0.545) data 0.000 (0.084) loss 2.4180 (2.4150) lr 9.9114e-02 eta 0:10:06
epoch [4/50] batch [18/24] time 0.427 (0.532) data 0.000 (0.074) loss 2.4434 (2.4236) lr 9.9114e-02 eta 0:09:51
epoch [4/50] batch [20/24] time 0.432 (0.522) data 0.000 (0.067) loss 2.2188 (2.4208) lr 9.9114e-02 eta 0:09:38
epoch [4/50] batch [22/24] time 0.432 (0.515) data 0.000 (0.061) loss 2.4238 (2.4170) lr 9.9114e-02 eta 0:09:29
epoch [4/50] batch [24/24] time 0.426 (0.507) data 0.000 (0.056) loss 2.3691 (2.4117) lr 9.8429e-02 eta 0:09:19
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 537
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 64.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [5/50] batch [2/24] time 0.550 (1.364) data 0.000 (0.712) loss 2.3926 (2.3545) lr 9.8429e-02 eta 0:25:02
epoch [5/50] batch [4/24] time 0.426 (0.897) data 0.000 (0.356) loss 2.4023 (2.3960) lr 9.8429e-02 eta 0:16:26
epoch [5/50] batch [6/24] time 0.428 (0.740) data 0.000 (0.237) loss 2.2637 (2.3701) lr 9.8429e-02 eta 0:13:32
epoch [5/50] batch [8/24] time 0.430 (0.663) data 0.000 (0.178) loss 2.4922 (2.4280) lr 9.8429e-02 eta 0:12:06
epoch [5/50] batch [10/24] time 0.428 (0.616) data 0.000 (0.143) loss 2.3945 (2.4115) lr 9.8429e-02 eta 0:11:13
epoch [5/50] batch [12/24] time 0.425 (0.584) data 0.000 (0.119) loss 2.3750 (2.4040) lr 9.8429e-02 eta 0:10:37
epoch [5/50] batch [14/24] time 0.424 (0.561) data 0.000 (0.102) loss 2.4160 (2.3998) lr 9.8429e-02 eta 0:10:11
epoch [5/50] batch [16/24] time 0.425 (0.544) data 0.000 (0.089) loss 2.2441 (2.3821) lr 9.8429e-02 eta 0:09:52
epoch [5/50] batch [18/24] time 0.424 (0.531) data 0.000 (0.079) loss 2.4434 (2.3818) lr 9.8429e-02 eta 0:09:36
epoch [5/50] batch [20/24] time 0.425 (0.521) data 0.000 (0.071) loss 2.3906 (2.3919) lr 9.8429e-02 eta 0:09:24
epoch [5/50] batch [22/24] time 0.424 (0.512) data 0.000 (0.065) loss 2.2285 (2.3810) lr 9.8429e-02 eta 0:09:13
epoch [5/50] batch [24/24] time 0.432 (0.505) data 0.000 (0.060) loss 2.4805 (2.3829) lr 9.7553e-02 eta 0:09:05
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 535
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 64.1%

epoch [6/50] batch [2/24] time 0.610 (1.302) data 0.001 (0.607) loss 2.5039 (2.4365) lr 9.7553e-02 eta 0:23:23
epoch [6/50] batch [4/24] time 0.426 (0.865) data 0.000 (0.304) loss 2.3711 (2.4307) lr 9.7553e-02 eta 0:15:30
epoch [6/50] batch [6/24] time 0.426 (0.718) data 0.000 (0.203) loss 2.5762 (2.4544) lr 9.7553e-02 eta 0:12:51
epoch [6/50] batch [8/24] time 0.426 (0.645) data 0.000 (0.152) loss 2.3633 (2.4275) lr 9.7553e-02 eta 0:11:31
epoch [6/50] batch [10/24] time 0.426 (0.603) data 0.000 (0.122) loss 2.3652 (2.3979) lr 9.7553e-02 eta 0:10:45
epoch [6/50] batch [12/24] time 0.424 (0.574) data 0.000 (0.101) loss 2.6992 (2.4232) lr 9.7553e-02 eta 0:10:13
epoch [6/50] batch [14/24] time 0.424 (0.553) data 0.000 (0.087) loss 2.2812 (2.4037) lr 9.7553e-02 eta 0:09:49
epoch [6/50] batch [16/24] time 0.425 (0.537) data 0.000 (0.076) loss 2.2910 (2.3903) lr 9.7553e-02 eta 0:09:31
epoch [6/50] batch [18/24] time 0.426 (0.525) data 0.000 (0.068) loss 2.3242 (2.3936) lr 9.7553e-02 eta 0:09:17
epoch [6/50] batch [20/24] time 0.426 (0.515) data 0.000 (0.061) loss 2.6387 (2.4133) lr 9.7553e-02 eta 0:09:05
epoch [6/50] batch [22/24] time 0.429 (0.507) data 0.000 (0.055) loss 2.4648 (2.4123) lr 9.7553e-02 eta 0:08:56
epoch [6/50] batch [24/24] time 0.426 (0.500) data 0.000 (0.051) loss 2.3086 (2.4025) lr 9.6489e-02 eta 0:08:48
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 540
* accuracy: 66.5%
* error: 33.5%
* macro_f1: 64.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [7/50] batch [2/24] time 0.572 (1.329) data 0.000 (0.664) loss 2.3301 (2.3369) lr 9.6489e-02 eta 0:23:20
epoch [7/50] batch [4/24] time 0.433 (0.896) data 0.000 (0.332) loss 2.4629 (2.3740) lr 9.6489e-02 eta 0:15:42
epoch [7/50] batch [6/24] time 0.427 (0.740) data 0.000 (0.221) loss 2.4082 (2.3633) lr 9.6489e-02 eta 0:12:57
epoch [7/50] batch [8/24] time 0.426 (0.663) data 0.000 (0.166) loss 2.3633 (2.3611) lr 9.6489e-02 eta 0:11:34
epoch [7/50] batch [10/24] time 0.427 (0.616) data 0.000 (0.133) loss 2.2969 (2.3635) lr 9.6489e-02 eta 0:10:43
epoch [7/50] batch [12/24] time 0.426 (0.585) data 0.000 (0.111) loss 2.2891 (2.3625) lr 9.6489e-02 eta 0:10:10
epoch [7/50] batch [14/24] time 0.432 (0.562) data 0.000 (0.095) loss 2.2285 (2.3450) lr 9.6489e-02 eta 0:09:46
epoch [7/50] batch [16/24] time 0.427 (0.546) data 0.000 (0.083) loss 2.4102 (2.3585) lr 9.6489e-02 eta 0:09:27
epoch [7/50] batch [18/24] time 0.433 (0.533) data 0.000 (0.074) loss 2.6445 (2.3735) lr 9.6489e-02 eta 0:09:12
epoch [7/50] batch [20/24] time 0.432 (0.522) data 0.000 (0.067) loss 2.1602 (2.3545) lr 9.6489e-02 eta 0:09:01
epoch [7/50] batch [22/24] time 0.426 (0.514) data 0.000 (0.061) loss 2.3672 (2.3601) lr 9.6489e-02 eta 0:08:51
epoch [7/50] batch [24/24] time 0.427 (0.507) data 0.000 (0.056) loss 2.3809 (2.3564) lr 9.5241e-02 eta 0:08:42
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.54s/it] 60%|██████    | 3/5 [00:03<00:01,  1.04it/s] 80%|████████  | 4/5 [00:04<00:00,  1.45it/s]100%|██████████| 5/5 [00:04<00:00,  1.16it/s]=> result
* total: 812
* correct: 539
* accuracy: 66.4%
* error: 33.6%
* macro_f1: 64.7%

epoch [8/50] batch [2/24] time 0.617 (1.293) data 0.000 (0.598) loss 2.3574 (2.4248) lr 9.5241e-02 eta 0:22:11
epoch [8/50] batch [4/24] time 0.429 (0.872) data 0.000 (0.299) loss 2.1582 (2.3721) lr 9.5241e-02 eta 0:14:56
epoch [8/50] batch [6/24] time 0.425 (0.724) data 0.000 (0.199) loss 2.1289 (2.3672) lr 9.5241e-02 eta 0:12:22
epoch [8/50] batch [8/24] time 0.428 (0.650) data 0.000 (0.150) loss 2.4785 (2.3782) lr 9.5241e-02 eta 0:11:05
epoch [8/50] batch [10/24] time 0.426 (0.606) data 0.000 (0.120) loss 2.3926 (2.3621) lr 9.5241e-02 eta 0:10:19
epoch [8/50] batch [12/24] time 0.431 (0.577) data 0.000 (0.100) loss 2.3828 (2.3706) lr 9.5241e-02 eta 0:09:48
epoch [8/50] batch [14/24] time 0.426 (0.555) data 0.000 (0.086) loss 2.1680 (2.3534) lr 9.5241e-02 eta 0:09:25
epoch [8/50] batch [16/24] time 0.426 (0.539) data 0.000 (0.075) loss 2.3359 (2.3518) lr 9.5241e-02 eta 0:09:07
epoch [8/50] batch [18/24] time 0.425 (0.527) data 0.000 (0.067) loss 2.4355 (2.3672) lr 9.5241e-02 eta 0:08:54
epoch [8/50] batch [20/24] time 0.432 (0.522) data 0.000 (0.060) loss 2.2832 (2.3695) lr 9.5241e-02 eta 0:08:47
epoch [8/50] batch [22/24] time 0.427 (0.513) data 0.000 (0.055) loss 2.3711 (2.3634) lr 9.5241e-02 eta 0:08:38
epoch [8/50] batch [24/24] time 0.426 (0.506) data 0.000 (0.050) loss 2.1328 (2.3534) lr 9.3815e-02 eta 0:08:30
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 537
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 64.3%

epoch [9/50] batch [2/24] time 0.447 (1.432) data 0.000 (0.823) loss 2.4141 (2.3643) lr 9.3815e-02 eta 0:24:00
epoch [9/50] batch [4/24] time 0.424 (0.928) data 0.000 (0.412) loss 2.2520 (2.2944) lr 9.3815e-02 eta 0:15:31
epoch [9/50] batch [6/24] time 0.424 (0.760) data 0.000 (0.274) loss 2.3809 (2.3327) lr 9.3815e-02 eta 0:12:41
epoch [9/50] batch [8/24] time 0.426 (0.677) data 0.000 (0.206) loss 2.5332 (2.3809) lr 9.3815e-02 eta 0:11:16
epoch [9/50] batch [10/24] time 0.424 (0.626) data 0.000 (0.165) loss 2.5938 (2.4064) lr 9.3815e-02 eta 0:10:24
epoch [9/50] batch [12/24] time 0.423 (0.592) data 0.000 (0.137) loss 2.0449 (2.3747) lr 9.3815e-02 eta 0:09:49
epoch [9/50] batch [14/24] time 0.423 (0.568) data 0.000 (0.118) loss 2.4102 (2.3647) lr 9.3815e-02 eta 0:09:24
epoch [9/50] batch [16/24] time 0.426 (0.550) data 0.000 (0.103) loss 2.3457 (2.3818) lr 9.3815e-02 eta 0:09:05
epoch [9/50] batch [18/24] time 0.425 (0.536) data 0.000 (0.092) loss 2.4102 (2.3839) lr 9.3815e-02 eta 0:08:50
epoch [9/50] batch [20/24] time 0.429 (0.525) data 0.000 (0.082) loss 2.4297 (2.3863) lr 9.3815e-02 eta 0:08:39
epoch [9/50] batch [22/24] time 0.425 (0.516) data 0.000 (0.075) loss 2.2910 (2.3881) lr 9.3815e-02 eta 0:08:28
epoch [9/50] batch [24/24] time 0.425 (0.509) data 0.000 (0.069) loss 2.2637 (2.3781) lr 9.2216e-02 eta 0:08:20
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 548
* accuracy: 67.5%
* error: 32.5%
* macro_f1: 65.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [10/50] batch [2/24] time 0.607 (1.304) data 0.001 (0.609) loss 2.3711 (2.3213) lr 9.2216e-02 eta 0:21:20
epoch [10/50] batch [4/24] time 0.427 (0.882) data 0.000 (0.305) loss 2.2422 (2.3164) lr 9.2216e-02 eta 0:14:24
epoch [10/50] batch [6/24] time 0.429 (0.731) data 0.000 (0.203) loss 2.2949 (2.3223) lr 9.2216e-02 eta 0:11:54
epoch [10/50] batch [8/24] time 0.431 (0.655) data 0.000 (0.152) loss 2.4707 (2.3198) lr 9.2216e-02 eta 0:10:39
epoch [10/50] batch [10/24] time 0.433 (0.610) data 0.000 (0.122) loss 2.3379 (2.3379) lr 9.2216e-02 eta 0:09:54
epoch [10/50] batch [12/24] time 0.426 (0.580) data 0.000 (0.102) loss 2.2617 (2.3304) lr 9.2216e-02 eta 0:09:23
epoch [10/50] batch [14/24] time 0.428 (0.558) data 0.000 (0.087) loss 2.3457 (2.3255) lr 9.2216e-02 eta 0:09:01
epoch [10/50] batch [16/24] time 0.426 (0.541) data 0.000 (0.076) loss 2.3281 (2.3362) lr 9.2216e-02 eta 0:08:44
epoch [10/50] batch [18/24] time 0.426 (0.529) data 0.000 (0.068) loss 2.3086 (2.3440) lr 9.2216e-02 eta 0:08:30
epoch [10/50] batch [20/24] time 0.430 (0.519) data 0.000 (0.061) loss 2.2676 (2.3460) lr 9.2216e-02 eta 0:08:19
epoch [10/50] batch [22/24] time 0.427 (0.510) data 0.000 (0.056) loss 2.4121 (2.3404) lr 9.2216e-02 eta 0:08:10
epoch [10/50] batch [24/24] time 0.428 (0.503) data 0.000 (0.051) loss 2.3516 (2.3420) lr 9.0451e-02 eta 0:08:03
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.22s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 554
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 66.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model.pth.tar-10

epoch [11/50] batch [2/24] time 0.506 (1.366) data 0.000 (0.761) loss 2.2441 (2.2422) lr 9.0451e-02 eta 0:21:48
epoch [11/50] batch [4/24] time 0.427 (0.900) data 0.000 (0.381) loss 2.3574 (2.2622) lr 9.0451e-02 eta 0:14:20
epoch [11/50] batch [6/24] time 0.427 (0.742) data 0.000 (0.254) loss 2.3984 (2.3148) lr 9.0451e-02 eta 0:11:48
epoch [11/50] batch [8/24] time 0.426 (0.663) data 0.000 (0.190) loss 2.3047 (2.3057) lr 9.0451e-02 eta 0:10:31
epoch [11/50] batch [10/24] time 0.425 (0.616) data 0.000 (0.152) loss 2.3281 (2.3062) lr 9.0451e-02 eta 0:09:45
epoch [11/50] batch [12/24] time 0.425 (0.584) data 0.000 (0.127) loss 2.4434 (2.3247) lr 9.0451e-02 eta 0:09:13
epoch [11/50] batch [14/24] time 0.431 (0.562) data 0.000 (0.109) loss 2.5332 (2.3298) lr 9.0451e-02 eta 0:08:51
epoch [11/50] batch [16/24] time 0.426 (0.545) data 0.000 (0.095) loss 2.2793 (2.3390) lr 9.0451e-02 eta 0:08:34
epoch [11/50] batch [18/24] time 0.429 (0.532) data 0.000 (0.085) loss 2.4766 (2.3509) lr 9.0451e-02 eta 0:08:21
epoch [11/50] batch [20/24] time 0.430 (0.522) data 0.000 (0.076) loss 2.4805 (2.3507) lr 9.0451e-02 eta 0:08:10
epoch [11/50] batch [22/24] time 0.431 (0.514) data 0.000 (0.069) loss 2.3086 (2.3499) lr 9.0451e-02 eta 0:08:01
epoch [11/50] batch [24/24] time 0.428 (0.507) data 0.000 (0.064) loss 2.2773 (2.3491) lr 8.8526e-02 eta 0:07:54
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 551
* accuracy: 67.9%
* error: 32.1%
* macro_f1: 66.7%

epoch [12/50] batch [2/24] time 0.582 (1.368) data 0.000 (0.709) loss 2.4102 (2.4727) lr 8.8526e-02 eta 0:21:17
epoch [12/50] batch [4/24] time 0.425 (0.900) data 0.000 (0.355) loss 2.3867 (2.4067) lr 8.8526e-02 eta 0:13:59
epoch [12/50] batch [6/24] time 0.424 (0.742) data 0.000 (0.237) loss 2.1836 (2.3776) lr 8.8526e-02 eta 0:11:29
epoch [12/50] batch [8/24] time 0.426 (0.663) data 0.000 (0.178) loss 2.1699 (2.3440) lr 8.8526e-02 eta 0:10:14
epoch [12/50] batch [10/24] time 0.425 (0.615) data 0.000 (0.142) loss 2.3965 (2.3543) lr 8.8526e-02 eta 0:09:29
epoch [12/50] batch [12/24] time 0.424 (0.583) data 0.000 (0.118) loss 2.2344 (2.3368) lr 8.8526e-02 eta 0:08:58
epoch [12/50] batch [14/24] time 0.424 (0.560) data 0.000 (0.102) loss 2.3164 (2.3432) lr 8.8526e-02 eta 0:08:36
epoch [12/50] batch [16/24] time 0.424 (0.543) data 0.000 (0.089) loss 2.3184 (2.3409) lr 8.8526e-02 eta 0:08:19
epoch [12/50] batch [18/24] time 0.424 (0.530) data 0.000 (0.079) loss 2.3125 (2.3364) lr 8.8526e-02 eta 0:08:06
epoch [12/50] batch [20/24] time 0.428 (0.520) data 0.000 (0.071) loss 2.3945 (2.3379) lr 8.8526e-02 eta 0:07:56
epoch [12/50] batch [22/24] time 0.425 (0.511) data 0.000 (0.065) loss 2.2637 (2.3351) lr 8.8526e-02 eta 0:07:47
epoch [12/50] batch [24/24] time 0.425 (0.504) data 0.000 (0.059) loss 2.2988 (2.3347) lr 8.6448e-02 eta 0:07:39
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 546
* accuracy: 67.2%
* error: 32.8%
* macro_f1: 65.8%

epoch [13/50] batch [2/24] time 0.601 (1.307) data 0.000 (0.640) loss 2.3633 (2.3896) lr 8.6448e-02 eta 0:19:49
epoch [13/50] batch [4/24] time 0.519 (0.896) data 0.000 (0.320) loss 2.1992 (2.3066) lr 8.6448e-02 eta 0:13:33
epoch [13/50] batch [6/24] time 0.437 (0.742) data 0.000 (0.213) loss 2.2266 (2.2764) lr 8.6448e-02 eta 0:11:12
epoch [13/50] batch [8/24] time 0.427 (0.663) data 0.000 (0.160) loss 2.1777 (2.2661) lr 8.6448e-02 eta 0:09:59
epoch [13/50] batch [10/24] time 0.436 (0.617) data 0.000 (0.128) loss 2.1855 (2.2584) lr 8.6448e-02 eta 0:09:16
epoch [13/50] batch [12/24] time 0.428 (0.586) data 0.000 (0.107) loss 2.1992 (2.2629) lr 8.6448e-02 eta 0:08:47
epoch [13/50] batch [14/24] time 0.426 (0.563) data 0.000 (0.092) loss 2.3008 (2.2708) lr 8.6448e-02 eta 0:08:25
epoch [13/50] batch [16/24] time 0.425 (0.546) data 0.000 (0.080) loss 2.3398 (2.2772) lr 8.6448e-02 eta 0:08:09
epoch [13/50] batch [18/24] time 0.426 (0.533) data 0.000 (0.071) loss 2.3203 (2.2875) lr 8.6448e-02 eta 0:07:56
epoch [13/50] batch [20/24] time 0.428 (0.523) data 0.000 (0.064) loss 2.3789 (2.2981) lr 8.6448e-02 eta 0:07:46
epoch [13/50] batch [22/24] time 0.429 (0.514) data 0.000 (0.058) loss 2.3633 (2.3071) lr 8.6448e-02 eta 0:07:37
epoch [13/50] batch [24/24] time 0.426 (0.507) data 0.000 (0.054) loss 2.4941 (2.3127) lr 8.4227e-02 eta 0:07:29
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 542
* accuracy: 66.7%
* error: 33.3%
* macro_f1: 65.1%

epoch [14/50] batch [2/24] time 0.438 (1.477) data 0.000 (0.955) loss 2.2051 (2.1973) lr 8.4227e-02 eta 0:21:48
epoch [14/50] batch [4/24] time 0.429 (0.954) data 0.000 (0.477) loss 2.3496 (2.2358) lr 8.4227e-02 eta 0:14:03
epoch [14/50] batch [6/24] time 0.426 (0.778) data 0.000 (0.318) loss 2.3027 (2.2357) lr 8.4227e-02 eta 0:11:26
epoch [14/50] batch [8/24] time 0.424 (0.689) data 0.000 (0.239) loss 2.3164 (2.2668) lr 8.4227e-02 eta 0:10:06
epoch [14/50] batch [10/24] time 0.424 (0.636) data 0.000 (0.191) loss 2.2363 (2.2680) lr 8.4227e-02 eta 0:09:18
epoch [14/50] batch [12/24] time 0.424 (0.601) data 0.000 (0.159) loss 2.1094 (2.2686) lr 8.4227e-02 eta 0:08:46
epoch [14/50] batch [14/24] time 0.424 (0.576) data 0.000 (0.137) loss 2.2871 (2.2819) lr 8.4227e-02 eta 0:08:23
epoch [14/50] batch [16/24] time 0.424 (0.557) data 0.000 (0.120) loss 2.3242 (2.2981) lr 8.4227e-02 eta 0:08:05
epoch [14/50] batch [18/24] time 0.426 (0.542) data 0.000 (0.106) loss 2.3984 (2.3160) lr 8.4227e-02 eta 0:07:51
epoch [14/50] batch [20/24] time 0.428 (0.531) data 0.000 (0.096) loss 2.2695 (2.3172) lr 8.4227e-02 eta 0:07:40
epoch [14/50] batch [22/24] time 0.433 (0.522) data 0.000 (0.087) loss 2.4082 (2.3285) lr 8.4227e-02 eta 0:07:31
epoch [14/50] batch [24/24] time 0.426 (0.514) data 0.000 (0.080) loss 2.1699 (2.3282) lr 8.1871e-02 eta 0:07:23
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 554
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 66.7%

epoch [15/50] batch [2/24] time 0.575 (1.296) data 0.000 (0.623) loss 2.3418 (2.3105) lr 8.1871e-02 eta 0:18:37
epoch [15/50] batch [4/24] time 0.431 (0.869) data 0.000 (0.311) loss 2.3379 (2.2915) lr 8.1871e-02 eta 0:12:27
epoch [15/50] batch [6/24] time 0.424 (0.722) data 0.000 (0.208) loss 2.3125 (2.2926) lr 8.1871e-02 eta 0:10:19
epoch [15/50] batch [8/24] time 0.425 (0.648) data 0.000 (0.156) loss 2.2754 (2.2917) lr 8.1871e-02 eta 0:09:14
epoch [15/50] batch [10/24] time 0.425 (0.603) data 0.000 (0.125) loss 2.1816 (2.2920) lr 8.1871e-02 eta 0:08:35
epoch [15/50] batch [12/24] time 0.429 (0.575) data 0.000 (0.104) loss 2.2793 (2.2949) lr 8.1871e-02 eta 0:08:09
epoch [15/50] batch [14/24] time 0.428 (0.554) data 0.000 (0.089) loss 2.1797 (2.2776) lr 8.1871e-02 eta 0:07:50
epoch [15/50] batch [16/24] time 0.426 (0.538) data 0.000 (0.078) loss 2.3711 (2.2856) lr 8.1871e-02 eta 0:07:35
epoch [15/50] batch [18/24] time 0.429 (0.525) data 0.000 (0.069) loss 2.3242 (2.2804) lr 8.1871e-02 eta 0:07:24
epoch [15/50] batch [20/24] time 0.425 (0.516) data 0.000 (0.062) loss 2.4355 (2.2919) lr 8.1871e-02 eta 0:07:15
epoch [15/50] batch [22/24] time 0.426 (0.507) data 0.000 (0.057) loss 2.4336 (2.3022) lr 8.1871e-02 eta 0:07:07
epoch [15/50] batch [24/24] time 0.425 (0.501) data 0.000 (0.052) loss 2.1797 (2.2923) lr 7.9389e-02 eta 0:07:00
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 554
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 67.1%

epoch [16/50] batch [2/24] time 0.563 (1.350) data 0.000 (0.684) loss 2.2793 (2.4043) lr 7.9389e-02 eta 0:18:51
epoch [16/50] batch [4/24] time 0.424 (0.887) data 0.000 (0.342) loss 2.4668 (2.4146) lr 7.9389e-02 eta 0:12:21
epoch [16/50] batch [6/24] time 0.423 (0.733) data 0.000 (0.228) loss 2.3926 (2.3949) lr 7.9389e-02 eta 0:10:10
epoch [16/50] batch [8/24] time 0.424 (0.656) data 0.000 (0.171) loss 2.3730 (2.3723) lr 7.9389e-02 eta 0:09:05
epoch [16/50] batch [10/24] time 0.424 (0.610) data 0.000 (0.137) loss 2.2812 (2.3729) lr 7.9389e-02 eta 0:08:26
epoch [16/50] batch [12/24] time 0.429 (0.579) data 0.000 (0.114) loss 2.3379 (2.3651) lr 7.9389e-02 eta 0:07:59
epoch [16/50] batch [14/24] time 0.427 (0.557) data 0.000 (0.098) loss 2.0293 (2.3315) lr 7.9389e-02 eta 0:07:40
epoch [16/50] batch [16/24] time 0.425 (0.541) data 0.000 (0.086) loss 2.2773 (2.3389) lr 7.9389e-02 eta 0:07:25
epoch [16/50] batch [18/24] time 0.424 (0.528) data 0.000 (0.076) loss 2.3789 (2.3366) lr 7.9389e-02 eta 0:07:13
epoch [16/50] batch [20/24] time 0.423 (0.517) data 0.000 (0.069) loss 2.4453 (2.3344) lr 7.9389e-02 eta 0:07:04
epoch [16/50] batch [22/24] time 0.424 (0.509) data 0.000 (0.062) loss 2.3105 (2.3281) lr 7.9389e-02 eta 0:06:56
epoch [16/50] batch [24/24] time 0.424 (0.502) data 0.000 (0.057) loss 2.3691 (2.3216) lr 7.6791e-02 eta 0:06:49
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.52s/it] 60%|██████    | 3/5 [00:03<00:01,  1.05it/s] 80%|████████  | 4/5 [00:04<00:00,  1.47it/s]100%|██████████| 5/5 [00:04<00:00,  1.17it/s]=> result
* total: 812
* correct: 555
* accuracy: 68.3%
* error: 31.7%
* macro_f1: 66.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [17/50] batch [2/24] time 0.674 (1.215) data 0.000 (0.489) loss 2.3027 (2.2637) lr 7.6791e-02 eta 0:16:29
epoch [17/50] batch [4/24] time 0.426 (0.841) data 0.000 (0.245) loss 2.2031 (2.3003) lr 7.6791e-02 eta 0:11:23
epoch [17/50] batch [6/24] time 0.424 (0.702) data 0.000 (0.163) loss 2.2910 (2.2741) lr 7.6791e-02 eta 0:09:28
epoch [17/50] batch [8/24] time 0.424 (0.633) data 0.000 (0.123) loss 2.1504 (2.2576) lr 7.6791e-02 eta 0:08:31
epoch [17/50] batch [10/24] time 0.424 (0.591) data 0.000 (0.098) loss 2.4707 (2.2887) lr 7.6791e-02 eta 0:07:56
epoch [17/50] batch [12/24] time 0.427 (0.563) data 0.000 (0.082) loss 2.2246 (2.2686) lr 7.6791e-02 eta 0:07:32
epoch [17/50] batch [14/24] time 0.432 (0.544) data 0.000 (0.070) loss 2.2500 (2.2810) lr 7.6791e-02 eta 0:07:16
epoch [17/50] batch [16/24] time 0.424 (0.529) data 0.000 (0.061) loss 2.1934 (2.2799) lr 7.6791e-02 eta 0:07:03
epoch [17/50] batch [18/24] time 0.425 (0.517) data 0.000 (0.055) loss 2.3125 (2.2829) lr 7.6791e-02 eta 0:06:52
epoch [17/50] batch [20/24] time 0.424 (0.508) data 0.000 (0.049) loss 2.4023 (2.2834) lr 7.6791e-02 eta 0:06:44
epoch [17/50] batch [22/24] time 0.425 (0.502) data 0.000 (0.045) loss 2.2812 (2.2858) lr 7.6791e-02 eta 0:06:38
epoch [17/50] batch [24/24] time 0.425 (0.495) data 0.000 (0.041) loss 2.4004 (2.2839) lr 7.4088e-02 eta 0:06:32
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 554
* accuracy: 68.2%
* error: 31.8%
* macro_f1: 66.5%

epoch [18/50] batch [2/24] time 0.612 (1.322) data 0.000 (0.656) loss 2.1836 (2.2109) lr 7.4088e-02 eta 0:17:24
epoch [18/50] batch [4/24] time 0.426 (0.875) data 0.000 (0.328) loss 2.3379 (2.2085) lr 7.4088e-02 eta 0:11:29
epoch [18/50] batch [6/24] time 0.425 (0.725) data 0.000 (0.219) loss 2.5000 (2.2604) lr 7.4088e-02 eta 0:09:29
epoch [18/50] batch [8/24] time 0.514 (0.661) data 0.000 (0.164) loss 2.1582 (2.2725) lr 7.4088e-02 eta 0:08:38
epoch [18/50] batch [10/24] time 0.428 (0.614) data 0.000 (0.131) loss 2.2910 (2.2795) lr 7.4088e-02 eta 0:08:00
epoch [18/50] batch [12/24] time 0.426 (0.583) data 0.000 (0.110) loss 2.1621 (2.2697) lr 7.4088e-02 eta 0:07:34
epoch [18/50] batch [14/24] time 0.425 (0.561) data 0.000 (0.094) loss 2.3184 (2.2794) lr 7.4088e-02 eta 0:07:16
epoch [18/50] batch [16/24] time 0.425 (0.544) data 0.000 (0.082) loss 2.3535 (2.2970) lr 7.4088e-02 eta 0:07:02
epoch [18/50] batch [18/24] time 0.426 (0.531) data 0.000 (0.073) loss 2.1914 (2.3041) lr 7.4088e-02 eta 0:06:51
epoch [18/50] batch [20/24] time 0.427 (0.521) data 0.000 (0.066) loss 2.0664 (2.2935) lr 7.4088e-02 eta 0:06:41
epoch [18/50] batch [22/24] time 0.426 (0.512) data 0.000 (0.060) loss 2.3887 (2.3041) lr 7.4088e-02 eta 0:06:34
epoch [18/50] batch [24/24] time 0.426 (0.505) data 0.000 (0.055) loss 2.5156 (2.3148) lr 7.1289e-02 eta 0:06:27
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 558
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 67.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [19/50] batch [2/24] time 0.529 (1.366) data 0.001 (0.726) loss 2.1973 (2.3096) lr 7.1289e-02 eta 0:17:26
epoch [19/50] batch [4/24] time 0.426 (0.898) data 0.000 (0.363) loss 2.1465 (2.2930) lr 7.1289e-02 eta 0:11:26
epoch [19/50] batch [6/24] time 0.426 (0.741) data 0.000 (0.242) loss 2.3809 (2.3105) lr 7.1289e-02 eta 0:09:24
epoch [19/50] batch [8/24] time 0.426 (0.662) data 0.000 (0.182) loss 2.4199 (2.3057) lr 7.1289e-02 eta 0:08:23
epoch [19/50] batch [10/24] time 0.426 (0.615) data 0.000 (0.145) loss 2.1172 (2.2912) lr 7.1289e-02 eta 0:07:45
epoch [19/50] batch [12/24] time 0.427 (0.583) data 0.000 (0.121) loss 2.4121 (2.3001) lr 7.1289e-02 eta 0:07:20
epoch [19/50] batch [14/24] time 0.426 (0.561) data 0.000 (0.104) loss 2.4453 (2.3087) lr 7.1289e-02 eta 0:07:02
epoch [19/50] batch [16/24] time 0.426 (0.544) data 0.000 (0.091) loss 2.3926 (2.3087) lr 7.1289e-02 eta 0:06:48
epoch [19/50] batch [18/24] time 0.426 (0.531) data 0.000 (0.081) loss 2.2598 (2.3213) lr 7.1289e-02 eta 0:06:38
epoch [19/50] batch [20/24] time 0.426 (0.520) data 0.000 (0.073) loss 2.2012 (2.3137) lr 7.1289e-02 eta 0:06:29
epoch [19/50] batch [22/24] time 0.429 (0.512) data 0.000 (0.066) loss 2.3398 (2.3082) lr 7.1289e-02 eta 0:06:21
epoch [19/50] batch [24/24] time 0.426 (0.505) data 0.000 (0.061) loss 2.1504 (2.3049) lr 6.8406e-02 eta 0:06:15
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 557
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 67.2%

epoch [20/50] batch [2/24] time 0.570 (1.331) data 0.000 (0.678) loss 2.2578 (2.2363) lr 6.8406e-02 eta 0:16:27
epoch [20/50] batch [4/24] time 0.425 (0.880) data 0.000 (0.339) loss 2.4805 (2.3091) lr 6.8406e-02 eta 0:10:51
epoch [20/50] batch [6/24] time 0.425 (0.729) data 0.000 (0.226) loss 2.2051 (2.2891) lr 6.8406e-02 eta 0:08:57
epoch [20/50] batch [8/24] time 0.424 (0.653) data 0.000 (0.170) loss 2.4258 (2.2871) lr 6.8406e-02 eta 0:08:00
epoch [20/50] batch [10/24] time 0.437 (0.611) data 0.000 (0.136) loss 2.3770 (2.3051) lr 6.8406e-02 eta 0:07:28
epoch [20/50] batch [12/24] time 0.429 (0.580) data 0.000 (0.113) loss 2.3906 (2.2987) lr 6.8406e-02 eta 0:07:04
epoch [20/50] batch [14/24] time 0.425 (0.558) data 0.000 (0.097) loss 2.1211 (2.2891) lr 6.8406e-02 eta 0:06:47
epoch [20/50] batch [16/24] time 0.424 (0.541) data 0.000 (0.085) loss 2.2715 (2.2749) lr 6.8406e-02 eta 0:06:33
epoch [20/50] batch [18/24] time 0.424 (0.528) data 0.000 (0.076) loss 2.4414 (2.2881) lr 6.8406e-02 eta 0:06:23
epoch [20/50] batch [20/24] time 0.424 (0.518) data 0.000 (0.068) loss 2.1660 (2.2842) lr 6.8406e-02 eta 0:06:15
epoch [20/50] batch [22/24] time 0.425 (0.510) data 0.000 (0.062) loss 2.1719 (2.2755) lr 6.8406e-02 eta 0:06:07
epoch [20/50] batch [24/24] time 0.425 (0.502) data 0.000 (0.057) loss 2.2207 (2.2742) lr 6.5451e-02 eta 0:06:01
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 557
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 67.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model.pth.tar-20

epoch [21/50] batch [2/24] time 0.540 (1.418) data 0.000 (0.797) loss 2.2129 (2.3076) lr 6.5451e-02 eta 0:16:57
epoch [21/50] batch [4/24] time 0.427 (0.923) data 0.000 (0.399) loss 2.4434 (2.3276) lr 6.5451e-02 eta 0:11:00
epoch [21/50] batch [6/24] time 0.427 (0.757) data 0.000 (0.266) loss 1.9844 (2.2435) lr 6.5451e-02 eta 0:09:00
epoch [21/50] batch [8/24] time 0.427 (0.674) data 0.000 (0.200) loss 2.3945 (2.2832) lr 6.5451e-02 eta 0:08:00
epoch [21/50] batch [10/24] time 0.426 (0.625) data 0.000 (0.160) loss 2.2324 (2.2668) lr 6.5451e-02 eta 0:07:23
epoch [21/50] batch [12/24] time 0.430 (0.593) data 0.000 (0.133) loss 2.3086 (2.2633) lr 6.5451e-02 eta 0:06:59
epoch [21/50] batch [14/24] time 0.427 (0.569) data 0.000 (0.114) loss 2.1973 (2.2783) lr 6.5451e-02 eta 0:06:41
epoch [21/50] batch [16/24] time 0.432 (0.551) data 0.000 (0.100) loss 2.3945 (2.2732) lr 6.5451e-02 eta 0:06:28
epoch [21/50] batch [18/24] time 0.432 (0.538) data 0.000 (0.089) loss 2.2695 (2.2686) lr 6.5451e-02 eta 0:06:17
epoch [21/50] batch [20/24] time 0.427 (0.527) data 0.000 (0.080) loss 2.2539 (2.2845) lr 6.5451e-02 eta 0:06:08
epoch [21/50] batch [22/24] time 0.428 (0.518) data 0.000 (0.073) loss 2.4551 (2.2957) lr 6.5451e-02 eta 0:06:01
epoch [21/50] batch [24/24] time 0.427 (0.511) data 0.000 (0.067) loss 2.3555 (2.2987) lr 6.2434e-02 eta 0:05:55
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.12s/it] 40%|████      | 2/5 [00:03<00:04,  1.50s/it] 60%|██████    | 3/5 [00:03<00:01,  1.06it/s] 80%|████████  | 4/5 [00:04<00:00,  1.49it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 557
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 66.9%

epoch [22/50] batch [2/24] time 0.521 (1.391) data 0.000 (0.674) loss 2.2227 (2.2744) lr 6.2434e-02 eta 0:16:05
epoch [22/50] batch [4/24] time 0.425 (0.910) data 0.000 (0.337) loss 2.3652 (2.3208) lr 6.2434e-02 eta 0:10:29
epoch [22/50] batch [6/24] time 0.425 (0.748) data 0.000 (0.225) loss 2.1934 (2.3138) lr 6.2434e-02 eta 0:08:36
epoch [22/50] batch [8/24] time 0.428 (0.668) data 0.000 (0.169) loss 2.1699 (2.2832) lr 6.2434e-02 eta 0:07:39
epoch [22/50] batch [10/24] time 0.427 (0.619) data 0.000 (0.135) loss 2.0820 (2.2812) lr 6.2434e-02 eta 0:07:04
epoch [22/50] batch [12/24] time 0.425 (0.587) data 0.000 (0.113) loss 2.2031 (2.2560) lr 6.2434e-02 eta 0:06:41
epoch [22/50] batch [14/24] time 0.422 (0.563) data 0.000 (0.096) loss 2.2656 (2.2542) lr 6.2434e-02 eta 0:06:24
epoch [22/50] batch [16/24] time 0.425 (0.546) data 0.000 (0.084) loss 2.3457 (2.2592) lr 6.2434e-02 eta 0:06:11
epoch [22/50] batch [18/24] time 0.425 (0.533) data 0.000 (0.075) loss 2.5234 (2.2815) lr 6.2434e-02 eta 0:06:01
epoch [22/50] batch [20/24] time 0.425 (0.523) data 0.000 (0.068) loss 2.1875 (2.2659) lr 6.2434e-02 eta 0:05:53
epoch [22/50] batch [22/24] time 0.430 (0.514) data 0.000 (0.061) loss 2.1328 (2.2559) lr 6.2434e-02 eta 0:05:46
epoch [22/50] batch [24/24] time 0.425 (0.507) data 0.000 (0.056) loss 2.3496 (2.2598) lr 5.9369e-02 eta 0:05:40
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 565
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 68.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [23/50] batch [2/24] time 0.649 (1.288) data 0.000 (0.592) loss 2.2930 (2.2676) lr 5.9369e-02 eta 0:14:23
epoch [23/50] batch [4/24] time 0.427 (0.862) data 0.000 (0.296) loss 2.3008 (2.2935) lr 5.9369e-02 eta 0:09:35
epoch [23/50] batch [6/24] time 0.427 (0.717) data 0.000 (0.197) loss 2.2559 (2.2910) lr 5.9369e-02 eta 0:07:57
epoch [23/50] batch [8/24] time 0.429 (0.645) data 0.000 (0.148) loss 2.1914 (2.2468) lr 5.9369e-02 eta 0:07:08
epoch [23/50] batch [10/24] time 0.428 (0.601) data 0.000 (0.118) loss 2.1934 (2.2521) lr 5.9369e-02 eta 0:06:37
epoch [23/50] batch [12/24] time 0.425 (0.572) data 0.000 (0.099) loss 2.3750 (2.2713) lr 5.9369e-02 eta 0:06:17
epoch [23/50] batch [14/24] time 0.427 (0.551) data 0.000 (0.085) loss 2.2695 (2.2817) lr 5.9369e-02 eta 0:06:02
epoch [23/50] batch [16/24] time 0.427 (0.536) data 0.000 (0.074) loss 2.2344 (2.2883) lr 5.9369e-02 eta 0:05:51
epoch [23/50] batch [18/24] time 0.426 (0.523) data 0.000 (0.066) loss 2.2637 (2.2981) lr 5.9369e-02 eta 0:05:42
epoch [23/50] batch [20/24] time 0.425 (0.514) data 0.000 (0.059) loss 2.3105 (2.3007) lr 5.9369e-02 eta 0:05:34
epoch [23/50] batch [22/24] time 0.428 (0.506) data 0.000 (0.054) loss 2.1406 (2.2969) lr 5.9369e-02 eta 0:05:28
epoch [23/50] batch [24/24] time 0.426 (0.499) data 0.000 (0.049) loss 2.3398 (2.2934) lr 5.6267e-02 eta 0:05:23
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 562
* accuracy: 69.2%
* error: 30.8%
* macro_f1: 67.8%

epoch [24/50] batch [2/24] time 0.633 (1.267) data 0.001 (0.576) loss 2.2695 (2.2217) lr 5.6267e-02 eta 0:13:38
epoch [24/50] batch [4/24] time 0.438 (0.867) data 0.000 (0.288) loss 2.3242 (2.2861) lr 5.6267e-02 eta 0:09:18
epoch [24/50] batch [6/24] time 0.427 (0.720) data 0.000 (0.192) loss 2.3477 (2.3008) lr 5.6267e-02 eta 0:07:42
epoch [24/50] batch [8/24] time 0.428 (0.647) data 0.000 (0.144) loss 2.2559 (2.3049) lr 5.6267e-02 eta 0:06:54
epoch [24/50] batch [10/24] time 0.426 (0.603) data 0.000 (0.115) loss 2.1895 (2.2996) lr 5.6267e-02 eta 0:06:24
epoch [24/50] batch [12/24] time 0.424 (0.574) data 0.000 (0.096) loss 2.3848 (2.3101) lr 5.6267e-02 eta 0:06:05
epoch [24/50] batch [14/24] time 0.428 (0.553) data 0.000 (0.082) loss 2.4180 (2.3076) lr 5.6267e-02 eta 0:05:50
epoch [24/50] batch [16/24] time 0.426 (0.537) data 0.000 (0.072) loss 2.3574 (2.3064) lr 5.6267e-02 eta 0:05:39
epoch [24/50] batch [18/24] time 0.430 (0.525) data 0.000 (0.064) loss 2.4219 (2.3212) lr 5.6267e-02 eta 0:05:30
epoch [24/50] batch [20/24] time 0.427 (0.515) data 0.000 (0.058) loss 2.4551 (2.3196) lr 5.6267e-02 eta 0:05:23
epoch [24/50] batch [22/24] time 0.427 (0.508) data 0.000 (0.053) loss 2.2578 (2.3086) lr 5.6267e-02 eta 0:05:17
epoch [24/50] batch [24/24] time 0.426 (0.501) data 0.000 (0.048) loss 2.1699 (2.3026) lr 5.3140e-02 eta 0:05:12
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 558
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 67.6%

epoch [25/50] batch [2/24] time 0.653 (1.276) data 0.001 (0.577) loss 2.2090 (2.1641) lr 5.3140e-02 eta 0:13:13
epoch [25/50] batch [4/24] time 0.426 (0.869) data 0.000 (0.289) loss 2.1816 (2.2183) lr 5.3140e-02 eta 0:08:59
epoch [25/50] batch [6/24] time 0.424 (0.722) data 0.000 (0.193) loss 2.1934 (2.1888) lr 5.3140e-02 eta 0:07:25
epoch [25/50] batch [8/24] time 0.423 (0.647) data 0.000 (0.145) loss 2.2266 (2.2144) lr 5.3140e-02 eta 0:06:38
epoch [25/50] batch [10/24] time 0.425 (0.603) data 0.000 (0.116) loss 2.2480 (2.2281) lr 5.3140e-02 eta 0:06:10
epoch [25/50] batch [12/24] time 0.422 (0.573) data 0.000 (0.096) loss 2.4414 (2.2516) lr 5.3140e-02 eta 0:05:50
epoch [25/50] batch [14/24] time 0.424 (0.552) data 0.000 (0.083) loss 2.4883 (2.2746) lr 5.3140e-02 eta 0:05:36
epoch [25/50] batch [16/24] time 0.423 (0.536) data 0.000 (0.072) loss 2.1797 (2.2645) lr 5.3140e-02 eta 0:05:25
epoch [25/50] batch [18/24] time 0.423 (0.523) data 0.000 (0.064) loss 2.2480 (2.2629) lr 5.3140e-02 eta 0:05:17
epoch [25/50] batch [20/24] time 0.423 (0.513) data 0.000 (0.058) loss 2.3223 (2.2606) lr 5.3140e-02 eta 0:05:09
epoch [25/50] batch [22/24] time 0.425 (0.505) data 0.000 (0.053) loss 2.3809 (2.2698) lr 5.3140e-02 eta 0:05:04
epoch [25/50] batch [24/24] time 0.427 (0.499) data 0.000 (0.048) loss 2.3086 (2.2712) lr 5.0000e-02 eta 0:04:59
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 557
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 67.4%

epoch [26/50] batch [2/24] time 0.544 (1.342) data 0.000 (0.706) loss 2.2988 (2.2744) lr 5.0000e-02 eta 0:13:22
epoch [26/50] batch [4/24] time 0.430 (0.900) data 0.000 (0.353) loss 2.1211 (2.2354) lr 5.0000e-02 eta 0:08:56
epoch [26/50] batch [6/24] time 0.425 (0.743) data 0.000 (0.236) loss 2.2227 (2.2764) lr 5.0000e-02 eta 0:07:21
epoch [26/50] batch [8/24] time 0.431 (0.665) data 0.000 (0.177) loss 2.2793 (2.2590) lr 5.0000e-02 eta 0:06:33
epoch [26/50] batch [10/24] time 0.425 (0.618) data 0.000 (0.141) loss 2.2754 (2.2762) lr 5.0000e-02 eta 0:06:04
epoch [26/50] batch [12/24] time 0.427 (0.587) data 0.000 (0.118) loss 2.3086 (2.2858) lr 5.0000e-02 eta 0:05:44
epoch [26/50] batch [14/24] time 0.427 (0.564) data 0.000 (0.101) loss 2.5684 (2.3125) lr 5.0000e-02 eta 0:05:30
epoch [26/50] batch [16/24] time 0.424 (0.547) data 0.000 (0.088) loss 2.3184 (2.2979) lr 5.0000e-02 eta 0:05:19
epoch [26/50] batch [18/24] time 0.426 (0.534) data 0.000 (0.079) loss 2.2266 (2.2847) lr 5.0000e-02 eta 0:05:10
epoch [26/50] batch [20/24] time 0.431 (0.524) data 0.000 (0.071) loss 2.1719 (2.2836) lr 5.0000e-02 eta 0:05:03
epoch [26/50] batch [22/24] time 0.431 (0.515) data 0.000 (0.064) loss 2.3516 (2.2909) lr 5.0000e-02 eta 0:04:57
epoch [26/50] batch [24/24] time 0.429 (0.508) data 0.000 (0.059) loss 2.2051 (2.2883) lr 4.6860e-02 eta 0:04:52
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 564
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 68.1%

epoch [27/50] batch [2/24] time 0.627 (1.334) data 0.000 (0.561) loss 2.4102 (2.4521) lr 4.6860e-02 eta 0:12:45
epoch [27/50] batch [4/24] time 0.425 (0.883) data 0.000 (0.280) loss 2.0996 (2.3364) lr 4.6860e-02 eta 0:08:25
epoch [27/50] batch [6/24] time 0.424 (0.731) data 0.000 (0.187) loss 2.2012 (2.3014) lr 4.6860e-02 eta 0:06:56
epoch [27/50] batch [8/24] time 0.425 (0.655) data 0.000 (0.140) loss 2.3477 (2.3201) lr 4.6860e-02 eta 0:06:11
epoch [27/50] batch [10/24] time 0.430 (0.610) data 0.000 (0.112) loss 2.3223 (2.2992) lr 4.6860e-02 eta 0:05:45
epoch [27/50] batch [12/24] time 0.431 (0.580) data 0.000 (0.094) loss 2.2363 (2.2853) lr 4.6860e-02 eta 0:05:27
epoch [27/50] batch [14/24] time 0.425 (0.558) data 0.000 (0.080) loss 2.2480 (2.2853) lr 4.6860e-02 eta 0:05:13
epoch [27/50] batch [16/24] time 0.425 (0.541) data 0.000 (0.070) loss 2.2266 (2.2793) lr 4.6860e-02 eta 0:05:03
epoch [27/50] batch [18/24] time 0.432 (0.529) data 0.000 (0.062) loss 2.2793 (2.2744) lr 4.6860e-02 eta 0:04:55
epoch [27/50] batch [20/24] time 0.433 (0.519) data 0.000 (0.056) loss 2.3594 (2.2850) lr 4.6860e-02 eta 0:04:48
epoch [27/50] batch [22/24] time 0.434 (0.511) data 0.000 (0.051) loss 2.2578 (2.2926) lr 4.6860e-02 eta 0:04:43
epoch [27/50] batch [24/24] time 0.434 (0.505) data 0.000 (0.047) loss 2.2109 (2.2939) lr 4.3733e-02 eta 0:04:38
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.52s/it] 60%|██████    | 3/5 [00:03<00:01,  1.05it/s] 80%|████████  | 4/5 [00:04<00:00,  1.47it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 561
* accuracy: 69.1%
* error: 30.9%
* macro_f1: 67.9%

epoch [28/50] batch [2/24] time 0.447 (1.493) data 0.000 (0.966) loss 2.2480 (2.2822) lr 4.3733e-02 eta 0:13:41
epoch [28/50] batch [4/24] time 0.428 (0.962) data 0.000 (0.483) loss 2.2695 (2.2749) lr 4.3733e-02 eta 0:08:46
epoch [28/50] batch [6/24] time 0.426 (0.784) data 0.000 (0.322) loss 2.2559 (2.2705) lr 4.3733e-02 eta 0:07:07
epoch [28/50] batch [8/24] time 0.431 (0.699) data 0.000 (0.242) loss 2.3105 (2.2708) lr 4.3733e-02 eta 0:06:20
epoch [28/50] batch [10/24] time 0.437 (0.647) data 0.000 (0.193) loss 2.1797 (2.2646) lr 4.3733e-02 eta 0:05:50
epoch [28/50] batch [12/24] time 0.436 (0.611) data 0.000 (0.161) loss 2.2227 (2.2697) lr 4.3733e-02 eta 0:05:29
epoch [28/50] batch [14/24] time 0.435 (0.586) data 0.000 (0.138) loss 2.2910 (2.2666) lr 4.3733e-02 eta 0:05:15
epoch [28/50] batch [16/24] time 0.433 (0.566) data 0.000 (0.121) loss 2.2129 (2.2605) lr 4.3733e-02 eta 0:05:03
epoch [28/50] batch [18/24] time 0.437 (0.551) data 0.000 (0.108) loss 2.3301 (2.2788) lr 4.3733e-02 eta 0:04:54
epoch [28/50] batch [20/24] time 0.426 (0.539) data 0.000 (0.097) loss 2.3379 (2.2834) lr 4.3733e-02 eta 0:04:46
epoch [28/50] batch [22/24] time 0.425 (0.529) data 0.000 (0.088) loss 2.2910 (2.2865) lr 4.3733e-02 eta 0:04:40
epoch [28/50] batch [24/24] time 0.426 (0.520) data 0.000 (0.081) loss 2.3047 (2.2905) lr 4.0631e-02 eta 0:04:34
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:13,  3.27s/it] 40%|████      | 2/5 [00:03<00:04,  1.50s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.48it/s]100%|██████████| 5/5 [00:04<00:00,  1.17it/s]=> result
* total: 812
* correct: 567
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 68.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [29/50] batch [2/24] time 0.616 (1.317) data 0.000 (0.626) loss 2.3887 (2.2930) lr 4.0631e-02 eta 0:11:32
epoch [29/50] batch [4/24] time 0.428 (0.877) data 0.001 (0.313) loss 2.2090 (2.2925) lr 4.0631e-02 eta 0:07:39
epoch [29/50] batch [6/24] time 0.427 (0.727) data 0.000 (0.209) loss 2.2461 (2.2923) lr 4.0631e-02 eta 0:06:19
epoch [29/50] batch [8/24] time 0.426 (0.652) data 0.000 (0.157) loss 2.2910 (2.2793) lr 4.0631e-02 eta 0:05:39
epoch [29/50] batch [10/24] time 0.426 (0.607) data 0.000 (0.126) loss 2.1289 (2.2670) lr 4.0631e-02 eta 0:05:14
epoch [29/50] batch [12/24] time 0.426 (0.577) data 0.000 (0.105) loss 2.3750 (2.2790) lr 4.0631e-02 eta 0:04:57
epoch [29/50] batch [14/24] time 0.427 (0.556) data 0.000 (0.090) loss 2.3262 (2.2843) lr 4.0631e-02 eta 0:04:45
epoch [29/50] batch [16/24] time 0.426 (0.540) data 0.000 (0.079) loss 2.4336 (2.2898) lr 4.0631e-02 eta 0:04:36
epoch [29/50] batch [18/24] time 0.426 (0.527) data 0.000 (0.070) loss 2.4219 (2.3021) lr 4.0631e-02 eta 0:04:28
epoch [29/50] batch [20/24] time 0.430 (0.518) data 0.000 (0.063) loss 2.1875 (2.3001) lr 4.0631e-02 eta 0:04:22
epoch [29/50] batch [22/24] time 0.426 (0.509) data 0.000 (0.057) loss 2.3379 (2.2950) lr 4.0631e-02 eta 0:04:17
epoch [29/50] batch [24/24] time 0.427 (0.502) data 0.000 (0.052) loss 2.2715 (2.2926) lr 3.7566e-02 eta 0:04:13
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.24s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 564
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 68.1%

epoch [30/50] batch [2/24] time 0.588 (1.317) data 0.001 (0.633) loss 2.3359 (2.4150) lr 3.7566e-02 eta 0:11:00
epoch [30/50] batch [4/24] time 0.438 (0.888) data 0.000 (0.317) loss 2.2168 (2.3267) lr 3.7566e-02 eta 0:07:24
epoch [30/50] batch [6/24] time 0.426 (0.734) data 0.000 (0.211) loss 2.3867 (2.3490) lr 3.7566e-02 eta 0:06:05
epoch [30/50] batch [8/24] time 0.429 (0.658) data 0.000 (0.158) loss 2.1895 (2.3030) lr 3.7566e-02 eta 0:05:26
epoch [30/50] batch [10/24] time 0.428 (0.612) data 0.000 (0.127) loss 2.3750 (2.3145) lr 3.7566e-02 eta 0:05:02
epoch [30/50] batch [12/24] time 0.424 (0.581) data 0.000 (0.106) loss 2.0820 (2.3022) lr 3.7566e-02 eta 0:04:45
epoch [30/50] batch [14/24] time 0.432 (0.559) data 0.000 (0.091) loss 2.3066 (2.2871) lr 3.7566e-02 eta 0:04:34
epoch [30/50] batch [16/24] time 0.425 (0.543) data 0.000 (0.079) loss 2.2598 (2.2860) lr 3.7566e-02 eta 0:04:24
epoch [30/50] batch [18/24] time 0.432 (0.530) data 0.000 (0.070) loss 2.3340 (2.2900) lr 3.7566e-02 eta 0:04:17
epoch [30/50] batch [20/24] time 0.427 (0.520) data 0.000 (0.063) loss 2.2520 (2.2855) lr 3.7566e-02 eta 0:04:11
epoch [30/50] batch [22/24] time 0.431 (0.512) data 0.000 (0.058) loss 2.2461 (2.2856) lr 3.7566e-02 eta 0:04:06
epoch [30/50] batch [24/24] time 0.425 (0.505) data 0.000 (0.053) loss 2.2383 (2.2843) lr 3.4549e-02 eta 0:04:02
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 568
* accuracy: 70.0%
* error: 30.0%
* macro_f1: 68.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model.pth.tar-30

epoch [31/50] batch [2/24] time 0.673 (1.236) data 0.000 (0.509) loss 2.3223 (2.2803) lr 3.4549e-02 eta 0:09:50
epoch [31/50] batch [4/24] time 0.430 (0.848) data 0.000 (0.254) loss 2.2637 (2.2397) lr 3.4549e-02 eta 0:06:43
epoch [31/50] batch [6/24] time 0.423 (0.707) data 0.000 (0.170) loss 2.2188 (2.2520) lr 3.4549e-02 eta 0:05:34
epoch [31/50] batch [8/24] time 0.432 (0.637) data 0.000 (0.127) loss 2.1465 (2.2483) lr 3.4549e-02 eta 0:05:00
epoch [31/50] batch [10/24] time 0.425 (0.595) data 0.000 (0.102) loss 2.0957 (2.2160) lr 3.4549e-02 eta 0:04:39
epoch [31/50] batch [12/24] time 0.425 (0.566) data 0.000 (0.085) loss 2.2891 (2.2308) lr 3.4549e-02 eta 0:04:25
epoch [31/50] batch [14/24] time 0.423 (0.546) data 0.000 (0.073) loss 2.1973 (2.2275) lr 3.4549e-02 eta 0:04:14
epoch [31/50] batch [16/24] time 0.426 (0.531) data 0.000 (0.064) loss 2.2090 (2.2349) lr 3.4549e-02 eta 0:04:06
epoch [31/50] batch [18/24] time 0.426 (0.520) data 0.000 (0.057) loss 2.4141 (2.2555) lr 3.4549e-02 eta 0:04:00
epoch [31/50] batch [20/24] time 0.429 (0.511) data 0.000 (0.051) loss 2.4414 (2.2751) lr 3.4549e-02 eta 0:03:54
epoch [31/50] batch [22/24] time 0.427 (0.503) data 0.000 (0.046) loss 2.3438 (2.2793) lr 3.4549e-02 eta 0:03:50
epoch [31/50] batch [24/24] time 0.428 (0.497) data 0.000 (0.043) loss 2.5195 (2.2895) lr 3.1594e-02 eta 0:03:46
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.10s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 571
* accuracy: 70.3%
* error: 29.7%
* macro_f1: 69.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [32/50] batch [2/24] time 0.555 (1.350) data 0.000 (0.691) loss 2.1426 (2.2012) lr 3.1594e-02 eta 0:10:12
epoch [32/50] batch [4/24] time 0.426 (0.891) data 0.000 (0.345) loss 2.2168 (2.2729) lr 3.1594e-02 eta 0:06:42
epoch [32/50] batch [6/24] time 0.427 (0.736) data 0.000 (0.230) loss 2.4551 (2.3285) lr 3.1594e-02 eta 0:05:31
epoch [32/50] batch [8/24] time 0.427 (0.659) data 0.000 (0.173) loss 2.3027 (2.3193) lr 3.1594e-02 eta 0:04:55
epoch [32/50] batch [10/24] time 0.426 (0.612) data 0.000 (0.138) loss 2.1191 (2.2865) lr 3.1594e-02 eta 0:04:33
epoch [32/50] batch [12/24] time 0.427 (0.582) data 0.000 (0.115) loss 2.2812 (2.2944) lr 3.1594e-02 eta 0:04:18
epoch [32/50] batch [14/24] time 0.437 (0.561) data 0.000 (0.099) loss 2.2520 (2.2885) lr 3.1594e-02 eta 0:04:07
epoch [32/50] batch [16/24] time 0.427 (0.544) data 0.000 (0.086) loss 2.1953 (2.2844) lr 3.1594e-02 eta 0:03:59
epoch [32/50] batch [18/24] time 0.514 (0.536) data 0.000 (0.077) loss 2.1250 (2.2820) lr 3.1594e-02 eta 0:03:54
epoch [32/50] batch [20/24] time 0.429 (0.525) data 0.000 (0.069) loss 2.3086 (2.2868) lr 3.1594e-02 eta 0:03:49
epoch [32/50] batch [22/24] time 0.432 (0.517) data 0.000 (0.063) loss 2.2656 (2.2798) lr 3.1594e-02 eta 0:03:44
epoch [32/50] batch [24/24] time 0.428 (0.510) data 0.000 (0.058) loss 2.3203 (2.2781) lr 2.8711e-02 eta 0:03:40
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 569
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 68.7%

epoch [33/50] batch [2/24] time 0.550 (1.336) data 0.000 (0.706) loss 2.1250 (2.1123) lr 2.8711e-02 eta 0:09:34
epoch [33/50] batch [4/24] time 0.437 (0.888) data 0.000 (0.353) loss 2.2754 (2.2300) lr 2.8711e-02 eta 0:06:19
epoch [33/50] batch [6/24] time 0.427 (0.734) data 0.000 (0.235) loss 2.2637 (2.2490) lr 2.8711e-02 eta 0:05:12
epoch [33/50] batch [8/24] time 0.426 (0.657) data 0.000 (0.177) loss 2.1016 (2.2371) lr 2.8711e-02 eta 0:04:38
epoch [33/50] batch [10/24] time 0.427 (0.611) data 0.000 (0.141) loss 2.2422 (2.2396) lr 2.8711e-02 eta 0:04:17
epoch [33/50] batch [12/24] time 0.431 (0.580) data 0.000 (0.118) loss 2.2520 (2.2406) lr 2.8711e-02 eta 0:04:03
epoch [33/50] batch [14/24] time 0.427 (0.558) data 0.000 (0.101) loss 2.2695 (2.2412) lr 2.8711e-02 eta 0:03:53
epoch [33/50] batch [16/24] time 0.425 (0.542) data 0.000 (0.088) loss 2.3496 (2.2375) lr 2.8711e-02 eta 0:03:45
epoch [33/50] batch [18/24] time 0.428 (0.529) data 0.000 (0.079) loss 2.3828 (2.2425) lr 2.8711e-02 eta 0:03:39
epoch [33/50] batch [20/24] time 0.430 (0.519) data 0.000 (0.071) loss 2.1934 (2.2358) lr 2.8711e-02 eta 0:03:33
epoch [33/50] batch [22/24] time 0.425 (0.511) data 0.000 (0.064) loss 2.3301 (2.2559) lr 2.8711e-02 eta 0:03:29
epoch [33/50] batch [24/24] time 0.427 (0.504) data 0.000 (0.059) loss 2.4414 (2.2624) lr 2.5912e-02 eta 0:03:25
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 567
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 68.6%

epoch [34/50] batch [2/24] time 0.552 (1.350) data 0.000 (0.711) loss 2.1582 (2.2207) lr 2.5912e-02 eta 0:09:08
epoch [34/50] batch [4/24] time 0.433 (0.893) data 0.000 (0.356) loss 2.1445 (2.2500) lr 2.5912e-02 eta 0:06:00
epoch [34/50] batch [6/24] time 0.427 (0.738) data 0.000 (0.237) loss 2.2715 (2.2301) lr 2.5912e-02 eta 0:04:56
epoch [34/50] batch [8/24] time 0.434 (0.662) data 0.000 (0.178) loss 2.2949 (2.2568) lr 2.5912e-02 eta 0:04:24
epoch [34/50] batch [10/24] time 0.439 (0.616) data 0.000 (0.142) loss 2.0996 (2.2502) lr 2.5912e-02 eta 0:04:05
epoch [34/50] batch [12/24] time 0.432 (0.585) data 0.000 (0.119) loss 2.1797 (2.2477) lr 2.5912e-02 eta 0:03:51
epoch [34/50] batch [14/24] time 0.434 (0.564) data 0.000 (0.102) loss 2.2227 (2.2522) lr 2.5912e-02 eta 0:03:42
epoch [34/50] batch [16/24] time 0.428 (0.547) data 0.000 (0.089) loss 2.2168 (2.2458) lr 2.5912e-02 eta 0:03:34
epoch [34/50] batch [18/24] time 0.436 (0.534) data 0.000 (0.079) loss 2.3164 (2.2640) lr 2.5912e-02 eta 0:03:28
epoch [34/50] batch [20/24] time 0.428 (0.523) data 0.000 (0.071) loss 2.0469 (2.2560) lr 2.5912e-02 eta 0:03:23
epoch [34/50] batch [22/24] time 0.434 (0.515) data 0.000 (0.065) loss 2.0859 (2.2447) lr 2.5912e-02 eta 0:03:18
epoch [34/50] batch [24/24] time 0.428 (0.508) data 0.000 (0.059) loss 2.3672 (2.2542) lr 2.3209e-02 eta 0:03:15
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 566
* accuracy: 69.7%
* error: 30.3%
* macro_f1: 68.7%

epoch [35/50] batch [2/24] time 0.622 (1.292) data 0.000 (0.592) loss 2.3438 (2.3525) lr 2.3209e-02 eta 0:08:13
epoch [35/50] batch [4/24] time 0.431 (0.866) data 0.000 (0.296) loss 2.2910 (2.3320) lr 2.3209e-02 eta 0:05:29
epoch [35/50] batch [6/24] time 0.427 (0.720) data 0.000 (0.198) loss 2.0762 (2.2467) lr 2.3209e-02 eta 0:04:32
epoch [35/50] batch [8/24] time 0.430 (0.647) data 0.000 (0.148) loss 2.3145 (2.2324) lr 2.3209e-02 eta 0:04:03
epoch [35/50] batch [10/24] time 0.426 (0.603) data 0.000 (0.119) loss 2.0488 (2.2174) lr 2.3209e-02 eta 0:03:45
epoch [35/50] batch [12/24] time 0.429 (0.574) data 0.000 (0.099) loss 2.2617 (2.2118) lr 2.3209e-02 eta 0:03:33
epoch [35/50] batch [14/24] time 0.433 (0.554) data 0.000 (0.085) loss 2.2832 (2.2194) lr 2.3209e-02 eta 0:03:24
epoch [35/50] batch [16/24] time 0.427 (0.538) data 0.000 (0.074) loss 2.2344 (2.2319) lr 2.3209e-02 eta 0:03:17
epoch [35/50] batch [18/24] time 0.428 (0.526) data 0.000 (0.066) loss 2.3750 (2.2396) lr 2.3209e-02 eta 0:03:12
epoch [35/50] batch [20/24] time 0.426 (0.516) data 0.000 (0.059) loss 2.0879 (2.2473) lr 2.3209e-02 eta 0:03:07
epoch [35/50] batch [22/24] time 0.434 (0.508) data 0.000 (0.054) loss 2.2617 (2.2496) lr 2.3209e-02 eta 0:03:04
epoch [35/50] batch [24/24] time 0.430 (0.502) data 0.000 (0.050) loss 2.4512 (2.2604) lr 2.0611e-02 eta 0:03:00
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.24s/it] 40%|████      | 2/5 [00:03<00:04,  1.50s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 570
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 69.2%

epoch [36/50] batch [2/24] time 0.645 (1.230) data 0.000 (0.495) loss 2.3770 (2.2900) lr 2.0611e-02 eta 0:07:20
epoch [36/50] batch [4/24] time 0.440 (0.853) data 0.000 (0.247) loss 2.2715 (2.2568) lr 2.0611e-02 eta 0:05:03
epoch [36/50] batch [6/24] time 0.433 (0.712) data 0.000 (0.165) loss 2.1055 (2.2409) lr 2.0611e-02 eta 0:04:12
epoch [36/50] batch [8/24] time 0.433 (0.642) data 0.000 (0.124) loss 2.1699 (2.2898) lr 2.0611e-02 eta 0:03:46
epoch [36/50] batch [10/24] time 0.431 (0.600) data 0.000 (0.099) loss 2.1484 (2.2701) lr 2.0611e-02 eta 0:03:29
epoch [36/50] batch [12/24] time 0.429 (0.572) data 0.000 (0.083) loss 2.3887 (2.2868) lr 2.0611e-02 eta 0:03:18
epoch [36/50] batch [14/24] time 0.436 (0.552) data 0.000 (0.071) loss 2.2461 (2.2829) lr 2.0611e-02 eta 0:03:11
epoch [36/50] batch [16/24] time 0.429 (0.537) data 0.000 (0.062) loss 2.3008 (2.2827) lr 2.0611e-02 eta 0:03:04
epoch [36/50] batch [18/24] time 0.429 (0.525) data 0.000 (0.055) loss 2.3848 (2.2803) lr 2.0611e-02 eta 0:02:59
epoch [36/50] batch [20/24] time 0.429 (0.515) data 0.000 (0.050) loss 2.4707 (2.2879) lr 2.0611e-02 eta 0:02:55
epoch [36/50] batch [22/24] time 0.428 (0.507) data 0.000 (0.045) loss 2.2520 (2.2939) lr 2.0611e-02 eta 0:02:51
epoch [36/50] batch [24/24] time 0.426 (0.501) data 0.000 (0.041) loss 2.3145 (2.3020) lr 1.8129e-02 eta 0:02:48
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 581
* accuracy: 71.6%
* error: 28.4%
* macro_f1: 70.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar

epoch [37/50] batch [2/24] time 0.649 (1.334) data 0.000 (0.605) loss 2.1562 (2.1895) lr 1.8129e-02 eta 0:07:25
epoch [37/50] batch [4/24] time 0.426 (0.883) data 0.000 (0.303) loss 2.3477 (2.2095) lr 1.8129e-02 eta 0:04:53
epoch [37/50] batch [6/24] time 0.425 (0.730) data 0.000 (0.202) loss 2.3906 (2.2458) lr 1.8129e-02 eta 0:04:00
epoch [37/50] batch [8/24] time 0.424 (0.654) data 0.000 (0.151) loss 2.2383 (2.2639) lr 1.8129e-02 eta 0:03:34
epoch [37/50] batch [10/24] time 0.424 (0.608) data 0.000 (0.121) loss 2.4961 (2.2828) lr 1.8129e-02 eta 0:03:18
epoch [37/50] batch [12/24] time 0.426 (0.577) data 0.000 (0.101) loss 2.0703 (2.2620) lr 1.8129e-02 eta 0:03:07
epoch [37/50] batch [14/24] time 0.428 (0.556) data 0.000 (0.087) loss 2.1523 (2.2515) lr 1.8129e-02 eta 0:02:58
epoch [37/50] batch [16/24] time 0.425 (0.539) data 0.000 (0.076) loss 2.1289 (2.2411) lr 1.8129e-02 eta 0:02:52
epoch [37/50] batch [18/24] time 0.427 (0.527) data 0.000 (0.067) loss 2.4004 (2.2461) lr 1.8129e-02 eta 0:02:47
epoch [37/50] batch [20/24] time 0.424 (0.517) data 0.000 (0.061) loss 2.4590 (2.2639) lr 1.8129e-02 eta 0:02:43
epoch [37/50] batch [22/24] time 0.424 (0.509) data 0.000 (0.055) loss 2.1582 (2.2641) lr 1.8129e-02 eta 0:02:39
epoch [37/50] batch [24/24] time 0.424 (0.502) data 0.000 (0.051) loss 2.4180 (2.2706) lr 1.5773e-02 eta 0:02:36
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.22s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 565
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 68.5%

epoch [38/50] batch [2/24] time 0.659 (1.203) data 0.000 (0.496) loss 2.1934 (2.2715) lr 1.5773e-02 eta 0:06:13
epoch [38/50] batch [4/24] time 0.435 (0.836) data 0.000 (0.248) loss 2.1855 (2.2583) lr 1.5773e-02 eta 0:04:17
epoch [38/50] batch [6/24] time 0.424 (0.698) data 0.000 (0.166) loss 2.3809 (2.2562) lr 1.5773e-02 eta 0:03:33
epoch [38/50] batch [8/24] time 0.426 (0.630) data 0.000 (0.124) loss 2.1191 (2.2542) lr 1.5773e-02 eta 0:03:11
epoch [38/50] batch [10/24] time 0.425 (0.589) data 0.000 (0.099) loss 2.4043 (2.2701) lr 1.5773e-02 eta 0:02:57
epoch [38/50] batch [12/24] time 0.425 (0.562) data 0.000 (0.083) loss 2.2461 (2.2767) lr 1.5773e-02 eta 0:02:48
epoch [38/50] batch [14/24] time 0.425 (0.542) data 0.000 (0.071) loss 2.2695 (2.2882) lr 1.5773e-02 eta 0:02:41
epoch [38/50] batch [16/24] time 0.425 (0.527) data 0.000 (0.062) loss 2.2305 (2.2997) lr 1.5773e-02 eta 0:02:36
epoch [38/50] batch [18/24] time 0.432 (0.521) data 0.000 (0.055) loss 2.3770 (2.2960) lr 1.5773e-02 eta 0:02:33
epoch [38/50] batch [20/24] time 0.430 (0.512) data 0.000 (0.050) loss 2.2012 (2.2834) lr 1.5773e-02 eta 0:02:29
epoch [38/50] batch [22/24] time 0.429 (0.504) data 0.000 (0.045) loss 2.3496 (2.2777) lr 1.5773e-02 eta 0:02:26
epoch [38/50] batch [24/24] time 0.424 (0.498) data 0.000 (0.042) loss 2.1992 (2.2737) lr 1.3552e-02 eta 0:02:23
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 577
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 70.1%

epoch [39/50] batch [2/24] time 0.558 (1.284) data 0.000 (0.621) loss 2.1738 (2.2314) lr 1.3552e-02 eta 0:06:07
epoch [39/50] batch [4/24] time 0.424 (0.857) data 0.000 (0.310) loss 2.1836 (2.2524) lr 1.3552e-02 eta 0:04:03
epoch [39/50] batch [6/24] time 0.424 (0.713) data 0.000 (0.207) loss 2.2344 (2.2441) lr 1.3552e-02 eta 0:03:21
epoch [39/50] batch [8/24] time 0.424 (0.641) data 0.000 (0.155) loss 2.1621 (2.2261) lr 1.3552e-02 eta 0:02:59
epoch [39/50] batch [10/24] time 0.427 (0.598) data 0.000 (0.124) loss 2.2324 (2.2381) lr 1.3552e-02 eta 0:02:46
epoch [39/50] batch [12/24] time 0.430 (0.569) data 0.000 (0.104) loss 2.2715 (2.2409) lr 1.3552e-02 eta 0:02:37
epoch [39/50] batch [14/24] time 0.425 (0.549) data 0.000 (0.089) loss 2.2168 (2.2460) lr 1.3552e-02 eta 0:02:30
epoch [39/50] batch [16/24] time 0.424 (0.533) data 0.000 (0.078) loss 2.2754 (2.2377) lr 1.3552e-02 eta 0:02:25
epoch [39/50] batch [18/24] time 0.423 (0.521) data 0.000 (0.069) loss 2.1680 (2.2383) lr 1.3552e-02 eta 0:02:20
epoch [39/50] batch [20/24] time 0.424 (0.511) data 0.000 (0.062) loss 2.2832 (2.2339) lr 1.3552e-02 eta 0:02:17
epoch [39/50] batch [22/24] time 0.425 (0.504) data 0.000 (0.057) loss 2.1914 (2.2365) lr 1.3552e-02 eta 0:02:13
epoch [39/50] batch [24/24] time 0.423 (0.497) data 0.000 (0.052) loss 2.1113 (2.2351) lr 1.1474e-02 eta 0:02:11
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 569
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 69.0%

epoch [40/50] batch [2/24] time 0.519 (1.403) data 0.000 (0.778) loss 2.0566 (2.1943) lr 1.1474e-02 eta 0:06:07
epoch [40/50] batch [4/24] time 0.425 (0.914) data 0.000 (0.389) loss 2.3145 (2.2285) lr 1.1474e-02 eta 0:03:57
epoch [40/50] batch [6/24] time 0.426 (0.751) data 0.000 (0.260) loss 2.1953 (2.1979) lr 1.1474e-02 eta 0:03:13
epoch [40/50] batch [8/24] time 0.425 (0.669) data 0.000 (0.195) loss 2.5508 (2.2495) lr 1.1474e-02 eta 0:02:51
epoch [40/50] batch [10/24] time 0.423 (0.620) data 0.000 (0.156) loss 2.2266 (2.2307) lr 1.1474e-02 eta 0:02:37
epoch [40/50] batch [12/24] time 0.426 (0.588) data 0.000 (0.130) loss 2.1387 (2.2201) lr 1.1474e-02 eta 0:02:28
epoch [40/50] batch [14/24] time 0.425 (0.565) data 0.000 (0.111) loss 2.2480 (2.2348) lr 1.1474e-02 eta 0:02:21
epoch [40/50] batch [16/24] time 0.423 (0.547) data 0.000 (0.097) loss 2.1387 (2.2408) lr 1.1474e-02 eta 0:02:15
epoch [40/50] batch [18/24] time 0.425 (0.533) data 0.000 (0.087) loss 2.2383 (2.2631) lr 1.1474e-02 eta 0:02:11
epoch [40/50] batch [20/24] time 0.422 (0.522) data 0.000 (0.078) loss 2.4707 (2.2702) lr 1.1474e-02 eta 0:02:07
epoch [40/50] batch [22/24] time 0.423 (0.513) data 0.000 (0.071) loss 2.2402 (2.2687) lr 1.1474e-02 eta 0:02:04
epoch [40/50] batch [24/24] time 0.423 (0.506) data 0.000 (0.065) loss 2.0859 (2.2527) lr 9.5492e-03 eta 0:02:01
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 573
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 69.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model.pth.tar-40

epoch [41/50] batch [2/24] time 0.532 (1.327) data 0.000 (0.686) loss 2.4258 (2.2852) lr 9.5492e-03 eta 0:05:15
epoch [41/50] batch [4/24] time 0.424 (0.878) data 0.000 (0.343) loss 2.2930 (2.2866) lr 9.5492e-03 eta 0:03:27
epoch [41/50] batch [6/24] time 0.426 (0.728) data 0.000 (0.229) loss 2.1113 (2.2760) lr 9.5492e-03 eta 0:02:50
epoch [41/50] batch [8/24] time 0.430 (0.653) data 0.000 (0.172) loss 2.3984 (2.2898) lr 9.5492e-03 eta 0:02:31
epoch [41/50] batch [10/24] time 0.422 (0.607) data 0.000 (0.137) loss 2.1562 (2.2658) lr 9.5492e-03 eta 0:02:19
epoch [41/50] batch [12/24] time 0.424 (0.577) data 0.000 (0.114) loss 2.3691 (2.2601) lr 9.5492e-03 eta 0:02:11
epoch [41/50] batch [14/24] time 0.425 (0.555) data 0.000 (0.098) loss 2.4043 (2.2577) lr 9.5492e-03 eta 0:02:05
epoch [41/50] batch [16/24] time 0.424 (0.539) data 0.000 (0.086) loss 2.4824 (2.2706) lr 9.5492e-03 eta 0:02:00
epoch [41/50] batch [18/24] time 0.431 (0.526) data 0.000 (0.076) loss 2.3047 (2.2673) lr 9.5492e-03 eta 0:01:56
epoch [41/50] batch [20/24] time 0.424 (0.516) data 0.000 (0.069) loss 2.3418 (2.2684) lr 9.5492e-03 eta 0:01:53
epoch [41/50] batch [22/24] time 0.425 (0.508) data 0.000 (0.063) loss 2.2949 (2.2601) lr 9.5492e-03 eta 0:01:50
epoch [41/50] batch [24/24] time 0.425 (0.502) data 0.000 (0.057) loss 2.3164 (2.2606) lr 7.7836e-03 eta 0:01:48
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.24s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 578
* accuracy: 71.2%
* error: 28.8%
* macro_f1: 70.3%

epoch [42/50] batch [2/24] time 0.512 (1.418) data 0.000 (0.778) loss 2.4355 (2.3652) lr 7.7836e-03 eta 0:05:03
epoch [42/50] batch [4/24] time 0.425 (0.923) data 0.000 (0.389) loss 2.2910 (2.2861) lr 7.7836e-03 eta 0:03:15
epoch [42/50] batch [6/24] time 0.429 (0.758) data 0.000 (0.260) loss 2.3379 (2.2793) lr 7.7836e-03 eta 0:02:39
epoch [42/50] batch [8/24] time 0.425 (0.675) data 0.000 (0.195) loss 2.2871 (2.2734) lr 7.7836e-03 eta 0:02:20
epoch [42/50] batch [10/24] time 0.425 (0.625) data 0.000 (0.156) loss 2.3379 (2.2604) lr 7.7836e-03 eta 0:02:08
epoch [42/50] batch [12/24] time 0.423 (0.591) data 0.000 (0.130) loss 2.1973 (2.2681) lr 7.7836e-03 eta 0:02:00
epoch [42/50] batch [14/24] time 0.430 (0.568) data 0.000 (0.111) loss 2.2461 (2.2730) lr 7.7836e-03 eta 0:01:54
epoch [42/50] batch [16/24] time 0.425 (0.550) data 0.000 (0.097) loss 2.5078 (2.2832) lr 7.7836e-03 eta 0:01:50
epoch [42/50] batch [18/24] time 0.429 (0.537) data 0.000 (0.087) loss 2.2324 (2.2832) lr 7.7836e-03 eta 0:01:46
epoch [42/50] batch [20/24] time 0.424 (0.526) data 0.000 (0.078) loss 2.1758 (2.2731) lr 7.7836e-03 eta 0:01:43
epoch [42/50] batch [22/24] time 0.429 (0.517) data 0.000 (0.071) loss 2.2031 (2.2678) lr 7.7836e-03 eta 0:01:40
epoch [42/50] batch [24/24] time 0.433 (0.510) data 0.000 (0.065) loss 2.2461 (2.2681) lr 6.1847e-03 eta 0:01:37
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.13s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.11it/s] 80%|████████  | 4/5 [00:03<00:00,  1.54it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 573
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 69.6%

epoch [43/50] batch [2/24] time 0.662 (1.253) data 0.000 (0.528) loss 2.1895 (2.1973) lr 6.1847e-03 eta 0:03:57
epoch [43/50] batch [4/24] time 0.427 (0.854) data 0.000 (0.264) loss 2.3496 (2.2031) lr 6.1847e-03 eta 0:02:40
epoch [43/50] batch [6/24] time 0.424 (0.711) data 0.000 (0.176) loss 2.2598 (2.2373) lr 6.1847e-03 eta 0:02:12
epoch [43/50] batch [8/24] time 0.425 (0.640) data 0.000 (0.132) loss 2.3750 (2.2349) lr 6.1847e-03 eta 0:01:57
epoch [43/50] batch [10/24] time 0.424 (0.597) data 0.000 (0.106) loss 2.3887 (2.2516) lr 6.1847e-03 eta 0:01:48
epoch [43/50] batch [12/24] time 0.425 (0.568) data 0.000 (0.088) loss 2.1172 (2.2376) lr 6.1847e-03 eta 0:01:42
epoch [43/50] batch [14/24] time 0.424 (0.548) data 0.000 (0.076) loss 2.1797 (2.2390) lr 6.1847e-03 eta 0:01:37
epoch [43/50] batch [16/24] time 0.427 (0.533) data 0.000 (0.066) loss 2.3945 (2.2526) lr 6.1847e-03 eta 0:01:33
epoch [43/50] batch [18/24] time 0.425 (0.521) data 0.000 (0.059) loss 2.3613 (2.2553) lr 6.1847e-03 eta 0:01:30
epoch [43/50] batch [20/24] time 0.428 (0.511) data 0.000 (0.053) loss 2.2793 (2.2651) lr 6.1847e-03 eta 0:01:27
epoch [43/50] batch [22/24] time 0.425 (0.503) data 0.000 (0.048) loss 2.1914 (2.2597) lr 6.1847e-03 eta 0:01:25
epoch [43/50] batch [24/24] time 0.430 (0.497) data 0.000 (0.044) loss 2.3555 (2.2689) lr 4.7586e-03 eta 0:01:23
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 572
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 69.6%

epoch [44/50] batch [2/24] time 0.492 (1.415) data 0.000 (0.845) loss 2.4277 (2.3242) lr 4.7586e-03 eta 0:03:54
epoch [44/50] batch [4/24] time 0.432 (0.925) data 0.000 (0.423) loss 2.3945 (2.3154) lr 4.7586e-03 eta 0:02:31
epoch [44/50] batch [6/24] time 0.432 (0.760) data 0.000 (0.282) loss 2.0508 (2.2588) lr 4.7586e-03 eta 0:02:03
epoch [44/50] batch [8/24] time 0.428 (0.677) data 0.000 (0.211) loss 2.0234 (2.2268) lr 4.7586e-03 eta 0:01:48
epoch [44/50] batch [10/24] time 0.427 (0.629) data 0.000 (0.169) loss 2.2852 (2.2342) lr 4.7586e-03 eta 0:01:39
epoch [44/50] batch [12/24] time 0.431 (0.596) data 0.000 (0.141) loss 2.2285 (2.2393) lr 4.7586e-03 eta 0:01:32
epoch [44/50] batch [14/24] time 0.437 (0.573) data 0.000 (0.121) loss 2.3398 (2.2381) lr 4.7586e-03 eta 0:01:28
epoch [44/50] batch [16/24] time 0.437 (0.555) data 0.000 (0.106) loss 2.3359 (2.2406) lr 4.7586e-03 eta 0:01:24
epoch [44/50] batch [18/24] time 0.427 (0.541) data 0.000 (0.094) loss 2.2578 (2.2438) lr 4.7586e-03 eta 0:01:21
epoch [44/50] batch [20/24] time 0.430 (0.530) data 0.000 (0.085) loss 2.3535 (2.2519) lr 4.7586e-03 eta 0:01:18
epoch [44/50] batch [22/24] time 0.431 (0.521) data 0.000 (0.077) loss 2.1641 (2.2572) lr 4.7586e-03 eta 0:01:15
epoch [44/50] batch [24/24] time 0.519 (0.517) data 0.000 (0.071) loss 2.2090 (2.2526) lr 3.5112e-03 eta 0:01:14
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 574
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 69.8%

epoch [45/50] batch [2/24] time 0.457 (1.472) data 0.000 (0.936) loss 2.3203 (2.3613) lr 3.5112e-03 eta 0:03:29
epoch [45/50] batch [4/24] time 0.425 (0.948) data 0.000 (0.468) loss 2.1016 (2.2837) lr 3.5112e-03 eta 0:02:12
epoch [45/50] batch [6/24] time 0.425 (0.774) data 0.000 (0.312) loss 2.1680 (2.2467) lr 3.5112e-03 eta 0:01:46
epoch [45/50] batch [8/24] time 0.424 (0.687) data 0.000 (0.234) loss 2.3262 (2.2881) lr 3.5112e-03 eta 0:01:33
epoch [45/50] batch [10/24] time 0.431 (0.635) data 0.000 (0.187) loss 2.2070 (2.2617) lr 3.5112e-03 eta 0:01:25
epoch [45/50] batch [12/24] time 0.427 (0.601) data 0.000 (0.156) loss 2.0840 (2.2598) lr 3.5112e-03 eta 0:01:19
epoch [45/50] batch [14/24] time 0.424 (0.575) data 0.000 (0.134) loss 2.3164 (2.2649) lr 3.5112e-03 eta 0:01:14
epoch [45/50] batch [16/24] time 0.425 (0.557) data 0.000 (0.117) loss 2.0430 (2.2568) lr 3.5112e-03 eta 0:01:11
epoch [45/50] batch [18/24] time 0.424 (0.542) data 0.000 (0.104) loss 2.3145 (2.2567) lr 3.5112e-03 eta 0:01:08
epoch [45/50] batch [20/24] time 0.424 (0.530) data 0.000 (0.094) loss 2.2676 (2.2594) lr 3.5112e-03 eta 0:01:05
epoch [45/50] batch [22/24] time 0.428 (0.521) data 0.000 (0.085) loss 2.0352 (2.2438) lr 3.5112e-03 eta 0:01:03
epoch [45/50] batch [24/24] time 0.430 (0.513) data 0.000 (0.078) loss 2.2246 (2.2540) lr 2.4472e-03 eta 0:01:01
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.14s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 572
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 69.4%

epoch [46/50] batch [2/24] time 0.699 (1.293) data 0.000 (0.578) loss 2.2363 (2.1572) lr 2.4472e-03 eta 0:02:32
epoch [46/50] batch [4/24] time 0.425 (0.863) data 0.000 (0.289) loss 2.2617 (2.1831) lr 2.4472e-03 eta 0:01:40
epoch [46/50] batch [6/24] time 0.425 (0.717) data 0.000 (0.193) loss 2.2832 (2.1742) lr 2.4472e-03 eta 0:01:21
epoch [46/50] batch [8/24] time 0.428 (0.645) data 0.000 (0.145) loss 2.4473 (2.2202) lr 2.4472e-03 eta 0:01:12
epoch [46/50] batch [10/24] time 0.430 (0.603) data 0.000 (0.116) loss 2.4258 (2.2400) lr 2.4472e-03 eta 0:01:06
epoch [46/50] batch [12/24] time 0.426 (0.573) data 0.000 (0.097) loss 2.3770 (2.2616) lr 2.4472e-03 eta 0:01:01
epoch [46/50] batch [14/24] time 0.429 (0.553) data 0.000 (0.083) loss 2.1055 (2.2540) lr 2.4472e-03 eta 0:00:58
epoch [46/50] batch [16/24] time 0.425 (0.537) data 0.000 (0.072) loss 2.1836 (2.2452) lr 2.4472e-03 eta 0:00:55
epoch [46/50] batch [18/24] time 0.431 (0.525) data 0.000 (0.064) loss 2.1133 (2.2401) lr 2.4472e-03 eta 0:00:53
epoch [46/50] batch [20/24] time 0.428 (0.515) data 0.000 (0.058) loss 2.4961 (2.2554) lr 2.4472e-03 eta 0:00:51
epoch [46/50] batch [22/24] time 0.428 (0.507) data 0.000 (0.053) loss 2.3105 (2.2634) lr 2.4472e-03 eta 0:00:49
epoch [46/50] batch [24/24] time 0.430 (0.501) data 0.000 (0.048) loss 2.2539 (2.2646) lr 1.5708e-03 eta 0:00:48
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 573
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 69.6%

epoch [47/50] batch [2/24] time 0.608 (1.296) data 0.000 (0.638) loss 2.1543 (2.2451) lr 1.5708e-03 eta 0:02:01
epoch [47/50] batch [4/24] time 0.424 (0.861) data 0.000 (0.319) loss 2.2070 (2.2642) lr 1.5708e-03 eta 0:01:19
epoch [47/50] batch [6/24] time 0.425 (0.716) data 0.000 (0.213) loss 2.2441 (2.2764) lr 1.5708e-03 eta 0:01:04
epoch [47/50] batch [8/24] time 0.427 (0.644) data 0.000 (0.160) loss 2.1465 (2.2427) lr 1.5708e-03 eta 0:00:56
epoch [47/50] batch [10/24] time 0.423 (0.600) data 0.000 (0.128) loss 2.2598 (2.2416) lr 1.5708e-03 eta 0:00:51
epoch [47/50] batch [12/24] time 0.425 (0.571) data 0.000 (0.107) loss 2.2441 (2.2459) lr 1.5708e-03 eta 0:00:47
epoch [47/50] batch [14/24] time 0.425 (0.550) data 0.000 (0.091) loss 2.2559 (2.2489) lr 1.5708e-03 eta 0:00:45
epoch [47/50] batch [16/24] time 0.424 (0.534) data 0.000 (0.080) loss 2.4277 (2.2582) lr 1.5708e-03 eta 0:00:42
epoch [47/50] batch [18/24] time 0.424 (0.522) data 0.000 (0.071) loss 2.0625 (2.2529) lr 1.5708e-03 eta 0:00:40
epoch [47/50] batch [20/24] time 0.429 (0.513) data 0.000 (0.064) loss 2.2598 (2.2331) lr 1.5708e-03 eta 0:00:38
epoch [47/50] batch [22/24] time 0.425 (0.505) data 0.000 (0.058) loss 2.2188 (2.2396) lr 1.5708e-03 eta 0:00:37
epoch [47/50] batch [24/24] time 0.425 (0.498) data 0.000 (0.053) loss 2.1641 (2.2375) lr 8.8564e-04 eta 0:00:35
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 572
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 69.4%

epoch [48/50] batch [2/24] time 0.551 (1.339) data 0.000 (0.672) loss 2.1855 (2.1914) lr 8.8564e-04 eta 0:01:33
epoch [48/50] batch [4/24] time 0.423 (0.883) data 0.000 (0.336) loss 2.3262 (2.2363) lr 8.8564e-04 eta 0:01:00
epoch [48/50] batch [6/24] time 0.425 (0.730) data 0.000 (0.224) loss 2.2754 (2.2340) lr 8.8564e-04 eta 0:00:48
epoch [48/50] batch [8/24] time 0.424 (0.654) data 0.000 (0.168) loss 2.1641 (2.2253) lr 8.8564e-04 eta 0:00:41
epoch [48/50] batch [10/24] time 0.424 (0.608) data 0.000 (0.134) loss 2.1465 (2.2252) lr 8.8564e-04 eta 0:00:37
epoch [48/50] batch [12/24] time 0.423 (0.577) data 0.000 (0.112) loss 2.1016 (2.2005) lr 8.8564e-04 eta 0:00:34
epoch [48/50] batch [14/24] time 0.424 (0.556) data 0.000 (0.096) loss 2.3203 (2.2137) lr 8.8564e-04 eta 0:00:32
epoch [48/50] batch [16/24] time 0.425 (0.539) data 0.000 (0.084) loss 2.3477 (2.2140) lr 8.8564e-04 eta 0:00:30
epoch [48/50] batch [18/24] time 0.423 (0.527) data 0.000 (0.075) loss 2.2520 (2.2081) lr 8.8564e-04 eta 0:00:28
epoch [48/50] batch [20/24] time 0.424 (0.516) data 0.000 (0.067) loss 2.4316 (2.2214) lr 8.8564e-04 eta 0:00:26
epoch [48/50] batch [22/24] time 0.423 (0.508) data 0.000 (0.061) loss 2.2871 (2.2274) lr 8.8564e-04 eta 0:00:25
epoch [48/50] batch [24/24] time 0.429 (0.501) data 0.000 (0.056) loss 2.2734 (2.2311) lr 3.9426e-04 eta 0:00:24
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.14s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 575
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 69.8%

epoch [49/50] batch [2/24] time 0.648 (1.286) data 0.000 (0.556) loss 2.1465 (2.2393) lr 3.9426e-04 eta 0:00:59
epoch [49/50] batch [4/24] time 0.432 (0.877) data 0.000 (0.278) loss 2.2246 (2.2246) lr 3.9426e-04 eta 0:00:38
epoch [49/50] batch [6/24] time 0.424 (0.726) data 0.000 (0.185) loss 2.1523 (2.2109) lr 3.9426e-04 eta 0:00:30
epoch [49/50] batch [8/24] time 0.425 (0.651) data 0.000 (0.139) loss 2.4590 (2.2344) lr 3.9426e-04 eta 0:00:26
epoch [49/50] batch [10/24] time 0.424 (0.606) data 0.000 (0.111) loss 2.0879 (2.2211) lr 3.9426e-04 eta 0:00:23
epoch [49/50] batch [12/24] time 0.424 (0.575) data 0.000 (0.093) loss 2.1543 (2.2358) lr 3.9426e-04 eta 0:00:20
epoch [49/50] batch [14/24] time 0.426 (0.554) data 0.000 (0.080) loss 2.3242 (2.2499) lr 3.9426e-04 eta 0:00:18
epoch [49/50] batch [16/24] time 0.425 (0.538) data 0.000 (0.070) loss 2.3340 (2.2560) lr 3.9426e-04 eta 0:00:17
epoch [49/50] batch [18/24] time 0.424 (0.525) data 0.000 (0.062) loss 2.1309 (2.2527) lr 3.9426e-04 eta 0:00:15
epoch [49/50] batch [20/24] time 0.514 (0.520) data 0.000 (0.056) loss 2.3809 (2.2517) lr 3.9426e-04 eta 0:00:14
epoch [49/50] batch [22/24] time 0.431 (0.512) data 0.000 (0.051) loss 2.1406 (2.2417) lr 3.9426e-04 eta 0:00:13
epoch [49/50] batch [24/24] time 0.426 (0.504) data 0.000 (0.046) loss 2.3184 (2.2497) lr 9.8664e-05 eta 0:00:12
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 574
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 69.8%

epoch [50/50] batch [2/24] time 0.594 (1.314) data 0.001 (0.657) loss 2.3398 (2.3008) lr 9.8664e-05 eta 0:00:28
epoch [50/50] batch [4/24] time 0.426 (0.884) data 0.000 (0.328) loss 2.2480 (2.2983) lr 9.8664e-05 eta 0:00:17
epoch [50/50] batch [6/24] time 0.423 (0.731) data 0.000 (0.219) loss 2.1953 (2.3050) lr 9.8664e-05 eta 0:00:13
epoch [50/50] batch [8/24] time 0.425 (0.654) data 0.000 (0.164) loss 2.3770 (2.2844) lr 9.8664e-05 eta 0:00:10
epoch [50/50] batch [10/24] time 0.424 (0.608) data 0.000 (0.131) loss 2.1836 (2.2773) lr 9.8664e-05 eta 0:00:08
epoch [50/50] batch [12/24] time 0.424 (0.578) data 0.000 (0.110) loss 2.1816 (2.2689) lr 9.8664e-05 eta 0:00:06
epoch [50/50] batch [14/24] time 0.433 (0.556) data 0.000 (0.094) loss 2.2305 (2.2595) lr 9.8664e-05 eta 0:00:05
epoch [50/50] batch [16/24] time 0.424 (0.540) data 0.000 (0.082) loss 2.3340 (2.2643) lr 9.8664e-05 eta 0:00:04
epoch [50/50] batch [18/24] time 0.424 (0.527) data 0.000 (0.073) loss 2.2969 (2.2684) lr 9.8664e-05 eta 0:00:03
epoch [50/50] batch [20/24] time 0.424 (0.517) data 0.000 (0.066) loss 2.1973 (2.2576) lr 9.8664e-05 eta 0:00:02
epoch [50/50] batch [22/24] time 0.424 (0.508) data 0.000 (0.060) loss 2.1758 (2.2586) lr 9.8664e-05 eta 0:00:01
epoch [50/50] batch [24/24] time 0.424 (0.501) data 0.000 (0.055) loss 2.1660 (2.2583) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]
=> result
* total: 812
* correct: 575
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 69.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model.pth.tar-50
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar" (epoch = 36)
Evaluate on the *test* set
  0%|          | 0/21 [00:00<?, ?it/s]  5%|▍         | 1/21 [00:04<01:23,  4.16s/it] 10%|▉         | 2/21 [00:04<00:38,  2.03s/it] 14%|█▍        | 3/21 [00:05<00:23,  1.29s/it] 19%|█▉        | 4/21 [00:05<00:15,  1.07it/s] 24%|██▍       | 5/21 [00:05<00:11,  1.33it/s] 29%|██▊       | 6/21 [00:06<00:09,  1.57it/s] 33%|███▎      | 7/21 [00:06<00:07,  1.77it/s] 38%|███▊      | 8/21 [00:07<00:06,  1.95it/s] 43%|████▎     | 9/21 [00:07<00:05,  2.12it/s] 48%|████▊     | 10/21 [00:07<00:04,  2.26it/s] 52%|█████▏    | 11/21 [00:08<00:03,  2.57it/s] 57%|█████▋    | 12/21 [00:08<00:03,  2.85it/s] 62%|██████▏   | 13/21 [00:08<00:02,  3.09it/s] 67%|██████▋   | 14/21 [00:08<00:02,  3.28it/s] 71%|███████▏  | 15/21 [00:09<00:01,  3.43it/s] 76%|███████▌  | 16/21 [00:09<00:01,  3.54it/s] 81%|████████  | 17/21 [00:09<00:01,  3.62it/s] 86%|████████▌ | 18/21 [00:10<00:00,  3.67it/s] 90%|█████████ | 19/21 [00:10<00:00,  3.71it/s] 95%|█████████▌| 20/21 [00:10<00:00,  3.74it/s]100%|██████████| 21/21 [00:10<00:00,  4.41it/s]100%|██████████| 21/21 [00:10<00:00,  1.95it/s]
=> result
* total: 4,002
* correct: 2,822
* accuracy: 70.5%
* error: 29.5%
* macro_f1: 69.9%
Elapsed: 0:13:52
+ sh scripts/rpo_prime/base2new_test.sh stanford_cars 2 0 main_tmp1 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_2.pkl
SUBSAMPLE NEW CLASSES!
1568 823 4039
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      823
# test     4,039
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed2/prompt_learner/model-best.pth.tar" (epoch = 36)
Evaluate on the *test* set
  0%|          | 0/21 [00:00<?, ?it/s]  5%|▍         | 1/21 [00:06<02:13,  6.68s/it] 10%|▉         | 2/21 [00:07<00:57,  3.02s/it] 14%|█▍        | 3/21 [00:07<00:32,  1.82s/it] 19%|█▉        | 4/21 [00:07<00:21,  1.28s/it] 24%|██▍       | 5/21 [00:08<00:15,  1.06it/s] 29%|██▊       | 6/21 [00:08<00:11,  1.36it/s] 33%|███▎      | 7/21 [00:08<00:08,  1.73it/s] 38%|███▊      | 8/21 [00:09<00:06,  2.10it/s] 43%|████▎     | 9/21 [00:09<00:04,  2.44it/s] 48%|████▊     | 10/21 [00:09<00:03,  2.76it/s] 52%|█████▏    | 11/21 [00:09<00:03,  3.02it/s] 57%|█████▋    | 12/21 [00:10<00:02,  3.23it/s] 62%|██████▏   | 13/21 [00:10<00:02,  3.40it/s] 67%|██████▋   | 14/21 [00:10<00:01,  3.52it/s] 71%|███████▏  | 15/21 [00:10<00:01,  3.62it/s] 76%|███████▌  | 16/21 [00:11<00:01,  3.65it/s] 81%|████████  | 17/21 [00:11<00:01,  3.70it/s] 86%|████████▌ | 18/21 [00:11<00:00,  3.75it/s] 90%|█████████ | 19/21 [00:12<00:00,  3.77it/s] 95%|█████████▌| 20/21 [00:12<00:00,  3.79it/s]100%|██████████| 21/21 [00:12<00:00,  4.23it/s]100%|██████████| 21/21 [00:12<00:00,  1.67it/s]
=> result
* total: 4,039
* correct: 2,993
* accuracy: 74.1%
* error: 25.9%
* macro_f1: 73.1%
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train.sh stanford_cars 3 0 main_tmp1 16
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE BASE CLASSES!
1568 812 4002
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      812
# test     4,002
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/tensorboard)
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
epoch [1/50] batch [2/24] time 0.424 (2.220) data 0.000 (0.842) loss 2.6719 (2.9941) lr 1.0000e-01 eta 0:44:19
epoch [1/50] batch [4/24] time 0.424 (1.322) data 0.000 (0.421) loss 2.5449 (2.7349) lr 1.0000e-01 eta 0:26:21
epoch [1/50] batch [6/24] time 0.426 (1.024) data 0.000 (0.281) loss 3.0840 (2.7917) lr 1.0000e-01 eta 0:20:22
epoch [1/50] batch [8/24] time 0.425 (0.875) data 0.000 (0.211) loss 2.5684 (2.7390) lr 1.0000e-01 eta 0:17:22
epoch [1/50] batch [10/24] time 0.425 (0.785) data 0.000 (0.169) loss 2.6426 (2.7193) lr 1.0000e-01 eta 0:15:34
epoch [1/50] batch [12/24] time 0.431 (0.725) data 0.000 (0.140) loss 2.4258 (2.6769) lr 1.0000e-01 eta 0:14:21
epoch [1/50] batch [14/24] time 0.428 (0.683) data 0.000 (0.120) loss 2.7793 (2.6705) lr 1.0000e-01 eta 0:13:29
epoch [1/50] batch [16/24] time 0.430 (0.651) data 0.000 (0.105) loss 2.5215 (2.6537) lr 1.0000e-01 eta 0:12:50
epoch [1/50] batch [18/24] time 0.425 (0.626) data 0.000 (0.094) loss 2.3438 (2.6356) lr 1.0000e-01 eta 0:12:20
epoch [1/50] batch [20/24] time 0.428 (0.607) data 0.000 (0.084) loss 2.5703 (2.6294) lr 1.0000e-01 eta 0:11:56
epoch [1/50] batch [22/24] time 0.428 (0.591) data 0.000 (0.077) loss 2.4941 (2.6175) lr 1.0000e-01 eta 0:11:36
epoch [1/50] batch [24/24] time 0.433 (0.578) data 0.000 (0.070) loss 2.3965 (2.6047) lr 9.9901e-02 eta 0:11:19
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.24s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 518
* accuracy: 63.8%
* error: 36.2%
* macro_f1: 61.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [2/50] batch [2/24] time 0.538 (1.328) data 0.000 (0.667) loss 2.3965 (2.4561) lr 9.9901e-02 eta 0:25:58
epoch [2/50] batch [4/24] time 0.428 (0.879) data 0.000 (0.334) loss 2.5254 (2.4512) lr 9.9901e-02 eta 0:17:09
epoch [2/50] batch [6/24] time 0.434 (0.729) data 0.000 (0.222) loss 2.3633 (2.4385) lr 9.9901e-02 eta 0:14:12
epoch [2/50] batch [8/24] time 0.424 (0.653) data 0.000 (0.167) loss 2.4434 (2.4470) lr 9.9901e-02 eta 0:12:42
epoch [2/50] batch [10/24] time 0.425 (0.607) data 0.000 (0.134) loss 2.4023 (2.4320) lr 9.9901e-02 eta 0:11:48
epoch [2/50] batch [12/24] time 0.431 (0.578) data 0.000 (0.111) loss 2.4883 (2.4481) lr 9.9901e-02 eta 0:11:12
epoch [2/50] batch [14/24] time 0.429 (0.557) data 0.000 (0.095) loss 2.4688 (2.4593) lr 9.9901e-02 eta 0:10:46
epoch [2/50] batch [16/24] time 0.428 (0.541) data 0.000 (0.084) loss 2.4668 (2.4739) lr 9.9901e-02 eta 0:10:27
epoch [2/50] batch [18/24] time 0.431 (0.529) data 0.000 (0.074) loss 2.2188 (2.4616) lr 9.9901e-02 eta 0:10:12
epoch [2/50] batch [20/24] time 0.430 (0.519) data 0.000 (0.067) loss 2.5762 (2.4639) lr 9.9901e-02 eta 0:10:00
epoch [2/50] batch [22/24] time 0.426 (0.511) data 0.000 (0.061) loss 2.5312 (2.4599) lr 9.9901e-02 eta 0:09:49
epoch [2/50] batch [24/24] time 0.428 (0.504) data 0.000 (0.056) loss 2.1816 (2.4492) lr 9.9606e-02 eta 0:09:40
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.14it/s]=> result
* total: 812
* correct: 524
* accuracy: 64.5%
* error: 35.5%
* macro_f1: 62.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [3/50] batch [2/24] time 0.568 (1.313) data 0.000 (0.654) loss 2.4395 (2.5137) lr 9.9606e-02 eta 0:25:10
epoch [3/50] batch [4/24] time 0.426 (0.871) data 0.000 (0.327) loss 2.3438 (2.4253) lr 9.9606e-02 eta 0:16:39
epoch [3/50] batch [6/24] time 0.523 (0.738) data 0.000 (0.218) loss 2.3105 (2.4300) lr 9.9606e-02 eta 0:14:05
epoch [3/50] batch [8/24] time 0.425 (0.661) data 0.000 (0.164) loss 2.4473 (2.4434) lr 9.9606e-02 eta 0:12:36
epoch [3/50] batch [10/24] time 0.430 (0.615) data 0.000 (0.131) loss 2.3809 (2.4182) lr 9.9606e-02 eta 0:11:42
epoch [3/50] batch [12/24] time 0.424 (0.583) data 0.000 (0.109) loss 2.1953 (2.3984) lr 9.9606e-02 eta 0:11:04
epoch [3/50] batch [14/24] time 0.424 (0.561) data 0.000 (0.094) loss 2.4902 (2.4030) lr 9.9606e-02 eta 0:10:38
epoch [3/50] batch [16/24] time 0.425 (0.544) data 0.000 (0.082) loss 2.5605 (2.4042) lr 9.9606e-02 eta 0:10:17
epoch [3/50] batch [18/24] time 0.425 (0.531) data 0.000 (0.073) loss 2.4160 (2.4044) lr 9.9606e-02 eta 0:10:01
epoch [3/50] batch [20/24] time 0.439 (0.521) data 0.000 (0.066) loss 2.3594 (2.4058) lr 9.9606e-02 eta 0:09:49
epoch [3/50] batch [22/24] time 0.433 (0.513) data 0.000 (0.060) loss 2.3633 (2.4007) lr 9.9606e-02 eta 0:09:39
epoch [3/50] batch [24/24] time 0.425 (0.506) data 0.000 (0.055) loss 2.2871 (2.3940) lr 9.9114e-02 eta 0:09:30
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 532
* accuracy: 65.5%
* error: 34.5%
* macro_f1: 63.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [4/50] batch [2/24] time 0.549 (1.332) data 0.000 (0.703) loss 2.3496 (2.2930) lr 9.9114e-02 eta 0:24:59
epoch [4/50] batch [4/24] time 0.425 (0.880) data 0.000 (0.351) loss 2.6133 (2.3774) lr 9.9114e-02 eta 0:16:29
epoch [4/50] batch [6/24] time 0.438 (0.736) data 0.000 (0.234) loss 2.2422 (2.4069) lr 9.9114e-02 eta 0:13:45
epoch [4/50] batch [8/24] time 0.430 (0.659) data 0.000 (0.176) loss 2.2910 (2.3972) lr 9.9114e-02 eta 0:12:17
epoch [4/50] batch [10/24] time 0.434 (0.613) data 0.000 (0.141) loss 2.4902 (2.3920) lr 9.9114e-02 eta 0:11:25
epoch [4/50] batch [12/24] time 0.428 (0.582) data 0.000 (0.117) loss 2.3555 (2.3913) lr 9.9114e-02 eta 0:10:49
epoch [4/50] batch [14/24] time 0.437 (0.561) data 0.000 (0.101) loss 2.3027 (2.3987) lr 9.9114e-02 eta 0:10:24
epoch [4/50] batch [16/24] time 0.431 (0.544) data 0.000 (0.088) loss 2.3164 (2.3883) lr 9.9114e-02 eta 0:10:05
epoch [4/50] batch [18/24] time 0.433 (0.532) data 0.000 (0.078) loss 2.3516 (2.3868) lr 9.9114e-02 eta 0:09:50
epoch [4/50] batch [20/24] time 0.437 (0.522) data 0.000 (0.070) loss 2.4336 (2.3912) lr 9.9114e-02 eta 0:09:38
epoch [4/50] batch [22/24] time 0.428 (0.514) data 0.000 (0.064) loss 2.3965 (2.3931) lr 9.9114e-02 eta 0:09:28
epoch [4/50] batch [24/24] time 0.428 (0.507) data 0.000 (0.059) loss 2.3320 (2.3992) lr 9.8429e-02 eta 0:09:19
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 535
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 63.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [5/50] batch [2/24] time 0.554 (1.334) data 0.000 (0.691) loss 2.4199 (2.3740) lr 9.8429e-02 eta 0:24:30
epoch [5/50] batch [4/24] time 0.430 (0.883) data 0.000 (0.345) loss 2.4727 (2.3374) lr 9.8429e-02 eta 0:16:11
epoch [5/50] batch [6/24] time 0.435 (0.733) data 0.000 (0.230) loss 2.3848 (2.3577) lr 9.8429e-02 eta 0:13:24
epoch [5/50] batch [8/24] time 0.427 (0.656) data 0.000 (0.173) loss 2.2402 (2.3313) lr 9.8429e-02 eta 0:11:59
epoch [5/50] batch [10/24] time 0.430 (0.611) data 0.000 (0.138) loss 2.1719 (2.3275) lr 9.8429e-02 eta 0:11:08
epoch [5/50] batch [12/24] time 0.427 (0.580) data 0.000 (0.115) loss 2.3887 (2.3330) lr 9.8429e-02 eta 0:10:33
epoch [5/50] batch [14/24] time 0.428 (0.558) data 0.000 (0.099) loss 2.5098 (2.3486) lr 9.8429e-02 eta 0:10:08
epoch [5/50] batch [16/24] time 0.428 (0.542) data 0.000 (0.087) loss 2.3535 (2.3558) lr 9.8429e-02 eta 0:09:49
epoch [5/50] batch [18/24] time 0.432 (0.529) data 0.000 (0.077) loss 2.3047 (2.3633) lr 9.8429e-02 eta 0:09:35
epoch [5/50] batch [20/24] time 0.429 (0.519) data 0.000 (0.069) loss 2.4707 (2.3574) lr 9.8429e-02 eta 0:09:23
epoch [5/50] batch [22/24] time 0.432 (0.511) data 0.000 (0.063) loss 2.2461 (2.3493) lr 9.8429e-02 eta 0:09:13
epoch [5/50] batch [24/24] time 0.428 (0.504) data 0.000 (0.058) loss 2.6074 (2.3629) lr 9.7553e-02 eta 0:09:04
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 535
* accuracy: 65.9%
* error: 34.1%
* macro_f1: 64.0%

epoch [6/50] batch [2/24] time 0.443 (1.472) data 0.000 (0.944) loss 2.4082 (2.3867) lr 9.7553e-02 eta 0:26:26
epoch [6/50] batch [4/24] time 0.428 (0.949) data 0.000 (0.472) loss 2.3418 (2.4077) lr 9.7553e-02 eta 0:17:01
epoch [6/50] batch [6/24] time 0.427 (0.775) data 0.000 (0.315) loss 2.3047 (2.3672) lr 9.7553e-02 eta 0:13:52
epoch [6/50] batch [8/24] time 0.427 (0.688) data 0.000 (0.236) loss 2.3223 (2.3694) lr 9.7553e-02 eta 0:12:17
epoch [6/50] batch [10/24] time 0.429 (0.636) data 0.000 (0.189) loss 2.3496 (2.3654) lr 9.7553e-02 eta 0:11:20
epoch [6/50] batch [12/24] time 0.428 (0.601) data 0.000 (0.158) loss 2.3730 (2.3685) lr 9.7553e-02 eta 0:10:42
epoch [6/50] batch [14/24] time 0.428 (0.577) data 0.000 (0.135) loss 2.4258 (2.3634) lr 9.7553e-02 eta 0:10:15
epoch [6/50] batch [16/24] time 0.428 (0.558) data 0.000 (0.118) loss 2.3125 (2.3416) lr 9.7553e-02 eta 0:09:54
epoch [6/50] batch [18/24] time 0.427 (0.544) data 0.000 (0.105) loss 2.2832 (2.3418) lr 9.7553e-02 eta 0:09:37
epoch [6/50] batch [20/24] time 0.426 (0.532) data 0.000 (0.095) loss 2.3145 (2.3439) lr 9.7553e-02 eta 0:09:24
epoch [6/50] batch [22/24] time 0.427 (0.522) data 0.000 (0.086) loss 2.4785 (2.3491) lr 9.7553e-02 eta 0:09:12
epoch [6/50] batch [24/24] time 0.425 (0.514) data 0.000 (0.079) loss 2.4375 (2.3547) lr 9.6489e-02 eta 0:09:03
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 536
* accuracy: 66.0%
* error: 34.0%
* macro_f1: 63.7%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [7/50] batch [2/24] time 0.620 (1.273) data 0.000 (0.598) loss 2.3457 (2.3525) lr 9.6489e-02 eta 0:22:21
epoch [7/50] batch [4/24] time 0.427 (0.852) data 0.000 (0.299) loss 2.2227 (2.3481) lr 9.6489e-02 eta 0:14:56
epoch [7/50] batch [6/24] time 0.434 (0.712) data 0.000 (0.199) loss 2.5625 (2.3652) lr 9.6489e-02 eta 0:12:27
epoch [7/50] batch [8/24] time 0.430 (0.641) data 0.000 (0.150) loss 2.3984 (2.3975) lr 9.6489e-02 eta 0:11:12
epoch [7/50] batch [10/24] time 0.428 (0.599) data 0.000 (0.120) loss 2.2207 (2.3512) lr 9.6489e-02 eta 0:10:26
epoch [7/50] batch [12/24] time 0.427 (0.570) data 0.000 (0.100) loss 2.2773 (2.3442) lr 9.6489e-02 eta 0:09:55
epoch [7/50] batch [14/24] time 0.428 (0.550) data 0.000 (0.086) loss 2.3789 (2.3545) lr 9.6489e-02 eta 0:09:33
epoch [7/50] batch [16/24] time 0.427 (0.535) data 0.000 (0.075) loss 2.2207 (2.3447) lr 9.6489e-02 eta 0:09:16
epoch [7/50] batch [18/24] time 0.432 (0.524) data 0.000 (0.067) loss 2.4473 (2.3451) lr 9.6489e-02 eta 0:09:03
epoch [7/50] batch [20/24] time 0.429 (0.515) data 0.000 (0.060) loss 2.3867 (2.3547) lr 9.6489e-02 eta 0:08:53
epoch [7/50] batch [22/24] time 0.427 (0.507) data 0.000 (0.055) loss 2.1250 (2.3421) lr 9.6489e-02 eta 0:08:43
epoch [7/50] batch [24/24] time 0.428 (0.500) data 0.000 (0.050) loss 2.2559 (2.3472) lr 9.5241e-02 eta 0:08:36
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.23s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 537
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 64.2%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [8/50] batch [2/24] time 0.586 (1.314) data 0.000 (0.625) loss 2.3262 (2.2568) lr 9.5241e-02 eta 0:22:32
epoch [8/50] batch [4/24] time 0.433 (0.875) data 0.000 (0.313) loss 2.3730 (2.3223) lr 9.5241e-02 eta 0:14:59
epoch [8/50] batch [6/24] time 0.427 (0.726) data 0.000 (0.209) loss 2.5898 (2.3662) lr 9.5241e-02 eta 0:12:25
epoch [8/50] batch [8/24] time 0.431 (0.653) data 0.000 (0.156) loss 2.3555 (2.3767) lr 9.5241e-02 eta 0:11:08
epoch [8/50] batch [10/24] time 0.429 (0.609) data 0.000 (0.125) loss 2.3672 (2.3834) lr 9.5241e-02 eta 0:10:21
epoch [8/50] batch [12/24] time 0.434 (0.579) data 0.000 (0.104) loss 2.3613 (2.3853) lr 9.5241e-02 eta 0:09:50
epoch [8/50] batch [14/24] time 0.428 (0.557) data 0.000 (0.090) loss 2.4062 (2.3728) lr 9.5241e-02 eta 0:09:27
epoch [8/50] batch [16/24] time 0.429 (0.541) data 0.000 (0.078) loss 2.0176 (2.3490) lr 9.5241e-02 eta 0:09:09
epoch [8/50] batch [18/24] time 0.427 (0.528) data 0.000 (0.070) loss 2.2637 (2.3390) lr 9.5241e-02 eta 0:08:55
epoch [8/50] batch [20/24] time 0.431 (0.523) data 0.000 (0.063) loss 2.3750 (2.3423) lr 9.5241e-02 eta 0:08:48
epoch [8/50] batch [22/24] time 0.427 (0.514) data 0.000 (0.057) loss 2.2363 (2.3392) lr 9.5241e-02 eta 0:08:39
epoch [8/50] batch [24/24] time 0.430 (0.507) data 0.000 (0.052) loss 2.3633 (2.3376) lr 9.3815e-02 eta 0:08:31
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.13s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.54it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 533
* accuracy: 65.6%
* error: 34.4%
* macro_f1: 64.0%

epoch [9/50] batch [2/24] time 0.494 (1.356) data 0.000 (0.722) loss 2.3125 (2.2705) lr 9.3815e-02 eta 0:22:43
epoch [9/50] batch [4/24] time 0.425 (0.892) data 0.000 (0.361) loss 2.3105 (2.3027) lr 9.3815e-02 eta 0:14:55
epoch [9/50] batch [6/24] time 0.428 (0.737) data 0.000 (0.241) loss 2.3438 (2.3519) lr 9.3815e-02 eta 0:12:18
epoch [9/50] batch [8/24] time 0.431 (0.660) data 0.000 (0.181) loss 2.2734 (2.3083) lr 9.3815e-02 eta 0:11:00
epoch [9/50] batch [10/24] time 0.427 (0.614) data 0.000 (0.145) loss 2.2656 (2.2762) lr 9.3815e-02 eta 0:10:12
epoch [9/50] batch [12/24] time 0.427 (0.583) data 0.000 (0.120) loss 2.3730 (2.2814) lr 9.3815e-02 eta 0:09:40
epoch [9/50] batch [14/24] time 0.427 (0.561) data 0.000 (0.103) loss 2.5176 (2.2962) lr 9.3815e-02 eta 0:09:17
epoch [9/50] batch [16/24] time 0.427 (0.544) data 0.000 (0.090) loss 2.2891 (2.2957) lr 9.3815e-02 eta 0:08:59
epoch [9/50] batch [18/24] time 0.427 (0.531) data 0.000 (0.080) loss 2.2949 (2.2955) lr 9.3815e-02 eta 0:08:45
epoch [9/50] batch [20/24] time 0.429 (0.521) data 0.000 (0.072) loss 2.3750 (2.3018) lr 9.3815e-02 eta 0:08:34
epoch [9/50] batch [22/24] time 0.433 (0.513) data 0.000 (0.066) loss 2.2656 (2.3018) lr 9.3815e-02 eta 0:08:25
epoch [9/50] batch [24/24] time 0.429 (0.506) data 0.000 (0.060) loss 2.1992 (2.2977) lr 9.2216e-02 eta 0:08:17
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 537
* accuracy: 66.1%
* error: 33.9%
* macro_f1: 64.2%

epoch [10/50] batch [2/24] time 0.500 (1.366) data 0.000 (0.709) loss 2.1719 (2.2168) lr 9.2216e-02 eta 0:22:21
epoch [10/50] batch [4/24] time 0.427 (0.899) data 0.000 (0.355) loss 2.6016 (2.3066) lr 9.2216e-02 eta 0:14:41
epoch [10/50] batch [6/24] time 0.428 (0.743) data 0.000 (0.237) loss 2.1543 (2.3125) lr 9.2216e-02 eta 0:12:06
epoch [10/50] batch [8/24] time 0.430 (0.664) data 0.000 (0.177) loss 2.3496 (2.3110) lr 9.2216e-02 eta 0:10:48
epoch [10/50] batch [10/24] time 0.429 (0.618) data 0.000 (0.142) loss 2.2793 (2.3092) lr 9.2216e-02 eta 0:10:01
epoch [10/50] batch [12/24] time 0.428 (0.586) data 0.000 (0.118) loss 2.1270 (2.3105) lr 9.2216e-02 eta 0:09:29
epoch [10/50] batch [14/24] time 0.428 (0.564) data 0.000 (0.101) loss 2.3359 (2.3111) lr 9.2216e-02 eta 0:09:06
epoch [10/50] batch [16/24] time 0.427 (0.547) data 0.000 (0.089) loss 2.3633 (2.3186) lr 9.2216e-02 eta 0:08:49
epoch [10/50] batch [18/24] time 0.426 (0.533) data 0.000 (0.079) loss 2.5215 (2.3301) lr 9.2216e-02 eta 0:08:35
epoch [10/50] batch [20/24] time 0.432 (0.523) data 0.000 (0.071) loss 2.3066 (2.3269) lr 9.2216e-02 eta 0:08:24
epoch [10/50] batch [22/24] time 0.436 (0.515) data 0.000 (0.065) loss 2.2988 (2.3229) lr 9.2216e-02 eta 0:08:15
epoch [10/50] batch [24/24] time 0.427 (0.507) data 0.000 (0.059) loss 2.4980 (2.3234) lr 9.0451e-02 eta 0:08:07
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.12s/it] 40%|████      | 2/5 [00:03<00:04,  1.44s/it] 60%|██████    | 3/5 [00:03<00:01,  1.11it/s] 80%|████████  | 4/5 [00:03<00:00,  1.54it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 545
* accuracy: 67.1%
* error: 32.9%
* macro_f1: 65.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model.pth.tar-10

epoch [11/50] batch [2/24] time 0.542 (1.344) data 0.000 (0.704) loss 2.2773 (2.2822) lr 9.0451e-02 eta 0:21:27
epoch [11/50] batch [4/24] time 0.428 (0.889) data 0.000 (0.352) loss 2.1953 (2.2808) lr 9.0451e-02 eta 0:14:10
epoch [11/50] batch [6/24] time 0.426 (0.735) data 0.000 (0.235) loss 2.3164 (2.2933) lr 9.0451e-02 eta 0:11:40
epoch [11/50] batch [8/24] time 0.427 (0.658) data 0.000 (0.176) loss 2.2383 (2.3030) lr 9.0451e-02 eta 0:10:26
epoch [11/50] batch [10/24] time 0.426 (0.612) data 0.000 (0.141) loss 2.1836 (2.2959) lr 9.0451e-02 eta 0:09:41
epoch [11/50] batch [12/24] time 0.425 (0.582) data 0.000 (0.118) loss 2.3848 (2.3099) lr 9.0451e-02 eta 0:09:11
epoch [11/50] batch [14/24] time 0.428 (0.559) data 0.000 (0.101) loss 2.4258 (2.3305) lr 9.0451e-02 eta 0:08:49
epoch [11/50] batch [16/24] time 0.427 (0.543) data 0.000 (0.088) loss 2.3457 (2.3301) lr 9.0451e-02 eta 0:08:32
epoch [11/50] batch [18/24] time 0.428 (0.530) data 0.000 (0.078) loss 2.2754 (2.3201) lr 9.0451e-02 eta 0:08:19
epoch [11/50] batch [20/24] time 0.426 (0.520) data 0.000 (0.071) loss 2.2070 (2.3091) lr 9.0451e-02 eta 0:08:08
epoch [11/50] batch [22/24] time 0.433 (0.511) data 0.000 (0.064) loss 2.3711 (2.3058) lr 9.0451e-02 eta 0:07:59
epoch [11/50] batch [24/24] time 0.429 (0.504) data 0.000 (0.059) loss 2.4102 (2.3066) lr 8.8526e-02 eta 0:07:52
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:13,  3.29s/it] 40%|████      | 2/5 [00:03<00:04,  1.51s/it] 60%|██████    | 3/5 [00:03<00:01,  1.06it/s] 80%|████████  | 4/5 [00:04<00:00,  1.49it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 548
* accuracy: 67.5%
* error: 32.5%
* macro_f1: 65.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [12/50] batch [2/24] time 0.494 (1.348) data 0.000 (0.744) loss 2.5605 (2.4219) lr 8.8526e-02 eta 0:20:58
epoch [12/50] batch [4/24] time 0.427 (0.889) data 0.000 (0.372) loss 2.3066 (2.3462) lr 8.8526e-02 eta 0:13:48
epoch [12/50] batch [6/24] time 0.426 (0.735) data 0.000 (0.248) loss 2.3184 (2.3242) lr 8.8526e-02 eta 0:11:23
epoch [12/50] batch [8/24] time 0.430 (0.658) data 0.000 (0.186) loss 2.3125 (2.3330) lr 8.8526e-02 eta 0:10:11
epoch [12/50] batch [10/24] time 0.432 (0.613) data 0.000 (0.149) loss 2.2129 (2.3283) lr 8.8526e-02 eta 0:09:27
epoch [12/50] batch [12/24] time 0.425 (0.581) data 0.000 (0.124) loss 2.2344 (2.3285) lr 8.8526e-02 eta 0:08:57
epoch [12/50] batch [14/24] time 0.431 (0.560) data 0.000 (0.106) loss 2.3789 (2.3351) lr 8.8526e-02 eta 0:08:36
epoch [12/50] batch [16/24] time 0.426 (0.544) data 0.000 (0.093) loss 2.1484 (2.3225) lr 8.8526e-02 eta 0:08:20
epoch [12/50] batch [18/24] time 0.429 (0.531) data 0.000 (0.083) loss 2.2910 (2.3143) lr 8.8526e-02 eta 0:08:07
epoch [12/50] batch [20/24] time 0.429 (0.521) data 0.000 (0.075) loss 2.1973 (2.2970) lr 8.8526e-02 eta 0:07:56
epoch [12/50] batch [22/24] time 0.427 (0.512) data 0.000 (0.068) loss 2.2734 (2.3034) lr 8.8526e-02 eta 0:07:48
epoch [12/50] batch [24/24] time 0.430 (0.505) data 0.000 (0.062) loss 2.2598 (2.2987) lr 8.6448e-02 eta 0:07:40
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.22s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 545
* accuracy: 67.1%
* error: 32.9%
* macro_f1: 65.3%

epoch [13/50] batch [2/24] time 0.532 (1.328) data 0.000 (0.702) loss 2.1992 (2.2422) lr 8.6448e-02 eta 0:20:08
epoch [13/50] batch [4/24] time 0.432 (0.881) data 0.000 (0.351) loss 2.1836 (2.2524) lr 8.6448e-02 eta 0:13:20
epoch [13/50] batch [6/24] time 0.428 (0.730) data 0.000 (0.234) loss 2.2695 (2.2643) lr 8.6448e-02 eta 0:11:01
epoch [13/50] batch [8/24] time 0.427 (0.655) data 0.000 (0.176) loss 2.2363 (2.2634) lr 8.6448e-02 eta 0:09:51
epoch [13/50] batch [10/24] time 0.427 (0.610) data 0.000 (0.141) loss 2.2188 (2.2738) lr 8.6448e-02 eta 0:09:09
epoch [13/50] batch [12/24] time 0.428 (0.580) data 0.000 (0.117) loss 2.4590 (2.3011) lr 8.6448e-02 eta 0:08:41
epoch [13/50] batch [14/24] time 0.433 (0.558) data 0.000 (0.101) loss 2.5059 (2.3175) lr 8.6448e-02 eta 0:08:21
epoch [13/50] batch [16/24] time 0.427 (0.542) data 0.000 (0.088) loss 2.4570 (2.3223) lr 8.6448e-02 eta 0:08:05
epoch [13/50] batch [18/24] time 0.432 (0.530) data 0.000 (0.078) loss 2.4199 (2.3214) lr 8.6448e-02 eta 0:07:53
epoch [13/50] batch [20/24] time 0.427 (0.520) data 0.000 (0.070) loss 2.4258 (2.3275) lr 8.6448e-02 eta 0:07:43
epoch [13/50] batch [22/24] time 0.432 (0.512) data 0.000 (0.064) loss 2.5000 (2.3360) lr 8.6448e-02 eta 0:07:35
epoch [13/50] batch [24/24] time 0.428 (0.505) data 0.000 (0.059) loss 2.4473 (2.3367) lr 8.4227e-02 eta 0:07:28
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 546
* accuracy: 67.2%
* error: 32.8%
* macro_f1: 65.7%

epoch [14/50] batch [2/24] time 0.566 (1.316) data 0.001 (0.625) loss 2.3594 (2.4082) lr 8.4227e-02 eta 0:19:25
epoch [14/50] batch [4/24] time 0.426 (0.872) data 0.000 (0.313) loss 2.3828 (2.4062) lr 8.4227e-02 eta 0:12:50
epoch [14/50] batch [6/24] time 0.513 (0.738) data 0.000 (0.209) loss 2.2637 (2.3438) lr 8.4227e-02 eta 0:10:50
epoch [14/50] batch [8/24] time 0.425 (0.660) data 0.000 (0.156) loss 2.3867 (2.3633) lr 8.4227e-02 eta 0:09:40
epoch [14/50] batch [10/24] time 0.425 (0.613) data 0.000 (0.125) loss 2.2773 (2.3338) lr 8.4227e-02 eta 0:08:58
epoch [14/50] batch [12/24] time 0.427 (0.582) data 0.000 (0.104) loss 2.4219 (2.3359) lr 8.4227e-02 eta 0:08:29
epoch [14/50] batch [14/24] time 0.426 (0.560) data 0.000 (0.089) loss 2.3828 (2.3364) lr 8.4227e-02 eta 0:08:09
epoch [14/50] batch [16/24] time 0.424 (0.543) data 0.000 (0.078) loss 2.2637 (2.3182) lr 8.4227e-02 eta 0:07:53
epoch [14/50] batch [18/24] time 0.426 (0.530) data 0.000 (0.070) loss 2.3457 (2.3219) lr 8.4227e-02 eta 0:07:41
epoch [14/50] batch [20/24] time 0.428 (0.520) data 0.000 (0.063) loss 2.2852 (2.3307) lr 8.4227e-02 eta 0:07:31
epoch [14/50] batch [22/24] time 0.429 (0.512) data 0.000 (0.057) loss 2.3965 (2.3362) lr 8.4227e-02 eta 0:07:22
epoch [14/50] batch [24/24] time 0.426 (0.504) data 0.000 (0.052) loss 2.3418 (2.3343) lr 8.1871e-02 eta 0:07:15
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 548
* accuracy: 67.5%
* error: 32.5%
* macro_f1: 66.0%

epoch [15/50] batch [2/24] time 0.502 (1.327) data 0.000 (0.665) loss 2.3672 (2.3428) lr 8.1871e-02 eta 0:19:04
epoch [15/50] batch [4/24] time 0.427 (0.877) data 0.000 (0.333) loss 2.0547 (2.2559) lr 8.1871e-02 eta 0:12:34
epoch [15/50] batch [6/24] time 0.431 (0.728) data 0.000 (0.222) loss 2.3125 (2.2767) lr 8.1871e-02 eta 0:10:24
epoch [15/50] batch [8/24] time 0.429 (0.653) data 0.000 (0.166) loss 2.2168 (2.2898) lr 8.1871e-02 eta 0:09:18
epoch [15/50] batch [10/24] time 0.428 (0.608) data 0.000 (0.133) loss 2.2930 (2.3021) lr 8.1871e-02 eta 0:08:39
epoch [15/50] batch [12/24] time 0.427 (0.578) data 0.000 (0.111) loss 2.2559 (2.3179) lr 8.1871e-02 eta 0:08:12
epoch [15/50] batch [14/24] time 0.427 (0.556) data 0.000 (0.095) loss 2.3281 (2.3234) lr 8.1871e-02 eta 0:07:52
epoch [15/50] batch [16/24] time 0.434 (0.541) data 0.000 (0.083) loss 2.2812 (2.3140) lr 8.1871e-02 eta 0:07:38
epoch [15/50] batch [18/24] time 0.430 (0.529) data 0.000 (0.074) loss 2.5391 (2.3252) lr 8.1871e-02 eta 0:07:27
epoch [15/50] batch [20/24] time 0.427 (0.519) data 0.000 (0.067) loss 2.3828 (2.3195) lr 8.1871e-02 eta 0:07:17
epoch [15/50] batch [22/24] time 0.432 (0.511) data 0.000 (0.061) loss 2.2871 (2.3256) lr 8.1871e-02 eta 0:07:10
epoch [15/50] batch [24/24] time 0.434 (0.504) data 0.000 (0.056) loss 2.3301 (2.3236) lr 7.9389e-02 eta 0:07:03
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 552
* accuracy: 68.0%
* error: 32.0%
* macro_f1: 66.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [16/50] batch [2/24] time 0.665 (1.236) data 0.000 (0.495) loss 2.1582 (2.1230) lr 7.9389e-02 eta 0:17:15
epoch [16/50] batch [4/24] time 0.433 (0.839) data 0.000 (0.248) loss 2.1777 (2.2012) lr 7.9389e-02 eta 0:11:41
epoch [16/50] batch [6/24] time 0.428 (0.703) data 0.000 (0.165) loss 2.2402 (2.2135) lr 7.9389e-02 eta 0:09:46
epoch [16/50] batch [8/24] time 0.430 (0.634) data 0.000 (0.124) loss 2.2285 (2.2302) lr 7.9389e-02 eta 0:08:47
epoch [16/50] batch [10/24] time 0.432 (0.593) data 0.000 (0.099) loss 2.3730 (2.2633) lr 7.9389e-02 eta 0:08:12
epoch [16/50] batch [12/24] time 0.425 (0.565) data 0.000 (0.083) loss 2.4082 (2.2915) lr 7.9389e-02 eta 0:07:47
epoch [16/50] batch [14/24] time 0.427 (0.546) data 0.000 (0.071) loss 2.2969 (2.2960) lr 7.9389e-02 eta 0:07:30
epoch [16/50] batch [16/24] time 0.427 (0.531) data 0.000 (0.062) loss 2.1465 (2.2933) lr 7.9389e-02 eta 0:07:17
epoch [16/50] batch [18/24] time 0.432 (0.520) data 0.000 (0.055) loss 2.2676 (2.2936) lr 7.9389e-02 eta 0:07:07
epoch [16/50] batch [20/24] time 0.427 (0.511) data 0.000 (0.050) loss 2.2949 (2.2893) lr 7.9389e-02 eta 0:06:58
epoch [16/50] batch [22/24] time 0.427 (0.503) data 0.000 (0.045) loss 2.2832 (2.2912) lr 7.9389e-02 eta 0:06:51
epoch [16/50] batch [24/24] time 0.431 (0.497) data 0.000 (0.041) loss 2.2207 (2.2843) lr 7.6791e-02 eta 0:06:45
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:13,  3.32s/it] 40%|████      | 2/5 [00:03<00:04,  1.53s/it] 60%|██████    | 3/5 [00:03<00:01,  1.05it/s] 80%|████████  | 4/5 [00:04<00:00,  1.48it/s]100%|██████████| 5/5 [00:04<00:00,  1.16it/s]=> result
* total: 812
* correct: 552
* accuracy: 68.0%
* error: 32.0%
* macro_f1: 66.4%

epoch [17/50] batch [2/24] time 0.539 (1.335) data 0.000 (0.697) loss 2.3047 (2.3369) lr 7.6791e-02 eta 0:18:06
epoch [17/50] batch [4/24] time 0.425 (0.882) data 0.000 (0.349) loss 2.4512 (2.2634) lr 7.6791e-02 eta 0:11:56
epoch [17/50] batch [6/24] time 0.425 (0.730) data 0.000 (0.233) loss 2.3555 (2.2834) lr 7.6791e-02 eta 0:09:51
epoch [17/50] batch [8/24] time 0.424 (0.653) data 0.000 (0.174) loss 2.2227 (2.2816) lr 7.6791e-02 eta 0:08:47
epoch [17/50] batch [10/24] time 0.424 (0.607) data 0.000 (0.140) loss 2.3613 (2.2802) lr 7.6791e-02 eta 0:08:09
epoch [17/50] batch [12/24] time 0.423 (0.577) data 0.000 (0.116) loss 2.3555 (2.2913) lr 7.6791e-02 eta 0:07:44
epoch [17/50] batch [14/24] time 0.424 (0.555) data 0.000 (0.100) loss 2.5039 (2.3124) lr 7.6791e-02 eta 0:07:25
epoch [17/50] batch [16/24] time 0.423 (0.539) data 0.000 (0.087) loss 2.3770 (2.3148) lr 7.6791e-02 eta 0:07:11
epoch [17/50] batch [18/24] time 0.423 (0.526) data 0.000 (0.078) loss 2.5840 (2.3234) lr 7.6791e-02 eta 0:06:59
epoch [17/50] batch [20/24] time 0.423 (0.516) data 0.000 (0.070) loss 2.5527 (2.3217) lr 7.6791e-02 eta 0:06:50
epoch [17/50] batch [22/24] time 0.423 (0.507) data 0.000 (0.064) loss 2.2520 (2.3243) lr 7.6791e-02 eta 0:06:42
epoch [17/50] batch [24/24] time 0.424 (0.500) data 0.000 (0.058) loss 2.1992 (2.3198) lr 7.4088e-02 eta 0:06:36
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 557
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 67.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [18/50] batch [2/24] time 0.629 (1.241) data 0.000 (0.547) loss 2.1250 (2.1846) lr 7.4088e-02 eta 0:16:20
epoch [18/50] batch [4/24] time 0.430 (0.835) data 0.000 (0.274) loss 2.1309 (2.1719) lr 7.4088e-02 eta 0:10:58
epoch [18/50] batch [6/24] time 0.425 (0.699) data 0.000 (0.183) loss 2.4785 (2.2367) lr 7.4088e-02 eta 0:09:09
epoch [18/50] batch [8/24] time 0.426 (0.630) data 0.000 (0.137) loss 2.2539 (2.2859) lr 7.4088e-02 eta 0:08:14
epoch [18/50] batch [10/24] time 0.436 (0.590) data 0.000 (0.110) loss 2.4141 (2.3029) lr 7.4088e-02 eta 0:07:41
epoch [18/50] batch [12/24] time 0.426 (0.571) data 0.000 (0.091) loss 2.2363 (2.2910) lr 7.4088e-02 eta 0:07:25
epoch [18/50] batch [14/24] time 0.425 (0.550) data 0.000 (0.078) loss 2.2539 (2.2942) lr 7.4088e-02 eta 0:07:07
epoch [18/50] batch [16/24] time 0.424 (0.534) data 0.000 (0.069) loss 2.4023 (2.2977) lr 7.4088e-02 eta 0:06:54
epoch [18/50] batch [18/24] time 0.426 (0.522) data 0.000 (0.061) loss 2.3164 (2.2959) lr 7.4088e-02 eta 0:06:44
epoch [18/50] batch [20/24] time 0.424 (0.512) data 0.000 (0.055) loss 2.2500 (2.2992) lr 7.4088e-02 eta 0:06:35
epoch [18/50] batch [22/24] time 0.429 (0.505) data 0.000 (0.050) loss 2.1445 (2.2910) lr 7.4088e-02 eta 0:06:28
epoch [18/50] batch [24/24] time 0.437 (0.499) data 0.000 (0.046) loss 2.0488 (2.2778) lr 7.1289e-02 eta 0:06:22
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.09s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 547
* accuracy: 67.4%
* error: 32.6%
* macro_f1: 65.4%

epoch [19/50] batch [2/24] time 0.643 (1.272) data 0.000 (0.566) loss 2.3125 (2.2832) lr 7.1289e-02 eta 0:16:14
epoch [19/50] batch [4/24] time 0.427 (0.852) data 0.000 (0.283) loss 2.3203 (2.3042) lr 7.1289e-02 eta 0:10:50
epoch [19/50] batch [6/24] time 0.426 (0.710) data 0.000 (0.189) loss 2.2871 (2.2939) lr 7.1289e-02 eta 0:09:00
epoch [19/50] batch [8/24] time 0.427 (0.639) data 0.000 (0.142) loss 2.2676 (2.2832) lr 7.1289e-02 eta 0:08:05
epoch [19/50] batch [10/24] time 0.426 (0.596) data 0.000 (0.113) loss 2.2676 (2.2809) lr 7.1289e-02 eta 0:07:32
epoch [19/50] batch [12/24] time 0.429 (0.568) data 0.000 (0.095) loss 2.3008 (2.2852) lr 7.1289e-02 eta 0:07:09
epoch [19/50] batch [14/24] time 0.430 (0.548) data 0.000 (0.081) loss 2.2852 (2.2799) lr 7.1289e-02 eta 0:06:53
epoch [19/50] batch [16/24] time 0.426 (0.533) data 0.000 (0.071) loss 2.2188 (2.2843) lr 7.1289e-02 eta 0:06:41
epoch [19/50] batch [18/24] time 0.425 (0.521) data 0.000 (0.063) loss 2.3047 (2.2846) lr 7.1289e-02 eta 0:06:30
epoch [19/50] batch [20/24] time 0.425 (0.512) data 0.000 (0.057) loss 2.2070 (2.2789) lr 7.1289e-02 eta 0:06:22
epoch [19/50] batch [22/24] time 0.425 (0.504) data 0.000 (0.052) loss 2.2676 (2.2784) lr 7.1289e-02 eta 0:06:15
epoch [19/50] batch [24/24] time 0.427 (0.498) data 0.000 (0.047) loss 2.2480 (2.2774) lr 6.8406e-02 eta 0:06:10
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 560
* accuracy: 69.0%
* error: 31.0%
* macro_f1: 67.5%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [20/50] batch [2/24] time 0.484 (1.357) data 0.000 (0.738) loss 2.2988 (2.2939) lr 6.8406e-02 eta 0:16:47
epoch [20/50] batch [4/24] time 0.429 (0.895) data 0.000 (0.369) loss 2.1641 (2.2373) lr 6.8406e-02 eta 0:11:02
epoch [20/50] batch [6/24] time 0.428 (0.739) data 0.000 (0.246) loss 2.2031 (2.2135) lr 6.8406e-02 eta 0:09:05
epoch [20/50] batch [8/24] time 0.431 (0.661) data 0.000 (0.185) loss 2.5020 (2.2681) lr 6.8406e-02 eta 0:08:06
epoch [20/50] batch [10/24] time 0.426 (0.614) data 0.000 (0.148) loss 2.4199 (2.2697) lr 6.8406e-02 eta 0:07:30
epoch [20/50] batch [12/24] time 0.427 (0.582) data 0.000 (0.123) loss 2.3086 (2.2868) lr 6.8406e-02 eta 0:07:06
epoch [20/50] batch [14/24] time 0.428 (0.560) data 0.000 (0.106) loss 2.4707 (2.2808) lr 6.8406e-02 eta 0:06:48
epoch [20/50] batch [16/24] time 0.424 (0.544) data 0.000 (0.092) loss 2.3516 (2.2892) lr 6.8406e-02 eta 0:06:35
epoch [20/50] batch [18/24] time 0.424 (0.530) data 0.000 (0.082) loss 2.1895 (2.2828) lr 6.8406e-02 eta 0:06:25
epoch [20/50] batch [20/24] time 0.425 (0.520) data 0.000 (0.074) loss 2.3359 (2.2803) lr 6.8406e-02 eta 0:06:16
epoch [20/50] batch [22/24] time 0.426 (0.511) data 0.000 (0.067) loss 2.1445 (2.2677) lr 6.8406e-02 eta 0:06:09
epoch [20/50] batch [24/24] time 0.429 (0.504) data 0.000 (0.062) loss 2.2598 (2.2616) lr 6.5451e-02 eta 0:06:03
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.49s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 561
* accuracy: 69.1%
* error: 30.9%
* macro_f1: 67.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model.pth.tar-20

epoch [21/50] batch [2/24] time 0.427 (1.401) data 0.000 (0.859) loss 2.3418 (2.3799) lr 6.5451e-02 eta 0:16:45
epoch [21/50] batch [4/24] time 0.428 (0.914) data 0.000 (0.429) loss 2.3359 (2.3594) lr 6.5451e-02 eta 0:10:54
epoch [21/50] batch [6/24] time 0.427 (0.751) data 0.000 (0.286) loss 2.3047 (2.3291) lr 6.5451e-02 eta 0:08:56
epoch [21/50] batch [8/24] time 0.426 (0.671) data 0.000 (0.215) loss 2.4219 (2.3469) lr 6.5451e-02 eta 0:07:57
epoch [21/50] batch [10/24] time 0.425 (0.623) data 0.000 (0.172) loss 2.3125 (2.3170) lr 6.5451e-02 eta 0:07:22
epoch [21/50] batch [12/24] time 0.435 (0.591) data 0.000 (0.143) loss 2.5059 (2.3381) lr 6.5451e-02 eta 0:06:58
epoch [21/50] batch [14/24] time 0.427 (0.568) data 0.000 (0.123) loss 2.1367 (2.3082) lr 6.5451e-02 eta 0:06:40
epoch [21/50] batch [16/24] time 0.429 (0.550) data 0.000 (0.108) loss 2.2090 (2.2947) lr 6.5451e-02 eta 0:06:27
epoch [21/50] batch [18/24] time 0.426 (0.536) data 0.000 (0.096) loss 2.3242 (2.3016) lr 6.5451e-02 eta 0:06:16
epoch [21/50] batch [20/24] time 0.426 (0.525) data 0.000 (0.086) loss 2.3613 (2.3090) lr 6.5451e-02 eta 0:06:07
epoch [21/50] batch [22/24] time 0.429 (0.516) data 0.000 (0.078) loss 2.1738 (2.3032) lr 6.5451e-02 eta 0:06:00
epoch [21/50] batch [24/24] time 0.433 (0.509) data 0.000 (0.072) loss 2.4707 (2.3069) lr 6.2434e-02 eta 0:05:54
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.52s/it] 60%|██████    | 3/5 [00:03<00:01,  1.06it/s] 80%|████████  | 4/5 [00:04<00:00,  1.48it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 557
* accuracy: 68.6%
* error: 31.4%
* macro_f1: 66.9%

epoch [22/50] batch [2/24] time 0.602 (1.264) data 0.001 (0.589) loss 2.1953 (2.1836) lr 6.2434e-02 eta 0:14:37
epoch [22/50] batch [4/24] time 0.428 (0.850) data 0.000 (0.294) loss 2.4863 (2.2793) lr 6.2434e-02 eta 0:09:48
epoch [22/50] batch [6/24] time 0.428 (0.709) data 0.000 (0.196) loss 2.2598 (2.2891) lr 6.2434e-02 eta 0:08:09
epoch [22/50] batch [8/24] time 0.429 (0.639) data 0.000 (0.147) loss 2.2695 (2.2971) lr 6.2434e-02 eta 0:07:19
epoch [22/50] batch [10/24] time 0.427 (0.597) data 0.000 (0.118) loss 2.2734 (2.3031) lr 6.2434e-02 eta 0:06:49
epoch [22/50] batch [12/24] time 0.512 (0.576) data 0.000 (0.098) loss 2.2793 (2.3047) lr 6.2434e-02 eta 0:06:33
epoch [22/50] batch [14/24] time 0.429 (0.555) data 0.000 (0.084) loss 2.3301 (2.3012) lr 6.2434e-02 eta 0:06:18
epoch [22/50] batch [16/24] time 0.429 (0.539) data 0.000 (0.074) loss 2.1250 (2.2913) lr 6.2434e-02 eta 0:06:06
epoch [22/50] batch [18/24] time 0.427 (0.527) data 0.000 (0.066) loss 2.3477 (2.2869) lr 6.2434e-02 eta 0:05:57
epoch [22/50] batch [20/24] time 0.427 (0.517) data 0.000 (0.059) loss 2.2832 (2.2951) lr 6.2434e-02 eta 0:05:49
epoch [22/50] batch [22/24] time 0.426 (0.508) data 0.000 (0.054) loss 2.2695 (2.2987) lr 6.2434e-02 eta 0:05:42
epoch [22/50] batch [24/24] time 0.428 (0.502) data 0.000 (0.049) loss 2.1934 (2.2837) lr 5.9369e-02 eta 0:05:37
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.14s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 558
* accuracy: 68.7%
* error: 31.3%
* macro_f1: 67.1%

epoch [23/50] batch [2/24] time 0.627 (1.222) data 0.000 (0.536) loss 2.2168 (2.2100) lr 5.9369e-02 eta 0:13:39
epoch [23/50] batch [4/24] time 0.425 (0.833) data 0.000 (0.268) loss 2.1426 (2.1968) lr 5.9369e-02 eta 0:09:16
epoch [23/50] batch [6/24] time 0.429 (0.698) data 0.000 (0.179) loss 2.3398 (2.2314) lr 5.9369e-02 eta 0:07:44
epoch [23/50] batch [8/24] time 0.428 (0.630) data 0.000 (0.134) loss 2.2969 (2.2346) lr 5.9369e-02 eta 0:06:58
epoch [23/50] batch [10/24] time 0.425 (0.589) data 0.000 (0.107) loss 2.3008 (2.2559) lr 5.9369e-02 eta 0:06:30
epoch [23/50] batch [12/24] time 0.428 (0.563) data 0.000 (0.090) loss 2.3574 (2.2611) lr 5.9369e-02 eta 0:06:11
epoch [23/50] batch [14/24] time 0.428 (0.544) data 0.000 (0.077) loss 2.2559 (2.2543) lr 5.9369e-02 eta 0:05:57
epoch [23/50] batch [16/24] time 0.427 (0.529) data 0.000 (0.067) loss 2.2422 (2.2574) lr 5.9369e-02 eta 0:05:47
epoch [23/50] batch [18/24] time 0.427 (0.518) data 0.000 (0.060) loss 2.3262 (2.2630) lr 5.9369e-02 eta 0:05:38
epoch [23/50] batch [20/24] time 0.427 (0.509) data 0.000 (0.054) loss 2.4473 (2.2713) lr 5.9369e-02 eta 0:05:31
epoch [23/50] batch [22/24] time 0.435 (0.502) data 0.000 (0.049) loss 2.3984 (2.2775) lr 5.9369e-02 eta 0:05:26
epoch [23/50] batch [24/24] time 0.427 (0.496) data 0.000 (0.045) loss 2.2051 (2.2744) lr 5.6267e-02 eta 0:05:21
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.19s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 556
* accuracy: 68.5%
* error: 31.5%
* macro_f1: 67.0%

epoch [24/50] batch [2/24] time 0.603 (1.303) data 0.000 (0.607) loss 2.1191 (2.2080) lr 5.6267e-02 eta 0:14:01
epoch [24/50] batch [4/24] time 0.428 (0.867) data 0.000 (0.304) loss 2.2695 (2.1895) lr 5.6267e-02 eta 0:09:18
epoch [24/50] batch [6/24] time 0.428 (0.721) data 0.000 (0.203) loss 2.2402 (2.1953) lr 5.6267e-02 eta 0:07:42
epoch [24/50] batch [8/24] time 0.429 (0.647) data 0.000 (0.152) loss 2.3730 (2.2048) lr 5.6267e-02 eta 0:06:54
epoch [24/50] batch [10/24] time 0.427 (0.603) data 0.000 (0.122) loss 2.1855 (2.2033) lr 5.6267e-02 eta 0:06:24
epoch [24/50] batch [12/24] time 0.427 (0.574) data 0.000 (0.101) loss 2.2207 (2.2017) lr 5.6267e-02 eta 0:06:05
epoch [24/50] batch [14/24] time 0.433 (0.554) data 0.000 (0.087) loss 2.3965 (2.2171) lr 5.6267e-02 eta 0:05:51
epoch [24/50] batch [16/24] time 0.435 (0.538) data 0.000 (0.076) loss 2.0117 (2.2252) lr 5.6267e-02 eta 0:05:40
epoch [24/50] batch [18/24] time 0.427 (0.526) data 0.000 (0.068) loss 2.3340 (2.2241) lr 5.6267e-02 eta 0:05:31
epoch [24/50] batch [20/24] time 0.432 (0.517) data 0.000 (0.061) loss 2.1934 (2.2346) lr 5.6267e-02 eta 0:05:24
epoch [24/50] batch [22/24] time 0.427 (0.508) data 0.000 (0.055) loss 2.2129 (2.2425) lr 5.6267e-02 eta 0:05:18
epoch [24/50] batch [24/24] time 0.427 (0.502) data 0.000 (0.051) loss 2.3086 (2.2400) lr 5.3140e-02 eta 0:05:13
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 563
* accuracy: 69.3%
* error: 30.7%
* macro_f1: 68.1%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [25/50] batch [2/24] time 0.526 (1.365) data 0.000 (0.710) loss 2.2969 (2.2715) lr 5.3140e-02 eta 0:14:09
epoch [25/50] batch [4/24] time 0.427 (0.899) data 0.000 (0.355) loss 2.2402 (2.2339) lr 5.3140e-02 eta 0:09:17
epoch [25/50] batch [6/24] time 0.427 (0.742) data 0.000 (0.237) loss 2.2734 (2.2435) lr 5.3140e-02 eta 0:07:38
epoch [25/50] batch [8/24] time 0.432 (0.664) data 0.000 (0.178) loss 2.3008 (2.2844) lr 5.3140e-02 eta 0:06:48
epoch [25/50] batch [10/24] time 0.444 (0.618) data 0.000 (0.142) loss 2.3066 (2.2795) lr 5.3140e-02 eta 0:06:19
epoch [25/50] batch [12/24] time 0.430 (0.587) data 0.000 (0.119) loss 2.3066 (2.2869) lr 5.3140e-02 eta 0:05:58
epoch [25/50] batch [14/24] time 0.435 (0.564) data 0.000 (0.102) loss 2.1875 (2.2730) lr 5.3140e-02 eta 0:05:44
epoch [25/50] batch [16/24] time 0.427 (0.547) data 0.000 (0.089) loss 2.3965 (2.2800) lr 5.3140e-02 eta 0:05:32
epoch [25/50] batch [18/24] time 0.428 (0.534) data 0.000 (0.079) loss 2.1328 (2.2771) lr 5.3140e-02 eta 0:05:23
epoch [25/50] batch [20/24] time 0.428 (0.523) data 0.000 (0.071) loss 2.1680 (2.2757) lr 5.3140e-02 eta 0:05:16
epoch [25/50] batch [22/24] time 0.429 (0.515) data 0.000 (0.065) loss 2.6328 (2.2849) lr 5.3140e-02 eta 0:05:09
epoch [25/50] batch [24/24] time 0.427 (0.508) data 0.000 (0.059) loss 2.2344 (2.2848) lr 5.0000e-02 eta 0:05:04
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 561
* accuracy: 69.1%
* error: 30.9%
* macro_f1: 67.5%

epoch [26/50] batch [2/24] time 0.657 (1.245) data 0.000 (0.551) loss 2.2090 (2.2158) lr 5.0000e-02 eta 0:12:24
epoch [26/50] batch [4/24] time 0.428 (0.844) data 0.000 (0.275) loss 2.3496 (2.2583) lr 5.0000e-02 eta 0:08:23
epoch [26/50] batch [6/24] time 0.428 (0.706) data 0.000 (0.184) loss 2.4707 (2.2744) lr 5.0000e-02 eta 0:06:59
epoch [26/50] batch [8/24] time 0.427 (0.636) data 0.000 (0.138) loss 2.3262 (2.2678) lr 5.0000e-02 eta 0:06:16
epoch [26/50] batch [10/24] time 0.428 (0.595) data 0.000 (0.110) loss 2.0566 (2.2496) lr 5.0000e-02 eta 0:05:50
epoch [26/50] batch [12/24] time 0.433 (0.568) data 0.000 (0.092) loss 2.1621 (2.2594) lr 5.0000e-02 eta 0:05:33
epoch [26/50] batch [14/24] time 0.427 (0.548) data 0.000 (0.079) loss 2.0879 (2.2446) lr 5.0000e-02 eta 0:05:20
epoch [26/50] batch [16/24] time 0.426 (0.533) data 0.000 (0.069) loss 2.3672 (2.2439) lr 5.0000e-02 eta 0:05:11
epoch [26/50] batch [18/24] time 0.427 (0.521) data 0.000 (0.061) loss 2.1582 (2.2410) lr 5.0000e-02 eta 0:05:03
epoch [26/50] batch [20/24] time 0.428 (0.512) data 0.000 (0.055) loss 2.2520 (2.2467) lr 5.0000e-02 eta 0:04:56
epoch [26/50] batch [22/24] time 0.428 (0.504) data 0.000 (0.050) loss 2.2754 (2.2493) lr 5.0000e-02 eta 0:04:51
epoch [26/50] batch [24/24] time 0.427 (0.498) data 0.000 (0.046) loss 2.3945 (2.2586) lr 4.6860e-02 eta 0:04:46
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.19it/s]=> result
* total: 812
* correct: 567
* accuracy: 69.8%
* error: 30.2%
* macro_f1: 68.4%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [27/50] batch [2/24] time 0.555 (1.318) data 0.000 (0.651) loss 2.2988 (2.2275) lr 4.6860e-02 eta 0:12:36
epoch [27/50] batch [4/24] time 0.427 (0.872) data 0.000 (0.326) loss 2.3340 (2.2358) lr 4.6860e-02 eta 0:08:18
epoch [27/50] batch [6/24] time 0.426 (0.737) data 0.000 (0.217) loss 2.3613 (2.2620) lr 4.6860e-02 eta 0:07:00
epoch [27/50] batch [8/24] time 0.426 (0.660) data 0.000 (0.163) loss 2.1934 (2.2539) lr 4.6860e-02 eta 0:06:14
epoch [27/50] batch [10/24] time 0.429 (0.614) data 0.000 (0.130) loss 2.2324 (2.2461) lr 4.6860e-02 eta 0:05:47
epoch [27/50] batch [12/24] time 0.426 (0.582) data 0.000 (0.109) loss 2.3125 (2.2427) lr 4.6860e-02 eta 0:05:28
epoch [27/50] batch [14/24] time 0.426 (0.560) data 0.000 (0.093) loss 2.2070 (2.2404) lr 4.6860e-02 eta 0:05:14
epoch [27/50] batch [16/24] time 0.426 (0.544) data 0.000 (0.082) loss 2.1895 (2.2292) lr 4.6860e-02 eta 0:05:04
epoch [27/50] batch [18/24] time 0.425 (0.531) data 0.000 (0.072) loss 2.0957 (2.2180) lr 4.6860e-02 eta 0:04:56
epoch [27/50] batch [20/24] time 0.425 (0.520) data 0.000 (0.065) loss 2.0703 (2.2171) lr 4.6860e-02 eta 0:04:49
epoch [27/50] batch [22/24] time 0.426 (0.512) data 0.000 (0.059) loss 2.3457 (2.2234) lr 4.6860e-02 eta 0:04:43
epoch [27/50] batch [24/24] time 0.425 (0.504) data 0.000 (0.054) loss 2.2109 (2.2267) lr 4.3733e-02 eta 0:04:38
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 570
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 68.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [28/50] batch [2/24] time 0.497 (1.333) data 0.000 (0.700) loss 2.1250 (2.2012) lr 4.3733e-02 eta 0:12:13
epoch [28/50] batch [4/24] time 0.426 (0.880) data 0.000 (0.350) loss 2.1426 (2.2290) lr 4.3733e-02 eta 0:08:02
epoch [28/50] batch [6/24] time 0.425 (0.729) data 0.000 (0.234) loss 2.2578 (2.2591) lr 4.3733e-02 eta 0:06:37
epoch [28/50] batch [8/24] time 0.447 (0.656) data 0.000 (0.175) loss 2.3262 (2.2747) lr 4.3733e-02 eta 0:05:56
epoch [28/50] batch [10/24] time 0.426 (0.610) data 0.000 (0.140) loss 2.2988 (2.2539) lr 4.3733e-02 eta 0:05:30
epoch [28/50] batch [12/24] time 0.425 (0.579) data 0.000 (0.117) loss 2.3574 (2.2563) lr 4.3733e-02 eta 0:05:12
epoch [28/50] batch [14/24] time 0.425 (0.557) data 0.000 (0.100) loss 2.1152 (2.2461) lr 4.3733e-02 eta 0:04:59
epoch [28/50] batch [16/24] time 0.429 (0.541) data 0.000 (0.088) loss 2.2773 (2.2477) lr 4.3733e-02 eta 0:04:49
epoch [28/50] batch [18/24] time 0.429 (0.529) data 0.000 (0.078) loss 2.3848 (2.2420) lr 4.3733e-02 eta 0:04:42
epoch [28/50] batch [20/24] time 0.426 (0.518) data 0.000 (0.070) loss 2.3359 (2.2474) lr 4.3733e-02 eta 0:04:35
epoch [28/50] batch [22/24] time 0.430 (0.510) data 0.000 (0.064) loss 2.3457 (2.2432) lr 4.3733e-02 eta 0:04:30
epoch [28/50] batch [24/24] time 0.425 (0.503) data 0.000 (0.059) loss 2.2168 (2.2458) lr 4.0631e-02 eta 0:04:25
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.50s/it] 60%|██████    | 3/5 [00:03<00:01,  1.07it/s] 80%|████████  | 4/5 [00:04<00:00,  1.50it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 564
* accuracy: 69.5%
* error: 30.5%
* macro_f1: 68.2%

epoch [29/50] batch [2/24] time 0.530 (1.385) data 0.000 (0.760) loss 2.1523 (2.1826) lr 4.0631e-02 eta 0:12:08
epoch [29/50] batch [4/24] time 0.430 (0.910) data 0.000 (0.380) loss 2.3809 (2.2114) lr 4.0631e-02 eta 0:07:56
epoch [29/50] batch [6/24] time 0.427 (0.749) data 0.000 (0.254) loss 2.2031 (2.2194) lr 4.0631e-02 eta 0:06:30
epoch [29/50] batch [8/24] time 0.427 (0.668) data 0.000 (0.190) loss 2.0977 (2.2178) lr 4.0631e-02 eta 0:05:47
epoch [29/50] batch [10/24] time 0.426 (0.620) data 0.000 (0.152) loss 2.1504 (2.2145) lr 4.0631e-02 eta 0:05:21
epoch [29/50] batch [12/24] time 0.426 (0.588) data 0.000 (0.127) loss 2.1016 (2.2091) lr 4.0631e-02 eta 0:05:03
epoch [29/50] batch [14/24] time 0.430 (0.565) data 0.000 (0.109) loss 2.1094 (2.2012) lr 4.0631e-02 eta 0:04:50
epoch [29/50] batch [16/24] time 0.428 (0.548) data 0.000 (0.095) loss 2.3809 (2.2064) lr 4.0631e-02 eta 0:04:40
epoch [29/50] batch [18/24] time 0.424 (0.534) data 0.000 (0.085) loss 2.2012 (2.2078) lr 4.0631e-02 eta 0:04:32
epoch [29/50] batch [20/24] time 0.425 (0.523) data 0.000 (0.076) loss 2.2988 (2.2125) lr 4.0631e-02 eta 0:04:25
epoch [29/50] batch [22/24] time 0.426 (0.514) data 0.000 (0.069) loss 2.2227 (2.2108) lr 4.0631e-02 eta 0:04:20
epoch [29/50] batch [24/24] time 0.428 (0.507) data 0.000 (0.064) loss 2.3184 (2.2221) lr 3.7566e-02 eta 0:04:15
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 563
* accuracy: 69.3%
* error: 30.7%
* macro_f1: 67.9%

epoch [30/50] batch [2/24] time 0.501 (1.417) data 0.000 (0.779) loss 2.2188 (2.2129) lr 3.7566e-02 eta 0:11:51
epoch [30/50] batch [4/24] time 0.435 (0.933) data 0.000 (0.390) loss 2.2422 (2.2490) lr 3.7566e-02 eta 0:07:46
epoch [30/50] batch [6/24] time 0.428 (0.764) data 0.000 (0.260) loss 2.3281 (2.2396) lr 3.7566e-02 eta 0:06:20
epoch [30/50] batch [8/24] time 0.430 (0.680) data 0.000 (0.195) loss 2.4766 (2.2878) lr 3.7566e-02 eta 0:05:37
epoch [30/50] batch [10/24] time 0.428 (0.630) data 0.000 (0.156) loss 2.2363 (2.2781) lr 3.7566e-02 eta 0:05:11
epoch [30/50] batch [12/24] time 0.427 (0.597) data 0.000 (0.130) loss 2.1504 (2.2749) lr 3.7566e-02 eta 0:04:53
epoch [30/50] batch [14/24] time 0.430 (0.574) data 0.000 (0.112) loss 2.2754 (2.2599) lr 3.7566e-02 eta 0:04:41
epoch [30/50] batch [16/24] time 0.430 (0.556) data 0.000 (0.098) loss 2.1270 (2.2631) lr 3.7566e-02 eta 0:04:31
epoch [30/50] batch [18/24] time 0.431 (0.542) data 0.000 (0.087) loss 2.2539 (2.2592) lr 3.7566e-02 eta 0:04:23
epoch [30/50] batch [20/24] time 0.427 (0.531) data 0.000 (0.078) loss 2.1602 (2.2606) lr 3.7566e-02 eta 0:04:16
epoch [30/50] batch [22/24] time 0.427 (0.521) data 0.000 (0.071) loss 2.3789 (2.2642) lr 3.7566e-02 eta 0:04:11
epoch [30/50] batch [24/24] time 0.429 (0.513) data 0.000 (0.065) loss 2.0469 (2.2550) lr 3.4549e-02 eta 0:04:06
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.10s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 573
* accuracy: 70.6%
* error: 29.4%
* macro_f1: 68.6%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model.pth.tar-30

epoch [31/50] batch [2/24] time 0.585 (1.304) data 0.001 (0.610) loss 2.2266 (2.1855) lr 3.4549e-02 eta 0:10:23
epoch [31/50] batch [4/24] time 0.428 (0.868) data 0.000 (0.305) loss 2.2441 (2.2251) lr 3.4549e-02 eta 0:06:53
epoch [31/50] batch [6/24] time 0.428 (0.722) data 0.000 (0.204) loss 2.3477 (2.2624) lr 3.4549e-02 eta 0:05:42
epoch [31/50] batch [8/24] time 0.428 (0.648) data 0.000 (0.153) loss 2.1094 (2.2471) lr 3.4549e-02 eta 0:05:06
epoch [31/50] batch [10/24] time 0.428 (0.604) data 0.000 (0.122) loss 2.3867 (2.2502) lr 3.4549e-02 eta 0:04:44
epoch [31/50] batch [12/24] time 0.433 (0.576) data 0.000 (0.102) loss 2.3555 (2.2445) lr 3.4549e-02 eta 0:04:29
epoch [31/50] batch [14/24] time 0.431 (0.555) data 0.000 (0.087) loss 2.2734 (2.2458) lr 3.4549e-02 eta 0:04:18
epoch [31/50] batch [16/24] time 0.430 (0.539) data 0.000 (0.076) loss 2.3359 (2.2510) lr 3.4549e-02 eta 0:04:10
epoch [31/50] batch [18/24] time 0.428 (0.527) data 0.000 (0.068) loss 2.0781 (2.2373) lr 3.4549e-02 eta 0:04:03
epoch [31/50] batch [20/24] time 0.426 (0.517) data 0.000 (0.061) loss 2.2695 (2.2376) lr 3.4549e-02 eta 0:03:57
epoch [31/50] batch [22/24] time 0.432 (0.509) data 0.000 (0.056) loss 2.1797 (2.2419) lr 3.4549e-02 eta 0:03:53
epoch [31/50] batch [24/24] time 0.428 (0.502) data 0.000 (0.051) loss 2.1250 (2.2381) lr 3.1594e-02 eta 0:03:49
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 566
* accuracy: 69.7%
* error: 30.3%
* macro_f1: 68.2%

epoch [32/50] batch [2/24] time 0.595 (1.288) data 0.000 (0.614) loss 2.1602 (2.2197) lr 3.1594e-02 eta 0:09:44
epoch [32/50] batch [4/24] time 0.427 (0.861) data 0.000 (0.307) loss 2.1621 (2.2329) lr 3.1594e-02 eta 0:06:29
epoch [32/50] batch [6/24] time 0.427 (0.716) data 0.000 (0.205) loss 2.3223 (2.2575) lr 3.1594e-02 eta 0:05:22
epoch [32/50] batch [8/24] time 0.433 (0.645) data 0.000 (0.154) loss 2.2578 (2.2351) lr 3.1594e-02 eta 0:04:48
epoch [32/50] batch [10/24] time 0.426 (0.601) data 0.000 (0.123) loss 2.3066 (2.2367) lr 3.1594e-02 eta 0:04:28
epoch [32/50] batch [12/24] time 0.428 (0.572) data 0.000 (0.102) loss 2.2070 (2.2318) lr 3.1594e-02 eta 0:04:14
epoch [32/50] batch [14/24] time 0.433 (0.552) data 0.000 (0.088) loss 1.9336 (2.2302) lr 3.1594e-02 eta 0:04:04
epoch [32/50] batch [16/24] time 0.427 (0.537) data 0.000 (0.077) loss 2.1523 (2.2297) lr 3.1594e-02 eta 0:03:56
epoch [32/50] batch [18/24] time 0.429 (0.525) data 0.000 (0.068) loss 2.1582 (2.2265) lr 3.1594e-02 eta 0:03:49
epoch [32/50] batch [20/24] time 0.428 (0.515) data 0.000 (0.062) loss 2.1523 (2.2149) lr 3.1594e-02 eta 0:03:44
epoch [32/50] batch [22/24] time 0.428 (0.507) data 0.000 (0.056) loss 2.2207 (2.2256) lr 3.1594e-02 eta 0:03:40
epoch [32/50] batch [24/24] time 0.433 (0.501) data 0.000 (0.051) loss 2.1699 (2.2269) lr 2.8711e-02 eta 0:03:36
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 565
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 68.1%

epoch [33/50] batch [2/24] time 0.605 (1.266) data 0.000 (0.587) loss 2.1855 (2.3145) lr 2.8711e-02 eta 0:09:04
epoch [33/50] batch [4/24] time 0.441 (0.867) data 0.000 (0.294) loss 2.4707 (2.3271) lr 2.8711e-02 eta 0:06:11
epoch [33/50] batch [6/24] time 0.428 (0.721) data 0.000 (0.196) loss 2.2949 (2.2712) lr 2.8711e-02 eta 0:05:07
epoch [33/50] batch [8/24] time 0.428 (0.648) data 0.000 (0.147) loss 2.3457 (2.2939) lr 2.8711e-02 eta 0:04:34
epoch [33/50] batch [10/24] time 0.428 (0.604) data 0.000 (0.118) loss 2.1836 (2.3008) lr 2.8711e-02 eta 0:04:15
epoch [33/50] batch [12/24] time 0.516 (0.583) data 0.000 (0.098) loss 2.1602 (2.2847) lr 2.8711e-02 eta 0:04:04
epoch [33/50] batch [14/24] time 0.429 (0.561) data 0.000 (0.084) loss 2.4805 (2.2906) lr 2.8711e-02 eta 0:03:54
epoch [33/50] batch [16/24] time 0.427 (0.544) data 0.000 (0.074) loss 2.1270 (2.2758) lr 2.8711e-02 eta 0:03:46
epoch [33/50] batch [18/24] time 0.428 (0.531) data 0.000 (0.065) loss 2.0684 (2.2526) lr 2.8711e-02 eta 0:03:39
epoch [33/50] batch [20/24] time 0.428 (0.521) data 0.000 (0.059) loss 2.2383 (2.2477) lr 2.8711e-02 eta 0:03:34
epoch [33/50] batch [22/24] time 0.427 (0.513) data 0.000 (0.054) loss 2.2031 (2.2497) lr 2.8711e-02 eta 0:03:30
epoch [33/50] batch [24/24] time 0.427 (0.506) data 0.000 (0.049) loss 2.3516 (2.2583) lr 2.5912e-02 eta 0:03:26
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.45s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 568
* accuracy: 70.0%
* error: 30.0%
* macro_f1: 68.4%

epoch [34/50] batch [2/24] time 0.531 (1.366) data 0.000 (0.777) loss 2.3184 (2.3271) lr 2.5912e-02 eta 0:09:14
epoch [34/50] batch [4/24] time 0.427 (0.900) data 0.000 (0.388) loss 2.4492 (2.3232) lr 2.5912e-02 eta 0:06:03
epoch [34/50] batch [6/24] time 0.428 (0.743) data 0.000 (0.259) loss 2.1934 (2.2887) lr 2.5912e-02 eta 0:04:58
epoch [34/50] batch [8/24] time 0.431 (0.665) data 0.000 (0.194) loss 2.1699 (2.2585) lr 2.5912e-02 eta 0:04:25
epoch [34/50] batch [10/24] time 0.428 (0.617) data 0.000 (0.155) loss 2.2734 (2.2514) lr 2.5912e-02 eta 0:04:05
epoch [34/50] batch [12/24] time 0.428 (0.586) data 0.000 (0.130) loss 2.3691 (2.2557) lr 2.5912e-02 eta 0:03:51
epoch [34/50] batch [14/24] time 0.429 (0.563) data 0.000 (0.111) loss 2.1680 (2.2506) lr 2.5912e-02 eta 0:03:41
epoch [34/50] batch [16/24] time 0.427 (0.546) data 0.000 (0.097) loss 2.3242 (2.2548) lr 2.5912e-02 eta 0:03:34
epoch [34/50] batch [18/24] time 0.427 (0.533) data 0.000 (0.086) loss 2.1914 (2.2537) lr 2.5912e-02 eta 0:03:27
epoch [34/50] batch [20/24] time 0.428 (0.523) data 0.000 (0.078) loss 2.1836 (2.2474) lr 2.5912e-02 eta 0:03:22
epoch [34/50] batch [22/24] time 0.427 (0.514) data 0.000 (0.071) loss 2.3379 (2.2431) lr 2.5912e-02 eta 0:03:18
epoch [34/50] batch [24/24] time 0.427 (0.507) data 0.000 (0.065) loss 2.1680 (2.2382) lr 2.3209e-02 eta 0:03:14
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.52s/it] 60%|██████    | 3/5 [00:03<00:01,  1.05it/s] 80%|████████  | 4/5 [00:04<00:00,  1.47it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 565
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 68.2%

epoch [35/50] batch [2/24] time 0.482 (1.346) data 0.000 (0.741) loss 2.2637 (2.2676) lr 2.3209e-02 eta 0:08:34
epoch [35/50] batch [4/24] time 0.426 (0.887) data 0.000 (0.371) loss 2.3672 (2.2798) lr 2.3209e-02 eta 0:05:37
epoch [35/50] batch [6/24] time 0.429 (0.734) data 0.000 (0.247) loss 2.1543 (2.2217) lr 2.3209e-02 eta 0:04:37
epoch [35/50] batch [8/24] time 0.429 (0.658) data 0.000 (0.185) loss 2.3262 (2.2161) lr 2.3209e-02 eta 0:04:07
epoch [35/50] batch [10/24] time 0.433 (0.612) data 0.000 (0.148) loss 2.2168 (2.2295) lr 2.3209e-02 eta 0:03:48
epoch [35/50] batch [12/24] time 0.427 (0.581) data 0.000 (0.124) loss 2.1582 (2.2288) lr 2.3209e-02 eta 0:03:36
epoch [35/50] batch [14/24] time 0.429 (0.559) data 0.000 (0.106) loss 2.1211 (2.2137) lr 2.3209e-02 eta 0:03:26
epoch [35/50] batch [16/24] time 0.425 (0.542) data 0.000 (0.093) loss 2.1895 (2.2256) lr 2.3209e-02 eta 0:03:19
epoch [35/50] batch [18/24] time 0.425 (0.529) data 0.000 (0.083) loss 2.2090 (2.2127) lr 2.3209e-02 eta 0:03:13
epoch [35/50] batch [20/24] time 0.425 (0.519) data 0.000 (0.074) loss 2.1855 (2.2131) lr 2.3209e-02 eta 0:03:09
epoch [35/50] batch [22/24] time 0.425 (0.511) data 0.000 (0.068) loss 2.3809 (2.2228) lr 2.3209e-02 eta 0:03:04
epoch [35/50] batch [24/24] time 0.427 (0.504) data 0.000 (0.062) loss 2.1250 (2.2198) lr 2.0611e-02 eta 0:03:01
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.21s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:04<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 565
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 67.9%

epoch [36/50] batch [2/24] time 0.686 (1.235) data 0.000 (0.480) loss 2.1133 (2.1846) lr 2.0611e-02 eta 0:07:22
epoch [36/50] batch [4/24] time 0.425 (0.834) data 0.000 (0.240) loss 2.2539 (2.2246) lr 2.0611e-02 eta 0:04:56
epoch [36/50] batch [6/24] time 0.432 (0.699) data 0.000 (0.160) loss 2.0566 (2.1930) lr 2.0611e-02 eta 0:04:07
epoch [36/50] batch [8/24] time 0.426 (0.631) data 0.000 (0.120) loss 2.2520 (2.1841) lr 2.0611e-02 eta 0:03:42
epoch [36/50] batch [10/24] time 0.426 (0.590) data 0.001 (0.096) loss 2.3164 (2.1842) lr 2.0611e-02 eta 0:03:26
epoch [36/50] batch [12/24] time 0.427 (0.563) data 0.000 (0.080) loss 2.3008 (2.2135) lr 2.0611e-02 eta 0:03:15
epoch [36/50] batch [14/24] time 0.425 (0.543) data 0.000 (0.069) loss 2.2578 (2.2091) lr 2.0611e-02 eta 0:03:07
epoch [36/50] batch [16/24] time 0.425 (0.528) data 0.000 (0.060) loss 2.1992 (2.2043) lr 2.0611e-02 eta 0:03:01
epoch [36/50] batch [18/24] time 0.434 (0.517) data 0.000 (0.053) loss 2.2891 (2.2088) lr 2.0611e-02 eta 0:02:56
epoch [36/50] batch [20/24] time 0.426 (0.508) data 0.000 (0.048) loss 2.5039 (2.2342) lr 2.0611e-02 eta 0:02:52
epoch [36/50] batch [22/24] time 0.425 (0.501) data 0.000 (0.044) loss 2.2129 (2.2317) lr 2.0611e-02 eta 0:02:49
epoch [36/50] batch [24/24] time 0.425 (0.495) data 0.000 (0.040) loss 2.2598 (2.2367) lr 1.8129e-02 eta 0:02:46
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.22it/s]=> result
* total: 812
* correct: 570
* accuracy: 70.2%
* error: 29.8%
* macro_f1: 68.6%

epoch [37/50] batch [2/24] time 0.620 (1.280) data 0.000 (0.591) loss 2.4922 (2.3223) lr 1.8129e-02 eta 0:07:07
epoch [37/50] batch [4/24] time 0.428 (0.854) data 0.000 (0.296) loss 2.0977 (2.2954) lr 1.8129e-02 eta 0:04:43
epoch [37/50] batch [6/24] time 0.431 (0.713) data 0.000 (0.197) loss 2.0723 (2.2373) lr 1.8129e-02 eta 0:03:55
epoch [37/50] batch [8/24] time 0.428 (0.642) data 0.000 (0.148) loss 2.1621 (2.2148) lr 1.8129e-02 eta 0:03:30
epoch [37/50] batch [10/24] time 0.431 (0.600) data 0.000 (0.118) loss 2.2949 (2.2600) lr 1.8129e-02 eta 0:03:15
epoch [37/50] batch [12/24] time 0.433 (0.572) data 0.000 (0.099) loss 2.4316 (2.2643) lr 1.8129e-02 eta 0:03:05
epoch [37/50] batch [14/24] time 0.432 (0.552) data 0.000 (0.085) loss 2.4082 (2.2702) lr 1.8129e-02 eta 0:02:57
epoch [37/50] batch [16/24] time 0.430 (0.537) data 0.000 (0.074) loss 2.1699 (2.2594) lr 1.8129e-02 eta 0:02:51
epoch [37/50] batch [18/24] time 0.433 (0.525) data 0.000 (0.066) loss 2.1582 (2.2593) lr 1.8129e-02 eta 0:02:46
epoch [37/50] batch [20/24] time 0.431 (0.515) data 0.000 (0.059) loss 2.3320 (2.2585) lr 1.8129e-02 eta 0:02:42
epoch [37/50] batch [22/24] time 0.427 (0.507) data 0.000 (0.054) loss 2.1484 (2.2618) lr 1.8129e-02 eta 0:02:39
epoch [37/50] batch [24/24] time 0.427 (0.501) data 0.000 (0.049) loss 2.3320 (2.2630) lr 1.5773e-02 eta 0:02:36
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 577
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 70.0%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [38/50] batch [2/24] time 0.540 (1.307) data 0.000 (0.648) loss 2.1523 (2.2490) lr 1.5773e-02 eta 0:06:45
epoch [38/50] batch [4/24] time 0.425 (0.870) data 0.000 (0.324) loss 2.1973 (2.1899) lr 1.5773e-02 eta 0:04:28
epoch [38/50] batch [6/24] time 0.424 (0.722) data 0.000 (0.216) loss 2.2832 (2.2129) lr 1.5773e-02 eta 0:03:40
epoch [38/50] batch [8/24] time 0.428 (0.648) data 0.000 (0.162) loss 2.1445 (2.2046) lr 1.5773e-02 eta 0:03:17
epoch [38/50] batch [10/24] time 0.427 (0.604) data 0.000 (0.130) loss 2.1582 (2.1904) lr 1.5773e-02 eta 0:03:02
epoch [38/50] batch [12/24] time 0.512 (0.582) data 0.000 (0.108) loss 2.2891 (2.2274) lr 1.5773e-02 eta 0:02:54
epoch [38/50] batch [14/24] time 0.425 (0.560) data 0.000 (0.093) loss 2.3613 (2.2284) lr 1.5773e-02 eta 0:02:46
epoch [38/50] batch [16/24] time 0.428 (0.543) data 0.000 (0.081) loss 2.2305 (2.2294) lr 1.5773e-02 eta 0:02:40
epoch [38/50] batch [18/24] time 0.429 (0.530) data 0.000 (0.072) loss 2.3086 (2.2273) lr 1.5773e-02 eta 0:02:35
epoch [38/50] batch [20/24] time 0.424 (0.520) data 0.000 (0.065) loss 2.1445 (2.2354) lr 1.5773e-02 eta 0:02:31
epoch [38/50] batch [22/24] time 0.426 (0.511) data 0.000 (0.059) loss 2.2500 (2.2348) lr 1.5773e-02 eta 0:02:28
epoch [38/50] batch [24/24] time 0.429 (0.504) data 0.000 (0.054) loss 2.1230 (2.2281) lr 1.3552e-02 eta 0:02:25
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.15s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 565
* accuracy: 69.6%
* error: 30.4%
* macro_f1: 68.2%

epoch [39/50] batch [2/24] time 0.540 (1.307) data 0.000 (0.652) loss 2.1934 (2.2012) lr 1.3552e-02 eta 0:06:13
epoch [39/50] batch [4/24] time 0.425 (0.869) data 0.000 (0.326) loss 2.2109 (2.2041) lr 1.3552e-02 eta 0:04:06
epoch [39/50] batch [6/24] time 0.425 (0.721) data 0.000 (0.218) loss 2.0840 (2.1709) lr 1.3552e-02 eta 0:03:23
epoch [39/50] batch [8/24] time 0.425 (0.648) data 0.000 (0.163) loss 2.2539 (2.1809) lr 1.3552e-02 eta 0:03:01
epoch [39/50] batch [10/24] time 0.425 (0.603) data 0.000 (0.131) loss 2.2715 (2.1996) lr 1.3552e-02 eta 0:02:47
epoch [39/50] batch [12/24] time 0.427 (0.574) data 0.000 (0.109) loss 2.2070 (2.2030) lr 1.3552e-02 eta 0:02:38
epoch [39/50] batch [14/24] time 0.425 (0.552) data 0.000 (0.093) loss 2.2344 (2.2072) lr 1.3552e-02 eta 0:02:31
epoch [39/50] batch [16/24] time 0.429 (0.537) data 0.000 (0.082) loss 2.3223 (2.2162) lr 1.3552e-02 eta 0:02:26
epoch [39/50] batch [18/24] time 0.425 (0.525) data 0.000 (0.073) loss 2.2715 (2.2141) lr 1.3552e-02 eta 0:02:21
epoch [39/50] batch [20/24] time 0.425 (0.515) data 0.000 (0.065) loss 2.1777 (2.2200) lr 1.3552e-02 eta 0:02:17
epoch [39/50] batch [22/24] time 0.429 (0.507) data 0.000 (0.059) loss 2.0254 (2.2195) lr 1.3552e-02 eta 0:02:14
epoch [39/50] batch [24/24] time 0.425 (0.500) data 0.000 (0.055) loss 2.1797 (2.2271) lr 1.1474e-02 eta 0:02:12
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.13s/it] 40%|████      | 2/5 [00:03<00:04,  1.51s/it] 60%|██████    | 3/5 [00:03<00:01,  1.05it/s] 80%|████████  | 4/5 [00:04<00:00,  1.47it/s]100%|██████████| 5/5 [00:04<00:00,  1.18it/s]=> result
* total: 812
* correct: 568
* accuracy: 70.0%
* error: 30.0%
* macro_f1: 68.6%

epoch [40/50] batch [2/24] time 0.467 (1.351) data 0.000 (0.742) loss 2.1582 (2.2812) lr 1.1474e-02 eta 0:05:53
epoch [40/50] batch [4/24] time 0.426 (0.889) data 0.000 (0.371) loss 2.1914 (2.2549) lr 1.1474e-02 eta 0:03:51
epoch [40/50] batch [6/24] time 0.426 (0.735) data 0.000 (0.247) loss 2.1992 (2.2575) lr 1.1474e-02 eta 0:03:09
epoch [40/50] batch [8/24] time 0.426 (0.658) data 0.000 (0.186) loss 1.9941 (2.2185) lr 1.1474e-02 eta 0:02:48
epoch [40/50] batch [10/24] time 0.431 (0.612) data 0.000 (0.148) loss 2.5020 (2.2350) lr 1.1474e-02 eta 0:02:35
epoch [40/50] batch [12/24] time 0.428 (0.581) data 0.000 (0.124) loss 2.2168 (2.2568) lr 1.1474e-02 eta 0:02:26
epoch [40/50] batch [14/24] time 0.429 (0.560) data 0.000 (0.106) loss 2.3008 (2.2591) lr 1.1474e-02 eta 0:02:19
epoch [40/50] batch [16/24] time 0.427 (0.543) data 0.000 (0.093) loss 2.1523 (2.2538) lr 1.1474e-02 eta 0:02:14
epoch [40/50] batch [18/24] time 0.429 (0.530) data 0.000 (0.083) loss 2.1641 (2.2525) lr 1.1474e-02 eta 0:02:10
epoch [40/50] batch [20/24] time 0.429 (0.520) data 0.000 (0.074) loss 2.2695 (2.2498) lr 1.1474e-02 eta 0:02:06
epoch [40/50] batch [22/24] time 0.434 (0.512) data 0.000 (0.068) loss 2.2539 (2.2536) lr 1.1474e-02 eta 0:02:03
epoch [40/50] batch [24/24] time 0.442 (0.506) data 0.000 (0.062) loss 2.2832 (2.2544) lr 9.5492e-03 eta 0:02:01
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 569
* accuracy: 70.1%
* error: 29.9%
* macro_f1: 68.8%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model.pth.tar-40

epoch [41/50] batch [2/24] time 0.587 (1.286) data 0.000 (0.596) loss 2.1934 (2.3271) lr 9.5492e-03 eta 0:05:06
epoch [41/50] batch [4/24] time 0.427 (0.862) data 0.000 (0.298) loss 2.1738 (2.3140) lr 9.5492e-03 eta 0:03:23
epoch [41/50] batch [6/24] time 0.428 (0.717) data 0.000 (0.199) loss 2.2734 (2.2747) lr 9.5492e-03 eta 0:02:47
epoch [41/50] batch [8/24] time 0.427 (0.645) data 0.000 (0.149) loss 2.1191 (2.2341) lr 9.5492e-03 eta 0:02:29
epoch [41/50] batch [10/24] time 0.429 (0.602) data 0.000 (0.119) loss 2.1895 (2.2396) lr 9.5492e-03 eta 0:02:18
epoch [41/50] batch [12/24] time 0.425 (0.573) data 0.000 (0.099) loss 2.0273 (2.2174) lr 9.5492e-03 eta 0:02:10
epoch [41/50] batch [14/24] time 0.427 (0.552) data 0.000 (0.085) loss 2.3105 (2.2194) lr 9.5492e-03 eta 0:02:04
epoch [41/50] batch [16/24] time 0.425 (0.536) data 0.000 (0.075) loss 2.3086 (2.2252) lr 9.5492e-03 eta 0:02:00
epoch [41/50] batch [18/24] time 0.429 (0.524) data 0.000 (0.066) loss 2.2559 (2.2346) lr 9.5492e-03 eta 0:01:56
epoch [41/50] batch [20/24] time 0.432 (0.515) data 0.000 (0.060) loss 2.3652 (2.2456) lr 9.5492e-03 eta 0:01:53
epoch [41/50] batch [22/24] time 0.430 (0.507) data 0.000 (0.054) loss 2.2734 (2.2446) lr 9.5492e-03 eta 0:01:50
epoch [41/50] batch [24/24] time 0.432 (0.500) data 0.000 (0.050) loss 2.3066 (2.2471) lr 7.7836e-03 eta 0:01:48
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 577
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 69.9%

epoch [42/50] batch [2/24] time 0.626 (1.265) data 0.000 (0.574) loss 2.2363 (2.3018) lr 7.7836e-03 eta 0:04:30
epoch [42/50] batch [4/24] time 0.431 (0.848) data 0.000 (0.287) loss 2.3203 (2.2793) lr 7.7836e-03 eta 0:02:59
epoch [42/50] batch [6/24] time 0.427 (0.708) data 0.000 (0.192) loss 2.1387 (2.2223) lr 7.7836e-03 eta 0:02:28
epoch [42/50] batch [8/24] time 0.431 (0.638) data 0.000 (0.144) loss 2.2773 (2.2183) lr 7.7836e-03 eta 0:02:12
epoch [42/50] batch [10/24] time 0.430 (0.596) data 0.000 (0.115) loss 2.3418 (2.2549) lr 7.7836e-03 eta 0:02:02
epoch [42/50] batch [12/24] time 0.426 (0.568) data 0.000 (0.096) loss 2.4434 (2.2720) lr 7.7836e-03 eta 0:01:55
epoch [42/50] batch [14/24] time 0.432 (0.548) data 0.000 (0.082) loss 2.0430 (2.2430) lr 7.7836e-03 eta 0:01:50
epoch [42/50] batch [16/24] time 0.431 (0.533) data 0.000 (0.072) loss 2.1699 (2.2375) lr 7.7836e-03 eta 0:01:46
epoch [42/50] batch [18/24] time 0.431 (0.522) data 0.000 (0.064) loss 2.1328 (2.2388) lr 7.7836e-03 eta 0:01:43
epoch [42/50] batch [20/24] time 0.428 (0.513) data 0.000 (0.058) loss 2.3906 (2.2425) lr 7.7836e-03 eta 0:01:40
epoch [42/50] batch [22/24] time 0.433 (0.505) data 0.000 (0.052) loss 2.0000 (2.2396) lr 7.7836e-03 eta 0:01:38
epoch [42/50] batch [24/24] time 0.435 (0.499) data 0.000 (0.048) loss 2.1738 (2.2406) lr 6.1847e-03 eta 0:01:35
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.10s/it] 40%|████      | 2/5 [00:03<00:04,  1.44s/it] 60%|██████    | 3/5 [00:03<00:01,  1.11it/s] 80%|████████  | 4/5 [00:03<00:00,  1.54it/s]100%|██████████| 5/5 [00:04<00:00,  1.23it/s]=> result
* total: 812
* correct: 574
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 69.4%

epoch [43/50] batch [2/24] time 0.620 (1.277) data 0.001 (0.550) loss 2.2969 (2.2666) lr 6.1847e-03 eta 0:04:02
epoch [43/50] batch [4/24] time 0.430 (0.853) data 0.000 (0.275) loss 2.0430 (2.2354) lr 6.1847e-03 eta 0:02:40
epoch [43/50] batch [6/24] time 0.433 (0.713) data 0.000 (0.183) loss 2.1758 (2.2188) lr 6.1847e-03 eta 0:02:12
epoch [43/50] batch [8/24] time 0.433 (0.643) data 0.000 (0.138) loss 2.2246 (2.2114) lr 6.1847e-03 eta 0:01:58
epoch [43/50] batch [10/24] time 0.435 (0.600) data 0.000 (0.110) loss 2.3184 (2.2328) lr 6.1847e-03 eta 0:01:49
epoch [43/50] batch [12/24] time 0.428 (0.573) data 0.000 (0.092) loss 2.1562 (2.2204) lr 6.1847e-03 eta 0:01:43
epoch [43/50] batch [14/24] time 0.431 (0.552) data 0.000 (0.079) loss 2.1504 (2.2174) lr 6.1847e-03 eta 0:01:38
epoch [43/50] batch [16/24] time 0.428 (0.537) data 0.000 (0.069) loss 2.2520 (2.2206) lr 6.1847e-03 eta 0:01:34
epoch [43/50] batch [18/24] time 0.429 (0.525) data 0.000 (0.061) loss 2.1602 (2.2253) lr 6.1847e-03 eta 0:01:31
epoch [43/50] batch [20/24] time 0.518 (0.519) data 0.000 (0.055) loss 2.2910 (2.2339) lr 6.1847e-03 eta 0:01:29
epoch [43/50] batch [22/24] time 0.432 (0.511) data 0.000 (0.050) loss 2.3223 (2.2417) lr 6.1847e-03 eta 0:01:26
epoch [43/50] batch [24/24] time 0.433 (0.505) data 0.000 (0.046) loss 2.2363 (2.2402) lr 4.7586e-03 eta 0:01:24
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:13,  3.31s/it] 40%|████      | 2/5 [00:03<00:04,  1.52s/it] 60%|██████    | 3/5 [00:03<00:01,  1.06it/s] 80%|████████  | 4/5 [00:04<00:00,  1.48it/s]100%|██████████| 5/5 [00:04<00:00,  1.17it/s]=> result
* total: 812
* correct: 572
* accuracy: 70.4%
* error: 29.6%
* macro_f1: 69.1%

epoch [44/50] batch [2/24] time 0.451 (1.366) data 0.000 (0.768) loss 2.2656 (2.2031) lr 4.7586e-03 eta 0:03:46
epoch [44/50] batch [4/24] time 0.430 (0.898) data 0.000 (0.384) loss 2.0938 (2.1421) lr 4.7586e-03 eta 0:02:27
epoch [44/50] batch [6/24] time 0.427 (0.742) data 0.000 (0.256) loss 2.2402 (2.1536) lr 4.7586e-03 eta 0:02:00
epoch [44/50] batch [8/24] time 0.428 (0.663) data 0.000 (0.192) loss 2.1465 (2.1604) lr 4.7586e-03 eta 0:01:46
epoch [44/50] batch [10/24] time 0.436 (0.617) data 0.000 (0.154) loss 2.3184 (2.1867) lr 4.7586e-03 eta 0:01:37
epoch [44/50] batch [12/24] time 0.425 (0.585) data 0.000 (0.128) loss 2.1562 (2.1826) lr 4.7586e-03 eta 0:01:31
epoch [44/50] batch [14/24] time 0.430 (0.562) data 0.000 (0.110) loss 2.3125 (2.1942) lr 4.7586e-03 eta 0:01:26
epoch [44/50] batch [16/24] time 0.426 (0.546) data 0.000 (0.096) loss 2.3594 (2.2067) lr 4.7586e-03 eta 0:01:22
epoch [44/50] batch [18/24] time 0.426 (0.532) data 0.000 (0.086) loss 2.2012 (2.2053) lr 4.7586e-03 eta 0:01:19
epoch [44/50] batch [20/24] time 0.426 (0.522) data 0.000 (0.077) loss 2.3594 (2.2196) lr 4.7586e-03 eta 0:01:17
epoch [44/50] batch [22/24] time 0.425 (0.513) data 0.000 (0.070) loss 2.0293 (2.2126) lr 4.7586e-03 eta 0:01:14
epoch [44/50] batch [24/24] time 0.430 (0.506) data 0.000 (0.064) loss 2.1602 (2.2186) lr 3.5112e-03 eta 0:01:12
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 579
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 70.3%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar

epoch [45/50] batch [2/24] time 0.450 (1.415) data 0.001 (0.859) loss 2.3203 (2.3184) lr 3.5112e-03 eta 0:03:20
epoch [45/50] batch [4/24] time 0.424 (0.920) data 0.000 (0.430) loss 2.3691 (2.2925) lr 3.5112e-03 eta 0:02:08
epoch [45/50] batch [6/24] time 0.426 (0.756) data 0.000 (0.287) loss 2.0332 (2.2679) lr 3.5112e-03 eta 0:01:44
epoch [45/50] batch [8/24] time 0.427 (0.673) data 0.000 (0.215) loss 2.2852 (2.2568) lr 3.5112e-03 eta 0:01:31
epoch [45/50] batch [10/24] time 0.426 (0.624) data 0.000 (0.172) loss 2.2070 (2.2467) lr 3.5112e-03 eta 0:01:23
epoch [45/50] batch [12/24] time 0.425 (0.590) data 0.000 (0.143) loss 2.2148 (2.2277) lr 3.5112e-03 eta 0:01:17
epoch [45/50] batch [14/24] time 0.426 (0.567) data 0.000 (0.123) loss 2.1875 (2.2281) lr 3.5112e-03 eta 0:01:13
epoch [45/50] batch [16/24] time 0.425 (0.549) data 0.000 (0.108) loss 2.1660 (2.2098) lr 3.5112e-03 eta 0:01:10
epoch [45/50] batch [18/24] time 0.426 (0.536) data 0.000 (0.096) loss 2.1621 (2.2135) lr 3.5112e-03 eta 0:01:07
epoch [45/50] batch [20/24] time 0.433 (0.526) data 0.000 (0.086) loss 2.1621 (2.2030) lr 3.5112e-03 eta 0:01:05
epoch [45/50] batch [22/24] time 0.429 (0.517) data 0.000 (0.078) loss 2.2734 (2.2084) lr 3.5112e-03 eta 0:01:03
epoch [45/50] batch [24/24] time 0.427 (0.509) data 0.000 (0.072) loss 2.1250 (2.2064) lr 2.4472e-03 eta 0:01:01
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.11s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 579
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 70.2%

epoch [46/50] batch [2/24] time 0.626 (1.295) data 0.001 (0.576) loss 2.1074 (2.1250) lr 2.4472e-03 eta 0:02:32
epoch [46/50] batch [4/24] time 0.429 (0.864) data 0.000 (0.288) loss 2.4512 (2.2417) lr 2.4472e-03 eta 0:01:40
epoch [46/50] batch [6/24] time 0.431 (0.720) data 0.000 (0.192) loss 2.2363 (2.2344) lr 2.4472e-03 eta 0:01:22
epoch [46/50] batch [8/24] time 0.426 (0.647) data 0.000 (0.144) loss 2.2031 (2.2192) lr 2.4472e-03 eta 0:01:12
epoch [46/50] batch [10/24] time 0.427 (0.603) data 0.000 (0.115) loss 2.0996 (2.2006) lr 2.4472e-03 eta 0:01:06
epoch [46/50] batch [12/24] time 0.430 (0.575) data 0.000 (0.096) loss 2.3867 (2.2173) lr 2.4472e-03 eta 0:01:02
epoch [46/50] batch [14/24] time 0.433 (0.554) data 0.000 (0.082) loss 2.1992 (2.2027) lr 2.4472e-03 eta 0:00:58
epoch [46/50] batch [16/24] time 0.426 (0.538) data 0.000 (0.072) loss 2.1387 (2.1952) lr 2.4472e-03 eta 0:00:55
epoch [46/50] batch [18/24] time 0.426 (0.526) data 0.000 (0.064) loss 2.1465 (2.1915) lr 2.4472e-03 eta 0:00:53
epoch [46/50] batch [20/24] time 0.430 (0.516) data 0.000 (0.058) loss 2.1152 (2.1855) lr 2.4472e-03 eta 0:00:51
epoch [46/50] batch [22/24] time 0.425 (0.508) data 0.000 (0.053) loss 2.4023 (2.1988) lr 2.4472e-03 eta 0:00:49
epoch [46/50] batch [24/24] time 0.431 (0.501) data 0.000 (0.048) loss 2.1895 (2.2009) lr 1.5708e-03 eta 0:00:48
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 577
* accuracy: 71.1%
* error: 28.9%
* macro_f1: 70.0%

epoch [47/50] batch [2/24] time 0.517 (1.318) data 0.000 (0.685) loss 2.3242 (2.4121) lr 1.5708e-03 eta 0:02:03
epoch [47/50] batch [4/24] time 0.424 (0.872) data 0.000 (0.343) loss 2.2812 (2.3354) lr 1.5708e-03 eta 0:01:20
epoch [47/50] batch [6/24] time 0.425 (0.723) data 0.000 (0.228) loss 2.2363 (2.2972) lr 1.5708e-03 eta 0:01:05
epoch [47/50] batch [8/24] time 0.426 (0.648) data 0.000 (0.171) loss 2.2344 (2.2817) lr 1.5708e-03 eta 0:00:57
epoch [47/50] batch [10/24] time 0.429 (0.604) data 0.000 (0.137) loss 2.2402 (2.2754) lr 1.5708e-03 eta 0:00:51
epoch [47/50] batch [12/24] time 0.425 (0.575) data 0.000 (0.114) loss 2.4531 (2.2733) lr 1.5708e-03 eta 0:00:48
epoch [47/50] batch [14/24] time 0.428 (0.554) data 0.000 (0.098) loss 2.3848 (2.2924) lr 1.5708e-03 eta 0:00:45
epoch [47/50] batch [16/24] time 0.427 (0.538) data 0.000 (0.086) loss 2.1113 (2.2760) lr 1.5708e-03 eta 0:00:43
epoch [47/50] batch [18/24] time 0.427 (0.526) data 0.000 (0.076) loss 2.1621 (2.2597) lr 1.5708e-03 eta 0:00:40
epoch [47/50] batch [20/24] time 0.427 (0.516) data 0.000 (0.069) loss 2.3496 (2.2674) lr 1.5708e-03 eta 0:00:39
epoch [47/50] batch [22/24] time 0.428 (0.508) data 0.000 (0.062) loss 2.1191 (2.2545) lr 1.5708e-03 eta 0:00:37
epoch [47/50] batch [24/24] time 0.429 (0.501) data 0.000 (0.057) loss 2.3086 (2.2540) lr 8.8564e-04 eta 0:00:36
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.18s/it] 40%|████      | 2/5 [00:03<00:04,  1.48s/it] 60%|██████    | 3/5 [00:03<00:01,  1.08it/s] 80%|████████  | 4/5 [00:03<00:00,  1.51it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 579
* accuracy: 71.3%
* error: 28.7%
* macro_f1: 70.2%

epoch [48/50] batch [2/24] time 0.535 (1.369) data 0.000 (0.698) loss 2.2207 (2.2441) lr 8.8564e-04 eta 0:01:35
epoch [48/50] batch [4/24] time 0.425 (0.901) data 0.000 (0.349) loss 2.1211 (2.2129) lr 8.8564e-04 eta 0:01:01
epoch [48/50] batch [6/24] time 0.428 (0.743) data 0.000 (0.233) loss 2.1289 (2.2298) lr 8.8564e-04 eta 0:00:49
epoch [48/50] batch [8/24] time 0.425 (0.663) data 0.000 (0.175) loss 2.1895 (2.2241) lr 8.8564e-04 eta 0:00:42
epoch [48/50] batch [10/24] time 0.425 (0.616) data 0.000 (0.140) loss 2.0742 (2.2227) lr 8.8564e-04 eta 0:00:38
epoch [48/50] batch [12/24] time 0.425 (0.584) data 0.000 (0.117) loss 2.1953 (2.2194) lr 8.8564e-04 eta 0:00:35
epoch [48/50] batch [14/24] time 0.424 (0.561) data 0.000 (0.100) loss 2.1016 (2.2066) lr 8.8564e-04 eta 0:00:32
epoch [48/50] batch [16/24] time 0.426 (0.544) data 0.000 (0.087) loss 2.1797 (2.2063) lr 8.8564e-04 eta 0:00:30
epoch [48/50] batch [18/24] time 0.431 (0.532) data 0.000 (0.078) loss 2.1113 (2.1985) lr 8.8564e-04 eta 0:00:28
epoch [48/50] batch [20/24] time 0.425 (0.521) data 0.000 (0.070) loss 2.0195 (2.1939) lr 8.8564e-04 eta 0:00:27
epoch [48/50] batch [22/24] time 0.424 (0.512) data 0.000 (0.064) loss 2.3320 (2.2043) lr 8.8564e-04 eta 0:00:25
epoch [48/50] batch [24/24] time 0.430 (0.505) data 0.000 (0.058) loss 2.1562 (2.1989) lr 3.9426e-04 eta 0:00:24
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.20s/it] 40%|████      | 2/5 [00:03<00:04,  1.47s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.20it/s]=> result
* total: 812
* correct: 574
* accuracy: 70.7%
* error: 29.3%
* macro_f1: 69.6%

epoch [49/50] batch [2/24] time 0.529 (1.325) data 0.000 (0.663) loss 2.1172 (2.1309) lr 3.9426e-04 eta 0:01:00
epoch [49/50] batch [4/24] time 0.425 (0.879) data 0.000 (0.332) loss 2.2500 (2.1733) lr 3.9426e-04 eta 0:00:38
epoch [49/50] batch [6/24] time 0.430 (0.729) data 0.000 (0.221) loss 2.2051 (2.1901) lr 3.9426e-04 eta 0:00:30
epoch [49/50] batch [8/24] time 0.429 (0.654) data 0.000 (0.166) loss 2.2129 (2.1912) lr 3.9426e-04 eta 0:00:26
epoch [49/50] batch [10/24] time 0.424 (0.609) data 0.000 (0.133) loss 2.3320 (2.2219) lr 3.9426e-04 eta 0:00:23
epoch [49/50] batch [12/24] time 0.509 (0.585) data 0.000 (0.111) loss 2.2129 (2.2129) lr 3.9426e-04 eta 0:00:21
epoch [49/50] batch [14/24] time 0.435 (0.563) data 0.000 (0.095) loss 2.4316 (2.2267) lr 3.9426e-04 eta 0:00:19
epoch [49/50] batch [16/24] time 0.430 (0.546) data 0.000 (0.083) loss 2.2773 (2.2283) lr 3.9426e-04 eta 0:00:17
epoch [49/50] batch [18/24] time 0.426 (0.533) data 0.000 (0.074) loss 2.2969 (2.2312) lr 3.9426e-04 eta 0:00:15
epoch [49/50] batch [20/24] time 0.440 (0.523) data 0.000 (0.066) loss 2.3672 (2.2415) lr 3.9426e-04 eta 0:00:14
epoch [49/50] batch [22/24] time 0.429 (0.515) data 0.000 (0.060) loss 2.1738 (2.2327) lr 3.9426e-04 eta 0:00:13
epoch [49/50] batch [24/24] time 0.427 (0.507) data 0.000 (0.055) loss 2.1270 (2.2301) lr 9.8664e-05 eta 0:00:12
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.16s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.10it/s] 80%|████████  | 4/5 [00:03<00:00,  1.53it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]=> result
* total: 812
* correct: 575
* accuracy: 70.8%
* error: 29.2%
* macro_f1: 69.7%

epoch [50/50] batch [2/24] time 0.542 (1.315) data 0.000 (0.661) loss 2.1133 (2.2354) lr 9.8664e-05 eta 0:00:28
epoch [50/50] batch [4/24] time 0.427 (0.873) data 0.000 (0.331) loss 2.1875 (2.2202) lr 9.8664e-05 eta 0:00:17
epoch [50/50] batch [6/24] time 0.427 (0.724) data 0.000 (0.220) loss 2.1836 (2.2669) lr 9.8664e-05 eta 0:00:13
epoch [50/50] batch [8/24] time 0.428 (0.650) data 0.000 (0.165) loss 2.3359 (2.2747) lr 9.8664e-05 eta 0:00:10
epoch [50/50] batch [10/24] time 0.426 (0.605) data 0.000 (0.132) loss 2.1758 (2.2557) lr 9.8664e-05 eta 0:00:08
epoch [50/50] batch [12/24] time 0.427 (0.575) data 0.000 (0.110) loss 2.3086 (2.2554) lr 9.8664e-05 eta 0:00:06
epoch [50/50] batch [14/24] time 0.426 (0.554) data 0.000 (0.095) loss 2.1289 (2.2404) lr 9.8664e-05 eta 0:00:05
epoch [50/50] batch [16/24] time 0.426 (0.538) data 0.000 (0.083) loss 2.1758 (2.2332) lr 9.8664e-05 eta 0:00:04
epoch [50/50] batch [18/24] time 0.425 (0.526) data 0.000 (0.074) loss 2.0039 (2.2099) lr 9.8664e-05 eta 0:00:03
epoch [50/50] batch [20/24] time 0.429 (0.516) data 0.000 (0.066) loss 2.3203 (2.2168) lr 9.8664e-05 eta 0:00:02
epoch [50/50] batch [22/24] time 0.427 (0.508) data 0.000 (0.060) loss 2.1465 (2.2120) lr 9.8664e-05 eta 0:00:01
epoch [50/50] batch [24/24] time 0.426 (0.501) data 0.000 (0.055) loss 2.3555 (2.2209) lr 0.0000e+00 eta 0:00:00
Evaluate on the *val* set
  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:03<00:12,  3.17s/it] 40%|████      | 2/5 [00:03<00:04,  1.46s/it] 60%|██████    | 3/5 [00:03<00:01,  1.09it/s] 80%|████████  | 4/5 [00:03<00:00,  1.52it/s]100%|██████████| 5/5 [00:04<00:00,  1.21it/s]
=> result
* total: 812
* correct: 576
* accuracy: 70.9%
* error: 29.1%
* macro_f1: 69.9%
Checkpoint saved to output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model.pth.tar-50
Finish training
Deploy the model with the best val performance
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar" (epoch = 44)
Evaluate on the *test* set
  0%|          | 0/21 [00:00<?, ?it/s]  5%|▍         | 1/21 [00:04<01:24,  4.22s/it] 10%|▉         | 2/21 [00:05<00:41,  2.20s/it] 14%|█▍        | 3/21 [00:05<00:24,  1.38s/it] 19%|█▉        | 4/21 [00:05<00:16,  1.01it/s] 24%|██▍       | 5/21 [00:06<00:12,  1.28it/s] 29%|██▊       | 6/21 [00:06<00:09,  1.53it/s] 33%|███▎      | 7/21 [00:07<00:07,  1.76it/s] 38%|███▊      | 8/21 [00:07<00:06,  1.94it/s] 43%|████▎     | 9/21 [00:07<00:05,  2.08it/s] 48%|████▊     | 10/21 [00:08<00:04,  2.21it/s] 52%|█████▏    | 11/21 [00:08<00:04,  2.33it/s] 57%|█████▋    | 12/21 [00:08<00:03,  2.46it/s] 62%|██████▏   | 13/21 [00:09<00:02,  2.71it/s] 67%|██████▋   | 14/21 [00:09<00:02,  2.96it/s] 71%|███████▏  | 15/21 [00:09<00:01,  3.16it/s] 76%|███████▌  | 16/21 [00:10<00:01,  3.33it/s] 81%|████████  | 17/21 [00:10<00:01,  3.46it/s] 86%|████████▌ | 18/21 [00:10<00:00,  3.56it/s] 90%|█████████ | 19/21 [00:10<00:00,  3.63it/s] 95%|█████████▌| 20/21 [00:11<00:00,  3.68it/s]100%|██████████| 21/21 [00:11<00:00,  4.35it/s]100%|██████████| 21/21 [00:11<00:00,  1.86it/s]
=> result
* total: 4,002
* correct: 2,907
* accuracy: 72.6%
* error: 27.4%
* macro_f1: 72.0%
Elapsed: 0:13:52
+ sh scripts/rpo_prime/base2new_test.sh stanford_cars 3 0 main_tmp1 16 new
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/stanford_cars.yaml
eval_only: True
head: 
load_epoch: None
model_dir: output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'new']
output_dir: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: StanfordCars
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: new
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/test_new/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:StanfordCars
Loading dataset: StanfordCars
Reading split from /shared/s2/lab01/dataset/clip/stanford_cars/split_zhou_StanfordCars.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/stanford_cars/split_fewshot_taesup/shot_16-seed_3.pkl
SUBSAMPLE NEW CLASSES!
1568 823 4039
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ------------
Dataset    StanfordCars
# classes  98
# train_x  1,568
# val      823
# test     4,039
---------  ------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/base2new/train_base/stanford_cars/shots_16/RPO_prime/main_tmp1/seed3/prompt_learner/model-best.pth.tar" (epoch = 44)
Evaluate on the *test* set
  0%|          | 0/21 [00:00<?, ?it/s]  5%|▍         | 1/21 [00:07<02:28,  7.45s/it] 10%|▉         | 2/21 [00:07<01:02,  3.30s/it] 14%|█▍        | 3/21 [00:08<00:35,  1.97s/it] 19%|█▉        | 4/21 [00:08<00:22,  1.35s/it] 24%|██▍       | 5/21 [00:09<00:16,  1.01s/it] 29%|██▊       | 6/21 [00:09<00:11,  1.25it/s] 33%|███▎      | 7/21 [00:09<00:09,  1.48it/s] 38%|███▊      | 8/21 [00:10<00:07,  1.82it/s] 43%|████▎     | 9/21 [00:10<00:05,  2.18it/s] 48%|████▊     | 10/21 [00:10<00:04,  2.52it/s] 52%|█████▏    | 11/21 [00:10<00:03,  2.80it/s] 57%|█████▋    | 12/21 [00:11<00:02,  3.06it/s] 62%|██████▏   | 13/21 [00:11<00:02,  3.26it/s] 67%|██████▋   | 14/21 [00:11<00:02,  3.42it/s] 71%|███████▏  | 15/21 [00:11<00:01,  3.54it/s] 76%|███████▌  | 16/21 [00:12<00:01,  3.60it/s] 81%|████████  | 17/21 [00:12<00:01,  3.67it/s] 86%|████████▌ | 18/21 [00:12<00:00,  3.72it/s] 90%|█████████ | 19/21 [00:12<00:00,  3.76it/s] 95%|█████████▌| 20/21 [00:13<00:00,  3.79it/s]100%|██████████| 21/21 [00:13<00:00,  4.22it/s]100%|██████████| 21/21 [00:13<00:00,  1.55it/s]
=> result
* total: 4,039
* correct: 2,948
* accuracy: 73.0%
* error: 27.0%
* macro_f1: 71.9%
+ for dataset in oxford_flowers stanford_cars oxford_pets food101 eurosat dtd sun397 ucf101 caltech101 imagenet
+ for seed in 1 2 3
+ sh scripts/rpo_prime/base2new_train.sh oxford_pets 1 0 main_tmp1 16
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_tmp1.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime/main_tmp1/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.1
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/base2new/train_base/oxford_pets/shots_16/RPO_prime/main_tmp1/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: best_val
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 10
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: 
    CSC: False
    CTX_INIT: 
    N_CTX: 4
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 8
    K2: 24
    PREC: fp16
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:OxfordPets
Loading dataset: OxfordPets
Reading split from /shared/s2/lab01/dataset/clip/oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /shared/s2/lab01/dataset/clip/oxford_pets/split_fewshot_taesup/shot_16-seed_1.pkl
Traceback (most recent call last):
  File "train.py", line 230, in <module>
    main(args)
  File "train.py", line 165, in main
    trainer = build_trainer(cfg)
  File "/home/s2/mjoolee/CLIP/KgCoop/Dassl.pytorch/dassl/engine/build.py", line 11, in build_trainer
    return TRAINER_REGISTRY.get(cfg.TRAINER.NAME)(cfg)
  File "/home/s2/mjoolee/CLIP/KgCoop/Dassl.pytorch/dassl/engine/trainer.py", line 324, in __init__
    self.build_data_loader() #수정
  File "/home/s2/mjoolee/CLIP/KgCoop/Dassl.pytorch/dassl/engine/trainer.py", line 347, in build_data_loader
    dm = DataManager(self.cfg)
  File "/home/s2/mjoolee/CLIP/KgCoop/Dassl.pytorch/dassl/data/data_manager.py", line 61, in __init__
    dataset = build_dataset(cfg)
  File "/home/s2/mjoolee/CLIP/KgCoop/Dassl.pytorch/dassl/data/datasets/build.py", line 11, in build_dataset
    return DATASET_REGISTRY.get(cfg.DATASET.NAME)(cfg)
  File "/shared/s2/lab01/myungjoo/RPO_v2/datasets/oxford_pets.py", line 41, in __init__
    data = pickle.load(file)
ValueError: unsupported pickle protocol: 5

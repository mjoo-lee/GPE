set -e
set -x

eval "$(conda shell.bash hook)"
++ conda shell.bash hook
+ eval 'export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\''

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We'\''re not allowing PS1 to be unbound. It must at least be set.
    # However, we'\''re not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi

conda activate base'
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python

# Copyright (C) 2012 Anaconda, Inc
# SPDX-License-Identifier: BSD-3-Clause
__conda_exe() (
    "$CONDA_EXE" $_CE_M $_CE_CONDA "$@"
)

__conda_hashr() {
    if [ -n "${ZSH_VERSION:+x}" ]; then
        \rehash
    elif [ -n "${POSH_VERSION:+x}" ]; then
        :  # pass
    else
        \hash -r
    fi
}

__conda_activate() {
    if [ -n "${CONDA_PS1_BACKUP:+x}" ]; then
        # Handle transition from shell activated with conda <= 4.3 to a subsequent activation
        # after conda updated to >= 4.4. See issue #6173.
        PS1="$CONDA_PS1_BACKUP"
        \unset CONDA_PS1_BACKUP
    fi
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix "$@")" || \return
    \eval "$ask_conda"
    __conda_hashr
}

__conda_reactivate() {
    \local ask_conda
    ask_conda="$(PS1="${PS1:-}" __conda_exe shell.posix reactivate)" || \return
    \eval "$ask_conda"
    __conda_hashr
}

conda() {
    \local cmd="${1-__missing__}"
    case "$cmd" in
        activate|deactivate)
            __conda_activate "$@"
            ;;
        install|update|upgrade|remove|uninstall)
            __conda_exe "$@" || \return
            __conda_reactivate
            ;;
        *)
            __conda_exe "$@"
            ;;
    esac
}

if [ -z "${CONDA_SHLVL+x}" ]; then
    \export CONDA_SHLVL=0
    # In dev-mode CONDA_EXE is python.exe and on Windows
    # it is in a different relative location to condabin.
    if [ -n "${_CE_CONDA:+x}" ] && [ -n "${WINDIR+x}" ]; then
        PATH="$(\dirname "$CONDA_EXE")/condabin${PATH:+":${PATH}"}"
    else
        PATH="$(\dirname "$(\dirname "$CONDA_EXE")")/condabin${PATH:+":${PATH}"}"
    fi
    \export PATH

    # We're not allowing PS1 to be unbound. It must at least be set.
    # However, we're not exporting it, which can cause problems when starting a second shell
    # via a first shell (i.e. starting zsh from bash).
    if [ -z "${PS1+x}" ]; then
        PS1=
    fi
fi
++ '[' -z x ']'

conda activate base
++ conda activate base
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate base
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate base
+++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate base
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(base) '
+++ PS1='(base) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
+++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
+++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda'
+++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda
+++ CONDA_PREFIX=/home/s2/mjoolee/anaconda
export CONDA_SHLVL='3'
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
export CONDA_DEFAULT_ENV='base'
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
export CONDA_PROMPT_MODIFIER='(base) '
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
export CONDA_PREFIX_2='/home/s2/mjoolee/anaconda/envs/dassl'
+++ export CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
+++ CONDA_PREFIX_2=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
+++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
+++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
+++ export _CE_M=
+++ _CE_M=
export _CE_CONDA=''
+++ export _CE_CONDA=
+++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
+++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
conda activate dassl
+ conda activate dassl
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate dassl
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate dassl
++ /home/s2/mjoolee/anaconda/bin/conda shell.posix activate dassl
+ ask_conda='PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
+ eval 'PS1='\''(dassl) '\''
export PATH='\''/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'\''
export CONDA_PREFIX='\''/home/s2/mjoolee/anaconda/envs/dassl'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''dassl'\''
export CONDA_PROMPT_MODIFIER='\''(dassl) '\''
export CONDA_PREFIX_3='\''/home/s2/mjoolee/anaconda'\''
export CONDA_EXE='\''/home/s2/mjoolee/anaconda/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/home/s2/mjoolee/anaconda/bin/python'\'''
PS1='(dassl) '
++ PS1='(dassl) '
export PATH='/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'
++ export PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
++ PATH=/home/s2/mjoolee/.vscode-server/cli/servers/Stable-903b1e9d8990623e3d7da1df3d33db3e42d80eda/server/bin/remote-cli:/home/s2/mjoolee/anaconda/envs/dassl/bin:/home/s2/mjoolee/anaconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
export CONDA_PREFIX='/home/s2/mjoolee/anaconda/envs/dassl'
++ export CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
++ CONDA_PREFIX=/home/s2/mjoolee/anaconda/envs/dassl
export CONDA_SHLVL='4'
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
export CONDA_DEFAULT_ENV='dassl'
++ export CONDA_DEFAULT_ENV=dassl
++ CONDA_DEFAULT_ENV=dassl
export CONDA_PROMPT_MODIFIER='(dassl) '
++ export 'CONDA_PROMPT_MODIFIER=(dassl) '
++ CONDA_PROMPT_MODIFIER='(dassl) '
export CONDA_PREFIX_3='/home/s2/mjoolee/anaconda'
++ export CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
++ CONDA_PREFIX_3=/home/s2/mjoolee/anaconda
export CONDA_EXE='/home/s2/mjoolee/anaconda/bin/conda'
++ export CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
++ CONDA_EXE=/home/s2/mjoolee/anaconda/bin/conda
export _CE_M=''
++ export _CE_M=
++ _CE_M=
export _CE_CONDA=''
++ export _CE_CONDA=
++ _CE_CONDA=
export CONDA_PYTHON_EXE='/home/s2/mjoolee/anaconda/bin/python'
++ export CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
++ CONDA_PYTHON_EXE=/home/s2/mjoolee/anaconda/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r

GPU=0
+ GPU=0
SHOT=16
+ SHOT=16
EPOCH=15
+ EPOCH=15
TRAINER=RPO_prime
+ TRAINER=RPO_prime

for seed in 1 2 3
do
    #sh scripts/rpo_prime/dg_train.sh imagenet ${seed} ${GPU} main_final_imagenet ${SHOT} ${TRAINER}
    for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2 #imagenet 
    do 
        sh scripts/rpo_prime/dg_test.sh imagenet  ${dataset} ${seed} ${GPU} main_final_imagenet ${SHOT} ${EPOCH} ${TRAINER}
    done
done
+ for seed in 1 2 3
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenet_a 1 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenet_a.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenet_a/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetA
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenet_a/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetA
Loading dataset: ImageNetA
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ---------
Dataset    ImageNetA
# classes  200
# train_x  7,500
# test     7,500
---------  ---------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed1/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/39 [00:00<?, ?it/s]  3%|▎         | 1/39 [00:07<04:54,  7.74s/it]  5%|▌         | 2/39 [00:08<02:06,  3.43s/it]  8%|▊         | 3/39 [00:08<01:13,  2.05s/it] 10%|█         | 4/39 [00:09<00:50,  1.45s/it] 13%|█▎        | 5/39 [00:09<00:38,  1.13s/it] 15%|█▌        | 6/39 [00:09<00:28,  1.16it/s] 18%|█▊        | 7/39 [00:10<00:22,  1.42it/s] 21%|██        | 8/39 [00:10<00:18,  1.64it/s] 23%|██▎       | 9/39 [00:11<00:16,  1.86it/s] 26%|██▌       | 10/39 [00:11<00:14,  2.01it/s] 28%|██▊       | 11/39 [00:11<00:13,  2.12it/s] 31%|███       | 12/39 [00:12<00:12,  2.22it/s] 33%|███▎      | 13/39 [00:12<00:11,  2.34it/s] 36%|███▌      | 14/39 [00:13<00:10,  2.40it/s] 38%|███▊      | 15/39 [00:13<00:09,  2.41it/s] 41%|████      | 16/39 [00:13<00:09,  2.44it/s] 44%|████▎     | 17/39 [00:14<00:08,  2.47it/s] 46%|████▌     | 18/39 [00:14<00:08,  2.52it/s] 49%|████▊     | 19/39 [00:15<00:07,  2.65it/s] 51%|█████▏    | 20/39 [00:15<00:06,  2.76it/s] 54%|█████▍    | 21/39 [00:15<00:06,  2.74it/s] 56%|█████▋    | 22/39 [00:16<00:06,  2.82it/s] 59%|█████▉    | 23/39 [00:16<00:05,  2.99it/s] 62%|██████▏   | 24/39 [00:16<00:04,  3.12it/s] 64%|██████▍   | 25/39 [00:16<00:04,  3.18it/s] 67%|██████▋   | 26/39 [00:17<00:03,  3.26it/s] 69%|██████▉   | 27/39 [00:17<00:03,  3.31it/s] 72%|███████▏  | 28/39 [00:17<00:03,  3.34it/s] 74%|███████▍  | 29/39 [00:18<00:02,  3.37it/s] 77%|███████▋  | 30/39 [00:18<00:02,  3.39it/s] 79%|███████▉  | 31/39 [00:18<00:02,  3.39it/s] 82%|████████▏ | 32/39 [00:19<00:02,  3.39it/s] 85%|████████▍ | 33/39 [00:19<00:01,  3.41it/s] 87%|████████▋ | 34/39 [00:19<00:01,  3.41it/s] 90%|████████▉ | 35/39 [00:19<00:01,  3.43it/s] 92%|█████████▏| 36/39 [00:20<00:00,  3.44it/s] 95%|█████████▍| 37/39 [00:20<00:00,  3.43it/s] 97%|█████████▋| 38/39 [00:20<00:00,  3.41it/s]100%|██████████| 39/39 [00:20<00:00,  4.08it/s]100%|██████████| 39/39 [00:20<00:00,  1.86it/s]
=> result
* total: 7,500
* correct: 3,651
* accuracy: 48.7%
* error: 51.3%
* macro_f1: 44.8%
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenet_r 1 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenet_r.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenet_r/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetR
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenet_r/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetR
Loading dataset: ImageNetR
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ---------
Dataset    ImageNetR
# classes  200
# train_x  30,000
# test     30,000
---------  ---------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed1/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/154 [00:00<?, ?it/s]  1%|          | 1/154 [00:07<19:24,  7.61s/it]  1%|▏         | 2/154 [00:08<08:33,  3.38s/it]  2%|▏         | 3/154 [00:08<05:07,  2.03s/it]  3%|▎         | 4/154 [00:09<03:38,  1.46s/it]  3%|▎         | 5/154 [00:09<02:47,  1.13s/it]  4%|▍         | 6/154 [00:09<02:09,  1.14it/s]  5%|▍         | 7/154 [00:10<01:45,  1.40it/s]  5%|▌         | 8/154 [00:10<01:30,  1.61it/s]  6%|▌         | 9/154 [00:11<01:20,  1.81it/s]  6%|▋         | 10/154 [00:11<01:13,  1.95it/s]  7%|▋         | 11/154 [00:12<01:08,  2.08it/s]  8%|▊         | 12/154 [00:12<01:05,  2.16it/s]  8%|▊         | 13/154 [00:12<01:04,  2.18it/s]  9%|▉         | 14/154 [00:13<01:02,  2.25it/s] 10%|▉         | 15/154 [00:13<01:00,  2.31it/s] 10%|█         | 16/154 [00:14<00:59,  2.34it/s] 11%|█         | 17/154 [00:14<00:58,  2.36it/s] 12%|█▏        | 18/154 [00:14<00:56,  2.41it/s] 12%|█▏        | 19/154 [00:15<00:55,  2.44it/s] 13%|█▎        | 20/154 [00:15<00:55,  2.43it/s] 14%|█▎        | 21/154 [00:16<00:54,  2.44it/s] 14%|█▍        | 22/154 [00:16<00:54,  2.43it/s] 15%|█▍        | 23/154 [00:16<00:53,  2.46it/s] 16%|█▌        | 24/154 [00:17<00:53,  2.41it/s] 16%|█▌        | 25/154 [00:17<00:52,  2.43it/s] 17%|█▋        | 26/154 [00:18<00:52,  2.44it/s] 18%|█▊        | 27/154 [00:18<00:52,  2.42it/s] 18%|█▊        | 28/154 [00:19<00:52,  2.41it/s] 19%|█▉        | 29/154 [00:19<00:52,  2.40it/s] 19%|█▉        | 30/154 [00:19<00:51,  2.41it/s] 20%|██        | 31/154 [00:20<00:52,  2.35it/s] 21%|██        | 32/154 [00:20<00:52,  2.34it/s] 21%|██▏       | 33/154 [00:21<00:50,  2.37it/s] 22%|██▏       | 34/154 [00:21<00:50,  2.36it/s] 23%|██▎       | 35/154 [00:21<00:50,  2.37it/s] 23%|██▎       | 36/154 [00:22<00:49,  2.39it/s] 24%|██▍       | 37/154 [00:22<00:49,  2.38it/s] 25%|██▍       | 38/154 [00:23<00:48,  2.38it/s] 25%|██▌       | 39/154 [00:23<00:47,  2.40it/s] 26%|██▌       | 40/154 [00:24<00:46,  2.43it/s] 27%|██▋       | 41/154 [00:24<00:46,  2.42it/s] 27%|██▋       | 42/154 [00:24<00:46,  2.43it/s] 28%|██▊       | 43/154 [00:25<00:45,  2.43it/s] 29%|██▊       | 44/154 [00:25<00:45,  2.42it/s] 29%|██▉       | 45/154 [00:26<00:46,  2.37it/s] 30%|██▉       | 46/154 [00:26<00:45,  2.38it/s] 31%|███       | 47/154 [00:26<00:44,  2.41it/s] 31%|███       | 48/154 [00:27<00:43,  2.45it/s] 32%|███▏      | 49/154 [00:27<00:43,  2.42it/s] 32%|███▏      | 50/154 [00:28<00:42,  2.44it/s] 33%|███▎      | 51/154 [00:28<00:41,  2.46it/s] 34%|███▍      | 52/154 [00:29<00:41,  2.46it/s] 34%|███▍      | 53/154 [00:29<00:41,  2.44it/s] 35%|███▌      | 54/154 [00:29<00:41,  2.41it/s] 36%|███▌      | 55/154 [00:30<00:41,  2.39it/s] 36%|███▋      | 56/154 [00:30<00:40,  2.40it/s] 37%|███▋      | 57/154 [00:31<00:40,  2.37it/s] 38%|███▊      | 58/154 [00:31<00:39,  2.43it/s] 38%|███▊      | 59/154 [00:31<00:39,  2.43it/s] 39%|███▉      | 60/154 [00:32<00:38,  2.42it/s] 40%|███▉      | 61/154 [00:32<00:38,  2.40it/s] 40%|████      | 62/154 [00:33<00:38,  2.42it/s] 41%|████      | 63/154 [00:33<00:37,  2.44it/s] 42%|████▏     | 64/154 [00:33<00:36,  2.44it/s] 42%|████▏     | 65/154 [00:34<00:36,  2.44it/s] 43%|████▎     | 66/154 [00:34<00:35,  2.45it/s] 44%|████▎     | 67/154 [00:35<00:35,  2.48it/s] 44%|████▍     | 68/154 [00:35<00:34,  2.46it/s] 45%|████▍     | 69/154 [00:36<00:34,  2.45it/s] 45%|████▌     | 70/154 [00:36<00:34,  2.43it/s] 46%|████▌     | 71/154 [00:36<00:33,  2.45it/s] 47%|████▋     | 72/154 [00:37<00:33,  2.45it/s] 47%|████▋     | 73/154 [00:37<00:33,  2.45it/s] 48%|████▊     | 74/154 [00:38<00:32,  2.44it/s] 49%|████▊     | 75/154 [00:38<00:32,  2.43it/s] 49%|████▉     | 76/154 [00:38<00:32,  2.43it/s] 50%|█████     | 77/154 [00:39<00:31,  2.41it/s] 51%|█████     | 78/154 [00:39<00:31,  2.39it/s] 51%|█████▏    | 79/154 [00:40<00:31,  2.39it/s] 52%|█████▏    | 80/154 [00:40<00:31,  2.38it/s] 53%|█████▎    | 81/154 [00:41<00:31,  2.34it/s] 53%|█████▎    | 82/154 [00:41<00:30,  2.39it/s] 54%|█████▍    | 83/154 [00:41<00:29,  2.44it/s] 55%|█████▍    | 84/154 [00:42<00:28,  2.42it/s] 55%|█████▌    | 85/154 [00:42<00:28,  2.42it/s] 56%|█████▌    | 86/154 [00:43<00:28,  2.40it/s] 56%|█████▋    | 87/154 [00:43<00:27,  2.40it/s] 57%|█████▋    | 88/154 [00:43<00:27,  2.37it/s] 58%|█████▊    | 89/154 [00:44<00:27,  2.34it/s] 58%|█████▊    | 90/154 [00:44<00:27,  2.34it/s] 59%|█████▉    | 91/154 [00:45<00:26,  2.37it/s] 60%|█████▉    | 92/154 [00:45<00:25,  2.39it/s] 60%|██████    | 93/154 [00:46<00:25,  2.40it/s] 61%|██████    | 94/154 [00:46<00:24,  2.43it/s] 62%|██████▏   | 95/154 [00:46<00:24,  2.39it/s] 62%|██████▏   | 96/154 [00:47<00:23,  2.42it/s] 63%|██████▎   | 97/154 [00:47<00:23,  2.43it/s] 64%|██████▎   | 98/154 [00:48<00:22,  2.44it/s] 64%|██████▍   | 99/154 [00:48<00:22,  2.46it/s] 65%|██████▍   | 100/154 [00:48<00:22,  2.44it/s] 66%|██████▌   | 101/154 [00:49<00:21,  2.43it/s] 66%|██████▌   | 102/154 [00:49<00:21,  2.41it/s] 67%|██████▋   | 103/154 [00:50<00:21,  2.38it/s] 68%|██████▊   | 104/154 [00:50<00:20,  2.40it/s] 68%|██████▊   | 105/154 [00:50<00:20,  2.41it/s] 69%|██████▉   | 106/154 [00:51<00:19,  2.41it/s] 69%|██████▉   | 107/154 [00:51<00:19,  2.46it/s] 70%|███████   | 108/154 [00:52<00:18,  2.45it/s] 71%|███████   | 109/154 [00:52<00:18,  2.47it/s] 71%|███████▏  | 110/154 [00:52<00:17,  2.48it/s] 72%|███████▏  | 111/154 [00:53<00:17,  2.45it/s] 73%|███████▎  | 112/154 [00:53<00:17,  2.46it/s] 73%|███████▎  | 113/154 [00:54<00:16,  2.46it/s] 74%|███████▍  | 114/154 [00:54<00:16,  2.47it/s] 75%|███████▍  | 115/154 [00:55<00:15,  2.44it/s] 75%|███████▌  | 116/154 [00:55<00:15,  2.44it/s] 76%|███████▌  | 117/154 [00:55<00:15,  2.44it/s] 77%|███████▋  | 118/154 [00:56<00:14,  2.45it/s] 77%|███████▋  | 119/154 [00:56<00:14,  2.42it/s] 78%|███████▊  | 120/154 [00:57<00:14,  2.40it/s] 79%|███████▊  | 121/154 [00:57<00:13,  2.47it/s] 79%|███████▉  | 122/154 [00:57<00:13,  2.46it/s] 80%|███████▉  | 123/154 [00:58<00:12,  2.44it/s] 81%|████████  | 124/154 [00:58<00:12,  2.43it/s] 81%|████████  | 125/154 [00:59<00:12,  2.39it/s] 82%|████████▏ | 126/154 [00:59<00:11,  2.43it/s] 82%|████████▏ | 127/154 [00:59<00:11,  2.43it/s] 83%|████████▎ | 128/154 [01:00<00:10,  2.45it/s] 84%|████████▍ | 129/154 [01:00<00:10,  2.44it/s] 84%|████████▍ | 130/154 [01:01<00:09,  2.46it/s] 85%|████████▌ | 131/154 [01:01<00:09,  2.46it/s] 86%|████████▌ | 132/154 [01:01<00:08,  2.51it/s] 86%|████████▋ | 133/154 [01:02<00:08,  2.58it/s] 87%|████████▋ | 134/154 [01:02<00:07,  2.57it/s] 88%|████████▊ | 135/154 [01:03<00:07,  2.62it/s] 88%|████████▊ | 136/154 [01:03<00:06,  2.67it/s] 89%|████████▉ | 137/154 [01:03<00:06,  2.82it/s] 90%|████████▉ | 138/154 [01:04<00:05,  2.94it/s] 90%|█████████ | 139/154 [01:04<00:04,  3.02it/s] 91%|█████████ | 140/154 [01:04<00:04,  3.11it/s] 92%|█████████▏| 141/154 [01:04<00:04,  3.17it/s] 92%|█████████▏| 142/154 [01:05<00:03,  3.20it/s] 93%|█████████▎| 143/154 [01:05<00:03,  3.24it/s] 94%|█████████▎| 144/154 [01:05<00:03,  3.26it/s] 94%|█████████▍| 145/154 [01:06<00:02,  3.29it/s] 95%|█████████▍| 146/154 [01:06<00:02,  3.31it/s] 95%|█████████▌| 147/154 [01:06<00:02,  3.29it/s] 96%|█████████▌| 148/154 [01:07<00:01,  3.30it/s] 97%|█████████▋| 149/154 [01:07<00:01,  3.31it/s] 97%|█████████▋| 150/154 [01:07<00:01,  3.29it/s] 98%|█████████▊| 151/154 [01:07<00:00,  3.31it/s] 99%|█████████▊| 152/154 [01:08<00:00,  3.32it/s] 99%|█████████▉| 153/154 [01:08<00:00,  3.29it/s]100%|██████████| 154/154 [01:08<00:00,  2.24it/s]
=> result
* total: 30,000
* correct: 22,864
* accuracy: 76.2%
* error: 23.8%
* macro_f1: 74.4%
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenet_sketch 1 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenet_sketch.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenet_sketch/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetSketch
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenet_sketch/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetSketch
Loading dataset: ImageNetSketch
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------
Dataset    ImageNetSketch
# classes  1,000
# train_x  50,889
# test     50,889
---------  --------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed1/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/260 [00:00<?, ?it/s]  0%|          | 1/260 [00:10<45:23, 10.52s/it]  1%|          | 2/260 [00:11<20:37,  4.80s/it]  1%|          | 3/260 [00:12<12:45,  2.98s/it]  2%|▏         | 4/260 [00:12<09:06,  2.13s/it]  2%|▏         | 5/260 [00:13<07:19,  1.72s/it]  2%|▏         | 6/260 [00:14<06:18,  1.49s/it]  3%|▎         | 7/260 [00:15<05:17,  1.26s/it]  3%|▎         | 8/260 [00:16<04:35,  1.09s/it]  3%|▎         | 9/260 [00:17<04:09,  1.01it/s]  4%|▍         | 10/260 [00:18<03:52,  1.08it/s]  4%|▍         | 11/260 [00:18<03:43,  1.11it/s]  5%|▍         | 12/260 [00:19<03:36,  1.14it/s]  5%|▌         | 13/260 [00:20<03:32,  1.16it/s]  5%|▌         | 14/260 [00:21<03:25,  1.20it/s]  6%|▌         | 15/260 [00:22<03:18,  1.24it/s]  6%|▌         | 16/260 [00:22<03:16,  1.24it/s]  7%|▋         | 17/260 [00:23<03:15,  1.24it/s]  7%|▋         | 18/260 [00:24<03:14,  1.25it/s]  7%|▋         | 19/260 [00:25<03:11,  1.26it/s]  8%|▊         | 20/260 [00:26<03:08,  1.27it/s]  8%|▊         | 21/260 [00:26<03:06,  1.28it/s]  8%|▊         | 22/260 [00:27<03:06,  1.28it/s]  9%|▉         | 23/260 [00:28<03:06,  1.27it/s]  9%|▉         | 24/260 [00:29<03:05,  1.27it/s] 10%|▉         | 25/260 [00:30<03:09,  1.24it/s] 10%|█         | 26/260 [00:30<03:04,  1.27it/s] 10%|█         | 27/260 [00:31<03:08,  1.24it/s] 11%|█         | 28/260 [00:32<03:00,  1.28it/s] 11%|█         | 29/260 [00:33<02:57,  1.30it/s] 12%|█▏        | 30/260 [00:33<02:53,  1.33it/s] 12%|█▏        | 31/260 [00:34<02:50,  1.34it/s] 12%|█▏        | 32/260 [00:35<02:50,  1.34it/s] 13%|█▎        | 33/260 [00:35<02:47,  1.36it/s] 13%|█▎        | 34/260 [00:36<02:47,  1.35it/s] 13%|█▎        | 35/260 [00:37<02:46,  1.35it/s] 14%|█▍        | 36/260 [00:38<02:44,  1.36it/s] 14%|█▍        | 37/260 [00:38<02:45,  1.35it/s] 15%|█▍        | 38/260 [00:39<02:44,  1.35it/s] 15%|█▌        | 39/260 [00:40<02:44,  1.34it/s] 15%|█▌        | 40/260 [00:41<02:44,  1.34it/s] 16%|█▌        | 41/260 [00:41<02:41,  1.35it/s] 16%|█▌        | 42/260 [00:42<02:40,  1.36it/s] 17%|█▋        | 43/260 [00:43<02:41,  1.35it/s] 17%|█▋        | 44/260 [00:44<02:39,  1.35it/s] 17%|█▋        | 45/260 [00:44<02:38,  1.36it/s] 18%|█▊        | 46/260 [00:45<02:37,  1.36it/s] 18%|█▊        | 47/260 [00:46<02:36,  1.36it/s] 18%|█▊        | 48/260 [00:47<02:36,  1.35it/s] 19%|█▉        | 49/260 [00:47<02:35,  1.36it/s] 19%|█▉        | 50/260 [00:48<02:35,  1.35it/s] 20%|█▉        | 51/260 [00:49<02:34,  1.35it/s] 20%|██        | 52/260 [00:50<02:33,  1.35it/s] 20%|██        | 53/260 [00:50<02:33,  1.35it/s] 21%|██        | 54/260 [00:51<02:32,  1.35it/s] 21%|██        | 55/260 [00:52<02:37,  1.30it/s] 22%|██▏       | 56/260 [00:53<02:40,  1.27it/s] 22%|██▏       | 57/260 [00:53<02:39,  1.27it/s] 22%|██▏       | 58/260 [00:54<02:39,  1.27it/s] 23%|██▎       | 59/260 [00:55<02:37,  1.27it/s] 23%|██▎       | 60/260 [00:56<02:37,  1.27it/s] 23%|██▎       | 61/260 [00:57<02:35,  1.28it/s] 24%|██▍       | 62/260 [00:57<02:34,  1.28it/s] 24%|██▍       | 63/260 [00:58<02:34,  1.28it/s] 25%|██▍       | 64/260 [00:59<02:32,  1.28it/s] 25%|██▌       | 65/260 [01:00<02:29,  1.31it/s] 25%|██▌       | 66/260 [01:00<02:26,  1.33it/s] 26%|██▌       | 67/260 [01:01<02:22,  1.35it/s] 26%|██▌       | 68/260 [01:02<02:22,  1.35it/s] 27%|██▋       | 69/260 [01:03<02:21,  1.35it/s] 27%|██▋       | 70/260 [01:03<02:21,  1.35it/s] 27%|██▋       | 71/260 [01:04<02:20,  1.35it/s] 28%|██▊       | 72/260 [01:05<02:21,  1.33it/s] 28%|██▊       | 73/260 [01:06<02:20,  1.33it/s] 28%|██▊       | 74/260 [01:06<02:24,  1.29it/s] 29%|██▉       | 75/260 [01:07<02:23,  1.29it/s] 29%|██▉       | 76/260 [01:08<02:22,  1.29it/s] 30%|██▉       | 77/260 [01:09<02:21,  1.29it/s] 30%|███       | 78/260 [01:10<02:23,  1.27it/s] 30%|███       | 79/260 [01:10<02:20,  1.28it/s] 31%|███       | 80/260 [01:11<02:18,  1.30it/s] 31%|███       | 81/260 [01:12<02:18,  1.29it/s] 32%|███▏      | 82/260 [01:13<02:16,  1.30it/s] 32%|███▏      | 83/260 [01:13<02:14,  1.31it/s] 32%|███▏      | 84/260 [01:14<02:12,  1.33it/s] 33%|███▎      | 85/260 [01:15<02:14,  1.30it/s] 33%|███▎      | 86/260 [01:16<02:13,  1.30it/s] 33%|███▎      | 87/260 [01:16<02:13,  1.29it/s] 34%|███▍      | 88/260 [01:17<02:13,  1.29it/s] 34%|███▍      | 89/260 [01:18<02:13,  1.28it/s] 35%|███▍      | 90/260 [01:19<02:13,  1.27it/s] 35%|███▌      | 91/260 [01:20<02:12,  1.28it/s] 35%|███▌      | 92/260 [01:20<02:11,  1.28it/s] 36%|███▌      | 93/260 [01:21<02:08,  1.30it/s] 36%|███▌      | 94/260 [01:22<02:07,  1.31it/s] 37%|███▋      | 95/260 [01:23<02:05,  1.32it/s] 37%|███▋      | 96/260 [01:23<02:03,  1.32it/s] 37%|███▋      | 97/260 [01:24<02:04,  1.31it/s] 38%|███▊      | 98/260 [01:25<02:07,  1.27it/s] 38%|███▊      | 99/260 [01:26<02:05,  1.29it/s] 38%|███▊      | 100/260 [01:26<02:03,  1.30it/s] 39%|███▉      | 101/260 [01:27<02:02,  1.29it/s] 39%|███▉      | 102/260 [01:28<02:03,  1.28it/s] 40%|███▉      | 103/260 [01:29<02:04,  1.26it/s] 40%|████      | 104/260 [01:30<02:02,  1.27it/s] 40%|████      | 105/260 [01:30<02:04,  1.25it/s] 41%|████      | 106/260 [01:31<01:59,  1.29it/s] 41%|████      | 107/260 [01:32<02:01,  1.26it/s] 42%|████▏     | 108/260 [01:33<01:59,  1.28it/s] 42%|████▏     | 109/260 [01:34<01:59,  1.26it/s] 42%|████▏     | 110/260 [01:34<01:58,  1.27it/s] 43%|████▎     | 111/260 [01:35<01:56,  1.28it/s] 43%|████▎     | 112/260 [01:36<01:56,  1.27it/s] 43%|████▎     | 113/260 [01:37<01:53,  1.30it/s] 44%|████▍     | 114/260 [01:37<01:51,  1.30it/s] 44%|████▍     | 115/260 [01:38<01:51,  1.30it/s] 45%|████▍     | 116/260 [01:39<01:50,  1.30it/s] 45%|████▌     | 117/260 [01:40<01:50,  1.30it/s] 45%|████▌     | 118/260 [01:40<01:47,  1.32it/s] 46%|████▌     | 119/260 [01:41<01:47,  1.31it/s] 46%|████▌     | 120/260 [01:42<01:48,  1.29it/s] 47%|████▋     | 121/260 [01:43<01:44,  1.33it/s] 47%|████▋     | 122/260 [01:44<01:42,  1.34it/s] 47%|████▋     | 123/260 [01:44<01:39,  1.37it/s] 48%|████▊     | 124/260 [01:45<01:38,  1.38it/s] 48%|████▊     | 125/260 [01:46<01:37,  1.39it/s] 48%|████▊     | 126/260 [01:46<01:36,  1.38it/s] 49%|████▉     | 127/260 [01:47<01:35,  1.39it/s] 49%|████▉     | 128/260 [01:48<01:36,  1.36it/s] 50%|████▉     | 129/260 [01:49<01:36,  1.35it/s] 50%|█████     | 130/260 [01:49<01:35,  1.37it/s] 50%|█████     | 131/260 [01:50<01:34,  1.37it/s] 51%|█████     | 132/260 [01:51<01:33,  1.37it/s] 51%|█████     | 133/260 [01:51<01:31,  1.39it/s] 52%|█████▏    | 134/260 [01:52<01:29,  1.41it/s] 52%|█████▏    | 135/260 [01:53<01:28,  1.41it/s] 52%|█████▏    | 136/260 [01:54<01:28,  1.40it/s] 53%|█████▎    | 137/260 [01:54<01:26,  1.42it/s] 53%|█████▎    | 138/260 [01:55<01:27,  1.40it/s] 53%|█████▎    | 139/260 [01:56<01:26,  1.40it/s] 54%|█████▍    | 140/260 [01:56<01:27,  1.37it/s] 54%|█████▍    | 141/260 [01:57<01:25,  1.39it/s] 55%|█████▍    | 142/260 [01:58<01:24,  1.40it/s] 55%|█████▌    | 143/260 [01:59<01:22,  1.41it/s] 55%|█████▌    | 144/260 [01:59<01:21,  1.42it/s] 56%|█████▌    | 145/260 [02:00<01:19,  1.44it/s] 56%|█████▌    | 146/260 [02:01<01:19,  1.44it/s] 57%|█████▋    | 147/260 [02:01<01:20,  1.41it/s] 57%|█████▋    | 148/260 [02:02<01:20,  1.39it/s] 57%|█████▋    | 149/260 [02:03<01:21,  1.37it/s] 58%|█████▊    | 150/260 [02:04<01:20,  1.36it/s] 58%|█████▊    | 151/260 [02:04<01:18,  1.38it/s] 58%|█████▊    | 152/260 [02:05<01:17,  1.39it/s] 59%|█████▉    | 153/260 [02:06<01:17,  1.38it/s] 59%|█████▉    | 154/260 [02:06<01:16,  1.38it/s] 60%|█████▉    | 155/260 [02:07<01:14,  1.42it/s] 60%|██████    | 156/260 [02:08<01:14,  1.40it/s] 60%|██████    | 157/260 [02:09<01:13,  1.41it/s] 61%|██████    | 158/260 [02:09<01:13,  1.38it/s] 61%|██████    | 159/260 [02:10<01:16,  1.32it/s] 62%|██████▏   | 160/260 [02:11<01:13,  1.35it/s] 62%|██████▏   | 161/260 [02:12<01:11,  1.38it/s] 62%|██████▏   | 162/260 [02:12<01:11,  1.36it/s] 63%|██████▎   | 163/260 [02:13<01:12,  1.34it/s] 63%|██████▎   | 164/260 [02:14<01:12,  1.32it/s] 63%|██████▎   | 165/260 [02:15<01:11,  1.33it/s] 64%|██████▍   | 166/260 [02:15<01:09,  1.35it/s] 64%|██████▍   | 167/260 [02:16<01:10,  1.32it/s] 65%|██████▍   | 168/260 [02:17<01:10,  1.30it/s] 65%|██████▌   | 169/260 [02:18<01:12,  1.26it/s] 65%|██████▌   | 170/260 [02:19<01:10,  1.27it/s] 66%|██████▌   | 171/260 [02:19<01:10,  1.26it/s] 66%|██████▌   | 172/260 [02:20<01:09,  1.27it/s] 67%|██████▋   | 173/260 [02:21<01:07,  1.28it/s] 67%|██████▋   | 174/260 [02:22<01:05,  1.31it/s] 67%|██████▋   | 175/260 [02:22<01:05,  1.30it/s] 68%|██████▊   | 176/260 [02:23<01:04,  1.30it/s] 68%|██████▊   | 177/260 [02:24<01:04,  1.29it/s] 68%|██████▊   | 178/260 [02:25<01:03,  1.29it/s] 69%|██████▉   | 179/260 [02:25<01:02,  1.29it/s] 69%|██████▉   | 180/260 [02:26<01:03,  1.26it/s] 70%|██████▉   | 181/260 [02:27<01:02,  1.26it/s] 70%|███████   | 182/260 [02:28<01:02,  1.25it/s] 70%|███████   | 183/260 [02:29<01:02,  1.24it/s] 71%|███████   | 184/260 [02:30<01:01,  1.23it/s] 71%|███████   | 185/260 [02:30<00:59,  1.25it/s] 72%|███████▏  | 186/260 [02:31<00:58,  1.26it/s] 72%|███████▏  | 187/260 [02:32<00:57,  1.27it/s] 72%|███████▏  | 188/260 [02:33<00:57,  1.26it/s] 73%|███████▎  | 189/260 [02:34<00:56,  1.26it/s] 73%|███████▎  | 190/260 [02:34<00:55,  1.27it/s] 73%|███████▎  | 191/260 [02:35<00:54,  1.27it/s] 74%|███████▍  | 192/260 [02:36<00:53,  1.28it/s] 74%|███████▍  | 193/260 [02:37<00:53,  1.26it/s] 75%|███████▍  | 194/260 [02:37<00:52,  1.26it/s] 75%|███████▌  | 195/260 [02:38<00:51,  1.27it/s] 75%|███████▌  | 196/260 [02:39<00:50,  1.26it/s] 76%|███████▌  | 197/260 [02:40<00:48,  1.29it/s] 76%|███████▌  | 198/260 [02:40<00:46,  1.32it/s] 77%|███████▋  | 199/260 [02:41<00:46,  1.30it/s] 77%|███████▋  | 200/260 [02:42<00:46,  1.29it/s] 77%|███████▋  | 201/260 [02:43<00:47,  1.25it/s] 78%|███████▊  | 202/260 [02:44<00:46,  1.25it/s] 78%|███████▊  | 203/260 [02:45<00:45,  1.25it/s] 78%|███████▊  | 204/260 [02:45<00:44,  1.26it/s] 79%|███████▉  | 205/260 [02:46<00:43,  1.27it/s] 79%|███████▉  | 206/260 [02:47<00:42,  1.28it/s] 80%|███████▉  | 207/260 [02:48<00:41,  1.29it/s] 80%|████████  | 208/260 [02:48<00:40,  1.29it/s] 80%|████████  | 209/260 [02:49<00:39,  1.28it/s] 81%|████████  | 210/260 [02:50<00:38,  1.29it/s] 81%|████████  | 211/260 [02:51<00:37,  1.30it/s] 82%|████████▏ | 212/260 [02:51<00:37,  1.29it/s] 82%|████████▏ | 213/260 [02:52<00:36,  1.28it/s] 82%|████████▏ | 214/260 [02:53<00:36,  1.27it/s] 83%|████████▎ | 215/260 [02:54<00:35,  1.27it/s] 83%|████████▎ | 216/260 [02:55<00:34,  1.28it/s] 83%|████████▎ | 217/260 [02:55<00:33,  1.28it/s] 84%|████████▍ | 218/260 [02:56<00:32,  1.29it/s] 84%|████████▍ | 219/260 [02:57<00:31,  1.30it/s] 85%|████████▍ | 220/260 [02:58<00:31,  1.29it/s] 85%|████████▌ | 221/260 [02:58<00:30,  1.29it/s] 85%|████████▌ | 222/260 [02:59<00:29,  1.27it/s] 86%|████████▌ | 223/260 [03:00<00:29,  1.27it/s] 86%|████████▌ | 224/260 [03:01<00:27,  1.29it/s] 87%|████████▋ | 225/260 [03:02<00:27,  1.28it/s] 87%|████████▋ | 226/260 [03:02<00:26,  1.27it/s] 87%|████████▋ | 227/260 [03:03<00:25,  1.28it/s] 88%|████████▊ | 228/260 [03:04<00:25,  1.28it/s] 88%|████████▊ | 229/260 [03:05<00:23,  1.30it/s] 88%|████████▊ | 230/260 [03:05<00:23,  1.30it/s] 89%|████████▉ | 231/260 [03:06<00:22,  1.30it/s] 89%|████████▉ | 232/260 [03:07<00:21,  1.28it/s] 90%|████████▉ | 233/260 [03:08<00:21,  1.25it/s] 90%|█████████ | 234/260 [03:09<00:20,  1.27it/s] 90%|█████████ | 235/260 [03:09<00:19,  1.26it/s] 91%|█████████ | 236/260 [03:10<00:19,  1.25it/s] 91%|█████████ | 237/260 [03:11<00:18,  1.26it/s] 92%|█████████▏| 238/260 [03:12<00:17,  1.27it/s] 92%|█████████▏| 239/260 [03:13<00:16,  1.28it/s] 92%|█████████▏| 240/260 [03:13<00:15,  1.29it/s] 93%|█████████▎| 241/260 [03:14<00:14,  1.31it/s] 93%|█████████▎| 242/260 [03:15<00:13,  1.35it/s] 93%|█████████▎| 243/260 [03:15<00:12,  1.40it/s] 94%|█████████▍| 244/260 [03:16<00:11,  1.43it/s] 94%|█████████▍| 245/260 [03:17<00:10,  1.47it/s] 95%|█████████▍| 246/260 [03:17<00:09,  1.49it/s] 95%|█████████▌| 247/260 [03:18<00:08,  1.51it/s] 95%|█████████▌| 248/260 [03:19<00:07,  1.52it/s] 96%|█████████▌| 249/260 [03:19<00:07,  1.52it/s] 96%|█████████▌| 250/260 [03:20<00:06,  1.53it/s] 97%|█████████▋| 251/260 [03:21<00:05,  1.52it/s] 97%|█████████▋| 252/260 [03:21<00:05,  1.53it/s] 97%|█████████▋| 253/260 [03:22<00:04,  1.53it/s] 98%|█████████▊| 254/260 [03:23<00:03,  1.54it/s] 98%|█████████▊| 255/260 [03:23<00:03,  1.53it/s] 98%|█████████▊| 256/260 [03:24<00:02,  1.53it/s] 99%|█████████▉| 257/260 [03:25<00:01,  1.52it/s] 99%|█████████▉| 258/260 [03:25<00:01,  1.52it/s]100%|█████████▉| 259/260 [03:26<00:00,  1.53it/s]100%|██████████| 260/260 [03:26<00:00,  1.59it/s]100%|██████████| 260/260 [03:27<00:00,  1.26it/s]
=> result
* total: 50,889
* correct: 25,007
* accuracy: 49.1%
* error: 50.9%
* macro_f1: 47.3%
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenetv2 1 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 1
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenetv2.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed1
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenetv2/seed1
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 1
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetV2
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenetv2/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetV2
Loading dataset: ImageNetV2
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    ImageNetV2
# classes  1,000
# train_x  10,000
# test     10,000
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed1/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/52 [00:00<?, ?it/s]  2%|▏         | 1/52 [00:07<06:22,  7.50s/it]  4%|▍         | 2/52 [00:08<02:55,  3.50s/it]  6%|▌         | 3/52 [00:08<01:49,  2.23s/it]  8%|▊         | 4/52 [00:09<01:18,  1.64s/it] 10%|▉         | 5/52 [00:10<01:01,  1.31s/it] 12%|█▏        | 6/52 [00:11<00:51,  1.12s/it] 13%|█▎        | 7/52 [00:11<00:44,  1.00it/s] 15%|█▌        | 8/52 [00:12<00:39,  1.10it/s] 17%|█▋        | 9/52 [00:13<00:36,  1.17it/s] 19%|█▉        | 10/52 [00:14<00:34,  1.21it/s] 21%|██        | 11/52 [00:14<00:33,  1.23it/s] 23%|██▎       | 12/52 [00:15<00:31,  1.27it/s] 25%|██▌       | 13/52 [00:16<00:30,  1.30it/s] 27%|██▋       | 14/52 [00:17<00:28,  1.31it/s] 29%|██▉       | 15/52 [00:17<00:28,  1.30it/s] 31%|███       | 16/52 [00:18<00:27,  1.31it/s] 33%|███▎      | 17/52 [00:19<00:26,  1.30it/s] 35%|███▍      | 18/52 [00:20<00:26,  1.30it/s] 37%|███▋      | 19/52 [00:20<00:25,  1.31it/s] 38%|███▊      | 20/52 [00:21<00:24,  1.33it/s] 40%|████      | 21/52 [00:22<00:23,  1.33it/s] 42%|████▏     | 22/52 [00:23<00:22,  1.33it/s] 44%|████▍     | 23/52 [00:23<00:20,  1.38it/s] 46%|████▌     | 24/52 [00:24<00:20,  1.40it/s] 48%|████▊     | 25/52 [00:25<00:19,  1.40it/s] 50%|█████     | 26/52 [00:25<00:18,  1.37it/s] 52%|█████▏    | 27/52 [00:26<00:18,  1.37it/s] 54%|█████▍    | 28/52 [00:27<00:17,  1.35it/s] 56%|█████▌    | 29/52 [00:28<00:16,  1.36it/s] 58%|█████▊    | 30/52 [00:28<00:15,  1.38it/s] 60%|█████▉    | 31/52 [00:29<00:14,  1.43it/s] 62%|██████▏   | 32/52 [00:30<00:13,  1.47it/s] 63%|██████▎   | 33/52 [00:30<00:12,  1.50it/s] 65%|██████▌   | 34/52 [00:31<00:11,  1.52it/s] 67%|██████▋   | 35/52 [00:32<00:11,  1.53it/s] 69%|██████▉   | 36/52 [00:32<00:10,  1.54it/s] 71%|███████   | 37/52 [00:33<00:09,  1.55it/s] 73%|███████▎  | 38/52 [00:34<00:09,  1.55it/s] 75%|███████▌  | 39/52 [00:34<00:08,  1.55it/s] 77%|███████▋  | 40/52 [00:35<00:07,  1.56it/s] 79%|███████▉  | 41/52 [00:35<00:07,  1.56it/s] 81%|████████  | 42/52 [00:36<00:06,  1.56it/s] 83%|████████▎ | 43/52 [00:37<00:05,  1.56it/s] 85%|████████▍ | 44/52 [00:37<00:05,  1.56it/s] 87%|████████▋ | 45/52 [00:38<00:04,  1.56it/s] 88%|████████▊ | 46/52 [00:39<00:03,  1.57it/s] 90%|█████████ | 47/52 [00:39<00:03,  1.56it/s] 92%|█████████▏| 48/52 [00:40<00:02,  1.56it/s] 94%|█████████▍| 49/52 [00:41<00:01,  1.56it/s] 96%|█████████▌| 50/52 [00:41<00:01,  1.56it/s] 98%|█████████▊| 51/52 [00:42<00:00,  1.57it/s]100%|██████████| 52/52 [00:42<00:00,  1.74it/s]100%|██████████| 52/52 [00:42<00:00,  1.21it/s]
=> result
* total: 10,000
* correct: 6,521
* accuracy: 65.2%
* error: 34.8%
* macro_f1: 64.3%
+ for seed in 1 2 3
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenet_a 2 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenet_a.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenet_a/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetA
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenet_a/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetA
Loading dataset: ImageNetA
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ---------
Dataset    ImageNetA
# classes  200
# train_x  7,500
# test     7,500
---------  ---------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed2/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/39 [00:00<?, ?it/s]  3%|▎         | 1/39 [00:06<04:04,  6.44s/it]  5%|▌         | 2/39 [00:06<01:45,  2.85s/it]  8%|▊         | 3/39 [00:07<01:01,  1.71s/it] 10%|█         | 4/39 [00:07<00:41,  1.18s/it] 13%|█▎        | 5/39 [00:07<00:30,  1.11it/s] 15%|█▌        | 6/39 [00:08<00:23,  1.38it/s] 18%|█▊        | 7/39 [00:08<00:19,  1.62it/s] 21%|██        | 8/39 [00:09<00:16,  1.83it/s] 23%|██▎       | 9/39 [00:09<00:15,  1.98it/s] 26%|██▌       | 10/39 [00:09<00:13,  2.11it/s] 28%|██▊       | 11/39 [00:10<00:12,  2.21it/s] 31%|███       | 12/39 [00:10<00:11,  2.28it/s] 33%|███▎      | 13/39 [00:11<00:11,  2.32it/s] 36%|███▌      | 14/39 [00:11<00:10,  2.40it/s] 38%|███▊      | 15/39 [00:11<00:09,  2.44it/s] 41%|████      | 16/39 [00:12<00:09,  2.47it/s] 44%|████▎     | 17/39 [00:12<00:08,  2.58it/s] 46%|████▌     | 18/39 [00:13<00:08,  2.59it/s] 49%|████▊     | 19/39 [00:13<00:07,  2.67it/s] 51%|█████▏    | 20/39 [00:13<00:06,  2.86it/s] 54%|█████▍    | 21/39 [00:13<00:05,  3.01it/s] 56%|█████▋    | 22/39 [00:14<00:05,  3.13it/s] 59%|█████▉    | 23/39 [00:14<00:04,  3.22it/s] 62%|██████▏   | 24/39 [00:14<00:04,  3.27it/s] 64%|██████▍   | 25/39 [00:15<00:04,  3.32it/s] 67%|██████▋   | 26/39 [00:15<00:03,  3.34it/s] 69%|██████▉   | 27/39 [00:15<00:03,  3.37it/s] 72%|███████▏  | 28/39 [00:16<00:03,  3.39it/s] 74%|███████▍  | 29/39 [00:16<00:02,  3.41it/s] 77%|███████▋  | 30/39 [00:16<00:02,  3.41it/s] 79%|███████▉  | 31/39 [00:16<00:02,  3.42it/s] 82%|████████▏ | 32/39 [00:17<00:02,  3.43it/s] 85%|████████▍ | 33/39 [00:17<00:01,  3.42it/s] 87%|████████▋ | 34/39 [00:17<00:01,  3.41it/s] 90%|████████▉ | 35/39 [00:18<00:01,  3.40it/s] 92%|█████████▏| 36/39 [00:18<00:00,  3.40it/s] 95%|█████████▍| 37/39 [00:18<00:00,  3.39it/s] 97%|█████████▋| 38/39 [00:18<00:00,  3.37it/s]100%|██████████| 39/39 [00:19<00:00,  4.02it/s]100%|██████████| 39/39 [00:19<00:00,  2.03it/s]
=> result
* total: 7,500
* correct: 3,659
* accuracy: 48.8%
* error: 51.2%
* macro_f1: 45.1%
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenet_r 2 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenet_r.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenet_r/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetR
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenet_r/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetR
Loading dataset: ImageNetR
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ---------
Dataset    ImageNetR
# classes  200
# train_x  30,000
# test     30,000
---------  ---------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed2/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/154 [00:00<?, ?it/s]  1%|          | 1/154 [00:05<15:03,  5.91s/it]  1%|▏         | 2/154 [00:06<07:08,  2.82s/it]  2%|▏         | 3/154 [00:06<04:14,  1.69s/it]  3%|▎         | 4/154 [00:07<02:54,  1.17s/it]  3%|▎         | 5/154 [00:07<02:14,  1.11it/s]  4%|▍         | 6/154 [00:08<01:47,  1.37it/s]  5%|▍         | 7/154 [00:08<01:31,  1.61it/s]  5%|▌         | 8/154 [00:08<01:20,  1.81it/s]  6%|▌         | 9/154 [00:09<01:13,  1.97it/s]  6%|▋         | 10/154 [00:09<01:09,  2.08it/s]  7%|▋         | 11/154 [00:10<01:05,  2.18it/s]  8%|▊         | 12/154 [00:10<01:02,  2.26it/s]  8%|▊         | 13/154 [00:10<01:00,  2.32it/s]  9%|▉         | 14/154 [00:11<00:59,  2.34it/s] 10%|▉         | 15/154 [00:11<00:58,  2.38it/s] 10%|█         | 16/154 [00:12<00:57,  2.38it/s] 11%|█         | 17/154 [00:12<00:58,  2.33it/s] 12%|█▏        | 18/154 [00:13<00:57,  2.38it/s] 12%|█▏        | 19/154 [00:13<00:56,  2.38it/s] 13%|█▎        | 20/154 [00:13<00:55,  2.40it/s] 14%|█▎        | 21/154 [00:14<00:55,  2.41it/s] 14%|█▍        | 22/154 [00:14<00:54,  2.42it/s] 15%|█▍        | 23/154 [00:15<00:54,  2.41it/s] 16%|█▌        | 24/154 [00:15<00:53,  2.42it/s] 16%|█▌        | 25/154 [00:15<00:53,  2.43it/s] 17%|█▋        | 26/154 [00:16<00:52,  2.42it/s] 18%|█▊        | 27/154 [00:16<00:52,  2.42it/s] 18%|█▊        | 28/154 [00:17<00:51,  2.44it/s] 19%|█▉        | 29/154 [00:17<00:51,  2.41it/s] 19%|█▉        | 30/154 [00:17<00:50,  2.45it/s] 20%|██        | 31/154 [00:18<00:50,  2.43it/s] 21%|██        | 32/154 [00:18<00:50,  2.42it/s] 21%|██▏       | 33/154 [00:19<00:49,  2.47it/s] 22%|██▏       | 34/154 [00:19<00:48,  2.47it/s] 23%|██▎       | 35/154 [00:20<00:48,  2.44it/s] 23%|██▎       | 36/154 [00:20<00:48,  2.44it/s] 24%|██▍       | 37/154 [00:20<00:47,  2.47it/s] 25%|██▍       | 38/154 [00:21<00:46,  2.47it/s] 25%|██▌       | 39/154 [00:21<00:46,  2.46it/s] 26%|██▌       | 40/154 [00:22<00:45,  2.48it/s] 27%|██▋       | 41/154 [00:22<00:45,  2.50it/s] 27%|██▋       | 42/154 [00:22<00:45,  2.47it/s] 28%|██▊       | 43/154 [00:23<00:45,  2.46it/s] 29%|██▊       | 44/154 [00:23<00:44,  2.45it/s] 29%|██▉       | 45/154 [00:24<00:43,  2.49it/s] 30%|██▉       | 46/154 [00:24<00:43,  2.49it/s] 31%|███       | 47/154 [00:24<00:43,  2.46it/s] 31%|███       | 48/154 [00:25<00:43,  2.46it/s] 32%|███▏      | 49/154 [00:25<00:42,  2.46it/s] 32%|███▏      | 50/154 [00:26<00:42,  2.47it/s] 33%|███▎      | 51/154 [00:26<00:41,  2.47it/s] 34%|███▍      | 52/154 [00:26<00:41,  2.46it/s] 34%|███▍      | 53/154 [00:27<00:40,  2.48it/s] 35%|███▌      | 54/154 [00:27<00:40,  2.47it/s] 36%|███▌      | 55/154 [00:28<00:39,  2.51it/s] 36%|███▋      | 56/154 [00:28<00:39,  2.49it/s] 37%|███▋      | 57/154 [00:28<00:39,  2.48it/s] 38%|███▊      | 58/154 [00:29<00:38,  2.51it/s] 38%|███▊      | 59/154 [00:29<00:38,  2.49it/s] 39%|███▉      | 60/154 [00:30<00:37,  2.51it/s] 40%|███▉      | 61/154 [00:30<00:36,  2.52it/s] 40%|████      | 62/154 [00:30<00:36,  2.50it/s] 41%|████      | 63/154 [00:31<00:36,  2.48it/s] 42%|████▏     | 64/154 [00:31<00:36,  2.47it/s] 42%|████▏     | 65/154 [00:32<00:35,  2.48it/s] 43%|████▎     | 66/154 [00:32<00:35,  2.47it/s] 44%|████▎     | 67/154 [00:32<00:34,  2.50it/s] 44%|████▍     | 68/154 [00:33<00:34,  2.50it/s] 45%|████▍     | 69/154 [00:33<00:34,  2.48it/s] 45%|████▌     | 70/154 [00:34<00:34,  2.46it/s] 46%|████▌     | 71/154 [00:34<00:33,  2.48it/s] 47%|████▋     | 72/154 [00:34<00:33,  2.46it/s] 47%|████▋     | 73/154 [00:35<00:33,  2.43it/s] 48%|████▊     | 74/154 [00:35<00:32,  2.46it/s] 49%|████▊     | 75/154 [00:36<00:32,  2.45it/s] 49%|████▉     | 76/154 [00:36<00:32,  2.43it/s] 50%|█████     | 77/154 [00:37<00:31,  2.44it/s] 51%|█████     | 78/154 [00:37<00:31,  2.44it/s] 51%|█████▏    | 79/154 [00:37<00:30,  2.43it/s] 52%|█████▏    | 80/154 [00:38<00:30,  2.43it/s] 53%|█████▎    | 81/154 [00:38<00:29,  2.44it/s] 53%|█████▎    | 82/154 [00:39<00:29,  2.42it/s] 54%|█████▍    | 83/154 [00:39<00:28,  2.47it/s] 55%|█████▍    | 84/154 [00:39<00:28,  2.47it/s] 55%|█████▌    | 85/154 [00:40<00:27,  2.48it/s] 56%|█████▌    | 86/154 [00:40<00:27,  2.50it/s] 56%|█████▋    | 87/154 [00:41<00:26,  2.54it/s] 57%|█████▋    | 88/154 [00:41<00:26,  2.51it/s] 58%|█████▊    | 89/154 [00:41<00:26,  2.48it/s] 58%|█████▊    | 90/154 [00:42<00:25,  2.48it/s] 59%|█████▉    | 91/154 [00:42<00:25,  2.49it/s] 60%|█████▉    | 92/154 [00:43<00:24,  2.50it/s] 60%|██████    | 93/154 [00:43<00:24,  2.48it/s] 61%|██████    | 94/154 [00:43<00:24,  2.47it/s] 62%|██████▏   | 95/154 [00:44<00:23,  2.49it/s] 62%|██████▏   | 96/154 [00:44<00:23,  2.49it/s] 63%|██████▎   | 97/154 [00:45<00:22,  2.49it/s] 64%|██████▎   | 98/154 [00:45<00:22,  2.48it/s] 64%|██████▍   | 99/154 [00:45<00:22,  2.48it/s] 65%|██████▍   | 100/154 [00:46<00:21,  2.49it/s] 66%|██████▌   | 101/154 [00:46<00:21,  2.49it/s] 66%|██████▌   | 102/154 [00:47<00:20,  2.50it/s] 67%|██████▋   | 103/154 [00:47<00:20,  2.51it/s] 68%|██████▊   | 104/154 [00:47<00:19,  2.52it/s] 68%|██████▊   | 105/154 [00:48<00:19,  2.49it/s] 69%|██████▉   | 106/154 [00:48<00:19,  2.49it/s] 69%|██████▉   | 107/154 [00:49<00:19,  2.47it/s] 70%|███████   | 108/154 [00:49<00:18,  2.46it/s] 71%|███████   | 109/154 [00:49<00:18,  2.47it/s] 71%|███████▏  | 110/154 [00:50<00:17,  2.48it/s] 72%|███████▏  | 111/154 [00:50<00:17,  2.50it/s] 73%|███████▎  | 112/154 [00:51<00:16,  2.49it/s] 73%|███████▎  | 113/154 [00:51<00:16,  2.48it/s] 74%|███████▍  | 114/154 [00:51<00:16,  2.49it/s] 75%|███████▍  | 115/154 [00:52<00:15,  2.53it/s] 75%|███████▌  | 116/154 [00:52<00:15,  2.48it/s] 76%|███████▌  | 117/154 [00:53<00:14,  2.55it/s] 77%|███████▋  | 118/154 [00:53<00:13,  2.60it/s] 77%|███████▋  | 119/154 [00:53<00:13,  2.55it/s] 78%|███████▊  | 120/154 [00:54<00:13,  2.52it/s] 79%|███████▊  | 121/154 [00:54<00:13,  2.49it/s] 79%|███████▉  | 122/154 [00:55<00:12,  2.47it/s] 80%|███████▉  | 123/154 [00:55<00:12,  2.46it/s] 81%|████████  | 124/154 [00:55<00:12,  2.47it/s] 81%|████████  | 125/154 [00:56<00:11,  2.50it/s] 82%|████████▏ | 126/154 [00:56<00:11,  2.51it/s] 82%|████████▏ | 127/154 [00:57<00:10,  2.53it/s] 83%|████████▎ | 128/154 [00:57<00:10,  2.54it/s] 84%|████████▍ | 129/154 [00:57<00:09,  2.51it/s] 84%|████████▍ | 130/154 [00:58<00:09,  2.48it/s] 85%|████████▌ | 131/154 [00:58<00:09,  2.51it/s] 86%|████████▌ | 132/154 [00:58<00:08,  2.66it/s] 86%|████████▋ | 133/154 [00:59<00:08,  2.62it/s] 87%|████████▋ | 134/154 [00:59<00:07,  2.77it/s] 88%|████████▊ | 135/154 [00:59<00:06,  2.94it/s] 88%|████████▊ | 136/154 [01:00<00:05,  3.07it/s] 89%|████████▉ | 137/154 [01:00<00:05,  3.17it/s] 90%|████████▉ | 138/154 [01:00<00:04,  3.24it/s] 90%|█████████ | 139/154 [01:01<00:04,  3.29it/s] 91%|█████████ | 140/154 [01:01<00:04,  3.33it/s] 92%|█████████▏| 141/154 [01:01<00:03,  3.36it/s] 92%|█████████▏| 142/154 [01:02<00:03,  3.38it/s] 93%|█████████▎| 143/154 [01:02<00:03,  3.39it/s] 94%|█████████▎| 144/154 [01:02<00:02,  3.40it/s] 94%|█████████▍| 145/154 [01:02<00:02,  3.41it/s] 95%|█████████▍| 146/154 [01:03<00:02,  3.42it/s] 95%|█████████▌| 147/154 [01:03<00:02,  3.41it/s] 96%|█████████▌| 148/154 [01:03<00:01,  3.41it/s] 97%|█████████▋| 149/154 [01:04<00:01,  3.42it/s] 97%|█████████▋| 150/154 [01:04<00:01,  3.42it/s] 98%|█████████▊| 151/154 [01:04<00:00,  3.42it/s] 99%|█████████▊| 152/154 [01:04<00:00,  3.42it/s] 99%|█████████▉| 153/154 [01:05<00:00,  3.40it/s]100%|██████████| 154/154 [01:05<00:00,  2.35it/s]
=> result
* total: 30,000
* correct: 23,001
* accuracy: 76.7%
* error: 23.3%
* macro_f1: 74.7%
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenet_sketch 2 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenet_sketch.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenet_sketch/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetSketch
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenet_sketch/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetSketch
Loading dataset: ImageNetSketch
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------
Dataset    ImageNetSketch
# classes  1,000
# train_x  50,889
# test     50,889
---------  --------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed2/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/260 [00:00<?, ?it/s]  0%|          | 1/260 [00:08<37:04,  8.59s/it]  1%|          | 2/260 [00:09<17:30,  4.07s/it]  1%|          | 3/260 [00:10<11:52,  2.77s/it]  2%|▏         | 4/260 [00:11<08:51,  2.08s/it]  2%|▏         | 5/260 [00:12<06:41,  1.57s/it]  2%|▏         | 6/260 [00:13<05:25,  1.28s/it]  3%|▎         | 7/260 [00:13<04:33,  1.08s/it]  3%|▎         | 8/260 [00:14<04:07,  1.02it/s]  3%|▎         | 9/260 [00:15<03:46,  1.11it/s]  4%|▍         | 10/260 [00:16<03:34,  1.17it/s]  4%|▍         | 11/260 [00:16<03:27,  1.20it/s]  5%|▍         | 12/260 [00:17<03:20,  1.24it/s]  5%|▌         | 13/260 [00:18<03:14,  1.27it/s]  5%|▌         | 14/260 [00:19<03:10,  1.29it/s]  6%|▌         | 15/260 [00:19<03:11,  1.28it/s]  6%|▌         | 16/260 [00:20<03:12,  1.27it/s]  7%|▋         | 17/260 [00:21<03:10,  1.27it/s]  7%|▋         | 18/260 [00:22<03:05,  1.30it/s]  7%|▋         | 19/260 [00:22<03:07,  1.29it/s]  8%|▊         | 20/260 [00:23<03:04,  1.30it/s]  8%|▊         | 21/260 [00:24<03:05,  1.29it/s]  8%|▊         | 22/260 [00:25<03:04,  1.29it/s]  9%|▉         | 23/260 [00:26<03:08,  1.26it/s]  9%|▉         | 24/260 [00:26<03:04,  1.28it/s] 10%|▉         | 25/260 [00:27<03:01,  1.29it/s] 10%|█         | 26/260 [00:28<02:58,  1.31it/s] 10%|█         | 27/260 [00:29<02:58,  1.30it/s] 11%|█         | 28/260 [00:29<02:56,  1.32it/s] 11%|█         | 29/260 [00:30<02:59,  1.29it/s] 12%|█▏        | 30/260 [00:31<02:55,  1.31it/s] 12%|█▏        | 31/260 [00:32<02:50,  1.34it/s] 12%|█▏        | 32/260 [00:32<02:43,  1.39it/s] 13%|█▎        | 33/260 [00:33<02:42,  1.40it/s] 13%|█▎        | 34/260 [00:34<02:38,  1.43it/s] 13%|█▎        | 35/260 [00:34<02:37,  1.43it/s] 14%|█▍        | 36/260 [00:35<02:32,  1.46it/s] 14%|█▍        | 37/260 [00:36<02:34,  1.44it/s] 15%|█▍        | 38/260 [00:36<02:34,  1.43it/s] 15%|█▌        | 39/260 [00:37<02:33,  1.44it/s] 15%|█▌        | 40/260 [00:38<02:32,  1.45it/s] 16%|█▌        | 41/260 [00:38<02:30,  1.46it/s] 16%|█▌        | 42/260 [00:39<02:32,  1.43it/s] 17%|█▋        | 43/260 [00:40<02:29,  1.46it/s] 17%|█▋        | 44/260 [00:41<02:27,  1.47it/s] 17%|█▋        | 45/260 [00:41<02:27,  1.46it/s] 18%|█▊        | 46/260 [00:42<02:29,  1.43it/s] 18%|█▊        | 47/260 [00:43<02:25,  1.46it/s] 18%|█▊        | 48/260 [00:43<02:27,  1.44it/s] 19%|█▉        | 49/260 [00:44<02:24,  1.46it/s] 19%|█▉        | 50/260 [00:45<02:26,  1.43it/s] 20%|█▉        | 51/260 [00:45<02:27,  1.42it/s] 20%|██        | 52/260 [00:46<02:28,  1.40it/s] 20%|██        | 53/260 [00:47<02:25,  1.42it/s] 21%|██        | 54/260 [00:48<02:25,  1.42it/s] 21%|██        | 55/260 [00:48<02:32,  1.34it/s] 22%|██▏       | 56/260 [00:49<02:37,  1.30it/s] 22%|██▏       | 57/260 [00:50<02:33,  1.32it/s] 22%|██▏       | 58/260 [00:51<02:34,  1.30it/s] 23%|██▎       | 59/260 [00:52<02:32,  1.31it/s] 23%|██▎       | 60/260 [00:52<02:32,  1.31it/s] 23%|██▎       | 61/260 [00:53<02:32,  1.31it/s] 24%|██▍       | 62/260 [00:54<02:31,  1.30it/s] 24%|██▍       | 63/260 [00:55<02:27,  1.34it/s] 25%|██▍       | 64/260 [00:55<02:27,  1.33it/s] 25%|██▌       | 65/260 [00:56<02:28,  1.31it/s] 25%|██▌       | 66/260 [00:57<02:24,  1.35it/s] 26%|██▌       | 67/260 [00:58<02:23,  1.35it/s] 26%|██▌       | 68/260 [00:58<02:22,  1.35it/s] 27%|██▋       | 69/260 [00:59<02:22,  1.34it/s] 27%|██▋       | 70/260 [01:00<02:20,  1.35it/s] 27%|██▋       | 71/260 [01:00<02:20,  1.34it/s] 28%|██▊       | 72/260 [01:01<02:16,  1.37it/s] 28%|██▊       | 73/260 [01:02<02:15,  1.38it/s] 28%|██▊       | 74/260 [01:03<02:15,  1.37it/s] 29%|██▉       | 75/260 [01:03<02:12,  1.40it/s] 29%|██▉       | 76/260 [01:04<02:10,  1.41it/s] 30%|██▉       | 77/260 [01:05<02:10,  1.40it/s] 30%|███       | 78/260 [01:05<02:08,  1.42it/s] 30%|███       | 79/260 [01:06<02:09,  1.39it/s] 31%|███       | 80/260 [01:07<02:11,  1.37it/s] 31%|███       | 81/260 [01:08<02:07,  1.41it/s] 32%|███▏      | 82/260 [01:08<02:09,  1.37it/s] 32%|███▏      | 83/260 [01:09<02:12,  1.34it/s] 32%|███▏      | 84/260 [01:10<02:10,  1.35it/s] 33%|███▎      | 85/260 [01:11<02:07,  1.37it/s] 33%|███▎      | 86/260 [01:11<02:04,  1.40it/s] 33%|███▎      | 87/260 [01:12<02:06,  1.37it/s] 34%|███▍      | 88/260 [01:13<02:03,  1.39it/s] 34%|███▍      | 89/260 [01:13<02:04,  1.37it/s] 35%|███▍      | 90/260 [01:14<02:05,  1.35it/s] 35%|███▌      | 91/260 [01:15<02:06,  1.33it/s] 35%|███▌      | 92/260 [01:16<02:06,  1.33it/s] 36%|███▌      | 93/260 [01:17<02:06,  1.32it/s] 36%|███▌      | 94/260 [01:17<02:06,  1.31it/s] 37%|███▋      | 95/260 [01:18<02:05,  1.31it/s] 37%|███▋      | 96/260 [01:19<02:03,  1.33it/s] 37%|███▋      | 97/260 [01:20<02:00,  1.35it/s] 38%|███▊      | 98/260 [01:20<01:57,  1.38it/s] 38%|███▊      | 99/260 [01:21<01:55,  1.40it/s] 38%|███▊      | 100/260 [01:22<01:56,  1.38it/s] 39%|███▉      | 101/260 [01:22<01:58,  1.34it/s] 39%|███▉      | 102/260 [01:23<01:57,  1.34it/s] 40%|███▉      | 103/260 [01:24<01:55,  1.35it/s] 40%|████      | 104/260 [01:25<01:54,  1.37it/s] 40%|████      | 105/260 [01:25<01:53,  1.36it/s] 41%|████      | 106/260 [01:26<01:52,  1.37it/s] 41%|████      | 107/260 [01:27<01:52,  1.37it/s] 42%|████▏     | 108/260 [01:28<01:52,  1.36it/s] 42%|████▏     | 109/260 [01:28<01:52,  1.34it/s] 42%|████▏     | 110/260 [01:29<01:52,  1.33it/s] 43%|████▎     | 111/260 [01:30<01:54,  1.30it/s] 43%|████▎     | 112/260 [01:31<01:55,  1.29it/s] 43%|████▎     | 113/260 [01:32<01:55,  1.27it/s] 44%|████▍     | 114/260 [01:32<01:55,  1.26it/s] 44%|████▍     | 115/260 [01:33<01:54,  1.27it/s] 45%|████▍     | 116/260 [01:34<01:52,  1.28it/s] 45%|████▌     | 117/260 [01:35<01:51,  1.28it/s] 45%|████▌     | 118/260 [01:35<01:49,  1.29it/s] 46%|████▌     | 119/260 [01:36<01:48,  1.30it/s] 46%|████▌     | 120/260 [01:37<01:48,  1.29it/s] 47%|████▋     | 121/260 [01:38<01:47,  1.30it/s] 47%|████▋     | 122/260 [01:38<01:46,  1.29it/s] 47%|████▋     | 123/260 [01:39<01:45,  1.29it/s] 48%|████▊     | 124/260 [01:40<01:44,  1.30it/s] 48%|████▊     | 125/260 [01:41<01:44,  1.30it/s] 48%|████▊     | 126/260 [01:42<01:43,  1.30it/s] 49%|████▉     | 127/260 [01:42<01:42,  1.30it/s] 49%|████▉     | 128/260 [01:43<01:41,  1.30it/s] 50%|████▉     | 129/260 [01:44<01:40,  1.31it/s] 50%|█████     | 130/260 [01:45<01:40,  1.29it/s] 50%|█████     | 131/260 [01:45<01:40,  1.28it/s] 51%|█████     | 132/260 [01:46<01:40,  1.27it/s] 51%|█████     | 133/260 [01:47<01:41,  1.25it/s] 52%|█████▏    | 134/260 [01:48<01:41,  1.24it/s] 52%|█████▏    | 135/260 [01:49<01:41,  1.23it/s] 52%|█████▏    | 136/260 [01:50<01:39,  1.25it/s] 53%|█████▎    | 137/260 [01:50<01:37,  1.26it/s] 53%|█████▎    | 138/260 [01:51<01:35,  1.28it/s] 53%|█████▎    | 139/260 [01:52<01:34,  1.27it/s] 54%|█████▍    | 140/260 [01:53<01:32,  1.29it/s] 54%|█████▍    | 141/260 [01:53<01:33,  1.27it/s] 55%|█████▍    | 142/260 [01:54<01:33,  1.26it/s] 55%|█████▌    | 143/260 [01:55<01:32,  1.27it/s] 55%|█████▌    | 144/260 [01:56<01:31,  1.26it/s] 56%|█████▌    | 145/260 [01:57<01:31,  1.26it/s] 56%|█████▌    | 146/260 [01:57<01:30,  1.26it/s] 57%|█████▋    | 147/260 [01:58<01:28,  1.27it/s] 57%|█████▋    | 148/260 [01:59<01:27,  1.28it/s] 57%|█████▋    | 149/260 [02:00<01:29,  1.24it/s] 58%|█████▊    | 150/260 [02:01<01:27,  1.26it/s] 58%|█████▊    | 151/260 [02:01<01:27,  1.25it/s] 58%|█████▊    | 152/260 [02:02<01:25,  1.26it/s] 59%|█████▉    | 153/260 [02:03<01:25,  1.25it/s] 59%|█████▉    | 154/260 [02:04<01:24,  1.26it/s] 60%|█████▉    | 155/260 [02:05<01:23,  1.26it/s] 60%|██████    | 156/260 [02:05<01:23,  1.25it/s] 60%|██████    | 157/260 [02:06<01:21,  1.27it/s] 61%|██████    | 158/260 [02:07<01:19,  1.29it/s] 61%|██████    | 159/260 [02:08<01:16,  1.32it/s] 62%|██████▏   | 160/260 [02:08<01:15,  1.32it/s] 62%|██████▏   | 161/260 [02:09<01:14,  1.34it/s] 62%|██████▏   | 162/260 [02:10<01:14,  1.32it/s] 63%|██████▎   | 163/260 [02:11<01:14,  1.31it/s] 63%|██████▎   | 164/260 [02:11<01:14,  1.29it/s] 63%|██████▎   | 165/260 [02:12<01:14,  1.28it/s] 64%|██████▍   | 166/260 [02:13<01:11,  1.31it/s] 64%|██████▍   | 167/260 [02:14<01:11,  1.31it/s] 65%|██████▍   | 168/260 [02:14<01:10,  1.30it/s] 65%|██████▌   | 169/260 [02:15<01:10,  1.29it/s] 65%|██████▌   | 170/260 [02:16<01:09,  1.29it/s] 66%|██████▌   | 171/260 [02:17<01:08,  1.29it/s] 66%|██████▌   | 172/260 [02:18<01:09,  1.27it/s] 67%|██████▋   | 173/260 [02:18<01:08,  1.26it/s] 67%|██████▋   | 174/260 [02:19<01:07,  1.27it/s] 67%|██████▋   | 175/260 [02:20<01:06,  1.27it/s] 68%|██████▊   | 176/260 [02:21<01:07,  1.24it/s] 68%|██████▊   | 177/260 [02:22<01:06,  1.25it/s] 68%|██████▊   | 178/260 [02:22<01:05,  1.26it/s] 69%|██████▉   | 179/260 [02:23<01:04,  1.26it/s] 69%|██████▉   | 180/260 [02:24<01:03,  1.26it/s] 70%|██████▉   | 181/260 [02:25<01:02,  1.26it/s] 70%|███████   | 182/260 [02:26<01:02,  1.25it/s] 70%|███████   | 183/260 [02:26<01:00,  1.26it/s] 71%|███████   | 184/260 [02:27<00:59,  1.28it/s] 71%|███████   | 185/260 [02:28<00:57,  1.30it/s] 72%|███████▏  | 186/260 [02:29<00:57,  1.30it/s] 72%|███████▏  | 187/260 [02:29<00:56,  1.30it/s] 72%|███████▏  | 188/260 [02:30<00:55,  1.30it/s] 73%|███████▎  | 189/260 [02:31<00:54,  1.30it/s] 73%|███████▎  | 190/260 [02:32<00:53,  1.30it/s] 73%|███████▎  | 191/260 [02:32<00:53,  1.30it/s] 74%|███████▍  | 192/260 [02:33<00:52,  1.31it/s] 74%|███████▍  | 193/260 [02:34<00:51,  1.31it/s] 75%|███████▍  | 194/260 [02:35<00:49,  1.32it/s] 75%|███████▌  | 195/260 [02:35<00:48,  1.33it/s] 75%|███████▌  | 196/260 [02:36<00:47,  1.36it/s] 76%|███████▌  | 197/260 [02:37<00:46,  1.37it/s] 76%|███████▌  | 198/260 [02:38<00:45,  1.36it/s] 77%|███████▋  | 199/260 [02:38<00:46,  1.31it/s] 77%|███████▋  | 200/260 [02:39<00:46,  1.29it/s] 77%|███████▋  | 201/260 [02:40<00:46,  1.27it/s] 78%|███████▊  | 202/260 [02:41<00:46,  1.25it/s] 78%|███████▊  | 203/260 [02:42<00:45,  1.25it/s] 78%|███████▊  | 204/260 [02:42<00:44,  1.27it/s] 79%|███████▉  | 205/260 [02:43<00:42,  1.30it/s] 79%|███████▉  | 206/260 [02:44<00:40,  1.32it/s] 80%|███████▉  | 207/260 [02:45<00:40,  1.32it/s] 80%|████████  | 208/260 [02:46<00:39,  1.30it/s] 80%|████████  | 209/260 [02:46<00:39,  1.29it/s] 81%|████████  | 210/260 [02:47<00:38,  1.30it/s] 81%|████████  | 211/260 [02:48<00:37,  1.31it/s] 82%|████████▏ | 212/260 [02:49<00:36,  1.31it/s] 82%|████████▏ | 213/260 [02:49<00:36,  1.29it/s] 82%|████████▏ | 214/260 [02:50<00:35,  1.29it/s] 83%|████████▎ | 215/260 [02:51<00:35,  1.28it/s] 83%|████████▎ | 216/260 [02:52<00:34,  1.29it/s] 83%|████████▎ | 217/260 [02:52<00:33,  1.30it/s] 84%|████████▍ | 218/260 [02:53<00:31,  1.31it/s] 84%|████████▍ | 219/260 [02:54<00:30,  1.33it/s] 85%|████████▍ | 220/260 [02:55<00:30,  1.31it/s] 85%|████████▌ | 221/260 [02:55<00:29,  1.32it/s] 85%|████████▌ | 222/260 [02:56<00:28,  1.33it/s] 86%|████████▌ | 223/260 [02:57<00:27,  1.33it/s] 86%|████████▌ | 224/260 [02:58<00:27,  1.31it/s] 87%|████████▋ | 225/260 [02:59<00:26,  1.31it/s] 87%|████████▋ | 226/260 [02:59<00:26,  1.30it/s] 87%|████████▋ | 227/260 [03:00<00:25,  1.31it/s] 88%|████████▊ | 228/260 [03:01<00:24,  1.33it/s] 88%|████████▊ | 229/260 [03:02<00:23,  1.34it/s] 88%|████████▊ | 230/260 [03:02<00:22,  1.32it/s] 89%|████████▉ | 231/260 [03:03<00:21,  1.34it/s] 89%|████████▉ | 232/260 [03:04<00:20,  1.33it/s] 90%|████████▉ | 233/260 [03:05<00:20,  1.34it/s] 90%|█████████ | 234/260 [03:05<00:19,  1.36it/s] 90%|█████████ | 235/260 [03:06<00:18,  1.33it/s] 91%|█████████ | 236/260 [03:07<00:18,  1.32it/s] 91%|█████████ | 237/260 [03:08<00:17,  1.29it/s] 92%|█████████▏| 238/260 [03:08<00:16,  1.30it/s] 92%|█████████▏| 239/260 [03:09<00:16,  1.30it/s] 92%|█████████▏| 240/260 [03:10<00:15,  1.33it/s] 93%|█████████▎| 241/260 [03:10<00:13,  1.38it/s] 93%|█████████▎| 242/260 [03:11<00:12,  1.42it/s] 93%|█████████▎| 243/260 [03:12<00:11,  1.45it/s] 94%|█████████▍| 244/260 [03:12<00:10,  1.47it/s] 94%|█████████▍| 245/260 [03:13<00:10,  1.48it/s] 95%|█████████▍| 246/260 [03:14<00:09,  1.49it/s] 95%|█████████▌| 247/260 [03:14<00:08,  1.50it/s] 95%|█████████▌| 248/260 [03:15<00:08,  1.50it/s] 96%|█████████▌| 249/260 [03:16<00:07,  1.51it/s] 96%|█████████▌| 250/260 [03:16<00:06,  1.51it/s] 97%|█████████▋| 251/260 [03:17<00:05,  1.52it/s] 97%|█████████▋| 252/260 [03:18<00:05,  1.52it/s] 97%|█████████▋| 253/260 [03:18<00:04,  1.51it/s] 98%|█████████▊| 254/260 [03:19<00:03,  1.51it/s] 98%|█████████▊| 255/260 [03:20<00:03,  1.51it/s] 98%|█████████▊| 256/260 [03:20<00:02,  1.52it/s] 99%|█████████▉| 257/260 [03:21<00:01,  1.52it/s] 99%|█████████▉| 258/260 [03:22<00:01,  1.52it/s]100%|█████████▉| 259/260 [03:22<00:00,  1.51it/s]100%|██████████| 260/260 [03:23<00:00,  1.57it/s]100%|██████████| 260/260 [03:23<00:00,  1.28it/s]
=> result
* total: 50,889
* correct: 25,092
* accuracy: 49.3%
* error: 50.7%
* macro_f1: 47.5%
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenetv2 2 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 2
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenetv2.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed2
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenetv2/seed2
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 2
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetV2
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenetv2/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetV2
Loading dataset: ImageNetV2
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    ImageNetV2
# classes  1,000
# train_x  10,000
# test     10,000
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed2/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/52 [00:00<?, ?it/s]  2%|▏         | 1/52 [00:07<06:15,  7.36s/it]  4%|▍         | 2/52 [00:08<02:50,  3.42s/it]  6%|▌         | 3/52 [00:08<01:45,  2.16s/it]  8%|▊         | 4/52 [00:09<01:14,  1.55s/it] 10%|▉         | 5/52 [00:09<00:57,  1.23s/it] 12%|█▏        | 6/52 [00:10<00:48,  1.05s/it] 13%|█▎        | 7/52 [00:11<00:42,  1.06it/s] 15%|█▌        | 8/52 [00:12<00:38,  1.15it/s] 17%|█▋        | 9/52 [00:12<00:35,  1.22it/s] 19%|█▉        | 10/52 [00:13<00:33,  1.27it/s] 21%|██        | 11/52 [00:14<00:30,  1.33it/s] 23%|██▎       | 12/52 [00:14<00:29,  1.35it/s] 25%|██▌       | 13/52 [00:15<00:28,  1.39it/s] 27%|██▋       | 14/52 [00:16<00:26,  1.43it/s] 29%|██▉       | 15/52 [00:16<00:25,  1.47it/s] 31%|███       | 16/52 [00:17<00:25,  1.44it/s] 33%|███▎      | 17/52 [00:18<00:24,  1.41it/s] 35%|███▍      | 18/52 [00:18<00:23,  1.44it/s] 37%|███▋      | 19/52 [00:19<00:23,  1.43it/s] 38%|███▊      | 20/52 [00:20<00:22,  1.42it/s] 40%|████      | 21/52 [00:21<00:21,  1.47it/s] 42%|████▏     | 22/52 [00:21<00:20,  1.48it/s] 44%|████▍     | 23/52 [00:22<00:19,  1.46it/s] 46%|████▌     | 24/52 [00:23<00:19,  1.45it/s] 48%|████▊     | 25/52 [00:23<00:18,  1.45it/s] 50%|█████     | 26/52 [00:24<00:17,  1.45it/s] 52%|█████▏    | 27/52 [00:25<00:17,  1.43it/s] 54%|█████▍    | 28/52 [00:25<00:16,  1.42it/s] 56%|█████▌    | 29/52 [00:26<00:16,  1.44it/s] 58%|█████▊    | 30/52 [00:27<00:14,  1.48it/s] 60%|█████▉    | 31/52 [00:27<00:13,  1.52it/s] 62%|██████▏   | 32/52 [00:28<00:12,  1.55it/s] 63%|██████▎   | 33/52 [00:29<00:12,  1.58it/s] 65%|██████▌   | 34/52 [00:29<00:11,  1.59it/s] 67%|██████▋   | 35/52 [00:30<00:10,  1.61it/s] 69%|██████▉   | 36/52 [00:30<00:09,  1.62it/s] 71%|███████   | 37/52 [00:31<00:09,  1.63it/s] 73%|███████▎  | 38/52 [00:32<00:08,  1.63it/s] 75%|███████▌  | 39/52 [00:32<00:07,  1.63it/s] 77%|███████▋  | 40/52 [00:33<00:07,  1.63it/s] 79%|███████▉  | 41/52 [00:33<00:06,  1.63it/s] 81%|████████  | 42/52 [00:34<00:06,  1.63it/s] 83%|████████▎ | 43/52 [00:35<00:05,  1.63it/s] 85%|████████▍ | 44/52 [00:35<00:04,  1.63it/s] 87%|████████▋ | 45/52 [00:36<00:04,  1.63it/s] 88%|████████▊ | 46/52 [00:37<00:03,  1.63it/s] 90%|█████████ | 47/52 [00:37<00:03,  1.64it/s] 92%|█████████▏| 48/52 [00:38<00:02,  1.64it/s] 94%|█████████▍| 49/52 [00:38<00:01,  1.64it/s] 96%|█████████▌| 50/52 [00:39<00:01,  1.64it/s] 98%|█████████▊| 51/52 [00:40<00:00,  1.64it/s]100%|██████████| 52/52 [00:40<00:00,  1.84it/s]100%|██████████| 52/52 [00:40<00:00,  1.28it/s]
=> result
* total: 10,000
* correct: 6,526
* accuracy: 65.3%
* error: 34.7%
* macro_f1: 64.5%
+ for seed in 1 2 3
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenet_a 3 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenet_a.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenet_a/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetA
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenet_a/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetA
Loading dataset: ImageNetA
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ---------
Dataset    ImageNetA
# classes  200
# train_x  7,500
# test     7,500
---------  ---------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed3/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/39 [00:00<?, ?it/s]  3%|▎         | 1/39 [00:06<04:06,  6.48s/it]  5%|▌         | 2/39 [00:06<01:47,  2.90s/it]  8%|▊         | 3/39 [00:07<01:02,  1.74s/it] 10%|█         | 4/39 [00:07<00:41,  1.19s/it] 13%|█▎        | 5/39 [00:07<00:30,  1.11it/s] 15%|█▌        | 6/39 [00:08<00:24,  1.37it/s] 18%|█▊        | 7/39 [00:08<00:19,  1.62it/s] 21%|██        | 8/39 [00:09<00:16,  1.85it/s] 23%|██▎       | 9/39 [00:09<00:14,  2.01it/s] 26%|██▌       | 10/39 [00:09<00:13,  2.14it/s] 28%|██▊       | 11/39 [00:10<00:12,  2.28it/s] 31%|███       | 12/39 [00:10<00:11,  2.40it/s] 33%|███▎      | 13/39 [00:11<00:10,  2.42it/s] 36%|███▌      | 14/39 [00:11<00:10,  2.43it/s] 38%|███▊      | 15/39 [00:11<00:09,  2.53it/s] 41%|████      | 16/39 [00:12<00:09,  2.49it/s] 44%|████▎     | 17/39 [00:12<00:08,  2.61it/s] 46%|████▌     | 18/39 [00:12<00:08,  2.60it/s] 49%|████▊     | 19/39 [00:13<00:07,  2.79it/s] 51%|█████▏    | 20/39 [00:13<00:06,  2.94it/s] 54%|█████▍    | 21/39 [00:13<00:05,  3.06it/s] 56%|█████▋    | 22/39 [00:14<00:05,  3.12it/s] 59%|█████▉    | 23/39 [00:14<00:05,  3.19it/s] 62%|██████▏   | 24/39 [00:14<00:04,  3.24it/s] 64%|██████▍   | 25/39 [00:15<00:04,  3.28it/s] 67%|██████▋   | 26/39 [00:15<00:03,  3.30it/s] 69%|██████▉   | 27/39 [00:15<00:03,  3.32it/s] 72%|███████▏  | 28/39 [00:15<00:03,  3.32it/s] 74%|███████▍  | 29/39 [00:16<00:03,  3.33it/s] 77%|███████▋  | 30/39 [00:16<00:02,  3.34it/s] 79%|███████▉  | 31/39 [00:16<00:02,  3.35it/s] 82%|████████▏ | 32/39 [00:17<00:02,  3.36it/s] 85%|████████▍ | 33/39 [00:17<00:01,  3.36it/s] 87%|████████▋ | 34/39 [00:17<00:01,  3.36it/s] 90%|████████▉ | 35/39 [00:18<00:01,  3.35it/s] 92%|█████████▏| 36/39 [00:18<00:00,  3.34it/s] 95%|█████████▍| 37/39 [00:18<00:00,  3.35it/s] 97%|█████████▋| 38/39 [00:18<00:00,  3.35it/s]100%|██████████| 39/39 [00:19<00:00,  3.99it/s]100%|██████████| 39/39 [00:19<00:00,  2.03it/s]
=> result
* total: 7,500
* correct: 3,660
* accuracy: 48.8%
* error: 51.2%
* macro_f1: 44.8%
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenet_r 3 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenet_r.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenet_r/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetR
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenet_r/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetR
Loading dataset: ImageNetR
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ---------
Dataset    ImageNetR
# classes  200
# train_x  30,000
# test     30,000
---------  ---------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed3/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/154 [00:00<?, ?it/s]  1%|          | 1/154 [00:06<16:27,  6.46s/it]  1%|▏         | 2/154 [00:06<07:18,  2.88s/it]  2%|▏         | 3/154 [00:07<04:19,  1.72s/it]  3%|▎         | 4/154 [00:07<02:59,  1.19s/it]  3%|▎         | 5/154 [00:07<02:13,  1.11it/s]  4%|▍         | 6/154 [00:08<01:48,  1.36it/s]  5%|▍         | 7/154 [00:08<01:32,  1.59it/s]  5%|▌         | 8/154 [00:09<01:21,  1.79it/s]  6%|▌         | 9/154 [00:09<01:14,  1.95it/s]  6%|▋         | 10/154 [00:10<01:10,  2.05it/s]  7%|▋         | 11/154 [00:10<01:06,  2.15it/s]  8%|▊         | 12/154 [00:10<01:03,  2.24it/s]  8%|▊         | 13/154 [00:11<01:01,  2.30it/s]  9%|▉         | 14/154 [00:11<01:00,  2.32it/s] 10%|▉         | 15/154 [00:12<00:59,  2.35it/s] 10%|█         | 16/154 [00:12<00:57,  2.39it/s] 11%|█         | 17/154 [00:12<00:57,  2.37it/s] 12%|█▏        | 18/154 [00:13<00:56,  2.39it/s] 12%|█▏        | 19/154 [00:13<00:56,  2.41it/s] 13%|█▎        | 20/154 [00:14<00:55,  2.41it/s] 14%|█▎        | 21/154 [00:14<00:55,  2.39it/s] 14%|█▍        | 22/154 [00:14<00:55,  2.40it/s] 15%|█▍        | 23/154 [00:15<00:54,  2.41it/s] 16%|█▌        | 24/154 [00:15<00:54,  2.39it/s] 16%|█▌        | 25/154 [00:16<00:53,  2.40it/s] 17%|█▋        | 26/154 [00:16<00:52,  2.44it/s] 18%|█▊        | 27/154 [00:17<00:52,  2.44it/s] 18%|█▊        | 28/154 [00:17<00:51,  2.43it/s] 19%|█▉        | 29/154 [00:17<00:51,  2.41it/s] 19%|█▉        | 30/154 [00:18<00:51,  2.43it/s] 20%|██        | 31/154 [00:18<00:50,  2.42it/s] 21%|██        | 32/154 [00:19<00:50,  2.41it/s] 21%|██▏       | 33/154 [00:19<00:50,  2.42it/s] 22%|██▏       | 34/154 [00:19<00:48,  2.46it/s] 23%|██▎       | 35/154 [00:20<00:48,  2.47it/s] 23%|██▎       | 36/154 [00:20<00:47,  2.50it/s] 24%|██▍       | 37/154 [00:21<00:46,  2.50it/s] 25%|██▍       | 38/154 [00:21<00:46,  2.49it/s] 25%|██▌       | 39/154 [00:21<00:46,  2.49it/s] 26%|██▌       | 40/154 [00:22<00:45,  2.49it/s] 27%|██▋       | 41/154 [00:22<00:45,  2.49it/s] 27%|██▋       | 42/154 [00:23<00:45,  2.48it/s] 28%|██▊       | 43/154 [00:23<00:45,  2.46it/s] 29%|██▊       | 44/154 [00:23<00:44,  2.45it/s] 29%|██▉       | 45/154 [00:24<00:44,  2.43it/s] 30%|██▉       | 46/154 [00:24<00:43,  2.48it/s] 31%|███       | 47/154 [00:25<00:43,  2.47it/s] 31%|███       | 48/154 [00:25<00:43,  2.46it/s] 32%|███▏      | 49/154 [00:25<00:42,  2.45it/s] 32%|███▏      | 50/154 [00:26<00:42,  2.45it/s] 33%|███▎      | 51/154 [00:26<00:41,  2.45it/s] 34%|███▍      | 52/154 [00:27<00:41,  2.45it/s] 34%|███▍      | 53/154 [00:27<00:41,  2.45it/s] 35%|███▌      | 54/154 [00:28<00:40,  2.44it/s] 36%|███▌      | 55/154 [00:28<00:40,  2.44it/s] 36%|███▋      | 56/154 [00:28<00:40,  2.44it/s] 37%|███▋      | 57/154 [00:29<00:39,  2.46it/s] 38%|███▊      | 58/154 [00:29<00:38,  2.46it/s] 38%|███▊      | 59/154 [00:30<00:38,  2.48it/s] 39%|███▉      | 60/154 [00:30<00:37,  2.48it/s] 40%|███▉      | 61/154 [00:30<00:37,  2.51it/s] 40%|████      | 62/154 [00:31<00:36,  2.49it/s] 41%|████      | 63/154 [00:31<00:36,  2.47it/s] 42%|████▏     | 64/154 [00:32<00:36,  2.45it/s] 42%|████▏     | 65/154 [00:32<00:36,  2.45it/s] 43%|████▎     | 66/154 [00:32<00:36,  2.44it/s] 44%|████▎     | 67/154 [00:33<00:35,  2.46it/s] 44%|████▍     | 68/154 [00:33<00:34,  2.50it/s] 45%|████▍     | 69/154 [00:34<00:34,  2.47it/s] 45%|████▌     | 70/154 [00:34<00:34,  2.46it/s] 46%|████▌     | 71/154 [00:34<00:33,  2.48it/s] 47%|████▋     | 72/154 [00:35<00:33,  2.46it/s] 47%|████▋     | 73/154 [00:35<00:33,  2.43it/s] 48%|████▊     | 74/154 [00:36<00:32,  2.44it/s] 49%|████▊     | 75/154 [00:36<00:32,  2.44it/s] 49%|████▉     | 76/154 [00:36<00:32,  2.43it/s] 50%|█████     | 77/154 [00:37<00:30,  2.52it/s] 51%|█████     | 78/154 [00:37<00:30,  2.49it/s] 51%|█████▏    | 79/154 [00:38<00:30,  2.49it/s] 52%|█████▏    | 80/154 [00:38<00:29,  2.47it/s] 53%|█████▎    | 81/154 [00:38<00:29,  2.50it/s] 53%|█████▎    | 82/154 [00:39<00:28,  2.49it/s] 54%|█████▍    | 83/154 [00:39<00:28,  2.46it/s] 55%|█████▍    | 84/154 [00:40<00:28,  2.46it/s] 55%|█████▌    | 85/154 [00:40<00:27,  2.47it/s] 56%|█████▌    | 86/154 [00:40<00:27,  2.46it/s] 56%|█████▋    | 87/154 [00:41<00:27,  2.45it/s] 57%|█████▋    | 88/154 [00:41<00:26,  2.49it/s] 58%|█████▊    | 89/154 [00:42<00:26,  2.48it/s] 58%|█████▊    | 90/154 [00:42<00:25,  2.48it/s] 59%|█████▉    | 91/154 [00:42<00:25,  2.49it/s] 60%|█████▉    | 92/154 [00:43<00:24,  2.48it/s] 60%|██████    | 93/154 [00:43<00:24,  2.48it/s] 61%|██████    | 94/154 [00:44<00:24,  2.46it/s] 62%|██████▏   | 95/154 [00:44<00:23,  2.47it/s] 62%|██████▏   | 96/154 [00:45<00:23,  2.44it/s] 63%|██████▎   | 97/154 [00:45<00:23,  2.44it/s] 64%|██████▎   | 98/154 [00:45<00:22,  2.46it/s] 64%|██████▍   | 99/154 [00:46<00:22,  2.46it/s] 65%|██████▍   | 100/154 [00:46<00:21,  2.47it/s] 66%|██████▌   | 101/154 [00:47<00:21,  2.49it/s] 66%|██████▌   | 102/154 [00:47<00:20,  2.50it/s] 67%|██████▋   | 103/154 [00:47<00:19,  2.59it/s] 68%|██████▊   | 104/154 [00:48<00:19,  2.56it/s] 68%|██████▊   | 105/154 [00:48<00:19,  2.56it/s] 69%|██████▉   | 106/154 [00:48<00:18,  2.59it/s] 69%|██████▉   | 107/154 [00:49<00:18,  2.52it/s] 70%|███████   | 108/154 [00:49<00:18,  2.50it/s] 71%|███████   | 109/154 [00:50<00:18,  2.46it/s] 71%|███████▏  | 110/154 [00:50<00:17,  2.47it/s] 72%|███████▏  | 111/154 [00:51<00:17,  2.50it/s] 73%|███████▎  | 112/154 [00:51<00:16,  2.50it/s] 73%|███████▎  | 113/154 [00:51<00:16,  2.50it/s] 74%|███████▍  | 114/154 [00:52<00:16,  2.49it/s] 75%|███████▍  | 115/154 [00:52<00:15,  2.47it/s] 75%|███████▌  | 116/154 [00:53<00:15,  2.47it/s] 76%|███████▌  | 117/154 [00:53<00:15,  2.46it/s] 77%|███████▋  | 118/154 [00:53<00:14,  2.45it/s] 77%|███████▋  | 119/154 [00:54<00:14,  2.44it/s] 78%|███████▊  | 120/154 [00:54<00:13,  2.45it/s] 79%|███████▊  | 121/154 [00:55<00:13,  2.45it/s] 79%|███████▉  | 122/154 [00:55<00:12,  2.53it/s] 80%|███████▉  | 123/154 [00:55<00:12,  2.53it/s] 81%|████████  | 124/154 [00:56<00:12,  2.49it/s] 81%|████████  | 125/154 [00:56<00:11,  2.50it/s] 82%|████████▏ | 126/154 [00:57<00:11,  2.51it/s] 82%|████████▏ | 127/154 [00:57<00:10,  2.52it/s] 83%|████████▎ | 128/154 [00:57<00:10,  2.49it/s] 84%|████████▍ | 129/154 [00:58<00:10,  2.47it/s] 84%|████████▍ | 130/154 [00:58<00:09,  2.48it/s] 85%|████████▌ | 131/154 [00:59<00:09,  2.55it/s] 86%|████████▌ | 132/154 [00:59<00:08,  2.66it/s] 86%|████████▋ | 133/154 [00:59<00:07,  2.74it/s] 87%|████████▋ | 134/154 [01:00<00:07,  2.83it/s] 88%|████████▊ | 135/154 [01:00<00:06,  2.98it/s] 88%|████████▊ | 136/154 [01:00<00:05,  3.10it/s] 89%|████████▉ | 137/154 [01:00<00:05,  3.19it/s] 90%|████████▉ | 138/154 [01:01<00:04,  3.26it/s] 90%|█████████ | 139/154 [01:01<00:04,  3.30it/s] 91%|█████████ | 140/154 [01:01<00:04,  3.34it/s] 92%|█████████▏| 141/154 [01:02<00:03,  3.37it/s] 92%|█████████▏| 142/154 [01:02<00:03,  3.39it/s] 93%|█████████▎| 143/154 [01:02<00:03,  3.40it/s] 94%|█████████▎| 144/154 [01:02<00:02,  3.41it/s] 94%|█████████▍| 145/154 [01:03<00:02,  3.41it/s] 95%|█████████▍| 146/154 [01:03<00:02,  3.41it/s] 95%|█████████▌| 147/154 [01:03<00:02,  3.42it/s] 96%|█████████▌| 148/154 [01:04<00:01,  3.42it/s] 97%|█████████▋| 149/154 [01:04<00:01,  3.42it/s] 97%|█████████▋| 150/154 [01:04<00:01,  3.42it/s] 98%|█████████▊| 151/154 [01:05<00:00,  3.43it/s] 99%|█████████▊| 152/154 [01:05<00:00,  3.43it/s] 99%|█████████▉| 153/154 [01:05<00:00,  3.43it/s]100%|██████████| 154/154 [01:05<00:00,  2.34it/s]
=> result
* total: 30,000
* correct: 22,881
* accuracy: 76.3%
* error: 23.7%
* macro_f1: 74.4%
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenet_sketch 3 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenet_sketch.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenet_sketch/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetSketch
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenet_sketch/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetSketch
Loading dataset: ImageNetSketch
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------------
Dataset    ImageNetSketch
# classes  1,000
# train_x  50,889
# test     50,889
---------  --------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.img_prompt', 'prompt_learner.text_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed3/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/260 [00:00<?, ?it/s]  0%|          | 1/260 [00:09<39:04,  9.05s/it]  1%|          | 2/260 [00:10<18:27,  4.29s/it]  1%|          | 3/260 [00:11<12:13,  2.85s/it]  2%|▏         | 4/260 [00:11<08:31,  2.00s/it]  2%|▏         | 5/260 [00:12<06:29,  1.53s/it]  2%|▏         | 6/260 [00:13<05:18,  1.25s/it]  3%|▎         | 7/260 [00:13<04:34,  1.09s/it]  3%|▎         | 8/260 [00:14<04:08,  1.01it/s]  3%|▎         | 9/260 [00:15<03:49,  1.10it/s]  4%|▍         | 10/260 [00:16<03:42,  1.13it/s]  4%|▍         | 11/260 [00:17<03:31,  1.17it/s]  5%|▍         | 12/260 [00:17<03:28,  1.19it/s]  5%|▌         | 13/260 [00:18<03:14,  1.27it/s]  5%|▌         | 14/260 [00:19<03:07,  1.31it/s]  6%|▌         | 15/260 [00:20<03:04,  1.33it/s]  6%|▌         | 16/260 [00:20<03:07,  1.30it/s]  7%|▋         | 17/260 [00:21<03:07,  1.29it/s]  7%|▋         | 18/260 [00:22<03:03,  1.32it/s]  7%|▋         | 19/260 [00:23<03:00,  1.33it/s]  8%|▊         | 20/260 [00:23<02:58,  1.35it/s]  8%|▊         | 21/260 [00:24<03:02,  1.31it/s]  8%|▊         | 22/260 [00:25<03:02,  1.31it/s]  9%|▉         | 23/260 [00:26<03:00,  1.32it/s]  9%|▉         | 24/260 [00:26<03:04,  1.28it/s] 10%|▉         | 25/260 [00:27<02:59,  1.31it/s] 10%|█         | 26/260 [00:28<02:51,  1.37it/s] 10%|█         | 27/260 [00:28<02:44,  1.42it/s] 11%|█         | 28/260 [00:29<02:42,  1.43it/s] 11%|█         | 29/260 [00:30<02:37,  1.46it/s] 12%|█▏        | 30/260 [00:30<02:33,  1.50it/s] 12%|█▏        | 31/260 [00:31<02:33,  1.49it/s] 12%|█▏        | 32/260 [00:32<02:35,  1.47it/s] 13%|█▎        | 33/260 [00:33<02:36,  1.45it/s] 13%|█▎        | 34/260 [00:33<02:37,  1.43it/s] 13%|█▎        | 35/260 [00:34<02:43,  1.37it/s] 14%|█▍        | 36/260 [00:35<02:39,  1.40it/s] 14%|█▍        | 37/260 [00:35<02:37,  1.41it/s] 15%|█▍        | 38/260 [00:36<02:34,  1.43it/s] 15%|█▌        | 39/260 [00:37<02:34,  1.43it/s] 15%|█▌        | 40/260 [00:37<02:32,  1.44it/s] 16%|█▌        | 41/260 [00:38<02:32,  1.44it/s] 16%|█▌        | 42/260 [00:39<02:31,  1.43it/s] 17%|█▋        | 43/260 [00:40<02:31,  1.44it/s] 17%|█▋        | 44/260 [00:40<02:29,  1.45it/s] 17%|█▋        | 45/260 [00:41<02:30,  1.42it/s] 18%|█▊        | 46/260 [00:42<02:30,  1.42it/s] 18%|█▊        | 47/260 [00:42<02:30,  1.42it/s] 18%|█▊        | 48/260 [00:43<02:31,  1.40it/s] 19%|█▉        | 49/260 [00:44<02:31,  1.39it/s] 19%|█▉        | 50/260 [00:45<02:31,  1.38it/s] 20%|█▉        | 51/260 [00:45<02:32,  1.37it/s] 20%|██        | 52/260 [00:46<02:31,  1.37it/s] 20%|██        | 53/260 [00:47<02:32,  1.36it/s] 21%|██        | 54/260 [00:48<02:34,  1.34it/s] 21%|██        | 55/260 [00:48<02:31,  1.35it/s] 22%|██▏       | 56/260 [00:49<02:30,  1.35it/s] 22%|██▏       | 57/260 [00:50<02:35,  1.31it/s] 22%|██▏       | 58/260 [00:51<02:31,  1.33it/s] 23%|██▎       | 59/260 [00:51<02:26,  1.37it/s] 23%|██▎       | 60/260 [00:52<02:26,  1.36it/s] 23%|██▎       | 61/260 [00:53<02:27,  1.35it/s] 24%|██▍       | 62/260 [00:54<02:31,  1.31it/s] 24%|██▍       | 63/260 [00:54<02:28,  1.33it/s] 25%|██▍       | 64/260 [00:55<02:28,  1.32it/s] 25%|██▌       | 65/260 [00:56<02:29,  1.30it/s] 25%|██▌       | 66/260 [00:57<02:28,  1.31it/s] 26%|██▌       | 67/260 [00:57<02:27,  1.31it/s] 26%|██▌       | 68/260 [00:58<02:25,  1.32it/s] 27%|██▋       | 69/260 [00:59<02:25,  1.32it/s] 27%|██▋       | 70/260 [01:00<02:25,  1.31it/s] 27%|██▋       | 71/260 [01:01<02:26,  1.29it/s] 28%|██▊       | 72/260 [01:01<02:27,  1.27it/s] 28%|██▊       | 73/260 [01:02<02:27,  1.27it/s] 28%|██▊       | 74/260 [01:03<02:27,  1.26it/s] 29%|██▉       | 75/260 [01:04<02:25,  1.27it/s] 29%|██▉       | 76/260 [01:04<02:24,  1.27it/s] 30%|██▉       | 77/260 [01:05<02:23,  1.28it/s] 30%|███       | 78/260 [01:06<02:21,  1.29it/s] 30%|███       | 79/260 [01:07<02:20,  1.28it/s] 31%|███       | 80/260 [01:08<02:20,  1.28it/s] 31%|███       | 81/260 [01:08<02:19,  1.29it/s] 32%|███▏      | 82/260 [01:09<02:16,  1.30it/s] 32%|███▏      | 83/260 [01:10<02:15,  1.31it/s] 32%|███▏      | 84/260 [01:11<02:14,  1.31it/s] 33%|███▎      | 85/260 [01:11<02:13,  1.31it/s] 33%|███▎      | 86/260 [01:12<02:13,  1.30it/s] 33%|███▎      | 87/260 [01:13<02:13,  1.30it/s] 34%|███▍      | 88/260 [01:14<02:11,  1.30it/s] 34%|███▍      | 89/260 [01:14<02:12,  1.29it/s] 35%|███▍      | 90/260 [01:15<02:11,  1.30it/s] 35%|███▌      | 91/260 [01:16<02:10,  1.29it/s] 35%|███▌      | 92/260 [01:17<02:07,  1.31it/s] 36%|███▌      | 93/260 [01:18<02:08,  1.30it/s] 36%|███▌      | 94/260 [01:18<02:08,  1.29it/s] 37%|███▋      | 95/260 [01:19<02:06,  1.31it/s] 37%|███▋      | 96/260 [01:20<02:06,  1.30it/s] 37%|███▋      | 97/260 [01:21<02:04,  1.31it/s] 38%|███▊      | 98/260 [01:21<02:02,  1.32it/s] 38%|███▊      | 99/260 [01:22<02:02,  1.32it/s] 38%|███▊      | 100/260 [01:23<02:02,  1.30it/s] 39%|███▉      | 101/260 [01:24<02:03,  1.28it/s] 39%|███▉      | 102/260 [01:24<01:59,  1.32it/s] 40%|███▉      | 103/260 [01:25<01:58,  1.32it/s] 40%|████      | 104/260 [01:26<01:54,  1.36it/s] 40%|████      | 105/260 [01:27<01:51,  1.40it/s] 41%|████      | 106/260 [01:27<01:49,  1.40it/s] 41%|████      | 107/260 [01:28<01:49,  1.40it/s] 42%|████▏     | 108/260 [01:29<01:48,  1.40it/s] 42%|████▏     | 109/260 [01:29<01:53,  1.33it/s] 42%|████▏     | 110/260 [01:30<01:54,  1.31it/s] 43%|████▎     | 111/260 [01:31<01:52,  1.32it/s] 43%|████▎     | 112/260 [01:32<01:54,  1.29it/s] 43%|████▎     | 113/260 [01:33<01:53,  1.29it/s] 44%|████▍     | 114/260 [01:33<01:52,  1.30it/s] 44%|████▍     | 115/260 [01:34<01:53,  1.28it/s] 45%|████▍     | 116/260 [01:35<01:52,  1.27it/s] 45%|████▌     | 117/260 [01:36<01:49,  1.30it/s] 45%|████▌     | 118/260 [01:36<01:47,  1.33it/s] 46%|████▌     | 119/260 [01:37<01:47,  1.31it/s] 46%|████▌     | 120/260 [01:38<01:45,  1.32it/s] 47%|████▋     | 121/260 [01:39<01:44,  1.32it/s] 47%|████▋     | 122/260 [01:39<01:44,  1.32it/s] 47%|████▋     | 123/260 [01:40<01:44,  1.31it/s] 48%|████▊     | 124/260 [01:41<01:44,  1.31it/s] 48%|████▊     | 125/260 [01:42<01:42,  1.31it/s] 48%|████▊     | 126/260 [01:43<01:42,  1.31it/s] 49%|████▉     | 127/260 [01:43<01:41,  1.31it/s] 49%|████▉     | 128/260 [01:44<01:40,  1.32it/s] 50%|████▉     | 129/260 [01:45<01:40,  1.31it/s] 50%|█████     | 130/260 [01:46<01:39,  1.31it/s] 50%|█████     | 131/260 [01:46<01:38,  1.31it/s] 51%|█████     | 132/260 [01:47<01:38,  1.30it/s] 51%|█████     | 133/260 [01:48<01:35,  1.33it/s] 52%|█████▏    | 134/260 [01:49<01:33,  1.34it/s] 52%|█████▏    | 135/260 [01:49<01:32,  1.35it/s] 52%|█████▏    | 136/260 [01:50<01:32,  1.34it/s] 53%|█████▎    | 137/260 [01:51<01:31,  1.35it/s] 53%|█████▎    | 138/260 [01:52<01:31,  1.33it/s] 53%|█████▎    | 139/260 [01:52<01:31,  1.32it/s] 54%|█████▍    | 140/260 [01:53<01:31,  1.31it/s] 54%|█████▍    | 141/260 [01:54<01:32,  1.28it/s] 55%|█████▍    | 142/260 [01:55<01:31,  1.29it/s] 55%|█████▌    | 143/260 [01:55<01:30,  1.30it/s] 55%|█████▌    | 144/260 [01:56<01:29,  1.30it/s] 56%|█████▌    | 145/260 [01:57<01:29,  1.29it/s] 56%|█████▌    | 146/260 [01:58<01:28,  1.28it/s] 57%|█████▋    | 147/260 [01:59<01:27,  1.30it/s] 57%|█████▋    | 148/260 [01:59<01:26,  1.30it/s] 57%|█████▋    | 149/260 [02:00<01:25,  1.30it/s] 58%|█████▊    | 150/260 [02:01<01:23,  1.31it/s] 58%|█████▊    | 151/260 [02:02<01:22,  1.32it/s] 58%|█████▊    | 152/260 [02:02<01:21,  1.32it/s] 59%|█████▉    | 153/260 [02:03<01:22,  1.30it/s] 59%|█████▉    | 154/260 [02:04<01:22,  1.28it/s] 60%|█████▉    | 155/260 [02:05<01:22,  1.28it/s] 60%|██████    | 156/260 [02:06<01:22,  1.27it/s] 60%|██████    | 157/260 [02:06<01:20,  1.28it/s] 61%|██████    | 158/260 [02:07<01:19,  1.29it/s] 61%|██████    | 159/260 [02:08<01:17,  1.30it/s] 62%|██████▏   | 160/260 [02:09<01:16,  1.31it/s] 62%|██████▏   | 161/260 [02:09<01:15,  1.31it/s] 62%|██████▏   | 162/260 [02:10<01:15,  1.30it/s] 63%|██████▎   | 163/260 [02:11<01:13,  1.32it/s] 63%|██████▎   | 164/260 [02:12<01:12,  1.33it/s] 63%|██████▎   | 165/260 [02:12<01:11,  1.33it/s] 64%|██████▍   | 166/260 [02:13<01:10,  1.33it/s] 64%|██████▍   | 167/260 [02:14<01:10,  1.32it/s] 65%|██████▍   | 168/260 [02:15<01:09,  1.32it/s] 65%|██████▌   | 169/260 [02:15<01:09,  1.31it/s] 65%|██████▌   | 170/260 [02:16<01:09,  1.30it/s] 66%|██████▌   | 171/260 [02:17<01:06,  1.35it/s] 66%|██████▌   | 172/260 [02:18<01:06,  1.33it/s] 67%|██████▋   | 173/260 [02:18<01:05,  1.32it/s] 67%|██████▋   | 174/260 [02:19<01:04,  1.34it/s] 67%|██████▋   | 175/260 [02:20<01:02,  1.35it/s] 68%|██████▊   | 176/260 [02:21<01:03,  1.32it/s] 68%|██████▊   | 177/260 [02:21<01:02,  1.33it/s] 68%|██████▊   | 178/260 [02:22<01:00,  1.35it/s] 69%|██████▉   | 179/260 [02:23<01:00,  1.34it/s] 69%|██████▉   | 180/260 [02:24<01:00,  1.31it/s] 70%|██████▉   | 181/260 [02:24<01:00,  1.30it/s] 70%|███████   | 182/260 [02:25<01:00,  1.30it/s] 70%|███████   | 183/260 [02:26<01:00,  1.28it/s] 71%|███████   | 184/260 [02:27<00:59,  1.27it/s] 71%|███████   | 185/260 [02:28<00:58,  1.27it/s] 72%|███████▏  | 186/260 [02:28<00:57,  1.28it/s] 72%|███████▏  | 187/260 [02:29<00:57,  1.26it/s] 72%|███████▏  | 188/260 [02:30<00:55,  1.29it/s] 73%|███████▎  | 189/260 [02:31<00:54,  1.30it/s] 73%|███████▎  | 190/260 [02:31<00:53,  1.31it/s] 73%|███████▎  | 191/260 [02:32<00:52,  1.31it/s] 74%|███████▍  | 192/260 [02:33<00:51,  1.32it/s] 74%|███████▍  | 193/260 [02:34<00:51,  1.31it/s] 75%|███████▍  | 194/260 [02:35<00:51,  1.29it/s] 75%|███████▌  | 195/260 [02:35<00:50,  1.28it/s] 75%|███████▌  | 196/260 [02:36<00:48,  1.32it/s] 76%|███████▌  | 197/260 [02:37<00:48,  1.30it/s] 76%|███████▌  | 198/260 [02:38<00:47,  1.29it/s] 77%|███████▋  | 199/260 [02:38<00:49,  1.24it/s] 77%|███████▋  | 200/260 [02:39<00:48,  1.23it/s] 77%|███████▋  | 201/260 [02:40<00:47,  1.23it/s] 78%|███████▊  | 202/260 [02:41<00:47,  1.22it/s] 78%|███████▊  | 203/260 [02:42<00:46,  1.23it/s] 78%|███████▊  | 204/260 [02:43<00:44,  1.25it/s] 79%|███████▉  | 205/260 [02:43<00:43,  1.27it/s] 79%|███████▉  | 206/260 [02:44<00:42,  1.27it/s] 80%|███████▉  | 207/260 [02:45<00:41,  1.27it/s] 80%|████████  | 208/260 [02:46<00:40,  1.29it/s] 80%|████████  | 209/260 [02:46<00:38,  1.31it/s] 81%|████████  | 210/260 [02:47<00:38,  1.30it/s] 81%|████████  | 211/260 [02:48<00:37,  1.29it/s] 82%|████████▏ | 212/260 [02:49<00:37,  1.27it/s] 82%|████████▏ | 213/260 [02:50<00:37,  1.26it/s] 82%|████████▏ | 214/260 [02:50<00:36,  1.27it/s] 83%|████████▎ | 215/260 [02:51<00:35,  1.28it/s] 83%|████████▎ | 216/260 [02:52<00:34,  1.29it/s] 83%|████████▎ | 217/260 [02:53<00:33,  1.30it/s] 84%|████████▍ | 218/260 [02:53<00:31,  1.31it/s] 84%|████████▍ | 219/260 [02:54<00:30,  1.32it/s] 85%|████████▍ | 220/260 [02:55<00:30,  1.31it/s] 85%|████████▌ | 221/260 [02:56<00:30,  1.28it/s] 85%|████████▌ | 222/260 [02:56<00:29,  1.29it/s] 86%|████████▌ | 223/260 [02:57<00:29,  1.27it/s] 86%|████████▌ | 224/260 [02:58<00:28,  1.26it/s] 87%|████████▋ | 225/260 [02:59<00:27,  1.28it/s] 87%|████████▋ | 226/260 [03:00<00:26,  1.28it/s] 87%|████████▋ | 227/260 [03:00<00:25,  1.30it/s] 88%|████████▊ | 228/260 [03:01<00:24,  1.31it/s] 88%|████████▊ | 229/260 [03:02<00:23,  1.32it/s] 88%|████████▊ | 230/260 [03:03<00:23,  1.30it/s] 89%|████████▉ | 231/260 [03:03<00:22,  1.30it/s] 89%|████████▉ | 232/260 [03:04<00:21,  1.30it/s] 90%|████████▉ | 233/260 [03:05<00:20,  1.32it/s] 90%|█████████ | 234/260 [03:06<00:19,  1.32it/s] 90%|█████████ | 235/260 [03:06<00:18,  1.32it/s] 91%|█████████ | 236/260 [03:07<00:18,  1.30it/s] 91%|█████████ | 237/260 [03:08<00:17,  1.31it/s] 92%|█████████▏| 238/260 [03:09<00:16,  1.31it/s] 92%|█████████▏| 239/260 [03:09<00:16,  1.31it/s] 92%|█████████▏| 240/260 [03:10<00:14,  1.34it/s] 93%|█████████▎| 241/260 [03:11<00:13,  1.40it/s] 93%|█████████▎| 242/260 [03:11<00:12,  1.44it/s] 93%|█████████▎| 243/260 [03:12<00:11,  1.48it/s] 94%|█████████▍| 244/260 [03:13<00:10,  1.50it/s] 94%|█████████▍| 245/260 [03:13<00:09,  1.51it/s] 95%|█████████▍| 246/260 [03:14<00:09,  1.52it/s] 95%|█████████▌| 247/260 [03:15<00:08,  1.52it/s] 95%|█████████▌| 248/260 [03:15<00:07,  1.52it/s] 96%|█████████▌| 249/260 [03:16<00:07,  1.53it/s] 96%|█████████▌| 250/260 [03:17<00:06,  1.53it/s] 97%|█████████▋| 251/260 [03:17<00:05,  1.54it/s] 97%|█████████▋| 252/260 [03:18<00:05,  1.54it/s] 97%|█████████▋| 253/260 [03:19<00:04,  1.54it/s] 98%|█████████▊| 254/260 [03:19<00:03,  1.54it/s] 98%|█████████▊| 255/260 [03:20<00:03,  1.54it/s] 98%|█████████▊| 256/260 [03:21<00:02,  1.54it/s] 99%|█████████▉| 257/260 [03:21<00:01,  1.54it/s] 99%|█████████▉| 258/260 [03:22<00:01,  1.54it/s]100%|█████████▉| 259/260 [03:22<00:00,  1.54it/s]100%|██████████| 260/260 [03:23<00:00,  1.60it/s]100%|██████████| 260/260 [03:23<00:00,  1.28it/s]
=> result
* total: 50,889
* correct: 25,122
* accuracy: 49.4%
* error: 50.6%
* macro_f1: 47.4%
+ for dataset in imagenet_a imagenet_r imagenet_sketch imagenetv2
+ sh scripts/rpo_prime/dg_test.sh imagenet imagenetv2 3 0 main_final_imagenet 16 15 RPO_prime
/shared/s2/lab01/myungjoo/RPO_v2/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
Setting fixed seed: 3
***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RPO_prime/main_final_imagenet.yaml
dataset_config_file: configs/datasets/imagenetv2.yaml
eval_only: True
head: 
load_epoch: 15
model_dir: output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed3
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'all']
output_dir: output/rpo_prime/dg/test_target/source_imagenet/imagenetv2/seed3
resume: 
root: /shared/s2/lab01/dataset/clip
seed: 3
source_domains: None
target_domains: None
trainer: RPO_prime
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 12
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 196
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: ImageNetV2
  NUM_LABELED: -1
  NUM_SHOTS: 16
  PROMPT: a photo of a _.
  ROOT: /shared/s2/lab01/dataset/clip
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.01
  LR_SCHEDULER: cosine
  MAX_EPOCH: 15
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/rpo_prime/dg/test_target/source_imagenet/imagenetv2/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 5
  COUNT_ITER: train_x
  PRINT_FREQ: 2
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LP:
    PREC: fp16
    PROMPT: A photo of a {cls_name}
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RPO_prime
  RPO:
    CTX_INIT: a photo of a
    K1: 18
    K2: 6
    PREC: fp16
    cov_loss: 500
    sdl_loss: 1
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.16.3
Libc version: glibc-2.10

Python version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-debian-bullseye-sid
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 3090
Nvidia driver version: 520.61.05
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] imagenetv2-pytorch==0.1
[pip3] numpy==1.21.5
[pip3] torch==1.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] imagenetv2-pytorch        0.1                      pypi_0    pypi
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py37h7f8727e_0  
[conda] mkl_fft                   1.3.1            py37hd3c417c_0  
[conda] mkl_random                1.2.2            py37h51133e4_0  
[conda] numpy                     1.21.6                   pypi_0    pypi
[conda] numpy-base                1.21.5           py37ha15fc14_3  
[conda] pytorch                   1.13.1          py3.7_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_5    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.14.1               py37_cu117    pytorch
        Pillow (9.4.0)

requested:RPO_prime
Loading trainer: RPO_prime
requested:ImageNetV2
Loading dataset: ImageNetV2
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    ImageNetV2
# classes  1,000
# train_x  10,000
# test     10,000
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Parameters to be updated: {'prompt_learner.text_prompt', 'prompt_learner.img_prompt'}
requested:Classification
Loading evaluator: Classification
Loading weights to prompt_learner from "output/rpo_prime/crossdataset/train_source/imagenet/shots_16/RPO_prime/main_final_imagenet/seed3/prompt_learner/model.pth.tar-15" (epoch = 15)
Evaluate on the *test* set
  0%|          | 0/52 [00:00<?, ?it/s]  2%|▏         | 1/52 [00:07<06:22,  7.51s/it]  4%|▍         | 2/52 [00:08<02:54,  3.48s/it]  6%|▌         | 3/52 [00:08<01:46,  2.17s/it]  8%|▊         | 4/52 [00:09<01:15,  1.57s/it] 10%|▉         | 5/52 [00:10<00:58,  1.25s/it] 12%|█▏        | 6/52 [00:10<00:48,  1.06s/it] 13%|█▎        | 7/52 [00:11<00:42,  1.05it/s] 15%|█▌        | 8/52 [00:12<00:38,  1.13it/s] 17%|█▋        | 9/52 [00:12<00:35,  1.20it/s] 19%|█▉        | 10/52 [00:13<00:33,  1.26it/s] 21%|██        | 11/52 [00:14<00:31,  1.29it/s] 23%|██▎       | 12/52 [00:15<00:30,  1.31it/s] 25%|██▌       | 13/52 [00:15<00:29,  1.31it/s] 27%|██▋       | 14/52 [00:16<00:28,  1.32it/s] 29%|██▉       | 15/52 [00:17<00:28,  1.32it/s] 31%|███       | 16/52 [00:18<00:27,  1.32it/s] 33%|███▎      | 17/52 [00:18<00:26,  1.33it/s] 35%|███▍      | 18/52 [00:19<00:25,  1.32it/s] 37%|███▋      | 19/52 [00:20<00:24,  1.34it/s] 38%|███▊      | 20/52 [00:21<00:24,  1.33it/s] 40%|████      | 21/52 [00:21<00:23,  1.33it/s] 42%|████▏     | 22/52 [00:22<00:22,  1.33it/s] 44%|████▍     | 23/52 [00:23<00:21,  1.35it/s] 46%|████▌     | 24/52 [00:24<00:20,  1.35it/s] 48%|████▊     | 25/52 [00:24<00:19,  1.37it/s] 50%|█████     | 26/52 [00:25<00:19,  1.36it/s] 52%|█████▏    | 27/52 [00:26<00:18,  1.37it/s] 54%|█████▍    | 28/52 [00:27<00:17,  1.36it/s] 56%|█████▌    | 29/52 [00:27<00:16,  1.37it/s] 58%|█████▊    | 30/52 [00:28<00:15,  1.40it/s] 60%|█████▉    | 31/52 [00:29<00:14,  1.43it/s] 62%|██████▏   | 32/52 [00:29<00:13,  1.46it/s] 63%|██████▎   | 33/52 [00:30<00:12,  1.48it/s] 65%|██████▌   | 34/52 [00:31<00:12,  1.50it/s] 67%|██████▋   | 35/52 [00:31<00:11,  1.51it/s] 69%|██████▉   | 36/52 [00:32<00:10,  1.51it/s] 71%|███████   | 37/52 [00:33<00:09,  1.52it/s] 73%|███████▎  | 38/52 [00:33<00:09,  1.52it/s] 75%|███████▌  | 39/52 [00:34<00:08,  1.52it/s] 77%|███████▋  | 40/52 [00:34<00:07,  1.52it/s] 79%|███████▉  | 41/52 [00:35<00:07,  1.53it/s] 81%|████████  | 42/52 [00:36<00:06,  1.53it/s] 83%|████████▎ | 43/52 [00:36<00:05,  1.53it/s] 85%|████████▍ | 44/52 [00:37<00:05,  1.52it/s] 87%|████████▋ | 45/52 [00:38<00:04,  1.52it/s] 88%|████████▊ | 46/52 [00:38<00:03,  1.52it/s] 90%|█████████ | 47/52 [00:39<00:03,  1.53it/s] 92%|█████████▏| 48/52 [00:40<00:02,  1.53it/s] 94%|█████████▍| 49/52 [00:40<00:01,  1.52it/s] 96%|█████████▌| 50/52 [00:41<00:01,  1.52it/s] 98%|█████████▊| 51/52 [00:42<00:00,  1.52it/s]100%|██████████| 52/52 [00:42<00:00,  1.69it/s]100%|██████████| 52/52 [00:42<00:00,  1.22it/s]
=> result
* total: 10,000
* correct: 6,512
* accuracy: 65.1%
* error: 34.9%
* macro_f1: 64.3%
